## Regularized Discriminant Analysis

### Introdução
Em continuidade aos métodos lineares para classificação, este capítulo explora uma alternativa que busca um compromisso entre duas abordagens clássicas: Linear Discriminant Analysis (LDA) e Quadratic Discriminant Analysis (QDA). Regularized Discriminant Analysis (RDA) [^112] surge como uma técnica que visa mitigar as limitações de cada um desses métodos, ao introduzir um mecanismo de regularização que "encolhe" as covariâncias separadas do QDA em direção a uma covariância comum, similar ao LDA. Este processo é análogo à regressão ridge, onde um termo de penalidade é adicionado para evitar overfitting.

### Conceitos Fundamentais
A motivação por trás do RDA reside no fato de que, enquanto o LDA assume que todas as classes compartilham a mesma matriz de covariância, o QDA permite que cada classe tenha sua própria matriz de covariância [^108]. Essa flexibilidade do QDA pode levar a um melhor ajuste aos dados de treinamento, mas também pode resultar em overfitting, especialmente quando o número de amostras é pequeno em relação à dimensionalidade dos dados. O RDA busca um equilíbrio entre esses dois extremos, permitindo uma certa flexibilidade nas covariâncias das classes, ao mesmo tempo em que impõe uma regularização para evitar overfitting.

A forma das matrizes de covariância regularizadas no RDA é dada por [^112]:
$$\Sigma_k(\alpha) = \alpha \hat{\Sigma}_k + (1 - \alpha) \Sigma$$
onde:
- $\Sigma_k(\alpha)$ é a matriz de covariância regularizada para a classe *k*.
- $\hat{\Sigma}_k$ é a matriz de covariância amostral para a classe *k*.
- $\Sigma$ é a matriz de covariância *pooled*, estimada a partir de todas as classes, como no LDA.
- $\alpha \in [0, 1]$ é um parâmetro de regularização que controla o grau de "encolhimento" das covariâncias individuais em direção à covariância *pooled*.

Quando $\alpha = 1$, o RDA se reduz ao QDA, pois cada classe tem sua própria matriz de covariância estimada a partir dos dados [^112]. Quando $\alpha = 0$, o RDA se torna equivalente ao LDA, pois todas as classes compartilham a mesma matriz de covariância *pooled* [^112]. Para valores intermediários de $\alpha$, o RDA representa um compromisso entre esses dois extremos, permitindo que as classes tenham covariâncias diferentes, mas com um grau de regularização que depende do valor de $\alpha$.

Além disso, uma modificação similar permite que $\Sigma$ seja "encolhida" em direção à covariância escalar [^112]:
$$\Sigma(\gamma) = \gamma \Sigma + (1 - \gamma) \hat{\sigma}^2 I$$
onde $\gamma \in [0, 1]$ e $\hat{\sigma}^2$ é a variância escalar. Substituindo $\Sigma$ em (4.13) por $\Sigma(\gamma)$, tem-se uma família mais geral de covariâncias $\Sigma(\alpha, \gamma)$ indexada por um par de parâmetros.

A escolha do valor de $\alpha$ (e, possivelmente, $\gamma$) é crucial para o desempenho do RDA. Em geral, esses parâmetros são selecionados por meio de validação cruzada ou outras técnicas de seleção de modelo, buscando o valor que minimize o erro de classificação em dados não utilizados no treinamento [^112].

**Exemplo:** A Figura 4.7 [^112] ilustra o uso do RDA nos dados de vogais. Tanto o erro de treinamento quanto o de teste melhoram com o aumento de $\alpha$, embora o erro de teste aumente acentuadamente após $\alpha = 0.9$. A grande discrepância entre os erros de treinamento e teste deve-se, em parte, ao fato de existirem muitas medições repetidas em um pequeno número de indivíduos, diferentes nos conjuntos de treinamento e teste.

### Conclusão
O Regularized Discriminant Analysis oferece uma abordagem flexível para classificação que combina as vantagens do LDA e do QDA. Ao introduzir um parâmetro de regularização, o RDA permite controlar o grau de flexibilidade das covariâncias das classes, evitando overfitting e melhorando o desempenho em dados não vistos. A escolha apropriada do parâmetro de regularização é fundamental para o sucesso do RDA, e técnicas de validação cruzada são comumente utilizadas para otimizar esse valor. O RDA se encaixa no conjunto de métodos lineares para classificação, oferecendo uma alternativa robusta e eficiente para uma ampla gama de aplicações.

### Referências
[^112]: Seção 4.3.1, página 112 de "The Elements of Statistical Learning" por Hastie, Tibshirani, and Friedman.
[^108]: Seção 4.3, página 108 de "The Elements of Statistical Learning" por Hastie, Tibshirani, and Friedman.

<!-- END -->