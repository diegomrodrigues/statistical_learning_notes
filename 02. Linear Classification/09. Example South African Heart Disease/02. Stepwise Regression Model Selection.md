### Sele√ß√£o de Modelos via Regress√£o Stepwise e Deviance Residual

```mermaid
graph TB
    subgraph "Stepwise Model Selection"
        direction TB
        A["Initial Model: All predictors"] --> B{"Evaluate Variable Significance"}
        B --"Remove Least Significant"--> C["Refit Model"]
        C --> B
        B --"All Significant"--> D["Final Model"]
    end
```

A **sele√ß√£o de modelos** √© uma etapa crucial na an√°lise estat√≠stica e em aprendizado de m√°quina, com o objetivo de identificar um subconjunto de vari√°veis preditoras que s√£o mais informativas e que levam a um modelo mais parcimonioso e com boa capacidade de generaliza√ß√£o. M√©todos **stepwise**, como o *backward elimination*, oferecem abordagens sistem√°ticas para selecionar um conjunto de vari√°veis mais adequado [^4.4.2].

O *backward elimination* inicia com um modelo contendo todas as vari√°veis preditoras e, iterativamente, remove as vari√°veis menos significativas com base em algum crit√©rio, como o teste de raz√£o de verossimilhan√ßa ou o teste Wald [^4.4.2]. Cada itera√ß√£o envolve a remo√ß√£o da vari√°vel com menor signific√¢ncia e o refit do modelo com o subconjunto restante de vari√°veis. O processo continua at√© que nenhum termo possa ser removido sem aumentar significativamente o erro do modelo, avaliado por um crit√©rio estat√≠stico [^4.4.2].

> üí° **Exemplo Num√©rico:**
>
> Vamos supor que temos um conjunto de dados com uma vari√°vel resposta bin√°ria (y) e quatro vari√°veis preditoras (X1, X2, X3, X4). Inicialmente, ajustamos um modelo log√≠stico com todas as vari√°veis.
>
> ```python
> import numpy as np
> import statsmodels.api as sm
>
> # Dados de exemplo
> y = np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
> X = np.array([[1, 2, 3, 4],
>               [2, 3, 4, 5],
>               [3, 4, 5, 6],
>               [4, 5, 6, 7],
>               [5, 6, 7, 8],
>               [6, 7, 8, 9],
>               [7, 8, 9, 10],
>               [8, 9, 10, 11],
>               [9, 10, 11, 12],
>               [10, 11, 12, 13]])
>
> X = sm.add_constant(X) # Adiciona a constante para o intercepto
>
> # Ajusta o modelo log√≠stico inicial
> model = sm.Logit(y, X)
> result = model.fit()
> print(result.summary())
> ```
>
> Ap√≥s o ajuste, suponha que os p-valores dos testes de Wald para os coeficientes s√£o:
>
> *   X1: 0.02
> *   X2: 0.05
> *   X3: 0.15
> *   X4: 0.30
>
> Usando um n√≠vel de signific√¢ncia de 0.05, a vari√°vel X4 √© a menos significativa. No primeiro passo do *backward elimination*, removemos X4 e reajustamos o modelo.
>
> ```python
> # Remove a vari√°vel X4 e reajusta o modelo
> X_reduced = X[:, [0, 1, 2, 3]] # Mant√©m as colunas 0 (constante), 1, 2 e 3
> model_reduced = sm.Logit(y, X_reduced)
> result_reduced = model_reduced.fit()
> print(result_reduced.summary())
> ```
>
> Agora, suponha que os p-valores para o modelo reduzido s√£o:
> *   X1: 0.01
> *   X2: 0.04
> *   X3: 0.08
>
> A vari√°vel X3 √© a menos significativa agora. Removemos X3 e reajustamos o modelo. Este processo continua at√© que todas as vari√°veis remanescentes sejam significativas.

```mermaid
graph TB
 subgraph "Deviance Calculation"
    direction TB
        A["Log-Likelihood of Model: L(Œ≤ÃÇ)"] --> B["Deviance: D = -2 * log(L(Œ≤ÃÇ))"]
        B --> C["Residual Deviance"]
        C --> D["Model Assessment"]
    end
```

O crit√©rio para avaliar a signific√¢ncia de uma vari√°vel e decidir pela remo√ß√£o pode ser baseado na **deviance residual** [^4.4.2]. A deviance √© uma medida de qu√£o bem um modelo se ajusta aos dados, sendo definida como menos duas vezes o log-likelihood do modelo. Para modelos de regress√£o log√≠stica, a deviance √© dada por [^4.4.3]:

$$
    D = -2 \sum_{i=1}^N [y_i \log(\hat{p}_i) + (1-y_i) \log(1 - \hat{p}_i)]
$$

onde $\hat{p}_i$ s√£o as probabilidades ajustadas pelo modelo. A diferen√ßa na deviance entre dois modelos aninhados (um com mais vari√°veis que o outro) segue aproximadamente uma distribui√ß√£o qui-quadrado sob a hip√≥tese nula de que o modelo mais simples √© verdadeiro. Assim, podemos utilizar um teste de raz√£o de verossimilhan√ßa para determinar se a remo√ß√£o de uma vari√°vel causa um aumento significativo na deviance. Ou seja, se a diferen√ßa de deviance entre um modelo com e sem a vari√°vel a ser testada for estatisticamente significativa, rejeita-se a hip√≥tese nula de que a vari√°vel pode ser removida sem perda de informa√ß√£o [^4.4.2].

> üí° **Exemplo Num√©rico:**
>
> Continuando o exemplo anterior, vamos calcular a deviance para os modelos com e sem a vari√°vel X4.
>
> ```python
> # Calcula a deviance para o modelo completo
> deviance_full = -2 * result.llf
> print(f"Deviance do modelo completo: {deviance_full:.2f}")
>
> # Calcula a deviance para o modelo reduzido
> deviance_reduced = -2 * result_reduced.llf
> print(f"Deviance do modelo reduzido: {deviance_reduced:.2f}")
>
> # Calcula a diferen√ßa de deviance
> deviance_diff = deviance_reduced - deviance_full
> print(f"Diferen√ßa na deviance: {deviance_diff:.2f}")
>
> # Calcula o p-valor do teste de raz√£o de verossimilhan√ßa
> from scipy.stats import chi2
> df_diff = 1 # Diferen√ßa nos graus de liberdade (n√∫mero de par√¢metros removidos)
> p_value = 1 - chi2.cdf(deviance_diff, df_diff)
> print(f"P-valor do teste de raz√£o de verossimilhan√ßa: {p_value:.3f}")
> ```
>
> Se a diferen√ßa na deviance for grande e o p-valor for menor que 0.05, rejeitamos a hip√≥tese nula de que a vari√°vel X4 pode ser removida. Caso contr√°rio, removemos a vari√°vel e continuamos o processo.

```mermaid
graph TB
    subgraph "Wald Test"
        direction TB
        A["Estimate Coefficients: Œ≤ÃÇ"] --> B["Calculate Standard Error: se(Œ≤ÃÇ)"]
        B --> C["Z-score: z = Œ≤ÃÇ / se(Œ≤ÃÇ)"]
        C --> D{"Compare |z| to Threshold"}
        D --"|z| > threshold"--> E["Variable Significant"]
        D --"|z| <= threshold"--> F["Variable Not Significant"]
    end
```

Alternativamente, pode-se usar o **teste de Wald**, que avalia a signific√¢ncia de um coeficiente em um modelo. O teste de Wald se baseia na estat√≠stica z (coeficiente dividido pelo seu erro padr√£o). Se o valor absoluto do z-score √© maior que aproximadamente 2, a vari√°vel √© considerada significativa no n√≠vel de 5%.

A deviance residual de um modelo √© dada por $D = -2 \log \mathcal{L}(\hat{\beta})$, onde $\mathcal{L}(\hat{\beta})$ √© a verossimilhan√ßa do modelo ajustado. Modelos mais simples tendem a ter deviances maiores, e modelos mais complexos tendem a ter deviances menores, a diferen√ßa de deviance entre dois modelos √© dada por $D_1 - D_2$. O processo de sele√ß√£o por stepwise, em resumo, busca identificar um modelo que minimize a deviance, mas tamb√©m evita o overfiting atrav√©s da remo√ß√£o de vari√°veis n√£o significativas [^4.4.2].

**Lemma 5:** *A diferen√ßa na deviance entre dois modelos aninhados √© assintoticamente distribu√≠da como uma qui-quadrado com graus de liberdade iguais √† diferen√ßa no n√∫mero de par√¢metros entre os modelos*.

*Prova:* Este resultado √© uma consequ√™ncia da teoria assint√≥tica da m√°xima verossimilhan√ßa. Sob certas condi√ß√µes de regularidade, a diferen√ßa na deviance tem uma distribui√ß√£o qui-quadrado assint√≥tica. [^4.4.3] $\blacksquare$

**Corol√°rio 5:** *O processo stepwise de remo√ß√£o de vari√°veis menos significativas, usando a deviance residual, tende a encontrar um modelo mais parcimonioso que equilibra o ajuste aos dados e a complexidade do modelo.*

*Prova:* A remo√ß√£o iterativa de vari√°veis n√£o significativas reduz o n√∫mero de par√¢metros do modelo, levando a um modelo mais simples e com melhor capacidade de generaliza√ß√£o. [^4.4.2] $\blacksquare$

O uso da deviance e do teste de raz√£o de verossimilhan√ßa oferece um crit√©rio formal para a sele√ß√£o de modelos em regress√£o log√≠stica e outros modelos lineares generalizados. Ao remover as vari√°veis menos significativas de forma iterativa, podemos obter um modelo mais interpret√°vel e com melhor capacidade de generaliza√ß√£o.

### Infer√™ncia em Modelos Log√≠sticos e Aproxima√ß√µes Quadr√°ticas

```mermaid
graph TB
    subgraph "Logistic Regression Inference"
    direction TB
        A["Log-Likelihood Function"] --> B["Quadratic Approximation"]
        B --> C["Iteratively Reweighted Least Squares (IRLS)"]
        C --> D["Parameter Estimation: Œ≤ÃÇ"]
        D --> E["Covariance Matrix Estimation"]
        E --> F["Hypothesis Tests & Confidence Intervals"]
    end
```

A infer√™ncia em modelos log√≠sticos √© geralmente baseada em resultados assint√≥ticos da teoria da m√°xima verossimilhan√ßa. O estimador de m√°xima verossimilhan√ßa $\hat{\beta}$ possui propriedades assint√≥ticas que permitem a constru√ß√£o de intervalos de confian√ßa e a realiza√ß√£o de testes de hip√≥tese. Uma forma de obter esses resultados √© atrav√©s de **aproxima√ß√µes quadr√°ticas** da fun√ß√£o de log-verossimilhan√ßa [^4.4.3].

Conforme discutido em [^4.4.3], as estimativas de m√°xima verossimilhan√ßa s√£o as solu√ß√µes de um problema de m√≠nimos quadrados iterativamente ponderado (IRLS). Este processo iterativo envolve o ajuste de um modelo de regress√£o linear ponderado, onde as respostas s√£o dadas por:

$$
    z_i = x_i^T\hat{\beta} + \frac{y_i - \hat{p}_i}{\hat{p}_i(1-\hat{p}_i)}
$$

e os pesos s√£o dados por $w_i = \hat{p}_i(1-\hat{p}_i)$.  Esta formula√ß√£o permite obter as estimativas dos coeficientes $\beta$ e tamb√©m fornecer uma matriz de covari√¢ncia dos coeficientes estimada.

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um exemplo com 5 observa√ß√µes e 2 preditores (al√©m do intercepto). As respostas observadas s√£o $y = [0, 1, 0, 1, 0]$ e as matriz de preditores $X$ (incluindo o intercepto) e os coeficientes estimados $\hat{\beta}$ s√£o:
>
> ```python
> import numpy as np
> import statsmodels.api as sm
>
> y = np.array([0, 1, 0, 1, 0])
> X = np.array([[1, 2],
>               [2, 3],
>               [3, 4],
>               [4, 5],
>               [5, 6]])
> X = sm.add_constant(X)
>
> model = sm.Logit(y, X)
> result = model.fit()
> beta_hat = result.params
> print("Coeficientes estimados:", beta_hat)
>
> # Calcula as probabilidades preditas
> p_hat = model.predict(result.params, exog=X)
> print("Probabilidades preditas:", p_hat)
>
> # Calcula a resposta z_i e pesos w_i
> z = X @ beta_hat + (y - p_hat) / (p_hat * (1 - p_hat))
> w = p_hat * (1 - p_hat)
> print("Respostas z_i:", z)
> print("Pesos w_i:", w)
> ```
>
> O processo IRLS itera sobre estes passos. Na primeira itera√ß√£o, usa-se um valor inicial para $\hat{\beta}$. Em cada itera√ß√£o, os valores de $z_i$ e $w_i$ s√£o recalculados com base em $\hat{\beta}$ da itera√ß√£o anterior.

```mermaid
graph TB
    subgraph "Asymptotic Normality"
        direction TB
        A["Maximum Likelihood Estimator: Œ≤ÃÇ"] --> B["Asymptotic Distribution: Œ≤ÃÇ ~ N(Œ≤, (X^T W X)^-1)"]
        B --> C["Covariance Matrix: (X^T W X)^-1"]
        C --> D["Standard Errors: se(Œ≤ÃÇ)"]
        D --> E["Confidence Intervals & Hypothesis Tests"]
    end
```

As aproxima√ß√µes quadr√°ticas tamb√©m permitem a obten√ß√£o de resultados inferenciais utilizando a teoria normal assint√≥tica. Em particular, sob certas condi√ß√µes de regularidade, o estimador $\hat{\beta}$ segue uma distribui√ß√£o normal assintoticamente:

$$
\hat{\beta} \sim N(\beta, (X^T W X)^{-1})
$$

onde $W$ √© a matriz diagonal de pesos $w_i$ [^4.4.3].

Com base nessa distribui√ß√£o assint√≥tica, podemos calcular intervalos de confian√ßa para os coeficientes e realizar testes de hip√≥tese, como o teste de Wald [^4.4.3]. O teste de Wald utiliza a estat√≠stica z, dada por $z_j = \hat{\beta}_j / se(\hat{\beta}_j)$, onde $se(\hat{\beta}_j)$ √© o erro padr√£o do coeficiente $\hat{\beta}_j$. Se o valor absoluto do z-score √© maior que um valor cr√≠tico (por exemplo, 1.96 para um n√≠vel de signific√¢ncia de 5%), rejeitamos a hip√≥tese nula de que o coeficiente √© igual a zero [^4.4.3].

> üí° **Exemplo Num√©rico:**
>
> Usando os resultados do exemplo anterior, podemos calcular os erros padr√£o e os intervalos de confian√ßa para os coeficientes:
>
> ```python
> # Calcula a matriz de covari√¢ncia
> cov_matrix = result.cov_params()
> print("Matriz de covari√¢ncia:", cov_matrix)
>
> # Calcula os erros padr√£o dos coeficientes
> se_beta = np.sqrt(np.diag(cov_matrix))
> print("Erros padr√£o dos coeficientes:", se_beta)
>
> # Calcula os z-scores
> z_scores = beta_hat / se_beta
> print("Z-scores:", z_scores)
>
> # Calcula os intervalos de confian√ßa de 95%
> alpha = 0.05
> from scipy.stats import norm
> ci_lower = beta_hat - norm.ppf(1 - alpha/2) * se_beta
> ci_upper = beta_hat + norm.ppf(1 - alpha/2) * se_beta
> print("Intervalos de confian√ßa:", list(zip(ci_lower, ci_upper)))
> ```
> Os intervalos de confian√ßa indicam a precis√£o com que estimamos os coeficientes. Se o intervalo de confian√ßa n√£o inclui zero, o coeficiente √© considerado estatisticamente significativo.

Al√©m disso, o **res√≠duo ponderado** do ajuste √© dado por:

$$
    r_i = \frac{y_i - \hat{p}_i}{\sqrt{\hat{p}_i(1 - \hat{p}_i)}}
$$

A soma dos quadrados dos res√≠duos ponderados √© a estat√≠stica de qui-quadrado de Pearson, uma aproxima√ß√£o quadr√°tica da deviance que pode ser usada para avaliar a qualidade do ajuste do modelo.

**Lemma 6:** *A matriz de covari√¢ncia dos estimadores de m√°xima verossimilhan√ßa √© assintoticamente igual ao inverso da matriz Hessiana da fun√ß√£o de log-verossimilhan√ßa avaliada no estimador de m√°xima verossimilhan√ßa.*

*Prova:* Este resultado √© uma consequ√™ncia da teoria da m√°xima verossimilhan√ßa e do teorema de informa√ß√£o de Fisher, conforme discutido em [^4.4.3]. $\blacksquare$

**Corol√°rio 6:** *O m√©todo de m√≠nimos quadrados ponderados iterativamente (IRLS) utilizado para ajustar modelos log√≠sticos fornece tanto as estimativas dos par√¢metros quanto a matriz de covari√¢ncia desses par√¢metros, permitindo infer√™ncias estat√≠sticas.*

*Prova:* Atrav√©s da expans√£o de Taylor de segunda ordem da fun√ß√£o de verossimilhan√ßa, o m√©todo IRLS gera os coeficientes e a matriz de covari√¢ncia dos mesmos. [^4.4.3] $\blacksquare$

As aproxima√ß√µes quadr√°ticas e a teoria assint√≥tica s√£o ferramentas poderosas para a realiza√ß√£o de infer√™ncia em modelos log√≠sticos. Elas permitem a constru√ß√£o de intervalos de confian√ßa, testes de hip√≥teses e avalia√ß√µes da qualidade do ajuste do modelo.

### Regulariza√ß√£o L1 em Regress√£o Log√≠stica e Implica√ß√µes

```mermaid
graph TB
    subgraph "L1 Regularization in Logistic Regression"
        direction TB
        A["Log-Likelihood Function"] --> B["L1 Penalty: ŒªŒ£|Œ≤j|"]
        B --> C["Regularized Objective Function"]
        C --> D["Optimization (Coordinate Descent/IRLS)"]
        D --> E["Sparse Coefficients: Some Œ≤j = 0"]
        E --> F["Feature Selection & Improved Generalization"]
    end
```

A regulariza√ß√£o √© um m√©todo essencial para lidar com overfitting e melhorar a generaliza√ß√£o de modelos, particularmente em casos onde o n√∫mero de preditores √© grande ou quando h√° multicolinearidade. A **penaliza√ß√£o L1** ou *Lasso* √© uma abordagem de regulariza√ß√£o que adiciona um termo proporcional √† soma dos valores absolutos dos coeficientes na fun√ß√£o de custo do modelo [^4.4.4]:

$$
    \max_{\beta_0, \beta} \sum_{i=1}^N \left[y_i(\beta_0 + \beta^T x_i) - \log(1 + e^{\beta_0 + \beta^T x_i})\right] - \lambda \sum_{j=1}^p |\beta_j|
$$

onde $\lambda$ √© o par√¢metro de regulariza√ß√£o. A penaliza√ß√£o L1 tem a propriedade de induzir esparsidade nos coeficientes, isto √©, alguns coeficientes s√£o for√ßados a exatamente zero. Isso resulta n√£o apenas em um modelo mais simples e interpret√°vel, mas tamb√©m realiza sele√ß√£o de vari√°veis, eliminando aquelas consideradas menos importantes [^4.4.4].

> üí° **Exemplo Num√©rico:**
>
> Vamos demonstrar a penaliza√ß√£o L1 com um exemplo. Suponha que temos um modelo log√≠stico com 3 preditores e que, sem regulariza√ß√£o, os coeficientes estimados s√£o $\hat{\beta} = [0.8, -1.2, 0.5]$. Aplicando a penalidade L1 com um valor de $\lambda = 0.5$, a fun√ß√£o objetivo torna-se:
>
> $$
>   \text{Objetivo} = \text{Verossimilhan√ßa} - 0.5 \times (|0.8| + |-1.2| + |0.5|)
> $$
>
> A penalidade L1 tenta reduzir o valor absoluto dos coeficientes, e em alguns casos, pode for√ß√°-los a zero. Para valores maiores de $\lambda$, a penalidade tem um efeito maior na redu√ß√£o dos coeficientes.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.preprocessing import StandardScaler
>
> # Dados de exemplo com 10 observa√ß√µes e 3 preditores
> X = np.array([[1, 2, 3],
>               [2, 3, 4],
>               [3, 4, 5],
>               [4, 5, 6],
>               [5, 6, 7],
>               [6, 7, 8],
>               [7, 8, 9],
>               [8, 9, 10],
>               [9, 10, 11],
>               [10, 11, 12]])
> y = np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
>
> # Padroniza os preditores
> scaler = StandardScaler()
> X_scaled = scaler.fit_transform(X)
>
> # Aplica regress√£o log√≠stica com penalidade L1 (Lasso)
> lambda_values = [0.1, 0.5, 1] # Diferentes valores de lambda
>
> for lambda_value in lambda_values:
>     model_lasso = LogisticRegression(penalty='l1', C=1/(2*lambda_value), solver='liblinear', random_state=42)
>     model_lasso.fit(X_scaled, y)
>     print(f"Lambda = {lambda_value}: Coeficientes = {model_lasso.coef_}")
> ```
>
> Observe como os coeficientes se aproximam de zero √† medida que aumentamos o valor de $\lambda$.

```mermaid
graph TB
    subgraph "L1 Regularization Path"
        direction TB
        A["Varying Œª Values"] --> B{"Optimization with L1 Penalty"}
        B --> C["Coefficient Trajectories"]
        C --> D{"Selection of Optimal Œª"}
        D --> E["Sparsity at Higher Œª"]
    end
```

O processo de otimiza√ß√£o com a penalidade L1 n√£o √© diferenci√°vel no ponto zero. Para obter uma solu√ß√£o, s√£o utilizadas abordagens como o m√©todo de gradiente descendente projetado e o m√©todo de *coordinate descent*, ou o algoritmo iterativo de m√≠nimos quadrados ponderados (IRLS) com algumas modifica√ß√µes [^4.4.4]. O m√©todo IRLS, quando combinado com a penalidade L1, pode ser adaptado para encontrar solu√ß√µes para o problema de otimiza√ß√£o com penalidades [^4.4.4].

O par√¢metro de regulariza√ß√£o $\lambda$ controla o n√≠vel de esparsidade e *shrinkage* nos coeficientes. Valores maiores de $\lambda$ resultam em modelos mais esparsos, com um menor n√∫mero de vari√°veis preditoras. A escolha de $\lambda$ pode ser feita por valida√ß√£o cruzada ou outros m√©todos de sele√ß√£o de modelos [^4.4.5].

> üí° **Exemplo Num√©rico:**
>
> Para ilustrar a escolha de $\lambda$ por valida√ß√£o cruzada, podemos usar o `LogisticRegressionCV` do scikit-learn:
>
> ```python
> from sklearn.linear_model import LogisticRegressionCV
>
> # Aplica regress√£o log√≠stica com valida√ß√£o cruzada para escolher o melhor lambda
> model_cv = LogisticRegressionCV(penalty='l1', solver='liblinear', cv=5, random_state=42, Cs=10)
> model_cv.fit(X_scaled, y)
>
> best_lambda = 1/(2*model_cv.C_[0])
> print(f"Melhor Lambda (via valida√ß√£o cruzada): {best_lambda:.3f}")
> print(f"Coeficientes com o melhor Lambda: {model_cv.coef_}")
> ```
> A valida√ß√£o cruzada ajuda a encontrar o valor de $\lambda$ que equilibra a complexidade e o ajuste do modelo aos dados.

A capacidade de sele√ß√£o de vari√°veis da regulariza√ß√£o L1 √© valiosa em modelos log√≠sticos, pois ajuda a identificar quais preditores s√£o mais importantes para explicar a resposta, al√©m de melhorar a generaliza√ß√£o do modelo para dados n√£o vistos.

**Lemma 7:** *A regulariza√ß√£o L1 induz esparsidade nos coeficientes por meio de um processo de otimiza√ß√£o onde a derivada do termo de verossimilhan√ßa (score) se equilibra com o sinal do coeficiente penalizado, resultando em coeficientes iguais a zero.*

*Prova:* Ao otimizar a fun√ß√£o objetivo com penaliza√ß√£o L1, a derivada da verossimilhan√ßa em rela√ß√£o a um coeficiente n√£o nulo se iguala ao produto do par√¢metro de regulariza√ß√£o e o sinal do coeficiente. Se o score for menor que o par√¢metro de regulariza√ß√£o, o coeficiente √© for√ßado a ser zero. [^4.4.4] $\blacksquare$

**Corol√°rio 7:** *O caminho da regulariza√ß√£o L1 revela a import√¢ncia relativa das vari√°veis preditoras, mostrando como seus coeficientes variam com diferentes valores do par√¢metro de regulariza√ß√£o.*

*Prova:* Como o par√¢metro de regulariza√ß√£o varia, alguns coeficientes tendem a ser for√ßados a zero mais rapidamente, revelando que s√£o menos relevantes. A trajet√≥ria dos coeficientes permite analisar e entender como a escolha do par√¢metro de regulariza√ß√£o afeta as vari√°veis preditoras no modelo. [^4.4.4] $\blacksquare$

A regulariza√ß√£o L1 √©, portanto, uma ferramenta poderosa para a sele√ß√£o de vari√°veis e melhoria de modelos log√≠sticos, especialmente quando h√° um grande n√∫mero de preditores e deseja-se identificar os preditores mais informativos.

### Exemplo: Regress√£o Log√≠stica com Sele√ß√£o Stepwise e Intera√ß√µes

```mermaid
graph TB
    subgraph "Stepwise Model with Interactions"
    direction TB
        A["Initial Logistic Model: All Predictors"] --> B["Stepwise Selection (Deviance/Wald)"]
        B --> C["Reduced Model: Significant Predictors"]
        C --> D["Interaction Exploration: Add Interaction Terms"]
        D --> E["Significance Test of Interactions (Likelihood Ratio Test)"]
        E --> F["Final Model: Main Effects and Significant Interactions"]
    end
```

Apresentamos aqui um exemplo de aplica√ß√£o de regress√£o log√≠stica com sele√ß√£o stepwise e explora√ß√£o de intera√ß√µes, utilizando o conjunto de dados sobre doen√ßas card√≠acas da √Åfrica do Sul, mencionado em [^4.4.2].

O conjunto de dados inclui as vari√°veis:
* sbp (press√£o arterial sist√≥lica)
* tobacco (consumo de tabaco)
* ldl (lipoprote√≠na de baixa densidade)
* famhist (hist√≥rico familiar de doen√ßas card√≠acas)
* obesity (obesidade)
* alcohol (consumo de √°lcool)
* age (idade)

O objetivo √© modelar a probabilidade de infarto do mioc√°rdio (MI) com base nesses preditores.

**An√°lise Inicial:**

Ajustamos um modelo log√≠stico com todos os preditores e avaliamos os z-scores, como apresentado em [^4.4.2]. Observamos que algumas vari√°veis, como a press√£o arterial sist√≥lica (sbp) e a obesidade, podem n√£o ser significativas no modelo inicial. O teste de Wald nos ajuda a identificar quais vari√°veis podem ser removidas do modelo [^4.4.2].

> üí° **Exemplo Num√©rico:**
>
> Usando dados simulados, vamos ajustar o modelo inicial e verificar os z-scores:
>
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
>
> # Simula√ß√£o de dados (substitua isso com seus dados reais)
> np.random.seed(42)
> n = 100
> sbp = np.random.normal(130, 15, n)
> tobacco = np.random.normal(10, 5, n)
> ldl = np.random.normal(4, 1.5, n)
> famhist = np.random.choice([0, 1], n)
> obesity = np.random.normal(30, 5, n)
> alcohol = np.random.normal(5, 3, n)
> age = np.random.normal(50, 10, n)
>
> # Cria um dataframe com os dados simulados
> data = pd.DataFrame({'sbp': sbp, 'tobacco': tobacco, 'ldl': ldl, 'famhist': famhist,
>                      'obesity': obesity, 'alcohol': alcohol, 'age': age})
>
> # Simula a vari√°vel resposta (MI)
> logit_prob = -3 + 0.02*sbp + 0.05*tobacco + 0.2*ldl + 0.8*famhist -0.01*obesity + 0.01*alcohol + 0.04*age
> prob = 1/(1 + np.exp(-logit_prob))
> MI = np.random.binomial(1, prob)
> data['MI'] = MI
>
> # Adiciona a constante para o intercepto
> X = sm.add_constant(data[['sbp', 'tobacco', 'ldl', 'famhist', 'obesity', 'alcohol', 'age']])
> y = data['MI']
>
> # Ajusta o modelo log√≠stico inicial
> model = sm.Logit(y, X)
> result = model.fit()
> print(result.summary())
> ```
>
> Ao analisar o sum√°rio do modelo, verificamos os z-scores (coluna `z`) e os p-valores (coluna `P>|z|`). Vari√°veis com p-valores altos (acima de 0.05) podem ser candidatas √† remo√ß√£o na sele√ß√£o stepwise.

**Sele√ß√£o Stepwise:**

Realizamos a sele√ß√£o stepwise utilizando a deviance residual e o teste de raz√£o de verossimilhan√ßa. Come√ßamos removendo a vari√°vel menos significativa (por exemplo, a obesidade) e reajustamos o modelo com os preditores restantes. Esse processo √© repetido at√© que todos os preditores restantes sejam significativos, conforme [^4.4.2].

> üí° **Exemplo Num√©rico:**
>
> Vamos executar um passo do backward elimination usando o exemplo anterior:
>
> ```python
> # Remove a vari√°vel 'obesity' e reajusta o modelo
> X_reduced = sm.add_constant(data[['sbp', 'tobacco', 'ldl', 'famhist', 'alcohol', 'age']])
> model_reduced = sm.Logit(y, X_reduced)
> result_reduced = model_reduced.fit()
>
> # Calcula a deviance dos dois modelos
> deviance_full = -2 * result.llf
> deviance_reduced = -2 * result_reduced.llf
>
> # Calcula a diferen√ßa na deviance e o p-valor
> deviance_diff = deviance_reduced - deviance_full
> from scipy.stats import chi2
> p_value = 1 - chi2.cdf(deviance_diff, 1)
>
> print(f"Deviance do modelo completo: {deviance_full:.2f}")
> print(f"Deviance do modelo reduzido: {deviance_reduced:.2f}")
> print(f"Diferen√ßa na deviance: {deviance_diff:.2f}")
> print(f"P-valor do teste de raz√£o de verossimilhan√ßa: {p_value:.3f}")
>
> print(result_reduced.summary())
> ```
> Se o p-valor for maior que 0.05, removemos a vari√°vel 'obesity' e continuamos o processo stepwise com as vari√°veis restantes.

**Explora√ß√£o de Intera√ß√µes:**

Ap√≥s a sele√ß√£o stepwise, exploramos poss√≠veis intera√ß√µes entre vari√°veis. Por exemplo, podemos avaliar se o efeito do tabaco na probabilidade de infarto varia com a idade. Para isso, adicionamos um termo de intera√ß√£o (age \* tobacco) ao modelo. Ajustamos o modelo com o termo de intera√ß√£o e avaliamos sua signific√¢ncia atrav√©s do teste de raz√£o de verossimilhan√ßa. Se a intera√ß√£o for significativa, ela permanece no modelo, caso contr√°rio, √© removida.

> üí° **Exemplo Num√©rico:**
>
> Vamos adicionar a intera√ß√£o 'age*tobacco' e verificar sua signific√¢ncia:
>
> ```python
> # Cria o termo de intera√ß√£o
> data['age_tobacco'] = data['age'] * data['tobacco']
>
> # Ajusta o modelo com a intera√ß√£o
> X_interaction = sm.add_constant(data[['sbp', 'tobacco', 'ldl', 'famhist', 'alcohol', 'age', 'age_tobacco']])
> model_interaction = sm.Logit(y, X_interaction)
> result_interaction = model_interaction.fit()
>
> # Calcula a deviance do modelo com intera√ß√£o
> deviance_interaction = -2 * result_interaction.llf
>
> # Calcula a diferen√ßa de deviance e o p-valor
> deviance_diff_interaction = deviance_reduced - deviance_interaction
> p_value_interaction = 1 - chi2.cdf(deviance_diff_interaction, 1)
>
> print(f"Deviance do modelo com intera√ß√£o: {deviance_interaction:.2f}")
> print(f"Diferen√ßa na deviance: {deviance_diff_interaction:.2f}")
> print(f"P-valor do teste de raz√£o de verossimilhan√ßa para intera√ß√£o: {p_value_interaction:.3f}")
>
> print(result_interaction.summary())
> ```
> Se o p-valor da intera√ß√£o for menor que 0.05, a intera√ß√£o √© considerada significativa e mantida no modelo.

**Interpreta√ß√£o do Modelo Final:**

O modelo final selecionado por meio do m√©todo stepwise e explora√ß√£o de intera√ß√µes permite uma interpreta√ß√£o mais precisa e parcimoniosa dos dados. As vari√°veis e intera√ß√µes que permanecem no modelo s√£o consideradas as mais relevantes para predizer o risco de infarto do mioc√°rdio. Al√©m disso, os coeficientes podem ser interpretados em termos de aumentos no log-odds ou no odds-ratio para cada vari√°vel ou intera√ß√£o, de forma similar ao que foi descrito em [^4.4.2] e [^4.4.3].

### Pergunta Te√≥rica Avan√ßada: Como a escolha entre LDA, Regress√£o Log√≠stica e Hiperplanos Separadores influencia a generaliza√ß√£o do modelo?

```mermaid
graph TB
    subgraph "Impact on Generalization"
    direction TB
        A["Method Choice: LDA, Logistic Regression, Separating Hyperplanes"] --> B["Underlying Assumptions & Principles"]
        B --> C["Model Complexity & Parameters"]
        C --> D["Decision Boundary Modeling"]
        D --> E["Ability to Fit Training Data"]
        E --> F["Generalization Performance on Unseen Data"]
    end
```

**Resposta:**

A escolha entre **An√°lise Discriminante Linear (LDA), regress√£o log√≠stica e hiperplanos separadores** impacta diretamente a capacidade de generaliza√ß√£o de um modelo de classifica√ß√£o, que se refere √† sua performance em dados n√£o vistos [^4.1], [^4.3], [^4.4]. Cada m√©todo opera sob diferentes suposi√ß√µes e princ√≠pios, que influenciam a maneira como eles modelam as fronteiras de