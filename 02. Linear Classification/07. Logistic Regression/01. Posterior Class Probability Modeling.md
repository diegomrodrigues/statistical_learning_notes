## T√≠tulo Conciso: Classifica√ß√£o Linear e a Modelagem de Probabilidades Posteriores: Restri√ß√µes de Intervalo e Soma Unit√°ria

```mermaid
graph LR
    subgraph "Linear Classification Model"
    direction TB
        A["Input Data: X"]
        B["Linear Model: f(X) = Œ≤‚ÇÄ + Œ≤·µÄX"]
        C["Transformation Function: g(f(X))"]
        D["Output Probabilities: P(G=k|X=x)"]
        E["Class Prediction"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

### Introdu√ß√£o

Este cap√≠tulo explora a fundo a modelagem de **probabilidades posteriores das classes** utilizando **fun√ß√µes lineares**, com √™nfase em como impor as restri√ß√µes de que as probabilidades devem estar no intervalo [0,1] e somar 1. Analisaremos como a **regress√£o log√≠stica** utiliza a fun√ß√£o log√≠stica para garantir que as probabilidades posteriores estejam devidamente calibradas, e como essa abordagem contrasta com a **regress√£o linear com matrizes de indicadores**, que n√£o modela as probabilidades diretamente [^4.2], [^4.4]. Discutiremos como o **Linear Discriminant Analysis (LDA)**, sob a suposi√ß√£o gaussiana, tamb√©m leva a probabilidades posteriores com essas propriedades, embora de forma indireta [^4.3]. Abordaremos a import√¢ncia da **sele√ß√£o de vari√°veis e regulariza√ß√£o** para a constru√ß√£o de modelos que n√£o apresentem *overfitting* e que sejam robustos, especialmente quando as probabilidades s√£o modeladas diretamente com fun√ß√µes lineares [^4.4.4], [^4.5]. Exploraremos tamb√©m como o conceito de **hiperplanos separadores** se relaciona com a modelagem das probabilidades posteriores [^4.5.2]. O objetivo deste cap√≠tulo √© fornecer uma compreens√£o detalhada e abrangente de como a modelagem de probabilidades posteriores com fun√ß√µes lineares e as restri√ß√µes de soma unit√°ria e intervalo [0,1] podem ser utilizadas na constru√ß√£o de modelos de classifica√ß√£o lineares.

### Conceitos Fundamentais

**Conceito 1:  A Necessidade de Probabilidades Posteriores Calibradas**

Em problemas de classifica√ß√£o, o objetivo final √© atribuir uma observa√ß√£o $x$ √† classe $k$ com a maior probabilidade posterior $P(G=k|X=x)$ [^4.3]. Para que essas probabilidades sejam interpretadas corretamente e utilizadas na tomada de decis√µes, √© fundamental que elas estejam no intervalo [0,1] e que a soma das probabilidades para todas as classes seja igual a 1. Modelos que n√£o imp√µem essas restri√ß√µes podem levar a decis√µes de classifica√ß√£o sub√≥timas e a resultados pouco confi√°veis. Em modelos lineares, √© importante, portanto, que as sa√≠das sejam adequadamente calibradas, de forma a se comportarem como probabilidades.

**Lemma 1:** *Em problemas de classifica√ß√£o, a necessidade de que as probabilidades posteriores perten√ßam ao intervalo [0,1] e somem 1 √© fundamental para a interpretabilidade dos modelos e para a aplica√ß√£o da teoria de decis√£o.* A prova desse lema reside na defini√ß√£o de probabilidades como sendo valores entre 0 e 1, que representam a incerteza de um evento, e como essas propriedades s√£o utilizadas no processo de tomada de decis√£o.

**Conceito 2: Regress√£o Log√≠stica e a Modelagem da Probabilidade Posterior**

A **regress√£o log√≠stica** modela diretamente as probabilidades posteriores utilizando a fun√ß√£o log√≠stica, que garante que os valores estejam no intervalo [0,1] e que a soma das probabilidades para todas as classes seja igual a 1. Para um problema de classifica√ß√£o com $K$ classes, a regress√£o log√≠stica modela os log-odds (logaritmo da raz√£o das chances) das classes $1$ a $K-1$ em rela√ß√£o √† classe $K$, como fun√ß√µes lineares:

$$
\log \frac{P(G=k|X=x)}{P(G=K|X=x)} = \beta_{k0} + \beta_k^T x \text{ para } k=1, \ldots, K-1
$$

A probabilidade posterior para cada classe √© dada por:

```mermaid
graph TB
    subgraph "Logistic Regression Probability Calculation"
    direction TB
        A["Linear Combination: Œ≤‚Çñ‚ÇÄ + Œ≤‚Çñ·µÄx"]
        B["Exponentiation: exp(Œ≤‚Çñ‚ÇÄ + Œ≤‚Çñ·µÄx)"]
        C["Sum of Exponentials: 1 + Œ£ exp(Œ≤‚Çó‚ÇÄ + Œ≤‚Çó·µÄx)"]
        D["P(G=k|X=x) = exp(Œ≤‚Çñ‚ÇÄ + Œ≤‚Çñ·µÄx) / C"]
        E["P(G=K|X=x) = 1 / C"]
        A --> B
        B --> C
        C --> D
        C --> E
    end
```

$$
P(G=k|X=x) = \frac{e^{\beta_{k0} + \beta_k^T x}}{1 + \sum_{l=1}^{K-1} e^{\beta_{l0} + \beta_l^T x}}
$$

para $k=1, \ldots, K-1$ e,

$$
P(G=K|X=x) = \frac{1}{1 + \sum_{l=1}^{K-1} e^{\beta_{l0} + \beta_l^T x}}
$$

Essa modelagem, por meio da fun√ß√£o log√≠stica, garante que as probabilidades estejam no intervalo [0,1] e que a soma de todas as probabilidades seja igual a 1 [^4.4].

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o bin√°ria (K=2) com uma √∫nica vari√°vel preditora ($x$). Suponha que os par√¢metros da regress√£o log√≠stica sejam $\beta_{10} = -1$ e $\beta_1 = 0.5$. Para uma observa√ß√£o $x=2$, podemos calcular os log-odds e a probabilidade posterior da classe 1:
>
> $$
> \log \frac{P(G=1|X=2)}{P(G=2|X=2)} = -1 + 0.5 \times 2 = 0
> $$
>
> Isso significa que o log-odds √© 0, o que implica que as chances s√£o iguais (1:1). A probabilidade posterior para a classe 1 √©:
>
> $$
> P(G=1|X=2) = \frac{e^0}{1 + e^0} = \frac{1}{1 + 1} = 0.5
> $$
>
> E a probabilidade posterior para a classe 2 √©:
>
> $$
> P(G=2|X=2) = \frac{1}{1 + e^0} = \frac{1}{1 + 1} = 0.5
> $$
>
> Observe que as probabilidades est√£o entre 0 e 1 e somam 1, como esperado.

**Corol√°rio 1:** *A regress√£o log√≠stica garante que as estimativas das probabilidades posteriores perten√ßam ao intervalo [0,1] e somem 1, o que √© consistente com a defini√ß√£o de probabilidades e com a teoria de decis√£o.* O uso da fun√ß√£o log√≠stica √© fundamental para que essa garantia seja obtida.

**Conceito 3: LDA e a Deriva√ß√£o Indireta das Probabilidades Posteriores**

No **LDA**, as probabilidades posteriores n√£o s√£o modeladas diretamente como na regress√£o log√≠stica, mas s√£o derivadas da suposi√ß√£o de que as densidades condicionais seguem distribui√ß√µes Gaussianas multivariadas com a mesma matriz de covari√¢ncia [^4.3].  A fun√ß√£o discriminante do LDA, que √© linear, pode ser relacionada com o log das probabilidades posteriores, de modo que a maximiza√ß√£o da fun√ß√£o discriminante leva √† maximiza√ß√£o da probabilidade posterior. A regra de decis√£o do LDA tamb√©m garante que as probabilidades posteriores sejam normalizadas, embora de forma indireta [^4.3].

> ‚ö†Ô∏è **Nota Importante**: A regress√£o log√≠stica modela as probabilidades posteriores diretamente, atrav√©s de uma fun√ß√£o log√≠stica, enquanto o LDA deriva as probabilidades a partir da suposi√ß√£o gaussiana, e a rela√ß√£o com o log das probabilidades √© atrav√©s da fun√ß√£o discriminante.

> ‚ùó **Ponto de Aten√ß√£o**: A regress√£o log√≠stica modela as probabilidades posteriores de forma mais flex√≠vel, sem impor a restri√ß√£o gaussiana, mas necessita de ajuste dos par√¢metros por maximiza√ß√£o da verossimilhan√ßa.

> ‚úîÔ∏è **Destaque**: A imposi√ß√£o de restri√ß√µes sobre as probabilidades posteriores √© fundamental para a interpretabilidade dos modelos de classifica√ß√£o e para a aplica√ß√£o da teoria de decis√£o.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Comparison of Linear Regression and Logistic Regression"
    direction LR
        A["Linear Regression with Indicator Matrices"]
        B["Logistic Regression"]
        A --> C["Direct Linear Output:  yÃÇ = Œ≤‚ÇÄ + Œ≤·µÄx"]
        B --> D["Log-Odds Model: log(P(G=k|X)/P(G=K|X)) = Œ≤‚ÇÄ + Œ≤·µÄx"]
        C --> E["Output may be outside [0,1] and sum ‚â† 1"]
        D --> F["Logistic Transformation"]
        F --> G["Output is in [0,1] and sums to 1"]
    end
```

A **regress√£o linear com matrizes de indicadores** busca ajustar fun√ß√µes lineares para cada classe, utilizando o m√©todo dos m√≠nimos quadrados, sem impor restri√ß√µes sobre o comportamento dos valores de sa√≠da. Em particular, a regress√£o linear n√£o garante que as estimativas estejam no intervalo [0,1] e que somem 1, que s√£o as propriedades desejadas para as probabilidades posteriores. Isso ocorre pois a fun√ß√£o linear utilizada na regress√£o linear permite estimativas que n√£o s√£o consistentes com a teoria de probabilidade [^4.2].

A falta dessas restri√ß√µes resulta em um modelo que n√£o pode ser interpretado como uma estimativa direta da probabilidade posterior das classes, dificultando a aplica√ß√£o da teoria de decis√£o e levando a erros de interpreta√ß√£o.  Al√©m disso, as estimativas obtidas pela regress√£o linear podem levar a resultados sub√≥timos, especialmente em problemas multiclasse.

A regress√£o linear com matrizes de indicadores, portanto, n√£o modela as probabilidades posteriores diretamente, o que a distingue de modelos como a regress√£o log√≠stica que utilizam a fun√ß√£o log√≠stica para garantir a calibra√ß√£o das probabilidades e o somat√≥rio unit√°rio [^4.4]. A regress√£o linear com matrizes de indicadores utiliza fun√ß√µes lineares como aproxima√ß√£o da resposta de classes, o que √© diferente de modelar a probabilidade posterior.

> üí° **Exemplo Num√©rico:**
>
>  Suponha um problema de classifica√ß√£o bin√°ria com uma vari√°vel preditora $x$. Usamos regress√£o linear para modelar as classes usando uma matriz de indicadores. A classe 1 √© codificada como 1 e a classe 2 como 0.  Ap√≥s ajustar o modelo de regress√£o linear, obtemos os seguintes coeficientes: $\beta_0 = 0.2$ e $\beta_1 = 0.4$.
>
> Para um valor de $x = 3$, a previs√£o do modelo √©:
>
> $$
> \hat{y} = \beta_0 + \beta_1 x = 0.2 + 0.4 \times 3 = 1.4
> $$
>
> Este valor, 1.4, est√° fora do intervalo [0,1] e n√£o pode ser interpretado como uma probabilidade. Em outro caso, para $x = -1$, ter√≠amos:
>
> $$
> \hat{y} = 0.2 + 0.4 \times (-1) = -0.2
> $$
>
> Este valor, -0.2, tamb√©m est√° fora do intervalo [0,1]. Isso demonstra que a regress√£o linear, sem restri√ß√µes, n√£o produz estimativas que se comportam como probabilidades.

**Lemma 2:** *A regress√£o linear com matrizes de indicadores n√£o garante que as estimativas obtidas estejam no intervalo [0,1] e que a soma para todas as classes seja igual a 1, o que impede a sua interpreta√ß√£o direta como probabilidades posteriores.* A prova desse lema reside na forma como a regress√£o linear ajusta os par√¢metros, sem impor nenhuma restri√ß√£o sobre os valores de sa√≠da.

**Corol√°rio 2:** *A regress√£o linear com matrizes de indicadores, por n√£o impor restri√ß√µes sobre as estimativas, dificulta a aplica√ß√£o da teoria de decis√£o e pode levar a classifica√ß√µes menos precisas em compara√ß√£o com m√©todos que modelam diretamente as probabilidades posteriores ou as densidades, como a regress√£o log√≠stica ou LDA.*  Este corol√°rio destaca uma limita√ß√£o fundamental da regress√£o linear como classificador.

Em resumo, a regress√£o linear com matrizes de indicadores, embora utilize fun√ß√µes lineares para tomada de decis√£o, n√£o modela as probabilidades posteriores de forma direta e n√£o garante que as estimativas resultantes se comportem como probabilidades, o que a distingue de abordagens como a regress√£o log√≠stica que utilizam transforma√ß√µes n√£o lineares para atingir esse objetivo [^4.2], [^4.4].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization in Logistic Regression"
    direction TB
        A["Log-Likelihood Function"]
        B["Penalty Term: ŒªP(Œ≤)"]
        C["Regularized Objective Function: Maximize A - B"]
        D["L1 Regularization (Lasso): P(Œ≤) = Œ£|Œ≤‚±º|"]
        E["L2 Regularization (Ridge): P(Œ≤) = Œ£Œ≤‚±º¬≤"]
        F["Variable Selection (L1) or Coefficient Shrinkage (L2)"]
        A --> C
        B --> C
        C --> D
        C --> E
        D --> F
        E --> F
    end
```

A **sele√ß√£o de vari√°veis** e a **regulariza√ß√£o** s√£o t√©cnicas importantes para melhorar a qualidade da estimativa das probabilidades posteriores, mesmo em modelos onde as restri√ß√µes de soma unit√°ria e valores no intervalo [0,1] s√£o impostas [^4.5]. A regulariza√ß√£o, ao adicionar um termo de penalidade √† fun√ß√£o de custo, controla a magnitude dos coeficientes, o que pode melhorar a estabilidade da estimativa e prevenir o overfitting.

Na **regress√£o log√≠stica**, a regulariza√ß√£o √© implementada modificando a fun√ß√£o de verossimilhan√ßa para incluir um termo de penalidade:

$$
\max_{\beta_0, \beta} \left[ \sum_{i=1}^N \left( y_i (\beta_0 + \beta^T x_i) - \log(1 + e^{\beta_0 + \beta^T x_i}) \right) - \lambda P(\beta) \right]
$$

onde $P(\beta)$ √© a penalidade e $\lambda$ √© o par√¢metro de regulariza√ß√£o. A penalidade **L1** (Lasso), dada por $P(\beta) = \sum_{j=1}^p |\beta_j|$, promove a esparsidade dos coeficientes, selecionando as vari√°veis mais relevantes para a modelagem das probabilidades posteriores [^4.4.4]. A penalidade **L2** (Ridge), dada por $P(\beta) = \sum_{j=1}^p \beta_j^2$, reduz a magnitude dos coeficientes, estabilizando o modelo e tornando a estimativa das probabilidades mais robusta [^4.5].

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de regress√£o log√≠stica com duas vari√°veis preditoras ($x_1$ e $x_2$) e regulariza√ß√£o L1 (Lasso). A fun√ß√£o de verossimilhan√ßa √© modificada com a penalidade L1.  Suponha que, ap√≥s o ajuste do modelo com $\lambda = 0.5$, os coeficientes resultantes sejam: $\beta_0 = -0.2$, $\beta_1 = 0.8$ e $\beta_2 = 0$.
>
> A penalidade L1 for√ßou $\beta_2$ a ser exatamente 0, o que significa que a vari√°vel $x_2$ foi eliminada do modelo. Se tiv√©ssemos utilizado regulariza√ß√£o L2 (Ridge) com o mesmo $\lambda$, os coeficientes poderiam ser, por exemplo, $\beta_0 = -0.15$, $\beta_1 = 0.6$ e $\beta_2 = 0.2$.
>
> Observe que, com regulariza√ß√£o L2, ambas as vari√°veis s√£o mantidas no modelo, mas seus coeficientes s√£o reduzidos em magnitude em compara√ß√£o com um modelo sem regulariza√ß√£o. A regulariza√ß√£o L1 promove a esparsidade, simplificando o modelo, enquanto a regulariza√ß√£o L2 reduz a complexidade dos coeficientes.
>
> Para comparar, vamos considerar um modelo sem regulariza√ß√£o, onde os coeficientes seriam $\beta_0 = -0.3$, $\beta_1 = 1.2$ e $\beta_2 = 0.5$. A tabela abaixo resume os resultados:
>
> | M√©todo       | $\beta_0$ | $\beta_1$ | $\beta_2$ |
> |--------------|-----------|-----------|-----------|
> | Sem Regulariza√ß√£o | -0.3     | 1.2       | 0.5       |
> | Lasso (L1)   | -0.2     | 0.8       | 0         |
> | Ridge (L2)   | -0.15    | 0.6       | 0.2       |
>
> Este exemplo ilustra como a regulariza√ß√£o L1 pode realizar a sele√ß√£o de vari√°veis (esparsidade), enquanto a regulariza√ß√£o L2 reduz a magnitude dos coeficientes, contribuindo para a estabilidade do modelo.

A aplica√ß√£o de t√©cnicas de regulariza√ß√£o, portanto, complementa a modelagem da probabilidade posterior, melhorando a capacidade de generaliza√ß√£o do modelo para novos dados e diminuindo o risco de overfitting.

**Lemma 3:** *A regulariza√ß√£o L1 na regress√£o log√≠stica, ao promover a esparsidade dos coeficientes, seleciona as vari√°veis mais importantes para a estimativa das probabilidades posteriores, o que leva a modelos mais simples e com melhor interpretabilidade.*  A prova reside na forma da penalidade L1 e como ela afeta a fun√ß√£o de custo.

**Prova do Lemma 3:**  A penalidade L1 adiciona um termo √† fun√ß√£o de custo que √© proporcional ao valor absoluto dos coeficientes. A minimiza√ß√£o deste termo for√ßa alguns dos coeficientes a se tornarem exatamente zero, promovendo a sele√ß√£o de vari√°veis e levando a modelos mais simples e com melhor interpretabilidade [^4.4.3], [^4.4.4]. $\blacksquare$

**Corol√°rio 3:** *A regulariza√ß√£o, tanto L1 quanto L2, contribui para a estabilidade e a capacidade de generaliza√ß√£o dos modelos que modelam probabilidades posteriores, ao controlar o overfitting e reduzir a complexidade das estimativas.* A regulariza√ß√£o, neste contexto, pode ser vista como uma ferramenta para aprimorar a qualidade da modelagem das probabilidades posteriores.

> ‚ö†Ô∏è **Ponto Crucial**:  A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas essenciais para complementar a modelagem das probabilidades posteriores em modelos lineares de classifica√ß√£o, melhorando a estabilidade e a capacidade de generaliza√ß√£o dos modelos, mesmo quando se utilizam fun√ß√µes que imp√µem que as probabilidades estejam entre 0 e 1 e somem 1 [^4.5].

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Hyperplane and Decision Boundary"
    direction TB
        A["Input Data X"]
        B["Linear Function: f(x) = Œ≤‚ÇÄ + Œ≤·µÄx"]
        C["Decision Boundary: f(x) = 0"]
        D["Separating Hyperplane"]
        E["Margin Maximization"]
        F["Perceptron Algorithm"]
        G["Classification based on sign(f(x))"]
        A --> B
        B --> C
        C --> D
        D --> E
        E --> F
        F --> G
    end
```

A busca por **hiperplanos separadores** visa encontrar uma fronteira linear que maximize a separa√ß√£o entre as classes. Essa abordagem pode ser vista como uma forma de aproximar a modelagem das probabilidades posteriores, especialmente em problemas de classifica√ß√£o bin√°ria [^4.5.2]. Um hiperplano separador √© definido como $f(x) = \beta_0 + \beta^T x = 0$, e o objetivo √© encontrar os par√¢metros $\beta_0$ e $\beta$ que maximizem a dist√¢ncia entre o hiperplano e os pontos mais pr√≥ximos de cada classe.

O algoritmo do **Perceptron**, ao buscar um hiperplano separador atrav√©s de ajustes iterativos, encontra uma fronteira de decis√£o que separa as classes com um n√∫mero m√≠nimo de erros, e que se conecta com o conceito de probabilidades posteriores por buscar uma solu√ß√£o que classifique as amostras corretamente [^4.5.1]. O Perceptron, por√©m, n√£o modela explicitamente as probabilidades posteriores, e foca mais na separa√ß√£o das classes, do que na estimativa de probabilidades bem calibradas.

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o bin√°ria com duas vari√°veis preditoras ($x_1$ e $x_2$) e duas classes, onde os pontos da classe 1 s√£o (2, 3), (3, 4), (4, 2) e os pontos da classe 2 s√£o (1, 1), (2, 1), (1, 2). O perceptron busca um hiperplano que separe as classes.
>
> Inicialmente, podemos come√ßar com um hiperplano aleat√≥rio, por exemplo, $\beta_0 = -1$, $\beta_1 = 1$ e $\beta_2 = -1$, o que corresponde √† equa√ß√£o $-1 + x_1 - x_2 = 0$. Podemos verificar o sinal da fun√ß√£o $f(x) = \beta_0 + \beta_1 x_1 + \beta_2 x_2$ para cada ponto:
>
> - Para (2,3):  $f(2,3) = -1 + 2 - 3 = -2 < 0$ (classificado incorretamente, pois √© classe 1)
> - Para (3,4):  $f(3,4) = -1 + 3 - 4 = -2 < 0$ (classificado incorretamente, pois √© classe 1)
> - Para (4,2):  $f(4,2) = -1 + 4 - 2 = 1 > 0$ (classificado corretamente, pois √© classe 1)
> - Para (1,1):  $f(1,1) = -1 + 1 - 1 = -1 < 0$ (classificado corretamente, pois √© classe 2)
> - Para (2,1):  $f(2,1) = -1 + 2 - 1 = 0$ (na fronteira)
> - Para (1,2):  $f(1,2) = -1 + 1 - 2 = -2 < 0$ (classificado corretamente, pois √© classe 2)
>
> Os pontos (2,3) e (3,4) foram classificados incorretamente. O algoritmo do Perceptron ajusta os par√¢metros iterativamente para reduzir o n√∫mero de erros, atualizando o hiperplano com base nos pontos mal classificados, at√© encontrar um hiperplano que separe as classes. O perceptron n√£o modela a probabilidade posterior, mas busca um hiperplano que separe as classes.

**Teorema:** *Em cen√°rios de dados linearmente separ√°veis, o algoritmo do Perceptron converge para um hiperplano separador que minimiza o n√∫mero de erros na classifica√ß√£o, mas n√£o garante, a priori, que a forma da fun√ß√£o de decis√£o se conecte com a probabilidade posterior da classe.* Este teorema estabelece as bases para a garantia de converg√™ncia do Perceptron em situa√ß√µes espec√≠ficas, embora ele n√£o modele as probabilidades posteriores diretamente [^4.5.1].

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**

A **Regra de Decis√£o Bayesiana** busca classificar uma observa√ß√£o $x$ na classe $k$ que maximize a probabilidade posterior $P(G=k|X=x)$ [^4.3].  Sob a suposi√ß√£o de que as classes seguem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia $\Sigma$, a probabilidade posterior √© dada por:

```mermaid
graph LR
    subgraph "Bayesian Decision Rule and LDA"
        direction TB
        A["Class-Conditional Density: œÜ(x;Œº‚Çñ,Œ£)"]
        B["Prior Probability: œÄ‚Çñ"]
        C["Posterior Probability: P(G=k|X=x) = (œÜ(x;Œº‚Çñ,Œ£) * œÄ‚Çñ) / Œ£(œÜ(x;Œº‚Çó,Œ£) * œÄ‚Çó)"]
        D["LDA Discriminant Function (Linear)"]
         E["Decision based on max P(G=k|X=x) (Bayes) or max discriminant (LDA)"]
        A --> C
        B --> C
        C --> E
        A --> D
        D --> E
    end
```

$$
P(G=k|X=x) = \frac{ \phi(x;\mu_k,\Sigma)\pi_k}{\sum_{l=1}^K \phi(x;\mu_l,\Sigma)\pi_l}
$$

onde $\phi(x;\mu_k,\Sigma)$ √© a densidade gaussiana para a classe $k$, $\mu_k$ √© a m√©dia da classe $k$ e $\pi_k$ √© a probabilidade a priori da classe. O **LDA**, por sua vez, deriva suas fun√ß√µes discriminantes lineares a partir dessas suposi√ß√µes, e busca maximizar a separa√ß√£o entre as classes no espa√ßo de caracter√≠sticas, o que corresponde, sob as mesmas premissas, √† maximiza√ß√£o da probabilidade posterior [^4.3].

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o com duas classes, onde as observa√ß√µes de cada classe seguem uma distribui√ß√£o gaussiana com a mesma matriz de covari√¢ncia. Suponha que a m√©dia da classe 1 seja $\mu_1 = [1, 1]^T$ e a m√©dia da classe 2 seja $\mu_2 = [3, 3]^T$. A matriz de covari√¢ncia comum √© $\Sigma = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$. As probabilidades a priori s√£o $\pi_1 = 0.6$ e $\pi_2 = 0.4$.
>
> Um ponto $x = [2, 2]^T$ precisa ser classificado. A fun√ß√£o de densidade gaussiana para cada classe √©:
>
> $$
> \phi(x;\mu_k,\Sigma) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}} \exp\left(-\frac{1}{2}(x-\mu_k)^T\Sigma^{-1}(x-\mu_k)\right)
> $$
>
> Onde $p=2$ √© o n√∫mero de vari√°veis preditoras. Calculando as densidades:
>
> $$
> \phi(x;\mu_1,\Sigma) = \frac{1}{2\pi} \exp\left(-\frac{1}{2}\begin{bmatrix} 2-1 \\ 2-1 \end{bmatrix}^T\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}^{-1}\begin{bmatrix} 2-1 \\ 2-1 \end{bmatrix}\right) = \frac{1}{2\pi} \exp(-1) \approx 0.058
> $$
>
> $$
> \phi(x;\mu_2,\Sigma) = \frac{1}{2\pi} \exp\left(-\frac{1}{2}\begin{bmatrix} 2-3 \\ 2-3 \end{bmatrix}^T\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}^{-1}\begin{bmatrix} 2-3 \\ 2-3 \end{bmatrix}\right) = \frac{1}{2\pi} \exp(-1) \approx 0.058
> $$
>
> As probabilidades posteriores s√£o:
>
> $$
> P(G=1|X=x) = \frac{0.058 \times 0.6}{0.058 \times 0.6 + 0.058 \times 0.4} = \frac{0.0348}{0.058} = 0.6
> $$
>
> $$
> P(G=2|X=x) = \frac{0.058 \times 0.4}{0.058 \times 0.6 + 0.058 \times 0.4} = \frac{0.0232}{0.058} = 0.4
> $$
>
> De acordo com a regra de decis√£o Bayesiana, o ponto $x$ seria classificado na classe 1, pois $P(G=1|X=x) > P(G=2|X=x)$. O LDA, sob as mesmas premissas, chegaria √† mesma conclus√£o.

**Lemma 4:** *Sob a suposi√ß√£o de distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia, a regra de decis√£o Bayesiana e o LDA s√£o equivalentes e levam √† mesma fronteira de decis√£o linear e √† mesma classifica√ß√£o, e ambos se baseiam na maximiza√ß√£o da probabilidade posterior da classe.* A demonstra√ß√£o dessa equival√™ncia se d√° atrav√©s da manipula√ß√£o alg√©brica, que mostra como as fun√ß√µes discriminantes do LDA e a probabilidade posterior s√£o relacionadas atrav√©s do log-ratio das probabilidades posteriores [^4.3].

**Corol√°rio 4:** *Quando a restri√ß√£o de igualdade de covari√¢ncias √© relaxada, a regra de decis√£o Bayesiana leva ao Quadratic Discriminant Analysis (QDA), que n√£o utiliza fun√ß√µes discriminantes lineares, e cujas fronteiras de decis√£o s√£o quadr√°ticas. O QDA representa uma abordagem mais geral para a tomada de decis√£o, que se baseia na modelagem de probabilidades posteriores, mas relaxa a suposi√ß√£o de covari√¢ncias iguais.* A remo√ß√£o da suposi√ß√£o de igualdade das matrizes de covari√¢ncias leva a um modelo mais complexo, e a fronteiras de decis√£o n√£o lineares [^4.3.1], [^4.3.3].

> ‚ö†Ô∏è **Ponto Crucial**: A principal diferen√ßa entre LDA e a regra de decis√£o Bayesiana reside na abordagem. LDA √© um caso particular onde a suposi√ß√£o gaussiana e de covari√¢ncias iguais leva a uma forma funcional espec√≠fica, uma fun√ß√£o discriminante linear, enquanto a regra Bayesiana oferece uma formula√ß√£o mais geral da decis√£o. LDA deriva a fun√ß√£o discriminante utilizando premissas sobre as densidades e que levam ao mesmo log-ratio que a regra de decis√£o Bayesiana sob as mesmas premissas [^4.3].

### Conclus√£o

Neste cap√≠tulo, exploramos a modelagem de probabilidades posteriores com fun√ß√µes lineares, com √™nfase em como impor as restri√ß√µes de soma unit√°ria e intervalo [0,1]. Analisamos como a regress√£o log√≠stica utiliza a fun√ß√£o log√≠stica para garantir que as estimativas se comportem como probabilidades, e como o LDA deriva as probabilidades posteriores atrav√©s da suposi√ß√£o gaussiana e de covari√¢ncias iguais. Discutimos como a regress√£o linear com matrizes de indicadores n√£o modela as probabilidades posteriores diretamente, e como a sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o importantes para melhorar a estabilidade e a capacidade de generaliza√ß√£o dos modelos.  Vimos tamb√©m como a busca por hiperplanos separadores se relaciona com a modelagem de probabilidades posteriores. Ao longo do cap√≠tulo, procuramos fornecer uma vis√£o aprofundada da rela√ß√£o entre a modelagem de probabilidades posteriores e a constru√ß√£o de modelos de classifica√ß√£o linear.

### Footnotes

[^4.1]: *In this chapter we revisit the classification problem and focus on linear methods for classification...There are several different ways in which linear decision boundaries can be found.* *(Trecho de Linear Methods for Classification)*

[^4.2]: *In Chapter 2 we fit linear regression models to the class indicator variables, and classify to the largest fit...Linear inequalities in this space are quadratic inequalities in the original space.* *(Trecho de Linear Methods for Classification)*

[^4.3]: *Decision theory for classification (Section 2.4) tells us that we need to know the class posteriors Pr(G|X) for optimal classification. Suppose fk(x) is the class-conditional density of X in class G = k, and let œÄŒ∫ be the prior probability of class k... Linear discriminant analysis (LDA) arises in the special case when we assume that the classes have a common covariance matrix Œ£k = Œ£.* *(Trecho de Linear Methods for Classification)*

[^4.3.1]: *The decision boundary between each pair of classes k and l is described by a quadratic equation {x: Œ¥Œ∫(x) = Œ¥(x)}.* *(Trecho de Linear Methods for Classification)*

[^4.3.3]: *In the special case when we assume that the classes have a common covariance matrix...When the classes are really Gaussian, then LDA is optimal* *(Trecho de Linear Methods for Classification)*

[^4.4]: *The logistic regression model arises from the desire to model the posterior probabilities of the K classes via linear functions in x, while at the same time ensuring that they sum to one and remain in [0,1].* *(Trecho de Linear Methods for Classification)*

[^4.4.1]: *Logistic regression models are usually fit by maximum likelihood... The logistic regression model is more general, in that it makes less assumptions.* *(Trecho de Linear Methods for Classification)*

[^4.4.2]: *It is convenient to code the two-class gi via a 0/1 response Yi, where yi = 1 when gi = 1, and yi = 0 when gi = 2... Typically many models are fit in a search for a parsimonious model involving a subset of the variables.* *(Trecho de Linear Methods for Classification)*

[^4.4.3]: *To maximize the log-likelihood, we set its derivatives to zero. These score equations are...To solve the score equations (4.21), we use the Newton-Raphson algorithm...* *(Trecho de Linear Methods for Classification)*

[^4.4.4]: *The L1 penalty used in the lasso (Section 3.4.2) can be used for variable selection and shrinkage with any linear regression model...As with the lasso, we typically do not penalize the intercept term.* *(Trecho de Linear Methods for Classification)*

[^4.5]: *Here we present an analysis of binary data to illustrate the traditional statistical use of the logistic regression model... With two classes there is a simple correspondence between linear discriminant analysis and classification by linear least squares, as in (4.5).* *(Trecho de Linear Methods for Classification)*

[^4.5.1]: *The perceptron learning algorithm tries to find a separating hyperplane by minimizing the distance of misclassified points to the decision boundary.* *(Trecho de Linear Methods for Classification)*

[^4.5.2]: *The optimal separating hyperplane separates the two classes and maximizes the distance to the closest point from either class... In light of (4.40), the constraints define an empty slab or margin around the linear decision boundary...* *(Trecho de Linear Methods for Classification)*
