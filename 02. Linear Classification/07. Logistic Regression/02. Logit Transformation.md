## T√≠tulo Conciso: Classifica√ß√£o Linear e a Transforma√ß√£o Logit: Lineariza√ß√£o da Rela√ß√£o Probabilidade-Preditor

```mermaid
graph LR
    subgraph "Logit Transformation and Linearization"
        direction TB
        A["Input: Probability p (0 to 1)"]
        B["Logit Transformation: log(p/(1-p))"]
        C["Output: Log-odds (-‚àû to +‚àû)"]
        D["Linear Model: Œ≤‚ÇÄ + Œ≤·µÄx"]
        E["Linear Relationship: logit(P(G=1|X=x)) = Œ≤‚ÇÄ + Œ≤·µÄx"]
        A --> B
        B --> C
        D --> E
        C --> E
    end
```

### Introdu√ß√£o

Este cap√≠tulo explora em profundidade a **transforma√ß√£o logit**, e como ela √© utilizada na **regress√£o log√≠stica** para linearizar a rela√ß√£o entre a probabilidade de uma classe e um preditor linear. Analisaremos como a fun√ß√£o log√≠stica, quando transformada atrav√©s do logit, resulta em uma fun√ß√£o linear em rela√ß√£o aos par√¢metros do modelo, e como essa lineariza√ß√£o facilita a estima√ß√£o e a interpreta√ß√£o dos resultados [^4.4]. Compararemos a abordagem da regress√£o log√≠stica com a **regress√£o linear com matrizes de indicadores**, que n√£o utiliza a transforma√ß√£o logit e com o **Linear Discriminant Analysis (LDA)**, que utiliza transforma√ß√µes lineares baseadas em suposi√ß√µes gaussianas [^4.2], [^4.3]. Abordaremos tamb√©m a import√¢ncia da **sele√ß√£o de vari√°veis e regulariza√ß√£o** para controlar a complexidade dos modelos log√≠sticos e melhorar a sua capacidade de generaliza√ß√£o [^4.4.4], [^4.5]. Discutiremos como a transforma√ß√£o logit se conecta com a busca por **hiperplanos separadores** em modelos de classifica√ß√£o [^4.5.2]. O objetivo deste cap√≠tulo √© fornecer uma compreens√£o detalhada de como a transforma√ß√£o logit √© utilizada para modelar probabilidades posteriores de forma linear, e como isso se conecta com a constru√ß√£o de modelos de classifica√ß√£o eficientes e robustos.

### Conceitos Fundamentais

**Conceito 1: O Conceito da Transforma√ß√£o Logit**

A **transforma√ß√£o logit**, tamb√©m conhecida como log-odds, √© uma fun√ß√£o que mapeia probabilidades do intervalo [0,1] para o intervalo dos n√∫meros reais ($-\infty$, $+\infty$).  O logit de uma probabilidade $p$ √© definido como:

$$
\text{logit}(p) = \log \left( \frac{p}{1-p} \right)
$$

A transforma√ß√£o logit √© utilizada na regress√£o log√≠stica para linearizar a rela√ß√£o entre a probabilidade de pertencer a uma classe e o preditor linear $\beta_0 + \beta^T x$. A transforma√ß√£o logit, portanto, cria uma rela√ß√£o linear entre o preditor linear e o log-odds da probabilidade, facilitando a aplica√ß√£o de modelos lineares [^4.4].

> üí° **Exemplo Num√©rico:**
>
> Vamos calcular o logit para algumas probabilidades:
>
> - Se $p = 0.1$, ent√£o $\text{logit}(0.1) = \log(\frac{0.1}{1-0.1}) = \log(\frac{0.1}{0.9}) = \log(1/9) \approx -2.197$.
> - Se $p = 0.5$, ent√£o $\text{logit}(0.5) = \log(\frac{0.5}{1-0.5}) = \log(\frac{0.5}{0.5}) = \log(1) = 0$.
> - Se $p = 0.9$, ent√£o $\text{logit}(0.9) = \log(\frac{0.9}{1-0.9}) = \log(\frac{0.9}{0.1}) = \log(9) \approx 2.197$.
>
> Observe que probabilidades menores que 0.5 resultam em logits negativos, probabilidades iguais a 0.5 resultam em um logit de 0, e probabilidades maiores que 0.5 resultam em logits positivos. A transforma√ß√£o logit estica a escala de probabilidade, especialmente perto dos limites 0 e 1, tornando-a linearmente relacionada com o preditor.

**Lemma 1:** *A transforma√ß√£o logit √© uma fun√ß√£o que mapeia probabilidades do intervalo [0,1] para o conjunto dos n√∫meros reais, o que permite que modelos lineares sejam utilizados para modelar o log-odds (logaritmo da raz√£o das chances) e que os par√¢metros sejam estimados de forma mais simples.* A prova desse lema est√° na forma funcional da transforma√ß√£o logit e como ela relaciona probabilidade e preditores lineares.

**Conceito 2: Regress√£o Log√≠stica e a Lineariza√ß√£o da Rela√ß√£o Probabilidade-Preditor**

Na **regress√£o log√≠stica**, a probabilidade de uma observa√ß√£o $x$ pertencer a uma classe $k$ (num problema bin√°rio, a classe 1) √© modelada usando a fun√ß√£o log√≠stica:

$$
P(G=1|X=x) = \frac{e^{\beta_0 + \beta^T x}}{1 + e^{\beta_0 + \beta^T x}}
$$

A aplica√ß√£o da transforma√ß√£o logit nessa probabilidade resulta em uma fun√ß√£o linear:

```mermaid
graph LR
    subgraph "Logit Transformation in Logistic Regression"
        direction TB
        A["P(G=1|X=x) = e^(Œ≤‚ÇÄ + Œ≤·µÄx) / (1 + e^(Œ≤‚ÇÄ + Œ≤·µÄx))"]
        B["Apply Logit: log(P/(1-P))"]
        C["logit(P(G=1|X=x)) = Œ≤‚ÇÄ + Œ≤·µÄx"]
        A --> B
        B --> C
    end
```

$$
\text{logit}(P(G=1|X=x)) = \log \left(\frac{P(G=1|X=x)}{1 - P(G=1|X=x)}\right) = \beta_0 + \beta^T x
$$

Essa lineariza√ß√£o √© fundamental para que os par√¢metros $\beta_0$ e $\beta$ possam ser estimados utilizando t√©cnicas de otimiza√ß√£o, como a maximiza√ß√£o da verossimilhan√ßa [^4.4.1].  A transforma√ß√£o logit, portanto, transforma um problema n√£o linear em um problema linear no espa√ßo dos par√¢metros.

> üí° **Exemplo Num√©rico:**
>
> Suponha que tenhamos um modelo de regress√£o log√≠stica com um √∫nico preditor $x$ e par√¢metros $\beta_0 = -2$ e $\beta_1 = 1$.  Ent√£o, o log-odds para um valor de $x=2$ seria:
>
> $\text{logit}(P(G=1|X=2)) = -2 + 1 \cdot 2 = 0$
>
> Para encontrar a probabilidade correspondente, usamos a fun√ß√£o log√≠stica inversa:
>
> $P(G=1|X=2) = \frac{e^0}{1+e^0} = \frac{1}{1+1} = 0.5$
>
> Se $x = 3$:
>
> $\text{logit}(P(G=1|X=3)) = -2 + 1 \cdot 3 = 1$
>
> $P(G=1|X=3) = \frac{e^1}{1+e^1} \approx \frac{2.718}{1+2.718} \approx 0.731$
>
> Aqui, o aumento em $x$ leva a um aumento linear no log-odds, e um aumento n√£o linear na probabilidade, demonstrando como a transforma√ß√£o logit lineariza a rela√ß√£o no espa√ßo dos par√¢metros.

**Corol√°rio 1:** *A transforma√ß√£o logit lineariza a rela√ß√£o entre a probabilidade e o preditor linear na regress√£o log√≠stica, o que permite que modelos lineares sejam utilizados para modelar a probabilidade de pertencer a uma classe.* Esse corol√°rio estabelece a raz√£o de ser do logit e de sua import√¢ncia em modelos lineares de classifica√ß√£o.

**Conceito 3:  A Fun√ß√£o Log√≠stica e a Garantia de Probabilidades no Intervalo [0, 1]**

A **fun√ß√£o log√≠stica** (sigmoide), que √© a inversa da transforma√ß√£o logit, garante que as probabilidades estimadas pela regress√£o log√≠stica estejam no intervalo [0,1].  A fun√ß√£o log√≠stica, dada por:

$$
\frac{e^x}{1 + e^x}
$$

mapeia um n√∫mero real $x$ para um valor entre 0 e 1.  Essa propriedade da fun√ß√£o log√≠stica √© crucial para que a sa√≠da da regress√£o log√≠stica possa ser interpretada como uma probabilidade [^4.4].

> üí° **Exemplo Num√©rico:**
>
> Vamos avaliar a fun√ß√£o log√≠stica para alguns valores de $x$:
>
> - Se $x = -5$, a fun√ß√£o log√≠stica resulta em $\frac{e^{-5}}{1 + e^{-5}} \approx \frac{0.0067}{1 + 0.0067} \approx 0.0066$.
> - Se $x = 0$, a fun√ß√£o log√≠stica resulta em $\frac{e^0}{1 + e^0} = \frac{1}{1+1} = 0.5$.
> - Se $x = 5$, a fun√ß√£o log√≠stica resulta em $\frac{e^5}{1 + e^5} \approx \frac{148.41}{1 + 148.41} \approx 0.9933$.
>
> Como podemos ver, a fun√ß√£o log√≠stica sempre produz um valor entre 0 e 1, independentemente do valor de entrada $x$, garantindo que as probabilidades estimadas na regress√£o log√≠stica sejam v√°lidas.

> ‚ö†Ô∏è **Nota Importante**:  A transforma√ß√£o logit lineariza a rela√ß√£o probabilidade-preditor, e a fun√ß√£o log√≠stica garante que as probabilidades resultantes estejam no intervalo [0,1].

> ‚ùó **Ponto de Aten√ß√£o**: A regress√£o log√≠stica, ao utilizar a fun√ß√£o log√≠stica para modelar as probabilidades, se torna um m√©todo de classifica√ß√£o flex√≠vel e que n√£o necessita das suposi√ß√µes Gaussianas, como no LDA.

> ‚úîÔ∏è **Destaque**: A transforma√ß√£o logit √© uma ferramenta fundamental para a modelagem de probabilidades com modelos lineares, e a fun√ß√£o log√≠stica garante a calibra√ß√£o das probabilidades estimadas.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regression Methods for Classification"
        direction LR
        A["Linear Regression with Indicator Matrix"]
        B["Logistic Regression with Logit"]
        A --> C["Directly Fits Classes"]
        B --> D["Transforms Probabilities with Logit"]
        C --> E["Outputs can be outside [0,1]"]
        D --> F["Outputs in [0,1] using Logistic function"]
    end
```

A **regress√£o linear com matrizes de indicadores**, ao contr√°rio da regress√£o log√≠stica, n√£o utiliza a transforma√ß√£o logit para modelar as probabilidades posteriores.  A regress√£o linear ajusta diretamente um modelo linear para cada classe, buscando minimizar a soma de quadrados dos erros, e n√£o imp√µe nenhuma restri√ß√£o sobre a forma funcional das probabilidades estimadas [^4.2]. Isso resulta em estimativas que podem assumir valores fora do intervalo [0,1], e que a soma das probabilidades n√£o √© garantidamente igual a 1. A regress√£o linear n√£o modela o log-odds como uma fun√ß√£o linear dos par√¢metros, e n√£o se beneficia da transforma√ß√£o que lineariza essa rela√ß√£o como faz a regress√£o log√≠stica [^4.2].

Enquanto a regress√£o log√≠stica utiliza a transforma√ß√£o logit e a fun√ß√£o log√≠stica para modelar as probabilidades de forma calibrada, a regress√£o linear busca uma rela√ß√£o linear entre os dados e a resposta de cada classe, sem levar em considera√ß√£o a necessidade de que as respostas se comportem como probabilidades [^4.4].

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o bin√°ria com uma vari√°vel preditora $x$ e duas classes (0 e 1). Vamos gerar dados simulados para ilustrar a diferen√ßa entre regress√£o linear e log√≠stica.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression, LogisticRegression
>
> np.random.seed(42)
> X = np.linspace(-5, 5, 100).reshape(-1, 1)
> y = (X > 0).astype(int).flatten()
> y_noisy = y + np.random.normal(0, 0.2, 100) # Adicionando ru√≠do
> y_noisy = np.clip(y_noisy, 0, 1) # Garante que os valores estejam entre 0 e 1
>
> # Regress√£o Linear
> linear_model = LinearRegression()
> linear_model.fit(X, y_noisy)
> y_linear_pred = linear_model.predict(X)
>
> # Regress√£o Log√≠stica
> logistic_model = LogisticRegression()
> logistic_model.fit(X, y)
> y_logistic_pred = logistic_model.predict_proba(X)[:, 1]
>
> # Plotting
> plt.figure(figsize=(10, 6))
> plt.scatter(X, y_noisy, label='Dados Ruidosos', alpha=0.5)
> plt.plot(X, y_linear_pred, color='red', label='Regress√£o Linear')
> plt.plot(X, y_logistic_pred, color='green', label='Regress√£o Log√≠stica')
> plt.xlabel('Preditor (x)')
> plt.ylabel('Probabilidade/Valor da Classe')
> plt.legend()
> plt.title('Compara√ß√£o entre Regress√£o Linear e Log√≠stica')
> plt.grid(True)
> plt.ylim(-0.1, 1.1)
> plt.show()
> ```
>
> O gr√°fico gerado mostra que a regress√£o linear pode produzir valores fora do intervalo [0, 1], enquanto a regress√£o log√≠stica sempre produz probabilidades dentro desse intervalo. A regress√£o log√≠stica, ao utilizar a fun√ß√£o log√≠stica, modela as probabilidades de forma mais apropriada para o problema de classifica√ß√£o.

**Lemma 2:** *A regress√£o linear com matrizes de indicadores n√£o utiliza a transforma√ß√£o logit para modelar as probabilidades posteriores, e portanto, n√£o garante que as estimativas perten√ßam ao intervalo [0, 1] e que somem 1.*  A prova deste lema reside na formula√ß√£o do m√©todo dos m√≠nimos quadrados, que n√£o imp√µe qualquer restri√ß√£o sobre os valores de sa√≠da.

**Corol√°rio 2:** *A falta de utiliza√ß√£o da transforma√ß√£o logit na regress√£o linear com matrizes de indicadores resulta em um modelo que n√£o modela as probabilidades posteriores diretamente, e, portanto, n√£o garante que as estimativas sejam calibradas e consistentes com a teoria de decis√£o, ao contr√°rio da regress√£o log√≠stica.*  Este corol√°rio destaca a diferen√ßa fundamental entre os dois m√©todos.

A regress√£o linear com matrizes de indicadores, portanto, ao n√£o utilizar a transforma√ß√£o logit, apresenta limita√ß√µes para modelar probabilidades posteriores, o que a distingue da regress√£o log√≠stica, que utiliza a fun√ß√£o log√≠stica para linearizar a rela√ß√£o entre probabilidade e preditores lineares, e assim, obter uma estimativa de probabilidades mais calibrada e consistente com a teoria de decis√£o [^4.2], [^4.4].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization in Logistic Regression"
        direction TB
        A["Logistic Regression Model: logit(P) = Œ≤‚ÇÄ + Œ≤·µÄx"]
        B["Add Regularization Term: - ŒªP(Œ≤)"]
        C["L1 (Lasso) Penalty: P(Œ≤) = Œ£|Œ≤‚±º|"]
        D["L2 (Ridge) Penalty: P(Œ≤) = Œ£Œ≤‚±º¬≤"]
        E["Optimization: Maximize Log-Likelihood - ŒªP(Œ≤)"]
        A --> B
        B --> C
        B --> D
        C --> E
        D --> E
    end
```

A **sele√ß√£o de vari√°veis** e a **regulariza√ß√£o** s√£o ferramentas essenciais para melhorar a qualidade da modelagem das probabilidades posteriores em modelos de classifica√ß√£o, como a regress√£o log√≠stica, e auxiliar na obten√ß√£o de estimativas mais robustas e est√°veis dos coeficientes do modelo [^4.5].  A regulariza√ß√£o, em particular, busca restringir a magnitude dos coeficientes, o que pode melhorar a estabilidade da fun√ß√£o log√≠stica e prevenir o *overfitting*.

Na **regress√£o log√≠stica**, a regulariza√ß√£o √© implementada adicionando um termo de penalidade √† fun√ß√£o de verossimilhan√ßa:

$$
\max_{\beta_0, \beta} \left[ \sum_{i=1}^N \left( y_i (\beta_0 + \beta^T x_i) - \log(1 + e^{\beta_0 + \beta^T x_i}) \right) - \lambda P(\beta) \right]
$$

onde $P(\beta)$ √© a penalidade e $\lambda$ √© o par√¢metro de regulariza√ß√£o.  A penalidade **L1** (Lasso) √© dada por $P(\beta) = \sum_{j=1}^p |\beta_j|$, que promove a esparsidade nos coeficientes, selecionando as vari√°veis mais relevantes para a modelagem da probabilidade posterior [^4.4.4]. A penalidade **L2** (Ridge) √© dada por $P(\beta) = \sum_{j=1}^p \beta_j^2$, que reduz a magnitude dos coeficientes e estabiliza o modelo [^4.5].

> üí° **Exemplo Num√©rico:**
>
> Vamos demonstrar o efeito da regulariza√ß√£o L1 (Lasso) em um modelo de regress√£o log√≠stica. Usaremos um conjunto de dados simulado com 10 vari√°veis preditoras, onde apenas 3 s√£o realmente relevantes para a classe.
>
> ```python
> import numpy as np
> import pandas as pd
> from sklearn.model_selection import train_test_split
> from sklearn.linear_model import LogisticRegression
> from sklearn.metrics import accuracy_score
>
> # Gerando dados simulados
> np.random.seed(42)
> n_samples = 200
> n_features = 10
> X = np.random.rand(n_samples, n_features)
> beta_true = np.array([2, -3, 1.5, 0, 0, 0, 0, 0, 0, 0])
> y_prob = 1 / (1 + np.exp(-(np.dot(X, beta_true) + np.random.normal(0, 0.5, n_samples))))
> y = (y_prob > 0.5).astype(int)
>
> # Dividindo os dados em treinamento e teste
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Modelo sem regulariza√ß√£o
> model_no_reg = LogisticRegression(penalty=None, solver='lbfgs', max_iter=1000)
> model_no_reg.fit(X_train, y_train)
> y_pred_no_reg = model_no_reg.predict(X_test)
> accuracy_no_reg = accuracy_score(y_test, y_pred_no_reg)
>
> # Modelo com regulariza√ß√£o L1 (Lasso)
> model_l1 = LogisticRegression(penalty='l1', C=0.5, solver='liblinear', random_state=42, max_iter=1000) # C √© o inverso de lambda
> model_l1.fit(X_train, y_train)
> y_pred_l1 = model_l1.predict(X_test)
> accuracy_l1 = accuracy_score(y_test, y_pred_l1)
>
> # Comparando os coeficientes
> coef_no_reg = model_no_reg.coef_.flatten()
> coef_l1 = model_l1.coef_.flatten()
>
> df_coef = pd.DataFrame({'Feature': range(n_features),
>                           'No Regularization': coef_no_reg,
>                            'L1 Regularization': coef_l1})
> print("Acur√°cia sem regulariza√ß√£o: ", accuracy_no_reg)
> print("Acur√°cia com regulariza√ß√£o L1: ", accuracy_l1)
> print("\nCoeficientes do modelo:\n", df_coef)
> ```
>
> Executando este c√≥digo, podemos observar que:
>
> 1. A regulariza√ß√£o L1 leva a coeficientes nulos para as vari√°veis irrelevantes, realizando a sele√ß√£o de vari√°veis.
> 2. A acur√°cia pode ser similar ou melhor com regulariza√ß√£o, devido √† redu√ß√£o do overfitting e √† sele√ß√£o de vari√°veis.
>
> A tabela de coeficientes mostra que a regulariza√ß√£o L1 (Lasso) zerou os coeficientes das vari√°veis menos relevantes, simplificando o modelo.

Ao controlar a complexidade do modelo atrav√©s da regulariza√ß√£o e da sele√ß√£o de vari√°veis, √© poss√≠vel obter estimativas mais precisas das probabilidades posteriores, e construir modelos que s√£o mais robustos e com melhor capacidade de generaliza√ß√£o.

**Lemma 3:** *A regulariza√ß√£o L1, ao promover a esparsidade, leva √† sele√ß√£o de vari√°veis mais relevantes para a estimativa das probabilidades posteriores, resultando em modelos mais simples e com melhor capacidade de generaliza√ß√£o*. O mecanismo que gera a esparsidade est√° na forma da penalidade L1.

**Prova do Lemma 3:**  A penalidade L1, ao adicionar um termo que √© proporcional ao valor absoluto dos coeficientes, for√ßa os coeficientes menos relevantes a se tornarem exatamente zero durante o processo de otimiza√ß√£o, e essa esparsidade leva √† modelos mais simples, e que focam na vari√°veis mais relevantes para a estimativa das probabilidades posteriores [^4.4.3], [^4.4.4]. $\blacksquare$

**Corol√°rio 3:** *A regulariza√ß√£o, tanto L1 quanto L2, contribui para uma estimativa mais precisa e est√°vel das probabilidades posteriores, e o controle da complexidade do modelo atrav√©s da regulariza√ß√£o melhora a capacidade de generaliza√ß√£o, e evita o overfitting, mesmo quando se utiliza a transforma√ß√£o logit.*  O controle da complexidade √© uma ferramenta importante para obter estimativas de probabilidade mais robustas.

> ‚ö†Ô∏è **Ponto Crucial**: A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas cruciais para melhorar a modelagem das probabilidades posteriores, e o controle da complexidade dos modelos,  levando a modelos mais robustos e generaliz√°veis [^4.5].

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Perceptron Algorithm and Hyperplane Separation"
        direction TB
        A["Input Data: (X, y)"]
        B["Initialize: w, b"]
        C["For each misclassified point:"]
        D["Update: w = w + Œ∑y·µ¢x·µ¢"]
        E["Update: b = b + Œ∑y·µ¢"]
        C --> D
        C --> E
        D --> C
        E --> C
        F["Converges to separating hyperplane"]
        C --> F
    end
```

A busca por **hiperplanos separadores** busca encontrar uma fronteira linear que maximize a separa√ß√£o entre as classes, e essa busca, embora n√£o modele explicitamente as probabilidades posteriores, pode ser vista como uma aproxima√ß√£o para a separa√ß√£o das classes com base em informa√ß√µes derivadas da modelagem dessas probabilidades [^4.5.2].  O hiperplano separador define uma fronteira linear no espa√ßo de caracter√≠sticas, e a posi√ß√£o do hiperplano (definida pelo intercepto e pelos coeficientes) √© otimizada para maximizar a dist√¢ncia entre as classes, de acordo com um crit√©rio espec√≠fico.

O algoritmo do **Perceptron**, por sua vez, busca um hiperplano separador ajustando os par√¢metros do modelo de forma iterativa com base nas classifica√ß√µes incorretas [^4.5.1]. O Perceptron, em sua forma original, n√£o modela as probabilidades posteriores, e busca apenas a separa√ß√£o das classes. Contudo, em problemas de classifica√ß√£o bin√°ria, o Perceptron pode ser interpretado como um m√©todo que modela o sinal do log-odds, que √© uma transforma√ß√£o da probabilidade posterior, e sua converg√™ncia est√° relacionada com a capacidade de separar as classes de forma linear.

> üí° **Exemplo Num√©rico:**
>
> Considere um exemplo de dados linearmente separ√°veis em duas dimens√µes. Vamos usar o Perceptron para encontrar o hiperplano separador.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Dados linearmente separ√°veis
> X = np.array([[1, 1], [2, 2], [2, 0], [0, 0], [1, 0], [0, 1]])
> y = np.array([1, 1, 1, -1, -1, -1])
>
> def perceptron_step(X, y, w, b, learning_rate=0.1):
>     misclassified = True
>     while misclassified:
>         misclassified = False
>         for i in range(len(X)):
>             if y[i] * (np.dot(w, X[i]) + b) <= 0:
>                 w = w + learning_rate * y[i] * X[i]
>                 b = b + learning_rate * y[i]
>                 misclassified = True
>     return w, b
>
> # Inicializa√ß√£o dos pesos e bias
> w = np.array([0, 0])
> b = 0
>
> # Executando o Perceptron
> w, b = perceptron_step(X, y, w, b)
>
> # Plotando o hiperplano separador
> x_vals = np.linspace(-1, 3, 100)
> y_vals = (-w[0] * x_vals - b) / w[1]
>
> plt.figure(figsize=(8, 6))
> plt.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm')
> plt.plot(x_vals, y_vals, color='black', label='Hiperplano')
> plt.xlabel('X1')
> plt.ylabel('X2')
> plt.title('Perceptron - Hiperplano Separador')
> plt.legend()
> plt.grid(True)
> plt.show()
>
> print("Pesos encontrados:", w)
> print("Bias encontrado:", b)
>
> ```
>
> O c√≥digo demonstra que o Perceptron encontra um hiperplano que separa os dados, ajustando iterativamente os pesos e o bias at√© que n√£o haja mais classifica√ß√µes incorretas.  Este hiperplano, embora n√£o represente diretamente as probabilidades, serve como uma aproxima√ß√£o para a separa√ß√£o das classes.

**Teorema:** *Em um cen√°rio de dados linearmente separ√°veis, o algoritmo do Perceptron converge para um hiperplano separador em um n√∫mero finito de itera√ß√µes, mas n√£o garante a obten√ß√£o das estimativas de probabilidades posteriores, mas busca uma separa√ß√£o baseada na rela√ß√£o entre as probabilidades das classes.*  A converg√™ncia para uma solu√ß√£o separadora sob condi√ß√µes espec√≠ficas, e sem utilizar informa√ß√£o da teoria da decis√£o, √© a principal caracter√≠stica do algoritmo do Perceptron [^4.5.1].

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

```mermaid
graph LR
    subgraph "LDA vs Bayesian Decision Rule"
        direction LR
        A["Bayesian Decision Rule: Max P(G=k|X=x)"]
        B["LDA: Linear Discriminant Functions"]
        C["Assumption: Gaussian Classes with Same Covariance"]
        A --> C
        B --> C
        D["Bayes Posterior: P(G=k|X=x) = (œÜ(x;Œº‚Çñ,Œ£)œÄ‚Çñ) / (Œ£‚ÇóœÜ(x;Œº‚Çó,Œ£)œÄ‚Çó)"]
        E["LDA Discriminant Function: Œ¥‚Çñ(x) = x·µÄŒ£‚Åª¬πŒº‚Çñ - 0.5Œº‚Çñ·µÄŒ£‚Åª¬πŒº‚Çñ + log(œÄ‚Çñ)"]
        C --> D
        C --> E
        F["Log-ratio of Bayes posterior ‚âà LDA discriminant"]
        D --> F
        E --> F
    end
```

**Resposta:**

A **Regra de Decis√£o Bayesiana** busca classificar uma observa√ß√£o $x$ na classe $k$ que maximize a probabilidade posterior $P(G=k|X=x)$ [^4.3]. Sob a suposi√ß√£o de que as distribui√ß√µes condicionais $P(X|G=k)$ s√£o Gaussianas com a mesma matriz de covari√¢ncia $\Sigma$, a probabilidade posterior √© dada por:

$$
P(G=k|X=x) = \frac{ \phi(x;\mu_k,\Sigma)\pi_k}{\sum_{l=1}^K \phi(x;\mu_l,\Sigma)\pi_l}
$$

onde $\phi(x;\mu_k,\Sigma)$ √© a densidade gaussiana da classe $k$, $\mu_k$ √© a m√©dia da classe $k$ e $\pi_k$ √© a probabilidade a priori da classe. O **LDA**, por sua vez, deriva suas fun√ß√µes discriminantes lineares diretamente dessas suposi√ß√µes e ao tomar o log-ratio das probabilidades posteriores, e utiliza as probabilidades a priori das classes, e as m√©dias, e covari√¢ncia comum para obter a sua fun√ß√£o discriminante linear [^4.3].

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um exemplo simplificado com duas classes, cada uma com uma distribui√ß√£o gaussiana com a mesma matriz de covari√¢ncia.
>
> Suponha que temos:
>
> - Classe 1: $\mu_1 = [1, 1]$, $\pi_1 = 0.6$
> - Classe 2: $\mu_2 = [3, 3]$, $\pi_2 = 0.4$
> - Matriz de covari√¢ncia comum: $\Sigma = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$
>
> Vamos calcular as fun√ß√µes discriminantes do LDA para um ponto $x = [2, 2]$.
>
> A fun√ß√£o discriminante do LDA para a classe $k$ √©:
>
> $\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log \pi_k$
>
> Como $\Sigma$ √© a matriz identidade, $\Sigma^{-1} = \Sigma$:
>
> $\delta_1(x) = [2, 2] \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} [1, 1]^T - \frac{1}{2} [1, 1] \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} [1, 1]^T + \log(0.6)$
> $\delta_1(x) = [2, 2] [1, 1]^T - \frac{1}{2} [1, 1] [1, 1]^T + \log(0.6)$
> $\delta_1(x) = 4 - \frac{1}{2} (2) + \log(0.6) = 4 - 1 - 0.51 \approx 2.49$
>
> $\delta_2(x) = [2, 2] \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} [3, 3]^T - \frac{1}{2} [3, 3] \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} [3, 3]^T + \log(0.4)$
> $\delta_2(x) = [2, 2] [3, 3]^T - \frac{1}{2} [3, 3] [3, 3]^T + \log(0.4)$
> $\delta_2(x) = 12 - \frac{1}{2} (18) + \log(0.4) = 12 - 9 - 0.916 \approx 2.084$
>
> Como $\delta_1(x) > \delta_2(x)$, o LDA classificaria o ponto $x$ como pertencente √† Classe 1. Este exemplo ilustra como o LDA utiliza as m√©dias, a covari√¢ncia comum, e as probabilidades a priori para construir as fun√ß√µes discriminantes lineares.

**Lemma 4:** *Sob a suposi√ß√£o de que as classes seguem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia, a regra de decis√£o Bayesiana e as fun√ß√µes discriminantes do LDA s√£o equivalentes, e o LDA utiliza a suposi√ß√£o gaussiana para simplificar a forma da fun√ß√£o discriminante e para obter uma forma linear das probabilidades posteriores, de maneira indireta.* Esta equival√™ncia √© obtida mostrando que o log-ratio das probabilidades posteriores na regra de decis√£o Bayesiana √© equivalente √† fun√ß√£o discriminante do LDA sob a mesma premissa. [^4.3]

**Corol√°rio 4:** *Ao remover a restri√ß√£o de igualdade de covari√¢ncias, a regra de decis√£o Bayesiana leva ao QDA, onde as probabilidades posteriores s√£o modeladas de forma mais geral e a fronteira de decis√£o n√£o √© mais linear, mas sim quadr√°tica.* O QDA, portanto, relaxa uma premissa do LDA, e utiliza informa√ß√µes da covari√¢ncia de cada classe para a constru√ß√£o da fronteira de decis√£o. [^4.3.1], [^4.3.3].

> ‚ö†Ô∏è **Ponto Crucial**:  A principal diferen√ßa entre o LDA e a regra de decis√£o Bayesiana est√° na suposi√ß√£o da igualdade das matrizes de covari√¢ncia, e como esta suposi√ß√£o leva √† mesma fronteira de decis√£o linear, que √© expressa atrav√©s da fun√ß√£o discriminante do LDA.  Sob a mesma suposi√ß√£o, a regra de decis√£o Bayesiana leva ao mesmo resultado [^4.3].

### Conclus√£o

Neste cap√≠tulo, exploramos a transforma√ß√£o logit como uma ferramenta para modelar as probabilidades posteriores com fun√ß√µes lineares, com foco em como a fun√ß√£o log√≠stica garante que as probabilidades estejam no intervalo [0,1] e que somem 1, e como essa modelagem √© feita na regress√£o log√≠stica, e como ela se difere da regress√£o linear com matrizes de indicadores, que n√£o modela as probabilidades diretamente. Analisamos como o LDA, sob a suposi√ß√£o gaussiana, se conecta com a modelagem das probabilidades posteriores. Discutimos a import√¢ncia da sele√ß√£o de vari√°veis e da regulariza√ß√£o para obter estimativas mais robustas e est√°veis das probabilidades. Vimos tamb√©m como a busca por hiperplanos separadores se relaciona com a modelagem das probabilidades posteriores. Atrav√©s deste cap√≠tulo, buscamos oferecer uma vis√£o abrangente sobre a utiliza√ß√£o de modelos lineares para a classifica√ß√£o, e o papel fundamental da transforma√ß√£o logit para a constru√ß√£o de modelos com probabilidades calibradas e com boa capacidade de generaliza√ß√£o.

### Footnotes

[^4.1]: *In this chapter we revisit the classification problem and focus on linear methods for classification...There are several different ways in which linear decision boundaries can be found.* *(Trecho de Linear Methods for Classification)*

[^4.2]: *In Chapter 2 we fit linear regression models to the class indicator variables, and classify to the largest fit...Linear inequalities in this space are quadratic inequalities in the original space.* *(Trecho de Linear Methods for Classification)*

[^4.3]: *Decision theory for classification (Section 2.4) tells us that we need to know the class posteriors Pr(G|X) for optimal