## T√≠tulo Conciso: M√©todos Lineares para Classifica√ß√£o e Sele√ß√£o de Vari√°veis

```mermaid
graph LR
    subgraph "Linear Classification Methods"
        direction TB
        A["Input Data: \"x\" (Features)"]
        B["Indicator Regression"]
        C["Linear Discriminant Analysis (LDA)"]
        D["Logistic Regression"]
        E["Separating Hyperplanes"]
        A --> B
        A --> C
        A --> D
        A --> E
        style A fill:#f9f,stroke:#333,stroke-width:2px
        style B,C,D,E fill:#ccf,stroke:#333,stroke-width:1px
    end
    subgraph "Variable Selection & Regularization"
        direction TB
        F["Feature Set Reduction"]
        G["L1 Regularization (Lasso)"]
        H["L2 Regularization (Ridge)"]
        I["Elastic Net"]
        F --> G
        F --> H
        F --> I
        style F fill:#ffc,stroke:#333,stroke-width:2px
        style G,H,I fill:#ffc,stroke:#333,stroke-width:1px
    end
    B --> F
    C --> F
    D --> F
    E --> F
```

### Introdu√ß√£o

Este cap√≠tulo aborda o problema de classifica√ß√£o, focando em **m√©todos lineares** para essa tarefa. A classifica√ß√£o envolve a atribui√ß√£o de um valor discreto (classe) a uma entrada, com base em suas caracter√≠sticas [^4.1]. Podemos sempre dividir o espa√ßo de entrada em regi√µes, cada uma associada a uma classe, e as fronteiras entre essas regi√µes podem ser suaves ou irregulares, dependendo da fun√ß√£o de predi√ß√£o utilizada. Uma classe importante de m√©todos gera **fronteiras de decis√£o lineares**, e √© nelas que focaremos nossa aten√ß√£o [^4.1].

Existem diversas abordagens para encontrar tais fronteiras de decis√£o lineares. Uma das formas √© ajustar modelos de regress√£o linear para as **vari√°veis indicadoras de classe**, atribuindo a classe correspondente ao maior valor predito. Supondo *K* classes rotuladas de 1 a *K*, modelamos a vari√°vel indicadora *k* como $f_k(x) = \beta_{k0} + \beta_k^T x$. A fronteira de decis√£o entre as classes *k* e *l* √© definida pelos pontos onde $f_k(x) = f_l(x)$, que √© um conjunto afim ou hiperplano, dado por $\{x: (\beta_{k0} - \beta_{l0}) + (\beta_k - \beta_l)^T x = 0\}$ [^4.1].

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o com tr√™s classes e duas vari√°veis preditoras ($x_1$ e $x_2$). Ajustamos tr√™s modelos de regress√£o linear, um para cada classe. As fun√ß√µes resultantes s√£o:
>
> $f_1(x) = 1 + 2x_1 - x_2$
> $f_2(x) = -1 + x_1 + 2x_2$
> $f_3(x) = 0 - x_1 - x_2$
>
> Para classificar um novo ponto, digamos $x = (1, 1)$, calculamos:
>
> $f_1(1, 1) = 1 + 2(1) - 1 = 2$
> $f_2(1, 1) = -1 + 1 + 2(1) = 2$
> $f_3(1, 1) = 0 - 1 - 1 = -2$
>
> Como $f_1(1,1) = f_2(1,1)$ e s√£o os maiores valores, o ponto est√° na fronteira de decis√£o entre as classes 1 e 2, e pode ser atribu√≠do a qualquer uma das classes.
>
> Para classificar o ponto $x=(2, -1)$:
>
> $f_1(2, -1) = 1 + 2(2) - (-1) = 6$
> $f_2(2, -1) = -1 + 2 + 2(-1) = -1$
> $f_3(2, -1) = 0 - 2 - (-1) = -1$
>
> Neste caso, como $f_1(2,-1) = 6$ √© o maior valor, o ponto seria classificado como pertencente √† classe 1.
>
> A fronteira de decis√£o entre as classes 1 e 2 seria definida por $f_1(x) = f_2(x)$:
> $1 + 2x_1 - x_2 = -1 + x_1 + 2x_2$
> $2 + x_1 - 3x_2 = 0$
> $x_2 = \frac{2+x_1}{3}$
>
> Esta √© a equa√ß√£o de uma linha reta, demonstrando que a fronteira de decis√£o √© linear.

Outra abordagem consiste em modelar diretamente as **fun√ß√µes discriminantes** $\delta_k(x)$ para cada classe, classificando uma entrada *x* para a classe com o maior valor da fun√ß√£o discriminante [^4.1]. M√©todos que modelam as **probabilidades a posteriori** $Pr(G = k | X = x)$ tamb√©m podem levar a fronteiras de decis√£o lineares. De fato, basta que alguma transforma√ß√£o monot√¥nica de $\delta_k(x)$ ou $Pr(G = k | X = x)$ seja linear em *x* para que as fronteiras de decis√£o sejam lineares. Por exemplo, na classifica√ß√£o com duas classes, um modelo comum para as probabilidades a posteriori √© dado por:
$$Pr(G = 1|X = x) = \frac{exp(\beta_0 + \beta^T x)}{1 + exp(\beta_0 + \beta^T x)},$$
$$Pr(G = 2|X = x) = \frac{1}{1 + exp(\beta_0 + \beta^T x)}.$$
Neste caso, a **transforma√ß√£o logit**, $\log[p/(1-p)]$, resulta em:
$$\log \frac{Pr(G = 1|X = x)}{Pr(G = 2|X = x)} = \beta_0 + \beta^T x.$$
A fronteira de decis√£o corresponde ao conjunto de pontos para os quais o log-odds √© zero, que √© o hiperplano $\{x: \beta_0 + \beta^T x = 0\}$ [^4.1].

Exploraremos neste cap√≠tulo dois m√©todos populares que geram logits lineares: **Linear Discriminant Analysis (LDA)** e **Regress√£o Log√≠stica Linear**. Apesar de suas deriva√ß√µes diferentes, a diferen√ßa crucial reside na forma como a fun√ß√£o linear √© ajustada aos dados de treinamento. Al√©m disso, discutiremos m√©todos que modelam explicitamente as fronteiras entre as classes como lineares, usando o conceito de **hiperplanos separadores**[^4.1].

### Conceitos Fundamentais

**Conceito 1: O Problema de Classifica√ß√£o e M√©todos Lineares**

O problema de classifica√ß√£o busca atribuir uma observa√ß√£o *x* a uma entre um n√∫mero finito de classes *G*. Formalmente, temos um espa√ßo de entrada *X* e um conjunto de sa√≠da *G* com *K* classes,  $G = \{1, 2, \ldots, K\}$. O objetivo √© construir um preditor $G(x)$ que mapeie *x* para a classe correta. Os m√©todos lineares, neste contexto, utilizam fun√ß√µes lineares para definir fronteiras de decis√£o no espa√ßo de entrada [^4.1]. Essas fronteiras dividem o espa√ßo em regi√µes associadas a cada classe.

```mermaid
graph LR
    subgraph "Classification Problem"
        direction TB
        A["Input Space \"X\""]
        B["Output Space \"G\" = {1, 2, ..., K}"]
        C["Linear Classifier \"G(x)\""]
        A --> C
        B --> C
    end
    subgraph "Decision Boundary"
      D["Linear Decision Boundary"]
      C --> D
   end
   style A fill:#ccf,stroke:#333,stroke-width:1px
   style B fill:#ccf,stroke:#333,stroke-width:1px
   style C fill:#f9f,stroke:#333,stroke-width:2px
   style D fill:#ccf,stroke:#333,stroke-width:1px
```


A natureza linear dessas fronteiras implica que as decis√µes s√£o baseadas em combina√ß√µes lineares das caracter√≠sticas de entrada. Embora essa abordagem seja limitada em compara√ß√£o com modelos n√£o lineares, ela possui vantagens como simplicidade, interpretabilidade e efici√™ncia computacional. A escolha por m√©todos lineares geralmente envolve um *trade-off* entre **vi√©s** e **vari√¢ncia**. Modelos lineares podem ter um alto vi√©s se as verdadeiras fronteiras de decis√£o forem complexas, mas tendem a ter baixa vari√¢ncia.

**Lemma 1:** *Em problemas de classifica√ß√£o com duas classes, a fronteira de decis√£o gerada por um modelo linear pode ser vista como um hiperplano. A forma desse hiperplano depende dos par√¢metros do modelo, que s√£o ajustados utilizando um conjunto de dados de treinamento.*

A prova desse lemma decorre da formula√ß√£o matem√°tica de um modelo linear de classifica√ß√£o: seja $f(x) = \beta_0 + \beta^T x$ a fun√ß√£o discriminante, onde $x$ representa o vetor de atributos, e $\beta_0$ e $\beta$ s√£o os par√¢metros do modelo. A fronteira de decis√£o √© definida pelos pontos onde $f(x) = 0$, ou seja, $\beta_0 + \beta^T x = 0$. Essa equa√ß√£o descreve um hiperplano no espa√ßo de entrada. Portanto, a decis√£o de classe √© baseada na posi√ß√£o de *x* em rela√ß√£o a este hiperplano. A estrutura linear do hiperplano surge diretamente da forma funcional linear do modelo. A adapta√ß√£o do hiperplano se d√° atrav√©s do ajuste dos par√¢metros $\beta_0$ e $\beta$ com base no conjunto de dados de treino. $\blacksquare$

**Conceito 2: Linear Discriminant Analysis (LDA)**

A An√°lise Discriminante Linear (LDA) √© um m√©todo de classifica√ß√£o que assume que as classes seguem distribui√ß√µes Gaussianas com uma matriz de covari√¢ncia comum ($\Sigma$). Formalmente, a densidade condicional de *X* na classe *G* = *k* √© dada por:
$$f_k(x) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}}exp\left(-\frac{1}{2}(x-\mu_k)^T\Sigma^{-1}(x-\mu_k)\right),$$
onde $\mu_k$ √© o vetor de m√©dias da classe *k* e *p* √© a dimensionalidade de *x*.

```mermaid
graph LR
    subgraph "LDA Density Function"
        direction TB
        A["f_k(x) = Gaussian Density"]
        B["Mean Vector: \"Œº_k\""]
        C["Covariance Matrix: \"Œ£\""]
        D["Dimensionality: \"p\""]
        A --> B
        A --> C
        A --> D
    end
```


Ao comparar duas classes, *k* e *l*, √© suficiente examinar o log-ratio das probabilidades posteriores:
$$log \frac{Pr(G=k|X=x)}{Pr(G=l|X=x)} = log \frac{f_k(x)}{f_l(x)} + log \frac{\pi_k}{\pi_l} = log \frac{\pi_k}{\pi_l} - \frac{1}{2} (\mu_k - \mu_l)^T \Sigma^{-1} (\mu_k - \mu_l) + x^T \Sigma^{-1} (\mu_k - \mu_l).$$
Essa equa√ß√£o √© linear em *x* devido √† premissa da matriz de covari√¢ncia comum, resultando em fronteiras de decis√£o lineares [^4.3].

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o com duas classes e duas vari√°veis preditoras ($x_1$ e $x_2$). Suponha que as m√©dias das classes s√£o $\mu_1 = [1, 1]^T$ e $\mu_2 = [3, 3]^T$, e que a matriz de covari√¢ncia comum √© $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$. As probabilidades a priori s√£o $\pi_1 = 0.4$ e $\pi_2 = 0.6$.
>
> Calculamos $\Sigma^{-1} = \frac{1}{0.75} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$.
>
> A fun√ß√£o discriminante para a classe 1 √©:
> $\delta_1(x) = x^T \Sigma^{-1} \mu_1 - \frac{1}{2} \mu_1^T \Sigma^{-1} \mu_1 + log(\pi_1)$.
> $\delta_1(x) = x^T \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} + log(0.4)$.
> $\delta_1(x) =  x^T \begin{bmatrix} 0.66 \\ 0.66 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 0.66 \\ 0.66 \end{bmatrix} + log(0.4)$
> $\delta_1(x) = 0.66x_1 + 0.66x_2 - 0.66 + log(0.4)$
>
> Similarmente, para classe 2:
> $\delta_2(x) = x^T \Sigma^{-1} \mu_2 - \frac{1}{2} \mu_2^T \Sigma^{-1} \mu_2 + log(\pi_2)$.
> $\delta_2(x) =  x^T \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 3 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} + log(0.6)$
> $\delta_2(x) =  x^T \begin{bmatrix} 2 \\ 2 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 3 \end{bmatrix} \begin{bmatrix} 2 \\ 2 \end{bmatrix} + log(0.6)$
> $\delta_2(x) = 2x_1 + 2x_2 - 6 + log(0.6)$
>
> A fronteira de decis√£o √© definida por $\delta_1(x) = \delta_2(x)$:
> $0.66x_1 + 0.66x_2 - 0.66 + log(0.4) = 2x_1 + 2x_2 - 6 + log(0.6)$
>  $-1.34x_1 - 1.34x_2 + 5.34 - log(0.4) + log(0.6) = 0$
>  $-1.34x_1 - 1.34x_2 + 5.34 + 0.916 - 0.511 = 0$
>  $1.34x_1 + 1.34x_2 = 5.745$
> $x_1 + x_2 = 4.29$
>
> Esta √© a equa√ß√£o de uma linha reta, confirmando que a fronteira de decis√£o √© linear.

**Corol√°rio 1:** *A fun√ß√£o discriminante linear da LDA, expressa como $\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + log(\pi_k)$, pode ser interpretada como uma proje√ß√£o do ponto *x* para um subespa√ßo, onde as classes est√£o melhor separadas. A matriz de covari√¢ncia comum $\Sigma$ afeta essa proje√ß√£o, e a diferen√ßa nas m√©dias $\mu_k$ e $\mu_l$ define a dire√ß√£o de separa√ß√£o das classes.*

A prova desse corol√°rio pode ser inferida a partir da an√°lise da f√≥rmula do log-odds em LDA. A fun√ß√£o discriminante linear $\delta_k(x)$ tem a forma de uma combina√ß√£o linear das vari√°veis de entrada, onde os coeficientes s√£o definidos pelas m√©dias das classes ($\mu_k$) e pela matriz de covari√¢ncia comum ($\Sigma$). A matriz $\Sigma^{-1}$ √© uma transforma√ß√£o linear que esf√©rica os dados, removendo as correla√ß√µes e permitindo que a separa√ß√£o de classes ocorra de forma mais eficiente. A proje√ß√£o, ent√£o, ocorre no subespa√ßo definido pelos autovetores da matriz de covari√¢ncia $\Sigma$. Este corol√°rio estabelece a liga√ß√£o entre a fun√ß√£o discriminante linear e o conceito de proje√ß√£o em um espa√ßo que otimiza a separa√ß√£o entre classes. $\blacksquare$

**Conceito 3: Logistic Regression**

A Regress√£o Log√≠stica √© um m√©todo probabil√≠stico que modela diretamente as probabilidades posteriores das classes atrav√©s de fun√ß√µes lineares transformadas pela fun√ß√£o log√≠stica. Para o caso de duas classes, a probabilidade de uma observa√ß√£o *x* pertencer √† classe 1 √© dada por:
$$Pr(G=1|X=x) = \frac{exp(\beta_0 + \beta^T x)}{1+exp(\beta_0 + \beta^T x)},$$
onde $\beta_0$ e $\beta$ s√£o os par√¢metros do modelo [^4.4]. A transforma√ß√£o logit do odds-ratio √© linear em *x*:
$$\log \frac{Pr(G=1|X=x)}{Pr(G=2|X=x)} = \beta_0 + \beta^T x.$$
```mermaid
graph LR
    subgraph "Logistic Regression Probability"
      direction TB
        A["P(G=1|X=x) = \"exp(Œ≤‚ÇÄ + Œ≤·µÄx) / (1 + exp(Œ≤‚ÇÄ + Œ≤·µÄx))\""]
        B["Logit Transformation: log( P(G=1|X=x) / P(G=2|X=x) ) = \"Œ≤‚ÇÄ + Œ≤·µÄx\""]
         A --> B
    end
```

Os par√¢metros do modelo s√£o geralmente estimados por **m√°xima verossimilhan√ßa**, que busca encontrar os valores de $\beta_0$ e $\beta$ que maximizam a probabilidade dos dados observados, dada a forma funcional do modelo.

> ‚ö†Ô∏è **Nota Importante**: Na pr√°tica, a escolha entre LDA e Regress√£o Log√≠stica pode depender de diversos fatores, incluindo a validade das premissas de Gaussianidade e a necessidade de interpretabilidade do modelo.

> ‚ùó **Ponto de Aten√ß√£o**: Em situa√ß√µes com classes desbalanceadas, √© importante considerar o uso de t√©cnicas de balanceamento ou ajustes nas probabilidades de classes na Regress√£o Log√≠stica para evitar resultados enviesados.

> ‚úîÔ∏è **Destaque**:  Embora LDA e Regress√£o Log√≠stica apresentem deriva√ß√µes distintas, em cen√°rios com duas classes as estimativas de par√¢metros em LDA e em regress√£o log√≠stica podem estar relacionadas sob algumas condi√ß√µes.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Indicator Regression for Classification"
        direction TB
        A["Encode Classes: \"Y_k\" (Indicator Variables)"]
        B["Design Matrix: \"X\""]
        C["Estimate Coefficients: \"B\" = (X·µÄX)‚Åª¬πX·µÄY"]
        D["Prediction: f(x) = \"(1, x·µÄ)B\""]
        E["Classification: argmax_k f_k(x)"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

A regress√£o linear pode ser adaptada para problemas de classifica√ß√£o atrav√©s do uso de uma **matriz de indicadores** [^4.2]. Para um problema com *K* classes, cada classe √© representada por um indicador bin√°rio $Y_k$, onde $Y_k=1$ se a observa√ß√£o pertence √† classe *k* e $Y_k=0$ caso contr√°rio. Essas vari√°veis s√£o agrupadas em um vetor $Y = (Y_1, \ldots, Y_K)$, e as *N* inst√¢ncias de treinamento formam uma matriz de resposta $N \times K$, denotada por $\mathbf{Y}$.

Ajustamos um modelo de regress√£o linear para cada coluna da matriz $\mathbf{Y}$ simultaneamente, utilizando uma matriz de design $\mathbf{X}$ com as *p* vari√°veis de entrada mais uma coluna de 1's para o intercepto. O ajuste √© dado por:
$$ \hat{\mathbf{Y}} = \mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T \mathbf{Y}. $$
As estimativas dos coeficientes s√£o armazenadas em uma matriz $(p+1) \times K$, denotada por $\mathbf{B} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}$. Para classificar uma nova observa√ß√£o com entrada *x*, primeiro computamos o vetor de sa√≠das ajustadas $f(x) = (1, x^T)\mathbf{B}$. Em seguida, classificamos *x* para a classe correspondente ao maior valor predito:
$$\hat{G}(x) = argmax_k f_k(x)$$ [^4.2].

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o com 3 classes e 2 features. Temos 5 amostras de treinamento:
>
> | Amostra | Feature 1 ($x_1$) | Feature 2 ($x_2$) | Classe |
> |---|---|---|---|
> | 1 | 1 | 2 | 1 |
> | 2 | 2 | 1 | 2 |
> | 3 | 2 | 3 | 1 |
> | 4 | 3 | 2 | 3 |
> | 5 | 4 | 3 | 2 |
>
> Primeiro, criamos a matriz de design $\mathbf{X}$ e a matriz de indicadores $\mathbf{Y}$:
>
> $\mathbf{X} = \begin{bmatrix} 1 & 1 & 2 \\ 1 & 2 & 1 \\ 1 & 2 & 3 \\ 1 & 3 & 2 \\ 1 & 4 & 3 \end{bmatrix}$
>
> $\mathbf{Y} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1 \\ 0 & 1 & 0 \end{bmatrix}$
>
> Calculamos $\mathbf{X}^T\mathbf{X}$:
>
> $\mathbf{X}^T\mathbf{X} = \begin{bmatrix} 5 & 12 & 11 \\ 12 & 34 & 29 \\ 11 & 29 & 28 \end{bmatrix}$
>
> Calculamos $(\mathbf{X}^T\mathbf{X})^{-1}$:
>
> $(\mathbf{X}^T\mathbf{X})^{-1} = \begin{bmatrix} 4.5 & -1.75 & -1.25 \\ -1.75 & 0.75 & 0.5 \\ -1.25 & 0.5 & 0.75 \end{bmatrix}$
>
> Calculamos $\mathbf{X}^T\mathbf{Y}$:
>
> $\mathbf{X}^T\mathbf{Y} = \begin{bmatrix} 2 & 2 & 1 \\ 5 & 7 & 3 \\ 8 & 5 & 2 \end{bmatrix}$
>
> Calculamos $\mathbf{B} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}$:
>
> $\mathbf{B} = \begin{bmatrix} 4.5 & -1.75 & -1.25 \\ -1.75 & 0.75 & 0.5 \\ -1.25 & 0.5 & 0.75 \end{bmatrix} \begin{bmatrix} 2 & 2 & 1 \\ 5 & 7 & 3 \\ 8 & 5 & 2 \end{bmatrix} = \begin{bmatrix} 0.25 & -1.75 & 0.25 \\ 0.75 & 1.25 & 0.25 \\ -0.25 & 0.75 & 0.75 \end{bmatrix}$
>
>
> Para classificar um novo ponto $x = (2, 2)$, formamos o vetor $(1, 2, 2)$ e calculamos:
>
> $f(x) = (1, 2, 2)\mathbf{B} = (1, 2, 2) \begin{bmatrix} 0.25 & -1.75 & 0.25 \\ 0.75 & 1.25 & 0.25 \\ -0.25 & 0.75 & 0.75 \end{bmatrix} = [1.5, 1.75, 1.75]$
>
> Como os valores para as classes 2 e 3 s√£o os maiores e iguais (1.75), o ponto estaria na fronteira de decis√£o entre as classes 2 e 3.

Uma interpreta√ß√£o para esta abordagem √© que a regress√£o linear estima a expectativa condicional de cada vari√°vel indicadora, $E(Y_k|X=x) = Pr(G=k|X=x)$ [^4.2]. No entanto, a regress√£o linear n√£o garante que os valores preditos estejam no intervalo [0,1] ou que sua soma seja igual a 1. Apesar dessas limita√ß√µes, na pr√°tica essa abordagem pode apresentar resultados similares a outros m√©todos lineares de classifica√ß√£o. Essa limita√ß√£o √© uma consequ√™ncia da natureza r√≠gida da regress√£o linear, especialmente se fizermos predi√ß√µes fora do espa√ßo dos dados de treino.

**Lemma 2:** *Em certas condi√ß√µes, a regress√£o linear de uma matriz de indicadores pode levar √†s mesmas fronteiras de decis√£o de m√©todos como LDA. A fun√ß√£o discriminante resultante da regress√£o linear pode ser expressa como uma combina√ß√£o linear dos atributos, e essa combina√ß√£o √© similar √†quela obtida na LDA sob algumas premissas de distribui√ß√£o dos dados de entrada.*

A prova deste lemma se baseia na an√°lise da fun√ß√£o discriminante resultante do ajuste por m√≠nimos quadrados. Em cen√°rios com duas classes, onde as vari√°veis de resposta s√£o codificadas como -1 e +1, o vetor de coeficientes resultante da regress√£o linear √© proporcional √† dire√ß√£o definida na LDA. Essa proporcionalidade surge da estrutura da solu√ß√£o por m√≠nimos quadrados e das suposi√ß√µes subjacentes √† LDA, especialmente quando se considera uma matriz de covari√¢ncia comum entre classes. Consequentemente, a fronteira de decis√£o em ambos os m√©todos se torna um hiperplano. $\blacksquare$

**Corol√°rio 2:** *A equival√™ncia da regress√£o linear com m√©todos discriminantes lineares, sob certas condi√ß√µes, fornece uma justificativa adicional para a aplica√ß√£o da regress√£o como um m√©todo de classifica√ß√£o. No entanto, essa equival√™ncia pode n√£o se manter em situa√ß√µes com mais de duas classes ou quando as premissas de distribui√ß√£o dos dados n√£o s√£o satisfeitas.*

O corol√°rio segue do Lemma 2, e enfatiza a necessidade de cautela ao aplicar a regress√£o de indicadores em problemas de classifica√ß√£o. Embora a regress√£o seja intuitiva e simples, a equival√™ncia com m√©todos como LDA depende de certas premissas sobre os dados, e portanto sua aplica√ß√£o deve ser avaliada cuidadosamente. $\blacksquare$

Em alguns cen√°rios, a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1].

No entanto, h√° situa√ß√µes em que a regress√£o de indicadores √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Techniques"
       direction TB
       A["Cost Function: \"-log-likelihood\""]
       B["L1 Penalty (Lasso): \"Œª ‚àë|Œ≤_j| \""]
       C["L2 Penalty (Ridge): \"Œª ‚àëŒ≤_j¬≤ \""]
       D["Elastic Net Penalty: \"Œª‚ÇÅ ‚àë|Œ≤_j| + Œª‚ÇÇ ‚àëŒ≤_j¬≤ \""]
       A --> B
       A --> C
       A --> D
    end
```

Em problemas de classifica√ß√£o, o uso de muitas vari√°veis pode levar a modelos complexos, com alto risco de **sobreajuste**. M√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o s√£o cruciais para lidar com essa quest√£o [^4.5]. A regulariza√ß√£o adiciona um termo de penalidade √† fun√ß√£o de custo, controlando a magnitude dos coeficientes do modelo e promovendo a generaliza√ß√£o.

Em modelos de classifica√ß√£o, como na Regress√£o Log√≠stica, a fun√ß√£o de custo √© dada pela log-verossimilhan√ßa. Para adicionar regulariza√ß√£o, combinamos a log-verossimilhan√ßa com um termo de penalidade que depende dos coeficientes do modelo.

A **regulariza√ß√£o L1 (Lasso)** penaliza a soma dos valores absolutos dos coeficientes:
$$ \text{Custo} = - \sum_{i=1}^N \left[ y_i \log p(x_i) + (1-y_i) \log (1 - p(x_i)) \right] + \lambda \sum_{j=1}^p |\beta_j|. $$
Esta penalidade induz a **esparsidade**, ou seja, muitos coeficientes s√£o reduzidos a zero, selecionando um subconjunto de vari√°veis mais relevantes para o problema [^4.4.4].

> üí° **Exemplo Num√©rico:**
>
> Considere um modelo de regress√£o log√≠stica com duas vari√°veis, $x_1$ e $x_2$, e a fun√ß√£o de custo com penalidade L1:
>
> $ \text{Custo} = - \sum_{i=1}^N \left[ y_i \log p(x_i) + (1-y_i) \log (1 - p(x_i)) \right] + \lambda (|\beta_1| + |\beta_2|) $
>
> Suponha que, sem regulariza√ß√£o, os coeficientes estimados sejam $\beta_1 = 2$ e $\beta_2 = -3$. Se aplicarmos a regulariza√ß√£o L1 com $\lambda = 1$, a fun√ß√£o de custo ser√° penalizada por $|2| + |-3| = 5$. O algoritmo de otimiza√ß√£o ir√° procurar por coeficientes menores. Se aumentarmos $\lambda$ para 3, a penalidade ser√° ainda maior, e o modelo tender√° a zerar um ou mais coeficientes para minimizar o custo total. Por exemplo, poder√≠amos ter $\beta_1 = 0.5$ e $\beta_2 = 0$, com a penalidade reduzida para $|0.5| + |0| = 0.5$. O efeito da regulariza√ß√£o L1 √© for√ßar alguns coeficientes a serem exatamente zero, realizando sele√ß√£o de vari√°veis.

A **regulariza√ß√£o L2 (Ridge)** penaliza a soma dos quadrados dos coeficientes:
$$ \text{Custo} = - \sum_{i=1}^N \left[ y_i \log p(x_i) + (1-y_i) \log (1 - p(x_i)) \right] + \lambda \sum_{j=1}^p \beta_j^2. $$
Esta penalidade promove a redu√ß√£o da magnitude dos coeficientes, reduzindo a vari√¢ncia do modelo, mas sem induzir esparsidade.

> üí° **Exemplo Num√©rico:**
>
> Usando o mesmo cen√°rio anterior, mas com regulariza√ß√£o L2:
>
> $ \text{Custo} = - \sum_{i=1}^N \left[ y_i \log p(x_i) + (1-y_i) \log (1 - p(x_i)) \right] + \lambda (\beta_1^2 + \beta_2^2) $
>
> Com $\beta_1 = 2$ e $\beta_2 = -3$ sem regulariza√ß√£o, se usarmos $\lambda = 1$, a penalidade ser√° $2^2 + (-3)^2 = 13$. O modelo buscar√° reduzir a magnitude dos coeficientes, mas sem zer√°-los. Por exemplo, com $\lambda=1$, os coeficientes podem ser reduzidos para $\beta_1 = 1.5$ e $\beta_2 = -2.5$, resultando em uma penalidade de $1.5^2 + (-2.5)^2 = 8.5$. A regulariza√ß√£o L2 reduz a magnitude dos coeficientes, mas n√£o os zera, evitando a sele√ß√£o de vari√°veis.

A **Elastic Net**, combina as penalidades L1 e L2, aproveitando as vantagens de ambas as abordagens. A fun√ß√£o de custo √© dada por:
$$ \text{Custo} = - \sum_{i=1}^N \left[ y_i \log p(x_i) + (1-y_i) \log (1 - p(x_i)) \right] + \lambda_1 \sum_{j=1}^p |\beta_j| + \lambda_2 \sum_{j=1}^p \beta_j^2. $$
Os par√¢metros $\lambda$, $\lambda_1$ e $\lambda_2$ controlam a intensidade da regulariza√ß√£o. Em geral, esses par√¢metros s√£o otimizados por valida√ß√£o cruzada ou outros m√©todos de sele√ß√£o de modelos.

**Lemma 3:** *A penaliza√ß√£o L1 em modelos de classifica√ß√£o log√≠stica tende a gerar solu√ß√µes esparsas, onde a maioria dos coeficientes associados √†s vari√°veis de entrada s√£o exatamente zero. Isso ocorre devido √† natureza da penalidade L1 que, ao contr√°rio da L2, n√£o √© diferenci√°vel na origem, levando a uma solu√ß√£o que frequentemente se encontra em cantos do espa√ßo de par√¢metros.*

**Prova do Lemma 3:** Para provar que a penaliza√ß√£o L1 leva √† esparsidade, consideremos o problema de otimiza√ß√£o:
$$\min_{\beta} \left[ -\ell(\beta) + \lambda \|\beta\|_1 \right]$$
onde $\ell(\beta)$ representa o log-likelihood do modelo e $\|\beta\|_1 = \sum_{j=1}^p |\beta_j|$. A penaliza√ß√£o L1 √© n√£o-diferenci√°vel na origem, o que significa que os coeficientes podem ser levados exatamente a zero quando a penalidade domina. O ponto em que a penalidade L1 se torna determinante √© quando a derivada da fun√ß√£o de