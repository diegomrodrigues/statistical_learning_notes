## T√≠tulo Conciso: M√©todos Lineares para Classifica√ß√£o: Fronteiras Lineares e Otimiza√ß√£o

<imagem: Uma imagem composta mostrando uma s√©rie de gr√°ficos. O gr√°fico principal deve ilustrar um espa√ßo bidimensional com pontos de dados de duas ou mais classes separados por hiperplanos lineares. Um diagrama de fluxo de um algoritmo, como o Perceptron ou uma otimiza√ß√£o de margem, tamb√©m √© mostrado, com etapas claras de como os hiperplanos s√£o adaptados. Al√©m disso, inclua um painel menor que compara modelos lineares (LDA, Logistic Regression) e suas fronteiras de decis√£o. Finalmente, uma se√ß√£o que inclui mapas mentais com penalidades de regulariza√ß√£o (L1 e L2) e o efeito em modelos lineares, utilizando a linguagem Mermaid.>

### Introdu√ß√£o

Este cap√≠tulo explora m√©todos lineares para classifica√ß√£o, com √™nfase nas **fronteiras de decis√£o lineares**. Esses m√©todos, que utilizam **hiperplanos** para separar classes, s√£o fundamentais no aprendizado de m√°quina devido √† sua simplicidade, interpretabilidade e efici√™ncia computacional. Os m√©todos lineares oferecem uma abordagem direta para classifica√ß√£o, dividindo o espa√ßo de entrada em regi√µes associadas a diferentes classes por meio de combina√ß√µes lineares das vari√°veis de entrada [^4.1].

Em m√©todos lineares de classifica√ß√£o, a predi√ß√£o da classe a partir de um conjunto de atributos de entrada √© baseada em um modelo que define uma **fun√ß√£o discriminante**. Essa fun√ß√£o, quando avaliada em uma observa√ß√£o, fornece um valor que decide a classe a ser atribu√≠da. M√©todos lineares imp√µem que essa fun√ß√£o discriminante seja linear no espa√ßo de entrada ou em alguma transforma√ß√£o das vari√°veis de entrada [^4.1].

A busca por fronteiras de decis√£o lineares pode ser vista sob diferentes perspectivas. Uma delas √© ajustar modelos de regress√£o linear para vari√°veis indicadoras de classe e classificar as observa√ß√µes com base no maior valor predito. Uma segunda abordagem √© construir modelos que diretamente estimem as probabilidades a posteriori de cada classe atrav√©s de fun√ß√µes lineares transformadas, como no caso da Regress√£o Log√≠stica. Uma terceira perspectiva √© modelar as fronteiras de decis√£o como hiperplanos, definindo um problema de otimiza√ß√£o com o objetivo de separar as classes de forma √≥tima, como no caso do Perceptron e dos hiperplanos separadores √≥timos.

Ao longo deste cap√≠tulo, vamos detalhar os principais modelos lineares de classifica√ß√£o, suas formula√ß√µes matem√°ticas, algoritmos de treinamento e as situa√ß√µes em que eles s√£o mais adequados. Exploraremos tanto a An√°lise Discriminante Linear (LDA) e a Regress√£o Log√≠stica, discutindo sua rela√ß√£o com a regra de decis√£o bayesiana, como os modelos de hiperplanos separadores e o Perceptron, analisando suas caracter√≠sticas, vantagens e limita√ß√µes. Abordaremos tamb√©m como a regulariza√ß√£o e a sele√ß√£o de vari√°veis s√£o aplicadas nesses m√©todos para melhorar a generaliza√ß√£o e a interpretabilidade dos modelos.

### Conceitos Fundamentais

**Conceito 1: Classifica√ß√£o e Fun√ß√µes Discriminantes Lineares**

O objetivo fundamental da classifica√ß√£o √© mapear um espa√ßo de entrada *$X$* em um conjunto discreto de classes *$G$*, onde cada classe √© representada por um r√≥tulo. Uma fun√ß√£o discriminante $f(x)$ atribui um valor a cada observa√ß√£o $x$, indicando a qual classe ela pertence. Nos **m√©todos lineares**, essa fun√ß√£o tem a forma:
$$f(x) = \beta_0 + \beta^T x,$$
onde $\beta_0$ √© o intercepto, $\beta$ √© um vetor de pesos e $x$ √© o vetor de atributos da observa√ß√£o.

A fronteira de decis√£o entre duas classes √© o conjunto de pontos em que $f(x)$ assume um determinado valor (geralmente zero para decis√µes bin√°rias ou quando comparamos duas fun√ß√µes discriminantes). Essa fronteira define um **hiperplano** no espa√ßo de entrada, dividindo as observa√ß√µes em regi√µes associadas a cada classe.

**Lemma 1:** *A fronteira de decis√£o linear, resultado de um m√©todo de classifica√ß√£o linear, pode ser representada por um hiperplano, cujos par√¢metros s√£o determinados pelos pesos do modelo ($\beta$) e pelo intercepto ($\beta_0$).*

A prova deste Lemma √© direta: a fun√ß√£o discriminante linear $f(x) = \beta_0 + \beta^T x$ define a fronteira de decis√£o como o conjunto de pontos para os quais $f(x) = 0$. Essa equa√ß√£o descreve um hiperplano no espa√ßo de entrada, onde o vetor $\beta$ define o vetor normal ao hiperplano e $\beta_0$ define sua posi√ß√£o no espa√ßo. Qualquer ponto que esteja em um lado deste hiperplano √© classificado em uma classe e do outro lado, em outra. Portanto, a linearidade da fun√ß√£o discriminante garante que a fronteira de decis√£o seja um hiperplano. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos duas classes, representadas por c√≠rculos vermelhos e azuis, e duas vari√°veis de entrada, $x_1$ e $x_2$. A fun√ß√£o discriminante linear pode ser definida como:
> $$f(x) = -2 + 1.5x_1 + 0.5x_2$$
> Onde $\beta_0 = -2$, $\beta_1 = 1.5$ e $\beta_2 = 0.5$. Para classificar um ponto, digamos $x = (2, 3)$, calculamos:
> $$f(x) = -2 + 1.5(2) + 0.5(3) = -2 + 3 + 1.5 = 2.5$$
> Se $f(x) > 0$, classificamos como classe 1, caso contr√°rio, classe 0. Neste caso, o ponto seria classificado na classe 1. A fronteira de decis√£o √© definida por $f(x) = 0$, ou seja, $-2 + 1.5x_1 + 0.5x_2 = 0$, que √© a equa√ß√£o de uma reta (um hiperplano em 2D).
>
> Visualmente, podemos representar isso no espa√ßo 2D onde a linha $1.5x_1 + 0.5x_2 = 2$ separa os pontos.
>
> ```mermaid
>   graph LR
>       A["Input Space (x1, x2)"] --> B["Decision Boundary: 1.5x1 + 0.5x2 = 2"]
>       B --> C["Class 1: f(x) > 0"]
>       B --> D["Class 0: f(x) < 0"]
>       C --> E["Example: x=(2,3) classified as Class 1"]
> ```

**Conceito 2: Linear Discriminant Analysis (LDA) e a Premissa Gaussiana**

A An√°lise Discriminante Linear (LDA) √© um m√©todo de classifica√ß√£o linear que assume que as classes s√£o geradas por distribui√ß√µes Gaussianas com uma **matriz de covari√¢ncia comum**. Essa premissa simplifica a formula√ß√£o do problema de classifica√ß√£o, levando a fronteiras de decis√£o lineares [^4.3].

A probabilidade condicional de uma observa√ß√£o *$x$* pertencer a uma classe *$k$* √© modelada como uma distribui√ß√£o Gaussiana:
$$f_k(x) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}}exp\left(-\frac{1}{2}(x-\mu_k)^T\Sigma^{-1}(x-\mu_k)\right).$$
Ao comparar duas classes *$k$* e *$l$*, o log-odds das probabilidades a posteriori torna-se linear em *$x$*:
$$log \frac{Pr(G=k|X=x)}{Pr(G=l|X=x)} = log \frac{\pi_k}{\pi_l} - \frac{1}{2} (\mu_k - \mu_l)^T \Sigma^{-1} (\mu_k - \mu_l) + x^T \Sigma^{-1} (\mu_k - \mu_l),$$
onde $\mu_k$ s√£o os vetores de m√©dia, $\Sigma$ √© a matriz de covari√¢ncia comum e $\pi_k$ s√£o as probabilidades a priori das classes.

**Corol√°rio 1:** *A fun√ß√£o discriminante na LDA, expressa como $\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + log(\pi_k)$, √© uma fun√ß√£o linear de x. A premissa de matriz de covari√¢ncia comum garante que os termos quadr√°ticos se cancelem, resultando em uma fronteira de decis√£o linear.*

A prova deste corol√°rio segue diretamente da an√°lise do log-odds na LDA. A forma linear da fun√ß√£o discriminante $\delta_k(x)$ surge da premissa de igualdade de covari√¢ncias entre as classes. O termo $x^T \Sigma^{-1} (\mu_k - \mu_l)$ que √© linear em x garante que a fronteira de decis√£o entre as classes seja um hiperplano. Os outros termos dependem apenas dos par√¢metros das classes. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos duas classes com as seguintes m√©dias e matriz de covari√¢ncia comum:
>  - Classe 1: $\mu_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$
>  - Classe 2: $\mu_2 = \begin{bmatrix} 3 \\ 2 \end{bmatrix}$
>  - Matriz de covari√¢ncia comum: $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
>  - Probabilidades a priori: $\pi_1 = 0.4$, $\pi_2 = 0.6$
>
> Primeiro, calculamos a inversa da matriz de covari√¢ncia:
> $\Sigma^{-1} = \frac{1}{1 - 0.5^2} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \frac{4}{3} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix}$
>
> Agora, calculamos a fun√ß√£o discriminante para cada classe:
>
> $\delta_1(x) = x^T \Sigma^{-1} \mu_1 - \frac{1}{2} \mu_1^T \Sigma^{-1} \mu_1 + log(\pi_1)$
>
> $\delta_2(x) = x^T \Sigma^{-1} \mu_2 - \frac{1}{2} \mu_2^T \Sigma^{-1} \mu_2 + log(\pi_2)$
>
> $\delta_1(x) = x^T \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} + log(0.4)$
>
> $\delta_1(x) = x^T \begin{bmatrix} 2/3 \\ 2/3 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 2/3 \\ 2/3 \end{bmatrix} + log(0.4) = \frac{2}{3}x_1 + \frac{2}{3}x_2 - \frac{2}{3} + log(0.4)$
>
> $\delta_2(x) = x^T \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix} \begin{bmatrix} 3 \\ 2 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 2 \end{bmatrix} \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix} \begin{bmatrix} 3 \\ 2 \end{bmatrix} + log(0.6)$
>
> $\delta_2(x) = x^T \begin{bmatrix} 8/3 \\ 2/3 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 2 \end{bmatrix} \begin{bmatrix} 8/3 \\ -2/3 \end{bmatrix} + log(0.6) = \frac{8}{3}x_1 + \frac{2}{3}x_2 - \frac{10}{3} + log(0.6)$
>
> A fronteira de decis√£o √© dada por $\delta_1(x) = \delta_2(x)$, que ap√≥s simplifica√ß√£o, resulta em uma equa√ß√£o linear em x.

```mermaid
graph TD
    subgraph "LDA Discriminant Function"
        direction TB
        A["Discriminant Function: Œ¥k(x)"]
        B["Linear Term: xT Œ£‚àí1 Œºk"]
        C["Constant Term: -1/2 ŒºkT Œ£‚àí1 Œºk"]
        D["Prior Term: log(œÄk)"]
        A --> B
        A --> C
        A --> D
    end
    subgraph "LDA Assumptions"
      direction LR
    E["Gaussian Distribution"] --> F["Equal Covariance Matrices"]
    end
        F --> A
```

**Conceito 3: Regress√£o Log√≠stica e Probabilidades Posteriores**

A Regress√£o Log√≠stica modela diretamente as probabilidades a posteriori das classes usando a fun√ß√£o log√≠stica. No caso de duas classes, a probabilidade de uma observa√ß√£o *$x$* pertencer √† classe 1 √© dada por:
$$Pr(G=1|X=x) = \frac{exp(\beta_0 + \beta^T x)}{1+exp(\beta_0 + \beta^T x)}.$$
A transforma√ß√£o logit do odds-ratio √© linear em *$x$*:
$$\log \frac{Pr(G=1|X=x)}{Pr(G=2|X=x)} = \beta_0 + \beta^T x.$$

Diferente da LDA, a Regress√£o Log√≠stica n√£o faz suposi√ß√µes sobre a distribui√ß√£o das vari√°veis de entrada, estimando os par√¢metros $\beta_0$ e $\beta$ por **m√°xima verossimilhan√ßa**, que busca encontrar os valores dos par√¢metros que maximizam a probabilidade dos dados observados.

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um modelo de regress√£o log√≠stica com uma √∫nica vari√°vel de entrada $x$ e os seguintes par√¢metros:
> $\beta_0 = -3$ e $\beta_1 = 2$. A probabilidade de uma observa√ß√£o pertencer √† classe 1 √© dada por:
>
> $Pr(G=1|X=x) = \frac{exp(-3 + 2x)}{1+exp(-3 + 2x)}$
>
> Para um valor de $x = 1$, temos:
>
> $Pr(G=1|X=1) = \frac{exp(-3 + 2(1))}{1+exp(-3 + 2(1))} = \frac{exp(-1)}{1+exp(-1)} \approx \frac{0.368}{1+0.368} \approx 0.27$
>
> Para um valor de $x = 2$, temos:
>
> $Pr(G=1|X=2) = \frac{exp(-3 + 2(2))}{1+exp(-3 + 2(2))} = \frac{exp(1)}{1+exp(1)} \approx \frac{2.718}{1+2.718} \approx 0.73$
>
> Podemos ver que √† medida que o valor de $x$ aumenta, a probabilidade de pertencer √† classe 1 tamb√©m aumenta, o que √© intuitivo. A fronteira de decis√£o √© definida quando $Pr(G=1|X=x) = 0.5$, o que ocorre quando $\beta_0 + \beta_1x = 0$, ou seja, $x = -\frac{\beta_0}{\beta_1} = -\frac{-3}{2} = 1.5$ neste caso.

> ‚ö†Ô∏è **Nota Importante**: A escolha entre LDA e Regress√£o Log√≠stica depende das premissas sobre os dados e do objetivo do problema. A LDA assume distribui√ß√µes gaussianas com covari√¢ncias iguais, enquanto a Regress√£o Log√≠stica modela diretamente as probabilidades a posteriori, sem suposi√ß√µes sobre a distribui√ß√£o das vari√°veis de entrada. **Refer√™ncia ao t√≥pico [^4.4.1]**.

> ‚ùó **Ponto de Aten√ß√£o**: Em situa√ß√µes com classes desbalanceadas, t√©cnicas de balanceamento devem ser aplicadas para evitar vi√©s nas estimativas da Regress√£o Log√≠stica. **Conforme indicado em [^4.4.2]**.

> ‚úîÔ∏è **Destaque**: LDA e Regress√£o Log√≠stica, apesar de deriva√ß√µes distintas, levam a modelos com fun√ß√µes discriminantes lineares. **Baseado no t√≥pico [^4.5]**.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

<imagem: Um diagrama utilizando a linguagem Mermaid, mostrando o processo de regress√£o linear para classifica√ß√£o utilizando uma matriz de indicadores. Inicie com os dados de entrada (X) e um vetor de r√≥tulos (Y). Em seguida, mostre a codifica√ß√£o das classes em uma matriz de indicadores (Y_indicador). Represente o c√°lculo da matriz de coeficientes B usando m√≠nimos quadrados (Y_hat = XB). Mostre como uma nova entrada (x_novo) √© classificada pela fun√ß√£o discriminante (f(x) = x_novo^T B) e, finalmente, escolha a classe com o maior valor predito. As setas devem indicar o fluxo de informa√ß√µes e as diferentes etapas do processo. Use cores para diferenciar os dados, os resultados intermedi√°rios e os resultados finais. >

A regress√£o linear pode ser adaptada para classifica√ß√£o utilizando vari√°veis indicadoras. Em um problema com *$K$* classes, cada classe √© representada por uma vari√°vel bin√°ria $Y_k$, tal que $Y_k = 1$ se a observa√ß√£o pertence √† classe *$k$*, e $Y_k = 0$ caso contr√°rio [^4.2]. Essas vari√°veis s√£o agrupadas em um vetor $Y = (Y_1, \ldots, Y_K)$, e as *$N$* inst√¢ncias de treinamento formam uma matriz $N \times K$, denotada por $\mathbf{Y}$.

Um modelo de regress√£o linear √© ajustado para cada coluna de $\mathbf{Y}$ simultaneamente, obtendo-se a matriz de coeficientes $\mathbf{B}$, onde cada coluna corresponde a uma classe [^4.2]:
$$\mathbf{B} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}$$
Para classificar uma nova observa√ß√£o *$x$*, calculamos as sa√≠das ajustadas para cada classe:
$$f(x) = (1, x^T)\mathbf{B}.$$
A classe predita √© aquela correspondente ao maior valor predito:
$$\hat{G}(x) = argmax_k f_k(x).$$

Embora essa abordagem seja simples e direta, ela tem algumas limita√ß√µes. A principal √© que as sa√≠das da regress√£o linear n√£o s√£o necessariamente probabilidades (podem ser negativas ou maiores que 1) e a soma delas n√£o √© necessariamente igual a 1, ao contr√°rio do que se espera em problemas de classifica√ß√£o. Apesar disso, em muitos casos, esse m√©todo pode levar a resultados compar√°veis com outros m√©todos de classifica√ß√£o.

**Lemma 2:** *Sob a condi√ß√£o de um espa√ßo de sa√≠da com apenas duas classes, o resultado da regress√£o linear da matriz de indicadores e o resultado do m√©todo discriminante linear (LDA) s√£o proporcionais, indicando que ambos levam a fronteiras de decis√£o lineares similares.*

A prova deste lemma pode ser demonstrada atrav√©s da an√°lise da solu√ß√£o de m√≠nimos quadrados na regress√£o linear e da fun√ß√£o discriminante da LDA. Em problemas com duas classes, podemos codificar a classe como +1 ou -1, e podemos verificar que o vetor de coeficientes resultante da regress√£o linear √© proporcional √† dire√ß√£o definida pelo vetor de diferen√ßas de m√©dias ponderadas pela matriz de covari√¢ncia, o mesmo vetor utilizado na fun√ß√£o discriminante da LDA. A equival√™ncia √© estabelecida sob certas condi√ß√µes, especificamente quando o intercepto do LDA tamb√©m √© ajustado para minimizar o erro de classifica√ß√£o no conjunto de treinamento. $\blacksquare$

**Corol√°rio 2:** *A equival√™ncia entre a regress√£o linear e a LDA em problemas com duas classes, demonstra que ambos os m√©todos, embora baseados em princ√≠pios diferentes, podem produzir fronteiras de decis√£o lineares semelhantes. No entanto, esta equival√™ncia n√£o se mant√©m em problemas com mais de duas classes.*

Este corol√°rio ressalta a robustez de ambos os m√©todos em casos particulares. Apesar de diferentes nas suas deriva√ß√µes, regress√£o linear e LDA podem chegar a decis√µes similares, em especial, quando se trata de duas classes, e as premissas da LDA s√£o satisfeitas. √â importante notar, no entanto, que a equival√™ncia se desfaz quando o n√∫mero de classes aumenta, onde as diferen√ßas entre os m√©todos se tornam mais evidentes. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Consideremos um conjunto de dados com 5 amostras e duas classes. As amostras s√£o representadas por duas vari√°veis $x_1$ e $x_2$.
>
> Dados:
>
> | Amostra | $x_1$ | $x_2$ | Classe |
> |--------|-------|-------|--------|
> | 1      | 1     | 2     | 1      |
> | 2      | 1.5   | 1.8   | 1      |
> | 3      | 2     | 2.5   | 1      |
> | 4      | 4     | 1     | 2      |
> | 5      | 4.5   | 2     | 2      |
>
> Primeiro, codificamos as classes como vari√°veis indicadoras. A matriz $\mathbf{Y}$ ser√°:
>
> $\mathbf{Y} = \begin{bmatrix} 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 0 & 1 \\ 0 & 1 \end{bmatrix}$
>
> E a matriz $\mathbf{X}$ (com um intercepto) √©:
>
> $\mathbf{X} = \begin{bmatrix} 1 & 1 & 2 \\ 1 & 1.5 & 1.8 \\ 1 & 2 & 2.5 \\ 1 & 4 & 1 \\ 1 & 4.5 & 2 \end{bmatrix}$
>
> Calculamos $\mathbf{B}$ usando a f√≥rmula de m√≠nimos quadrados:
>
> $\mathbf{B} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}$
>
>  $\mathbf{X}^T \mathbf{X} = \begin{bmatrix} 5 & 13 & 9.3 \\ 13 & 43.5 & 27.6 \\ 9.3 & 27.6 & 19.69 \end{bmatrix}$
>
>  $(\mathbf{X}^T \mathbf{X})^{-1} \approx \begin{bmatrix} 3.69 & -1.36 & -1.86 \\ -1.36 & 0.63 & 0.42 \\ -1.86 & 0.42 & 0.95 \end{bmatrix}$
>
>  $\mathbf{X}^T \mathbf{Y} = \begin{bmatrix} 3 & 2 \\ 6.5 & 6.5 \\ 6.3 & 4.3 \end{bmatrix}$
>
>  $\mathbf{B} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y} \approx  \begin{bmatrix} 3.69 & -1.36 & -1.86 \\ -1.36 & 0.63 & 0.42 \\ -1.86 & 0.42 & 0.95 \end{bmatrix} \begin{bmatrix} 3 & 2 \\ 6.5 & 6.5 \\ 6.3 & 4.3 \end{bmatrix} \approx \begin{bmatrix} 1.12 & -0.12 \\ -0.59 & 0.59 \\ -0.16 & 0.16 \end{bmatrix}$
>
> Para classificar uma nova amostra, por exemplo, $x_{new} = (3, 2)$, calculamos:
>
> $f(x_{new}) = (1, 3, 2) \mathbf{B} = \begin{bmatrix} 1 & 3 & 2 \end{bmatrix} \begin{bmatrix} 1.12 & -0.12 \\ -0.59 & 0.59 \\ -0.16 & 0.16 \end{bmatrix} = \begin{bmatrix} -1.23 & 1.23 \end{bmatrix}$
>
> Como o segundo valor √© maior, classificamos $x_{new}$ como classe 2.

Apesar das limita√ß√µes da regress√£o linear para classifica√ß√£o, ela √© muitas vezes suficiente, especialmente quando o objetivo √© obter uma fronteira de decis√£o linear simples e os dados n√£o violam as premissas de forma muito significativa. Em alguns casos, uma abordagem usando regress√£o linear pode ser mais simples e computacionalmente eficiente do que outros m√©todos mais complexos.

```mermaid
graph TB
    subgraph "Linear Regression for Classification"
        direction TB
        A["Input Data: X, Labels: Y"] --> B["Encode Labels as Indicator Matrix: Y_indicator"]
        B --> C["Calculate Coefficient Matrix: B = (XTX)-1XTY"]
        C --> D["New Input: x_new"]
        D --> E["Discriminant Function: f(x) = x_newT B"]
        E --> F["Classify: argmax_k f_k(x)"]
    end
```

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

<imagem: Mapa mental utilizando Mermaid que conecta m√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o. O n√≥ central √© "Sele√ß√£o de Vari√°veis e Regulariza√ß√£o", com ramos para "Penaliza√ß√£o L1 (Lasso)", "Penaliza√ß√£o L2 (Ridge)", "Elastic Net", e "Sele√ß√£o por Subconjuntos". Para cada m√©todo, mostre suas propriedades, como "Induz esparsidade" (L1), "Reduz a vari√¢ncia" (L2), "Combina L1 e L2" (Elastic Net), e "Avalia subconjuntos de vari√°veis" (Sele√ß√£o por Subconjuntos). As setas devem mostrar como cada m√©todo impacta a fun√ß√£o de custo e os par√¢metros do modelo. Inclua f√≥rmulas para os termos de penaliza√ß√£o e uma descri√ß√£o dos benef√≠cios e limita√ß√µes de cada m√©todo. Os n√≥s tamb√©m devem incluir onde esses m√©todos se encaixam nos modelos lineares de classifica√ß√£o (Regress√£o Log√≠stica).>

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas fundamentais para lidar com a complexidade e evitar o sobreajuste em modelos de classifica√ß√£o, especialmente em contextos com um grande n√∫mero de atributos [^4.5]. A **sele√ß√£o de vari√°veis** visa identificar e reter apenas os atributos mais relevantes para o problema, reduzindo a dimensionalidade do espa√ßo de entrada e melhorando a interpretabilidade do modelo. A **regulariza√ß√£o**, por outro lado, adiciona uma penalidade √† fun√ß√£o de custo do modelo, controlando a magnitude dos par√¢metros e evitando que o modelo se ajuste excessivamente ao ru√≠do presente nos dados de treinamento [^4.4.4].

Em modelos lineares como a Regress√£o Log√≠stica, a fun√ß√£o de custo geralmente √© a log-verossimilhan√ßa, que mede o qu√£o bem o modelo se ajusta aos dados. Para adicionar regulariza√ß√£o, combinamos essa fun√ß√£o com um termo que penaliza a complexidade do modelo, baseado nos seus coeficientes:
$$ \text{Custo} = - \ell(\beta) + \lambda \text{Penalidade}(\beta),$$
onde $\ell(\beta)$ representa a log-verossimilhan√ßa e $\text{Penalidade}(\beta)$ √© uma fun√ß√£o que depende dos coeficientes $\beta$.

A **penaliza√ß√£o L1 (Lasso)** adiciona um termo proporcional √† soma dos valores absolutos dos coeficientes:
$$ \text{Penalidade}_{L1}(\beta) = \sum_{j=1}^p |\beta_j|,$$
onde $\lambda$ controla a intensidade da penalidade. Essa penalidade tende a gerar solu√ß√µes esparsas, onde muitos coeficientes s√£o exatamente zero, selecionando um subconjunto de vari√°veis mais relevantes [^4.4.4].

A **penaliza√ß√£o L2 (Ridge)** adiciona um termo proporcional √† soma dos quadrados dos coeficientes:
$$\text{Penalidade}_{L2}(\beta) = \sum_{j=1}^p \beta_j^2.$$
Essa penalidade reduz a magnitude dos coeficientes, diminuindo a vari√¢ncia do modelo, mas n√£o leva a solu√ß√µes esparsas.

O **Elastic Net** combina as penalidades L1 e L2:
$$\text{Penalidade}_{ElasticNet}(\beta) = \lambda_1 \sum_{j=1}^p |\beta_j| + \lambda_2 \sum_{j=1}^p \beta_j^2.$$
Essa abordagem visa aproveitar as vantagens de ambas as penalidades, promovendo tanto a esparsidade quanto a redu√ß√£o da vari√¢ncia.

**Lemma 3:** *A penaliza√ß√£o L1 em modelos de classifica√ß√£o log√≠stica leva √† solu√ß√µes esparsas, ou seja, muitos coeficientes s√£o iguais a zero. Essa caracter√≠stica √© consequ√™ncia da n√£o diferenciabilidade da norma L1 na origem, o que leva a solu√ß√µes em que muitos coeficientes s√£o exatamente zero.*

A prova deste Lemma pode ser feita utilizando as condi√ß√µes de otimalidade de Karush-Kuhn-Tucker (KKT), que indicam que a solu√ß√£o de um problema de otimiza√ß√£o com restri√ß√µes deve satisfazer certas condi√ß√µes. No caso da penaliza√ß√£o L1, a condi√ß√£o de KKT para um coeficiente $\beta_j$ √© que o gradiente do custo em rela√ß√£o a $\beta_j$ deve ser igual a zero, ou seja:
$$
-\frac{\partial \ell(\beta)}{\partial \beta_j} + \lambda \cdot \text{sign}(\beta_j) = 0
$$
No entanto, o termo de penaliza√ß√£o √© subgradiente, n√£o diferenci√°vel na origem, o que implica que para o coeficiente $\beta_j$ ser igual a zero, a derivada da fun√ß√£o de custo (sem regulariza√ß√£o) deve ser menor do que $\lambda$. Caso contr√°rio, $\beta_j$ ser√° diferente de zero. A penaliza√ß√£o L1 empurra alguns coeficientes para zero. $\blacksquare$

**Corol√°rio 3:** *A esparsidade promovida pela regulariza√ß√£o L1 leva √† sele√ß√£o autom√°tica de vari√°veis, tornando o modelo mais interpret√°vel ao identificar os atributos mais relevantes para a classifica√ß√£o. Al√©m disso, a redu√ß√£o do n√∫mero de vari√°veis contribui para a redu√ß√£o da complexidade do modelo e, consequentemente, para a redu√ß√£o do risco de sobreajuste.*

O corol√°rio segue da demonstra√ß√£o do Lemma 3. Como a penaliza√ß√£o L1 leva √† solu√ß√µes esparsas, o resultado √© que as vari√°veis com coeficientes diferentes de zero s√£o as que t√™m maior impacto no processo de classifica√ß√£o. Isso facilita a interpreta√ß√£o dos resultados, pois podemos identificar quais s√£o os atributos mais relevantes para o problema. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um problema de classifica√ß√£o com 3 vari√°veis de entrada ($x_1$, $x_2$, $x_3$) e duas classes, usando regress√£o log√≠stica. Suponha que, sem regulariza√ß√£o, os coeficientes do modelo sejam:
> $\beta_0 = -1$, $\beta_1 = 0.8$, $\beta_2 = -0.5$, $\beta_3 = 1.2$.
>
> Agora, vamos aplicar a regulariza√ß√£o L1 (Lasso) com diferentes valores de $\lambda$:
>
> - **$\lambda = 0.5$**: Os coeficientes podem se tornar:
>  $\beta_0 = -0.9$, $\beta_1 = 0.4$, $\beta_2 = 0$, $\beta_3 = 0.9$. Observe que $\beta_2$ foi zerado, indicando que a vari√°vel $x_2$ √© menos relevante.
>
> - **$\lambda = 1.0$**: Os coeficientes podem se tornar:
>  $\beta_0 = -0.8$, $\beta_1 = 0$, $\beta_2 = 0$, $\beta_3 = 0.5$. Agora, tanto $\beta_1$ quanto $\beta_2$ s√£o zerados, indicando que apenas $x_3$ √© relevante.
>
> Com a regulariza√ß√£o L2 (Ridge), os coeficientes seriam reduzidos, mas nenhum seria exatamente zero. Por exemplo, com $\lambda = 0.5$:
>
>  $\beta_0 = -0.95$, $\beta_1 = 0.5$, $\beta_2 = -0.3$, $\beta_3 = 0.8$.
>
> O Elastic Net, por sua vez, combina os dois efeitos, resultando em uma solu√ß√£o intermedi√°ria.
>
> Podemos comparar os resultados em uma tabela:
>
> | M√©todo      | $\beta_0$ | $\beta_1$ | $\beta_2$ | $\beta_3$ |
> |-------------|----------|----------|----------|----------|
> | Sem Reg.    | -1       | 0.8      | -0.5     | 1.2      |
> | Lasso ($\lambda=0.5$) | -0.9    | 0.4      | 0        | 0.9      |
> | Lasso ($\lambda=1.0$) | -0.8    | 0        | 0        | 0.5      |
> | Ridge ($\lambda=0.5$)   | -0.95    | 0.5      | -0.3     | 0.8      |
>
> Observe como o Lasso promove a esparsidade, zerando coeficientes, enquanto o Ridge reduz sua magnitude.

```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["Cost Function: -‚Ñì(Œ≤) + Œª Penalty(Œ≤)"]
        B["L1 Penalty (Lasso): Œª‚àë|Œ≤j|"]
        C["L2 Penalty (Ridge): Œª‚àëŒ≤j¬≤"]
        D["Elastic Net: Œª1‚àë|Œ≤j| + Œª2‚àëŒ≤j¬≤"]
        A --> B
        A --> C
        A --> D
        B --> E["Induces Sparsity"]
        C --> F["Reduces Variance"]
        D --> G["Combines Sparsity and Variance Reduction"]
    end
```

> ‚ö†Ô∏è **Ponto Crucial**: A escolha da regulariza√ß√£o L1, L2, ou Elastic Net depende das caracter√≠sticas dos dados e do objetivo do modelo. Em geral, L1 √© √∫til para sele√ß√£o de vari√°veis, L2 para redu√ß√£o da vari√¢ncia, e Elastic Net para combinar os benef√≠cios de ambas as penalidades. **Conforme discutido em [^4.5]**.

### Separating Hyperplanes e Perceptrons

<imagem: Diagrama visual utilizando a linguagem Mermaid para apresentar a constru√ß√£o de hiperplanos separadores. Inicie com um conjunto de dados de duas classes, separados por um hiperplano. Mostre a margem, que √© a dist√¢ncia entre o hiperplano e os pontos mais pr√≥ximos das duas classes. Represente os vetores de suporte, que s√£o os pontos que definem a margem. Inclua a formula