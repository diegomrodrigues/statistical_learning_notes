## T√≠tulo Conciso: M√©todos Lineares para Classifica√ß√£o: Regress√£o, Discriminantes e Probabilidades

```mermaid
graph LR
    subgraph "Linear Classification Methods"
        direction TB
        A["Linear Methods for Classification"]
        B["Regression on Indicator Variables"]
        C["Discriminant Function Models (LDA, QDA)"]
        D["Probabilistic Models (Logistic Regression)"]
        A --> B
        A --> C
        A --> D
    end
    subgraph "Method Details"
        direction LR
        B --> E["Linear Regression Model Formula"]
        C --> F["Discriminant Function Calculation"]
        D --> G["Logistic Regression Probability Model"]
    end
    subgraph "Model Relationships"
       direction TB
        E --> H["Indicator Variable Encoding"]
        F --> I["Assumptions on Data Distribution"]
        G --> J["Probability Estimation"]
    end
    subgraph "Regularization"
       direction TB
         H --> K["L1/L2/Elastic Net Regularization"]
         I --> K
         J --> K
    end
```

### Introdu√ß√£o

Este cap√≠tulo foca em m√©todos lineares para classifica√ß√£o, explorando tr√™s abordagens principais: **Regress√£o Linear em Vari√°veis Indicadoras**, **Modelos de Fun√ß√µes Discriminantes** e **Modelos Probabil√≠sticos**. Cada uma dessas abordagens oferece uma maneira distinta de construir fronteiras de decis√£o lineares, utilizando combina√ß√µes lineares dos atributos de entrada para atribuir amostras a diferentes classes [^4.1].

A **Regress√£o Linear em Vari√°veis Indicadoras** utiliza a regress√£o linear para modelar vari√°veis bin√°rias que indicam a quais classes cada observa√ß√£o pertence, atribuindo a classe com o maior valor predito. Essa abordagem √© simples e intuitiva, mas tem limita√ß√µes em termos de garantir que os valores preditos se comportem como probabilidades. J√° os **Modelos de Fun√ß√µes Discriminantes**, como a An√°lise Discriminante Linear (LDA) e An√°lise Discriminante Quadr√°tica (QDA), definem fun√ß√µes que determinam a classe de uma observa√ß√£o com base em sua pontua√ß√£o discriminante. Esses modelos fazem premissas sobre a distribui√ß√£o dos dados, como a normalidade. Os **Modelos Probabil√≠sticos**, como a Regress√£o Log√≠stica, modelam diretamente as probabilidades a posteriori das classes, usando fun√ß√µes lineares transformadas, como a fun√ß√£o log√≠stica, e n√£o imp√µem premissas sobre a distribui√ß√£o das vari√°veis de entrada.

Ao longo deste cap√≠tulo, vamos detalhar cada um desses m√©todos, suas formula√ß√µes matem√°ticas, algoritmos de ajuste e os cen√°rios em que s√£o mais apropriados. Vamos discutir como as premissas de cada abordagem influenciam as decis√µes de classifica√ß√£o e como a regulariza√ß√£o pode ser utilizada para melhorar a generaliza√ß√£o dos modelos. Vamos tamb√©m explorar as conex√µes entre essas tr√™s abordagens, mostrando como diferentes formas de modelagem linear podem levar a resultados similares ou complementares.

### Conceitos Fundamentais

**Conceito 1: O Problema de Classifica√ß√£o e Abordagens Lineares**

O problema de classifica√ß√£o busca atribuir uma observa√ß√£o $x$ a uma de *K* classes distintas, ou seja, um r√≥tulo discreto $G$ a partir de um espa√ßo de atributos $X$. Os m√©todos lineares abordam esse problema atrav√©s da constru√ß√£o de fun√ß√µes discriminantes lineares, que dividem o espa√ßo de entrada em regi√µes associadas a cada classe, ou modelando diretamente as probabilidades das classes utilizando fun√ß√µes lineares.

As abordagens lineares se caracterizam pela simplicidade, facilidade de interpreta√ß√£o e efici√™ncia computacional. No entanto, essa abordagem pode n√£o ser adequada para problemas com fronteiras de decis√£o complexas. A escolha entre diferentes m√©todos lineares depende das premissas sobre a distribui√ß√£o dos dados, do objetivo do problema (classifica√ß√£o ou estima√ß√£o de probabilidades) e da necessidade de interpretabilidade.

**Lemma 1:** *Modelos lineares de classifica√ß√£o produzem fronteiras de decis√£o lineares, e.g., hiperplanos no espa√ßo de atributos, independentemente de serem modelos de regress√£o com vari√°veis indicadoras, modelos de fun√ß√µes discriminantes ou modelos probabil√≠sticos baseados em transforma√ß√£o linear.*

A prova deste lemma pode ser feita atrav√©s da an√°lise das diferentes formula√ß√µes. Em todos os casos, a decis√£o de classe √© baseada em uma fun√ß√£o linear, que separa as classes. Na regress√£o com vari√°veis indicadoras, a classe √© definida pelo maior valor de uma combina√ß√£o linear das vari√°veis. Nos modelos discriminantes, a fronteira de decis√£o √© dada por onde duas fun√ß√µes discriminantes lineares s√£o iguais. Nos modelos probabil√≠sticos, a fronteira de decis√£o tamb√©m √© obtida por uma fun√ß√£o linear, como o log-odds, que √© linear em termos dos atributos. Portanto, todos os modelos lineares levam a hiperplanos. $\blacksquare$

**Conceito 2: Modelos de Fun√ß√µes Discriminantes: LDA e QDA**

Os modelos de fun√ß√µes discriminantes, como a An√°lise Discriminante Linear (LDA) e a An√°lise Discriminante Quadr√°tica (QDA), s√£o m√©todos de classifica√ß√£o que buscam construir fun√ß√µes discriminantes $\delta_k(x)$ para cada classe *k*, de modo que a observa√ß√£o $x$ seja atribu√≠da √† classe que maximiza $\delta_k(x)$. A LDA assume que as classes t√™m distribui√ß√µes Gaussianas com uma mesma matriz de covari√¢ncia ($\Sigma$), enquanto que o QDA n√£o faz essa premissa.

```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction TB
        A["Œ¥_k(x) for LDA"]
        B["x^T Œ£‚Åª¬π Œº_k"]
        C["- 1/2 Œº_k^T Œ£‚Åª¬π Œº_k"]
        D["log(œÄ_k)"]
        A --> B
        A --> C
        A --> D
    end
    subgraph "QDA Discriminant Function"
        direction TB
        E["Œ¥_k(x) for QDA"]
        F["-1/2 (x-Œº_k)^T Œ£_k‚Åª¬π (x-Œº_k)"]
        G["log(œÄ_k)"]
        E --> F
        E --> G
    end
    subgraph "Key Differences"
      direction LR
        H["Common Covariance Matrix (LDA)"]
        I["Individual Covariance Matrices (QDA)"]
        H --> J["Linear Decision Boundaries"]
        I --> K["Quadratic Decision Boundaries"]
    end
```

No LDA, a fun√ß√£o discriminante √© dada por:
$$\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log(\pi_k),$$
que √© uma fun√ß√£o linear de $x$, onde $\mu_k$ √© a m√©dia da classe *k*, $\pi_k$ √© a probabilidade a priori da classe *k* e $\Sigma$ √© a matriz de covari√¢ncia comum. Em contraste, no QDA, as fun√ß√µes discriminantes s√£o quadr√°ticas em *x* devido √† aus√™ncia da premissa de covari√¢ncia comum:
$$\delta_k(x) = -\frac{1}{2}(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k) + \log(\pi_k).$$

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um exemplo simplificado com duas classes e duas caracter√≠sticas. Suponha que temos as seguintes m√©dias e matriz de covari√¢ncia para LDA:
>
> - Classe 1: $\mu_1 = [1, 1]^T$
> - Classe 2: $\mu_2 = [3, 3]^T$
> - Matriz de covari√¢ncia comum: $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
> - Probabilidades a priori: $\pi_1 = 0.6$, $\pi_2 = 0.4$
>
> Para calcular a fun√ß√£o discriminante para um ponto $x = [2, 2]^T$, primeiro precisamos calcular $\Sigma^{-1}$:
>
> $\Sigma^{-1} = \frac{1}{(1*1 - 0.5*0.5)} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \frac{1}{0.75} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$
>
> Agora, calculemos $\delta_1(x)$ e $\delta_2(x)$:
>
> $\delta_1(x) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} + \log(0.6)$
>
> $\delta_1(x) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 0.66 \\ 0.66 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 0.66 \\ 0.66 \end{bmatrix} + \log(0.6)$
>
> $\delta_1(x) = 2.64 - 0.66 + (-0.51) = 1.47$
>
> $\delta_2(x) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 3 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} + \log(0.4)$
>
> $\delta_2(x) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 1.98 \\ 1.98 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 3 \end{bmatrix} \begin{bmatrix} 1.98 \\ 1.98 \end{bmatrix} + \log(0.4)$
>
> $\delta_2(x) = 7.92 - 5.94 + (-0.92) = 1.06$
>
> Como $\delta_1(x) > \delta_2(x)$, o ponto $x$ seria classificado como pertencente √† classe 1.

**Corol√°rio 1:** *Enquanto a LDA gera fun√ß√µes discriminantes lineares devido √† premissa de covari√¢ncia comum, o QDA gera fun√ß√µes discriminantes quadr√°ticas devido √† estima√ß√£o de diferentes matrizes de covari√¢ncia para cada classe, resultando em fronteiras de decis√£o lineares e n√£o lineares, respectivamente.*

A prova deste corol√°rio pode ser feita atrav√©s da compara√ß√£o das fun√ß√µes discriminantes dos dois m√©todos. No LDA, a premissa de igualdade das matrizes de covari√¢ncia entre as classes leva ao cancelamento dos termos quadr√°ticos na equa√ß√£o, resultando em um fun√ß√£o discriminante linear. No QDA, ao assumir matrizes de covari√¢ncia distintas, os termos quadr√°ticos n√£o se cancelam, levando a fun√ß√µes quadr√°ticas. $\blacksquare$

**Conceito 3: Modelos Probabil√≠sticos: Regress√£o Log√≠stica**

A Regress√£o Log√≠stica √© um modelo probabil√≠stico que modela diretamente a probabilidade posterior de uma observa√ß√£o *x* pertencer a uma classe *k* por meio de uma fun√ß√£o linear transformada pela fun√ß√£o log√≠stica (sigmoide). Para o caso bin√°rio (duas classes), a probabilidade de *x* pertencer √† classe 1 √© dada por:
$$P(G=1|X=x) = \frac{\exp(\beta_0 + \beta^T x)}{1+\exp(\beta_0 + \beta^T x)},$$
onde $\beta_0$ e $\beta$ s√£o os par√¢metros do modelo.

```mermaid
graph LR
  subgraph "Logistic Regression"
    direction TB
    A["P(G=1|X=x)"]
    B["exp(Œ≤_0 + Œ≤^T x)"]
    C["1 + exp(Œ≤_0 + Œ≤^T x)"]
    A --> B
    A --> C
  end
    subgraph "Model Parameters"
        direction LR
        D["Œ≤_0"] --> E["Intercept Term"]
        F["Œ≤"] --> G["Coefficient Vector"]
    end
     subgraph "Model Behavior"
       direction TB
        H["Transforms linear function into a probability"]
        I["Does not assume input distribution"]
         B --> H
         C --> H
         H --> I
     end
```

A Regress√£o Log√≠stica n√£o faz suposi√ß√µes sobre a distribui√ß√£o das vari√°veis de entrada, diferentemente do LDA. Os par√¢metros s√£o geralmente estimados por m√°xima verossimilhan√ßa, ou seja, os par√¢metros que maximizam a probabilidade dos dados observados dada a forma funcional do modelo.

> ‚ö†Ô∏è **Nota Importante**:  A Regress√£o Log√≠stica modela diretamente as probabilidades posteriores, enquanto o LDA deriva as probabilidades a partir de suposi√ß√µes sobre as distribui√ß√µes das vari√°veis de entrada. A escolha entre eles depende do objetivo da modelagem e das caracter√≠sticas dos dados. **Refer√™ncia ao t√≥pico [^4.5]**.

> ‚ùó **Ponto de Aten√ß√£o**: Em situa√ß√µes com classes desbalanceadas, √© crucial usar t√©cnicas de balanceamento para evitar vieses nas estimativas da Regress√£o Log√≠stica. **Conforme indicado em [^4.4.2]**.

> ‚úîÔ∏è **Destaque**: LDA, QDA e Regress√£o Log√≠stica, embora distintos em suas formula√ß√µes, representam abordagens importantes para classifica√ß√£o linear, cada um com suas particularidades e aplicabilidades. **Baseado nos t√≥picos [^4.3] e [^4.4]**.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
    direction TB
    A["Input Data (X) and Classes (G)"]
    B["Encode Classes into Indicator Variables (Yk)"]
    C["Create Indicator Matrix (Y)"]
    D["Fit Linear Model (Y_hat = XB) using Least Squares"]
    E["Discriminant Function (f(x) = x^T B)"]
    F["Assign new observation to class with highest f(x)"]
     A --> B
     B --> C
     C --> D
     D --> E
     E --> F
    end
    subgraph "Mathematical Details"
        direction LR
        G["Y = XB + E"] --> H["B = (X^T X)^-1 X^T Y"]
         G --> I["Least Squares Solution"]
         H --> I
        J["f(x) = (1, x^T)B"]
        I --> J
    end
```

A regress√£o linear pode ser usada para classifica√ß√£o atrav√©s da codifica√ß√£o das classes em vari√°veis indicadoras. Se o problema de classifica√ß√£o tem *K* classes, para cada amostra *i* √© definido um vetor $y_i$, de tamanho *K*, onde $y_{ik} = 1$ se a amostra *i* pertence √† classe *k*, e $y_{ik} = 0$ caso contr√°rio. A matriz de indicadores $\mathbf{Y}$ √© uma matriz $N \times K$, onde $N$ √© o n√∫mero de amostras. Em seguida, ajustamos um modelo de regress√£o linear para cada coluna de $\mathbf{Y}$ atrav√©s da equa√ß√£o:
$$\mathbf{Y} = \mathbf{X}\mathbf{B} + \mathbf{E},$$
onde $\mathbf{X}$ √© a matriz de design com as vari√°veis de entrada, $\mathbf{B}$ √© a matriz de coeficientes e $\mathbf{E}$ √© a matriz de erros. A solu√ß√£o de m√≠nimos quadrados para $\mathbf{B}$ √©:
$$\mathbf{B} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}.$$

Para classificar uma nova observa√ß√£o $x$, computamos os valores preditos para cada classe atrav√©s da equa√ß√£o:
$$f(x) = (1, x^T)\mathbf{B}.$$
A classe predita √© aquela correspondente ao maior valor predito:
$$\hat{G}(x) = \arg\max_k f_k(x).$$

Embora esse m√©todo seja simples e intuitivo, ele tem algumas limita√ß√µes. A regress√£o linear n√£o garante que os valores preditos estejam no intervalo [0,1] ou que a soma dos valores preditos para uma mesma observa√ß√£o seja igual a 1. Al√©m disso, esse m√©todo √© muito sens√≠vel a outliers e pode n√£o produzir bons resultados em casos em que as classes n√£o s√£o bem separadas.

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o bin√°ria com 3 amostras e 2 atributos. Os dados s√£o:
>
> - Amostra 1: $x_1 = [1, 2]^T$, Classe 1
> - Amostra 2: $x_2 = [2, 1]^T$, Classe 1
> - Amostra 3: $x_3 = [3, 4]^T$, Classe 2
>
> Primeiro, criamos a matriz de design $\mathbf{X}$ (adicionando uma coluna de 1s para o intercepto) e a matriz de indicadores $\mathbf{Y}$:
>
> $\mathbf{X} = \begin{bmatrix} 1 & 1 & 2 \\ 1 & 2 & 1 \\ 1 & 3 & 4 \end{bmatrix}$
>
> $\mathbf{Y} = \begin{bmatrix} 1 & 0 \\ 1 & 0 \\ 0 & 1 \end{bmatrix}$
>
> Agora, calculamos $\mathbf{B} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}$.
>
> $\mathbf{X}^T\mathbf{X} = \begin{bmatrix} 3 & 6 & 7 \\ 6 & 14 & 16 \\ 7 & 16 & 21 \end{bmatrix}$
>
> $(\mathbf{X}^T\mathbf{X})^{-1} = \begin{bmatrix} 5.33 & -2.67 & 0.67 \\ -2.67 & 1.67 & -0.33 \\ 0.67 & -0.33 & 0.07 \end{bmatrix}$
>
> $\mathbf{X}^T\mathbf{Y} = \begin{bmatrix} 2 & 1 \\ 3 & 2 \\ 7 & 4 \end{bmatrix}$
>
> $\mathbf{B} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y} = \begin{bmatrix} 5.33 & -2.67 & 0.67 \\ -2.67 & 1.67 & -0.33 \\ 0.67 & -0.33 & 0.07 \end{bmatrix} \begin{bmatrix} 2 & 1 \\ 3 & 2 \\ 7 & 4 \end{bmatrix} = \begin{bmatrix} 1.67 & 0.33 \\ -0.67 & 0.33 \\ 0.07 & -0.07 \end{bmatrix}$
>
> Para classificar um novo ponto $x_{new} = [2, 3]^T$, adicionamos o intercepto e calculamos $f(x)$:
>
> $f(x_{new}) = \begin{bmatrix} 1 & 2 & 3 \end{bmatrix} \begin{bmatrix} 1.67 & 0.33 \\ -0.67 & 0.33 \\ 0.07 & -0.07 \end{bmatrix} = \begin{bmatrix} 0.43 & 0.43 \end{bmatrix}$
>
> Como $f_1(x_{new}) > f_2(x_{new})$, a nova observa√ß√£o seria classificada como Classe 1.

**Lemma 2:** *A fronteira de decis√£o obtida pela regress√£o linear de vari√°veis indicadoras, em problemas de classifica√ß√£o bin√°ria com codifica√ß√£o -1 e 1, √© proporcional √† obtida pela An√°lise Discriminante Linear (LDA) com a mesma codifica√ß√£o, indicando que ambos os modelos geram separa√ß√µes lineares equivalentes em alguns casos.*

A prova deste Lemma reside na compara√ß√£o das solu√ß√µes obtidas pelos dois m√©todos. Na regress√£o linear com codifica√ß√£o -1 e 1, a solu√ß√£o de m√≠nimos quadrados para o vetor de coeficientes √© proporcional ao vetor de diferen√ßa das m√©dias das classes ponderado pela inversa da matriz de covari√¢ncia, que √© o mesmo vetor definido para a fun√ß√£o discriminante na LDA. Essa proporcionalidade indica que os dois m√©todos produzem a mesma fronteira de decis√£o linear. $\blacksquare$

**Corol√°rio 2:** *A equival√™ncia entre a regress√£o linear em vari√°veis indicadoras e o LDA em problemas de classifica√ß√£o bin√°ria, sob certas premissas, demonstra que ambos os m√©todos exploram conceitos similares para definir fronteiras de decis√£o lineares, apesar de serem derivados de formula√ß√µes distintas.*

O corol√°rio segue diretamente do Lemma 2, e demonstra que os dois modelos, embora baseados em princ√≠pios diferentes, conseguem chegar a decis√µes similares, em especial para o cen√°rio bin√°rio com uma codifica√ß√£o espec√≠fica. $\blacksquare$

Em alguns cen√°rios, como os de dados bem separados, a regress√£o linear pode ser suficiente e at√© mesmo vantajosa quando o objetivo principal √© encontrar uma fronteira de decis√£o linear, sem necessidade de uma interpreta√ß√£o probabil√≠stica.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Variable Selection & Regularization"
        direction TB
        A["Variable Selection and Regularization"]
        B["L1 Penalty (Lasso)"]
        C["L2 Penalty (Ridge)"]
        D["Elastic Net"]
        E["Subset Selection"]
        A --> B
        A --> C
        A --> D
        A --> E
    end
      subgraph "Mathematical Formulation"
        direction LR
        F["Cost Function = -log-likelihood + Œª * Penalty"]
        G["L1 Penalty: sum(|Œ≤_j|)"]
        H["L2 Penalty: sum(Œ≤_j¬≤)"]
        I["Elastic Net: Œª1*sum(|Œ≤_j|) + Œª2*sum(Œ≤_j¬≤)"]
        F --> G
        F --> H
        F --> I

     end
      subgraph "Model Effects"
       direction TB
         J["L1 -> Sparsity"]
         K["L2 -> Variance Reduction"]
          G --> J
          H --> K
        I --> L["Combines L1 & L2 effects"]
     end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas cruciais para lidar com a complexidade e evitar o sobreajuste em modelos de classifica√ß√£o linear, especialmente quando o n√∫mero de atributos √© grande [^4.5]. A **sele√ß√£o de vari√°veis** visa escolher um subconjunto dos atributos que s√£o mais relevantes para a classifica√ß√£o, reduzindo a dimensionalidade do espa√ßo de entrada e melhorando a interpretabilidade do modelo. A **regulariza√ß√£o** adiciona uma penalidade √† fun√ß√£o de custo, controlando a magnitude dos par√¢metros do modelo e reduzindo o risco de sobreajuste.

A fun√ß√£o de custo geral para modelos lineares de classifica√ß√£o com regulariza√ß√£o √© da forma:
$$\text{Custo} = -\ell(\beta) + \lambda \cdot \text{Penalidade}(\beta),$$
onde $\ell(\beta)$ √© a log-verossimilhan√ßa, $\beta$ √© o vetor de par√¢metros e $\text{Penalidade}(\beta)$ √© o termo de penaliza√ß√£o, e $\lambda$ √© um hiperpar√¢metro que controla a intensidade da regulariza√ß√£o.

A **penaliza√ß√£o L1 (Lasso)** usa a norma L1 dos coeficientes:
$$\text{Penalidade}_{L1}(\beta) = \sum_{j=1}^p |\beta_j|.$$
Essa penalidade tem o efeito de induzir a esparsidade, levando a modelos onde muitos coeficientes s√£o iguais a zero, selecionando automaticamente um subconjunto de vari√°veis mais relevantes.

A **penaliza√ß√£o L2 (Ridge)** usa a norma L2 dos coeficientes:
$$\text{Penalidade}_{L2}(\beta) = \sum_{j=1}^p \beta_j^2.$$
Essa penalidade reduz a magnitude dos coeficientes, diminuindo a vari√¢ncia do modelo, mas geralmente n√£o leva a solu√ß√µes esparsas.

O **Elastic Net** combina as penalidades L1 e L2:
$$\text{Penalidade}_{ElasticNet}(\beta) = \lambda_1 \sum_{j=1}^p |\beta_j| + \lambda_2 \sum_{j=1}^p \beta_j^2.$$
Essa abordagem visa combinar os benef√≠cios de ambas as penalidades, induzindo a esparsidade e reduzindo a vari√¢ncia.

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um problema de regress√£o log√≠stica com 3 atributos ($x_1, x_2, x_3$) e os seguintes coeficientes obtidos por m√°xima verossimilhan√ßa sem regulariza√ß√£o: $\beta = [0.8, -1.2, 0.5]$. Vamos calcular as penalidades para diferentes m√©todos com $\lambda = 0.1$.
>
> **Lasso (L1):**
>
> $\text{Penalidade}_{L1}(\beta) = |0.8| + |-1.2| + |0.5| = 2.5$
>
> $\text{Custo}_{L1} = -\ell(\beta) + 0.1 * 2.5 = -\ell(\beta) + 0.25$
>
> **Ridge (L2):**
>
> $\text{Penalidade}_{L2}(\beta) = 0.8^2 + (-1.2)^2 + 0.5^2 = 0.64 + 1.44 + 0.25 = 2.33$
>
> $\text{Custo}_{L2} = -\ell(\beta) + 0.1 * 2.33 = -\ell(\beta) + 0.233$
>
> **Elastic Net (com $\lambda_1 = 0.05$ e $\lambda_2 = 0.05$):**
>
> $\text{Penalidade}_{ElasticNet}(\beta) = 0.05 * 2.5 + 0.05 * 2.33 = 0.125 + 0.1165 = 0.2415$
>
> $\text{Custo}_{ElasticNet} = -\ell(\beta) + 0.2415$
>
> A regulariza√ß√£o L1 penaliza mais fortemente os coeficientes, induzindo esparsidade. Ridge penaliza menos, encolhendo os coeficientes. Elastic Net combina os dois efeitos. Em termos de custo, a penaliza√ß√£o √© adicionada ao custo original, afetando o processo de otimiza√ß√£o.
>
> Suponha que, ap√≥s aplicar a regulariza√ß√£o, os coeficientes se tornem:
>
> - Lasso: $\beta_{L1} = [0.5, -0.8, 0]$
> - Ridge: $\beta_{L2} = [0.7, -1.1, 0.4]$
> - Elastic Net: $\beta_{EN} = [0.6, -0.9, 0.2]$
>
> O Lasso zerou o coeficiente de $x_3$, indicando que este atributo pode n√£o ser relevante para o modelo. Ridge e Elastic Net encolheram os coeficientes, mas n√£o os zeraram.

**Lemma 3:** *A penaliza√ß√£o L1, aplicada a modelos lineares de classifica√ß√£o, produz uma solu√ß√£o com um n√∫mero menor de coeficientes diferentes de zero em compara√ß√£o com a penaliza√ß√£o L2 ou a aus√™ncia de regulariza√ß√£o, facilitando a sele√ß√£o de vari√°veis.*

A prova deste Lemma se baseia nas propriedades da norma L1. A norma L1 n√£o √© diferenci√°vel na origem, o que leva a um ‚Äúempurr√£o‚Äù dos coeficientes para zero durante o processo de otimiza√ß√£o, ao contr√°rio da norma L2, que √© diferenci√°vel em toda a sua extens√£o. O efeito √© que a penaliza√ß√£o L1 tende a favorecer solu√ß√µes esparsas, enquanto que a L2 tende a ‚Äúencolher‚Äù todos os coeficientes uniformemente. $\blacksquare$

**Corol√°rio 3:** *Modelos lineares de classifica√ß√£o, com a aplica√ß√£o da regulariza√ß√£o L1, oferecem uma forma eficaz de sele√ß√£o de vari√°veis, selecionando automaticamente os atributos mais importantes para a classifica√ß√£o e reduzindo a complexidade do modelo.*

Este corol√°rio segue diretamente do Lemma 3, indicando que a penaliza√ß√£o L1 n√£o apenas reduz o risco de sobreajuste, mas tamb√©m aumenta a interpretabilidade do modelo, ao focar apenas nos atributos mais relevantes. $\blacksquare$

> ‚ö†Ô∏è **Ponto Crucial**: A escolha do tipo de regulariza√ß√£o (L1, L2 ou Elastic Net) depende do objetivo do modelo e das caracter√≠sticas dos dados. L1 √© apropriada para sele√ß√£o de vari√°veis, enquanto que L2 √© mais apropriada para problemas que necessitam de redu√ß√£o da vari√¢ncia. **Conforme discutido em [^4.5]**.

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Optimal Separating Hyperplane"
    direction TB
        A["Data Points from Two Classes"]
        B["Separating Hyperplane"]
        C["Margin between classes"]
        D["Support Vectors"]
        A --> B
        B --> C
        C --> D
    end
     subgraph "Optimization Problem"
        direction LR
            E["Minimize 1/2 ||Œ≤||¬≤"]
            F["Subject to y_i (Œ≤^T x_i + Œ≤_0) >= 1"]
            E --> F
        end
    subgraph "Perceptron Algorithm"
     direction TB
         G["Iterative Parameter Update"]
            H["Initial Hyperplane"]
            I["Update Œ≤ based on misclassified samples"]
            J["Œ≤_new = Œ≤_old + Œ∑ y_i x_i"]
            K["Converges to a separating hyperplane if data is linearly separable"]
            G --> H
            G --> I
            I --> J
            J --> K
    end

```

A abordagem de **hiperplanos separadores** visa encontrar uma fronteira linear que n√£o apenas separa as classes, mas tamb√©m maximiza a margem entre elas, onde a margem √© definida como a menor dist√¢ncia entre o hiperplano e as amostras mais pr√≥ximas de cada classe, chamadas de **vetores de suporte** [^4.5.2]. Essa abordagem √© fundamental em m√©todos como as **Support Vector Machines (SVM)**.

O problema de otimiza√ß√£o para encontrar o hiperplano separador √≥timo pode ser expresso como:
$$
\begin{aligned}
    \max_{\beta,\beta_0} \quad & M \\
    \text{s.t.} \quad & y_i (\beta^T x_i + \beta_0) \geq M, \quad \forall i = 1, \ldots, N,
\end{aligned}
$$
onde $M$ √© a largura da margem, $\beta$ √© o vetor normal ao hiperplano, $\beta_0$ √© o intercepto e $y_i$ √© o r√≥tulo da classe da observa√ß√£o $x_i$. Ao fixar a margem em 1, podemos transformar o problema em:
$$
\begin{aligned}
  \min_{\beta,\beta_0} \quad & \frac{1}{2} ||\beta||^2 \\
  \text{s.t.} \quad & y_i (\beta^T x_i + \beta_0) \geq 1, \quad \forall i = 1, \ldots, N,
\end{aligned}
$$
A solu√ß√£o deste problema √© dada por uma combina√ß√£o linear dos vetores de suporte.

O **Perceptron de Rosenblatt**, √© um algoritmo iterativo que busca um hiperplano separador, mas ao contr√°rio da abordagem da margem m√°xima, o Perceptron busca um hiperplano que apenas separa as classes, n√£o necessariamente com a maior margem [^4.5.1]. O algoritmo come√ßa com um hiperplano aleat√≥rio, e em cada itera√ß√£o, ele atualiza os par√¢metros ($\beta$) com base nas amostras que s√£o mal classificadas. A atualiza√ß√£o √© feita da seguinte forma:
$$\beta^{new} = \beta^{old} + \eta y_i x_i,$$
onde $\eta$ √© a taxa de aprendizado, $y_i$ √© o r√≥tulo da classe e $x_i$ s√£o os atributos da observa√ß√£o mal classificada.

> üí° **Exemplo Num√©rico:**
>
> Vamos ilustrar o algoritmo do Perceptron com um exemplo simplificado de duas classes e duas features.
>
> Dados:
> - Classe 1 (y=1): $x_1 = [1, 2]^T$, $x_2 = [2, 1]^T$
> - Classe 2 (y=-1): $x_3 = [3, 4]^T$, $x_4 = [4, 3]^T$
>
> Inicializa√ß√£o: $\beta = [0.1, 0.1]^T$, $\beta_0 = 0.1$, taxa de aprendizado $\eta = 0.1$.
>
> **Itera√ß√£o 1:**
>
> -  Amostra $x_1$: $y_1(\beta^T x_1 + \beta_0) = 1 * (0.1 * 1 + 0.1 * 2 + 0.1) = 0.4 > 0$. Classificada corretamente.
> -  Amostra $x_2$: $y_2(\beta^T x_2 + \beta_0) = 1 * (0.1 * 2 + 0.1 * 1 + 0.1) = 0.4 > 0$. Classificada corretamente.
> -  Amostra $x_3$: $y_3(\beta^T x_3 + \beta_0) = -1 * (0.1 * 3 + 0.1 * 4 + 0.1) = -0.8 < 0$. Classificada corretamente.
> -  Amostra $x_4$: $y_4(\beta^T x_4 + \beta_0) = -1 * (0.1 * 4 + 0.1 * 3 + 0.1) = -0.8 < 0$. Classificada corretamente.
>
> Como todas as amostras foram classificadas corretamente, n√£o h√° atualiza√ß√£o nesta itera√ß√£o.
>
> Vamos supor que na itera√ß√£o seguinte, os par√¢metros sejam: $\beta = [0.2, -0.1]^T$ e $\beta_0 = 0.2$
>
> **Itera√ß√£o 2:**
>
> -  Amostra $x_1$: $y_1(\beta^T x_1 + \beta_0) = 1 * (0.2 * 1 - 0.1 * 2 + 0.2) = 0.2 > 0$. Classificada corretamente