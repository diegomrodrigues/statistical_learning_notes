## T√≠tulo Conciso: Classifica√ß√£o Linear, Sele√ß√£o de Vari√°veis e Regulariza√ß√£o

```mermaid
graph LR
    subgraph "Classification Framework"
    direction TB
        A["Input Feature Space: x ‚àà ‚Ñù·µñ"]
        B["Discrete Class Labels: G = {1, 2, ..., K}"]
        C["Linear Models (LDA, Logistic Regression)"]
        D["Regression as Conditional Expectation: E(Y|X=x)"]
        E["Variable Selection & Regularization"]
        A --> C
        C --> D
        D --> E
        E --> B
    end
```

### Introdu√ß√£o

Este cap√≠tulo explora a fundo a aplica√ß√£o de modelos lineares para classifica√ß√£o, enfatizando uma perspectiva estat√≠stica que interpreta a **regress√£o linear** como uma estimativa da **expectativa condicional**. M√©todos lineares, tais como **Linear Discriminant Analysis (LDA)** e **Logistic Regression**, ser√£o analisados no contexto da regress√£o, com foco em como a regress√£o linear se encaixa na estrutura de classifica√ß√£o, particularmente atrav√©s da regress√£o em matrizes de indicadores [^4.2]. Al√©m disso, abordaremos t√©cnicas de **sele√ß√£o de vari√°veis e regulariza√ß√£o**, que desempenham um papel essencial na constru√ß√£o de modelos mais robustos e interpret√°veis [^4.4.4], [^4.5]. A discuss√£o sobre a rela√ß√£o entre **hiperplanos separadores** e m√©todos de regress√£o tamb√©m ser√° um ponto central [^4.5.2]. A inten√ß√£o deste cap√≠tulo √© fornecer uma vis√£o abrangente e aprofundada de como a regress√£o linear, como uma ferramenta de modelagem estat√≠stica, pode ser utilizada e interpretada no contexto de classifica√ß√£o.

### Conceitos Fundamentais

**Conceito 1: Classifica√ß√£o e a Estimativa da Expectativa Condicional**

O problema de classifica√ß√£o consiste em atribuir um r√≥tulo de classe $G$ a uma entrada $x \in \mathbb{R}^p$, onde $G$ pertence a um conjunto discreto de classes $G = \{1, 2, \ldots, K\}$ [^4.1]. Em uma perspectiva estat√≠stica, a regress√£o linear pode ser vista como uma forma de estimar a expectativa condicional da vari√°vel resposta, $E(Y|X=x)$. No contexto da classifica√ß√£o, esta perspectiva implica que a regress√£o busca modelar a probabilidade de uma observa√ß√£o pertencer a uma determinada classe, que √© uma forma de expectativa condicional [^4.2]. A fun√ß√£o linear $f(x) = \beta_0 + \beta^T x$ serve como uma aproxima√ß√£o para esta expectativa, e a regra de decis√£o √© baseada na classe que apresentar a maior expectativa condicional.

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o bin√°ria onde queremos prever se um cliente ir√° comprar um produto (classe 1) ou n√£o (classe 0) com base em seu hist√≥rico de compras (feature $x$). Suponha que ap√≥s aplicar regress√£o linear em uma matriz de indicadores (onde a classe 1 √© representada por 1 e a classe 0 por 0), obtivemos a fun√ß√£o: $f(x) = 0.2 + 0.8x$. Se um novo cliente tem um hist√≥rico de compras $x=0.7$, ent√£o $f(0.7) = 0.2 + 0.8 * 0.7 = 0.76$. Como este valor √© mais pr√≥ximo de 1 do que de 0, o modelo preveria que o cliente tem uma probabilidade maior de comprar o produto. Este valor, 0.76, pode ser interpretado como uma estimativa da expectativa condicional de compra dado o hist√≥rico do cliente.

**Lemma 1:** *Em um problema de classifica√ß√£o, a fun√ß√£o de regress√£o linear aplicada a uma matriz de indicadores pode ser interpretada como uma estimativa da expectativa condicional da vari√°vel indicadora de classe.* Essa interpreta√ß√£o √© fundamental para entender como a regress√£o linear se conecta com a classifica√ß√£o. A prova √© obtida mostrando que o valor esperado da vari√°vel indicadora corresponde √† probabilidade condicional da classe.

**Conceito 2: Linear Discriminant Analysis (LDA) e Expectativas Condicionais**

No **LDA**, as fun√ß√µes discriminantes lineares, $\delta_k(x)$, s√£o derivadas da suposi√ß√£o de que cada classe segue uma distribui√ß√£o Gaussiana multivariada com a mesma matriz de covari√¢ncia $\Sigma$ [^4.3]. As fun√ß√µes discriminantes podem ser interpretadas como uma forma de modelar as probabilidades posteriores $P(G=k|X=x)$. Embora o LDA seja constru√≠do atrav√©s da maximiza√ß√£o da verossimilhan√ßa conjunta sob a suposi√ß√£o Gaussiana, ele tamb√©m pode ser visto como uma forma de estimar a expectativa condicional da classe em termos de suas proje√ß√µes lineares no espa√ßo de atributos [^4.3].

```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction TB
        A["Input: x"]
        B["Class Means: Œº‚Çñ"]
        C["Common Covariance Matrix: Œ£"]
        D["Discriminant Function: Œ¥‚Çñ(x) = x·µÄŒ£‚Åª¬πŒº‚Çñ - 0.5Œº‚Çñ·µÄŒ£‚Åª¬πŒº‚Çñ + log(œÄ‚Çñ)"]
        E["Posterior Probability: P(G=k|X=x)"]
        A --> B
        A --> C
        B & C --> D
        D --> E
    end
```

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos duas classes, A e B, com m√©dias $\mu_A = [1, 1]$ e $\mu_B = [2, 2]$, respectivamente, e uma matriz de covari√¢ncia comum $\Sigma = [[0.5, 0], [0, 0.5]]$. O LDA calcula as fun√ß√µes discriminantes, que podem ser expressas como:
>
> $\delta_A(x) = x^T \Sigma^{-1} \mu_A - \frac{1}{2} \mu_A^T \Sigma^{-1} \mu_A + \log(\pi_A)$
> $\delta_B(x) = x^T \Sigma^{-1} \mu_B - \frac{1}{2} \mu_B^T \Sigma^{-1} \mu_B + \log(\pi_B)$
>
> onde $\pi_A$ e $\pi_B$ s√£o as probabilidades a priori das classes. Se $\pi_A = \pi_B = 0.5$, e dado um novo ponto $x = [1.5, 1.5]$, podemos calcular:
>
> $\Sigma^{-1} = [[2, 0], [0, 2]]$
>
> $\delta_A(x) = [1.5, 1.5] \cdot [[2, 0], [0, 2]] \cdot [1, 1] - \frac{1}{2} [1, 1] \cdot [[2, 0], [0, 2]] \cdot [1, 1] = 6 - 2 = 4$
>
> $\delta_B(x) = [1.5, 1.5] \cdot [[2, 0], [0, 2]] \cdot [2, 2] - \frac{1}{2} [2, 2] \cdot [[2, 0], [0, 2]] \cdot [2, 2] = 12 - 8 = 4$
>
> Como $\delta_A(x) = \delta_B(x)$, o LDA classificaria o ponto $x$ como estando no limiar entre as classes (neste caso, a decis√£o seria mais complexa, pois o ponto est√° exatamente na fronteira). A fun√ß√£o discriminante do LDA pode ser vista como uma estimativa da expectativa condicional da classe, sob a suposi√ß√£o gaussiana.

**Corol√°rio 1:** *A fun√ß√£o discriminante do LDA pode ser relacionada com a estimativa da expectativa condicional das classes sob a suposi√ß√£o gaussiana.* Isso deriva do fato de que a fun√ß√£o discriminante maximiza a probabilidade posterior, e sob certas condi√ß√µes, pode ser interpretada como uma estimativa da expectativa condicional da classe.

**Conceito 3: Regress√£o Log√≠stica e a Modelagem da Probabilidade Condicional**

A **Logistic Regression** modela a probabilidade condicional de uma observa√ß√£o pertencer a uma classe atrav√©s da fun√ß√£o log√≠stica [^4.4]. Para o caso de duas classes, a probabilidade $P(G=1|X=x)$ √© modelada como:

$$
P(G=1|X=x) = \frac{e^{\beta_0 + \beta^T x}}{1 + e^{\beta_0 + \beta^T x}}
$$

Neste caso, o log-odds (logit) √© uma fun√ß√£o linear de $x$. A Regress√£o Log√≠stica estima os par√¢metros $\beta_0$ e $\beta$ por maximiza√ß√£o da verossimilhan√ßa. Ao contr√°rio do LDA, a Regress√£o Log√≠stica modela diretamente a probabilidade condicional da classe, em vez de deriv√°-la de distribui√ß√µes gaussianas [^4.4.1]. O m√©todo busca diretamente estimar a expectativa condicional da vari√°vel resposta, codificada de forma bin√°ria.

```mermaid
graph LR
    subgraph "Logistic Regression"
        direction TB
        A["Input Features: x"]
        B["Linear Combination: Œ≤‚ÇÄ + Œ≤·µÄx"]
        C["Logistic Function: œÉ(z) = 1 / (1 + e‚Åª·∂ª)"]
        D["Conditional Probability: P(G=1|X=x) = œÉ(Œ≤‚ÇÄ + Œ≤·µÄx)"]
         A --> B
        B --> C
        C --> D
    end
```

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um modelo de regress√£o log√≠stica com $\beta_0 = -2$ e $\beta = [1, 0.5]$ para duas features $x_1$ e $x_2$. Para um novo ponto $x = [2, 1]$, a probabilidade de pertencer √† classe 1 seria:
>
> $P(G=1|X=x) = \frac{e^{-2 + (1*2) + (0.5*1)}}{1 + e^{-2 + (1*2) + (0.5*1)}} = \frac{e^{0.5}}{1 + e^{0.5}} \approx \frac{1.648}{1 + 1.648} \approx 0.622$
>
> Isso significa que, de acordo com o modelo de regress√£o log√≠stica, o ponto $x=[2, 1]$ tem aproximadamente 62.2% de probabilidade de pertencer √† classe 1. A regress√£o log√≠stica modela diretamente essa probabilidade condicional, que tamb√©m √© uma forma de estimar a expectativa condicional da vari√°vel de classe.

> ‚ö†Ô∏è **Nota Importante**: Enquanto o LDA faz suposi√ß√µes sobre a distribui√ß√£o das classes, a regress√£o log√≠stica modela diretamente a probabilidade condicional, o que a torna uma abordagem mais flex√≠vel [^4.4.1], [^4.4.2].

> ‚ùó **Ponto de Aten√ß√£o**: Em problemas com classes desbalanceadas, m√©todos de repondera√ß√£o ou sobreamostragem podem ser necess√°rios para que a regress√£o log√≠stica forne√ßa estimativas imparciais da probabilidade condicional [^4.4.2].

> ‚úîÔ∏è **Destaque**: A regress√£o log√≠stica, ao modelar a probabilidade condicional, tamb√©m pode ser interpretada como uma estimativa da expectativa condicional da classe sob uma transforma√ß√£o da vari√°vel resposta.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction TB
        A["Input: x ‚àà ‚Ñù·µñ"]
        B["Indicator Matrix: Y (N x K)"]
        C["Linear Regression: f‚Çñ(x) = Œ≤‚Çñ‚ÇÄ + Œ≤‚Çñ·µÄx for each class k"]
        D["Class Assignment: argmax‚Çñ f‚Çñ(x)"]
        E["Conditional Expectation Approximation"]
         A --> B
        B --> C
        C --> D
        D --> E
    end
```

Na aplica√ß√£o da **regress√£o linear para classifica√ß√£o**, cada classe $k$ √© representada por um vetor indicador $Y_k$, onde $Y_{ik} = 1$ se a observa√ß√£o $i$ pertence √† classe $k$, e $Y_{ik} = 0$ caso contr√°rio [^4.2]. Assim, para $K$ classes, teremos uma matriz de respostas $Y$ com dimens√£o $N \times K$. A regress√£o linear √© aplicada a cada coluna de $Y$, resultando em uma fun√ß√£o de regress√£o para cada classe: $f_k(x) = \beta_{k0} + \beta_k^T x$. A classifica√ß√£o √© ent√£o feita atribuindo $x$ √† classe $k$ que maximiza $f_k(x)$, que, sob a perspectiva estat√≠stica, √© a classe que maximiza a estimativa da expectativa condicional da vari√°vel indicadora.

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos 3 classes e 2 features. A matriz de indicadores $Y$ para 5 amostras poderia ser:
>
> ```
> Y = [[1, 0, 0],  # Classe 1
>      [0, 1, 0],  # Classe 2
>      [0, 0, 1],  # Classe 3
>      [1, 0, 0],  # Classe 1
>      [0, 1, 0]]  # Classe 2
> ```
>
> A matriz de features $X$ poderia ser:
> ```
> X = [[1, 2],
>      [2, 3],
>      [3, 1],
>      [1.5, 2.5],
>      [2.5, 3.5]]
> ```
>
> Aplicamos regress√£o linear para cada coluna de $Y$. Suponha que os coeficientes estimados para cada classe sejam:
>
> $\beta_1 = [0.1, 0.2, 0.3]$ (classe 1)
> $\beta_2 = [0.2, 0.3, 0.1]$ (classe 2)
> $\beta_3 = [0.3, 0.1, 0.2]$ (classe 3)
>
> Para um novo ponto $x = [2, 2]$, calculamos:
>
> $f_1(x) = 0.1 + 0.2 * 2 + 0.3 * 2 = 1.1$
> $f_2(x) = 0.2 + 0.3 * 2 + 0.1 * 2 = 1.0$
> $f_3(x) = 0.3 + 0.1 * 2 + 0.2 * 2 = 0.9$
>
>  O ponto $x$ seria classificado na classe 1, pois $f_1(x)$ √© o maior valor. Esta fun√ß√£o linear √© usada como uma aproxima√ß√£o da expectativa condicional da classe.

Apesar de sua simplicidade, essa abordagem apresenta algumas limita√ß√µes. As estimativas $f_k(x)$ podem n√£o estar entre 0 e 1, dificultando a interpreta√ß√£o como probabilidades. Al√©m disso, o m√©todo pode n√£o ser eficaz em cen√°rios com classes sobrepostas ou distribui√ß√µes complexas, j√° que o m√©todo busca uma aproxima√ß√£o linear da expectativa condicional [^4.2]. O problema do "masking" tamb√©m surge, onde a regress√£o linear n√£o consegue capturar adequadamente a estrutura dos dados [^4.2].

A regress√£o de indicadores, vista como um m√©todo para estimar a expectativa condicional, pode ser √∫til quando o objetivo principal √© uma fronteira de decis√£o linear e a interpreta√ß√£o probabil√≠stica n√£o √© essencial [^4.2]. Al√©m disso, sob certas condi√ß√µes, a regress√£o de indicadores e o LDA podem apresentar solu√ß√µes equivalentes [^4.3].

**Lemma 2:** *Quando se codifica as classes com valores 1 e -1 em um problema de classifica√ß√£o bin√°ria, a dire√ß√£o dos coeficientes da regress√£o linear √© proporcional √† dire√ß√£o do discriminante do LDA. Essa proporcionalidade √© uma manifesta√ß√£o da rela√ß√£o entre a regress√£o linear como estimativa da expectativa condicional e a deriva√ß√£o da fronteira de decis√£o do LDA.*  Este lema demonstra uma conex√£o te√≥rica entre regress√£o linear e m√©todos discriminantes [^4.2].

**Corol√°rio 2:** *A regra de decis√£o da regress√£o linear de indicadores coincide com a regra de decis√£o do LDA quando os dados s√£o distribu√≠dos de forma Gaussiana e as classes possuem a mesma probabilidade a priori e covari√¢ncia esf√©rica.* Esta condi√ß√£o ilustra um caso espec√≠fico onde os m√©todos se equivalem, refor√ßando a vis√£o da regress√£o linear como uma forma de estimar a expectativa condicional das classes [^4.3].

√â importante observar que a regress√£o log√≠stica, por sua vez, modela diretamente a probabilidade condicional, enquanto a regress√£o de indicadores aproxima a expectativa condicional por meio de uma fun√ß√£o linear. A regress√£o log√≠stica pode ser vista como uma estimativa mais direta da probabilidade condicional, enquanto a regress√£o linear em indicadores pode ser interpretada como uma aproxima√ß√£o da expectativa condicional das vari√°veis indicadoras.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization in Logistic Regression"
        direction TB
        A["Log-Likelihood Function"]
        B["L1 Penalty (Lasso): Œª‚àë|Œ≤‚±º|"]
        C["L2 Penalty (Ridge): Œª‚àëŒ≤‚±º¬≤"]
        D["Regularized Cost Function"]
        E["Parameter Estimation: Œ≤‚ÇÄ, Œ≤"]
        F["Improved Generalization & Sparsity"]
        A --> B
        A --> C
        B & C --> D
        D --> E
        E --> F
    end
```

**Sele√ß√£o de vari√°veis** e **regulariza√ß√£o** s√£o t√©cnicas que visam melhorar a capacidade de generaliza√ß√£o dos modelos de classifica√ß√£o, reduzindo a complexidade e o risco de overfitting [^4.5].  A **regulariza√ß√£o** adiciona termos de penalidade √† fun√ß√£o de custo, restringindo os valores dos coeficientes do modelo e, consequentemente, a complexidade do modelo.

Na **regress√£o log√≠stica**, a fun√ß√£o de verossimilhan√ßa √© modificada com a adi√ß√£o de um termo de penalidade:

$$
\max_{\beta_0, \beta} \left[ \sum_{i=1}^N \left( y_i (\beta_0 + \beta^T x_i) - \log(1 + e^{\beta_0 + \beta^T x_i}) \right) - \lambda P(\beta) \right]
$$

Onde $P(\beta)$ √© a penalidade e $\lambda$ √© o par√¢metro de regulariza√ß√£o. A penalidade **L1 (Lasso)**, dada por $P(\beta) = \sum_{j=1}^p |\beta_j|$, promove esparsidade, selecionando vari√°veis relevantes e "zerando" os coeficientes de vari√°veis menos importantes [^4.4.4]. A penalidade **L2 (Ridge)**, dada por $P(\beta) = \sum_{j=1}^p \beta_j^2$, reduz a magnitude dos coeficientes e estabiliza o modelo, reduzindo a vari√¢ncia [^4.5]. Essas penalidades podem ser vistas como um vi√©s que melhora a qualidade da estimativa da expectativa condicional, controlando o overfitting do modelo.

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um modelo de regress√£o log√≠stica com duas features, $x_1$ e $x_2$, e que, sem regulariza√ß√£o, os coeficientes estimados sejam $\beta_0 = -1$, $\beta_1 = 3$ e $\beta_2 = -2$.
>
> **Regulariza√ß√£o L1 (Lasso):** Se aplicarmos a regulariza√ß√£o L1 com $\lambda = 0.5$, a fun√ß√£o de custo se torna:
>
> $\text{Custo} =  -\sum_{i=1}^N \left( y_i (\beta_0 + \beta^T x_i) - \log(1 + e^{\beta_0 + \beta^T x_i}) \right) + 0.5(|\beta_1| + |\beta_2|)$
>
>  A otimiza√ß√£o desta fun√ß√£o de custo com regulariza√ß√£o L1 pode levar a um novo conjunto de coeficientes, por exemplo, $\beta_0 = -0.8$, $\beta_1 = 2.0$ e $\beta_2 = 0$. Observe que $\beta_2$ foi zerado, indicando que a feature $x_2$ foi considerada menos relevante pelo modelo. Isso promove a esparsidade e simplifica o modelo.
>
> **Regulariza√ß√£o L2 (Ridge):** Se aplicarmos a regulariza√ß√£o L2 com $\lambda = 0.5$, a fun√ß√£o de custo se torna:
>
> $\text{Custo} =  -\sum_{i=1}^N \left( y_i (\beta_0 + \beta^T x_i) - \log(1 + e^{\beta_0 + \beta^T x_i}) \right) + 0.5(\beta_1^2 + \beta_2^2)$
>
> A otimiza√ß√£o com regulariza√ß√£o L2 pode levar a coeficientes como $\beta_0 = -0.9$, $\beta_1 = 2.5$ e $\beta_2 = -1.5$. Observe que os coeficientes s√£o reduzidos em magnitude em rela√ß√£o ao modelo sem regulariza√ß√£o, mas ambos permanecem diferentes de zero. Isso ajuda a reduzir a vari√¢ncia do modelo e aumentar sua estabilidade.
>
> A regulariza√ß√£o, seja L1 ou L2, impacta a estimativa da expectativa condicional ao modificar a fun√ß√£o de custo e, consequentemente, os coeficientes do modelo.

**Lemma 3:** *A regulariza√ß√£o L1 na regress√£o log√≠stica promove a esparsidade dos coeficientes, zerando muitos deles, o que pode ser visto como uma maneira de simplificar a estimativa da expectativa condicional, reduzindo o n√∫mero de vari√°veis envolvidas no modelo.* Essa propriedade √© uma consequ√™ncia direta da derivada da penalidade L1 [^4.4.4].

**Prova do Lemma 3:** A penalidade L1 adiciona um termo que √© proporcional ao valor absoluto dos coeficientes. A otimiza√ß√£o da fun√ß√£o de custo com a penalidade L1 faz com que coeficientes menos relevantes tornem-se exatamente zero, simplificando o modelo final [^4.4.3]. $\blacksquare$

**Corol√°rio 3:** *Modelos esparsos, gerados pela regulariza√ß√£o L1, levam a uma melhor interpretabilidade e generaliza√ß√£o, pois a estimativa da expectativa condicional √© baseada em um conjunto menor de vari√°veis.* Isso ocorre porque apenas as vari√°veis mais importantes s√£o mantidas no modelo [^4.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: A regulariza√ß√£o L1 e L2, ao penalizarem os coeficientes, afetam a estimativa da expectativa condicional, controlando a complexidade do modelo e prevenindo o overfitting [^4.5].

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Separating Hyperplane"
        direction TB
        A["Input: x ‚àà ‚Ñù·µñ"]
        B["Hyperplane: Œ≤‚ÇÄ + Œ≤·µÄx = 0"]
        C["Margin Maximization"]
        D["Perceptron Algorithm (Iterative Adjustment)"]
         E["Linear Model as Conditional Expectation"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

A ideia de **hiperplanos separadores** surge da busca por uma fronteira linear que maximize a separa√ß√£o entre classes, ou seja, que separe as classes da melhor forma poss√≠vel e que tamb√©m seja robusta em rela√ß√£o a pequenas perturba√ß√µes [^4.5.2]. O hiperplano √© definido pela equa√ß√£o $\beta_0 + \beta^T x = 0$, e o objetivo √© encontrar os par√¢metros $\beta_0$ e $\beta$ que maximizem a margem, que √© a dist√¢ncia entre o hiperplano e as amostras mais pr√≥ximas de cada classe.

O algoritmo do **Perceptron** √© um m√©todo iterativo para encontrar um hiperplano separador [^4.5.1]. A cada itera√ß√£o, o algoritmo ajusta os par√¢metros do hiperplano com base nas classifica√ß√µes incorretas, buscando uma solu√ß√£o que minimize a dist√¢ncia entre as amostras e a fronteira de decis√£o. Se os dados forem linearmente separ√°veis, o algoritmo converge para uma solu√ß√£o em um n√∫mero finito de passos, que corresponde a um modelo linear que estima uma forma de expectativa condicional.

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos duas classes representadas por pontos no plano 2D. Classe 1: $(1,1), (2,1), (2,2)$ e Classe 2: $(3,3), (4,3), (4,4)$. Inicializamos o hiperplano com $\beta = [0.5, 0.5]$ e $\beta_0 = -2$.
>
> 1. **Itera√ß√£o 1:**
>    - Ponto (1,1): $0.5*1 + 0.5*1 - 2 = -1$ (classificado incorretamente, pois est√° na classe 1, mas o resultado √© negativo)
>    - Atualizamos $\beta = \beta + \alpha * x = [0.5, 0.5] + 0.1 * [1, 1] = [0.6, 0.6]$ e $\beta_0 = \beta_0 + \alpha = -2 + 0.1 = -1.9$.
>    - O hiperplano agora √© definido por $0.6x_1 + 0.6x_2 - 1.9 = 0$.
>
> 2. **Itera√ß√£o 2:**
>    - Repetimos o processo para todos os pontos, ajustando o hiperplano a cada classifica√ß√£o incorreta, at√© que todos os pontos sejam classificados corretamente.
>
> O algoritmo do Perceptron itera sobre os pontos, ajustando os par√¢metros at√© encontrar um hiperplano que separa linearmente os dados. Este hiperplano √© um modelo linear que estima a expectativa condicional da classe.

**Teorema:** *Se o conjunto de dados de treinamento √© linearmente separ√°vel, o algoritmo do Perceptron converge para um hiperplano separador em um n√∫mero finito de passos.* A prova formal deste resultado garante que, sob condi√ß√µes ideais, o algoritmo seja capaz de encontrar um modelo linear adequado [^4.5.1].

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**

A **Regra de Decis√£o Bayesiana** busca classificar uma observa√ß√£o $x$ na classe $k$ que maximiza a probabilidade posterior $P(G=k|X=x)$ [^4.3]. Quando as classes seguem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia $\Sigma$, podemos usar o Teorema de Bayes para derivar as probabilidades posteriores:

$$
P(G=k|X=x) = \frac{P(X=x|G=k)P(G=k)}{P(X=x)}
$$

Onde $P(X=x|G=k)$ √© a densidade gaussiana da classe $k$, e $P(G=k)=\pi_k$ √© a probabilidade a priori da classe. A decis√£o √© tomada atribuindo $x$ √† classe que maximiza essa probabilidade. O LDA, por outro lado, deriva suas fun√ß√µes discriminantes lineares atrav√©s de uma an√°lise direta das densidades gaussianas e da suposi√ß√£o de covari√¢ncias iguais, buscando maximizar a separa√ß√£o entre as classes no espa√ßo de caracter√≠sticas [^4.3]. Embora ambos os m√©todos compartilhem a mesma suposi√ß√£o de normalidade, a forma como a decis√£o de classifica√ß√£o √© implementada √© distinta.

```mermaid
graph LR
    subgraph "LDA vs. Bayesian Decision Rule"
        direction TB
        A["Gaussian Class Densities: P(X=x|G=k)"]
        B["Prior Probabilities: œÄ‚Çñ = P(G=k)"]
        C["Bayesian Posterior Probability: P(G=k|X=x)"]
        D["LDA Discriminant Functions: Œ¥‚Çñ(x)"]
        E["Decision Rule: argmax P(G=k|X=x)"]
        F["Decision Rule: argmax Œ¥‚Çñ(x)"]
         A & B --> C
        A & B --> D
        C --> E
        D --> F
        E <--> F
    end
```

**Lemma 4:** *Sob a suposi√ß√£o de distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia, a regra de decis√£o Bayesiana e o LDA s√£o equivalentes, resultando na mesma fronteira de decis√£o linear. A equival√™ncia √© demonstrada mostrando que a maximiza√ß√£o da probabilidade posterior na regra Bayesiana leva √† mesma forma funcional da fun√ß√£o discriminante do LDA. Ambas as abordagens s√£o, neste caso, formas de estimar a expectativa condicional das classes, com resultados equivalentes.* [^4.3]

**Corol√°rio 4:** *A viola√ß√£o da suposi√ß√£o de igualdade de covari√¢ncia no LDA leva √† abordagem QDA (Quadratic Discriminant Analysis), que relaxa essa restri√ß√£o e leva a fronteiras de decis√£o quadr√°ticas. O QDA pode ser interpretado como uma estimativa da expectativa condicional mais flex√≠vel, j√° que permite que a forma da fun√ß√£o de decis√£o seja mais complexa.* [^4.3.1], [^4.3.3]

> ‚ö†Ô∏è **Ponto Crucial**: A diferen√ßa fundamental reside na abordagem. A regra de decis√£o Bayesiana tenta otimizar diretamente a probabilidade posterior, enquanto o LDA deriva sua regra de uma modelagem das densidades gaussianas, com uma restri√ß√£o adicional sobre as matrizes de covari√¢ncia [^4.3].

### Conclus√£o

Neste cap√≠tulo, exploramos a fundo a vis√£o estat√≠stica que interpreta a regress√£o linear como uma estimativa da expectativa condicional. Vimos como essa perspectiva se conecta com m√©todos de classifica√ß√£o linear como LDA e regress√£o log√≠stica e a aplica√ß√£o da regress√£o em matrizes de indicadores. Abordamos tamb√©m a import√¢ncia da sele√ß√£o de vari√°veis e da regulariza√ß√£o, que s√£o cruciais para construir modelos robustos que generalizam bem para novos dados. A discuss√£o sobre hiperplanos separadores e o algoritmo do Perceptron tamb√©m refor√ßou a import√¢ncia das fronteiras de decis√£o lineares. A an√°lise da rela√ß√£o entre LDA e a regra de decis√£o Bayesiana sob distribui√ß√µes Gaussianas com covari√¢ncias iguais tamb√©m forneceu um entendimento mais profundo sobre as nuances te√≥ricas desses m√©todos. Atrav√©s deste cap√≠tulo, buscamos oferecer uma base s√≥lida para a aplica√ß√£o e interpreta√ß√£o de modelos lineares em problemas de classifica√ß√£o.

### Footnotes

[^4.1]: *In this chapter we revisit the classification problem and focus on linear methods for classification...There are several different ways in which linear decision boundaries can be found.* *(Trecho de Linear Methods for Classification)*

[^4.2]: *In Chapter 2 we fit linear regression models to the class indicator variables, and classify to the largest fit...Linear inequalities in this space are quadratic inequalities in the original space.* *(Trecho de Linear Methods for Classification)*

[^4.3]: *Decision theory for classification (Section 2.4) tells us that we need to know the class posteriors Pr(G|X) for optimal classification. Suppose fk(x) is the class-conditional density of X in class G = k, and let œÄŒ∫ be the prior probability of class k... Linear discriminant analysis (LDA) arises in the special case when we assume that the classes have a common covariance matrix Œ£k = Œ£.* *(Trecho de Linear Methods for Classification)*

[^4.3.1]: *The decision boundary between each pair of classes k and l is described by a quadratic equation {x: Œ¥Œ∫(x) = Œ¥(x)}.* *(Trecho de Linear Methods for Classification)*

[^4.3.3]: *In the special case when we assume that the classes have a common covariance matrix...When the classes are really Gaussian, then LDA is optimal* *(Trecho de Linear Methods for Classification)*

[^4.4]: *The logistic regression model arises from the desire to model the posterior probabilities of the K classes via linear functions in x, while at the same time ensuring that they sum to one and remain in [0,1].* *(Trecho de Linear Methods for Classification)*

[^4.4.1]: *Logistic regression models are usually fit by maximum likelihood... The logistic regression model is more general, in that it makes less assumptions.* *(Trecho de Linear Methods for Classification)*

[^4.4.2]: *It is convenient to code the two-class gi via a 0/1 response Yi, where yi = 1 when gi = 1, and yi = 0 when gi = 2... Typically many models are fit in a search for a parsimonious model involving a subset of the variables.* *(Trecho de Linear Methods for Classification)*

[^4.4.3]: *To maximize the log-likelihood, we set its derivatives to zero. These score equations are...To solve the score equations (4.21), we use the Newton-Raphson algorithm...* *(Trecho de Linear Methods for Classification)*

[^4.4.4]: *The L1 penalty used in the lasso (Section 3.4.2) can be used for variable selection and shrinkage with any linear regression model...As with the lasso, we typically do not penalize the intercept term.* *(Trecho de Linear Methods for Classification)*

[^4.5]: *Here we present an analysis of binary data to illustrate the traditional statistical use of the logistic regression model... With two classes there is a simple correspondence between linear discriminant analysis and classification by linear least squares, as in (4.5).* *(Trecho de Linear Methods for Classification)*

[^4.5.1]: *The perceptron learning algorithm tries to find a separating hyperplane by minimizing the distance of misclassified points to the decision boundary.* *(Trecho de Linear Methods for Classification)*

[^4.5.2]: *The optimal separating hyperplane separates the two classes and maximizes the distance to the closest point from either class... In light of (4.40), the constraints define an empty slab or margin around the linear decision boundary...* *(Trecho de Linear Methods for Classification)*
