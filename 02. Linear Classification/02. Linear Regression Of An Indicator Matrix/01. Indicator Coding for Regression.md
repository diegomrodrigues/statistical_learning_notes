## T√≠tulo Conciso: Classifica√ß√£o Linear, Sele√ß√£o de Vari√°veis e Regulariza√ß√£o

```mermaid
graph LR
    A["Linear Classification Methods"] --> B["LDA"]
    A --> C["Logistic Regression"]
    A --> D["Hyperplanes"]
    A --> E["Variable Selection"]
    A --> F["Regularization"]
    B --> E
    B --> F
    C --> E
    C --> F
    D --> E
    D --> F
```

### Introdu√ß√£o

A classifica√ß√£o √© um problema central em aprendizado de m√°quina e estat√≠stica, onde o objetivo √© atribuir uma classe ou categoria a uma dada entrada. M√©todos lineares de classifica√ß√£o s√£o uma classe fundamental de algoritmos que utilizam fronteiras de decis√£o lineares para separar as classes [^4.1]. Esses m√©todos, apesar de sua simplicidade, s√£o amplamente utilizados devido √† sua efici√™ncia computacional, interpretabilidade e bom desempenho em muitos cen√°rios pr√°ticos. Ao longo deste cap√≠tulo, exploraremos v√°rias t√©cnicas para construir modelos de classifica√ß√£o linear, com foco em m√©todos estat√≠sticos e de aprendizado de m√°quina que utilizam **Linear Discriminant Analysis (LDA)**, **Logistic Regression**, e **hiperplanos separadores**, bem como t√©cnicas de sele√ß√£o de vari√°veis e regulariza√ß√£o para melhorar a generaliza√ß√£o e robustez desses modelos [^4.1]. Abordaremos desde a regress√£o linear em matrizes de indicadores [^4.2] at√© a aplica√ß√£o de t√©cnicas de regulariza√ß√£o L1 [^4.4.4], sempre buscando aprofundar tanto a teoria quanto os algoritmos.

### Conceitos Fundamentais

**Conceito 1: O Problema de Classifica√ß√£o e M√©todos Lineares**

O problema de classifica√ß√£o consiste em, dado um conjunto de dados de entrada $x \in \mathbb{R}^p$, atribuir a este um r√≥tulo de classe $G$ pertencente a um conjunto discreto de classes $G=\{1, 2, \ldots, K\}$. M√©todos lineares de classifica√ß√£o assumem que as fronteiras de decis√£o entre as classes podem ser representadas por **hiperplanos** [^4.1]. Isto significa que cada classe √© delimitada por uma combina√ß√£o linear das vari√°veis de entrada. Uma fun√ß√£o discriminante linear $f(x) = \beta_0 + \beta^Tx$ √© utilizada para modelar a decis√£o de classe, onde $\beta_0$ √© o intercepto e $\beta$ s√£o os coeficientes. O uso de modelos lineares pode introduzir vi√©s, mas geralmente apresentam uma vari√¢ncia menor em compara√ß√£o com modelos n√£o-lineares mais complexos. Em situa√ß√µes onde as classes s√£o bem separadas por uma fronteira linear, essa abordagem linear √© bastante eficaz. Por exemplo, ao modelar um problema de classifica√ß√£o bin√°ria, podemos ter uma fun√ß√£o $f(x)$ onde, se $f(x) > 0$, atribu√≠mos o r√≥tulo $G=1$ e, caso contr√°rio, atribu√≠mos $G=2$ [^4.1].

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o bin√°ria com duas vari√°veis de entrada $x_1$ e $x_2$. Suponha que ap√≥s o treinamento de um modelo linear, obtivemos a fun√ß√£o discriminante: $f(x) = -1 + 2x_1 + 1x_2$.
>
> Para um ponto de dados $x = (1, 2)$, temos $f(1, 2) = -1 + 2(1) + 1(2) = 3$. Como $f(x) > 0$, este ponto seria classificado como pertencente √† classe 1.
>
> Para outro ponto $x = (0, 0)$, temos $f(0, 0) = -1 + 2(0) + 1(0) = -1$. Como $f(x) < 0$, este ponto seria classificado como pertencente √† classe 2.
>
> A fronteira de decis√£o √© o hiperplano (neste caso, uma linha) definido por $f(x) = 0$, ou seja, $-1 + 2x_1 + 1x_2 = 0$, que pode ser reescrito como $x_2 = 1 - 2x_1$.
>
> ```mermaid
>  graph LR
>      A["x=(1,2), f(x)=3"] -->|Class 1| C
>      B["x=(0,0), f(x)=-1"] -->|Class 2| D
>      C["Class 1"]
>      D["Class 2"]
>      E["Decision Boundary: x2 = 1 - 2x1"]
>      E --> F["Points above boundary are class 1"]
>      E --> G["Points below boundary are class 2"]
> ```

**Lemma 1:** *A fronteira de decis√£o entre duas classes usando uma fun√ß√£o discriminante linear √© sempre um hiperplano*. A prova consiste em mostrar que o conjunto de pontos $x$ onde $f_k(x) = f_l(x)$ (fun√ß√µes discriminantes das classes $k$ e $l$) resulta em uma equa√ß√£o linear que define um hiperplano [^4.1]. Ou seja, dado $f_k(x) = \beta_{k0} + \beta_k^T x$ e $f_l(x) = \beta_{l0} + \beta_l^T x$, a igualdade $\beta_{k0} + \beta_k^T x = \beta_{l0} + \beta_l^T x$ pode ser reescrita como $(\beta_{k0} - \beta_{l0}) + (\beta_k - \beta_l)^T x = 0$, que √© a equa√ß√£o de um hiperplano. $\blacksquare$

**Conceito 2: Linear Discriminant Analysis (LDA)**

**LDA** √© um m√©todo cl√°ssico para classifica√ß√£o que assume que cada classe segue uma distribui√ß√£o gaussiana multivariada com a mesma matriz de covari√¢ncia $\Sigma$ [^4.3]. A fun√ß√£o discriminante para cada classe $k$ √© dada por:

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log \pi_k
$$

onde $\mu_k$ √© o vetor de m√©dias para a classe $k$ e $\pi_k$ √© a probabilidade a priori da classe $k$ [^4.3]. A decis√£o de classe √© dada por $\hat{G}(x) = \arg\max_k \delta_k(x)$. A igualdade de matrizes de covari√¢ncia garante que as fronteiras de decis√£o entre as classes sejam lineares, o que √© uma propriedade fundamental do LDA [^4.3]. A suposi√ß√£o de normalidade dos dados √© uma limita√ß√£o do LDA, mas na pr√°tica, ele frequentemente funciona bem, mesmo quando essa suposi√ß√£o n√£o √© estritamente v√°lida.

```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction LR
        A["Œ¥_k(x)"] --> B["x^T Œ£‚Åª¬π Œº_k"]
        A --> C["- 1/2 Œº_k^T Œ£‚Åª¬π Œº_k"]
        A --> D["log œÄ_k"]
    end
```

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos duas classes, $G=1$ e $G=2$, com as seguintes caracter√≠sticas:
> - $\mu_1 = [2, 2]^T$ (m√©dia da classe 1)
> - $\mu_2 = [4, 4]^T$ (m√©dia da classe 2)
> - $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$ (matriz de covari√¢ncia comum)
> - $\pi_1 = 0.6$ (probabilidade a priori da classe 1)
> - $\pi_2 = 0.4$ (probabilidade a priori da classe 2)
>
> Para um ponto de dado $x = [3, 3]^T$, calculamos as fun√ß√µes discriminantes:
>
> 1.  $\Sigma^{-1} = \frac{1}{0.75} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$
>
> 2.  $\delta_1(x) = x^T \Sigma^{-1} \mu_1 - \frac{1}{2} \mu_1^T \Sigma^{-1} \mu_1 + \log \pi_1 = [3,3] \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 2 \\ 2 \end{bmatrix} - \frac{1}{2} [2,2] \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 2 \\ 2 \end{bmatrix} + \log(0.6) = 4 - 4 + \log(0.6) = -0.51$
>
> 3.  $\delta_2(x) = x^T \Sigma^{-1} \mu_2 - \frac{1}{2} \mu_2^T \Sigma^{-1} \mu_2 + \log \pi_2 = [3,3] \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 4 \\ 4 \end{bmatrix} - \frac{1}{2} [4,4] \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 4 \\ 4 \end{bmatrix} + \log(0.4) = 16 - 16 + \log(0.4) = -0.92$
>
> Como $\delta_1(x) > \delta_2(x)$, o ponto $x = [3, 3]^T$ seria classificado como pertencente √† classe 1.

**Corol√°rio 1:** *A fronteira de decis√£o entre classes no LDA √© um hiperplano.* Isto decorre da forma linear das fun√ß√µes discriminantes $\delta_k(x)$, pois ao igualar as fun√ß√µes de duas classes $k$ e $l$, temos: $\delta_k(x) = \delta_l(x)$, que leva a uma equa√ß√£o linear em $x$, definindo um hiperplano [^4.3.1].

**Conceito 3: Logistic Regression**

**Logistic Regression** √© outro m√©todo popular de classifica√ß√£o linear que modela a probabilidade de uma classe usando a fun√ß√£o log√≠stica [^4.4]. Para o caso de duas classes, a probabilidade de pertencer √† classe 1 √© modelada como:

$$
P(G=1|X=x) = \frac{e^{\beta_0 + \beta^T x}}{1 + e^{\beta_0 + \beta^T x}}
$$

O logit (log-odds) dessa probabilidade √© uma fun√ß√£o linear de $x$:

$$
\log \left(\frac{P(G=1|X=x)}{1 - P(G=1|X=x)}\right) = \beta_0 + \beta^T x
$$

Os par√¢metros $\beta_0$ e $\beta$ s√£o estimados maximizando a verossimilhan√ßa dos dados de treinamento [^4.4.1].  A logistic regression n√£o assume distribui√ß√£o gaussiana para os dados de entrada, sendo mais flex√≠vel que o LDA em rela√ß√£o a essa suposi√ß√£o [^4.4.2]. A principal diferen√ßa entre LDA e Logistic Regression reside na maneira como os coeficientes s√£o estimados: LDA usa momentos dos dados (m√©dias e covari√¢ncias) enquanto a regress√£o log√≠stica utiliza maximiza√ß√£o da verossimilhan√ßa [^4.4.1]. Em cen√°rios onde as classes s√£o linearmente separ√°veis, ambas as abordagens podem apresentar desempenhos similares, conforme observado em [^4.5].

```mermaid
graph LR
    subgraph "Logistic Regression Model"
        direction LR
        A["P(G=1|X=x)"] --> B["exp(Œ≤_0 + Œ≤^T x)"]
        C["1 + exp(Œ≤_0 + Œ≤^T x)"]
        B --> D["Fraction"]
        C --> D
    end
```

> üí° **Exemplo Num√©rico:**
>
> Considere um modelo de regress√£o log√≠stica com $\beta_0 = -2$, $\beta_1 = 1$ e $\beta_2 = 0.5$. A probabilidade de um ponto $x = [x_1, x_2]^T$ pertencer √† classe 1 √© dada por:
>
> $P(G=1|X=x) = \frac{e^{-2 + x_1 + 0.5x_2}}{1 + e^{-2 + x_1 + 0.5x_2}}$
>
> Para o ponto $x = [3, 2]$, temos:
>
> $P(G=1|X=[3,2]) = \frac{e^{-2 + 3 + 0.5(2)}}{1 + e^{-2 + 3 + 0.5(2)}} = \frac{e^{2}}{1 + e^{2}} \approx 0.88$
>
> Portanto, h√° uma probabilidade de aproximadamente 88% de que este ponto perten√ßa √† classe 1.
>
> Para o ponto $x = [0, 0]$, temos:
>
> $P(G=1|X=[0,0]) = \frac{e^{-2 + 0 + 0.5(0)}}{1 + e^{-2 + 0 + 0.5(0)}} = \frac{e^{-2}}{1 + e^{-2}} \approx 0.12$
>
> Neste caso, a probabilidade de pertencer √† classe 1 √© de apenas 12%, sendo mais prov√°vel que perten√ßa √† classe 2.
>
> A fronteira de decis√£o (onde a probabilidade √© 0.5) √© definida por $-2 + x_1 + 0.5x_2 = 0$, ou seja $x_2 = 4 - 2x_1$.
>
> ```mermaid
> graph LR
> A["x=[3,2], P(G=1|X)=0.88"] -->|High Probability of Class 1| C
> B["x=[0,0], P(G=1|X)=0.12"] -->|Low Probability of Class 1| D
> C["Class 1"]
> D["Class 2"]
> E["Decision Boundary: x2 = 4 - 2x1"]
> E --> F["Points above boundary are more likely class 1"]
> E --> G["Points below boundary are more likely class 2"]
> ```

> ‚ö†Ô∏è **Nota Importante**: A logistic regression √© uma abordagem mais flex√≠vel que o LDA, j√° que n√£o assume distribui√ß√µes gaussianas para os dados de entrada. [^4.4.1]

> ‚ùó **Ponto de Aten√ß√£o**: Em problemas com classes desbalanceadas, √© crucial ajustar as penalidades ou usar outras t√©cnicas para evitar o vi√©s do modelo em dire√ß√£o √† classe majorit√°ria [^4.4.2].

> ‚úîÔ∏è **Destaque**: Tanto LDA quanto Logistic Regression resultam em fronteiras de decis√£o lineares, por√©m os m√©todos de estima√ß√£o de par√¢metros s√£o distintos, e cada um pode ser mais adequado dependendo dos dados e do problema [^4.5].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Indicator Regression for Classification"
        direction LR
        A["Input Data"] --> B["Indicator Matrix Y"]
        B --> C["Linear Regression: f_k(x) = Œ≤_k0 + Œ≤_k^T x"]
        C --> D["Classification: argmax_k f_k(x)"]
    end
```

A **regress√£o linear** pode ser adaptada para problemas de classifica√ß√£o atrav√©s do uso de uma **matriz de indicadores** [^4.2]. Nesta abordagem, cada classe $k$ √© representada por um vetor indicador $Y_k$, onde $Y_k = 1$ se a observa√ß√£o pertence √† classe $k$, e $Y_k = 0$ caso contr√°rio [^4.2]. Assim, para um problema com $K$ classes, teremos uma matriz resposta $Y$ de dimens√£o $N \times K$, onde $N$ √© o n√∫mero de observa√ß√µes. A regress√£o linear √© ent√£o aplicada a cada coluna de $Y$, obtendo-se uma fun√ß√£o $f_k(x) = \beta_{k0} + \beta_k^T x$ para cada classe. A observa√ß√£o $x$ √© ent√£o classificada para a classe $k$ que apresentar o maior valor de $f_k(x)$ [^4.2].

Este m√©todo, embora simples, tem algumas limita√ß√µes. Uma delas √© que as estimativas $f_k(x)$ podem ser negativas ou maiores que 1, o que dificulta a interpreta√ß√£o como probabilidades. Al√©m disso, quando as classes s√£o sobrepostas ou apresentam estruturas complexas, a regress√£o linear pode ter um desempenho inferior aos m√©todos que modelam explicitamente a distribui√ß√£o de classes [^4.2]. Outra limita√ß√£o not√°vel √© o "masking problem" que ocorre quando uma classe intermedi√°ria √© completamente ignorada durante a classifica√ß√£o, levando a uma m√° representa√ß√£o das classes pelos m√©todos [^4.2].

Apesar dessas limita√ß√µes, a regress√£o de indicadores pode ser √∫til em certos cen√°rios onde o objetivo principal √© encontrar uma fronteira de decis√£o linear e a interpretabilidade das probabilidades n√£o √© essencial. Al√©m disso, sob certas condi√ß√µes, as proje√ß√µes nos hiperplanos de decis√£o gerados por regress√£o linear e discriminantes lineares podem ser equivalentes [^4.3], conforme detalhado em [^4.2].

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o com tr√™s classes e duas vari√°veis de entrada. Temos as seguintes observa√ß√µes e seus r√≥tulos:
>
> | Observa√ß√£o (x1, x2) | Classe |
> |--------------------|--------|
> | (1, 1)             | 1      |
> | (2, 1)             | 1      |
> | (1, 2)             | 2      |
> | (2, 2)             | 2      |
> | (3, 1)             | 3      |
> | (3, 2)             | 3      |
>
> A matriz de indicadores $Y$ ser√°:
>
> | Classe 1 | Classe 2 | Classe 3 |
> |----------|----------|----------|
> | 1        | 0        | 0        |
> | 1        | 0        | 0        |
> | 0        | 1        | 0        |
> | 0        | 1        | 0        |
> | 0        | 0        | 1        |
> | 0        | 0        | 1        |
>
> Aplicando a regress√£o linear para cada coluna da matriz $Y$, podemos obter as fun√ß√µes de decis√£o para cada classe:
>
> $f_1(x) = \beta_{10} + \beta_{11}x_1 + \beta_{12}x_2$
> $f_2(x) = \beta_{20} + \beta_{21}x_1 + \beta_{22}x_2$
> $f_3(x) = \beta_{30} + \beta_{31}x_1 + \beta_{32}x_2$
>
> Suponha que, ap√≥s a regress√£o, obtemos:
>
> $f_1(x) = 0.8 - 0.2x_1 + 0.1x_2$
> $f_2(x) = -0.1 + 0.1x_1 + 0.7x_2$
> $f_3(x) = -0.2 + 0.5x_1 - 0.3x_2$
>
> Para classificar um novo ponto $x = (2, 1.5)$, calculamos os valores das fun√ß√µes:
>
> $f_1(2, 1.5) = 0.8 - 0.2(2) + 0.1(1.5) = 0.55$
> $f_2(2, 1.5) = -0.1 + 0.1(2) + 0.7(1.5) = 1.15$
> $f_3(2, 1.5) = -0.2 + 0.5(2) - 0.3(1.5) = 0.35$
>
> Como $f_2(2, 1.5)$ √© o maior valor, o ponto $x = (2, 1.5)$ seria classificado como pertencente √† classe 2.

**Lemma 2:** *Em um problema de classifica√ß√£o com duas classes, a dire√ß√£o dos coeficientes obtida por regress√£o linear em uma codifica√ß√£o 1/-1 √© proporcional √† dire√ß√£o da fun√ß√£o discriminante do LDA.* Isto pode ser demonstrado mostrando que os coeficientes da regress√£o linear e os coeficientes do LDA s√£o colineares [^4.2]. $\blacksquare$

**Corol√°rio 2:** *Quando as classes s√£o equiprov√°veis e a matriz de covari√¢ncia √© esf√©rica ($\Sigma = \sigma^2 I$), a regress√£o linear de indicadores e o LDA retornam a mesma fronteira de decis√£o.* Sob essas condi√ß√µes, as estimativas do LDA e da regress√£o linear s√£o alinhadas, resultando na mesma separa√ß√£o das classes [^4.3].

Em rela√ß√£o √†s limita√ß√µes, conforme apontado em [^4.4], a regress√£o log√≠stica pode fornecer estimativas de probabilidade mais est√°veis, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora do intervalo [0,1]. Entretanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^4.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization in Logistic Regression"
        direction TB
        A["Logistic Regression Loss"] --> B["Without Regularization"]
        A --> C["With L1 Regularization"]
        A --> D["With L2 Regularization"]
        C --> E["Sparsity"]
        D --> F["Stability"]
    end
```

**Sele√ß√£o de vari√°veis** e **regulariza√ß√£o** s√£o t√©cnicas cruciais para melhorar o desempenho e a interpretabilidade de modelos de classifica√ß√£o [^4.5]. Em problemas com um n√∫mero elevado de vari√°veis ($p$), muitas podem ser irrelevantes ou redundantes, levando a modelos complexos e com alto risco de *overfitting*.  A **regulariza√ß√£o** adiciona um termo de penalidade √† fun√ß√£o de custo do modelo, que for√ßa os coeficientes a serem menores ou a se tornarem zero, reduzindo a complexidade do modelo e melhorando a capacidade de generaliza√ß√£o [^4.5].

Na **regress√£o log√≠stica**, a regulariza√ß√£o pode ser introduzida na fun√ß√£o de verossimilhan√ßa, como ilustrado abaixo:

$$
\text{max}_{\beta_0, \beta} \left[ \sum_{i=1}^N \left( y_i (\beta_0 + \beta^T x_i) - \log(1 + e^{\beta_0 + \beta^T x_i}) \right) - \lambda \sum_{j=1}^p |\beta_j| \right]
$$

Aqui, $\lambda$ √© o par√¢metro de regulariza√ß√£o e o termo $\sum_{j=1}^p |\beta_j|$ √© a penalidade **L1** (lasso), que induz esparsidade nos coeficientes, ou seja, faz com que alguns coeficientes sejam exatamente zero, realizando sele√ß√£o de vari√°veis [^4.4.4]. A penalidade **L2** (ridge), que penaliza a soma dos quadrados dos coeficientes, tamb√©m pode ser usada para estabilizar o modelo e reduzir a vari√¢ncia:

$$
\text{max}_{\beta_0, \beta} \left[ \sum_{i=1}^N \left( y_i (\beta_0 + \beta^T x_i) - \log(1 + e^{\beta_0 + \beta^T x_i}) \right) - \lambda \sum_{j=1}^p \beta_j^2 \right]
$$

A escolha entre L1 e L2, ou uma combina√ß√£o das duas (Elastic Net), depende da aplica√ß√£o e das propriedades desejadas do modelo [^4.5].

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um modelo de regress√£o log√≠stica com 5 vari√°veis ($x_1, x_2, x_3, x_4, x_5$). Ap√≥s o treinamento sem regulariza√ß√£o, obtivemos os seguintes coeficientes:
>
> $\beta = [1.5, -0.8, 2.2, 0.5, -1.1]^T$.
>
> Agora, aplicamos a regulariza√ß√£o L1 (Lasso) com $\lambda = 0.8$. Ap√≥s o treinamento com regulariza√ß√£o L1, os coeficientes podem se tornar:
>
> $\beta_{L1} = [1.0, 0.0, 1.5, 0.0, -0.6]^T$.
>
> Observe que os coeficientes $\beta_2$ e $\beta_4$ foram reduzidos a zero, indicando que as vari√°veis $x_2$ e $x_4$ foram consideradas menos relevantes pelo modelo regularizado.
>
> Se aplicarmos a regulariza√ß√£o L2 (Ridge) com $\lambda = 0.8$, os coeficientes podem se tornar:
>
> $\beta_{L2} = [1.2, -0.6, 1.8, 0.4, -0.9]^T$.
>
> Note que os coeficientes foram reduzidos em magnitude, mas nenhum se tornou exatamente zero.
>
> Agora, vamos comparar o efeito da regulariza√ß√£o L1 e L2 em um modelo real usando Python com `scikit-learn`.
>
> ```python
> import numpy as np
> import pandas as pd
> from sklearn.model_selection import train_test_split
> from sklearn.linear_model import LogisticRegression
> from sklearn.metrics import accuracy_score
> from sklearn.preprocessing import StandardScaler
>
> # Generate synthetic data for demonstration
> np.random.seed(42)
> n_samples = 200
> n_features = 10
> X = np.random.randn(n_samples, n_features)
> y = np.random.randint(0, 2, n_samples)
>
> # Split data
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Standardize data
> scaler = StandardScaler()
> X_train_scaled = scaler.fit_transform(X_train)
> X_test_scaled = scaler.transform(X_test)
>
> # Logistic Regression without regularization
> model_no_reg = LogisticRegression(penalty=None, solver='lbfgs', random_state=42)
> model_no_reg.fit(X_train_scaled, y_train)
> y_pred_no_reg = model_no_reg.predict(X_test_scaled)
> acc_no_reg = accuracy_score(y_test, y_pred_no_reg)
>
> # Logistic Regression with L1 regularization
> model_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=0.5, random_state=42)
> model_l1.fit(X_train_scaled, y_train)
> y_pred_l1 = model_l1.predict(X_test_scaled)
> acc_l1 = accuracy_score(y_test, y_pred_l1)
>
> # Logistic Regression with L2 regularization
> model_l2 = LogisticRegression(penalty='l2', solver='lbfgs', C=0.5, random_state=42)
> model_l2.fit(X_train_scaled, y_train)
> y_pred_l2 = model_l2.predict(X_test_scaled)
> acc_l2 = accuracy_score(y_test, y_pred_l2)
>
> # Results
> print(f"Accuracy without regularization: {acc_no_reg:.3f}")
> print(f"Accuracy with L1 regularization: {acc_l1:.3f}")
> print(f"Accuracy with L2 regularization: {acc_l2:.3f}")
>
> # Show coefficients
> coef_no_reg = model_no_reg.coef_[0]
> coef_l1 = model_l1.coef_[0]
> coef_l2 = model_l2.coef_[0]
>
> coef_df = pd.DataFrame({'No Reg': coef_no_reg, 'L1': coef_l1, 'L2': coef_l2})
> print("\nCoefficients:")
> print(coef_df)
>
> ```
>
> Este c√≥digo gera dados sint√©ticos, treina modelos de regress√£o log√≠stica com e sem regulariza√ß√£o L1 e L2, e compara a acur√°cia e os coeficientes resultantes.
>
> Os resultados mostrar√£o como a regulariza√ß√£o L1 pode zerar alguns coeficientes, enquanto a regulariza√ß√£o L2 reduz a magnitude de todos os coeficientes.

**Lemma 3:** *A penalidade L1 em regress√£o log√≠stica promove esparsidade nos coeficientes.* Isso ocorre devido √† natureza da penalidade L1, que imp√µe uma taxa constante de decr√©scimo nos coeficientes conforme $\lambda$ aumenta, fazendo com que muitos coeficientes cheguem a zero [^4.4.4].

**Prova do Lemma 3:** A penalidade L1 adiciona um termo $|\beta_j|$ √† fun√ß√£o de custo. A derivada deste termo √© $\pm 1$ dependendo do sinal do coeficiente. Para um coeficiente n√£o nulo, a otimiza√ß√£o faz com que o coeficiente reduza at√© que chegue a zero, dado que a penalidade L1 tem um comportamento linear na vizinhan√ßa de $\beta_j=0$, diferentemente de uma penalidade L2 (que reduz os coeficientes continuamente, sem zer√°-los). A penalidade L1 for√ßa a solu√ß√£o a se encontrar em pontos esparsos no espa√ßo de par√¢metros, zerando os coeficientes menos relevantes [^4.4.3]. $\blacksquare$

**Corol√°rio 3:** *A esparsidade induzida pela penalidade L1 facilita a interpretabilidade do modelo, pois apenas as vari√°veis mais relevantes permanecem no modelo final.* Isso ocorre porque os coeficientes de vari√°veis irrelevantes s√£o for√ßados a zero, simplificando a an√°lise e a compreens√£o dos fatores preditivos [^4.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: As penalidades L1 e L2 podem ser combinadas no **Elastic Net** para tirar proveito da sele√ß√£o de vari√°veis da L1 e da estabilidade da L2, conforme discutido em [^4.5].

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Perceptron Algorithm"
        direction TB
        A["Initialize Hyperplane"] --> B["For each misclassified point x_i"]
        B --> C["Update weights w = w + Œ∑ * y_i * x_i"]
        C --> D["Iterate until convergence or max iterations"]
        D --> E["Final Hyperplane"]
    end
```

A ideia de **hiperplanos separadores** surge do conceito de tentar encontrar uma fronteira linear que separe as classes da maneira mais eficaz poss√≠vel [^4.5.2]. O objetivo √© n√£o apenas separar as classes, mas tamb√©m maximizar a margem de separa√ß√£o, ou seja, a dist√¢ncia entre o hiperplano e os pontos mais pr√≥ximos de cada classe.  Esta abordagem leva ao problema de encontrar um hiperplano √≥timo que maximize esta margem, usando uma formula√ß√£o que pode ser resolvida atrav√©s da otimiza√ß√£o de uma fun√ß√£o dual de Wolfe [^4.5.2].

O algoritmo do **Perceptron**, proposto por Rosenblatt, √© um algoritmo iterativo que busca encontrar um hiperplano separador [^4.5.1]. O algoritmo come√ßa com um hiperplano aleat√≥rio e, iterativamente, ajusta os par√¢metros do hiperplano com base nas amostras de treinamento que s√£o classificadas incorretamente. Se os dados forem linearmente separ√°veis, o algoritmo do Perceptron garante converg√™ncia para uma solu√ß√£o que separa as classes. No entanto, se os dados n√£o forem linearmente separ√°veis, o algoritmo n√£o convergir√°. A solu√ß√£o final depende da inicializa√ß√£o e pode n√£o ser √∫nica [^4.5.1]. A formula√ß√£o do perceptron pode ser vista como um caso espec√≠fico da otimiza√ß√£o de uma fun√ß√£o de custo que busca minimizar a dist√¢ncia de amostras classificadas incorretamente ao hiperplano.

> üí° **Exemplo Num√©rico:**
>
> Vamos ilustrar o funcionamento do perceptron com um exemplo simplificado. Suponha que temos os seguintes dados e seus r√≥tulos:
>
> | Observa√ß√£o (x1, x2) | Classe (y) |
> |--------------------|------------|
> | (1, 1)             | 1          |
> | (2, 2)             | 1          |
> | (1, 3)             | -1         |
> | (2, 1)             | -1         |
>
> Inicializamos o vetor de pesos $w = [0, 0, 0]^T$ (incluindo o bias). A fun√ß√£o de decis√£o √© $f(x) = w_0 + w_1x_1 + w_2x_2$.
>
> **Itera√ß√£o 1:**
>
> - Ponto (1, 1): $f(1,1) = 0 + 0(1) + 0(1) = 0$. Classificado incorretamente (deveria ser 1).
> - Atualiza√ß√£o dos pesos: $w = w + \eta * y * [1, x_1, x_2] = [0, 0, 0] + 1 * 1 * [1, 1, 1] = [1, 1, 1]$ (assumindo $\eta = 1$).
>
> **Itera√ß√£o 2:**
>
> - Ponto (2, 2): $f(2,2) = 1 + 1(2) + 1(2) = 5$. Classificado corretamente.
> - Ponto (1, 3): $f(1,3) = 1 + 1(1) + 1(3) = 5$. Classificado incorretamente (deveria ser -1).
> - Atualiza√ß√£o dos pesos: $w = [1, 1, 1] + 1 * (-1) * [1, 1, 3] = [0, 0, -2]$.
>
> **Itera√ß√£o 3:**
>
> - Ponto (2, 1): $f(2,1) = 0 + 0(2) - 2(1) = -2$. Classificado corretamente.
> - Ponto