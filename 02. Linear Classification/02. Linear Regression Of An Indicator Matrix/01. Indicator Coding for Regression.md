## TÃ­tulo Conciso: ClassificaÃ§Ã£o Linear, SeleÃ§Ã£o de VariÃ¡veis e RegularizaÃ§Ã£o

```mermaid
graph LR
    A["Linear Classification Methods"] --> B["LDA"]
    A --> C["Logistic Regression"]
    A --> D["Hyperplanes"]
    A --> E["Variable Selection"]
    A --> F["Regularization"]
    B --> E
    B --> F
    C --> E
    C --> F
    D --> E
    D --> F
```

### IntroduÃ§Ã£o

A classificaÃ§Ã£o Ã© um problema central em aprendizado de mÃ¡quina e estatÃ­stica, onde o objetivo Ã© atribuir uma classe ou categoria a uma dada entrada. MÃ©todos lineares de classificaÃ§Ã£o sÃ£o uma classe fundamental de algoritmos que utilizam fronteiras de decisÃ£o lineares para separar as classes [^4.1]. Esses mÃ©todos, apesar de sua simplicidade, sÃ£o amplamente utilizados devido Ã  sua eficiÃªncia computacional, interpretabilidade e bom desempenho em muitos cenÃ¡rios prÃ¡ticos. Ao longo deste capÃ­tulo, exploraremos vÃ¡rias tÃ©cnicas para construir modelos de classificaÃ§Ã£o linear, com foco em mÃ©todos estatÃ­sticos e de aprendizado de mÃ¡quina que utilizam **Linear Discriminant Analysis (LDA)**, **Logistic Regression**, e **hiperplanos separadores**, bem como tÃ©cnicas de seleÃ§Ã£o de variÃ¡veis e regularizaÃ§Ã£o para melhorar a generalizaÃ§Ã£o e robustez desses modelos [^4.1]. Abordaremos desde a regressÃ£o linear em matrizes de indicadores [^4.2] atÃ© a aplicaÃ§Ã£o de tÃ©cnicas de regularizaÃ§Ã£o L1 [^4.4.4], sempre buscando aprofundar tanto a teoria quanto os algoritmos.

### Conceitos Fundamentais

**Conceito 1: O Problema de ClassificaÃ§Ã£o e MÃ©todos Lineares**

O problema de classificaÃ§Ã£o consiste em, dado um conjunto de dados de entrada $x \in \mathbb{R}^p$, atribuir a este um rÃ³tulo de classe $G$ pertencente a um conjunto discreto de classes $G=\{1, 2, \ldots, K\}$. MÃ©todos lineares de classificaÃ§Ã£o assumem que as fronteiras de decisÃ£o entre as classes podem ser representadas por **hiperplanos** [^4.1]. Isto significa que cada classe Ã© delimitada por uma combinaÃ§Ã£o linear das variÃ¡veis de entrada. Uma funÃ§Ã£o discriminante linear $f(x) = \beta_0 + \beta^Tx$ Ã© utilizada para modelar a decisÃ£o de classe, onde $\beta_0$ Ã© o intercepto e $\beta$ sÃ£o os coeficientes. O uso de modelos lineares pode introduzir viÃ©s, mas geralmente apresentam uma variÃ¢ncia menor em comparaÃ§Ã£o com modelos nÃ£o-lineares mais complexos. Em situaÃ§Ãµes onde as classes sÃ£o bem separadas por uma fronteira linear, essa abordagem linear Ã© bastante eficaz. Por exemplo, ao modelar um problema de classificaÃ§Ã£o binÃ¡ria, podemos ter uma funÃ§Ã£o $f(x)$ onde, se $f(x) > 0$, atribuÃ­mos o rÃ³tulo $G=1$ e, caso contrÃ¡rio, atribuÃ­mos $G=2$ [^4.1].

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Considere um problema de classificaÃ§Ã£o binÃ¡ria com duas variÃ¡veis de entrada $x_1$ e $x_2$. Suponha que apÃ³s o treinamento de um modelo linear, obtivemos a funÃ§Ã£o discriminante: $f(x) = -1 + 2x_1 + 1x_2$.
>
> Para um ponto de dados $x = (1, 2)$, temos $f(1, 2) = -1 + 2(1) + 1(2) = 3$. Como $f(x) > 0$, este ponto seria classificado como pertencente Ã  classe 1.
>
> Para outro ponto $x = (0, 0)$, temos $f(0, 0) = -1 + 2(0) + 1(0) = -1$. Como $f(x) < 0$, este ponto seria classificado como pertencente Ã  classe 2.
>
> A fronteira de decisÃ£o Ã© o hiperplano (neste caso, uma linha) definido por $f(x) = 0$, ou seja, $-1 + 2x_1 + 1x_2 = 0$, que pode ser reescrito como $x_2 = 1 - 2x_1$.
>
> ```mermaid
>  graph LR
>      A["x=(1,2), f(x)=3"] -->|Class 1| C
>      B["x=(0,0), f(x)=-1"] -->|Class 2| D
>      C["Class 1"]
>      D["Class 2"]
>      E["Decision Boundary: x2 = 1 - 2x1"]
>      E --> F["Points above boundary are class 1"]
>      E --> G["Points below boundary are class 2"]
> ```

**Lemma 1:** *A fronteira de decisÃ£o entre duas classes usando uma funÃ§Ã£o discriminante linear Ã© sempre um hiperplano*. A prova consiste em mostrar que o conjunto de pontos $x$ onde $f_k(x) = f_l(x)$ (funÃ§Ãµes discriminantes das classes $k$ e $l$) resulta em uma equaÃ§Ã£o linear que define um hiperplano [^4.1]. Ou seja, dado $f_k(x) = \beta_{k0} + \beta_k^T x$ e $f_l(x) = \beta_{l0} + \beta_l^T x$, a igualdade $\beta_{k0} + \beta_k^T x = \beta_{l0} + \beta_l^T x$ pode ser reescrita como $(\beta_{k0} - \beta_{l0}) + (\beta_k - \beta_l)^T x = 0$, que Ã© a equaÃ§Ã£o de um hiperplano. $\blacksquare$

**Conceito 2: Linear Discriminant Analysis (LDA)**

**LDA** Ã© um mÃ©todo clÃ¡ssico para classificaÃ§Ã£o que assume que cada classe segue uma distribuiÃ§Ã£o gaussiana multivariada com a mesma matriz de covariÃ¢ncia $\Sigma$ [^4.3]. A funÃ§Ã£o discriminante para cada classe $k$ Ã© dada por:

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log \pi_k
$$

onde $\mu_k$ Ã© o vetor de mÃ©dias para a classe $k$ e $\pi_k$ Ã© a probabilidade a priori da classe $k$ [^4.3]. A decisÃ£o de classe Ã© dada por $\hat{G}(x) = \arg\max_k \delta_k(x)$. A igualdade de matrizes de covariÃ¢ncia garante que as fronteiras de decisÃ£o entre as classes sejam lineares, o que Ã© uma propriedade fundamental do LDA [^4.3]. A suposiÃ§Ã£o de normalidade dos dados Ã© uma limitaÃ§Ã£o do LDA, mas na prÃ¡tica, ele frequentemente funciona bem, mesmo quando essa suposiÃ§Ã£o nÃ£o Ã© estritamente vÃ¡lida.

```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction LR
        A["Î´_k(x)"] --> B["x^T Î£â»Â¹ Î¼_k"]
        A --> C["- 1/2 Î¼_k^T Î£â»Â¹ Î¼_k"]
        A --> D["log Ï€_k"]
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que temos duas classes, $G=1$ e $G=2$, com as seguintes caracterÃ­sticas:
> - $\mu_1 = [2, 2]^T$ (mÃ©dia da classe 1)
> - $\mu_2 = [4, 4]^T$ (mÃ©dia da classe 2)
> - $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$ (matriz de covariÃ¢ncia comum)
> - $\pi_1 = 0.6$ (probabilidade a priori da classe 1)
> - $\pi_2 = 0.4$ (probabilidade a priori da classe 2)
>
> Para um ponto de dado $x = [3, 3]^T$, calculamos as funÃ§Ãµes discriminantes:
>
> 1.  $\Sigma^{-1} = \frac{1}{0.75} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$
>
> 2.  $\delta_1(x) = x^T \Sigma^{-1} \mu_1 - \frac{1}{2} \mu_1^T \Sigma^{-1} \mu_1 + \log \pi_1 = [3,3] \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 2 \\ 2 \end{bmatrix} - \frac{1}{2} [2,2] \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 2 \\ 2 \end{bmatrix} + \log(0.6) = 4 - 4 + \log(0.6) = -0.51$
>
> 3.  $\delta_2(x) = x^T \Sigma^{-1} \mu_2 - \frac{1}{2} \mu_2^T \Sigma^{-1} \mu_2 + \log \pi_2 = [3,3] \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 4 \\ 4 \end{bmatrix} - \frac{1}{2} [4,4] \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 4 \\ 4 \end{bmatrix} + \log(0.4) = 16 - 16 + \log(0.4) = -0.92$
>
> Como $\delta_1(x) > \delta_2(x)$, o ponto $x = [3, 3]^T$ seria classificado como pertencente Ã  classe 1.

**CorolÃ¡rio 1:** *A fronteira de decisÃ£o entre classes no LDA Ã© um hiperplano.* Isto decorre da forma linear das funÃ§Ãµes discriminantes $\delta_k(x)$, pois ao igualar as funÃ§Ãµes de duas classes $k$ e $l$, temos: $\delta_k(x) = \delta_l(x)$, que leva a uma equaÃ§Ã£o linear em $x$, definindo um hiperplano [^4.3.1].

**Conceito 3: Logistic Regression**

**Logistic Regression** Ã© outro mÃ©todo popular de classificaÃ§Ã£o linear que modela a probabilidade de uma classe usando a funÃ§Ã£o logÃ­stica [^4.4]. Para o caso de duas classes, a probabilidade de pertencer Ã  classe 1 Ã© modelada como:

$$
P(G=1|X=x) = \frac{e^{\beta_0 + \beta^T x}}{1 + e^{\beta_0 + \beta^T x}}
$$

O logit (log-odds) dessa probabilidade Ã© uma funÃ§Ã£o linear de $x$:

$$
\log \left(\frac{P(G=1|X=x)}{1 - P(G=1|X=x)}\right) = \beta_0 + \beta^T x
$$

Os parÃ¢metros $\beta_0$ e $\beta$ sÃ£o estimados maximizando a verossimilhanÃ§a dos dados de treinamento [^4.4.1].  A logistic regression nÃ£o assume distribuiÃ§Ã£o gaussiana para os dados de entrada, sendo mais flexÃ­vel que o LDA em relaÃ§Ã£o a essa suposiÃ§Ã£o [^4.4.2]. A principal diferenÃ§a entre LDA e Logistic Regression reside na maneira como os coeficientes sÃ£o estimados: LDA usa momentos dos dados (mÃ©dias e covariÃ¢ncias) enquanto a regressÃ£o logÃ­stica utiliza maximizaÃ§Ã£o da verossimilhanÃ§a [^4.4.1]. Em cenÃ¡rios onde as classes sÃ£o linearmente separÃ¡veis, ambas as abordagens podem apresentar desempenhos similares, conforme observado em [^4.5].

```mermaid
graph LR
    subgraph "Logistic Regression Model"
        direction LR
        A["P(G=1|X=x)"] --> B["exp(Î²_0 + Î²^T x)"]
        C["1 + exp(Î²_0 + Î²^T x)"]
        B --> D["Fraction"]
        C --> D
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Considere um modelo de regressÃ£o logÃ­stica com $\beta_0 = -2$, $\beta_1 = 1$ e $\beta_2 = 0.5$. A probabilidade de um ponto $x = [x_1, x_2]^T$ pertencer Ã  classe 1 Ã© dada por:
>
> $P(G=1|X=x) = \frac{e^{-2 + x_1 + 0.5x_2}}{1 + e^{-2 + x_1 + 0.5x_2}}$
>
> Para o ponto $x = [3, 2]$, temos:
>
> $P(G=1|X=[3,2]) = \frac{e^{-2 + 3 + 0.5(2)}}{1 + e^{-2 + 3 + 0.5(2)}} = \frac{e^{2}}{1 + e^{2}} \approx 0.88$
>
> Portanto, hÃ¡ uma probabilidade de aproximadamente 88% de que este ponto pertenÃ§a Ã  classe 1.
>
> Para o ponto $x = [0, 0]$, temos:
>
> $P(G=1|X=[0,0]) = \frac{e^{-2 + 0 + 0.5(0)}}{1 + e^{-2 + 0 + 0.5(0)}} = \frac{e^{-2}}{1 + e^{-2}} \approx 0.12$
>
> Neste caso, a probabilidade de pertencer Ã  classe 1 Ã© de apenas 12%, sendo mais provÃ¡vel que pertenÃ§a Ã  classe 2.
>
> A fronteira de decisÃ£o (onde a probabilidade Ã© 0.5) Ã© definida por $-2 + x_1 + 0.5x_2 = 0$, ou seja $x_2 = 4 - 2x_1$.
>
> ```mermaid
> graph LR
> A["x=[3,2], P(G=1|X)=0.88"] -->|High Probability of Class 1| C
> B["x=[0,0], P(G=1|X)=0.12"] -->|Low Probability of Class 1| D
> C["Class 1"]
> D["Class 2"]
> E["Decision Boundary: x2 = 4 - 2x1"]
> E --> F["Points above boundary are more likely class 1"]
> E --> G["Points below boundary are more likely class 2"]
> ```

> âš ï¸ **Nota Importante**: A logistic regression Ã© uma abordagem mais flexÃ­vel que o LDA, jÃ¡ que nÃ£o assume distribuiÃ§Ãµes gaussianas para os dados de entrada. [^4.4.1]

> â— **Ponto de AtenÃ§Ã£o**: Em problemas com classes desbalanceadas, Ã© crucial ajustar as penalidades ou usar outras tÃ©cnicas para evitar o viÃ©s do modelo em direÃ§Ã£o Ã  classe majoritÃ¡ria [^4.4.2].

> âœ”ï¸ **Destaque**: Tanto LDA quanto Logistic Regression resultam em fronteiras de decisÃ£o lineares, porÃ©m os mÃ©todos de estimaÃ§Ã£o de parÃ¢metros sÃ£o distintos, e cada um pode ser mais adequado dependendo dos dados e do problema [^4.5].

### RegressÃ£o Linear e MÃ­nimos Quadrados para ClassificaÃ§Ã£o

```mermaid
graph LR
    subgraph "Indicator Regression for Classification"
        direction LR
        A["Input Data"] --> B["Indicator Matrix Y"]
        B --> C["Linear Regression: f_k(x) = Î²_k0 + Î²_k^T x"]
        C --> D["Classification: argmax_k f_k(x)"]
    end
```

A **regressÃ£o linear** pode ser adaptada para problemas de classificaÃ§Ã£o atravÃ©s do uso de uma **matriz de indicadores** [^4.2]. Nesta abordagem, cada classe $k$ Ã© representada por um vetor indicador $Y_k$, onde $Y_k = 1$ se a observaÃ§Ã£o pertence Ã  classe $k$, e $Y_k = 0$ caso contrÃ¡rio [^4.2]. Assim, para um problema com $K$ classes, teremos uma matriz resposta $Y$ de dimensÃ£o $N \times K$, onde $N$ Ã© o nÃºmero de observaÃ§Ãµes. A regressÃ£o linear Ã© entÃ£o aplicada a cada coluna de $Y$, obtendo-se uma funÃ§Ã£o $f_k(x) = \beta_{k0} + \beta_k^T x$ para cada classe. A observaÃ§Ã£o $x$ Ã© entÃ£o classificada para a classe $k$ que apresentar o maior valor de $f_k(x)$ [^4.2].

Este mÃ©todo, embora simples, tem algumas limitaÃ§Ãµes. Uma delas Ã© que as estimativas $f_k(x)$ podem ser negativas ou maiores que 1, o que dificulta a interpretaÃ§Ã£o como probabilidades. AlÃ©m disso, quando as classes sÃ£o sobrepostas ou apresentam estruturas complexas, a regressÃ£o linear pode ter um desempenho inferior aos mÃ©todos que modelam explicitamente a distribuiÃ§Ã£o de classes [^4.2]. Outra limitaÃ§Ã£o notÃ¡vel Ã© o "masking problem" que ocorre quando uma classe intermediÃ¡ria Ã© completamente ignorada durante a classificaÃ§Ã£o, levando a uma mÃ¡ representaÃ§Ã£o das classes pelos mÃ©todos [^4.2].

Apesar dessas limitaÃ§Ãµes, a regressÃ£o de indicadores pode ser Ãºtil em certos cenÃ¡rios onde o objetivo principal Ã© encontrar uma fronteira de decisÃ£o linear e a interpretabilidade das probabilidades nÃ£o Ã© essencial. AlÃ©m disso, sob certas condiÃ§Ãµes, as projeÃ§Ãµes nos hiperplanos de decisÃ£o gerados por regressÃ£o linear e discriminantes lineares podem ser equivalentes [^4.3], conforme detalhado em [^4.2].

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Considere um problema de classificaÃ§Ã£o com trÃªs classes e duas variÃ¡veis de entrada. Temos as seguintes observaÃ§Ãµes e seus rÃ³tulos:
>
> | ObservaÃ§Ã£o (x1, x2) | Classe |
> |--------------------|--------|
> | (1, 1)             | 1      |
> | (2, 1)             | 1      |
> | (1, 2)             | 2      |
> | (2, 2)             | 2      |
> | (3, 1)             | 3      |
> | (3, 2)             | 3      |
>
> A matriz de indicadores $Y$ serÃ¡:
>
> | Classe 1 | Classe 2 | Classe 3 |
> |----------|----------|----------|
> | 1        | 0        | 0        |
> | 1        | 0        | 0        |
> | 0        | 1        | 0        |
> | 0        | 1        | 0        |
> | 0        | 0        | 1        |
> | 0        | 0        | 1        |
>
> Aplicando a regressÃ£o linear para cada coluna da matriz $Y$, podemos obter as funÃ§Ãµes de decisÃ£o para cada classe:
>
> $f_1(x) = \beta_{10} + \beta_{11}x_1 + \beta_{12}x_2$
> $f_2(x) = \beta_{20} + \beta_{21}x_1 + \beta_{22}x_2$
> $f_3(x) = \beta_{30} + \beta_{31}x_1 + \beta_{32}x_2$
>
> Suponha que, apÃ³s a regressÃ£o, obtemos:
>
> $f_1(x) = 0.8 - 0.2x_1 + 0.1x_2$
> $f_2(x) = -0.1 + 0.1x_1 + 0.7x_2$
> $f_3(x) = -0.2 + 0.5x_1 - 0.3x_2$
>
> Para classificar um novo ponto $x = (2, 1.5)$, calculamos os valores das funÃ§Ãµes:
>
> $f_1(2, 1.5) = 0.8 - 0.2(2) + 0.1(1.5) = 0.55$
> $f_2(2, 1.5) = -0.1 + 0.1(2) + 0.7(1.5) = 1.15$
> $f_3(2, 1.5) = -0.2 + 0.5(2) - 0.3(1.5) = 0.35$
>
> Como $f_2(2, 1.5)$ Ã© o maior valor, o ponto $x = (2, 1.5)$ seria classificado como pertencente Ã  classe 2.

**Lemma 2:** *Em um problema de classificaÃ§Ã£o com duas classes, a direÃ§Ã£o dos coeficientes obtida por regressÃ£o linear em uma codificaÃ§Ã£o 1/-1 Ã© proporcional Ã  direÃ§Ã£o da funÃ§Ã£o discriminante do LDA.* Isto pode ser demonstrado mostrando que os coeficientes da regressÃ£o linear e os coeficientes do LDA sÃ£o colineares [^4.2]. $\blacksquare$

**CorolÃ¡rio 2:** *Quando as classes sÃ£o equiprovÃ¡veis e a matriz de covariÃ¢ncia Ã© esfÃ©rica ($\Sigma = \sigma^2 I$), a regressÃ£o linear de indicadores e o LDA retornam a mesma fronteira de decisÃ£o.* Sob essas condiÃ§Ãµes, as estimativas do LDA e da regressÃ£o linear sÃ£o alinhadas, resultando na mesma separaÃ§Ã£o das classes [^4.3].

Em relaÃ§Ã£o Ã s limitaÃ§Ãµes, conforme apontado em [^4.4], a regressÃ£o logÃ­stica pode fornecer estimativas de probabilidade mais estÃ¡veis, enquanto a regressÃ£o de indicadores pode levar a extrapolaÃ§Ãµes fora do intervalo [0,1]. Entretanto, hÃ¡ situaÃ§Ãµes em que a regressÃ£o de indicadores, de acordo com [^4.2], Ã© suficiente e atÃ© mesmo vantajosa quando o objetivo principal Ã© a fronteira de decisÃ£o linear.

### MÃ©todos de SeleÃ§Ã£o de VariÃ¡veis e RegularizaÃ§Ã£o em ClassificaÃ§Ã£o

```mermaid
graph LR
    subgraph "Regularization in Logistic Regression"
        direction TB
        A["Logistic Regression Loss"] --> B["Without Regularization"]
        A --> C["With L1 Regularization"]
        A --> D["With L2 Regularization"]
        C --> E["Sparsity"]
        D --> F["Stability"]
    end
```

**SeleÃ§Ã£o de variÃ¡veis** e **regularizaÃ§Ã£o** sÃ£o tÃ©cnicas cruciais para melhorar o desempenho e a interpretabilidade de modelos de classificaÃ§Ã£o [^4.5]. Em problemas com um nÃºmero elevado de variÃ¡veis ($p$), muitas podem ser irrelevantes ou redundantes, levando a modelos complexos e com alto risco de *overfitting*.  A **regularizaÃ§Ã£o** adiciona um termo de penalidade Ã  funÃ§Ã£o de custo do modelo, que forÃ§a os coeficientes a serem menores ou a se tornarem zero, reduzindo a complexidade do modelo e melhorando a capacidade de generalizaÃ§Ã£o [^4.5].

Na **regressÃ£o logÃ­stica**, a regularizaÃ§Ã£o pode ser introduzida na funÃ§Ã£o de verossimilhanÃ§a, como ilustrado abaixo:

$$
\text{max}_{\beta_0, \beta} \left[ \sum_{i=1}^N \left( y_i (\beta_0 + \beta^T x_i) - \log(1 + e^{\beta_0 + \beta^T x_i}) \right) - \lambda \sum_{j=1}^p |\beta_j| \right]
$$

Aqui, $\lambda$ Ã© o parÃ¢metro de regularizaÃ§Ã£o e o termo $\sum_{j=1}^p |\beta_j|$ Ã© a penalidade **L1** (lasso), que induz esparsidade nos coeficientes, ou seja, faz com que alguns coeficientes sejam exatamente zero, realizando seleÃ§Ã£o de variÃ¡veis [^4.4.4]. A penalidade **L2** (ridge), que penaliza a soma dos quadrados dos coeficientes, tambÃ©m pode ser usada para estabilizar o modelo e reduzir a variÃ¢ncia:

$$
\text{max}_{\beta_0, \beta} \left[ \sum_{i=1}^N \left( y_i (\beta_0 + \beta^T x_i) - \log(1 + e^{\beta_0 + \beta^T x_i}) \right) - \lambda \sum_{j=1}^p \beta_j^2 \right]
$$

A escolha entre L1 e L2, ou uma combinaÃ§Ã£o das duas (Elastic Net), depende da aplicaÃ§Ã£o e das propriedades desejadas do modelo [^4.5].

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que temos um modelo de regressÃ£o logÃ­stica com 5 variÃ¡veis ($x_1, x_2, x_3, x_4, x_5$). ApÃ³s o treinamento sem regularizaÃ§Ã£o, obtivemos os seguintes coeficientes:
>
> $\beta = [1.5, -0.8, 2.2, 0.5, -1.1]^T$.
>
> Agora, aplicamos a regularizaÃ§Ã£o L1 (Lasso) com $\lambda = 0.8$. ApÃ³s o treinamento com regularizaÃ§Ã£o L1, os coeficientes podem se tornar:
>
> $\beta_{L1} = [1.0, 0.0, 1.5, 0.0, -0.6]^T$.
>
> Observe que os coeficientes $\beta_2$ e $\beta_4$ foram reduzidos a zero, indicando que as variÃ¡veis $x_2$ e $x_4$ foram consideradas menos relevantes pelo modelo regularizado.
>
> Se aplicarmos a regularizaÃ§Ã£o L2 (Ridge) com $\lambda = 0.8$, os coeficientes podem se tornar:
>
> $\beta_{L2} = [1.2, -0.6, 1.8, 0.4, -0.9]^T$.
>
> Note que os coeficientes foram reduzidos em magnitude, mas nenhum se tornou exatamente zero.
>
> Agora, vamos comparar o efeito da regularizaÃ§Ã£o L1 e L2 em um modelo real usando Python com `scikit-learn`.
>
> ```python
> import numpy as np
> import pandas as pd
> from sklearn.model_selection import train_test_split
> from sklearn.linear_model import LogisticRegression
> from sklearn.metrics import accuracy_score
> from sklearn.preprocessing import StandardScaler
>
> # Generate synthetic data for demonstration
> np.random.seed(42)
> n_samples = 200
> n_features = 10
> X = np.random.randn(n_samples, n_features)
> y = np.random.randint(0, 2, n_samples)
>
> # Split data
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Standardize data
> scaler = StandardScaler()
> X_train_scaled = scaler.fit_transform(X_train)
> X_test_scaled = scaler.transform(X_test)
>
> # Logistic Regression without regularization
> model_no_reg = LogisticRegression(penalty=None, solver='lbfgs', random_state=42)
> model_no_reg.fit(X_train_scaled, y_train)
> y_pred_no_reg = model_no_reg.predict(X_test_scaled)
> acc_no_reg = accuracy_score(y_test, y_pred_no_reg)
>
> # Logistic Regression with L1 regularization
> model_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=0.5, random_state=42)
> model_l1.fit(X_train_scaled, y_train)
> y_pred_l1 = model_l1.predict(X_test_scaled)
> acc_l1 = accuracy_score(y_test, y_pred_l1)
>
> # Logistic Regression with L2 regularization
> model_l2 = LogisticRegression(penalty='l2', solver='lbfgs', C=0.5, random_state=42)
> model_l2.fit(X_train_scaled, y_train)
> y_pred_l2 = model_l2.predict(X_test_scaled)
> acc_l2 = accuracy_score(y_test, y_pred_l2)
>
> # Results
> print(f"Accuracy without regularization: {acc_no_reg:.3f}")
> print(f"Accuracy with L1 regularization: {acc_l1:.3f}")
> print(f"Accuracy with L2 regularization: {acc_l2:.3f}")
>
> # Show coefficients
> coef_no_reg = model_no_reg.coef_[0]
> coef_l1 = model_l1.coef_[0]
> coef_l2 = model_l2.coef_[0]
>
> coef_df = pd.DataFrame({'No Reg': coef_no_reg, 'L1': coef_l1, 'L2': coef_l2})
> print("\nCoefficients:")
> print(coef_df)
>
> ```
>
> Este cÃ³digo gera dados sintÃ©ticos, treina modelos de regressÃ£o logÃ­stica com e sem regularizaÃ§Ã£o L1 e L2, e compara a acurÃ¡cia e os coeficientes resultantes.
>
> Os resultados mostrarÃ£o como a regularizaÃ§Ã£o L1 pode zerar alguns coeficientes, enquanto a regularizaÃ§Ã£o L2 reduz a magnitude de todos os coeficientes.

**Lemma 3:** *A penalidade L1 em regressÃ£o logÃ­stica promove esparsidade nos coeficientes.* Isso ocorre devido Ã  natureza da penalidade L1, que impÃµe uma taxa constante de decrÃ©scimo nos coeficientes conforme $\lambda$ aumenta, fazendo com que muitos coeficientes cheguem a zero [^4.4.4].

**Prova do Lemma 3:** A penalidade L1 adiciona um termo $|\beta_j|$ Ã  funÃ§Ã£o de custo. A derivada deste termo Ã© $\pm 1$ dependendo do sinal do coeficiente. Para um coeficiente nÃ£o nulo, a otimizaÃ§Ã£o faz com que o coeficiente reduza atÃ© que chegue a zero, dado que a penalidade L1 tem um comportamento linear na vizinhanÃ§a de $\beta_j=0$, diferentemente de uma penalidade L2 (que reduz os coeficientes continuamente, sem zerÃ¡-los). A penalidade L1 forÃ§a a soluÃ§Ã£o a se encontrar em pontos esparsos no espaÃ§o de parÃ¢metros, zerando os coeficientes menos relevantes [^4.4.3]. $\blacksquare$

**CorolÃ¡rio 3:** *A esparsidade induzida pela penalidade L1 facilita a interpretabilidade do modelo, pois apenas as variÃ¡veis mais relevantes permanecem no modelo final.* Isso ocorre porque os coeficientes de variÃ¡veis irrelevantes sÃ£o forÃ§ados a zero, simplificando a anÃ¡lise e a compreensÃ£o dos fatores preditivos [^4.4.5].

> âš ï¸ **Ponto Crucial**: As penalidades L1 e L2 podem ser combinadas no **Elastic Net** para tirar proveito da seleÃ§Ã£o de variÃ¡veis da L1 e da estabilidade da L2, conforme discutido em [^4.5].

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Perceptron Algorithm"
        direction TB
        A["Initialize Hyperplane"] --> B["For each misclassified point x_i"]
        B --> C["Update weights w = w + Î· * y_i * x_i"]
        C --> D["Iterate until convergence or max iterations"]
        D --> E["Final Hyperplane"]
    end
```

A ideia de **hiperplanos separadores** surge do conceito de tentar encontrar uma fronteira linear que separe as classes da maneira mais eficaz possÃ­vel [^4.5.2]. O objetivo Ã© nÃ£o apenas separar as classes, mas tambÃ©m maximizar a margem de separaÃ§Ã£o, ou seja, a distÃ¢ncia entre o hiperplano e os pontos mais prÃ³ximos de cada classe.  Esta abordagem leva ao problema de encontrar um hiperplano Ã³timo que maximize esta margem, usando uma formulaÃ§Ã£o que pode ser resolvida atravÃ©s da otimizaÃ§Ã£o de uma funÃ§Ã£o dual de Wolfe [^4.5.2].

O algoritmo do **Perceptron**, proposto por Rosenblatt, Ã© um algoritmo iterativo que busca encontrar um hiperplano separador [^4.5.1]. O algoritmo comeÃ§a com um hiperplano aleatÃ³rio e, iterativamente, ajusta os parÃ¢metros do hiperplano com base nas amostras de treinamento que sÃ£o classificadas incorretamente. Se os dados forem linearmente separÃ¡veis, o algoritmo do Perceptron garante convergÃªncia para uma soluÃ§Ã£o que separa as classes. No entanto, se os dados nÃ£o forem linearmente separÃ¡veis, o algoritmo nÃ£o convergirÃ¡. A soluÃ§Ã£o final depende da inicializaÃ§Ã£o e pode nÃ£o ser Ãºnica [^4.5.1]. A formulaÃ§Ã£o do perceptron pode ser vista como um caso especÃ­fico da otimizaÃ§Ã£o de uma funÃ§Ã£o de custo que busca minimizar a distÃ¢ncia de amostras classificadas incorretamente ao hiperplano.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Vamos ilustrar o funcionamento do perceptron com um exemplo simplificado. Suponha que temos os seguintes dados e seus rÃ³tulos:
>
> | ObservaÃ§Ã£o (x1, x2) | Classe (y) |
> |--------------------|------------|
> | (1, 1)             | 1          |
> | (2, 2)             | 1          |
> | (1, 3)             | -1         |
> | (2, 1)             | -1         |
>
> Inicializamos o vetor de pesos $w = [0, 0, 0]^T$ (incluindo o bias). A funÃ§Ã£o de decisÃ£o Ã© $f(x) = w_0 + w_1x_1 + w_2x_2$.
>
> **IteraÃ§Ã£o 1:**
>
> - Ponto (1, 1): $f(1,1) = 0 + 0(1) + 0(1) = 0$. Classificado incorretamente (deveria ser 1).
> - AtualizaÃ§Ã£o dos pesos: $w = w + \eta * y * [1, x_1, x_2] = [0, 0, 0] + 1 * 1 * [1, 1, 1] = [1, 1, 1]$ (assumindo $\eta = 1$).
>
> **IteraÃ§Ã£o 2:**
>
> - Ponto (2, 2): $f(2,2) = 1 + 1(2) + 1(2) = 5$. Classificado corretamente.
> - Ponto (1, 3): $f(1,3) = 1 + 1(1) + 1(3) = 5$. Classificado incorretamente (deveria ser -1).
> - AtualizaÃ§Ã£o dos pesos: $w = [1, 1, 1] + 1 * (-1) * [1, 1, 3] = [0, 0, -2]$.
>
> **IteraÃ§Ã£o 3:**
>
> - Ponto (2, 1): $f(2,1) = 0 + 0(2) - 2(1) = -2$. Classificado corretamente.
> - Ponto