## T√≠tulo Conciso: Classifica√ß√£o Linear, Sele√ß√£o de Vari√°veis e Regulariza√ß√£o

```mermaid
graph LR
    subgraph "Linear Classification Overview"
    direction TB
        A["Input Data 'X'"] --> B["Linear Model 'f(x)'"]
        B --> C["Target Matrix 'Y' (Identity)"]
        C --> D["Least Squares Optimization"]
        D --> E["Model Coefficients 'B'"]
        E --> F["Classification Decision: argmin ||f(x) - t_k||"]
    end
```

### Introdu√ß√£o

Este cap√≠tulo explora uma vis√£o simplificada e alternativa para entender a regress√£o linear aplicada √† classifica√ß√£o, focando no uso de uma **matriz identidade como alvo** e no ajuste por **m√≠nimos quadrados** [^4.2].  Esta perspectiva nos permite visualizar a classifica√ß√£o como um processo de aproxima√ß√£o de vetores, onde cada classe √© representada por um vetor √∫nico. Al√©m disso, analisaremos as limita√ß√µes dessa abordagem, especialmente o problema de **"masking" de classes** e a falta de restri√ß√µes nas estimativas para estarem entre 0 e 1 [^4.2]. Compararemos este m√©todo com outras abordagens, tais como **Linear Discriminant Analysis (LDA)** e **Logistic Regression**, que oferecem abordagens mais diretas para modelar as probabilidades das classes [^4.3], [^4.4]. Discutiremos tamb√©m t√©cnicas de **sele√ß√£o de vari√°veis e regulariza√ß√£o** para melhorar a robustez e a interpretabilidade dos modelos [^4.4.4], [^4.5]. O objetivo deste cap√≠tulo √© fornecer uma vis√£o concisa e abrangente dessa perspectiva alternativa sobre a regress√£o linear na classifica√ß√£o.

### Conceitos Fundamentais

**Conceito 1: Classifica√ß√£o com Matriz Identidade como Alvo**

Uma abordagem alternativa para a regress√£o linear na classifica√ß√£o consiste em definir *targets* (alvos) para cada classe usando uma matriz identidade $K \times K$, onde $K$ √© o n√∫mero de classes [^4.2]. Assim, a $k$-√©sima coluna da matriz identidade, $t_k$, representa o target para a classe $k$.  O objetivo passa a ser ajustar um modelo linear para cada observa√ß√£o $x_i$, de forma que a sa√≠da do modelo, $f(x_i)$, seja o mais pr√≥ximo poss√≠vel do target $t_k$ correspondente √† classe da observa√ß√£o $x_i$. Esse ajuste √© realizado por meio da minimiza√ß√£o da soma dos erros quadr√°ticos, o m√©todo dos m√≠nimos quadrados [^4.2]. A classifica√ß√£o √© ent√£o feita atribuindo $x$ √† classe cujo target √© o mais pr√≥ximo do vetor de sa√≠das $f(x)$, medido em termos da norma euclidiana.

> üí° **Exemplo Num√©rico:**
> Suponha que temos 3 classes ($K=3$). A matriz identidade $3 \times 3$ seria:
>
> $$
> I_3 = \begin{bmatrix}
> 1 & 0 & 0 \\
> 0 & 1 & 0 \\
> 0 & 0 & 1
> \end{bmatrix}
> $$
>
> Os targets para cada classe seriam:
>
> - Classe 1: $t_1 = \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}$
> - Classe 2: $t_2 = \begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix}$
> - Classe 3: $t_3 = \begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix}$
>
> Se o modelo linear produz uma sa√≠da $f(x) = \begin{bmatrix} 0.1 \\ 0.8 \\ 0.2 \end{bmatrix}$ para uma observa√ß√£o $x$, calcular√≠amos as dist√¢ncias euclidianas aos targets:
>
> - $||f(x) - t_1|| = \sqrt{(0.1-1)^2 + (0.8-0)^2 + (0.2-0)^2} = \sqrt{0.81 + 0.64 + 0.04} \approx 1.20$
> - $||f(x) - t_2|| = \sqrt{(0.1-0)^2 + (0.8-1)^2 + (0.2-0)^2} = \sqrt{0.01 + 0.04 + 0.04} \approx 0.30$
> - $||f(x) - t_3|| = \sqrt{(0.1-0)^2 + (0.8-0)^2 + (0.2-1)^2} = \sqrt{0.01 + 0.64 + 0.64} \approx 1.14$
>
> Classificar√≠amos $x$ como pertencente √† Classe 2, pois a dist√¢ncia a $t_2$ √© a menor.

**Lemma 1:** *O ajuste por m√≠nimos quadrados com targets definidos por matriz identidade √© equivalente √† regress√£o linear com matriz de indicadores.*

**Conceito 2: Ajuste por M√≠nimos Quadrados e a Regra de Decis√£o**

O ajuste por m√≠nimos quadrados busca minimizar a soma dos quadrados das diferen√ßas entre as sa√≠das do modelo e os *targets*. Matematicamente, isso √© expresso como:

```mermaid
graph LR
    subgraph "Least Squares Optimization"
        direction TB
        A["Minimize: Sum of Squared Errors"]
        B["Error: ||y_i - (1, x_i^T)B||¬≤"]
        A --> C["Objective: min_B ‚àë ||y_i - (1,x_i^T)B||¬≤"]
    end
```

onde $y_i$ √© o vetor *target* correspondente √† classe de $x_i$, $B$ √© a matriz de coeficientes e $f(x) = (1,x^T)B$ √© o vetor de sa√≠das do modelo. Ap√≥s o ajuste, a regra de decis√£o √© dada por:

$$
\hat{G}(x) = \arg \min_k ||f(x) - t_k||^2
$$

que atribui $x$ √† classe cujo vetor *target* √© o mais pr√≥ximo da sa√≠da do modelo [^4.2]. Essa regra de decis√£o √© equivalente √†quela utilizada na regress√£o linear com matriz de indicadores, onde se classifica $x$ para a classe com o maior valor da fun√ß√£o ajustada [^4.2].

> üí° **Exemplo Num√©rico:**
>
> Vamos supor que temos duas classes e duas observa√ß√µes, $x_1 = [2, 3]$ e $x_2 = [1, 1]$. As classes correspondentes s√£o $y_1 = [1, 0]$ (Classe 1) e $y_2 = [0, 1]$ (Classe 2), usando a matriz identidade como target. Precisamos adicionar um intercepto, ent√£o as entradas s√£o $x_1 = [1, 2, 3]$ e $x_2 = [1, 1, 1]$.
>
> A matriz de entradas $X$ e a matriz de targets $Y$ s√£o:
>
> $$
> X = \begin{bmatrix} 1 & 2 & 3 \\ 1 & 1 & 1 \end{bmatrix}, \quad Y = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}
> $$
>
> A matriz de coeficientes $B$ √© calculada por $B = (X^T X)^{-1} X^T Y$.
>
> **Passo 1:** Calcular $X^T X$
>
> $$
> X^T X = \begin{bmatrix} 1 & 1 \\ 2 & 1 \\ 3 & 1 \end{bmatrix} \begin{bmatrix} 1 & 2 & 3 \\ 1 & 1 & 1 \end{bmatrix} = \begin{bmatrix} 2 & 3 & 4 \\ 3 & 5 & 7 \\ 4 & 7 & 10 \end{bmatrix}
> $$
>
> **Passo 2:** Calcular $(X^T X)^{-1}$
>
> $$
> (X^T X)^{-1} = \begin{bmatrix} 5.5 & -3 & 0.5 \\ -3 & 2 & 1 \\ 0.5 & 1 & -0.5 \end{bmatrix}
> $$
>
> **Passo 3:** Calcular $X^T Y$
>
> $$
> X^T Y = \begin{bmatrix} 1 & 1 \\ 2 & 1 \\ 3 & 1 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 1 \\ 2 & 1 \\ 3 & 1 \end{bmatrix}
> $$
>
> **Passo 4:** Calcular $B = (X^T X)^{-1} X^T Y$
>
> $$
> B = \begin{bmatrix} 5.5 & -3 & 0.5 \\ -3 & 2 & 1 \\ 0.5 & 1 & -0.5 \end{bmatrix} \begin{bmatrix} 1 & 1 \\ 2 & 1 \\ 3 & 1 \end{bmatrix} = \begin{bmatrix} 0.5 & 3 \\ 1 & -2 \\ -0.5 & 1 \end{bmatrix}
> $$
>
> Agora, para uma nova observa√ß√£o, por exemplo, $x_{new} = [2, 2]$, adicionamos o intercepto, $x_{new} = [1, 2, 2]$. A sa√≠da do modelo √© $f(x_{new}) = x_{new}^T B$:
>
> $$
> f(x_{new}) = \begin{bmatrix} 1 & 2 & 2 \end{bmatrix} \begin{bmatrix} 0.5 & 3 \\ 1 & -2 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.5 & 1 \end{bmatrix}
> $$
>
> As dist√¢ncias para os targets s√£o:
>
> - $||f(x_{new}) - t_1|| = ||[1.5, 1] - [1, 0]|| = \sqrt{(1.5-1)^2 + (1-0)^2} = \sqrt{0.25 + 1} \approx 1.12$
> - $||f(x_{new}) - t_2|| = ||[1.5, 1] - [0, 1]|| = \sqrt{(1.5-0)^2 + (1-1)^2} = \sqrt{2.25 + 0} \approx 1.5$
>
> Classificar√≠amos $x_{new}$ como pertencente √† Classe 1, pois a dist√¢ncia a $t_1$ √© a menor.

**Corol√°rio 1:** *A regra de decis√£o baseada na matriz identidade como alvo √© equivalente √† regra de decis√£o da regress√£o linear com matriz de indicadores, sob o crit√©rio de m√≠nimos quadrados.*

**Conceito 3: Limita√ß√µes da Abordagem e a Necessidade de Alternativas**

Apesar da simplicidade dessa abordagem, ela compartilha as mesmas limita√ß√µes da regress√£o linear com matrizes de indicadores, tais como o problema do **"masking"** e a falta de restri√ß√£o das estimativas para estarem no intervalo [0,1] [^4.2]. Essas limita√ß√µes motivam o uso de m√©todos como LDA e Regress√£o Log√≠stica, que modelam a probabilidade das classes de forma mais direta [^4.3], [^4.4].

> ‚ö†Ô∏è **Nota Importante**: Embora a matriz identidade simplifique a formula√ß√£o do problema, ela n√£o resolve as limita√ß√µes inerentes √† regress√£o linear como classificador [^4.2].

> ‚ùó **Ponto de Aten√ß√£o**: O ajuste por m√≠nimos quadrados, embora computacionalmente eficiente, n√£o garante que as estimativas da fun√ß√£o de decis√£o se comportem como probabilidades [^4.2].

> ‚úîÔ∏è **Destaque**: Apesar de utilizar uma formula√ß√£o diferente, a abordagem com a matriz identidade como alvo leva aos mesmos resultados que a regress√£o linear com matriz de indicadores.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
 subgraph "Regression for Classification"
    direction TB
        subgraph "Indicator Matrix Regression"
          A["Input 'X'"] --> B["Indicator Matrix Encoding"]
          B --> C["Linear Regression 'f(x)'"]
        end
         subgraph "Identity Matrix Regression"
          D["Input 'X'"] --> E["Identity Matrix Targets"]
          E --> F["Linear Regression 'f(x)'"]
        end
        C & F --> G["Least Squares Optimization"]
        G --> H["Decision Rule: argmax f(x) or argmin ||f(x) - t_k||"]

    H --> I["Equivalent Results"]

 end
```

Na abordagem da regress√£o linear para classifica√ß√£o, utilizando a matriz identidade como alvo, o objetivo passa a ser encontrar os coeficientes que melhor aproximam o vetor de sa√≠das $f(x)$ do *target* apropriado $t_k$. Cada classe $k$ tem seu vetor alvo $t_k$ que corresponde √† coluna $k$ da matriz identidade de dimens√£o $K \times K$. Os coeficientes $\beta$ s√£o estimados usando o m√©todo dos m√≠nimos quadrados, que busca minimizar a soma dos erros quadr√°ticos:

$$
\min_B \sum_{i=1}^N ||y_i - (1, x_i^T)B ||^2
$$

onde $y_i$ √© o *target* para a observa√ß√£o $x_i$,  $(1, x_i^T)$ √© o vetor de entrada com intercepto adicionado, e $B$ √© a matriz de coeficientes a serem estimados. A classifica√ß√£o √© ent√£o realizada atribuindo uma nova observa√ß√£o $x$ √† classe $k$ cujo vetor *target* $t_k$ √© o mais pr√≥ximo de $f(x)$, ou seja:

$$
\hat{G}(x) = \arg \min_k ||f(x) - t_k ||^2
$$

Essa abordagem, embora conceitualmente diferente da regress√£o com matriz de indicadores, leva exatamente √† mesma solu√ß√£o e aos mesmos problemas (como o "masking problem" e a falta de garantia de que as estimativas estejam no intervalo [0,1]) quando se busca estimar as respostas usando a regra da m√°xima resposta [^4.2]. √â uma alternativa que fornece uma vis√£o simplificada do problema, facilitando a compreens√£o do m√©todo dos m√≠nimos quadrados em classifica√ß√£o.

**Lemma 2:** *O vetor de coeficientes obtido pela minimiza√ß√£o dos erros quadrados entre o target da matriz identidade e a estimativa da regress√£o linear √© equivalente ao vetor de coeficientes obtido pela regress√£o da matriz de indicadores usando o mesmo m√©todo.*

**Corol√°rio 2:** *A regra de decis√£o de classificar para a classe com o target mais pr√≥ximo √© equivalente √† regra de decis√£o da regress√£o de indicadores, que classifica para a classe com a maior sa√≠da ajustada.*

A abordagem com matriz identidade como target, vista como uma forma simplificada de regress√£o, compartilha as mesmas limita√ß√µes que a regress√£o linear com matriz de indicadores, como o problema do masking e a falta de calibra√ß√£o probabil√≠stica. M√©todos como LDA e Regress√£o Log√≠stica, ao modelarem probabilidades ou densidades, oferecem uma base te√≥rica mais s√≥lida para problemas de classifica√ß√£o [^4.3], [^4.4].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Impact"
        direction TB
        A["Linear Model"]
        B["L1 Regularization (Lasso)"]
        C["L2 Regularization (Ridge)"]
         D["L1+L2 Regularization (Elastic Net)"]
        A --> B
        A --> C
        A -->D
        B --> E["Feature Selection"]
        C --> F["Reduced Overfitting"]
        D --> G["Combined Benefit"]
       E & F & G -->H["Improved Generalization"]
    end
```

**Sele√ß√£o de vari√°veis** e **regulariza√ß√£o** s√£o t√©cnicas fundamentais para melhorar o desempenho de modelos lineares de classifica√ß√£o e mitigar os problemas de *overfitting*.  Em cen√°rios com muitas vari√°veis preditoras, a regulariza√ß√£o introduz um termo de penalidade na fun√ß√£o de custo, que restringe a magnitude dos coeficientes do modelo e, consequentemente, sua complexidade [^4.5].

Na **regress√£o log√≠stica**, a fun√ß√£o de custo regularizada pode ser expressa como:

$$
\max_{\beta_0, \beta} \left[ \sum_{i=1}^N \left( y_i (\beta_0 + \beta^T x_i) - \log(1 + e^{\beta_0 + \beta^T x_i}) \right) - \lambda P(\beta) \right]
$$

onde $P(\beta)$ √© o termo de penalidade e $\lambda$ √© o par√¢metro de regulariza√ß√£o. A penalidade **L1** (Lasso) √© dada por $P(\beta) = \sum_{j=1}^p |\beta_j|$, que promove a esparsidade dos coeficientes, selecionando as vari√°veis mais relevantes e "zerando" as menos importantes [^4.4.4]. A penalidade **L2** (Ridge) √© dada por $P(\beta) = \sum_{j=1}^p \beta_j^2$, que reduz a magnitude de todos os coeficientes, estabilizando o modelo e reduzindo o risco de *overfitting* [^4.5].

> üí° **Exemplo Num√©rico:**
> Vamos considerar um problema de regress√£o log√≠stica com duas vari√°veis preditoras, $x_1$ e $x_2$, e um intercepto. A fun√ß√£o de custo regularizada com penalidade L1 (Lasso) √©:
>
> $$
> \max_{\beta_0, \beta_1, \beta_2} \left[ \sum_{i=1}^N \left( y_i (\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2}) - \log(1 + e^{\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2}}) \right) - \lambda (|\beta_1| + |\beta_2|) \right]
> $$
>
> Suponha que, ap√≥s o ajuste do modelo com um $\lambda$ espec√≠fico, obtivemos os seguintes coeficientes: $\beta_0 = 0.5$, $\beta_1 = 2.0$ e $\beta_2 = 0.1$. Se aumentarmos o valor de $\lambda$, a penalidade L1 for√ßar√° alguns coeficientes a se aproximarem de zero.
>
> Por exemplo, com um $\lambda$ maior, poder√≠amos obter: $\beta_0 = 0.6$, $\beta_1 = 1.0$ e $\beta_2 = 0.0$. O coeficiente $\beta_2$ foi zerado, indicando que a vari√°vel $x_2$ √© menos importante para o modelo.
>
> Agora, para a penalidade L2 (Ridge), a fun√ß√£o de custo regularizada √©:
>
> $$
> \max_{\beta_0, \beta_1, \beta_2} \left[ \sum_{i=1}^N \left( y_i (\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2}) - \log(1 + e^{\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2}}) \right) - \lambda (\beta_1^2 + \beta_2^2) \right]
> $$
>
>  Com penalidade L2, ao aumentar $\lambda$, os coeficientes diminuem de magnitude, mas dificilmente se tornam exatamente zero. Usando os mesmos coeficientes iniciais ($\beta_0 = 0.5$, $\beta_1 = 2.0$ e $\beta_2 = 0.1$), um $\lambda$ maior poderia levar a: $\beta_0 = 0.55$, $\beta_1 = 1.2$ e $\beta_2 = 0.05$.
>
> A penalidade L1 promove a esparsidade, enquanto a penalidade L2 reduz a magnitude dos coeficientes, tornando o modelo mais est√°vel.

A regulariza√ß√£o √© essencial para construir modelos mais robustos que generalizem bem para novos dados, e a escolha entre L1, L2 ou uma combina√ß√£o de ambas (Elastic Net) depende do problema espec√≠fico.

**Lemma 3:** *A aplica√ß√£o da penalidade L1 em modelos de classifica√ß√£o, tais como a regress√£o log√≠stica, leva √† esparsidade dos coeficientes, selecionando as vari√°veis mais relevantes.*

**Prova do Lemma 3:** A penalidade L1 adiciona um termo linear em m√≥dulo na fun√ß√£o de custo, o que faz com que os coeficientes menos relevantes se tornem exatamente zero durante a otimiza√ß√£o. A derivada do termo L1 tem um valor constante em m√≥dulo, o que permite que coeficientes pequenos sejam zerados por completo [^4.4.3], [^4.4.4]. $\blacksquare$

**Corol√°rio 3:** *Modelos esparsos, resultantes da aplica√ß√£o da regulariza√ß√£o L1, apresentam uma melhor generaliza√ß√£o e s√£o menos suscet√≠veis ao problema de overfitting.*

> ‚ö†Ô∏è **Ponto Crucial**: A regulariza√ß√£o, seja L1 ou L2, √© fundamental para controlar a complexidade dos modelos lineares de classifica√ß√£o e melhorar sua capacidade de generaliza√ß√£o, al√©m de mitigar o risco de overfitting e problemas como o "masking" [^4.5].

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Separating Hyperplane"
        direction LR
         A["Data Points"] --> B["Initial Hyperplane"]
         B --> C["Classification Errors"]
         C --> D["Perceptron Update Rule"]
         D --> E["Adjusted Hyperplane"]
         E --> F["Minimizing Distance to Misclassified Points"]
        F --> G["Optimal Separating Hyperplane"]

        G --> H["Maximizing Margin"]
    end
```

A ideia de **hiperplanos separadores** surge da busca por uma fronteira linear que maximize a separa√ß√£o entre as classes, buscando, simultaneamente, minimizar o erro de classifica√ß√£o e garantir a robustez do modelo. O objetivo n√£o √© apenas separar as classes, mas tamb√©m maximizar a dist√¢ncia entre o hiperplano e as amostras mais pr√≥ximas de cada classe, o que √© definido como margem [^4.5.2].

O algoritmo do **Perceptron**, √© um m√©todo iterativo que busca um hiperplano separador com base nas amostras classificadas incorretamente no conjunto de treinamento [^4.5.1]. O Perceptron √© uma abordagem relativamente simples, mas pode n√£o garantir a maximiza√ß√£o da margem e nem a converg√™ncia para dados que n√£o s√£o linearmente separ√°veis [^4.5.1].  A busca por hiperplanos separadores pode ser vista como um problema de otimiza√ß√£o, onde o objetivo √© minimizar a dist√¢ncia das amostras ao hiperplano de separa√ß√£o.

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o bin√°ria com duas vari√°veis preditoras, $x_1$ e $x_2$. Temos duas classes, que representaremos por -1 e 1. Suponha que o hiperplano inicial seja dado por $w_0 + w_1 x_1 + w_2 x_2 = 0$, onde $w = [w_0, w_1, w_2]$.
>
> Inicialmente, os pesos podem ser definidos aleatoriamente, por exemplo, $w = [0.1, 0.2, -0.3]$. O algoritmo do Perceptron itera sobre os dados de treinamento e, para cada amostra classificada incorretamente, atualiza os pesos usando a regra:
>
> $$
> w_{new} = w_{old} + \eta y_i x_i
> $$
>
> onde $\eta$ √© a taxa de aprendizagem, $y_i$ √© a classe verdadeira da amostra $x_i$, e $x_i$ √© o vetor de entrada com o intercepto adicionado.
>
> Suponha que tenhamos a amostra $x = [1, 2]$ que pertence √† classe 1. O modelo inicialmente classifica essa amostra incorretamente.
>
> 1. **Classifica√ß√£o Inicial:** Calculamos o valor da fun√ß√£o de decis√£o: $0.1 + 0.2*1 - 0.3*2 = -0.3$. Como o resultado √© negativo, o modelo classifica $x$ como classe -1, o que √© incorreto.
> 2. **Atualiza√ß√£o dos Pesos:** Usando uma taxa de aprendizagem de $\eta = 0.1$, atualizamos os pesos:
> $$
> w_{new} = [0.1, 0.2, -0.3] + 0.1 * 1 * [1, 1, 2] = [0.2, 0.3, -0.1]
> $$
> 3. **Pr√≥xima Itera√ß√£o:** O algoritmo continua iterando sobre os dados de treinamento, ajustando os pesos at√© que todos os pontos sejam classificados corretamente (se os dados forem linearmente separ√°veis).
>
> Este processo iterativo busca um hiperplano que separe as classes, ajustando os pesos a cada erro de classifica√ß√£o.

**Teorema:** *O algoritmo do Perceptron converge para uma solu√ß√£o separadora em um n√∫mero finito de itera√ß√µes, desde que o conjunto de dados de treinamento seja linearmente separ√°vel*.

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**

A **Regra de Decis√£o Bayesiana** busca classificar uma observa√ß√£o $x$ na classe $k$ que maximize a probabilidade posterior $P(G=k|X=x)$ [^4.3]. Quando as distribui√ß√µes condicionais $P(X|G=k)$ s√£o Gaussianas com a mesma matriz de covari√¢ncia $\Sigma$, o Teorema de Bayes resulta em:

$$
P(G=k|X=x) = \frac{ \phi(x;\mu_k,\Sigma)\pi_k}{\sum_{l=1}^K \phi(x;\mu_l,\Sigma)\pi_l}
$$

onde $\phi(x;\mu_k,\Sigma)$ √© a fun√ß√£o densidade gaussiana, $\mu_k$ √© a m√©dia da classe $k$ e $\pi_k$ √© a probabilidade a priori da classe. O **LDA**, por sua vez, deriva suas fun√ß√µes discriminantes lineares diretamente dessas suposi√ß√µes, buscando otimizar a separa√ß√£o entre as classes no espa√ßo de caracter√≠sticas [^4.3].

```mermaid
graph LR
    subgraph "Bayesian vs LDA"
    direction TB
        subgraph "Bayes Decision Rule"
            A["Maximize Posterior Probability P(G=k|X=x)"]
            B["P(G=k|X=x) = 'phi(x;Œº_k,Œ£)œÄ_k / ‚àëphi(x;Œº_l,Œ£)œÄ_l'"]
        A-->B

        end

         subgraph "Linear Discriminant Analysis (LDA)"
             C["Derive Linear Discriminant Functions"]
             D["Optimize Class Separation"]
             C -->D
        end
    B --> E["Assumes Gaussian Classes with Equal Covariance 'Œ£'"]
    D --> E

     E --> F["Equivalent Decision Boundaries"]
    end
```

> üí° **Exemplo Num√©rico:**
>
> Suponha um problema com duas classes, onde as distribui√ß√µes de cada classe s√£o Gaussianas com m√©dias $\mu_1 = [1, 1]$ e $\mu_2 = [3, 3]$, e uma matriz de covari√¢ncia comum $\Sigma = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$. As probabilidades a priori s√£o $\pi_1 = 0.4$ e $\pi_2 = 0.6$.
>
> Um ponto de teste √© $x = [2, 2]$.
>
> 1. **Regra de Decis√£o Bayesiana:**
>    - Calculamos a densidade gaussiana para cada classe:
>    $$
>    \phi(x;\mu_k,\Sigma) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}} \exp\left(-\frac{1}{2}(x-\mu_k)^T\Sigma^{-1}(x-\mu_k)\right)
>    $$
>    - Para a classe 1:
>    $$
>    \phi(x;\mu_1,\Sigma) = \frac{1}{2\pi} \exp\left(-\frac{1}{2}([2,2]-[1,1])^T \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}^{-1} [2,2]-[1,1])\right) \approx \frac{1}{2\pi} \exp(-1) \approx 0.058
>    $$
>    - Para a classe 2:
>    $$
>    \phi(x;\mu_2,\Sigma) = \frac{1}{2\pi} \exp\left(-\frac{1}{2}([2,2]-[3,3])^T \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}^{-1} [2,2]-[3,3])\right) \approx \frac{1}{2\pi} \exp(-1) \approx 0.058
>    $$
>    - Calculamos as probabilidades posteriores:
>    $$
>    P(G=1|X=x) = \frac{0.058 * 0.4}{0.058 * 0.4 + 0.058 * 0.6} = 0.4
>    $$
>    $$
>    P(G=2|X=x) = \frac{0.058 * 0.6}{0.058 * 0.4 + 0.058 * 0.6} = 0.6
>    $$
>    - Classificamos $x$ como pertencente √† Classe 2, pois $P(G=2|X=x) > P(G=1|X=x)$.
>
> 2. **LDA:**
>   - LDA usa fun√ß√µes discriminantes lineares que s√£o equivalentes √†s probabilidades posteriores quando as covari√¢ncias s√£o iguais. O LDA levaria √† mesma decis√£o, classificando $x$ como Classe 2.

**Lemma 4:** *Sob a suposi√ß√£o de que as classes seguem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia, a regra de decis√£o Bayesiana e as fun√ß√µes discriminantes do LDA levam √† mesma fronteira de decis√£o linear.*

**Corol√°rio 4:** *A remo√ß√£o da restri√ß√£o de igualdade de covari√¢ncias no QDA leva a fronteiras de decis√£o quadr√°ticas (QDA) e n√£o mais a um hiperplano.*

> ‚ö†Ô∏è **Ponto Crucial**: A principal diferen√ßa est√° na forma de modelagem. A regra de decis√£o Bayesiana busca otimizar a probabilidade posterior, enquanto o LDA deriva sua regra a partir da modelagem da distribui√ß√£o gaussiana, assumindo a igualdade das matrizes de covari√¢ncia [^4.3].

### Conclus√£o

Neste cap√≠tulo, exploramos a aplica√ß√£o da regress√£o linear na classifica√ß√£o, com foco na vis√£o simplificada que utiliza a matriz identidade como alvo e o ajuste por m√≠nimos quadrados. Vimos como essa abordagem se conecta com a regress√£o linear em matrizes de indicadores e quais s√£o suas limita√ß√µes, particularmente o problema do "masking" e a falta de calibra√ß√£o probabil√≠stica. Analisamos tamb√©m a import√¢ncia da sele√ß√£o de vari√°veis e da regulariza√ß√£o para melhorar o desempenho dos modelos. A compara√ß√£o entre LDA e a regra de decis√£o Bayesiana, sob a suposi√ß√£o de distribui√ß√µes Gaussianas com covari√¢ncias iguais, forneceu um entendimento mais aprofundado das nuances desses m√©todos. Ao longo deste cap√≠tulo, procuramos oferecer uma base s√≥lida para a compreens√£o e aplica√ß√£o de modelos lineares em classifica√ß√£o, reconhecendo tanto suas vantagens quanto suas limita√ß√µes.

### Footnotes

[^4.1]: *In this chapter we revisit the classification problem and focus on linear methods for classification...There are several different ways in which linear decision boundaries can be found.*

[^4.2]: *In Chapter 2 we fit linear regression models to the class indicator variables, and classify to the largest fit...Linear inequalities in this space are quadratic inequalities in the original space.*

[^4.3]: *Decision theory for classification (Section 2.4) tells us that we need to know the class posteriors Pr(G|X) for optimal classification. Suppose fk(x) is the class-conditional density of X in class G = k, and let œÄŒ∫ be the prior probability of class k... Linear discriminant analysis (LDA) arises in the special case when we assume that the classes have a common covariance matrix Œ£k = Œ£.*

[^4.3.1]: *The decision boundary between each pair of classes k and l is described by a quadratic equation {x: Œ¥Œ∫(x) = Œ¥(x)}.*

[^4.3.3]: *In the special case when we assume that the classes have a common covariance matrix...When the classes are really Gaussian, then LDA is optimal*

[^4.4]: *The logistic regression model arises from the desire to model the posterior probabilities of the K classes via linear functions in x, while at the same time ensuring that they sum to one and remain in [0,1].*

[^4.4.1]: *Logistic regression models are usually fit by maximum likelihood... The logistic regression model is more general, in that it makes less assumptions.*

[^4.4.2]: *It is convenient to code the two-class gi via a 0/1 response Yi, where yi = 1 when gi = 1, and yi = 0 when gi = 2... Typically many models are fit in a search for a parsimonious model involving a subset of the variables.*

[^4.4.3]: *To maximize the log-likelihood, we set its derivatives to zero. These score equations are...To solve the score equations (4.21), we use the Newton-Raphson algorithm...*

[^4.4.4]: *The L1 penalty used in the lasso (Section 3.4.2) can be used for variable selection and shrinkage with any linear regression model...As with the lasso, we typically do not penalize the intercept term.*

[^4.5]: *Here we present an analysis of binary data to illustrate the traditional statistical use of the logistic regression model... With two classes there is a simple correspondence between linear discriminant analysis and classification by linear least squares, as in (4.5).*

[^4.5.1]: *The perceptron learning algorithm tries to find a separating hyperplane by minimizing the distance of misclassified points to the decision boundary.*

[^4.5.2]: *The optimal separating hyperplane separates the two classes and maximizes the distance to the closest point from either class... In light of (4.40), the constraints define an empty slab or margin around the linear decision boundary...*
