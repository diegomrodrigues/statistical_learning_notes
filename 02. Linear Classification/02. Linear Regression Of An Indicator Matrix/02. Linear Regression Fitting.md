## TÃ­tulo Conciso: ClassificaÃ§Ã£o Linear, SeleÃ§Ã£o de VariÃ¡veis e RegularizaÃ§Ã£o

```mermaid
graph LR
    subgraph "Classification Problem"
      A["Input Data 'x' âˆˆ â„áµ–"] --> B("Classification Model 'G(x)'")
      B --> C["Class Label 'G' âˆˆ {1, 2, ..., K}"]
      style A fill:#f9f,stroke:#333,stroke-width:2px
      style C fill:#ccf,stroke:#333,stroke-width:2px
    end
    subgraph "Linear Methods"
      direction TB
      D["Linear Discriminant Analysis (LDA)"]
      E["Logistic Regression"]
      F["Linear Regression (Indicator Matrix)"]
    end
    subgraph "Regularization and Variable Selection"
       direction LR
       G["Variable Selection"] --> H["Regularization Techniques"]
       H --> I["L1 (Lasso) Regularization"]
       H --> J["L2 (Ridge) Regularization"]
    end
    C --> D
    C --> E
    C --> F
    D --> G
    E --> G
    F --> G
```

### IntroduÃ§Ã£o

A classificaÃ§Ã£o, como um problema central em aprendizado de mÃ¡quina, envolve a atribuiÃ§Ã£o de rÃ³tulos a um conjunto de dados de entrada. MÃ©todos lineares sÃ£o frequentemente utilizados por sua simplicidade, eficiÃªncia computacional e interpretabilidade. Neste capÃ­tulo, vamos explorar o uso de **modelos lineares para classificaÃ§Ã£o**, comeÃ§ando pela **regressÃ£o linear** aplicada a **matrizes de indicadores**, que codificam as classes de forma numÃ©rica [^4.2]. AlÃ©m disso, vamos analisar outras abordagens fundamentais como **Linear Discriminant Analysis (LDA)** e **Logistic Regression**, que tambÃ©m geram fronteiras de decisÃ£o lineares, mas com diferentes bases teÃ³ricas e suposiÃ§Ãµes [^4.1]. Abordaremos tambÃ©m o uso de **hiperplanos separadores**, **seleÃ§Ã£o de variÃ¡veis** e tÃ©cnicas de **regularizaÃ§Ã£o**, que desempenham um papel crucial para aumentar a robustez e o desempenho dos modelos de classificaÃ§Ã£o [^4.4.4], [^4.5.2]. O objetivo deste capÃ­tulo Ã© apresentar uma anÃ¡lise detalhada desses mÃ©todos, explorando tanto os fundamentos teÃ³ricos quanto suas aplicaÃ§Ãµes prÃ¡ticas.

### Conceitos Fundamentais

**Conceito 1: O Problema de ClassificaÃ§Ã£o e Abordagens Lineares**

O problema de classificaÃ§Ã£o tem como objetivo construir um modelo preditivo $G(x)$ que mapeie um vetor de entrada $x \in \mathbb{R}^p$ para um rÃ³tulo de classe $G$, pertencente a um conjunto discreto $G = \{1, 2, \ldots, K\}$ [^4.1]. MÃ©todos lineares para classificaÃ§Ã£o assumem que as fronteiras de decisÃ£o entre as classes sÃ£o lineares, ou seja, podem ser representadas por hiperplanos no espaÃ§o de entrada [^4.1]. Essa suposiÃ§Ã£o simplifica o problema e permite a criaÃ§Ã£o de modelos que podem ser facilmente interpretados e computacionalmente eficientes. Uma funÃ§Ã£o discriminante linear Ã© dada por $f(x) = \beta_0 + \beta^T x$, onde $\beta_0$ Ã© o termo de intercepto e $\beta$ Ã© o vetor de coeficientes que definem a orientaÃ§Ã£o do hiperplano [^4.1]. A classificaÃ§Ã£o Ã© feita atribuindo $x$ Ã  classe com o maior valor da funÃ§Ã£o discriminante linear correspondente. Embora essa abordagem tenha suas limitaÃ§Ãµes (como a incapacidade de modelar fronteiras nÃ£o-lineares), ela oferece um ponto de partida sÃ³lido para muitos problemas de classificaÃ§Ã£o.

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Imagine um problema de classificaÃ§Ã£o binÃ¡ria com duas classes, onde temos duas features ($x_1$ e $x_2$). A funÃ§Ã£o discriminante linear pode ser $f(x) = 1 + 2x_1 - 1.5x_2$. Se tivermos um ponto $x = [2, 3]$, entÃ£o $f(x) = 1 + 2*2 - 1.5*3 = 1 + 4 - 4.5 = 0.5$. Se tivermos um outro ponto $x = [0, 1]$, entÃ£o $f(x) = 1 + 2*0 - 1.5*1 = 1 - 1.5 = -0.5$. Podemos usar um limiar (por exemplo, 0) para classificar, com valores acima do limiar atribuÃ­dos a uma classe e valores abaixo Ã  outra. Neste caso, o primeiro ponto seria classificado em uma classe e o segundo na outra. O hiperplano de decisÃ£o Ã© a reta $1 + 2x_1 - 1.5x_2 = 0$, que separa as duas classes.

**Lemma 1:** *A fronteira de decisÃ£o linear entre duas classes Ã© um hiperplano.* A prova reside no fato de que a igualdade das funÃ§Ãµes discriminantes de duas classes $f_k(x) = f_l(x)$ gera uma equaÃ§Ã£o linear em $x$, que define um hiperplano [^4.1]. Em outras palavras, o conjunto de pontos $x$ para os quais as funÃ§Ãµes discriminantes de duas classes sÃ£o iguais formam uma estrutura geomÃ©trica plana.

**Conceito 2: Linear Discriminant Analysis (LDA)**

**LDA (Linear Discriminant Analysis)** Ã© um mÃ©todo de classificaÃ§Ã£o que se baseia na modelagem das distribuiÃ§Ãµes condicionais das classes como Gaussianas multivariadas com a mesma matriz de covariÃ¢ncia $\Sigma$ [^4.3]. A funÃ§Ã£o discriminante linear para cada classe $k$ Ã© dada por:

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log \pi_k
$$

onde $\mu_k$ Ã© o vetor de mÃ©dias da classe $k$ e $\pi_k$ Ã© a probabilidade a priori da classe. As funÃ§Ãµes discriminantes lineares resultam de suposiÃ§Ãµes sobre a distribuiÃ§Ã£o dos dados e a busca por fronteiras de decisÃ£o que separam as classes com o menor risco de erro [^4.3]. O LDA Ã© frequentemente usado quando se tem uma boa separaÃ§Ã£o das classes e a suposiÃ§Ã£o de normalidade multivariada Ã© razoÃ¡vel, apesar de se mostrar robusto em diversos contextos, mesmo quando essa suposiÃ§Ã£o Ã© violada.

```mermaid
graph LR
    subgraph "Linear Discriminant Analysis (LDA)"
        direction TB
        A["Class-Conditional Density: P(X|G=k) ~ N(Î¼â‚–, Î£)"]
        B["Discriminant Function: Î´â‚–(x) = xáµ€Î£â»Â¹Î¼â‚– - 1/2Î¼â‚–áµ€Î£â»Â¹Î¼â‚– + log(Ï€â‚–)"]
        C["Class Assignment: argmaxâ‚–{Î´â‚–(x)}"]
    end
    A --> B
    B --> C
    style A fill:#ccf,stroke:#333,stroke-width:2px
    style B fill:#ccf,stroke:#333,stroke-width:2px
```

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Considere duas classes, com as seguintes mÃ©dias e matriz de covariÃ¢ncia (compartilhada):
>
> $\mu_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$, $\mu_2 = \begin{bmatrix} 3 \\ 2 \end{bmatrix}$, $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
>
> Assumindo probabilidades a priori iguais ($\pi_1 = \pi_2 = 0.5$), podemos calcular as funÃ§Ãµes discriminantes para cada classe. Primeiro, calculamos a inversa de $\Sigma$:
>
> $\Sigma^{-1} = \frac{1}{0.75} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$
>
> Agora, para um ponto $x = [2, 1.5]$, calculamos $\delta_1(x)$ e $\delta_2(x)$:
>
> $\delta_1(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} + \log(0.5)$
>
> $\delta_1(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 0.66 \\ 0.66 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 0.66 \\ 0.66 \end{bmatrix} + \log(0.5) = 2.31 - 0.66 + \log(0.5) = 1.65 -0.69 = 0.96$
>
> $\delta_2(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 2 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 2 \end{bmatrix} + \log(0.5)$
>
> $\delta_2(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 2.65 \\ 1.33 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 2 \end{bmatrix} \begin{bmatrix} 1.33 \\ 0.66 \end{bmatrix} + \log(0.5) = 7.30 - 2.66 + \log(0.5) = 4.64 -0.69 = 3.95$
>
> Como $\delta_2(x) > \delta_1(x)$, o ponto $x$ seria classificado na classe 2.

**CorolÃ¡rio 1:** *As fronteiras de decisÃ£o do LDA sÃ£o lineares (hiperplanos).* Isso decorre diretamente da forma linear das funÃ§Ãµes discriminantes $\delta_k(x)$, onde a igualdade de $\delta_k(x)$ e $\delta_l(x)$ resulta em uma equaÃ§Ã£o linear em $x$, definindo assim um hiperplano separador [^4.3.1].

**Conceito 3: RegressÃ£o LogÃ­stica**

**Logistic Regression** Ã© uma tÃ©cnica que modela a probabilidade de uma observaÃ§Ã£o pertencer a uma classe usando uma funÃ§Ã£o logÃ­stica [^4.4]. No caso de duas classes, a probabilidade $P(G=1|X=x)$ Ã© modelada como:

$$
P(G=1|X=x) = \frac{e^{\beta_0 + \beta^T x}}{1 + e^{\beta_0 + \beta^T x}}
$$

O log-odds (logit) dessa probabilidade Ã© uma funÃ§Ã£o linear de $x$, ou seja, $\log(\frac{P(G=1|X=x)}{1-P(G=1|X=x)}) = \beta_0 + \beta^T x$ [^4.4]. O mÃ©todo estima os coeficientes $\beta_0$ e $\beta$ atravÃ©s da maximizaÃ§Ã£o da funÃ§Ã£o de verossimilhanÃ§a dos dados de treinamento [^4.4.1]. A RegressÃ£o LogÃ­stica, ao contrÃ¡rio do LDA, nÃ£o faz suposiÃ§Ãµes sobre a distribuiÃ§Ã£o dos dados de entrada, o que a torna mais flexÃ­vel em muitas situaÃ§Ãµes prÃ¡ticas [^4.4.2].

```mermaid
graph LR
    subgraph "Logistic Regression"
        direction TB
         A["Probability: P(G=1|X=x) =  e^(Î²â‚€ + Î²áµ€x) / (1 + e^(Î²â‚€ + Î²áµ€x))"]
         B["Log-odds (Logit): log(P(G=1|X=x) / (1-P(G=1|X=x))) = Î²â‚€ + Î²áµ€x"]
         C["Parameter Estimation: Maximum Likelihood"]
    end
    A --> B
    B --> C
    style A fill:#ccf,stroke:#333,stroke-width:2px
     style B fill:#ccf,stroke:#333,stroke-width:2px
```

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Suponha que, apÃ³s treinar um modelo de regressÃ£o logÃ­stica, obtivemos os coeficientes $\beta_0 = -1$ e $\beta = \begin{bmatrix} 0.5 \\ 1 \end{bmatrix}$. Para um ponto $x = [2, 1]$, a probabilidade de pertencer Ã  classe 1 Ã©:
>
> $P(G=1|X=x) = \frac{e^{-1 + 0.5*2 + 1*1}}{1 + e^{-1 + 0.5*2 + 1*1}} = \frac{e^{1}}{1 + e^{1}} = \frac{2.718}{1 + 2.718} \approx 0.731$.
>
> Portanto, a probabilidade do ponto $x$ pertencer Ã  classe 1 Ã© de aproximadamente 73.1%. Para classificar, usarÃ­amos um limiar (por exemplo, 0.5). Neste caso, o ponto seria classificado como classe 1.

> âš ï¸ **Nota Importante**: A regressÃ£o logÃ­stica modela diretamente as probabilidades das classes, enquanto o LDA modela as distribuiÃ§Ãµes das classes [^4.4.1].

> â— **Ponto de AtenÃ§Ã£o**: Em datasets com classes desbalanceadas, Ã© fundamental usar tÃ©cnicas de rebalanceamento ou ajustar as penalidades para evitar o viÃ©s do modelo em direÃ§Ã£o Ã  classe majoritÃ¡ria [^4.4.2].

> âœ”ï¸ **Destaque**: Tanto LDA quanto a regressÃ£o logÃ­stica resultam em fronteiras de decisÃ£o lineares, mas a estimativa dos parÃ¢metros Ã© realizada de formas distintas, uma utilizando momentos dos dados e a outra utilizando a maximizaÃ§Ã£o da verossimilhanÃ§a [^4.5].

### RegressÃ£o Linear e MÃ­nimos Quadrados para ClassificaÃ§Ã£o

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction TB
        A["Encode Classes as Indicator Variables 'Y'"]
        B["Estimate Coefficients 'Î²' via Least Squares (LS)"]
        C["Decision Rule: argmaxâ‚–{fâ‚–(x)}"]
        D["Compare with Probabilistic Methods (LDA, Logistic Regression)"]
    end
    A --> B
    B --> C
    C --> D
    style A fill:#ccf,stroke:#333,stroke-width:2px
    style B fill:#ccf,stroke:#333,stroke-width:2px
```

A regressÃ£o linear, apesar de ser tradicionalmente usada para problemas de regressÃ£o, pode ser adaptada para problemas de classificaÃ§Ã£o atravÃ©s do uso de uma **matriz de indicadores** [^4.2]. Para um problema com $K$ classes, cada observaÃ§Ã£o $x_i$ Ã© associada a um vetor indicador $Y_i$ de dimensÃ£o $K$. Se $x_i$ pertence Ã  classe $k$, o elemento $Y_{ik}$ serÃ¡ igual a 1 e os demais serÃ£o 0. Isso gera uma matriz de respostas $Y$ com dimensÃ£o $N \times K$, onde $N$ Ã© o nÃºmero de observaÃ§Ãµes. Cada coluna da matriz $Y$ corresponde a uma das $K$ classes, contendo valores 0 ou 1 [^4.2].

Em seguida, um modelo de regressÃ£o linear Ã© ajustado a cada uma das $K$ colunas de $Y$ simultaneamente. O modelo estimado para cada classe $k$ Ã© dado por $f_k(x) = \beta_{k0} + \beta_k^T x$. Uma nova observaÃ§Ã£o $x$ Ã© classificada na classe $k$ que apresentar o maior valor de $f_k(x)$. Em outras palavras, o classificador escolhe a classe com a maior resposta ajustada pela regressÃ£o linear: $\hat{G}(x) = \arg\max_k f_k(x)$ [^4.2].

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que temos trÃªs classes e 4 observaÃ§Ãµes com duas features ($x_1, x_2$). A matriz de design $X$ e a matriz de indicadores $Y$ sÃ£o:
>
> $X = \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \\ 4 & 2 \end{bmatrix}$ , $Y = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 0 \end{bmatrix}$
>
> Para cada classe, ajustamos um modelo de regressÃ£o linear. Usando o mÃ©todo dos mÃ­nimos quadrados $\hat{\beta} = (X^TX)^{-1}X^TY$, podemos calcular os coeficientes.
>
> $X^TX = \begin{bmatrix} 1 & 2 & 3 & 4 \\ 2 & 1 & 3 & 2 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \\ 4 & 2 \end{bmatrix} = \begin{bmatrix} 30 & 23 \\ 23 & 18 \end{bmatrix}$
>
> $(X^TX)^{-1} = \frac{1}{30*18 - 23*23}\begin{bmatrix} 18 & -23 \\ -23 & 30 \end{bmatrix} = \frac{1}{29}\begin{bmatrix} 18 & -23 \\ -23 & 30 \end{bmatrix}$
>
> $X^TY = \begin{bmatrix} 1 & 2 & 3 & 4 \\ 2 & 1 & 3 & 2 \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 0 \end{bmatrix} = \begin{bmatrix} 5 & 2 & 3 \\ 4 & 1 & 3 \end{bmatrix}$
>
> $\hat{\beta} = (X^TX)^{-1}X^TY = \frac{1}{29}\begin{bmatrix} 18 & -23 \\ -23 & 30 \end{bmatrix} \begin{bmatrix} 5 & 2 & 3 \\ 4 & 1 & 3 \end{bmatrix} = \frac{1}{29} \begin{bmatrix} -2 & 13 & -15 \\ 5 & -16 & 21 \end{bmatrix} = \begin{bmatrix} -0.069 & 0.448 & -0.517 \\ 0.172 & -0.552 & 0.724 \end{bmatrix}$
>
>  Adicionando um intercepto $\beta_{k0}$, podemos usar $\hat{\beta}$ para fazer previsÃµes. Para um novo ponto $x = [3, 2]$, as previsÃµes seriam:
>
> $\hat{f_1}(x) = \beta_{10} + \beta_{11}*3 + \beta_{12}*2$
> $\hat{f_2}(x) = \beta_{20} + \beta_{21}*3 + \beta_{22}*2$
> $\hat{f_3}(x) = \beta_{30} + \beta_{31}*3 + \beta_{32}*2$
>
> A classe prevista seria a que tem o maior valor de $\hat{f_k}(x)$.

Apesar da simplicidade dessa abordagem, ela tem algumas limitaÃ§Ãµes importantes. Primeiro, a regressÃ£o linear pode produzir estimativas $f_k(x)$ que estÃ£o fora do intervalo $[0, 1]$, o que dificulta a interpretaÃ§Ã£o das mesmas como probabilidades [^4.2]. Segundo, em cenÃ¡rios onde as classes nÃ£o sÃ£o linearmente separÃ¡veis ou apresentam sobreposiÃ§Ã£o, essa abordagem pode ter um desempenho inferior quando comparada com mÃ©todos que modelam a distribuiÃ§Ã£o das classes de forma mais explÃ­cita, conforme detalhado em [^4.3]. O problema do "masking" tambÃ©m surge, onde classes intermediÃ¡rias podem ser completamente ignoradas, como exemplificado em [^4.2].

A regressÃ£o de indicadores, apesar dessas limitaÃ§Ãµes, pode ser Ãºtil quando o objetivo principal Ã© a fronteira de decisÃ£o linear e as classes podem ser razoavelmente separadas por um hiperplano. Ela tambÃ©m pode servir como uma aproximaÃ§Ã£o inicial em problemas de classificaÃ§Ã£o, com a vantagem de sua simplicidade computacional [^4.2].

**Lemma 2:** *Sob a codificaÃ§Ã£o 1/-1 para classes binÃ¡rias, a direÃ§Ã£o do vetor de coeficientes obtido via regressÃ£o linear (mÃ©todo dos mÃ­nimos quadrados) Ã© proporcional Ã  direÃ§Ã£o do discriminante do LDA.* Este resultado demonstra a conexÃ£o teÃ³rica entre a regressÃ£o linear em matriz de indicadores e o LDA quando as classes sÃ£o codificadas de forma adequada. [^4.2]

**CorolÃ¡rio 2:** *Em condiÃ§Ãµes especÃ­ficas, como igualdade de nÃºmero de observaÃ§Ãµes nas classes e covariÃ¢ncia esfÃ©rica, a regressÃ£o de indicadores e o LDA levam Ã  mesma regra de decisÃ£o.* Essas condiÃ§Ãµes, embora simplificadoras, mostram uma concordÃ¢ncia entre os dois mÃ©todos em cenÃ¡rios mais idealizados [^4.3].

Ã‰ importante notar que, conforme discutido em [^4.4], a regressÃ£o logÃ­stica pode fornecer estimativas de probabilidades mais estÃ¡veis, enquanto a regressÃ£o de indicadores pode gerar valores que extrapolam o intervalo [0,1]. No entanto, em cenÃ¡rios onde o objetivo Ã© apenas encontrar uma fronteira de decisÃ£o linear, a regressÃ£o de indicadores pode ser uma alternativa suficiente, conforme em [^4.2].

### MÃ©todos de SeleÃ§Ã£o de VariÃ¡veis e RegularizaÃ§Ã£o em ClassificaÃ§Ã£o

```mermaid
graph LR
    subgraph "Regularization for Logistic Regression"
        direction TB
        A["Cost Function: J(Î²)"]
        B["L1 Penalty (Lasso): Î»âˆ‘|Î²â±¼|"]
        C["L2 Penalty (Ridge): Î»âˆ‘Î²â±¼Â²"]
         D["Elastic Net: Combination of L1 and L2"]
        A --> B
        A --> C
        A --> D
    end
    style A fill:#ccf,stroke:#333,stroke-width:2px
     style B fill:#ccf,stroke:#333,stroke-width:2px
```

**SeleÃ§Ã£o de variÃ¡veis** e **regularizaÃ§Ã£o** sÃ£o mÃ©todos essenciais para construir modelos de classificaÃ§Ã£o mais robustos, especialmente em contextos com muitas variÃ¡veis preditoras [^4.5]. Em problemas de classificaÃ§Ã£o, o uso excessivo de variÃ¡veis pode levar ao *overfitting*, comprometendo a capacidade de generalizaÃ§Ã£o do modelo para novos dados. A **regularizaÃ§Ã£o** impÃµe restriÃ§Ãµes sobre os coeficientes do modelo, buscando reduzir a sua complexidade e melhorar o desempenho [^4.4.4].

Na **regressÃ£o logÃ­stica**, a regularizaÃ§Ã£o pode ser introduzida como um termo de penalidade na funÃ§Ã£o de custo:

$$
\max_{\beta_0, \beta} \left[ \sum_{i=1}^N \left( y_i (\beta_0 + \beta^T x_i) - \log(1 + e^{\beta_0 + \beta^T x_i}) \right) - \lambda P(\beta) \right]
$$

Onde $P(\beta)$ Ã© o termo de penalidade, e $\lambda$ Ã© o parÃ¢metro de regularizaÃ§Ã£o. A penalidade **L1 (Lasso)** Ã© dada por $P(\beta) = \sum_{j=1}^p |\beta_j|$, que induz a esparsidade do modelo, zerando coeficientes de variÃ¡veis menos relevantes e promovendo a seleÃ§Ã£o de variÃ¡veis [^4.4.4]. A penalidade **L2 (Ridge)** Ã© dada por $P(\beta) = \sum_{j=1}^p \beta_j^2$, que reduz a magnitude dos coeficientes, favorecendo soluÃ§Ãµes mais estÃ¡veis e com menor variÃ¢ncia [^4.5]. A escolha entre L1, L2 ou uma combinaÃ§Ã£o das duas (Elastic Net) depende da aplicaÃ§Ã£o e das propriedades desejadas do modelo.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Vamos supor que estamos treinando uma regressÃ£o logÃ­stica com duas features e estamos usando a regularizaÃ§Ã£o L1 (Lasso). A funÃ§Ã£o de custo com a penalidade L1 Ã©:
>
> $J(\beta) = -\frac{1}{N} \sum_{i=1}^N \left[ y_i \log(p_i) + (1 - y_i) \log(1 - p_i) \right] + \lambda (|\beta_1| + |\beta_2|)$
>
> Onde $p_i$ Ã© a probabilidade prevista para a observaÃ§Ã£o $i$.
>
> Suponha que apÃ³s a otimizaÃ§Ã£o, com $\lambda = 0.1$, obtivemos os seguintes coeficientes: $\beta_0 = -0.5, \beta_1 = 0.8, \beta_2 = 0.2$.
>
> Agora, se aumentarmos $\lambda$ para 0.5, a penalidade L1 se torna mais forte, resultando em uma soluÃ§Ã£o mais esparsa. ApÃ³s a otimizaÃ§Ã£o, podemos obter: $\beta_0 = -0.3, \beta_1 = 0.4, \beta_2 = 0.0$. Observe que $\beta_2$ foi zerado, indicando que a segunda feature se tornou menos relevante.
>
> Se usarmos a regularizaÃ§Ã£o L2 (Ridge) com $\lambda=0.1$, poderÃ­amos obter algo como $\beta_0 = -0.4, \beta_1 = 0.7, \beta_2 = 0.3$.
>
> A regularizaÃ§Ã£o L2 tende a reduzir os valores dos coeficientes sem zerÃ¡-los completamente, enquanto a L1 pode zerar alguns coeficientes.
>
> | MÃ©todo       | $\beta_0$ | $\beta_1$ | $\beta_2$ |
> |--------------|-----------|-----------|-----------|
> | Sem Reg.     | -0.5      | 0.9      | 0.3       |
> | Lasso ($\lambda=0.1$)   | -0.5      | 0.8      | 0.2      |
> | Lasso ($\lambda=0.5$)   | -0.3      | 0.4      | 0.0      |
> | Ridge ($\lambda=0.1$)   | -0.4      | 0.7      | 0.3      |

**Lemma 3:** *A penalidade L1 na regressÃ£o logÃ­stica resulta em coeficientes esparsos.* A penalidade L1 adiciona um termo que Ã© proporcional Ã  soma dos valores absolutos dos coeficientes, levando ao "zeramento" de muitos coeficientes durante o processo de otimizaÃ§Ã£o. [^4.4.4]

**Prova do Lemma 3:** A minimizaÃ§Ã£o da funÃ§Ã£o de custo com a penalidade L1 leva os coeficientes para zero sempre que a derivada da funÃ§Ã£o objetivo em relaÃ§Ã£o a esses coeficientes for menor que o parÃ¢metro de regularizaÃ§Ã£o $\lambda$. Devido Ã  natureza da penalidade L1, que possui uma derivada constante (em valor absoluto), ao contrÃ¡rio da penalidade L2 (cuja derivada Ã© proporcional ao coeficiente), a penalidade L1 forÃ§a alguns coeficientes a serem exatamente iguais a zero, promovendo a esparsidade do modelo. [^4.4.3] $\blacksquare$

**CorolÃ¡rio 3:** *A esparsidade induzida pela penalidade L1 leva Ã  seleÃ§Ã£o de variÃ¡veis, resultando em modelos mais interpretÃ¡veis e com melhor generalizaÃ§Ã£o.* A remoÃ§Ã£o de variÃ¡veis irrelevantes simplifica o modelo e reduz o risco de overfitting, melhorando o desempenho em novos dados [^4.4.5].

> âš ï¸ **Ponto Crucial**: A escolha entre penalidade L1 e L2 impacta diretamente na natureza da soluÃ§Ã£o, com L1 gerando modelos esparsos e L2 gerando modelos mais estÃ¡veis e com menor variÃ¢ncia. A combinaÃ§Ã£o de ambas, Elastic Net, oferece flexibilidade para explorar diferentes trade-offs [^4.5].

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
 subgraph "Separating Hyperplanes and Perceptron"
    direction TB
        A["Hyperplane Definition: Î²â‚€ + Î²áµ€x = 0"]
        B["Perceptron Algorithm: Iterative Search for Separating Hyperplane"]
        C["Weight Update: Î² = Î² + Î· * yáµ¢ * xáµ¢ (for misclassified points)"]
        D["Convergence: Finite steps if data is linearly separable"]
     end
     A --> B
     B --> C
     B --> D
    style A fill:#ccf,stroke:#333,stroke-width:2px
     style B fill:#ccf,stroke:#333,stroke-width:2px
```

O conceito de **hiperplanos separadores** emerge da busca por uma fronteira linear que maximize a separaÃ§Ã£o entre diferentes classes, ou seja, que nÃ£o apenas separe as classes, mas tambÃ©m maximize a distÃ¢ncia entre o hiperplano e as observaÃ§Ãµes mais prÃ³ximas de cada classe [^4.5.2]. Um hiperplano separador Ã© definido por $\beta_0 + \beta^T x = 0$, onde $\beta$ define a orientaÃ§Ã£o do hiperplano e $\beta_0$ define o deslocamento em relaÃ§Ã£o Ã  origem.

O **Perceptron**, um algoritmo clÃ¡ssico em aprendizado de mÃ¡quina, busca encontrar um hiperplano separador de forma iterativa [^4.5.1]. O algoritmo comeÃ§a com uma estimativa inicial do hiperplano e, para cada observaÃ§Ã£o classificada incorretamente, ajusta os parÃ¢metros $\beta_0$ e $\beta$ para se aproximar de uma soluÃ§Ã£o que separe as classes. Se os dados forem linearmente separÃ¡veis, o algoritmo do Perceptron converge para uma soluÃ§Ã£o em um nÃºmero finito de passos [^4.5.1]. No entanto, se os dados nÃ£o forem linearmente separÃ¡veis, o algoritmo pode oscilar e nÃ£o convergir. AlÃ©m disso, em casos separÃ¡veis, a soluÃ§Ã£o final pode nÃ£o ser Ãºnica e pode depender da inicializaÃ§Ã£o.

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Suponha que temos dados em duas dimensÃµes e queremos usar o Perceptron para encontrar um hiperplano separador. Inicializamos os pesos como $\beta_0 = 0$, $\beta = [0.1, -0.2]$.
>
> Temos os seguintes pontos e classes:
>
> $x_1 = [1, 1], y_1 = 1$
> $x_2 = [2, 0], y_2 = 1$
> $x_3 = [0, 2], y_3 = -1$
> $x_4 = [0, 0], y_4 = -1$
>
> Para cada ponto, calculamos $\hat{y} = \beta_0 + \beta^T x$.
>
> Para $x_1$: $\hat{y_1} = 0 + 0.1 * 1 - 0.2 * 1 = -0.1$. A classe prevista Ã© -1 (jÃ¡ que Ã© negativo). Como a classe real Ã© 1, temos um erro. Atualizamos os pesos:
>
> $\beta_0 = \beta_0 + \eta * y_1 = 0 + 0.1 * 1 = 0.1$ (onde $\eta$ Ã© a taxa de aprendizado, vamos usar $\eta = 0.1$)
> $\beta = \beta + \eta * y_1 * x_1 = [0.1, -0.2] + 0.1 * 1 * [1, 1] = [0.2, -0.1]$
>
> Agora, $\beta_0 = 0.1$, $\beta = [0.2, -0.1]$.
>
> Repetimos esse processo para os outros pontos e iteramos atÃ© que nÃ£o haja mais erros.
>
>  Vamos a segunda iteraÃ§Ã£o:
>
> Para $x_1$: $\hat{y_1} = 0.1 + 0.2 * 1 - 0.1 * 1 = 0.2$. A classe prevista Ã© 1. Sem erro.
> Para $x_2$: $\hat{y_2} = 0.1 + 0.2 * 2 - 0.1 * 0 = 0.5$. A classe prevista Ã© 1. Sem erro.
> Para $x_3$: $\hat{y_3} = 0.1 + 0.2 * 0 - 0.1 * 2 = -0.1$. A classe prevista Ã© -1. Sem erro.
> Para $x_4$: $\hat{y_4} = 0.1 + 0.2 * 0 - 0.1 * 0 = 0.1$. A classe prevista Ã© 1. Erro.
>
> Atualizamos os pesos:
>
> $\beta_0 = \beta_0 + \eta * y_4 = 0.1 + 0.1 * -1 = 0$
> $\beta = \beta + \eta * y_4 * x_4 = [0.2, -0.1] + 0.1 * -1 * [0, 0] = [0.2, -0.1]$
>
> Agora, $\beta_0 = 0$, $\beta = [0.2, -0.1]$.
>
> Este processo Ã© repetido atÃ© que o algoritmo convirja.

**Teorema:** *Se um conjunto de dados Ã© linearmente separÃ¡vel, o algoritmo do Perceptron irÃ¡ convergir para um hiperplano separador em um nÃºmero finito de iteraÃ§Ãµes.* Esse teorema Ã© fundamental para a compreensÃ£o da garantia de convergÃªncia do algoritmo em condiÃ§Ãµes ideais, mas nÃ£o garante convergÃªncia em dados nÃ£o linearmente separÃ¡veis [^4.5.1].

### Pergunta TeÃ³rica AvanÃ§ada: Quais as diferenÃ§as fundamentais entre a formulaÃ§Ã£o de LDA e a Regra de DecisÃ£o Bayesiana considerando distribuiÃ§Ãµes Gaussianas com covariÃ¢ncias iguais?

```mermaid
graph LR
    subgraph "Comparison: LDA vs. Bayesian Decision Rule"
        direction TB
        A["Bayesian Decision Rule: Maximize P(G=k|X=x)"]
        B["LDA Discriminant: Î´â‚–(x) = xáµ€Î£â»Â¹Î¼â‚– - 1/2Î¼â‚–áµ€Î£â»Â¹Î¼â‚– + log(Ï€â‚–)"]
        C["Gaussian Assumption: P(X|G=k) ~ N(Î¼â‚–, Î£) (same Î£ for all classes)"]
        D["Equivalence: Under Gaussian Assumption with equal covariances, LDA = Bayesian"]
    end
    A --> C
    B --> C
    C --> D
     style A fill:#ccf,stroke:#333,stroke-width:2px
    style B fill:#ccf,stroke