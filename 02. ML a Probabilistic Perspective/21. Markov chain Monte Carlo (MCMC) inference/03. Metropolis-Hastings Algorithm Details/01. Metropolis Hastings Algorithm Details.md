## Metropolis-Hastings Algorithm: A Detailed Exploration

### Introdução
O algoritmo de Metropolis-Hastings (MH) é um método MCMC (Markov chain Monte Carlo) amplamente utilizado para amostrar de distribuições de probabilidade complexas [^24.1]. Em essência, o MH constrói uma cadeia de Markov cujo estado estacionário corresponde à distribuição alvo desejada, $p^*(x)$ [^24.1]. Este capítulo detalha o funcionamento interno do algoritmo MH, explorando suas características, variações e considerações práticas.

### Conceitos Fundamentais
O algoritmo MH opera iterativamente, propondo movimentos de um estado atual $x$ para um novo estado $x'$ com uma probabilidade $q(x'|x)$ [^texto_ocr_1]. A função $q$ é conhecida como **distribuição de proposta** ou *kernel* [^texto_ocr_1].

1.  **Distribuição de Proposta (Proposal Distribution):** A escolha da distribuição de proposta $q(x'|x)$ é crucial para a eficiência do algoritmo [^texto_ocr_1]. Ela determina a probabilidade de propor um novo estado $x'$ dado o estado atual $x$. Uma escolha comum é uma distribuição Gaussiana simétrica centrada no estado atual, conhecida como **algoritmo de Metropolis de passeio aleatório (random walk Metropolis algorithm)** [^texto_ocr_1].

2.  **Fórmula de Aceitação:** O algoritmo MH usa uma fórmula de aceitação para decidir se aceita o estado proposto $x'$ [^texto_ocr_1]. Esta fórmula garante que o algoritmo amostre da distribuição desejada, mesmo que a proposta seja assimétrica. A probabilidade de aceitação é dada por:

    $$     \alpha = \min\left(1, \frac{p^*(x')q(x|x')}{p^*(x)q(x'|x)}\right)     $$

    onde $p^*(x)$ é a distribuição alvo [^24.3]. Se a proposta é simétrica, ou seja, $q(x'|x) = q(x|x')$, a fórmula se simplifica para:

    $$     r = \min\left(1, \frac{p^*(x')}{p^*(x)}\right)     $$

    Neste caso, se $x'$ for mais provável que $x$, o movimento é sempre aceito [^24.3]. Caso contrário, o movimento é aceito com uma probabilidade que depende das probabilidades relativas dos dois estados.

3. **Correção de Hastings:** Se a distribuição de proposta é assimétrica, é necessária a **correção de Hastings** [^24.3]. A probabilidade de aceitação é então:

    $$     \alpha = \frac{p^*(x')q(x|x')}{p^*(x)q(x'|x)}     $$

    Esta correção compensa o fato de que a distribuição de proposta pode favorecer certos estados [^24.3].

4.  **Vantagens do Algoritmo MH:**
    *   Flexibilidade: Permite ao usuário definir qualquer distribuição de proposta [^texto_ocr_1].
    *   Não requer conhecimento da constante de normalização: Só é necessário conhecer a distribuição alvo até uma constante de normalização [^24.3].

### Algoritmo Metropolis-Hastings: Passo a Passo
O algoritmo Metropolis-Hastings pode ser resumido nos seguintes passos [^24.3]:
1. Inicialize $x^0$ (estado inicial).
2. Para $s = 0, 1, 2, ...$:
    1.  Proponha um novo estado $x'$ amostrando de $q(x'|x^s)$.
    2.  Calcule a probabilidade de aceitação $\alpha$ usando a fórmula apropriada.
    3.  Amostre $u \sim U(0, 1)$.
    4.  Se $u < \alpha$:
        *   Aceite a proposta: $x^{s+1} = x'$.
    5.  Senão:
        *   Rejeite a proposta: $x^{s+1} = x^s$.

### Distribuições de Proposta
A escolha da distribuição de proposta é crucial [^texto_ocr_1]. Algumas opções comuns incluem:

1.  **Passeio Aleatório Gaussiano (Gaussian Random Walk):** $q(x'|x) = N(x'|x, \Sigma)$, onde $\Sigma$ é a matriz de covariância [^texto_ocr_1]. A escolha de $\Sigma$ afeta a eficiência do algoritmo. Se $\Sigma$ for muito pequena, a cadeia explorará o espaço de estados lentamente [^texto_ocr_1]. Se $\Sigma$ for muito grande, a maioria das propostas será rejeitada, tornando a cadeia "pegajosa" [^texto_ocr_1].
    Roberts e Rosenthal (2001) provaram que, se a distribuição posterior for gaussiana, o valor assintoticamente ótimo é usar $s^2 = 2.38^2/D$, onde $D$ é a dimensionalidade de $w$; isto resulta numa taxa de aceitação de 0.234 [^24.3].

2.  **Amostrador Independente (Independence Sampler):** $q(x'|x) = q(x')$, onde o novo estado é independente do estado atual [^texto_ocr_1]. Este método é semelhante à amostragem por importância [^texto_ocr_1].

3.  **Propostas Gaussianas:** Se o espaço de estados é contínuo, a Hessiana $H$ em um modo local $\hat w$ pode ser usada para definir a covariância de uma distribuição de proposta gaussiana [^24.3]. Existem duas abordagens óbvias:
    1.  Uma proposta de independência, $q(w'|w) = N(w'|\hat w, H^{-1})$.
    2.  Uma proposta de passeio aleatório, $q(w'|w) = N(w'|w, s^2H^{-1})$, onde $s^2$ é um fator de escala escolhido para facilitar a mistura rápida [^24.3].

#### Ajustando a Proposta
Ajustar a variância da proposta é crucial para o desempenho do algoritmo [^24.3]. Uma taxa de aceitação muito alta (próxima de 100%) pode indicar exploração insuficiente do espaço de estados, enquanto uma taxa muito baixa pode indicar que a cadeia está tendo dificuldade em se mover [^24.3]. Execuções piloto podem ser usadas para ajustar a variância da proposta até que a taxa de aceitação esteja dentro de um intervalo aceitável (por exemplo, entre 25% e 40%) [^24.3].

### Conclusão
O algoritmo de Metropolis-Hastings é uma ferramenta poderosa para amostragem de distribuições complexas. A escolha da distribuição de proposta e o ajuste de seus parâmetros são cruciais para a eficiência do algoritmo. Compreender os princípios subjacentes e as nuances práticas do MH é essencial para sua aplicação bem-sucedida em uma variedade de problemas estatísticos e de aprendizado de máquina.

### Referências
[^texto_ocr_1]: Texto fornecido no contexto.
[^24.1]: Chapter 24. Markov chain Monte Carlo (MCMC) inference.
[^24.3]: 24.3 Metropolis Hastings algorithm.

<!-- END -->