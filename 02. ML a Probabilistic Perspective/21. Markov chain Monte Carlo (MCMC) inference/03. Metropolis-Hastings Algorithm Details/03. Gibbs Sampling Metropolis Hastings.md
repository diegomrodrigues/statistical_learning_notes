## Gibbs Sampling: Um Caso Especial do Algoritmo de Metropolis-Hastings

### Introdução
Este capítulo aprofunda o conceito de **Gibbs sampling**, demonstrando como ele se encaixa como um caso especial dentro do framework mais geral do **algoritmo de Metropolis-Hastings (MH)** [^24.3]. Exploraremos a natureza da distribuição proposta no Gibbs sampling e como ela leva a uma taxa de aceitação de 100%.

### Conceitos Fundamentais
O algoritmo de Metropolis-Hastings é um método de **Monte Carlo via Cadeias de Markov (MCMC)** utilizado para amostrar de distribuições de probabilidade complexas [^24.1]. Ele funciona propondo movimentos de um estado atual $x$ para um novo estado $x'$ com probabilidade $q(x'|x)$, onde $q$ é a **distribuição proposta** (ou *kernel*) [^24.3.1]. A aceitação ou rejeição dessa proposta é determinada por uma razão que garante que a cadeia de Markov convirja para a distribuição alvo $p^*(x)$ [^24.1, 24.3.1].

**Gibbs sampling** é uma forma particular de MCMC onde cada variável é amostrada por vez, condicionado aos valores de todas as outras variáveis [^24.2]. Formalmente, dada uma amostra conjunta $x^s$ de todas as variáveis, uma nova amostra $x^{s+1}$ é gerada amostrando cada componente $x_i$ condicionado aos valores mais recentes das outras variáveis $x_{-i}$ [^24.2]. Matematicamente, isso é expresso como:
$$ x_i^{s+1} \sim p(x_i | x_{-i}^*) $$
onde $x_{-i}^*$ representa os valores mais recentes de todas as variáveis exceto $x_i$.

A conexão crucial com o algoritmo de Metropolis-Hastings reside na escolha da **distribuição proposta** [^24.3.2]. No Gibbs sampling, a distribuição proposta é a **distribuição condicional completa** [^24.2]:
$$ q(x'|x) = p(x_i' | x_{-i})I(x_{-i}' = x_{-i}) $$
Aqui, $I(x_{-i}' = x_{-i})$ é uma função indicadora que garante que apenas a *i*-ésima componente é alterada, enquanto as outras permanecem fixas [^24.3.2].

**Teorema:** *A taxa de aceitação no Gibbs sampling com a distribuição proposta definida acima é sempre 100%* [^24.3.2].

**Prova:**
Para mostrar isso, examinamos a razão de aceitação $\alpha$ no algoritmo de Metropolis-Hastings [^24.3.2]:
$$ \alpha = \frac{p^*(x')q(x|x')}{p^*(x)q(x'|x)} $$
Substituindo a distribuição proposta do Gibbs sampling, temos:
$$ \alpha = \frac{p(x') p(x_i | x'_{-i})I(x'_{-i} = x_{-i})}{p(x) p(x'_i | x_{-i})I(x_{-i} = x_{-i})} $$
Como $x'_{-i} = x_{-i}$, podemos simplificar $p(x')$ e $p(x)$ usando a regra do produto:
$$ p(x) = p(x_i | x_{-i}) p(x_{-i}) $$
$$ p(x') = p(x'_i | x'_{-i}) p(x'_{-i}) = p(x'_i | x_{-i}) p(x_{-i}) $$
Substituindo essas expressões na equação para $\alpha$, obtemos:
$$ \alpha = \frac{p(x'_i | x_{-i}) p(x_{-i}) p(x_i | x_{-i}) }{p(x_i | x_{-i}) p(x_{-i}) p(x'_i | x_{-i})} = 1 $$
Portanto, $\alpha = 1$, o que implica que a taxa de aceitação é sempre 100% [^24.3.2]. $\blacksquare$

**Observação:** Apesar da taxa de aceitação de 100%, o Gibbs sampling ainda pode apresentar convergência lenta se as variáveis forem altamente correlacionadas [^24.2.8]. Nesses casos, técnicas como *blocking Gibbs sampling* podem ser empregadas para amostrar grupos de variáveis simultaneamente [^24.2.8].

### Conclusão
Gibbs sampling é uma implementação eficiente do algoritmo de Metropolis-Hastings, aproveitando as distribuições condicionais completas como distribuições propostas [^24.3.2]. Sua taxa de aceitação de 100% o torna uma escolha atraente em muitos problemas estatísticos, particularmente em modelos hierárquicos e modelos gráficos [^24.2.5, 24.2]. No entanto, é crucial estar ciente de suas limitações, especialmente em cenários com alta correlação entre variáveis, e considerar técnicas alternativas ou complementares para melhorar a convergência [^24.2.8].

### Referências
[^24.1]: Markov chain Monte Carlo (MCMC) inference, Introduction.
[^24.2]: Markov chain Monte Carlo (MCMC) inference, Gibbs sampling.
[^24.3]: Markov chain Monte Carlo (MCMC) inference, Metropolis Hastings algorithm.
[^24.2.5]: Markov chain Monte Carlo (MCMC) inference, Gibbs sampling for hierarchical GLMs.
[^24.2.8]: Markov chain Monte Carlo (MCMC) inference, Blocking Gibbs sampling.
[^24.3.1]: Markov chain Monte Carlo (MCMC) inference, Metropolis Hastings algorithm, Basic idea.
[^24.3.2]: Markov chain Monte Carlo (MCMC) inference, Gibbs sampling is a special case of MH.
<!-- END -->