## Gibbs Sampling e o Modelo de Ising

### Introdução
O presente capítulo aprofunda a aplicação do **Gibbs sampling** em modelos específicos, com foco no **modelo de Ising** [^2]. Como vimos anteriormente [^2], o Gibbs sampling é um algoritmo MCMC popular para amostrar de distribuições de alta dimensionalidade. Este capítulo explorará como o Gibbs sampling é aplicado ao modelo de Ising, demonstrando sua utilidade em modelagem espacial e tarefas de processamento de imagem.

### Conceitos Fundamentais
O **modelo de Ising** é um modelo matemático de ferromagnetismo na física estatística [^1, ^2]. Ele consiste em um *grid* ou rede de *spins* que podem estar em um de dois estados: +1 ou -1. A probabilidade de um *spin* assumir um determinado estado depende da compatibilidade com seus vizinhos e dos dados observados [^2].

A aplicação do Gibbs sampling ao modelo de Ising envolve a amostragem iterativa de cada *spin* condicionado aos seus vizinhos [^2]. A probabilidade de um *spin* $x_t$ assumir o valor +1, dado o estado dos seus vizinhos $x_{-t}$, é dada por [^2]:

$$ p(x_t = +1 | x_{-t}, \theta) = \text{sigm}(2J n_t) $$

onde [^2]:
*   $J$ é a força de acoplamento (coupling strength) entre os spins
*   $n_t = \sum_{s \in \text{nbr}(t)} x_s$ é a soma dos spins vizinhos
*   $\text{sigm}(u) = \frac{1}{1 + e^{-u}}$ é a função sigmoide

Esta equação [^2] demonstra que a probabilidade de um *spin* ser +1 aumenta se a maioria dos seus vizinhos também for +1. A atualização de cada *spin* desta forma, iterativamente ao longo de toda a grade, leva a amostras da distribuição posterior do modelo de Ising.

**Modelo de Markov Random Field (MRF) / Conditional Random Field (CRF)** [^2]
O Gibbs sampling em um MRF/CRF *pairwise* toma a forma [^2]:

$$ p(X_t | x_{-t}, \theta) \propto \prod_{s \in \text{nbr}(t)} \psi_{st}(x_s, x_t) $$

onde $\psi_{st}(x_s, x_t)$ são as funções de potencial de aresta [^2]. No caso do modelo de Ising, $\psi_{st}(x_s, x_t) = \exp(J x_s x_t)$ [^2].

**Considerações Adicionais** [^2]

*   **Burn-in:** É necessário descartar as amostras iniciais (burn-in) para garantir que a cadeia de Markov tenha convergido para a distribuição estacionária.
*   **Inicialização:** A inicialização do Gibbs sampling pode influenciar a velocidade de convergência.
*   **Convergência:** Avaliar a convergência do Gibbs sampling pode ser desafiador e requer o uso de métricas e diagnósticos apropriados.

**Aplicação em Image Denoising** [^2]

O modelo de Ising pode ser combinado com um termo de evidência local para modelar a observação de dados ruidosos. Por exemplo, com um modelo de observação Gaussiano, temos $\psi_t(x_t) = N(y_t | x_t, \sigma^2)$, onde $y_t$ é o pixel observado e $\sigma^2$ é a variância do ruído. A distribuição condicional completa torna-se [^2]:

$$ p(x_t = +1 | x_{-t}, y, \theta) = \text{sigm} \left( 2J n_t - \log \frac{\psi_t(+1)}{\psi_t(-1)} \right) $$

A Figura 24.1 [^2] ilustra um exemplo de *image denoising* usando um *prior* de Ising com $W_{ij} = J = 1$ e um modelo de ruído Gaussiano com $\sigma = 2$. O Gibbs sampling é usado para realizar a inferência aproximada [^2].

### Conclusão
O Gibbs sampling fornece uma abordagem flexível e poderosa para inferência em modelos complexos, como o modelo de Ising [^2]. Sua capacidade de lidar com distribuições de alta dimensionalidade e dependências espaciais o torna uma ferramenta valiosa em diversas aplicações, incluindo modelagem espacial e processamento de imagem [^2]. No entanto, é importante estar ciente dos desafios associados à convergência e escolha de parâmetros para garantir resultados precisos e confiáveis [^2].

### Referências
[^1]: 24 Markov chain Monte Carlo (MCMC) inference
[^2]: 24.2 Gibbs sampling
<!-- END -->