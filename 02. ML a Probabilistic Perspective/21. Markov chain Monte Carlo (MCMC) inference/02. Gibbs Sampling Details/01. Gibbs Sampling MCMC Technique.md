## Gibbs Sampling: Uma Técnica MCMC Detalhada

### Introdução
Este capítulo aprofunda o conceito de **Gibbs sampling**, uma técnica de Monte Carlo via Cadeias de Markov (MCMC) amplamente utilizada para inferência estatística em modelos complexos de alta dimensionalidade. Em continuidade ao Capítulo 23, que introduziu métodos básicos de Monte Carlo [^1], exploraremos como o Gibbs sampling supera as limitações desses métodos em espaços de alta dimensão, fornecendo uma alternativa eficiente para amostrar distribuições complexas. O Gibbs sampling é um caso especial de MCMC, onde cada variável é amostrada condicionalmente aos valores atuais de todas as outras variáveis [^2]. Na física, essa técnica é conhecida como **dinâmica de Glauber** ou método do *heat bath* [^2].

### Conceitos Fundamentais

O Gibbs sampling é um algoritmo iterativo que amostra cada variável de sua distribuição condicional completa, dadas as outras variáveis, permitindo que a cadeia de Markov convirja gradualmente para a distribuição conjunta [^2]. Essa abordagem é análoga à **descida coordenada** em otimização [^2].

A **ideia básica** por trás do Gibbs sampling é amostrar cada variável, por sua vez, condicionada aos valores de todas as outras variáveis na distribuição [^2]. Ou seja, dado um conjunto de amostras conjuntas $x^s$ de todas as variáveis, geramos uma nova amostra $x^{s+1}$ amostrando cada componente por sua vez, com base nos valores mais recentes das outras variáveis [^2]. Por exemplo, com $D = 3$ variáveis, o processo iterativo é definido como [^2]:
*   $x_1^{s+1} \sim p(x_1 | x_2^s, x_3^s)$
*   $x_2^{s+1} \sim p(x_2 | x_1^{s+1}, x_3^s)$
*   $x_3^{s+1} \sim p(x_3 | x_1^{s+1}, x_2^{s+1})$

Este processo generaliza-se facilmente para $D$ variáveis. Se $x_i$ é uma variável visível, não a amostramos, pois seu valor já é conhecido [^2]. A expressão $p(x_i | x_{-i})$ é chamada a **condicional completa** para a variável $i$ [^2]. Em geral, $x_i$ pode depender apenas de algumas das outras variáveis. Se representarmos $p(x)$ como um modelo gráfico, podemos inferir as dependências olhando para o *Markov blanket* de $i$, que são seus vizinhos no grafo [^2]. Assim, para amostrar $x_i$, precisamos apenas conhecer os valores dos vizinhos de $i$ [^2]. Neste sentido, o Gibbs sampling é um algoritmo distribuído. No entanto, não é um algoritmo paralelo, uma vez que as amostras devem ser geradas sequencialmente [^2].

**Burn-in:** É necessário descartar algumas das amostras iniciais até que a cadeia de Markov tenha convergido ou entrado em sua distribuição estacionária [^2]. Estimar quando o *burn-in* ocorreu é crucial [^2].

**Exemplo: Gibbs sampling para o modelo de Ising:**
No contexto de um modelo de Ising, o Gibbs sampling pode ser aplicado para inferir a distribuição de probabilidade conjunta sobre as variáveis de spin. Dado um modelo de Ising *pairwise* MRF/CRF, a distribuição assume a forma [^2]:
$$ p(X_t | x_{-t}, \theta) \propto \prod_{s \in nbr(t)} \psi_{st}(x_s, x_t) $$
onde $nbr(t)$ representa os vizinhos do nó $t$ [^2]. No caso de um modelo de Ising com potenciais de aresta, $\psi_{st}(x_s, x_t) = \exp(J x_s x_t)$, onde $x_t \in \{-1, +1\}$ [^2]. A probabilidade condicional completa torna-se [^3]:
$$ p(x_t = +1 | x_{-t}, \theta) = \frac{\prod_{s \in nbr(t)} \psi_{st}(x_t = +1, x_s)}{\prod_{s \in nbr(t)} \psi_{st}(x_t = +1, x_s) + \prod_{s \in nbr(t)} \psi_{st}(x_t = -1, x_s)} $$
$$ = \frac{\exp[J \sum_{s \in nbr(t)} x_s]}{\exp[J \sum_{s \in nbr(t)} x_s] + \exp[-J \sum_{s \in nbr(t)} x_s]} $$
$$ = \frac{\exp[J \eta_t]}{\exp[J \eta_t] + \exp[-J \eta_t]} = \text{sigm}(2J\eta_t) $$
onde $\eta_t \equiv \sum_{s \in nbr(t)} x_s$ e $\text{sigm}(u) = 1/(1 + e^{-u})$ é a função sigmoide [^3].

### Conclusão

O Gibbs sampling oferece uma abordagem poderosa e flexível para a inferência em modelos estatísticos complexos. Sua capacidade de lidar com espaços de alta dimensão e distribuições condicionais completas relativamente fáceis de amostrar o torna uma ferramenta valiosa na análise de dados e no aprendizado de máquina. No entanto, é crucial estar ciente dos desafios associados ao *burn-in* e à convergência, bem como explorar técnicas avançadas como o *collapsed Gibbs sampling* e *blocking Gibbs sampling* para melhorar a eficiência e a precisão das amostras geradas.

### Referências
[^1]: Markov chain Monte Carlo (MCMC)
[^2]: Gibbs sampling
[^3]: Gibbs sampling
<!-- END -->