## Annealing Methods for Handling Multimodal Distributions

### Introdução
Como vimos anteriormente, a inferência em modelos probabilísticos complexos muitas vezes envolve distribuições multimodais, tornando desafiadora a tarefa de encontrar o ótimo global ou de amostrar adequadamente o espaço de parâmetros [^846]. Os métodos de *Annealing*, inspirados no processo metalúrgico de aquecimento e resfriamento de metais, oferecem uma abordagem para lidar com essas distribuições complexas [^868]. Este capítulo explorará em detalhes os métodos de *Annealing*, discutindo sua analogia com o processo físico, o uso de um parâmetro de temperatura computacional e as diferentes variações, como *Simulated Annealing* e *Annealed Importance Sampling*.

### Conceitos Fundamentais
Os métodos de *Annealing* exploram a analogia entre a busca pelo mínimo global de uma função de custo e o processo de resfriamento de um metal para atingir um estado de baixa energia [^868]. No contexto computacional, essa analogia é traduzida da seguinte forma:
1. **Distribuição Multimodal:** Representa a função de custo ou a distribuição *a posteriori* que se deseja otimizar ou amostrar.
2. **Temperatura Computacional (T):** Um parâmetro que controla a "suavidade" da distribuição. Em altas temperaturas, a distribuição é suavizada, facilitando a fuga de mínimos locais.
3. **Resfriamento Gradual:** A temperatura é gradualmente reduzida, permitindo que o sistema convirja para o mínimo global ou para uma amostra representativa da distribuição original.

#### Simulated Annealing
O *Simulated Annealing* (SA) é um algoritmo estocástico para encontrar o ótimo global de uma função [^869]. Ele se assemelha ao algoritmo de *Metropolis-Hastings* para gerar amostras de uma distribuição de probabilidade [^869]. O SA pode ser usado para otimização discreta e contínua. O método é inspirado na física estatística. A quantidade chave é a distribuição de *Boltzmann*, que especifica que a probabilidade de estar em qualquer estado particular $x$ é dada por:

$$p(x) \propto \exp(-f(x)/T)$$

onde $f(x)$ é a "energia" do sistema e $T$ é a temperatura computacional [^869]. À medida que a temperatura se aproxima de 0 (o sistema é resfriado), o sistema passa mais e mais tempo em seu estado de energia mínima (estado mais provável) [^869]. Em altas temperaturas ($T \gg 1$), a superfície é aproximadamente plana, e, portanto, é fácil se mover (isto é, para evitar ótimos locais). À medida que a temperatura esfria, os picos maiores se tornam maiores e os menores desaparecem [^869]. Resfriando lentamente o suficiente, é possível "rastrear" o pico maior e, assim, encontrar o ótimo global [^869]. Isso é um exemplo de um método de continuação [^869].

Podemos gerar um algoritmo a partir disso da seguinte forma. A cada etapa, amostre um novo estado de acordo com alguma distribuição de proposta $x' \sim q(\cdot|x_k)$. Para parâmetros de valor real, isso geralmente é simplesmente uma proposta de caminhada aleatória, $x' = x_k + \epsilon_k$, onde $\epsilon_k \sim N(0, \Sigma)$ [^869]. Para otimização discreta, outros tipos de movimentos locais devem ser definidos [^869]. Tendo proposto um novo estado, calculamos

$$\alpha = \exp((f(x) - f(x'))/T)$$

Em seguida, aceitamos o novo estado (isto é, definimos $x_{k+1} = x'$) com probabilidade $\min(1, \alpha)$, caso contrário, permanecemos no estado atual (isto é, definimos $x_{k+1} = x_k$) [^869]. Isso significa que se o novo estado tem energia menor (é mais provável), vamos definitivamente aceitá-lo, mas se ele tem energia maior (é menos provável), ainda podemos aceitar, dependendo da temperatura atual [^869]. Assim, o algoritmo permite movimentos "descendentes" no espaço de probabilidade (ascendentes no espaço de energia), mas com menos frequência à medida que a temperatura cai [^869]. A taxa na qual a temperatura muda ao longo do tempo é chamada de *cooling schedule* [^870]. Praticamente, é comum usar um *cooling schedule* exponencial da seguinte forma: $T_k = T_0C^k$, onde $T_0$ é a temperatura inicial (muitas vezes $T_0 \sim 1$) e $C$ é a taxa de resfriamento (muitas vezes $C \sim 0.8$) [^870].

#### Annealed Importance Sampling
O *Annealed Importance Sampling* (AIS) combina ideias de *Simulated Annealing* e *Importance Sampling* para amostrar distribuições complexas [^871]. O AIS constrói uma sequência de distribuições intermediárias que se movem gradualmente de uma distribuição mais simples $p_n(x) \propto f_n(x)$ (por exemplo, o *a priori*) para a distribuição alvo $p_0(x) \propto f_0(x)$ (por exemplo, a distribuição *a posteriori*):

$$f(x) = f_0(x)^{\beta_i} f_n(x)^{1-\beta_i}$$

onde $1 = \beta_0 > \beta_1 > \dots > \beta_n = 0$, com $\beta_j$ sendo uma temperatura inversa [^871]. Uma série de cadeias de Markov $T_i(x, x')$ são usadas, deixando cada $p_i$ invariante [^871]. O objetivo é amostrar $x$ de $p_0$ amostrando uma sequência $z = (z_{n-1}, \dots, z_0)$ da seguinte forma: amostrar $z_{n-1} \sim p_n$; amostrar $z_{n-2} \sim T_{n-1}(z_{n-1}, \cdot)$; ...; amostrar $z_0 \sim T_1(z_1, \cdot)$. Finalmente, definimos $x = z_0$ e atribuímos o peso:

$$w = \frac{f_{n-1}(z_{n-1})}{f_n(z_{n-1})} \frac{f_{n-2}(z_{n-2})}{f_{n-1}(z_{n-2})} \dots \frac{f_1(z_1)}{f_2(z_1)} \frac{f_0(z_0)}{f_1(z_0)}$$

Essa abordagem pode ser vista como uma forma de *Importance Sampling* em um espaço de estados estendido [^871].

#### Parallel Tempering
Outra maneira de combinar MCMC e *Annealing* é executar múltiplas cadeias em paralelo em diferentes temperaturas [^871]. Isso permite que uma cadeia de alta temperatura faça movimentos de longa distância através do espaço de estados e tenha essa influência em cadeias de baixa temperatura. Essa técnica é conhecida como *Parallel Tempering* [^871].

### Conclusão
Os métodos de *Annealing* oferecem abordagens eficazes para lidar com distribuições multimodais em problemas de inferência e otimização [^868]. Ao suavizar a distribuição com um parâmetro de temperatura e resfriá-la gradualmente, esses métodos podem escapar de mínimos locais e encontrar o ótimo global ou gerar amostras representativas [^869]. *Simulated Annealing*, *Annealed Importance Sampling* e *Parallel Tempering* representam variações importantes dessa técnica, cada uma com suas próprias vantagens e desvantagens [^871]. A escolha do método mais adequado depende das características específicas do problema em questão.

### Referências
[^846]: Chapter 24. Markov chain Monte Carlo (MCMC) inference
[^868]: Annealing methods
[^869]: Simulated annealing
[^870]: The cooling schedule
[^871]: Annealed importance sampling
<!-- END -->