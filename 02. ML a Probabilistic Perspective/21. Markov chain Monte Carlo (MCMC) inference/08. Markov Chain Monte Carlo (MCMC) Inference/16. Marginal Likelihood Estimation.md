## Aproximando a Verossimilhança Marginal em MCMC

### Introdução
A verossimilhança marginal, denotada por $p(D|M)$ [^24.107], é uma quantidade fundamental na seleção de modelos Bayesianos, onde $D$ representa os dados e $M$ o modelo. Ela representa a probabilidade dos dados dado o modelo, integrando sobre todos os possíveis valores dos parâmetros $\theta$. No entanto, o cálculo direto dessa integral é frequentemente intratável, especialmente quando se lida com priors não-conjugados ou variáveis latentes [^24.107]. Métodos de Monte Carlo, como os abordados neste capítulo, oferecem alternativas para aproximar essa quantidade.

### Conceitos Fundamentais
A dificuldade em calcular a verossimilhança marginal reside na integral [^24.107]:
$$ p(D|M) = \int p(D|\theta, M)p(\theta|M) d\theta $$.
onde $p(D|\theta, M)$ é a verossimilhança dos dados dado os parâmetros e o modelo, e $p(\theta|M)$ é a distribuição *a priori* dos parâmetros dado o modelo.

#### O Método do Candidato
O método do candidato [^24.108], proposto por Chib (1995), explora a seguinte identidade:
$$ p(D|M) = \frac{p(D|\theta, M)p(\theta|M)}{p(\theta|D, M)} $$.
Essa identidade é válida para qualquer valor de $\theta$. A estratégia consiste em escolher um valor $\theta$, calcular a verossimilhança $p(D|\theta, M)$ e a *a priori* $p(\theta|M)$, e estimar a distribuição *a posteriori* $p(\theta|D, M)$ usando MCMC. No entanto, esse método assume que a *a posteriori* $p(\theta|D, M)$ marginalizou sobre todos os modos da distribuição, o que raramente é o caso na prática [^24.108]. Isso pode levar a resultados imprecisos, como observado por Neal (1998).

#### Estimativa da Média Harmônica
Newton e Raftery (1994) propuseram um método simples para aproximar $p(D)$ usando a saída do MCMC [^24.109]:
$$ \frac{1}{p(D)} \approx \frac{1}{S} \sum_{s=1}^{S} \frac{1}{p(D|\theta^{s})} $$.
onde $\theta^{s} \sim p(\theta|D)$. Essa expressão representa a média harmônica da verossimilhança dos dados sob cada amostra. A correção teórica dessa expressão decorre da identidade [^24.110]:
$$ \int \frac{1}{p(D|\theta)} p(\theta|D) d\theta = \int \frac{p(\theta)}{p(D|\theta)p(\theta)} p(D|\theta)d\theta = \frac{1}{p(D)} $$.
Apesar de sua simplicidade, esse método apresenta um desempenho insatisfatório na prática. Radford Neal o rotulou como "o pior método de Monte Carlo de todos os tempos" [^6]. A principal razão para seu baixo desempenho é a sua dependência exclusiva de amostras da distribuição *a posteriori*, que é frequentemente insensível à *a priori*, enquanto a verossimilhança marginal é altamente dependente da *a priori* [^24.110].

#### Annealed Importance Sampling
O *annealed importance sampling* (AIS) [^24.7.3], proposto por Neal (2001), combina ideias de *simulated annealing* e *importance sampling* para obter amostras independentes de distribuições complexas. A ideia central é construir uma sequência de distribuições intermediárias que conectam uma distribuição inicial fácil de amostrar, $p_n(x) \propto f_n(x)$, a distribuição alvo, $p_0(x) \propto f_0(x)$ [^24.102].

A sequência de distribuições é definida como [^24.102]:
$$ f_j(x) = f_0(x)^{\beta_j} f_n(x)^{1-\beta_j} $$
onde $1 = \beta_0 > \beta_1 > ... > \beta_n = 0$, e $\beta_j$ é uma "temperatura inversa". Em contraste com o *simulated annealing*, onde se usa $f_j(x) = f_0(x)^{\beta_j}$, o AIS torna mais fácil a amostragem de $p_n$.

Dado uma série de cadeias de Markov $T_j(x, x')$ que preservam cada $p_j$, podemos amostrar $x$ de $p_0$ amostrando uma sequência $z = (z_{n-1}, ..., z_0)$ da seguinte forma:
1. Amostre $z_{n-1} \sim p_n$.
2. Amostre $z_{n-2} \sim T_{n-1}(z_{n-1}, \cdot)$.
3. ...
4. Amostre $z_0 \sim T_1(z_1, \cdot)$.
5. Defina $x = z_0$ e atribua o peso [^24.103]:
$$ w = \frac{f_{n-1}(z_{n-1})}{f_n(z_{n-1})} \frac{f_{n-2}(z_{n-2})}{f_{n-1}(z_{n-2})} ... \frac{f_1(z_1)}{f_2(z_1)} \frac{f_0(z_0)}{f_1(z_0)} $$
AIS pode ser visto como *importance sampling* em um espaço de estados estendido $z = (z_0, ..., z_{n-1})$ [^24.104]. A distribuição nesse espaço é:
$$ p(z) \propto f(z) = f_0(z_0)T_1(z_0, z_1)T_2(z_1, z_2) ... T_{n-1}(z_{n-2}, z_{n-1}) $$
onde $T_j$ é o reverso de $T_j$:
$$ T_j(z, z') = T_j(z', z) \frac{p_j(z')}{p_j(z)} = T_j(z', z) \frac{f_j(z')}{f_j(z)} $$
É claro que $\int_{z_1 ... z_{n-1}} f(z) = f_0(z_0)$, então podemos usar $z_0$ para recuperar a distribuição original [^24.105]. A distribuição da proposta é definida como [^24.106]:
$$ q(z) \propto g(z) = f_n(z_{n-1})T_{n-1}(z_{n-1}, z_{n-2}) ... T_2(z_2, z_1)T_1(z_1, z_0) $$
Os pesos de importância $w = \frac{f(z_0, ..., z_{n-1})}{g(z_0, ..., z_{n-1})}$ são dados pela Equação 24.103.

Uma aplicação importante do AIS é na avaliação da razão de funções de partição [^24.7.3]. Observando que $Z_0 = \int f_0(x) dx = \int f_n(z) dz$ e $Z_n = \int f_n(x) dx = \int g(z) dz$, temos:
$$ \frac{Z_0}{Z_n} = \frac{\int \frac{f_0(z)}{g(z)} g(z) dz}{\int g(z) dz} = \mathbb{E}_{g(z)} \left[ \frac{f_0(z)}{g(z)} \right] \approx \frac{1}{S} \sum_{s=1}^S w_s $$
Se $f_n$ é uma *a priori* e $f_0$ é a *a posteriori*, podemos estimar $Z_n = p(D)$, desde que a *a priori* tenha uma constante de normalização conhecida $Z_0$. Essa é uma forma de avaliar funções de partição difíceis.

### Conclusão
A aproximação da verossimilhança marginal é um problema central na inferência Bayesiana, especialmente para a seleção de modelos. Embora métodos como o do candidato e a estimativa da média harmônica apresentem limitações, o *annealed importance sampling* oferece uma abordagem mais robusta e precisa. Ao combinar ideias de *simulated annealing* e *importance sampling*, o AIS permite estimar a razão de funções de partição e, consequentemente, aproximar a verossimilhança marginal, desde que a *a priori* possua uma constante de normalização conhecida.

### Referências
[^24.107]: C. Bishop, *Pattern Recognition and Machine Learning*. Springer, 2006.
[^24.108]: S. Chib, "Marginal likelihood from Gibbs output," *Journal of the American Statistical Association*, vol. 90, no. 432, pp. 1313-1321, 1995.
[^24.109]: A. E. Raftery, "Estimating Bayes factors," *Sociological Methodology*, vol. 25, pp. 111-163, 1995.
[^6]: R. Neal, "The harmonic mean of the likelihood: Worst Monte Carlo method ever," [Online]. Available: radfordneal.wordpress.com/2008/08/17/the-harmonic-mean-of-the-likelihood-worst-monte-carlo-method-ever.
[^24.7.3]: R. M. Neal, "Annealed importance sampling," *Statistics and Computing*, vol. 11, no. 2, pp. 125-139, 2001.

<!-- END -->