## MCMC: Um Algoritmo Fundamental para Inferência Bayesiana e Aprendizado de Máquina

### Introdução
O algoritmo Markov Chain Monte Carlo (MCMC), originário da física, ganhou popularidade na estatística Bayesiana e no aprendizado de máquina, oferecendo uma alternativa à inferência variacional, especialmente para modelos complexos ou grandes conjuntos de dados [^1]. Os métodos MCMC são usados para amostrar de distribuições de alta dimensão, abordando as limitações de métodos Monte Carlo mais simples, como rejection sampling e importance sampling, nesses espaços [^1]. A ampla adoção do MCMC se deve à sua aplicabilidade a uma ampla gama de modelos, incluindo aqueles com tamanho ou estrutura variáveis dependendo dos valores das variáveis ou modelos sem priors conjugados, oferecendo uma alternativa aos métodos variacionais, especialmente para grandes conjuntos de dados [^1].

### Conceitos Fundamentais

O MCMC é uma técnica poderosa para aproximar distribuições de probabilidade complexas, especialmente em espaços de alta dimensão, onde métodos tradicionais de integração ou otimização se tornam inviáveis [^1]. A ideia básica por trás do MCMC é construir uma **cadeia de Markov** no espaço de estados $X$, cuja distribuição estacionária é a densidade alvo $p^*(x)$ de interesse [^1]. Esta densidade pode ser um *prior* ou *posterior*.

*Em outras palavras, realizamos um passeio aleatório no espaço de estados, de tal forma que a fração de tempo que passamos em cada estado $x$ seja proporcional a $p^*(x)$. Ao desenhar amostras (correlacionadas!) $x_0, x_1, x_2, ...$ da cadeia, podemos realizar a integração de Monte Carlo em relação a $p^*$.* [^1]

O MCMC tem uma história interessante [^1]. Foi descoberto por físicos que trabalhavam na bomba atômica em Los Alamos durante a Segunda Guerra Mundial e foi publicado pela primeira vez na literatura aberta em (Metropolis et al. 1953) em um periódico de química [^1]. Uma extensão foi publicada na literatura estatística em (Hastings 1970), mas passou em grande parte despercebida [^1]. Um caso especial (Gibbs sampling, Section 24.2) foi inventado independentemente em 1984 no contexto de modelos de Ising e foi publicado em (Geman and Geman 1984) [^1]. Mas foi somente até (Gelfand and Smith 1990) que o algoritmo se tornou bem conhecido na comunidade estatística mais ampla [^1]. Desde então, tornou-se extremamente popular na estatística Bayesiana e está se tornando cada vez mais popular no aprendizado de máquina [^1].

**Vantagens do MCMC em relação à Inferência Variacional:**

*   É frequentemente mais fácil de implementar [^1].
*   É aplicável a uma gama mais ampla de modelos, como modelos cujo tamanho ou estrutura muda dependendo dos valores de certas variáveis (e.g., como acontece em problemas de correspondência), ou modelos sem priors conjugados [^1].
*   A amostragem pode ser mais rápida que os métodos variacionais quando aplicada a conjuntos de dados realmente grandes [^1].

A razão é que a amostragem passa valores específicos de variáveis (ou conjuntos de variáveis), enquanto que na inferência variacional, passamos distribuições [^1]. Assim, a amostragem passa mensagens esparsas, enquanto a inferência variacional passa mensagens densas [^1].

### Conclusão

O MCMC representa uma ferramenta essencial no arsenal de um cientista de dados ou estatístico moderno, especialmente ao lidar com modelos complexos e dados de alta dimensão. Embora possa ser computacionalmente intensivo e exija um certo cuidado na implementação e diagnóstico, sua flexibilidade e aplicabilidade o tornam indispensável para inferência Bayesiana e aprendizado de máquina [^1]. Sua capacidade de amostrar diretamente de distribuições complexas, sem as restrições de priors conjugados ou aproximações variacionais, o torna particularmente valioso em cenários onde a precisão e a fidelidade ao modelo são primordiais [^1].
<!-- END -->