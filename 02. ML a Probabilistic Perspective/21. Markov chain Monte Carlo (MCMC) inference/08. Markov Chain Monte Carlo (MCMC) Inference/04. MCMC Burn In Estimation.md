## Burn-in em Markov Chain Monte Carlo (MCMC)

### Introdução
Em métodos de inferência baseados em Markov Chain Monte Carlo (MCMC), um desafio fundamental é assegurar que a cadeia de Markov tenha convergido para sua **distribuição estacionária** [^1, ^2, ^3]. Este processo é conhecido como *burn-in*. Amostras coletadas antes da cadeia atingir a distribuição estacionária podem introduzir *bias* nos resultados da inferência [^1, ^2, ^3]. Este capítulo explora em detalhes o conceito de *burn-in*, sua importância e estratégias para sua identificação e mitigação.

### Conceitos Fundamentais

**Distribuição Estacionária e Burn-in:**
A base do MCMC é construir uma cadeia de Markov no espaço de estados $\mathcal{X}$ cuja distribuição estacionária seja a densidade alvo $p^*(x)$ de interesse [^1]. Essa densidade pode representar uma *prior* ou uma *posterior*. Idealmente, após um número suficiente de iterações, a fração de tempo que a cadeia passa em cada estado $x$ é proporcional a $p^*(x)$ [^1].

No entanto, ao iniciar a cadeia de Markov de um estado arbitrário, as primeiras amostras podem refletir mais a distribuição inicial do que a distribuição alvo [^1, ^2, ^3]. O período de *burn-in* é o número de iterações necessárias para que a influência da distribuição inicial se dissipe e a cadeia comece a gerar amostras representativas de $p^*(x)$ [^2].

> É crucial descartar as amostras coletadas durante a fase de *burn-in* para evitar o *bias* nas estimativas [^1, ^2, ^3].

**Gibbs Sampling e Burn-in:**
Mesmo no contexto do *Gibbs sampling*, um dos algoritmos MCMC mais populares [^2], a fase de *burn-in* é essencial. No *Gibbs sampling*, cada variável é amostrada condicionalmente aos valores das demais [^2]. Embora o *Gibbs sampling* garanta a convergência para a distribuição estacionária, as amostras iniciais podem ainda ser influenciadas pelo ponto de partida [^2].

**Diagnóstico do Burn-in:**
Determinar quando o *burn-in* ocorreu é um problema complexo e um dos maiores desafios do MCMC [^2, ^20]. Não existe um método universalmente aplicável, e a maioria das abordagens são heurísticas que indicam *não-convergência* em vez de *convergência* [^24]. Algumas técnicas comuns incluem:

1.  **Análise Visual de Trace Plots:** Executar múltiplas cadeias a partir de pontos iniciais *overdispersed* e observar os *trace plots* de algumas variáveis de interesse [^24]. Se as cadeias convergirem para a mesma distribuição e se sobrepuserem, isso sugere que o *burn-in* foi alcançado.
2.  **EPSR (Estimated Potential Scale Reduction):** Comparar a variância de uma quantidade dentro de cada cadeia com a variância entre as cadeias [^24]. O EPSR quantifica o quanto a variância *posterior* diminuiria se continuássemos amostrando. Valores de EPSR próximos a 1 indicam que as cadeias convergiram [^24].
3.  **Autocorrelação:** Calcular a função de autocorrelação (ACF) das amostras [^24]. Uma ACF que decai rapidamente para zero indica que as amostras são menos correlacionadas e, portanto, mais representativas da distribuição estacionária.
4.  **Teste de Gelman-Rubin:** Este teste compara a variância dentro das cadeias com a variância entre as cadeias. Um valor próximo de 1 indica convergência.

**Metropolis-Hastings e Burn-in:**
Assim como no *Gibbs sampling*, o algoritmo de *Metropolis-Hastings* (MH) também requer uma fase de *burn-in* [^24]. O MH é um algoritmo mais geral que permite a amostragem de distribuições para as quais o *Gibbs sampling* não é diretamente aplicável [^24]. A escolha da distribuição de proposta $q(x'|x)$ influencia significativamente a eficiência do algoritmo e, consequentemente, o tempo necessário para o *burn-in* [^24].

### Conclusão
O *burn-in* é uma etapa crítica na inferência via MCMC. A escolha de um número adequado de iterações de *burn-in* é essencial para garantir a validade das amostras e a precisão das estimativas [^1, ^2, ^3]. As técnicas de diagnóstico de convergência, como análise de *trace plots*, EPSR e autocorrelação, fornecem ferramentas valiosas para avaliar se o *burn-in* foi alcançado e se as amostras subsequentes podem ser usadas para inferência estatística [^24]. A complexidade em diagnosticar o *burn-in* ressalta uma das fraquezas fundamentais do MCMC [^2].

### Referências
[^1]: Capítulo 24, Markov chain Monte Carlo (MCMC) inference, página 837
[^2]: Capítulo 24, Markov chain Monte Carlo (MCMC) inference, página 838
[^3]: Capítulo 24, Markov chain Monte Carlo (MCMC) inference, página 839
[^20]: Capítulo 24, Markov chain Monte Carlo (MCMC) inference, página 848
[^24]: Capítulo 24, Markov chain Monte Carlo (MCMC) inference, página 859
<!-- END -->