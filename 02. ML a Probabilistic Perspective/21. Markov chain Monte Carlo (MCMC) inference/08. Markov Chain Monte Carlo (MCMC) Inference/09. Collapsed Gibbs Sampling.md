## Collapsed Gibbs Sampling: Integrating Out Unknowns for Enhanced Efficiency

### Introdução
Em continuidade ao estudo de métodos de inferência MCMC, este capítulo detalha uma técnica avançada conhecida como **collapsed Gibbs sampling**. Como vimos anteriormente, Gibbs sampling é um algoritmo popular que amostra cada variável condicionado aos valores das outras [^838]. No entanto, *collapsed Gibbs sampling* eleva essa abordagem ao integrar analiticamente algumas quantidades desconhecidas, levando a um espaço de amostragem de menor dimensão e, consequentemente, a uma inferência mais eficiente [^841]. Este capítulo explorará os fundamentos teóricos e práticos do *collapsed Gibbs sampling*, demonstrando como ele se relaciona com o teorema de Rao-Blackwell e fornecendo exemplos concretos de sua aplicação.

### Conceitos Fundamentais
O *collapsed Gibbs sampling* é uma variação do Gibbs sampling que se destaca pela sua capacidade de **integrar analiticamente** certas variáveis desconhecidas, como os parâmetros $\theta$, antes de realizar a amostragem [^841]. Em vez de amostrar diretamente a partir da distribuição conjunta $p(\theta, z | D)$, onde $z$ representa as variáveis latentes e $D$ os dados, o *collapsed Gibbs sampling* amostra de $p(z | D)$ [^841].

Essa integração tem duas vantagens principais:
1.  **Redução da Dimensionalidade:** Ao eliminar $\theta$ do processo de amostragem, reduzimos a dimensionalidade do espaço de amostragem, o que pode levar a uma convergência mais rápida e eficiente [^841].
2.  **Redução da Variância:** A integração analítica de $\theta$ pode reduzir a variância das estimativas, conforme garantido pelo **teorema de Rao-Blackwell** [^841].

**Teorema 24.2.1 (Rao-Blackwell):** Sejam $z$ e $\theta$ variáveis aleatórias dependentes, e seja $f(z, \theta)$ uma função escalar qualquer. Então [^841]:
$$var_{z,\theta}[f(z, \theta)] \geq var_z[E_{\theta}[f(z, \theta) | z]]$$

Este teorema implica que a variância da estimativa criada pela integração analítica de $\theta$ será sempre menor (ou, no máximo, igual) à variância de uma estimativa de Monte Carlo direta [^841]. Em outras palavras, ao integrar $\theta$, estamos essencialmente calculando o valor esperado de $f(z, \theta)$ em relação a $\theta$, o que resulta em uma estimativa mais precisa.

No contexto do *collapsed Gibbs sampling*, amostramos $z$ com $\theta$ integrado; o teorema de Rao-Blackwell ainda se aplica neste caso (Liu et al. 1994) [^841].

Após a amostragem de $z$, podemos obter amostras de $\theta$ a partir da distribuição condicional $p(\theta | z, D)$. Essa amostragem é geralmente mais eficiente, pois as amostras de $z$ já capturam a informação essencial sobre a estrutura do modelo [^841]. As amostras de $\theta$ são, então, condicionalmente independentes, dadas as amostras de $z$, o que pode reduzir ainda mais a variância [^841].
$$theta^s \sim p(\theta | z^s, D)$$

**Exemplo: Collapsed Gibbs para um GMM**

Considere um *Gaussian Mixture Model* (GMM) com um *fully conjugate prior*. Podemos integrar analiticamente os parâmetros do modelo $\mu_k$, $\Sigma_k$ e $\pi$ e apenas amostrar os indicadores $z$ [^842]. Após integrar $\pi$, todos os nós $z_i$ tornam-se interdependentes. Similarmente, após integrar $\theta_k$, todos os nós $x_i$ tornam-se interdependentes, como mostrado na Figura 24.2(b) [^842]. No entanto, podemos facilmente calcular as condicionais completas da seguinte forma [^842]:
$$p(z_i = k | z_{-i}, x, \alpha, \beta) \propto p(z_i = k | z_{-i}, \alpha) p(x | z_i = k, z_{-i}, \beta) \propto p(z_i = k | z_{-i}, \alpha) p(x_i | x_{-i}, z_i = k, z_{-i}, \beta)$$
onde $\beta = (m_0, V_0, S_0, v_0)$ são os hiperparâmetros para as densidades condicionais de classe [^842]. O primeiro termo pode ser obtido integrando $\pi$. Suponha que usamos um *symmetric prior* da forma $\pi \sim Dir(\alpha)$, onde $\alpha_k = \alpha / K$. Da Equação 5.26, temos [^842]:
$$p(z_1, ..., z_N | \alpha) = \frac{\Gamma(\alpha)}{\Gamma(N + \alpha)} \prod_{k=1}^K \frac{\Gamma(N_k + \alpha / K)}{\Gamma(\alpha / K)}$$
Portanto [^843]:
$$p(z_i = k | z_{-i}, \alpha) = \frac{\frac{p(z_{1:N} | \alpha)}{p(z_{-i} | \alpha)}}{p(z_{-i} | \alpha)} = \frac{\frac{\Gamma(N + \alpha)}{\Gamma(N + \alpha - 1)} \frac{\Gamma(N_k + \alpha / K)}{\Gamma(N_{k, -i} + \alpha / K)}}{\frac{\Gamma(\alpha)}{\Gamma(\alpha / K)}} = \frac{\Gamma(N + \alpha)}{\Gamma(N + \alpha - 1)} \frac{\Gamma(N_k + \alpha / K)}{\Gamma(N_{k, -i} + \alpha / K)} \frac{\frac{\Gamma(N + \alpha - 1)}{\Gamma(N + \alpha)} \frac{\Gamma(N_{k, -i} + 1 + \alpha / K)}{\Gamma(N_k + \alpha / K)}}{\Gamma(N_{k, -i} + \alpha / K)} = \frac{N_{k, -i} + \alpha / K}{N + \alpha - 1}$$
onde $N_{k,-i} = \sum_{n \neq i} I(z_n = k) = N_k - 1$, e onde exploramos o fato de que $\Gamma(x + 1) = x\Gamma(x)$ [^843].

Para obter o segundo termo na Equação 24.23, que é a distribuição preditiva posterior para $x_i$ dado todos os outros dados e todas as atribuições, usamos o fato de que [^843]:
$$p(x_i | X_{-i}, Z_{-i}, z_i = k, \beta) = p(x_i | D_{-i,k})$$
onde $D_{-i,k} = \{x_j : z_j = k, j \neq i\}$ são todos os dados atribuídos ao cluster $k$ exceto por $x_i$ [^843].

### Conclusão
O *collapsed Gibbs sampling* oferece uma abordagem poderosa para melhorar a eficiência da inferência MCMC ao integrar analiticamente variáveis desconhecidas. Ao reduzir a dimensionalidade do espaço de amostragem e reduzir a variância das estimativas, essa técnica pode levar a uma convergência mais rápida e precisa. Como vimos, o teorema de Rao-Blackwell fornece uma base teórica para a redução da variância observada no *collapsed Gibbs sampling*. Embora a aplicação do *collapsed Gibbs sampling* possa ser complexa, seus benefícios em termos de eficiência computacional e precisão estatística o tornam uma ferramenta valiosa no arsenal de qualquer pesquisador que trabalhe com modelos probabilísticos complexos.

### Referências
[^838]: Capítulo 24. Markov chain Monte Carlo (MCMC) inference, página 838
[^841]: Capítulo 24. Markov chain Monte Carlo (MCMC) inference, página 841
[^842]: Capítulo 24. Markov chain Monte Carlo (MCMC) inference, página 842
[^843]: Capítulo 24. Markov chain Monte Carlo (MCMC) inference, página 843
<!-- END -->