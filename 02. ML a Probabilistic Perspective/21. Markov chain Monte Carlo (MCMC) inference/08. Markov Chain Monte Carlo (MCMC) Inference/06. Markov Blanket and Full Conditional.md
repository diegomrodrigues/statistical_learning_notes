## Gibbs Sampling: Full Conditionals e a Markov Blanket

### Introdução

Este capítulo aprofunda o conceito de **full conditional** dentro do contexto do *Gibbs sampling*, um dos algoritmos MCMC mais populares [^3]. Como vimos anteriormente, os métodos de Monte Carlo, incluindo *rejection sampling* e *importance sampling*, podem apresentar dificuldades em espaços de alta dimensionalidade [^24.1]. O Gibbs sampling oferece uma alternativa eficaz, especialmente quando as distribuições condicionais completas são conhecidas ou podem ser facilmente amostradas. Exploraremos como as dependências em modelos gráficos influenciam a construção dessas distribuições condicionais, utilizando o conceito de **Markov blanket**.

### Conceitos Fundamentais

O Gibbs sampling é um algoritmo iterativo onde cada variável é amostrada condicionalmente aos valores mais recentes de todas as outras variáveis [^24.2]. Dada uma amostra conjunta $x^s$ de todas as variáveis, uma nova amostra $x^{s+1}$ é gerada amostrando cada componente por vez, utilizando os valores mais recentes das outras variáveis. Por exemplo, com $D = 3$ variáveis:

*   $x_1^{s+1} \sim p(x_1 | x_2^s, x_3^s)$
*   $x_2^{s+1} \sim p(x_2 | x_1^{s+1}, x_3^s)$
*   $x_3^{s+1} \sim p(x_3 | x_1^{s+1}, x_2^{s+1})$

Este processo generaliza-se diretamente para $D$ variáveis. Variáveis visíveis (observadas) não são amostradas, pois seus valores já são conhecidos [^24.2].

A expressão $p(x_i | x_{-i})$ é denominada **full conditional** para a variável $i$ [^24.2]. Aqui, $x_{-i}$ representa todas as variáveis exceto $x_i$. Em geral, $x_i$ pode depender apenas de um subconjunto das outras variáveis. A estrutura de dependência é crucial para simplificar o processo de amostragem.

**Markov Blanket e Modelos Gráficos**

A conexão entre o **full conditional** e os modelos gráficos reside na **Markov blanket**. Se a distribuição $p(x)$ é representada por um modelo gráfico, as dependências podem ser inferidas observando o *Markov blanket* de $i$ [^24.2]. O *Markov blanket* de um nó em um grafo é o conjunto de seus pais, filhos e os pais de seus filhos. Assim, para amostrar $x_i$, é suficiente conhecer os valores dos vizinhos de $i$ no grafo, ou seja, seu *Markov blanket*.

> Se representarmos $p(x)$ como um modelo gráfico, podemos inferir as dependências observando o *Markov blanket* de $i$, que são seus vizinhos no grafo. [^24.2]

Em outras palavras, $p(x_i | x_{-i}) = p(x_i | MB(x_i))$, onde $MB(x_i)$ denota o *Markov blanket* de $x_i$. Essa propriedade é fundamental para tornar o *Gibbs sampling* computacionalmente viável em modelos complexos.

**Exemplo: Modelo de Ising**

Para ilustrar, considere o Modelo de Ising, frequentemente utilizado em problemas de física estatística e visão computacional [^24.2.2]. No contexto de um *pairwise Markov Random Field (MRF)* ou *Conditional Random Field (CRF)*, o modelo assume a forma:

$$ p(X_t | x_{-t}, \theta) \propto \prod_{s \in nbr(t)} \psi_{st}(x_s, x_t) $$

onde $nbr(t)$ representa os vizinhos de $t$ e $\psi_{st}(x_s, x_t)$ são as *edge potentials* [^24.2.2]. No caso específico do Modelo de Ising com *edge potentials* $\psi(x_s, x_t) = \exp(J x_s x_t)$, onde $x_t \in \{-1, +1\}$, o *full conditional* torna-se:

$$ p(x_t = +1 | x_{-t}, \theta) = \frac{\exp[J \sum_{s \in nbr(t)} x_s]}{\exp[J \sum_{s \in nbr(t)} x_s] + \exp[-J \sum_{s \in nbr(t)} x_s]} = \text{sigm}(2J n_t) $$

onde $J$ é a *coupling strength*, $n_t \equiv \sum_{s \in nbr(t)} x_s$ e $\text{sigm}(u) = 1/(1 + e^{-u})$ é a função sigmóide [^24.2.2].

**Implementação e Considerações**

A implementação do *Gibbs sampling* é geralmente mais fácil do que outros métodos MCMC [^24.1]. No entanto, é crucial descartar as amostras iniciais até que a cadeia de Markov convirja para a distribuição estacionária, um período conhecido como *burn-in* [^24.2]. A determinação do momento em que o *burn-in* ocorre pode ser desafiadora [^24.4.1].

O *Gibbs sampling* pode ser interpretado como um algoritmo distribuído, pois a amostragem de cada variável depende apenas de seu *Markov blanket* [^24.2]. No entanto, a natureza sequencial do algoritmo impede a sua paralelização direta.

### Conclusão

O *Gibbs sampling*, com sua dependência nas *full conditionals* e na estrutura de dependência revelada pelo *Markov blanket*, oferece uma abordagem eficiente para amostragem em modelos estatísticos complexos [^24.2]. A facilidade de implementação e a capacidade de explorar distribuições de alta dimensionalidade o tornam uma ferramenta valiosa no arsenal do cientista de dados e do estatístico. Contudo, a escolha do *burn-in* e a análise da convergência são aspectos críticos para garantir a validade dos resultados obtidos.

### Referências

[^3]: Josiah Willard Gibbs, 1839–1903, was an American physicist.
[^24.1]: See page 837
[^24.2]: See page 838
[^24.2.2]: See page 838
[^24.4.1]: See page 856
<!-- END -->