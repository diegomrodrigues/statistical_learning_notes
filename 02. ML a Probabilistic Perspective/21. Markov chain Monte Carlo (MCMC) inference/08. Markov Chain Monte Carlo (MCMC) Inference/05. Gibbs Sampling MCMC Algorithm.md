## Gibbs Sampling: Uma Análise Detalhada

### Introdução
O presente capítulo visa explorar em profundidade o Gibbs sampling, um algoritmo popular de Markov Chain Monte Carlo (MCMC) [^1, ^2]. Este método, análogo ao coordinate descent [^3], amostra cada variável condicionado aos valores atuais de todas as outras variáveis na distribuição [^3]. O Gibbs sampling se generaliza facilmente para *D* variáveis e infere dependências a partir do Markov blanket em modelos gráficos [^3]. Este capítulo detalhará o funcionamento do Gibbs sampling, suas propriedades e aplicações, construindo sobre os conceitos de MCMC introduzidos anteriormente [^1].

### Conceitos Fundamentais
O Gibbs sampling é um método MCMC no qual cada variável é amostrada por vez, condicionado aos valores das outras variáveis na distribuição conjunta [^3]. A ideia central é que, dado um conjunto de amostras $x^s$ de todas as variáveis, geramos uma nova amostra $x^{s+1}$ amostrando cada componente por vez, com base nos valores mais recentes das outras variáveis [^3].

Formalmente, para um conjunto de variáveis $x = (x_1, x_2, ..., x_D)$, o Gibbs sampling procede da seguinte forma [^3]:

1.  Inicialize as variáveis $x_1, x_2, ..., x_D$ com valores aleatórios ou por algum outro método.
2.  Para cada iteração $s$:
    *   Amostre $x_1^{s+1} \sim p(x_1 | x_2^s, x_3^s, ..., x_D^s)$
    *   Amostre $x_2^{s+1} \sim p(x_2 | x_1^{s+1}, x_3^s, ..., x_D^s)$
    *   ...
    *   Amostre $x_D^{s+1} \sim p(x_D | x_1^{s+1}, x_2^{s+1}, ..., x_{D-1}^{s+1})$

Para *D* = 3 variáveis, por exemplo, as etapas seriam [^3]:

*   $x_1^{s+1} \sim p(x_1 | x_2^s, x_3^s)$
*   $x_2^{s+1} \sim p(x_2 | x_1^{s+1}, x_3^s)$
*   $x_3^{s+1} \sim p(x_3 | x_1^{s+1}, x_2^{s+1})$

A expressão $p(x_i | x_{-i})$ é chamada de **full conditional** para a variável *i* [^3]. Em geral, $x_i$ pode depender apenas de algumas das outras variáveis. Se representarmos $p(x)$ como um modelo gráfico, podemos inferir as dependências observando o Markov blanket de *i*, que são seus vizinhos no grafo [^3]. Assim, para amostrar $x_i$, só precisamos conhecer os valores dos vizinhos de *i* [^3]. Nesse sentido, o Gibbs sampling é um algoritmo distribuído [^3]. No entanto, não é um algoritmo paralelo, pois as amostras devem ser geradas sequencialmente [^3].

> É importante descartar algumas das amostras iniciais até que a cadeia de Markov tenha "burned in" ou entrado em sua distribuição estacionária [^3].

Esse processo é conhecido como **burn-in**. A Seção 24.4.1 discute como estimar quando o burn-in ocorreu [^3].

#### Gibbs Sampling para o Modelo de Ising
No contexto de modelos gráficos, o Gibbs sampling pode ser aplicado, por exemplo, ao modelo de Ising [^3]. Em modelos MRF/CRF pairwise, o Gibbs sampling assume a forma [^3]:
$$p(x_t|x_{-t}, \theta) \propto \prod_{s \in nbr(t)} \psi_{st}(x_s, x_t) \tag{24.1}$$
onde $nbr(t)$ denota os vizinhos do nó $t$ [^3]. No caso de um modelo de Ising com potenciais de aresta $\psi(x_s, x_t) = exp(Jx_sx_t)$, onde $x_t \in \{-1, +1\}$, a full conditional se torna [^3]:
$$p(x_t = +1 | x_{-t}, \theta) = \frac{\prod_{s \in nbr(t)} \psi_{st}(x_t = +1, x_s)}{\prod_{s \in nbr(t)} \psi_{st}(x_t = +1, x_s) + \prod_{s \in nbr(t)} \psi_{st}(x_t = -1, x_s)} \tag{24.2}$$
$$= \frac{exp[J\sum_{s \in nbr(t)} x_s]}{exp[J\sum_{s \in nbr(t)} x_s] + exp[-J\sum_{s \in nbr(t)} x_s]} \tag{24.3}$$
$$= \frac{exp[Jn_t]}{exp[Jn_t] + exp[-Jn_t]} = sigm(2Jn_t) \tag{24.4}$$
onde *J* é a força de acoplamento, $n_t \equiv \sum_{s \in nbr(t)} x_s$ e $sigm(u) = 1/(1+e^{-u})$ é a função sigmoide [^3]. É fácil ver que $n_t = x_+(a_t - d_t)$, onde $a_t$ é o número de vizinhos que concordam (têm o mesmo sinal que) *t*, e $d_t$ é o número de vizinhos que discordam [^3]. Se esse número for igual, as "forças" em $x_t$ se cancelam, então a full conditional é uniforme [^3].

Podemos combinar um prior de Ising com um termo de evidência local $V_t$. Por exemplo, com um modelo de observação Gaussiana, temos $V_t(x_t) = N(y_t | x_t, \sigma^2)$. A full conditional se torna [^3]:
$$p(x_t = +1 | x_{-t}, y, \theta) = \frac{exp[Jn_t]V_t(+1)}{exp[Jn_t]V_t(+1) + exp[-Jn_t]V_t(-1)} \tag{24.5}$$
$$= sigm(2Jn_t - log(\frac{V_t(+1)}{V_t(-1)})) \tag{24.6}$$
Agora, a probabilidade de $x_t$ entrar em cada estado é determinada tanto pela compatibilidade com seus vizinhos (o prior de Ising) quanto pela compatibilidade com os dados (o termo de verossimilhança local) [^3].

#### Gibbs Sampling para inferir os parâmetros de um GMM
O Gibbs sampling também pode ser aplicado para inferir os parâmetros de um modelo de mistura Gaussiana (GMM) [^3]. Se utilizarmos priors conjugados, a derivação se torna mais simples. Suponha que usemos um prior semi-conjugado. Então, a distribuição conjunta completa é dada por [^3]:
$$p(x, z, \mu, \Sigma, \pi) = p(x|z, \mu, \Sigma)p(z|\pi)p(\pi) \prod_{k=1}^{K} p(\mu_k)p(\Sigma_k) \tag{24.7}$$
$$= (\prod_{i=1}^{N} \prod_{k=1}^{K} (N(x_i|\mu_k, \Sigma_k)^{I(z_i=k)})) \times Dir(\pi|\alpha) \prod_{k=1}^{K} N(\mu_k|m_0, V_0)IW(\Sigma_k|S_0, v_0) \tag{24.8}$$
$$Dir(\pi|\alpha) = \prod_{k=1}^{K} N(\mu_k|m_0, V_0)IW(\Sigma_k|S_0, v_0) \tag{24.9}$$
onde *N* é o número de pontos de dados, *K* é o número de componentes da mistura, $z_i$ são as variáveis de atribuição latentes, $\mu_k$ e $\Sigma_k$ são a média e a covariância da *k*-ésima componente, e $\pi$ são os pesos de mistura [^3]. Usamos o mesmo prior para cada componente da mistura. As full conditionals são as seguintes:
$$p(z_i = k|x_i, \mu, \Sigma, \pi) \propto \pi_k N(x_i|\mu_k, \Sigma_k) \tag{24.10}$$
$$p(\pi|z) = Dir(\{\alpha_k + \sum_{i=1}^{N} I(z_i=k)\}_{k=1}^{K}) \tag{24.11}$$
$$p(\mu_k|\Sigma_k, z, x) = N(\mu_k|m_k, V_k) \tag{24.12}$$
$$V_k^{-1} = V_0^{-1} + N_k \Sigma_k^{-1} \tag{24.13}$$
$$m_k = V_k(\Sigma_k^{-1} \sum_{i=1}^{N} I(z_i=k) x_i + V_0^{-1} m_0) \tag{24.14}$$
$$N_k = \sum_{i=1}^{N} I(z_i=k) \tag{24.15}$$
$$x_k = \sum_{i=1}^{N} I(z_i=k)x_i \tag{24.16}$$
$$p(\Sigma_k|\mu_k, z, x) = IW(\Sigma_k| S_k, v_k) \tag{24.17}$$
$$S_k = S_0 + \sum_{i=1}^{N} I(z_i=k)(x_i - \mu_k)(x_i - \mu_k)^T \tag{24.18}$$
$$v_k = v_0 + N_k \tag{24.19}$$

#### Label Switching
Apesar de simples de implementar, o Gibbs sampling para modelos de mistura tem uma fraqueza fundamental: os parâmetros do modelo $\theta$ e as funções indicadoras z são não identificáveis, pois podemos permutar arbitrariamente os rótulos ocultos sem afetar a verossimilhança [^3]. Consequentemente, não podemos simplesmente fazer uma média de Monte Carlo das amostras para calcular as médias posteriores, pois o que uma amostra considera os parâmetros para o cluster 1 pode ser o que outra amostra considera os parâmetros para o cluster 2 [^3]. Isso é chamado de **label switching problem** [^3]. Uma solução é perguntar por quantidades observáveis [^3].

#### Collapsed Gibbs sampling
Em alguns casos, podemos integrar analiticamente algumas das quantidades desconhecidas e apenas amostrar o restante [^3]. Isso é chamado de **collapsed Gibbs sampler**, e tende a ser muito mais eficiente, pois está amostrando em um espaço de dimensão inferior [^3]. Mais precisamente, suponha que amostramos z e integramos $\theta$ [^3]. Assim, os parâmetros não participam da cadeia de Markov; consequentemente, podemos desenhar amostras condicionalmente independentes $\theta^s \sim p(\theta|z^s, D)$, que terão uma variância muito menor do que as amostras retiradas do espaço de estado conjunto [^3]. Este processo é chamado de **Rao-Blackwellisation**, nomeado após o seguinte teorema [^3]:

**Teorema 24.2.1 (Rao-Blackwell).** Seja z e $\theta$ variáveis aleatórias dependentes, e f(z, $\theta$) seja alguma função escalar. Então [^3]:
$$var_{z,\theta}[f(z, \theta)] \geq var_z[E_{\theta}[f(z, \theta)|z]] \tag{24.20}$$
Este teorema garante que a variância da estimativa criada integrando analiticamente $\theta$ será sempre menor (ou melhor, nunca será maior) do que a variância de uma estimativa MC direta [^3]. No collapsed Gibbs, amostramos z com $\theta$ integrado; o teorema de Rao-Blackwell acima ainda se aplica neste caso [^3].

### Conclusão

O Gibbs sampling é uma ferramenta poderosa e amplamente utilizada para inferência em modelos probabilísticos complexos [^3]. Sua simplicidade conceitual e facilidade de implementação o tornam atraente para uma variedade de aplicações [^3]. No entanto, é crucial estar ciente de suas limitações, como a necessidade de diagnosticar a convergência e lidar com problemas como label switching [^3]. As extensões do Gibbs sampling, como o collapsed Gibbs sampling, buscam melhorar sua eficiência e robustez [^3].

### Referências
[^1]: Section 17.2
[^2]: Chapter 23
[^3]: Chapter 24
<!-- END -->