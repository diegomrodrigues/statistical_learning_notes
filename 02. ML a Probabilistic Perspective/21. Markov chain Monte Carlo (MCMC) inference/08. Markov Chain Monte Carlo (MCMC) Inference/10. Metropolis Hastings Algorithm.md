## O Algoritmo de Metropolis-Hastings

### Introdução
Em continuidade ao Capítulo 23, que introduziu métodos de Monte Carlo como *rejection sampling* e *importance sampling* [^24.1], este capítulo aborda o *Markov chain Monte Carlo (MCMC)*, uma técnica popular para amostragem de distribuições de alta dimensionalidade [^24.1]. Especificamente, este capítulo se aprofunda no algoritmo de Metropolis-Hastings (MH), uma generalização do método MCMC [^24.3]. O algoritmo MH propõe movimentos para novos estados com base em uma distribuição de proposta $q(x\'|x)$ e aceita ou rejeita o movimento para garantir a distribuição estacionária correta [^24.3]. Este capítulo explorará os fundamentos, a correção de Hastings e a relação com o *Gibbs sampling* [^24.3].

### Conceitos Fundamentais
O algoritmo de **Metropolis-Hastings (MH)** é um método MCMC que generaliza o Gibbs sampling [^24.3]. Enquanto o Gibbs sampling requer amostrar diretamente das distribuições condicionais completas, o MH permite a utilização de uma distribuição de proposta arbitrária $q(x\'|x)$ para sugerir novos estados [^24.3].

A ideia básica do algoritmo MH é, a cada passo, propor um movimento do estado atual $x$ para um novo estado $x\'$ com probabilidade $q(x\'|x)$, onde $q$ é chamada de **distribuição de proposta** (ou *kernel*) [^24.3]. O usuário tem a liberdade de usar qualquer tipo de proposta que desejar, sujeito a algumas condições que serão explicadas adiante [^24.3]. Uma proposta comumente utilizada é uma distribuição Gaussiana simétrica centrada no estado atual, $q(x\'|x) = N(x\'|x, \Sigma)$; isso é chamado de **algoritmo de Metropolis de passeio aleatório** [^24.3]. Discutiremos como escolher $\Sigma$ na Seção 24.3.3 [^24.3]. Se usarmos uma proposta da forma $q(x\'|x) = q(x\')$, onde o novo estado é independente do estado antigo, obtemos um método conhecido como **amostrador de independência**, que é semelhante ao *importance sampling* (Seção 23.4) [^24.3].

Tendo proposto um movimento para $x\'$, decidimos então se aceitamos esta proposta ou não, de acordo com alguma fórmula, que garante que a fração de tempo gasto em cada estado é proporcional a $p^*(x)$ [^24.3]. Se a proposta for aceita, o novo estado é $x\'$; caso contrário, o novo estado é o mesmo que o estado atual, $x$ (ou seja, repetimos a amostra) [^24.3].

Se a proposta é simétrica, de modo que $q(x\'|x) = q(x|x\')$, a probabilidade de aceitação é dada pela seguinte fórmula [^24.3]:

$$\
r = \min \left(1, \frac{p^*(x\')}{p^*(x)} \right)
$$

Vemos que se $x\'$ é mais provável que $x$, nós definitivamente nos movemos para lá (já que $\frac{p^*(x\')}{p^*(x)} > 1$) [^24.3]. Mas se $x\'$ é menos provável, ainda podemos nos mover para lá de qualquer forma, dependendo das probabilidades relativas [^24.3]. Assim, em vez de nos movermos gananciosamente apenas para os estados mais prováveis, ocasionalmente permitimos movimentos "ladeira abaixo" para estados menos prováveis [^24.3]. Na Seção 24.3.6, provamos que este procedimento garante que a fração de tempo que passamos em cada estado $x$ é proporcional a $p^*(x)$ [^24.3].

Se a proposta é assimétrica, de modo que $q(x\'|x) \neq q(x|x\')$, precisamos da **correção de Hastings**, dada pelo seguinte [^24.3]:

$$\
r = \min(1, \alpha)
$$

$$\
\alpha = \frac{p^*(x\')q(x|x\')}{p^*(x)q(x\'|x)} = \frac{p^*(x\')/q(x\'|x)}{p^*(x)/q(x\'|x)}
$$

Essa correção é necessária para compensar o fato de que a distribuição de proposta em si (em vez de apenas a distribuição alvo) pode favorecer certos estados [^24.3].

Uma razão importante pela qual MH é um algoritmo útil é que, ao avaliar $\alpha$, só precisamos conhecer a densidade alvo até uma constante de normalização [^24.3]. Em particular, suponha que $p^*(x) = \frac{1}{Z} \tilde{p}(x)$, onde $\tilde{p}(x)$ é uma distribuição não normalizada e $Z$ é a constante de normalização [^24.3]. Então

$$\
\alpha = \frac{(\tilde{p}(x\')/Z) q(x|x\')}{(\tilde{p}(x)/Z) q(x\'|x)}
$$

de modo que os $Z$\'s se cancelam [^24.3]. Portanto, podemos amostrar de $p^*$ mesmo que $Z$ seja desconhecido [^24.3]. Em particular, tudo o que temos de fazer é avaliar $\tilde{p}$ pontualmente, onde $\tilde{p}(x) = p^*(x)Z$ [^24.3].

**Gibbs sampling como um caso especial de MH**

O Gibbs sampling, discutido na Seção 24.2, é um caso especial de MH [^24.3]. Em particular, é equivalente a usar MH com uma sequência de propostas da forma [^24.3]:

$$\
q(x\'|x) = p(x_i\'|x_{-i})I(x_{-i}\' = x_{-i})
$$

Isto é, nos movemos para um novo estado onde $x_i$ é amostrado de sua condicional completa, mas $x_{-i}$ é deixado inalterado [^24.3].

Agora provamos que a taxa de aceitação de cada tal proposta é 1, de modo que o algoritmo geral também tem uma taxa de aceitação de 100% [^24.3]. Temos [^24.3]:

$$\
\alpha = \frac{p(x\')q(x|x\')}{p(x)q(x\'|x)} = \frac{p(x_i\'|x_{-i})p(x_{-i})p(x_i|x_{-i}\')}{p(x_i|x_{-i})p(x_{-i})p(x_i\'|x_{-i})} = \frac{p(x_i\'|x_{-i})p(x_{-i})p(x_i|x_{-i})}{p(x_i|x_{-i})p(x_{-i})p(x_i\'|x_{-i})} = 1
$$

### Conclusão
O algoritmo de Metropolis-Hastings oferece uma abordagem flexível e poderosa para a amostragem de distribuições complexas, especialmente em cenários de alta dimensionalidade onde métodos mais simples falham [^24.1]. A capacidade de utilizar uma distribuição de proposta arbitrária, juntamente com a correção de Hastings, torna o MH adaptável a uma ampla gama de problemas [^24.3]. Além disso, sua relação com o Gibbs sampling fornece insights valiosos sobre sua implementação e comportamento [^24.3].

### Referências
[^24.1]: "In Chapter 23, we introduced some simple Monte Carlo methods, including rejection sampling and importance sampling. The trouble with these methods is that they do not work well in high dimensional spaces. The most popular method for sampling from high-dimensional distributions is Markov chain Monte Carlo or MCMC."
[^24.3]: "The Metropolis-Hastings (MH) algorithm is a more general MCMC method that proposes moves to new states based on a proposal distribution q(x\'|x) and accepts or rejects the move to ensure the correct stationary distribution. The MH algorithm requires a Hastings correction when the proposal distribution is asymmetric, compensating for the fact that the proposal distribution itself might favor certain states. Gibbs sampling is a special case of MH, where the proposal distribution is the full conditional, and the acceptance rate is always 100%."
<!-- END -->