## Gibbs Sampling para Modelos Gráficos Probabilísticos

### Introdução
O presente capítulo aborda o **Gibbs sampling**, um dos algoritmos MCMC mais populares para inferência em modelos probabilísticos de alta dimensionalidade [^2]. Em continuidade ao Capítulo 23, que introduziu métodos Monte Carlo mais simples, como rejection sampling e importance sampling [^2], exploraremos como o Gibbs sampling supera as limitações desses métodos em espaços de alta dimensão. Este capítulo se baseia nos conceitos fundamentais de cadeias de Markov apresentados na Seção 17.2 [^2], e estende a discussão para inferência Bayesiana e aprendizado de máquina, áreas onde o Gibbs sampling tem se mostrado extremamente eficaz [^2].

### Conceitos Fundamentais
O Gibbs sampling é um caso especial de MCMC [^2, 13] que se baseia na construção de uma **cadeia de Markov** cujo estado converge para a distribuição alvo $p^*(x)$ [^2]. A ideia central do Gibbs sampling é amostrar cada variável individualmente, *condicionada nos valores mais recentes de todas as outras variáveis* [^3].

**24.2.1 Ideia Básica:**
Dado um conjunto de variáveis $x = (x_1, x_2, ..., x_D)$, o Gibbs sampling gera uma nova amostra $x^{s+1}$ amostrando cada componente $x_i$ condicionado aos valores mais recentes das outras variáveis $x_{-i}$, onde $x_{-i}$ representa todas as variáveis exceto $x_i$ [^3]. Matematicamente:

*   $x_1^{s+1} \sim p(x_1 | x_2^s, x_3^s, ..., x_D^s)$
*   $x_2^{s+1} \sim p(x_2 | x_1^{s+1}, x_3^s, ..., x_D^s)$
*   ...
*   $x_D^{s+1} \sim p(x_D | x_1^{s+1}, x_2^{s+1}, ..., x_{D-1}^{s+1})$

Este processo é repetido iterativamente até que a cadeia de Markov convirja para a distribuição alvo. A expressão $p(x_i | x_{-i})$ é chamada de **full conditional** para a variável $x_i$ [^3].

**Dependências e Markov Blanket:** Em geral, a variável $x_i$ pode depender apenas de um subconjunto das outras variáveis [^3]. Se representarmos $p(x)$ como um modelo gráfico, podemos inferir essas dependências observando o **Markov blanket** de $x_i$, que consiste em seus vizinhos no grafo [^3]. Portanto, para amostrar $x_i$, só precisamos conhecer os valores de seus vizinhos [^3].

**Natureza Distribuída e Sequencial:**
>Nesse sentido, o Gibbs sampling é um algoritmo distribuído [^3].
No entanto, é crucial notar que ele *não é um algoritmo paralelo, pois as amostras devem ser geradas sequencialmente* [^3]. Cada amostra de $x_i^{s+1}$ depende dos valores mais recentes das variáveis vizinhas [^3].

**Burn-in:**
>É necessário descartar algumas das amostras iniciais até que a cadeia de Markov tenha *burned in*, ou entrado em sua distribuição estacionária [^3].

Como discutido na Seção 24.4.1 [^3], as amostras coletadas antes da convergência não representam a distribuição alvo e devem ser descartadas. Métodos para estimar quando o burn-in ocorreu serão discutidos na Seção 24.4.1 [^3].

**24.2.3 Exemplo: Gibbs sampling para inferir os parâmetros de um GMM:**
Um exemplo prático da aplicação de Gibbs sampling é na inferência dos parâmetros de um **Gaussian Mixture Model (GMM)** [^4]. Com priors conjugados, o Gibbs sampling envolve amostrar iterativamente os indicadores discretos, os pesos de mistura, as médias e as covariâncias [^4].

Suponha que usemos um prior semi-conjugado [^4]. Então, a distribuição conjunta completa é dada por [^4]:
$$ p(x, z, \mu, \Sigma, \pi) = p(x|z, \mu, \Sigma)p(z|\pi)p(\pi) \prod_{k=1}^K p(\mu_k)p(\Sigma_k) $$
onde
$$ p(x, z, \mu, \Sigma, \pi) = \prod_{i=1}^N \prod_{k=1}^K (N(x_i|\mu_k, \Sigma_k))^{I(z_i=k)} Dir(\pi|\alpha) \prod_{k=1}^K N(\mu_k|m_0, V_0)IW(\Sigma_k|S_0, \nu_0) $$

Os full conditionals para os indicadores discretos, os pesos de mistura, as médias e as covariâncias são dados por [^4]:
*   $p(z_i = k|x_i, \mu, \Sigma, \pi) \propto \pi_k N(x_i|\mu_k, \Sigma_k)$
*   $p(\pi|z) = Dir(\{\alpha_k + \sum_{i=1}^N I(z_i = k)\}_{k=1}^K)$
*   $p(\mu_k|\Sigma_k, z, x) = N(\mu_k|m_k, V_k)$
*   $p(\Sigma_k|\mu_k, z, x) = IW(\Sigma_k|S_k, \nu_k)$

onde [^4]:
*   $V_k^{-1} = V_0^{-1} + N_k \Sigma_k^{-1}$
*   $m_k = V_k (\Sigma_i I(z_i = k) x_i + V_0^{-1} m_0)$
*   $S_k = S_0 + \Sigma_i I(z_i = k) (x_i - \mu_k) (x_i - \mu_k)^T$
*   $\nu_k = \nu_0 + N_k$

**24.2.3.1 Label Switching:**
Uma fraqueza fundamental do Gibbs sampling em modelos de mistura é o problema de **label switching** [^5]. Os parâmetros do modelo $\theta$ e as funções indicadoras $z$ são não identificáveis, pois podemos permutar arbitrariamente os rótulos ocultos sem afetar a verossimilhança [^5]. Isso impede o cálculo de médias posteriores diretas, pois o que uma amostra considera como parâmetros para o cluster 1 pode ser o que outra amostra considera para o cluster 2 [^5].

**24.2.4 Collapsed Gibbs Sampling:**
Em alguns casos, podemos integrar analiticamente algumas das quantidades desconhecidas, e amostrar apenas o restante [^5]. Isso é chamado de **collapsed Gibbs sampler** e tende a ser muito mais eficiente, pois amostra em um espaço de menor dimensão [^5].

### Conclusão
O Gibbs sampling é uma ferramenta poderosa e amplamente utilizada para inferência em modelos probabilísticos complexos. Sua natureza distribuída o torna aplicável a problemas de alta dimensionalidade, enquanto sua implementação relativamente simples facilita sua adoção em diversas áreas. No entanto, é crucial estar ciente das limitações do Gibbs sampling, como a necessidade de descartar amostras de burn-in e o problema de label switching em modelos de mistura. Técnicas como collapsed Gibbs sampling podem mitigar alguns desses problemas, aumentando a eficiência do algoritmo. Os tópicos discutidos neste capítulo fornecem uma base sólida para a compreensão e aplicação do Gibbs sampling em uma variedade de cenários práticos.

### Referências
[^2]: Markov chain Monte Carlo (MCMC) inference - Introdução
[^3]: Gibbs sampling - Conceitos Fundamentais
[^4]: Example: Gibbs sampling for inferring the parameters of a GMM
[^5]: Label switching and Collapsed Gibbs sampling
<!-- END -->