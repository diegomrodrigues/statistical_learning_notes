## Swendsen-Wang Algorithm: An Auxiliary Variable Approach for Ising Models

### Introdução
O algoritmo de Swendsen-Wang (SW) é uma técnica de amostragem MCMC (Markov chain Monte Carlo) que utiliza variáveis auxiliares para melhorar a eficiência da mistura em modelos de Ising [^24.5.3]. Modelos de Ising, como mencionado no Exemplo 24.2.2 [^2.2.2], são utilizados para modelar sistemas com interações binárias, e o algoritmo SW introduz variáveis binárias auxiliares, chamadas variáveis de ligação (*bond variables*), para facilitar a amostragem. Este capítulo detalha o funcionamento do algoritmo SW, sua relação com a amostragem de Gibbs e suas vantagens em cenários específicos.

### Conceitos Fundamentais
O algoritmo SW foi projetado para modelos de Ising e introduz variáveis binárias auxiliares (variáveis de ligação) para facilitar uma mistura mais rápida [^24.5.3]. O objetivo é permitir que o algoritmo desconecte arestas entre nós com diferentes atribuições e atualize componentes conectados inteiros simultaneamente, abordando os problemas de mistura lenta da amostragem de Gibbs padrão em certos cenários [^24.5.3].

**Modelo de Ising:** Considere um modelo de Ising da seguinte forma [^24.5.3]:
$$ p(x) = \frac{1}{Z} \prod_e f_e(x_e) $$
onde $x_e = (x_i, x_j)$ para a aresta $e = (i, j)$, $x_i \in \{+1, -1\}$, e o fator de aresta $f_e$ é definido por [^24.5.3]:
$$ f_e(x_e) = \begin{cases} e^J & \text{se } x_i = x_j \\ e^{-J} & \text{se } x_i \neq x_j \end{cases} $$
Aqui, $J$ representa a força da ligação (*edge strength*). A amostragem de Gibbs nesses modelos pode ser lenta quando $J$ é grande em valor absoluto, porque estados vizinhos podem ser altamente correlacionados [^24.5.3].

**Variáveis de Ligação:** O algoritmo SW introduz variáveis binárias auxiliares, uma para cada aresta, chamadas variáveis de ligação (*bond variables*) e denotadas por $z$ [^24.5.3]. Define-se então um modelo estendido $p(x, z)$ da forma [^24.5.3]:
$$ p(x, z) = \frac{1}{Z} \prod_e g_e(x_e, z_e) $$
onde $z_e \in \{0, 1\}$, e o novo fator $g_e$ é definido como [^24.5.3]:
$$ g_e(x_e, z_e = 0) = \begin{cases} e^{-J} & \text{se } x_i = x_j \\ e^{-J} & \text{se } x_i \neq x_j \end{cases} $$
e
$$ g_e(x_e, z_e = 1) = \begin{cases} e^{J} - e^{-J} & \text{se } x_i = x_j \\ 0 & \text{se } x_i \neq x_j \end{cases} $$
É claro que $\sum_{z_e} g_e(x_e, z_e) = f_e(x_e)$ [^24.5.3].

**Amostragem de Gibbs no Modelo Estendido:** Felizmente, é fácil aplicar a amostragem de Gibbs a este modelo estendido [^24.5.3]. A condicional completa $p(z|x)$ é fatorável sobre as arestas, já que as variáveis de ligação são condicionalmente independentes, dadas as variáveis dos nós [^24.5.3]. Além disso, a condicional completa $p(z_e|x_e)$ é simples de computar: se os nós em cada extremidade da aresta estão no mesmo estado ($x_i = x_j$), definimos a ligação $z_e$ como 1 com probabilidade $p = 1 - e^{-2J}$; caso contrário, definimos $z_e$ como 0 [^24.5.3].

Para amostrar $p(x|z)$, prosseguimos da seguinte forma [^24.5.3]:
1.  Encontrar os componentes conectados definidos pelo grafo induzido pelas ligações que estão ativadas.
2.  Escolher um desses componentes uniformemente ao acaso.
3.  Escolher um estado $\pm 1$ uniformemente ao acaso e forçar todas as variáveis neste componente a adotar este novo estado.

O algoritmo SW faz movimentos muito maiores através do espaço de estados do que a amostragem de Gibbs [^24.5.3]. No entanto, se alguns dos pesos das arestas são negativos, $J < 0$, o sistema é *frustrado*, e existem muitos modos exponencialmente, mesmo em baixa temperatura [^24.5.3]. O algoritmo SW não funciona muito bem neste cenário, pois tenta forçar muitas variáveis vizinhas a terem o mesmo estado [^24.5.3].

### Conclusão
O algoritmo de Swendsen-Wang oferece uma melhoria significativa em relação à amostragem de Gibbs para modelos de Ising com interações atrativas, ao introduzir variáveis auxiliares que permitem atualizações globais do estado [^24.5.3]. Embora possua limitações em sistemas frustrados, sua capacidade de superar correlações locais o torna uma ferramenta valiosa no arsenal de algoritmos MCMC [^24.5.3].

### Referências
[^24.5.3]: Seção 24.5.3 do texto fornecido.
[^2.2.2]: Seção 24.2.2 do texto fornecido.

<!-- END -->