## Slice Sampling em Auxiliary Variable MCMC

### Introdução
Em continuidade à discussão sobre métodos MCMC que utilizam variáveis auxiliares para melhorar a eficiência da amostragem [^863], este capítulo se aprofunda no *slice sampling*. O slice sampling é uma técnica ingenhosa que adiciona uma variável auxiliar para transformar a distribuição alvo original em uma distribuição conjunta da qual é mais fácil amostrar [^863]. Este método é particularmente útil para distribuições unimodais, mas pode ser adaptado para distribuições multimodais.

### Conceitos Fundamentais

O slice sampling opera adicionando uma variável auxiliar $u$ à distribuição univariada original $p(x)$ [^91]. Isso cria uma distribuição conjunta $p(x, u)$ definida como [^91, 93]:

$$
p(x, u) = 
\begin{cases}
\frac{1}{Z_p} & \text{se } 0 \leq u \leq p(x) \\
0 & \text{caso contrário}
\end{cases}
$$

onde $Z_p$ é uma constante de normalização [^93]. A ideia chave é que, amostrando desta distribuição conjunta e marginalizando $u$, obtemos amostras da distribuição original $p(x)$ [^863]. A marginalização de $u$ é garantida pela seguinte propriedade [^863, 94]:

$$
\int p(x, u) \, du = \frac{p(x)}{Z_p}
$$

A implementação do slice sampling envolve os seguintes passos [^863]:

1.  Dado um valor atual $x^{(i)}$, amostre $u^{(i+1)}$ uniformemente no intervalo $[0, p(x^{(i)})]$ [^863, 865, 95]:

    $$
    u^{(i+1)} \sim U[0, p(x^{(i)})]
    $$

2.  Amostre $x^{(i+1)}$ uniformemente a partir da *slice* definida pelo conjunto $A = \{x: p(x) \geq u^{(i+1)}\}$ [^863, 865, 96]:

    $$
    x^{(i+1)} \sim U(A)
    $$

    onde $A = \{x : p(x) \geq u\}$ é o conjunto de pontos acima da altura $u$ [^863, 865, 96].

A dificuldade prática reside na identificação do conjunto $A$ [^865]. Uma abordagem comum é construir um intervalo $[x_{min}, x_{max}]$ em torno do ponto atual $x_s$ e, em seguida, amostrar uniformemente dentro deste intervalo [^865]. O intervalo é então estendido iterativamente (um processo chamado *stepping out*) até que as extremidades do intervalo fiquem fora da slice [^865, 866]. Um novo valor candidato $x'$ é então escolhido uniformemente dentro deste intervalo [^866]. Se $x'$ estiver dentro da slice, ele é aceito como $x^{(i+1)}$; caso contrário, o intervalo é encolhido (um processo chamado *shrinkage*) e um novo candidato é amostrado [^866].

O slice sampling tem a vantagem de não necessitar da especificação dos condicionais completos como no Gibbs sampling [^866]. Além disso, ele não requer uma distribuição de proposta definida pelo usuário como no Metropolis-Hastings, embora requeira a especificação da largura do intervalo *stepping out* [^866].

### Conclusão

O slice sampling oferece uma abordagem flexível e eficiente para amostrar de distribuições complexas, aproveitando uma variável auxiliar para simplificar o processo de amostragem [^863]. Ao alternar entre amostragem uniforme sob a curva e amostragem da slice, o slice sampling melhora a capacidade de fazer grandes movimentos na distribuição, levando a uma exploração mais eficiente do espaço de estados [^863]. Este método, embora mais complexo que alguns outros, pode ser particularmente valioso em situações onde os métodos tradicionais de MCMC lutam devido a fortes correlações ou paisagens de probabilidade complexas.

### Referências
[^863]: Capítulo 24, Markov chain Monte Carlo (MCMC) inference.
[^91]: Seção 24.5.2, Slice sampling.
[^93]: Seção 24.5.2, Equação 24.93.
[^94]: Seção 24.5.2.
[^865]: Seção 24.5.2.
[^95]: Seção 24.5.2, Equação para amostragem de u.
[^96]: Seção 24.5.2, Equação para amostragem de x.
[^866]: Seção 24.5.2.

<!-- END -->