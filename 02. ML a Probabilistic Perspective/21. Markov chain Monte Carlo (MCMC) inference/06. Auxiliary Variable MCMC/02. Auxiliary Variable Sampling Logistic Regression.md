## Auxiliary Variable Sampling for Logistic Regression in MCMC

### Introdução
Este capítulo explora o uso de **variáveis auxiliares** em algoritmos MCMC (Markov Chain Monte Carlo), especificamente em relação à regressão logística. A introdução de variáveis auxiliares é uma técnica poderosa para melhorar a eficiência da amostragem, reduzindo a correlação entre as variáveis originais [^863]. Esta abordagem se baseia em uma interpretação de variável latente, onde uma variável latente é introduzida e a amostragem é realizada alternando entre a amostragem dos parâmetros do modelo e as variáveis latentes [^863].

### Conceitos Fundamentais
A ideia principal por trás do uso de variáveis auxiliares no contexto de MCMC é a de **aumentar o espaço amostral** com variáveis adicionais, tornando a distribuição conjunta mais tratável para amostragem [^863]. Se $x$ representa as variáveis originais e $z$ as variáveis auxiliares, o objetivo é que $\sum_z p(x, z) = p(x)$ e que $p(x, z)$ seja mais fácil de amostrar do que $p(x)$ diretamente [^863]. Após a amostragem no espaço aumentado, os valores de $z$ são descartados, recuperando amostras de $p(x)$ [^863].

No contexto da regressão logística, uma interpretação de variável latente é frequentemente usada [^863]. Considere o seguinte modelo de regressão logística binária:

$$
P(y_i = 1 | x_i, w) = \text{sigmoid}(w^T x_i) = \frac{1}{1 + e^{-w^T x_i}}
$$

onde $y_i$ é a variável de resposta binária, $x_i$ é o vetor de características, e $w$ é o vetor de pesos do modelo.

Uma variável latente $z_i$ pode ser introduzida de tal forma que [^863]:

$$
z_i = w^T x_i + \epsilon_i
$$

onde $\epsilon_i$ é um ruído aleatório. A ligação entre a variável latente e a variável de resposta é dada por [^863]:

$$
y_i =
\begin{cases}
1 & \text{se } z_i \geq 0 \\
0 & \text{se } z_i < 0
\end{cases}
$$

A escolha da distribuição para $\epsilon_i$ é crucial. Uma escolha comum é usar uma distribuição normal, resultando no modelo *probit* [^863]:

$$
\epsilon_i \sim N(0, 1)
$$

Neste caso, $p(y_i = 1 | x_i, w) = P(z_i > 0 | x_i, w) = \Phi(w^T x_i)$, onde $\Phi$ é a função de distribuição cumulativa da normal padrão.

Para a regressão logística, a distribuição logística é definida como [^863]:

$$
P_{\text{Logistic}}(\epsilon) = \frac{e^{-\epsilon}}{(1 + e^{-\epsilon})^2}
$$

com média $E[\epsilon] = 0$ e variância $\text{var}[\epsilon] = \pi^2/3$ [^863]. A função de distribuição acumulada (CDF) é $F(\epsilon) = \text{sigmoid}(\epsilon)$ [^863], onde $\text{sigmoid}(\epsilon) = \frac{1}{1 + e^{-\epsilon}}$.
Portanto [^864]:

$$
p(y_i = 1 | x_i, w) = \int_{-w^T x_i}^{\infty} f(\epsilon) d\epsilon = \int_{-\infty}^{w^T x_i} f(\epsilon) d\epsilon = F(w^T x_i) = \text{sigmoid}(w^T x_i)
$$

O processo de amostragem MCMC envolve alternar entre amostrar os parâmetros do modelo $w$ e as variáveis latentes $z_i$ [^863]. As etapas típicas são:

1.  **Amostrar $w$ dado $z$ e $D$ (dados)**: $p(w | z, D)$. Se uma distribuição *a priori* Gaussiana for usada para $w$, a *a posteriori* também será Gaussiana, facilitando a amostragem.
2.  **Amostrar $z_i$ dado $x_i$, $y_i$ e $w$**: $p(z_i | x_i, y_i, w)$. Esta é uma Gaussiana truncada, que pode ser amostrada usando técnicas padrão.

Para amostrar $z_i$, dado $y_i = 1$ e $w$, amostramos de uma Gaussiana truncada em $[0, \infty)$. Se $y_i = 0$, amostramos de uma Gaussiana truncada em $(-\infty, 0)$.

Embora a amostragem direta de $p(w|z, D)$ para regressão logística não seja possível, uma abordagem é aproximar a distribuição logística pela distribuição de Student [^864]. Outra abordagem envolve a definição de $\epsilon_i \sim N(0, \lambda_i)$, onde $\lambda_i = (2\psi_i)^2$ e $\psi_i$ segue uma distribuição de Kolmogorov-Smirnov (KS) [^864].

#### Vantagens da Amostragem com Variáveis Auxiliares
*   **Melhora na Eficiência:** A introdução de variáveis auxiliares pode reduzir a correlação entre as variáveis originais, levando a uma convergência mais rápida da cadeia MCMC [^863].
*   **Maior Flexibilidade:** Permite o uso de modelos mais complexos e não conjugados.

#### Desafios da Amostragem com Variáveis Auxiliares
*   **Complexidade:** A introdução de variáveis auxiliares pode aumentar a complexidade do modelo e do algoritmo de amostragem.
*   **Escolha da Distribuição:** A escolha da distribuição para as variáveis auxiliares é crucial e pode afetar o desempenho do algoritmo.

### Conclusão
A amostragem com variáveis auxiliares oferece uma abordagem poderosa para realizar inferência Bayesiana em modelos de regressão logística [^863]. Ao introduzir variáveis latentes e amostrar alternadamente entre os parâmetros do modelo e as variáveis latentes, a eficiência da amostragem MCMC pode ser significativamente melhorada [^863]. Embora a técnica envolva desafios, como a escolha da distribuição para as variáveis auxiliares, os benefícios potenciais em termos de convergência e flexibilidade a tornam uma ferramenta valiosa no arsenal de um estatístico Bayesiano.

### Referências
[^863]: Chapter 24. Markov chain Monte Carlo (MCMC) inference, p. 863
[^864]: Chapter 24. Markov chain Monte Carlo (MCMC) inference, p. 864
<!-- END -->