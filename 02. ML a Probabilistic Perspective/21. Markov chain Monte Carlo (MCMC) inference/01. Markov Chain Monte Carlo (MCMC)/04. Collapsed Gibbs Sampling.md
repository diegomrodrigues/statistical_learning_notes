## Collapsed Gibbs Sampling: Uma Técnica de Redução de Variância em MCMC

### Introdução
Em métodos Markov Chain Monte Carlo (MCMC), a eficiência é crucial para obter amostras precisas de distribuições complexas. Uma técnica avançada para melhorar essa eficiência é o **Collapsed Gibbs Sampling**. Este capítulo explora o Collapsed Gibbs Sampling como uma técnica de redução de variância, detalhando seus princípios, vantagens e aplicações. O Collapsed Gibbs Sampling se baseia nos fundamentos do Gibbs sampling [^8], explorando a integração analítica para reduzir a dimensionalidade do espaço amostral e, consequentemente, a variância das estimativas [^5].

### Conceitos Fundamentais

O Collapsed Gibbs Sampling é uma variante do Gibbs Sampling que envolve a integração analítica de algumas quantidades desconhecidas [^5]. Em vez de amostrar diretamente todos os parâmetros do modelo, algumas variáveis são integradas analiticamente, resultando em um sampler que opera em um espaço de menor dimensão. Esta redução de dimensionalidade leva a uma maior eficiência na amostragem e a estimativas de menor variância [^5].

**Rao-Blackwellização**: A técnica de integração analítica utilizada no Collapsed Gibbs Sampling é um exemplo de Rao-Blackwellização [^5]. O Teorema de Rao-Blackwell garante que a variância da estimativa criada ao integrar analiticamente uma variável sempre será menor do que a variância de uma estimativa direta de Monte Carlo [^5]. Formalmente, o Teorema de Rao-Blackwell, presente no texto como o Teorema 24.2.1 [^5], afirma:

> **Teorema 24.2.1 (Rao-Blackwell)**. Sejam $z$ e $\theta$ variáveis aleatórias dependentes, e seja $f(z, \theta)$ alguma função escalar. Então:
> $$var_{z,\theta}[f(z, \theta)] \geq var_z[E_{\theta}[f(z, \theta)|z]]$$ [^5]

Este teorema é fundamental para entender por que o Collapsed Gibbs Sampling é uma técnica de redução de variância. Ao integrar $\theta$ analiticamente, estamos calculando $E_{\theta}[f(z, \theta)|z]$, e o teorema garante que a variância da estimativa resultante será menor ou igual à variância da estimativa original.

**Implementação**: No Collapsed Gibbs Sampling, os parâmetros integrados não participam diretamente da cadeia de Markov [^5]. Em vez disso, amostras condicionalmente independentes são obtidas de $p(\theta|z, D)$, onde $z$ representa as variáveis amostradas e $D$ os dados observados [^5]. Este processo pode ser mais eficiente do que amostrar diretamente de $p(\theta, z|D)$, especialmente quando $p(\theta|z, D)$ tem uma forma analítica tratável.

**Exemplo**: Considere um modelo de mistura de Gaussianas (GMM) [^4]. Em um Gibbs Sampling tradicional, amostraríamos os parâmetros da mistura (médias, variâncias, pesos) e as atribuições de cluster para cada ponto de dados. No Collapsed Gibbs Sampling, podemos integrar analiticamente os parâmetros da mistura, amostrando apenas as atribuições de cluster [^5]. Isso reduz a dimensionalidade do espaço amostral e pode levar a uma convergência mais rápida e estimativas mais precisas.

**Vantagens e Desvantagens**:
*   **Vantagens**:
    *   **Redução de Variância**: Garante uma variância menor nas estimativas devido à Rao-Blackwellização [^5].
    *   **Eficiência**: Amostragem em um espaço de menor dimensão, resultando em uma convergência mais rápida [^5].
*   **Desvantagens**:
    *   **Complexidade Analítica**: Requer a capacidade de realizar a integração analítica, o que nem sempre é possível [^5].
    *   **Interdependência**: Após a integração, as variáveis restantes podem se tornar interdependentes, o que pode complicar a amostragem [^6].

### Conclusão

O Collapsed Gibbs Sampling é uma técnica poderosa para melhorar a eficiência e reduzir a variância em métodos MCMC [^5]. Ao integrar analiticamente certas variáveis, o sampler opera em um espaço de menor dimensão, levando a uma convergência mais rápida e estimativas mais precisas [^5]. O teorema de Rao-Blackwell fornece uma base teórica para a redução de variância observada no Collapsed Gibbs Sampling [^5]. Embora a técnica exija a capacidade de realizar a integração analítica, suas vantagens em termos de eficiência e precisão a tornam uma ferramenta valiosa para inferência Bayesiana e outras aplicações estatísticas [^5].

### Referências
[^5]: Capítulo 24, Markov chain Monte Carlo (MCMC) inference, Collapsed Gibbs sampling.
[^6]: Capítulo 24, Markov chain Monte Carlo (MCMC) inference, Example: collapsed Gibbs for fitting a GMM.
[^8]: Capítulo 24, Markov chain Monte Carlo (MCMC) inference, Gibbs sampling.

<!-- END -->