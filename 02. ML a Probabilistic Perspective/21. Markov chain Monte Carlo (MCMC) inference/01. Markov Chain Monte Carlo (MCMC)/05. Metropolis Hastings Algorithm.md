## Metropolis-Hastings Algorithm: A Generalization of Gibbs Sampling

### Introdução
Em continuidade ao estudo dos algoritmos de Markov Chain Monte Carlo (MCMC), apresentamos neste capítulo o algoritmo de Metropolis-Hastings (MH), uma generalização do Gibbs sampling [^1]. O algoritmo MH oferece maior flexibilidade e aplicabilidade em modelos onde o Gibbs sampling não é adequado [^1]. Exploraremos os conceitos fundamentais do MH, incluindo a distribuição de proposta, o critério de aceitação de Hastings e a correção para manter o balanço detalhado, além de demonstrar como o Gibbs sampling se encaixa como um caso especial do MH [^1].

### Conceitos Fundamentais

O algoritmo de **Metropolis-Hastings (MH)**, como mencionado, é uma generalização do Gibbs sampling [^1]. A flexibilidade do MH reside na sua capacidade de utilizar uma **distribuição de proposta** *q(x'|x)* para sugerir uma transição do estado atual *x* para um novo estado *x'*. Esta distribuição de proposta pode ser qualquer distribuição, desde que certas condições sejam satisfeitas [^1].

A principal ideia por trás do MH é propor um movimento do estado atual *x* para um novo estado *x'* com probabilidade *q(x'|x)* [^1]. A aceitação desta proposta é determinada por uma fórmula que garante que a fração de tempo gasto em cada estado seja proporcional à densidade alvo *p*(x) [^1]. Essa densidade alvo pode ser um prior ou um posterior [^1].

A probabilidade de aceitação, *α*, é calculada da seguinte forma [^13]:
$$\
\alpha = \min \left(1, \frac{p^*(x')q(x|x')}{p^*(x)q(x'|x)}\right)
$$
onde:
- $p^*(x')$ é a densidade alvo no novo estado *x'*.
- $p^*(x)$ é a densidade alvo no estado atual *x*.
- $q(x'|x)$ é a probabilidade de propor o estado *x'* dado o estado atual *x*.
- $q(x|x')$ é a probabilidade de propor o estado *x* dado o estado *x'*.

A fração $\frac{q(x|x')}{q(x'|x)}$ é conhecida como a **correção de Hastings**. Esta correção é crucial quando a distribuição de proposta não é simétrica, ou seja, quando $q(x'|x) \neq q(x|x')$ [^1]. A correção de Hastings compensa essa assimetria para garantir que o balanço detalhado seja mantido, assegurando a convergência para a distribuição alvo [^1].

Uma vantagem significativa do MH é que ele apenas requer o conhecimento da densidade alvo até uma constante de normalização [^1]. Isso significa que podemos amostrar de *p*(x) mesmo que a constante de normalização *Z* seja desconhecida, pois ela se cancela no cálculo da razão de aceitação [^13]:
$$\
\alpha = \frac{(p(x')/Z) q(x|x')}{(p(x)/Z) q(x'|x)} = \frac{p(x') q(x|x')}{p(x) q(x'|x)}
$$
onde $p(x)$ é a densidade não normalizada e $p^*(x) = \frac{p(x)}{Z}$ é a densidade normalizada [^13].

O **algoritmo MH** pode ser resumido nos seguintes passos [^13]:
1. Inicializar o estado $x^0$
2. Para $s = 0, 1, 2, ...$
    - Propor um novo estado $x'$ a partir da distribuição de proposta $q(x'|x^s)$
    - Calcular a probabilidade de aceitação $\alpha$
    - Gerar $u \sim U(0, 1)$
    - Se $u < \alpha$:
        - Aceitar a proposta: $x^{s+1} = x'$
    - Senão:
        - Rejeitar a proposta: $x^{s+1} = x^s$

O Gibbs sampling é um caso especial do algoritmo MH [^1]. No Gibbs sampling, a distribuição de proposta é a **distribuição condicional completa** [^1]. Isso significa que, ao atualizar uma variável $x_i$, amostramos diretamente da distribuição $p(x_i | x_{-i})$, onde $x_{-i}$ representa todas as outras variáveis [^1].

Como a proposta no Gibbs sampling é sempre da distribuição condicional completa, a taxa de aceitação é sempre 100% [^1]. Para demonstrar isso, considere a probabilidade de aceitação no MH [^13]:
$$\
\alpha = \frac{p(x') q(x|x')}{p(x) q(x'|x)}
$$
No caso do Gibbs sampling, $q(x'|x) = p(x_i' | x_{-i})$ e $q(x|x') = p(x_i | x_{-i}')$. Portanto [^13]:
$$\
\alpha = \frac{p(x_i' | x_{-i}) p(x_{-i})}{p(x_i | x_{-i}) p(x_{-i})} \cdot \frac{p(x_i | x_{-i}')}{p(x_i' | x_{-i})} = 1
$$
pois $x_{-i}' = x_{-i}$ no Gibbs Sampling [^13].

### Conclusão
O algoritmo de Metropolis-Hastings representa uma ferramenta poderosa e flexível no arsenal de métodos MCMC. Sua capacidade de utilizar distribuições de proposta arbitrárias, juntamente com a correção de Hastings, permite a aplicação em uma ampla gama de modelos estatísticos. Ao compreender os princípios fundamentais do MH e sua relação com o Gibbs sampling, podemos selecionar e implementar o algoritmo mais adequado para cada problema específico.

### Referências
[^1]: Capítulo 24 do livro texto.
<!-- END -->