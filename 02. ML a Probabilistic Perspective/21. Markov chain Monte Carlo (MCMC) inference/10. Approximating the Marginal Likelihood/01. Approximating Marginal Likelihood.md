## Aproximando a Verossimilhança Marginal
### Introdução
A verossimilhança marginal $p(D|M)$ é uma quantidade fundamental para a seleção de modelos Bayesianos [^872], onde $D$ representa os dados e $M$ o modelo. Ela representa a probabilidade dos dados, dada a estrutura do modelo, integrando sobre todos os possíveis valores dos parâmetros $\theta$. No entanto, essa integral é frequentemente intratável de ser computada analiticamente, especialmente em modelos complexos com priors não-conjugados ou variáveis latentes [^872]. Portanto, métodos de Monte Carlo são comumente empregados para aproximar essa quantidade [^872]. Este capítulo explora algumas dessas técnicas de aproximação, com foco em métodos que utilizam amostras geradas por MCMC.

### Métodos de Aproximação da Verossimilhança Marginal
#### Método do Candidato
Uma abordagem simples para aproximar a verossimilhança marginal é conhecida como o **método do candidato** [^872]. Este método explora a seguinte identidade [^872]:
$$\np(D|M) = \frac{p(D|\theta, M)p(\theta|M)}{p(\theta|D, M)}$$
Esta equação é válida para qualquer valor de $\theta$ [^872]. A ideia é escolher um valor $\theta$ para o qual $p(D|\theta, M)$ e $p(\theta|M)$ possam ser avaliados facilmente. Se tivermos uma estimativa razoável da distribuição posterior $p(\theta|D, M)$ nas proximidades de $\theta$, podemos também avaliar o denominador. Frequentemente, a posterior é aproximada usando MCMC [^872].

A principal limitação deste método reside na suposição de que a posterior $p(\theta|D, M)$ marginalizou sobre todos os modos da distribuição posterior, o que raramente é verdade na prática [^872]. Consequentemente, o método pode produzir resultados imprecisos [^872].

#### Estimativa da Média Harmônica
Outro método para aproximar $p(D)$ utilizando a saída de MCMC foi proposto por Newton e Raftery [^872]. Esta abordagem utiliza a média harmônica das verossimilhanças dos dados sob cada amostra:
$$\frac{1}{p(D)} \approx \frac{1}{S} \sum_{s=1}^{S} \frac{1}{p(D|\theta^s)}$$
onde $\theta^s \sim p(\theta|D)$ [^872]. Teoricamente, esta expressão é uma consequência da seguinte identidade [^872]:
$$\int \frac{1}{p(D|\theta)} p(\theta|D) d\theta = \int \frac{p(\theta)}{p(D|\theta) p(D)} d\theta = \frac{1}{p(D)}$$
Apesar da sua simplicidade, este método apresenta um desempenho insatisfatório na prática [^872]. Radford Neal classificou-o como "o pior método de Monte Carlo de sempre" [^872]. A principal razão para o seu fraco desempenho é que depende unicamente de amostras retiradas da posterior [^872]. A posterior é frequentemente insensível ao prior, enquanto a verossimilhança marginal é influenciada tanto pelo prior quanto pela verossimilhança [^872].

#### Amostragem de Importância Annealed
A **amostragem de importância annealed** (AIS) combina conceitos de simulated annealing e amostragem de importância para obter amostras independentes de distribuições complexas [^873].

Suponha que queremos amostrar de $p_0(x) \propto f_0(x)$, mas não conseguimos fazê-lo diretamente [^873]. Assuma, no entanto, que existe uma distribuição mais simples $p_n(x) \propto f_n(x)$ da qual podemos amostrar facilmente (por exemplo, o prior) [^873]. Podemos construir uma sequência de distribuições intermediárias que se movem gradualmente de $p_n$ para $p_0$ [^873]:
$$f(x) = f_0(x)^{\beta_j} f_n(x)^{1-\beta_j}$$
onde $1 = \beta_0 > \beta_1 > ... > \beta_n = 0$ e $\beta_j$ é uma temperatura inversa [^873]. Em contraste com o esquema utilizado pelo simulated annealing, que tem a forma $f_j(x) = f_0(x)^{\beta_j}$, isto torna difícil amostrar a partir de $p_n$ [^873]. Além disso, suponha que temos uma série de cadeias de Markov $T_j(x, x\')$ (de $x$ para $x\'$) que deixam cada $p_j$ invariante. Dado isto, podemos amostrar $x$ de $p_0$ amostrando primeiro uma sequência $z = (z_{n-1}, ..., z_0)$ como se segue: amostrar $z_{n-1} \sim p_n$; amostrar $z_{n-2} \sim T_{n-1}(z_{n-1}, \cdot)$; ...; amostrar $z_0 \sim T_1(z_1, \cdot)$. Finalmente, definimos $x = z_0$ e damos-lhe o peso [^873]:
$$w = \frac{\frac{f_{n-1}(z_{n-1})}{f_n(z_{n-1})} \frac{f_{n-2}(z_{n-2})}{f_{n-1}(z_{n-2})} ... \frac{f_1(z_1)}{f_2(z_1)} \frac{f_0(z_0)}{f_1(z_0)}}{1}$$

### Conclusão
Aproximar a verossimilhança marginal é um desafio fundamental na inferência Bayesiana, especialmente para modelos complexos. Embora existam várias abordagens, incluindo o método do candidato, a estimativa da média harmônica e a amostragem de importância annealed, cada uma tem suas próprias limitações e suposições subjacentes. A escolha do método apropriado depende das características específicas do modelo e dos dados. É crucial estar ciente das potenciais armadilhas de cada método e avaliar cuidadosamente a precisão das aproximações resultantes.
<!-- END -->