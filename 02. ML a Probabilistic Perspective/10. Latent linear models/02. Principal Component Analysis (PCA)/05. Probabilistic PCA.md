## Probabilistic PCA

### Introdução
Este capítulo dedica-se ao estudo da **Probabilistic Principal Component Analysis (PPCA)**, uma variante do PCA que introduz uma estrutura probabilística ao modelo de análise de componentes principais [^1]. Como veremos, o PPCA assume um modelo de análise fatorial com uma estrutura de ruído específica, onde a matriz de covariância é a soma de uma matriz de baixo rank e uma matriz diagonal [^1]. Exploraremos as propriedades do PPCA, suas relações com o PCA clássico e suas aplicações em diversos contextos [^1, 12].

### Conceitos Fundamentais

A **análise fatorial (FA)** é um modelo que usa variáveis latentes para gerar observações. Em particular, cada observação pode vir de um dos $K$ protótipos [^1]. Uma alternativa é usar um vetor de variáveis latentes de valor real, $z_i \in \mathbb{R}^L$ [^1]. A priori mais simples a ser usada é uma Gaussiana [^1]:
$$ p(z_i) = \mathcal{N}(z_i|\mu_0, \Sigma_0) \qquad (12.1) $$
Se as observações também forem contínuas, de modo que $x_i \in \mathbb{R}^D$, podemos usar uma Gaussiana para a verossimilhança [^1]. Assim como na regressão linear, assumiremos que a média é uma função linear das entradas (ocultas), produzindo assim [^1]:
$$ p(x_i|z_i, \theta) = \mathcal{N}(Wz_i + \mu, \Psi) \qquad (12.2) $$
onde $W$ é uma matriz $D \times L$, conhecida como a **matriz de carregamento de fator**, e $\Psi$ é uma matriz de covariância $D \times D$ [^1]. Tomamos $\Psi$ para ser diagonal, uma vez que o objetivo do modelo é "forçar" $z_i$ a explicar a correlação, em vez de "incorporá-la" à covariância da observação [^1]. Este modelo geral é chamado de **análise fatorial** ou FA [^1]. O caso especial em que $\Psi = \sigma^2I$ é chamado de **análise de componentes principais probabilística** ou PPCA [^1]. A razão para este nome se tornará aparente mais tarde [^1].

A **PPCA** assume que a matriz de covariância $\Psi$ é definida como $\sigma^2I$, onde $I$ é a matriz identidade e $\sigma^2$ é a variância do ruído isotrópico [^1]. Além disso, a matriz de carregamento de fatores $W$ é restrita a ser ortonormal [^1]. Esta restrição de ortonormalidade garante que as componentes principais sejam não correlacionadas [^1].

Um aspecto crucial do PPCA é sua relação com o PCA clássico [^1]. À medida que $\sigma^2$ se aproxima de 0, o PPCA se reduz ao PCA clássico (não probabilístico) [^1]. Isso significa que o PCA pode ser visto como um caso limite do PPCA, onde a variância do ruído é desprezível [^1].

Os máximos da log-verossimilhança no PPCA são dados por:

$$ W = V(\Lambda - \sigma^2I)R $$

Onde:
*   $V$ é a matriz de autovetores da matriz de covariância amostral $S$ [^1].
*   $\Lambda$ é a matriz diagonal correspondente de autovalores [^1].
*   $R$ é uma matriz ortogonal arbitrária [^1].
*   $\sigma^2$ é a variância média associada às dimensões descartadas [^1].

### Conclusão
Neste capítulo, exploramos o Probabilistic PCA (PPCA), uma extensão probabilística do PCA clássico. Vimos que o PPCA assume um modelo de análise fatorial com uma estrutura de ruído específica e que, sob certas condições, se reduz ao PCA clássico. O PPCA fornece uma estrutura probabilística para a análise de componentes principais, permitindo a modelagem de incertezas e a inferência de distribuições posteriores sobre as variáveis latentes. No próximo capítulo, exploraremos as aplicações do PPCA em diversos domínios, incluindo redução de dimensionalidade, visualização de dados e modelagem generativa.

### Referências
[^1]: Texto fornecido
<!-- END -->