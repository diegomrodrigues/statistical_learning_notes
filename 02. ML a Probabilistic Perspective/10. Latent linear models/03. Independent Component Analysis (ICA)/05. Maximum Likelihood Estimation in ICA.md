## Maximum Likelihood Estimation in Independent Component Analysis

### Introdução
Este capítulo explora a **estimação de máxima verossimilhança (MLE)** no contexto da **Análise de Componentes Independentes (ICA)**. O objetivo principal da ICA é decompor um conjunto de dados multivariados em componentes estatisticamente independentes [^407]. Diferentemente da **Análise de Fatores (FA)**, que assume que os dados são gerados por fatores latentes com distribuições Gaussianas [^381], a ICA relaxa essa suposição, permitindo que as fontes tenham distribuições não-Gaussianas [^408]. Abordaremos como a MLE pode ser aplicada para encontrar uma matriz de mistura que separa os sinais observados em seus componentes independentes, com ênfase nas simplificações matemáticas e algorítmicas que surgem ao impor restrições de ortogonalidade [^410].

### Conceitos Fundamentais
Na ICA, o modelo assume que os dados observados $\mathbf{x}_t \in \mathbb{R}^D$ são uma combinação linear de fontes independentes $\mathbf{z}_t \in \mathbb{R}^L$, onde $t$ representa o índice da amostra [^407]. A relação entre os dados observados e as fontes é dada por
$$\
\mathbf{x}_t = \mathbf{W}\mathbf{z}_t + \mathbf{\epsilon}_t,
$$\
onde $\mathbf{W}$ é a **matriz de mistura** $D \times L$ e $\mathbf{\epsilon}_t$ representa o ruído [^407]. Para simplificar a análise, frequentemente assume-se que o ruído é zero e que o número de fontes é igual ao número de sensores ($L = D$) [^408].

#### Estimação de Máxima Verossimilhança com Restrição de Ortogonalidade
A **estimação de máxima verossimilhança (MLE)** busca encontrar os parâmetros do modelo (neste caso, a matriz de mistura $\mathbf{W}$) que maximizam a função de verossimilhança dos dados observados [^410]. Na ICA, uma simplificação significativa ocorre ao restringir a matriz de mistura $\mathbf{W}$ a ser **ortogonal** [^410]. Isso implica que $\mathbf{W}\mathbf{W}^T = \mathbf{I}$, onde $\mathbf{I}$ é a matriz identidade. Essa restrição reduz o número de parâmetros a serem estimados de $D^2$ para $D(D-1)/2$ [^410], simplificando tanto a matemática quanto os algoritmos envolvidos.

Quando $\mathbf{W}$ é ortogonal, sua inversa $\mathbf{V} = \mathbf{W}^{-1}$ também é ortogonal [^410]. A matriz $\mathbf{V}$ é conhecida como a **matriz de reconhecimento** ou **pesos de reconhecimento** [^410]. Dado que $\mathbf{x} = \mathbf{W}\mathbf{z}$, temos $\mathbf{z} = \mathbf{V}\mathbf{x}$. A função de verossimilhança para ICA com fontes independentes pode ser escrita como
$$\np(\mathbf{x}_t) = p_{\mathbf{z}}(\mathbf{z}_t) |\det(\mathbf{W}^{-1})| = p_{\mathbf{z}}(\mathbf{V}\mathbf{x}_t) |\det(\mathbf{V})|,
$$\
onde $p_{\mathbf{z}}(\mathbf{z}_t)$ é a função de densidade de probabilidade conjunta das fontes [^410]. Assumindo que as fontes são independentes, temos
$$\np_{\mathbf{z}}(\mathbf{z}_t) = \prod_{j=1}^{L} p_j(z_{tj}),
$$\
onde $p_j(z_{tj})$ é a função de densidade de probabilidade da $j$-ésima fonte [^409].

#### Função Log-Verossimilhança
Para um conjunto de dados com $T$ amostras independentes e identicamente distribuídas (iid), a **função log-verossimilhança** é dada por [^410]
$$\frac{1}{T} \log p(\mathcal{D}|\mathbf{V}) = \log |\det(\mathbf{V})| + \frac{1}{T} \sum_{t=1}^{T} \sum_{j=1}^{L} \log p_j(v_j^T \mathbf{x}_t),
$$\
onde $\mathcal{D}$ representa o conjunto de dados, $v_j^T$ é a $j$-ésima linha de $\mathbf{V}$, e $p_j$ é a distribuição da $j$-ésima componente [^410]. O objetivo é encontrar a matriz $\mathbf{V}$ que maximize essa função log-verossimilhança [^410].

#### Restrição de Variância Unitária
Na ICA, é comum restringir a variância das distribuições das fontes a 1 [^409]. Essa restrição é importante porque remove a ambiguidade de escala entre a matriz de mistura $\mathbf{W}$ e as fontes $\mathbf{z}$ [^409]. Sem essa restrição, qualquer variação na escala de uma fonte poderia ser compensada por uma variação inversa na escala da coluna correspondente de $\mathbf{W}$, resultando em múltiplas soluções para a matriz de mistura [^409].

### Conclusão

A **estimação de máxima verossimilhança** é uma ferramenta poderosa para realizar a **Análise de Componentes Independentes (ICA)**. A imposição da restrição de ortogonalidade na matriz de mistura simplifica significativamente o problema de otimização, reduzindo o número de parâmetros a serem estimados e facilitando o desenvolvimento de algoritmos eficientes [^410]. Além disso, a restrição de variância unitária nas distribuições das fontes remove a ambiguidade de escala, garantindo uma solução única para a matriz de mistura [^409]. A combinação dessas técnicas permite a separação eficaz de sinais misturados em seus componentes independentes, abrindo caminho para uma ampla gama de aplicações em processamento de sinais, análise de dados e aprendizado de máquina [^407].

### Referências
[^381]: Chapter 12. Latent linear models.
[^407]: 12.6 Independent Component Analysis (ICA).
[^408]: where W is an D × L matrix, and et ~ N(0, Ψ).
[^409]: Without loss of generality, we can constrain the variance of the source distributions to be 1,
[^410]: Hence we see that W must be orthogonal. This reduces the number of parameters we have to
estimate from D² to D(D – 1)/2.
<!-- END -->