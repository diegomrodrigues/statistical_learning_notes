## Maxima of Log-Likelihood and MLE in Probabilistic PCA

### Introdução
Este capítulo aborda em detalhe as expressões para os **maxima da função de log-verossimilhança** (log-likelihood) e a **estimativa de máxima verossimilhança (MLE)** no contexto do Probabilistic Principal Component Analysis (PPCA). O PPCA, como uma variante do Factor Analysis (FA) [^1], impõe restrições específicas à estrutura da matriz de covariância do ruído, permitindo uma interpretação mais direta em termos de componentes principais. A análise a seguir detalha a derivação e a interpretação das equações fornecidas, crucial para a compreensão e aplicação do PPCA.

### Conceitos Fundamentais

No PPCA, o objetivo é modelar a distribuição de dados observados de alta dimensão ($x \in \mathbb{R}^D$) usando um espaço latente de dimensão inferior ($z \in \mathbb{R}^L$, com $L < D$). O modelo assume que os dados observados são gerados a partir de variáveis latentes através de uma transformação linear, acrescida de ruído isotrópico [^1].

A função de log-verossimilhança observada para o modelo PPCA, conforme mencionado [^15], é dada por:
$$ \log p(X|W, \sigma^2) = -\frac{N}{2} \left[ \log |C| + \operatorname{tr}(C^{-1}S) \right] $$
onde $C = WW^T + \sigma^2I$ e $S = \frac{1}{N} \sum_{i=1}^N x_i x_i^T = (1/N)X^T X$ [^15].

Os **maxima da função de log-verossimilhança** são atingidos quando [^15]:
$$ W = V(\Lambda - \sigma^2 I)R $$
onde:
*   $V$ é a matriz de autovetores de $S$ (a matriz de covariância amostral).
*   $\Lambda$ é a matriz diagonal correspondente de autovalores de $S$.
*   $R$ é uma matriz ortogonal arbitrária ($R R^T = I$).
*   $\sigma^2$ é a variância média associada às dimensões descartadas.

A **estimativa de máxima verossimilhança (MLE) de $W$** é dada por [^15]:
$$ \hat{W} = V (\Lambda - \sigma^2 I)^{1/2} $$
onde:
*   $V$ é a matriz dos primeiros $L$ autovetores de $S$.
*   $\Lambda$ é a matriz diagonal correspondente de autovalores.
*   Essa expressão é obtida quando $R = I$ na equação dos máximos da log-verossimilhança e restringindo $V$ aos primeiros $L$ autovetores, ou seja, aqueles correspondentes aos maiores autovalores.

A **MLE da variância do ruído** é dada por [^15]:
$$ \sigma^2 = \frac{1}{D - L} \sum_{j=L+1}^D \lambda_j $$
que representa a variância média associada às dimensões descartadas.

**Interpretação:**

*   A equação para $W$ mostra que as direções principais no espaço latente são alinhadas com os autovetores de $S$, ajustados pela variância do ruído $\sigma^2$. A matriz ortogonal $R$ representa uma ambiguidade rotacional, indicando que a orientação exata dos eixos latentes não é unicamente determinada.
*   A MLE de $W$ fornece uma estimativa específica, removendo a ambiguidade rotacional ao definir $R = I$ e restringindo a matriz $V$ aos primeiros $L$ autovetores. Isso corresponde à escolha da projeção que maximiza a variância dos dados projetados.
*   A MLE da variância do ruído $\sigma^2$ quantifica a quantidade de variância nos dados que não é explicada pelas $L$ componentes principais retidas. Ela é calculada como a média dos autovalores correspondentes às dimensões descartadas.

**Prova da MLE de $\sigma^2$ (Sketch):**

A MLE de $\sigma^2$ pode ser obtida maximizando a função de log-verossimilhança com respeito a $\sigma^2$. Isso envolve derivar a função de log-verossimilhança em relação a $\sigma^2$, igualar a zero e resolver para $\sigma^2$. A solução resultante é a média dos autovalores descartados, como mostrado acima.

**Conexão com PCA Clássico:**

Como mencionado [^15], quando $\sigma^2 \rightarrow 0$, o PPCA se reduz ao PCA clássico. Nesse caso, $\hat{W}$ se aproxima de $V$, e as direções latentes se alinham com os autovetores de $S$. A variância do ruído desaparece, indicando que todo o sinal é explicado pelas componentes principais retidas.

**Unidentifiability:**

É importante notar que, como em FA [^3], o PPCA também sofre de unidentifiability. Uma rotação ortogonal arbitrária $R$ aplicada a $W$ não altera a verossimilhança do modelo, devido à isotropia da distribuição Gaussiana latente [^3]:
$$ cov[x] = W E[zz^T] W^T + \Psi = WR R^T W^T + \Psi = WW^T + \Psi $$

### Conclusão

As expressões para os máximos da log-verossimilhança e a MLE em PPCA fornecem um quadro preciso para a estimativa dos parâmetros do modelo. A decomposição em autovetores da matriz de covariância amostral, juntamente com a estimativa da variância do ruído, permite a redução da dimensionalidade e a modelagem da estrutura de covariância dos dados observados. O PPCA, portanto, oferece uma abordagem probabilística ao PCA, com vantagens em termos de modelagem de ruído e estimativa de parâmetros. A compreensão dessas equações é crucial para a aplicação eficaz do PPCA em uma variedade de problemas de análise de dados.

### Referências
[^1]: Seção 12.1 do texto fornecido.
[^3]: Seção 12.1.3 do texto fornecido.
[^15]: Seção 12.2.4 do texto fornecido.

<!-- END -->