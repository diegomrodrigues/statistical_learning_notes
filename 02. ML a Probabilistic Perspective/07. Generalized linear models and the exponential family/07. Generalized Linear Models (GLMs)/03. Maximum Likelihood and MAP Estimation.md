## Maximum Likelihood and Maximum A Posteriori Estimation in GLMs

### Introdução
A estimação de parâmetros é uma etapa crucial na construção de modelos estatísticos, e os Modelos Lineares Generalizados (GLMs) não são exceção. Este capítulo explora como os métodos de **Maximum Likelihood Estimation (MLE)** e **Maximum A Posteriori (MAP) Estimation** podem ser aplicados para ajustar GLMs, utilizando métodos iterativos para otimizar as funções de log-verossimilhança ou log-verossimilhança penalizada [^9.3.2]. Os GLMs são modelos onde a variável resposta tem uma distribuição da família exponencial e a média é uma função linear das entradas [^9.1]. A versatilidade dos GLMs permite modelar diversos tipos de dados, como dados binários (regressão logística), contagens (regressão de Poisson) e dados contínuos (regressão linear) [^9.3].

### Conceitos Fundamentais

#### Maximum Likelihood Estimation (MLE)
Em MLE, o objetivo é encontrar os valores dos parâmetros que maximizam a função de verossimilhança, que representa a probabilidade dos dados observados dado o modelo [^9.2.4]. No contexto dos GLMs, a função de verossimilhança é baseada na distribuição da família exponencial da variável resposta.

A log-verossimilhança para um GLM tem a seguinte forma [^9.3.2]:
$$ l(w) = \log p(D|w) = \sum_{i=1}^{N} \frac{y_i\theta_i - A(\theta_i)}{\sigma^2} + c(y_i, \sigma^2) $$
onde:
*   $w$ representa os parâmetros do modelo.
*   $D$ representa os dados observados.
*   $y_i$ é a variável resposta para a i-ésima observação.
*   $\theta_i$ é o parâmetro natural da distribuição exponencial.
*   $A(\theta_i)$ é a função de partição logarítmica.
*   $\sigma^2$ é o parâmetro de dispersão (frequentemente definido como 1).
*   $c(y_i, \sigma^2)$ é uma constante de normalização.

Para encontrar os parâmetros que maximizam a log-verossimilhança, podemos usar métodos iterativos como o gradiente descendente ou métodos de segunda ordem [^9.3.2]. O gradiente da log-verossimilhança é dado por [^9.3.2]:

$$ \nabla l(w) = \frac{1}{\sigma^2} \sum_{i=1}^{N} (y_i - \mu_i)x_i $$
onde $\mu_i = A'(\theta_i)$ é a média da distribuição e $x_i$ é o vetor de covariáveis para a i-ésima observação [^9.3.2].

O Hessiano, que é a matriz das segundas derivadas parciais da log-verossimilhança, pode ser usado em métodos de segunda ordem, como o método de Newton, para acelerar a convergência. Para um link canônico, o Hessiano é dado por [^9.3.2]:

$$ H = \frac{1}{\sigma^2} \sum_{i=1}^{N} \frac{d\mu_i}{d\theta_i} x_i x_i^T = \frac{1}{\sigma^2} X^T S X $$

onde $S$ é uma matriz diagonal de pesos, $X$ é a matriz de covariáveis e $\frac{d\mu_i}{d\theta_i}=A''(\theta_i)$ [^9.3.2].

#### Maximum A Posteriori (MAP) Estimation
Em MAP, além de maximizar a verossimilhança, também incorporamos um *prior* sobre os parâmetros. O objetivo é encontrar os parâmetros que maximizam a probabilidade *a posteriori*, que é proporcional ao produto da verossimilhança pelo *prior*.

A probabilidade *a posteriori* é dada por:
$$ p(w|D) \propto p(D|w)p(w) $$
onde $p(w)$ é a distribuição *a priori* dos parâmetros.

Tomando o logaritmo, temos:
$$ \log p(w|D) = \log p(D|w) + \log p(w) $$
O termo $\log p(D|w)$ é a log-verossimilhança, como em MLE, e o termo $\log p(w)$ é o logaritmo da distribuição *a priori*.

A escolha do *prior* é crucial em MAP. Um *prior* comum é a distribuição Gaussiana, que leva à regularização $L_2$ [^9.3.3]. Com um *prior* Gaussiano, a função objetivo se torna:
$$ \log p(w|D) = l(w) - \frac{1}{2}w^T V_0^{-1} w $$

onde $V_0$ é a matriz de covariância do *prior* Gaussiano.

O gradiente e o Hessiano da função objetivo MAP são modificados em relação aos de MLE para incluir os termos do *prior*. O gradiente é dado por [^9.4.1]:
$$ \nabla \log p(w|D) = \nabla l(w) - V_0^{-1} w $$

e o Hessiano é dado por [^9.4.1]:
$$ H_{MAP} = H + V_0^{-1} $$

#### Métodos Iterativos
Tanto MLE quanto MAP requerem métodos iterativos para otimizar as funções objetivo. Alguns métodos comuns incluem:

*   **Gradiente Descendente:** Este é um método de primeira ordem que atualiza os parâmetros na direção oposta do gradiente [^9.3.2].
*   **Método de Newton:** Este é um método de segunda ordem que usa o Hessiano para aproximar a curvatura da função objetivo e acelerar a convergência [^9.3.2].
*   **Iteratively Reweighted Least Squares (IRLS):** Este é um método específico para GLMs que usa uma aproximação de mínimos quadrados ponderados para otimizar a função objetivo [^9.3.2].

### Conclusão
A estimação de parâmetros em GLMs usando MLE e MAP é uma tarefa fundamental para a construção de modelos estatísticos precisos e confiáveis. A escolha entre MLE e MAP depende da disponibilidade de conhecimento *a priori* sobre os parâmetros e da necessidade de regularização [^9.3.3]. Os métodos iterativos, como gradiente descendente, método de Newton e IRLS, fornecem ferramentas eficazes para otimizar as funções objetivo e encontrar os valores ideais dos parâmetros [^9.3.2].

### Referências
[^9.1]: Section 9.1
[^9.2.4]: Section 9.2.4
[^9.3]: Section 9.3
[^9.3.2]: Section 9.3.2
[^9.3.3]: Section 9.3.3
[^9.4.1]: Section 9.4.1
<!-- END -->