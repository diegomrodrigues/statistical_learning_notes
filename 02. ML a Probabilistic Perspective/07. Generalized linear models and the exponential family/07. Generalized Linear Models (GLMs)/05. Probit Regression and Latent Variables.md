## Probit Regression: An Alternative to Logistic Regression in GLMs

### Introdução
Em continuidade ao estudo dos Modelos Lineares Generalizados (GLMs) [^9], este capítulo explora a regressão probit, uma alternativa à regressão logística para modelar resultados binários. Enquanto a regressão logística utiliza a função logística para modelar a probabilidade de um resultado binário, a regressão probit emprega a função de distribuição cumulativa (CDF) da distribuição normal padrão [^9.4]. Ambas as abordagens pertencem à família dos GLMs, permitindo a modelagem de variáveis de resposta que não seguem uma distribuição normal [^9]. A regressão probit oferece uma perspectiva diferente sobre a classificação binária, conectando-se a modelos de utilidade aleatória (RUM) através da interpretação de variáveis latentes [^9.4.2].

### Conceitos Fundamentais
A **regressão probit** é um modelo estatístico que utiliza a função de distribuição cumulativa (CDF) da distribuição normal padrão para modelar a probabilidade de um resultado binário [^9.4]. Formalmente, o modelo pode ser expresso como:
$$
p(y = 1|x, w) = \Phi(w^T x)
$$
onde:
- $y$ é a variável de resposta binária (0 ou 1)
- $x$ é o vetor de preditores
- $w$ é o vetor de coeficientes
- $\Phi(\cdot)$ é a função de distribuição cumulativa (CDF) da distribuição normal padrão [^9.4]

A função $\Phi(z)$ é definida como:
$$
\Phi(z) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{z} e^{-\frac{t^2}{2}} dt
$$

A **interpretação da variável latente** da regressão probit conecta-a aos modelos de utilidade aleatória (RUM). Nesta interpretação, cada item $x_i$ está associado a duas utilidades latentes, $u_{0i}$ e $u_{1i}$, correspondendo às escolhas possíveis de $y_i = 0$ e $y_i = 1$, respectivamente [^9.4.2]. A escolha observada é determinada pela ação com maior utilidade:
$$
y_i = \mathbb{I}(u_{1i} > u_{0i})
$$
onde $\mathbb{I}(\cdot)$ é a função indicadora [^9.4.2]. As utilidades latentes são modeladas como:
$$\nu_{0i} = w^T x_i + \delta_{0i}$$
$$\nu_{1i} = w^T x_i + \delta_{1i}$$
onde $\delta_{0i}$ e $\delta_{1i}$ são termos de erro que representam fatores não modelados [^9.4.2]. A diferença nas utilidades é definida como $z_i = u_{1i} - u_{0i} = w^T x_i + \epsilon_i$, onde $\epsilon_i = \delta_{1i} - \delta_{0i}$ [^9.4.2]. Se os termos de erro $\delta$ seguem uma distribuição normal, então $\epsilon_i \sim N(0,1)$ [^9.4.2]. Portanto,
$$
p(y_i = 1|x_i, w) = P(z_i \geq 0) = P(\epsilon > -w^T x_i) = 1 - \Phi(-w^T x_i) = \Phi(w^T x_i)
$$
Essa derivação demonstra como a regressão probit surge naturalmente da interpretação da variável latente e da suposição de normalidade dos termos de erro [^9.4.2].

A regressão probit pode ser estendida para modelar dados ordinais, resultando na **regressão probit ordinal** [^9.4.3]. Neste caso, a variável de resposta pode assumir $C$ valores discretos ordenados. O modelo introduz $C + 1$ limiares $\gamma_j$ tais que:
$$
y_i = j \text{ se } \gamma_{j-1} < z_i \leq \gamma_j
$$
onde $\gamma_0 \leq \gamma_1 \leq \dots \leq \gamma_C$ [^9.4.3]. Para identificabilidade, normalmente define-se $\gamma_0 = -\infty$, $\gamma_1 = 0$ e $\gamma_C = \infty$ [^9.4.3].

Outra extensão é o **modelo probit multinomial**, onde a variável de resposta pode assumir $C$ valores categóricos não ordenados [^9.4.4]. Neste modelo, cada categoria $c$ está associada a uma utilidade latente:
$$
z_{ic} = w^T x_{ic} + \epsilon_{ic}
$$
onde $\epsilon \sim N(0, R)$ e $R$ é uma matriz de correlação [^9.4.4]. A categoria escolhida é aquela com a maior utilidade:
$$
y_i = \text{argmax}_c z_{ic}
$$

### Conclusão
A regressão probit oferece uma alternativa valiosa à regressão logística para modelar resultados binários em GLMs [^9.4]. Sua interpretação de variável latente fornece uma conexão com modelos de utilidade aleatória, oferecendo uma base teórica para o modelo [^9.4.2]. Além disso, a regressão probit pode ser estendida para modelar dados ordinais e multinomiais, tornando-a uma ferramenta flexível para uma variedade de aplicações [^9.4.3, 9.4.4]. Embora a regressão logística seja frequentemente mais utilizada devido à sua interpretabilidade direta em termos de *log-odds ratio* [^9.2.2.1, 9.3.1], a regressão probit pode ser preferível em situações onde a suposição de normalidade dos termos de erro é mais plausível [^9.4.2]. A escolha entre regressão logística e probit muitas vezes depende do contexto específico do problema e das propriedades dos dados [^9.4].

### Referências
[^9]: Capítulo 9 do texto base.
[^9.2.2.1]: Seção 9.2.2.1 do texto base.
[^9.3.1]: Seção 9.3.1 do texto base.
[^9.4]: Seção 9.4 do texto base.
[^9.4.2]: Seção 9.4.2 do texto base.
[^9.4.3]: Seção 9.4.3 do texto base.
[^9.4.4]: Seção 9.4.4 do texto base.

<!-- END -->