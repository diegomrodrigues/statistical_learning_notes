## Loss Functions for Learning to Rank

### Introdução
O objetivo do *Learning to Rank* é aprender uma função que ordene um conjunto de itens de acordo com sua relevância para uma dada consulta (query) [^300]. Para avaliar a qualidade dos modelos de *ranking*, diversas funções de perda (loss functions) são utilizadas, cada uma capturando diferentes aspectos da qualidade da ordenação. Além disso, métricas de correlação de *rank* são importantes para medir a similaridade entre o *rank* predito e o *ground truth*. Este capítulo explora algumas das funções de perda e métricas de correlação mais comuns utilizadas em *Learning to Rank*, incluindo *Mean Reciprocal Rank* (MRR), *Mean Average Precision* (MAP), *Normalized Discounted Cumulative Gain* (NDCG) e *Weighted Approximate-Rank Pairwise* (WARP) loss [^303].

### Conceitos Fundamentais

#### Funções de Perda Comuns para Ranking
As funções de perda são cruciais para treinar modelos de *Learning to Rank*. Elas quantificam a diferença entre a ordenação predita e a ordenação ideal, permitindo que o modelo ajuste seus parâmetros para minimizar essa diferença.

1.  **Mean Reciprocal Rank (MRR)**:
    -   O *reciprocal rank* (RR) é o inverso da posição do primeiro documento relevante na lista ordenada para uma dada consulta [^303].
    -   Se $r(q)$ é a posição do primeiro documento relevante para a consulta $q$, então $RR = \frac{1}{r(q)}$ [^303].
    -   O MRR é a média dos *reciprocal ranks* sobre todas as consultas:
        $$MRR = \frac{1}{|Q|} \sum_{q \in Q} \frac{1}{r(q)},$$
        onde $Q$ é o conjunto de consultas [^303].
    -   MRR é uma métrica simples e focada na precisão do primeiro resultado [^303].

2.  **Mean Average Precision (MAP)**:
    -   MAP é uma métrica que avalia a precisão média das ordenações para um conjunto de consultas [^303].
    -   A *precision at k* ($P@k$) é definida como a proporção de documentos relevantes nos $k$ primeiros resultados [^303]:
        $$P@k(\pi) = \frac{\text{número de documentos relevantes nos top k posições de } \pi}{k},$$
        onde $\pi$ é a ordenação dos documentos [^303].
    -   O *average precision* (AP) é a média das *precisions at k* para todos os documentos relevantes:
        $$AP(\pi) = \frac{\sum_{k} P@k(\pi) \cdot I_k}{\text{número de documentos relevantes}},$$
        onde $I_k$ é um indicador se o documento $k$ é relevante [^303].
    -   O MAP é a média dos *average precisions* sobre todas as consultas [^303].

3.  **Normalized Discounted Cumulative Gain (NDCG)**:
    -   NDCG é uma métrica que considera a relevância gradual dos documentos, descontando documentos relevantes que aparecem em posições inferiores na lista ordenada [^303].
    -   O *discounted cumulative gain* (DCG) é calculado como:
        $$DCG@k(r) = r_1 + \sum_{i=2}^{k} \frac{r_i}{\log_2 i},$$
        onde $r_i$ é a relevância do item $i$ [^303].
    -   Uma alternativa para o DCG é:
        $$DCG@k(r) = \sum_{i=1}^{k} \frac{2^{r_i} - 1}{\log_2(1 + i)}$$ [^303].
    -   Para normalizar o DCG, divide-se pelo *ideal DCG* (IDCG), que é o DCG da ordenação perfeita [^303]:
        $$NDCG = \frac{DCG}{IDCG}$$ [^304].

4.  **Weighted Approximate-Rank Pairwise (WARP) Loss:**
    -   WARP loss é uma função de perda que aproxima a precisão@k e é especialmente útil quando se deseja otimizar o desempenho nas primeiras posições do *ranking* [^304].
    -   WARP loss é definido como [^304]:
        $$WARP(f(x,:), y) = L(rank(f(x,:), y))$$
        onde $rank(f(x,:), y)$ é o *rank* do rótulo verdadeiro $y$ atribuído pela função de pontuação $f(x,:)$ e $L$ transforma o *rank* inteiro em uma penalidade de valor real [^304].
    -   WARP loss penaliza pares de documentos ordenados incorretamente, dando mais peso aos erros que ocorrem nas primeiras posições do *ranking* [^304].

#### Métricas de Correlação de Rank
As métricas de correlação de *rank* medem a similaridade entre duas listas ordenadas. Elas são úteis para avaliar a consistência entre a ordenação predita e a ordenação real.

1.  **Kendall's Tau**:
    -   Kendall's Tau é uma métrica que mede a correlação ordinal entre duas listas [^304].
    -   Ela quantifica a diferença entre o número de pares concordantes e discordantes nas duas listas [^304].
    -   O coeficiente de Kendall's Tau é definido como:
        $$tau(\pi, \pi^*) = \frac{\sum_{u<v} w_{uv} [1 + sgn(\pi_u - \pi_v)sgn(\pi_u^* - \pi_v^*)]}{2\sum_{u<v} w_{uv}}$$
        onde $\pi$ e $\pi^*$ são as listas ordenadas, $sgn$ é a função sinal e $w_{uv}$ é um peso opcional para pares [^304].

### Conclusão

A escolha da função de perda e da métrica de avaliação é crucial para o sucesso de um sistema de *Learning to Rank*. As métricas MRR, MAP e NDCG capturam diferentes aspectos da qualidade da ordenação, e o WARP loss oferece uma aproximação melhor para otimizar a precisão@k. As métricas de correlação de *rank*, como Kendall's Tau, fornecem uma visão sobre a similaridade entre a ordenação predita e o *ground truth* [^304]. A seleção apropriada depende dos requisitos específicos da aplicação e dos objetivos de otimização.

### Referências
[^300]: Capítulo 9, página 300.
[^303]: Capítulo 9, página 303.
[^304]: Capítulo 9, página 304.
<!-- END -->