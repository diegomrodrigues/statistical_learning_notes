## Ordinal Probit Regression

### Introdução
O modelo probit, como discutido anteriormente, é adequado para variáveis de resposta binárias. No entanto, muitas vezes encontramos situações em que a variável de resposta é *ordinal*, ou seja, pode assumir valores discretos que possuem uma ordem inerente. A regressão probit ordinal estende o modelo probit para lidar com esses tipos de variáveis [^295].

### Conceitos Fundamentais
A regressão probit ordinal baseia-se na interpretação de variável latente do modelo probit [^294]. A ideia central é que, embora observemos apenas uma variável de resposta ordinal, existe uma variável latente contínua subjacente que determina a categoria observada. As categorias ordenadas são determinadas por múltiplos limiares (thresholds) na variável de utilidade latente [^295].

Formalmente, suponha que temos uma variável de resposta $y_i$ que pode assumir $C$ valores discretos ordenados. Introduzimos $C+1$ limiares $\gamma_j$ tais que:
$$y_i = j \text{ se } \gamma_{j-1} < z_i \leq \gamma_j$$ [^295]

Onde $z_i$ é a variável latente. Para fins de identificabilidade, geralmente fixamos $\gamma_0 = -\infty$, $\gamma_1 = 0$ e $\gamma_C = \infty$ [^295].  Isso significa que a variável latente é comparada a um conjunto de limiares ordenados para determinar a categoria observada.

A variável latente $z_i$ é modelada como uma função linear dos preditores:
$$z_i = \mathbf{w}^T\mathbf{x}_i + \epsilon_i$$
Onde $\mathbf{w}$ é o vetor de pesos, $\mathbf{x}_i$ é o vetor de preditores e $\epsilon_i$ é um termo de erro com distribuição normal padrão [^294].

A probabilidade de observar a categoria $j$ é então dada por:
$$P(y_i = j | \mathbf{x}_i, \mathbf{w}, \boldsymbol{\gamma}) = P(\gamma_{j-1} < z_i \leq \gamma_j | \mathbf{x}_i, \mathbf{w}) = \Phi(\gamma_j - \mathbf{w}^T\mathbf{x}_i) - \Phi(\gamma_{j-1} - \mathbf{w}^T\mathbf{x}_i)$$
Onde $\Phi$ é a função de distribuição cumulativa normal padrão.

### Estimação dos Parâmetros
A estimação dos parâmetros $\mathbf{w}$ e $\boldsymbol{\gamma}$ envolve a maximização da função de verossimilhança (likelihood). Devido à complexidade da função de verossimilhança, métodos iterativos são geralmente empregados. A função log-verossimilhança é dada por:
$$l(\mathbf{w}, \boldsymbol{\gamma}) = \sum_{i=1}^N \log P(y_i | \mathbf{x}_i, \mathbf{w}, \boldsymbol{\gamma}) = \sum_{i=1}^N \log [\Phi(\gamma_{y_i} - \mathbf{w}^T\mathbf{x}_i) - \Phi(\gamma_{y_i-1} - \mathbf{w}^T\mathbf{x}_i)]$$

A maximização desta função requer otimização numérica, como o método de Newton-Raphson ou algoritmos de gradiente [^294]. É importante notar que, como os limiares $\gamma_j$ devem obedecer a uma restrição de ordem, a otimização deve levar em conta essa restrição [^295].

### Conclusão
A regressão probit ordinal oferece uma estrutura flexível para modelar variáveis de resposta ordinais. Ao assumir uma variável latente subjacente e limiares ordenados, o modelo captura a natureza ordenada das categorias de resposta. A estimação dos parâmetros envolve a maximização da função de verossimilhança, que pode ser realizada usando técnicas de otimização numérica. A interpretação do modelo fornece insights sobre como os preditores influenciam a variável latente e, portanto, a probabilidade de observar diferentes categorias ordinais.

### Referências
[^295]: Page 295 from the document.
[^294]: Page 294 from the document.

<!-- END -->