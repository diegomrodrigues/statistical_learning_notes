## Probit Regression: Modeling Binary Outcomes with Latent Variables

### Introdução
Este capítulo detalha os modelos de regressão Probit, que são utilizados para modelar resultados binários. Como alternativa à regressão logística, a regressão Probit emprega a função de distribuição cumulativa inversa (CDF) da distribuição normal padrão como sua função de ligação [^293]. A interpretação através de um modelo de variável latente, onde o resultado binário observado é determinado se uma variável de utilidade latente excede um limiar, conecta a regressão Probit aos modelos de utilidade aleatória (RUM) [^294].

### Conceitos Fundamentais

**Probit Regression e a Função de Ligação Normal Inversa:** Na regressão Probit, modelamos a probabilidade de um resultado binário $y$ dado um conjunto de preditores $x$ usando a função de distribuição cumulativa (CDF) da distribuição normal padrão, denotada por $\Phi(\cdot)$ [^293]. Especificamente, o modelo é definido como:

$$\
P(y = 1 | x, w) = \Phi(w^T x)
$$

onde $w$ é o vetor de coeficientes, $x$ é o vetor de preditores e $\Phi$ é a função de ligação Probit.  A função $\Phi(w^T x)$ mapeia a combinação linear dos preditores para um valor entre 0 e 1, representando a probabilidade de $y = 1$.

**Modelo de Variável Latente:** A regressão Probit pode ser interpretada através de um modelo de variável latente [^294]. Assumimos que existe uma variável latente $z$ que segue uma distribuição normal com média $w^T x$ e variância 1:

$$\
z \sim N(w^T x, 1)
$$

O resultado binário $y$ é determinado por se a variável latente $z$ excede um limiar, geralmente definido como 0:

$$\
y =
\begin{cases}
1 & \text{se } z \geq 0 \\\\
0 & \text{se } z < 0
\end{cases}
$$

Portanto, $P(y = 1 | x, w) = P(z \geq 0 | x, w) = P(w^T x + \epsilon \geq 0) = P(\epsilon \geq -w^T x) = 1 - \Phi(-w^T x) = \Phi(w^T x)$, onde $\epsilon$ é um erro aleatório seguindo uma distribuição normal padrão.

**Conexão com Modelos de Utilidade Aleatória (RUM):** A interpretação da variável latente conecta a regressão Probit aos modelos de utilidade aleatória (RUM) [^294]. Em um RUM, cada alternativa (neste caso, $y = 0$ ou $y = 1$) está associada a uma utilidade latente. A alternativa com a maior utilidade é escolhida. No contexto da regressão Probit, podemos associar duas utilidades latentes $u_{0i}$ e $u_{1i}$ a cada item $x_i$:

$$\nu_{0i} = w_0^T x_i + \delta_{0i}$$

$$\nu_{1i} = w_1^T x_i + \delta_{1i}$$

onde $\delta_{0i}$ e $\delta_{1i}$ são termos de erro representando fatores não modelados. A escolha observada $y_i$ é determinada por qual utilidade é maior:

$$\
y_i = \mathbb{I}(u_{1i} > u_{0i})
$$

Definindo $z_i = u_{1i} - u_{0i} = (w_1 - w_0)^T x_i + (\delta_{1i} - \delta_{0i}) = w^T x_i + \epsilon_i$, onde $w = w_1 - w_0$ e $\epsilon_i = \delta_{1i} - \delta_{0i}$, e assumindo que $\epsilon_i \sim N(0, 1)$, recuperamos o modelo Probit:

$$\
P(y_i = 1 | x_i, w) = P(z_i > 0) = P(w^T x_i + \epsilon_i > 0) = \Phi(w^T x_i)
$$

**Estimativa de ML/MAP usando Otimização Baseada em Gradiente:** Podemos encontrar a estimativa de máxima verossimilhança (MLE) para a regressão Probit usando métodos de gradiente padrão [^294]. Definindo $p_i = w^T x_i$ e $y_i \in \\{-1, +1\\}$, o gradiente do log-likelihood para um caso específico é dado por:

$$\
\frac{\partial}{\partial w} \log P(y_i | w^T x_i) = x_i \frac{y_i \phi(p_i)}{\Phi(y_i p_i)}
$$

onde $\phi$ é a função de densidade de probabilidade normal padrão (PDF) e $\Phi$ é a CDF normal padrão. Da mesma forma, o Hessiano para um único caso é dado por:

$$\
H_i = \frac{\partial^2}{\partial w^2} \log P(y_i | w^T x_i) = -x_i \left( \frac{y_i p_i \phi(p_i)}{\Phi(y_i p_i)} + \left( \frac{\phi(p_i)}{\Phi(y_i p_i)} \right)^2 \right) x_i^T
$$

Essas expressões podem ser modificadas para computar a estimativa de máxima a posteriori (MAP) de maneira direta, usando um prior $p(w) = N(0, V_0)$.

### Conclusão
A regressão Probit oferece uma alternativa à regressão logística para modelar resultados binários. Sua interpretação através de um modelo de variável latente a conecta aos modelos de utilidade aleatória, fornecendo uma estrutura teórica rica para entender e aplicar o modelo. A estimativa de parâmetros pode ser realizada usando métodos de otimização baseados em gradiente, tornando a regressão Probit uma ferramenta flexível e poderosa na análise estatística.

### Referências
[^293]: Page 293: "In (binary) logistic regression, we use a model of the form $p(y = 1|x_i, w) = sigm(w^T x_i)$. In general, we can write $p(y = 1|x_i, w) = g^{-1}(w^T x_i)$, for any function $g^{-1}$ that maps $[-\infty, \infty]$ to $[0, 1]$. Several possible mean functions are listed in Table 9.2. In this section, we focus on the case where $g^{-1}(n) = \Phi(n)$, where $\Phi(n)$ is the cdf of the standard normal. This is known as probit regression."
[^294]: Page 294: "We can interpret the probit (and logistic) model as follows. First, let us associate each item $x_i$ with two latent utilities, $u_{0i}$ and $u_{1i}$, corresponding to the possible choices of $y_i = 0$ and $y_i = 1$. We then assume that the observed choice is whichever action has larger utility. More precisely, the model is as follows: ... This is called a random utility model or RUM (McFadden 1974; Train 2009)."
<!-- END -->