## ML/MAP Estimation em Regressão Probit via Otimização Baseada em Gradiente

### Introdução
Este capítulo se aprofunda na aplicação de métodos de otimização baseados em gradiente para a estimação de máxima verossimilhança (ML) e máxima a posteriori (MAP) em modelos de regressão probit. A regressão probit, como uma forma de modelo linear generalizado (GLM) [^1: 9.1], é frequentemente utilizada para modelar variáveis dependentes binárias. Expandindo sobre o conceito de GLMs, onde a média da variável de resposta é uma função linear das entradas [^1: 9.1], exploraremos como a família exponencial [^1: 9.2] está no cerne dos GLMs. Diferente da regressão logística, que usa a função sigmoide, a regressão probit emprega a função de distribuição cumulativa (CDF) da normal padrão [^13: 9.4].

### Conceitos Fundamentais
#### Regressão Probit e a Função CDF Normal Padrão
Na regressão probit, modelamos a probabilidade de uma variável binária $y$ dado um vetor de entrada $x_i$ e um vetor de peso $w$ como:
$$np(y = 1|x_i, w) = \Phi(w^T x_i)$$
onde $\Phi(\eta)$ é a CDF da normal padrão [^13: 9.4].

#### Estimação de Máxima Verossimilhança (MLE)
Para encontrar a MLE dos parâmetros $w$, maximizamos a função de log-verossimilhança. Dado um conjunto de dados, a função de log-verossimilhança é:
$$mathcal{L}(w) = \sum_i \log p(y_i|x_i, w)$$
onde $y_i \in \{-1, +1\}$ é a variável de resposta binária, e $x_i$ é o vetor de entrada correspondente [^14: 9.4.1].

#### Otimização Baseada em Gradiente
A otimização baseada em gradiente é usada para encontrar os parâmetros $w$ que maximizam a log-verossimilhança [^14: 9.4.1]. Isso envolve calcular o gradiente e a Hessiana da função de log-verossimilhança e usá-los para atualizar iterativamente os parâmetros do modelo.

#### Gradiente da Log-Verossimilhança
O gradiente da log-verossimilhança para um caso específico é dado por:
$$frac{d}{dw} \log p(y_i|w^T x_i) = x_i \frac{y_i \phi(\mu_i)}{\Phi(z_i \mu_i)}$$
onde $\mu_i = w^T x_i$, $\phi$ é a função de densidade de probabilidade (PDF) normal padrão, e $z_i$ é igual a $y_i$ [^14: 9.4.1].

#### Hessiana da Log-Verossimilhança
A Hessiana para um caso específico é dada por:
$$nH_i = \frac{d^2}{dw^2} \log p(y_i|w^T x_i) = -x_i \left( \frac{y_i \mu_i \phi(\mu_i)}{\Phi(z_i \mu_i)} + \left( \frac{\phi(\mu_i)}{\Phi(z_i \mu_i)} \right)^2 \right) x_i^T$$
[^14: 9.4.1].

#### Estimação de Máxima a Posteriori (MAP)
Para incorporar conhecimento prévio sobre os parâmetros, podemos usar a estimativa MAP. Dado um prior $p(w)$, o objetivo é maximizar a função de log-posterior:
$$n\log p(w|D) = \log p(D|w) + \log p(w)$$
onde $D$ representa os dados [^14: 9.4.1]. Se usarmos um prior Gaussiano $p(w) = \mathcal{N}(0, V_0)$, então o gradiente e a Hessiana da log-posterior penalizada se tornam:
*   Gradiente: $\sum_i g_i + 2V_0^{-1}w$
*   Hessiana: $\sum_i H_i + 2V_0^{-1}$

#### Variável Latente e Interpretação
Modelos probit podem ser interpretados usando variáveis latentes [^14: 9.4.2]. Associamos cada item $x_i$ com duas utilidades latentes, $u_{0i}$ e $u_{1i}$, correspondendo às escolhas possíveis de $y_i = 0$ e $y_i = 1$. Assumimos que a escolha observada é a que tem a maior utilidade.

#### Modelo de Utilidade Aleatória (RUM)
Precisamente, o modelo é definido como:
$$n\begin{aligned}\nu_{0i} &= w^T x_i + \delta_{0i} \\\nu_{1i} &= w^T x_i + \delta_{1i} \\\ny_i &= \mathbb{I}(u_{1i} > u_{0i})\n\end{aligned}$$
onde $\delta$ são termos de erro [^14: 9.4.2].

### Conclusão
Este capítulo detalhou o processo de realização da estimação de ML/MAP na regressão probit usando métodos de otimização baseados em gradiente. Derivamos o gradiente e a Hessiana da função de log-verossimilhança, e explicamos como modificar essas expressões para computar a estimativa MAP com um prior Gaussiano. Além disso, exploramos a interpretação de variável latente do modelo probit, fornecendo *insights* sobre sua conexão com modelos de utilidade aleatória. Esses métodos fornecem uma base sólida para modelar variáveis binárias com regressão probit e podem ser estendidos para cenários mais complexos.

### Referências
[^1]: Murphy, Kevin P. *Machine learning: a probabilistic perspective*. MIT press, 2012.
[^13]: Murphy, Kevin P. *Machine learning: a probabilistic perspective*. MIT press, 2012. (Section 9.4)
[^14]: Murphy, Kevin P. *Machine learning: a probabilistic perspective*. MIT press, 2012. (Section 9.4.1)
<!-- END -->