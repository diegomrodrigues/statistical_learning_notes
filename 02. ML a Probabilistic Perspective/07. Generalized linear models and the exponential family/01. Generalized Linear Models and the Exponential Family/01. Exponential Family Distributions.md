## Aprofundando na Família Exponencial

### Introdução

Este capítulo explora em profundidade a **família exponencial**, uma classe ampla de distribuições de probabilidade que engloba distribuições comuns como a Gaussiana, Bernoulli, Student's t, uniforme e gama [^1]. A importância da família exponencial reside na sua capacidade de derivar teoremas e algoritmos gerais com ampla aplicabilidade em *machine learning* e simplificar o aprendizado *online* devido à sua capacidade de comprimir dados em estatísticas suficientes de tamanho fixo [^1].

### Conceitos Fundamentais

A **família exponencial** é definida formalmente como um conjunto de distribuições de probabilidade (PDFs ou PMFs) que podem ser expressas na seguinte forma [^2]:

$$ p(x|\theta) = \frac{1}{Z(\theta)} h(x) \exp[\theta^T \phi(x)] = h(x) \exp[\theta^T \phi(x) - A(\theta)] $$

onde:
*   $x$ representa os dados, pertencentes a um espaço amostral $\mathcal{X}^m$ [^2].
*   $\theta$ é o vetor de parâmetros, pertencente a um espaço de parâmetros $\Theta \subseteq \mathbb{R}^d$ [^2].
*   $h(x)$ é uma função de *scaling*, frequentemente igual a 1 [^2].
*   $\phi(x)$ é o vetor de **estatísticas suficientes**, pertencente a $\mathbb{R}^d$ [^2].
*   $Z(\theta)$ é a **função de partição**, que garante que a distribuição se normalize para 1 [^2].
*   $A(\theta) = \log Z(\theta)$ é a **função log-partição** ou função cumulante [^2].

Os parâmetros $\theta$ são chamados de **parâmetros naturais** ou **parâmetros canônicos** [^2]. Se $\phi(x) = x$, dizemos que é uma família exponencial natural [^2].

Uma forma mais geral da família exponencial pode ser escrita como [^2]:

$$ p(x|\theta) = h(x) \exp[\eta(\theta)^T \phi(x) - A(\eta(\theta))] $$

onde $\eta$ é uma função que mapeia os parâmetros $\theta$ para os parâmetros canônicos $\eta = \eta(\theta)$ [^2]. Se $\dim(\theta) < \dim(\eta(\theta))$, é chamada de **família exponencial curva**, indicando que existem mais estatísticas suficientes do que parâmetros [^2]. Se $\eta(\theta) = \theta$, o modelo está na **forma canônica** [^2]. Assumimos que os modelos estão na forma canônica, a menos que especificado de outra forma [^2].

#### Exemplos

##### Bernoulli

A distribuição de Bernoulli para $x \in \{0, 1\}$ pode ser escrita na forma da família exponencial como [^2]:

$$ \text{Ber}(x|\mu) = \mu^x (1 - \mu)^{1-x} = \exp[x \log(\mu) + (1 - x) \log(1 - \mu)] = \exp[\phi(x)^T \theta] $$

onde $\phi(x) = [I(x=0), I(x=1)]$ e $\theta = [\log(\mu), \log(1-\mu)]$ [^2]. No entanto, essa representação é *over-complete* devido à dependência linear entre as características [^2]:

$$ 1^T \phi(x) = I(x=0) + I(x=1) = 1 $$

Portanto, $\theta$ não é unicamente identificável [^2]. É comum requerer que a representação seja mínima, o que significa que existe um único $\theta$ associado à distribuição [^2]. Neste caso, podemos definir [^2]:

$$ \text{Ber}(x|\mu) = (1 - \mu) \exp\left[x \log\left(\frac{\mu}{1 - \mu}\right)\right] $$

Agora temos $\phi(x) = x$ e $\theta = \log(\frac{\mu}{1 - \mu})$, que é a razão de chances logarítmica (log-odds ratio), e $Z = 1/(1 - \mu)$ [^3]. Podemos recuperar o parâmetro médio $\mu$ do parâmetro canônico usando [^3]:

$$ \mu = \text{sigm}(\theta) = \frac{1}{1 + e^{-\theta}} $$

##### Multinoulli

A distribuição Multinoulli pode ser representada como uma família exponencial mínima da seguinte forma (onde $x_k = I(x = k)$) [^3]:

$$ \text{Cat}(x|\mu) = \prod_{k=1}^K \mu_k^{x_k} = \exp\left[\sum_{k=1}^K x_k \log \mu_k\right] $$

$$ = \exp\left[\sum_{k=1}^{K-1} x_k \log \mu_k + \left(1 - \sum_{k=1}^{K-1} x_k\right) \log\left(1 - \sum_{k=1}^{K-1} \mu_k\right)\right] $$

$$ = \exp\left[\sum_{k=1}^{K-1} x_k \log \frac{\mu_k}{1 - \sum_{j=1}^{K-1} \mu_j} + \log\left(1 - \sum_{k=1}^{K-1} \mu_k\right)\right] $$

$$ = \exp\left[\sum_{k=1}^{K-1} x_k \log \frac{\mu_k}{\mu_K} + \log \mu_K\right] $$

onde $\mu_K = 1 - \sum_{k=1}^{K-1} \mu_k$ [^3]. Podemos escrever isso na forma da família exponencial como [^3]:

$$ \text{Cat}(x|\theta) = \exp(\theta^T \phi(x) - A(\theta)) $$

$$ \theta = \left[\log \frac{\mu_1}{\mu_K}, \dots, \log \frac{\mu_{K-1}}{\mu_K}\right] $$

$$ \phi(x) = [I(x=1), \dots, I(x=K-1)] $$

Podemos recuperar os parâmetros médios dos parâmetros canônicos usando [^3]:

$$ \mu_k = \frac{e^{\theta_k}}{1 + \sum_{j=1}^{K-1} e^{\theta_j}} $$

A partir disso, encontramos [^3]:

$$ \mu_K = \frac{1}{1 + \sum_{j=1}^{K-1} e^{\theta_j}} $$

e, portanto [^3]:

$$ A(\theta) = \log\left(1 + \sum_{k=1}^{K-1} e^{\theta_k}\right) $$

Se definirmos $\theta_K = 0$, podemos escrever $\mu = S(\theta)$ e $A(\theta) = \log \sum_{k=1}^K e^{\theta_k}$, onde $S$ é a função softmax [^3].

##### Gaussiana Univariada

A Gaussiana univariada pode ser escrita na forma da família exponencial como [^4]:

$$ \mathcal{N}(x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left[-\frac{1}{2\sigma^2}(x - \mu)^2\right] $$

$$ = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left[-\frac{1}{2\sigma^2}x^2 + \frac{\mu}{\sigma^2}x - \frac{1}{2\sigma^2}\mu^2\right] $$

$$ = \frac{1}{Z(\theta)} \exp[\theta^T \phi(x)] $$

onde [^4]:

$$ \theta = \begin{bmatrix} \frac{\mu}{\sigma^2} \\ -\frac{1}{2\sigma^2} \end{bmatrix} $$

$$ \phi(x) = \begin{bmatrix} x \\ x^2 \end{bmatrix} $$

$$ Z(\mu, \sigma^2) = \sqrt{2\pi\sigma^2} \exp\left[\frac{\mu^2}{2\sigma^2}\right] $$

$$ A(\theta) = -\frac{\theta_1^2}{4\theta_2} - \frac{1}{2} \log(-2\theta_2) - \frac{1}{2} \log(2\pi) $$

#### Não-exemplos

Nem todas as distribuições de interesse pertencem à família exponencial [^4]. Por exemplo, a distribuição uniforme, $X \sim \text{Unif}(a, b)$, não pertence, pois o suporte da distribuição depende dos parâmetros [^4]. Além disso, a distribuição Student-t não pertence, pois não tem a forma requerida [^4].

#### Função Log-Partição

Uma propriedade importante da família exponencial é que as derivadas da função log-partição podem ser usadas para gerar *cumulantes* das estatísticas suficientes [^4]. Por esta razão, $A(\theta)$ é às vezes chamada de **função cumulante** [^4].

Para a primeira derivada, temos [^5]:

$$ \frac{dA}{d\theta} = \frac{d}{d\theta} \left(\log \int \exp(\theta \phi(x)) h(x) dx\right) $$

$$ = \frac{\int \frac{d}{d\theta} \exp(\theta \phi(x)) h(x) dx}{\int \exp(\theta \phi(x)) h(x) dx} $$

$$ = \frac{\int \phi(x) \exp(\theta \phi(x)) h(x) dx}{\exp(A(\theta))} $$

$$ = \int \phi(x) \exp(\theta \phi(x) - A(\theta)) h(x) dx $$

$$ = \int \phi(x) p(x) dx = \mathbb{E}[\phi(x)] $$

Para a segunda derivada, temos [^5]:

$$ \frac{d^2 A}{d\theta^2} = \int \phi(x) \exp (\theta \phi(x) - A(\theta)) h(x) (\phi(x) - A'(\theta)) dx $$

$$ = \int \phi(x) p(x) (\phi(x) - A'(\theta)) dx $$

$$ = \int \phi^2(x) p(x) dx - A'(\theta) \int \phi(x) p(x) dx $$

$$ = \mathbb{E}[\phi^2(X)] - \mathbb{E}[\phi(x)]^2 = \text{var}[\phi(x)] $$

No caso multivariado [^5]:

$$ \frac{\partial^2 A}{\partial \theta_i \partial \theta_j} = \mathbb{E}[\phi_i(x)\phi_j(x)] - \mathbb{E}[\phi_i(x)] \mathbb{E}[\phi_j(x)] $$

e, portanto [^5]:

$$ \nabla^2 A(\theta) = \text{cov}[\phi(x)] $$

Como a covariância é positiva definida, vemos que $A(\theta)$ é uma função convexa [^5].

##### Exemplo: Distribuição de Bernoulli

Para a distribuição de Bernoulli, temos $A(\theta) = \log(1 + e^\theta)$, então a média é dada por [^5]:

$$ \frac{dA}{d\theta} = \frac{e^\theta}{1 + e^\theta} = \frac{1}{1 + e^{-\theta}} = \text{sigm}(\theta) = \mu $$

A variância é dada por [^5]:

$$ \frac{d^2 A}{d\theta^2} = \frac{d}{d\theta} (1 + e^{-\theta})^{-1} = (1 + e^{-\theta})^{-2} e^{-\theta} $$

$$ = \frac{e^{-\theta}}{(1 + e^{-\theta})^2} = \frac{1}{e^{\theta} (1 + e^{-\theta})^2} = \frac{1}{(1 + e^{\theta})(1 + e^{-\theta})} = (1 - \mu)\mu $$

#### MLE para a Família Exponencial

A verossimilhança de um modelo de família exponencial tem a forma [^6]:

$$ p(\mathcal{D}|\theta) = \left[\prod_{i=1}^N h(x_i)\right] g(\theta)^N \exp\left(\eta(\theta)^T \sum_{i=1}^N \phi(x_i)\right) $$

Vemos que as estatísticas suficientes são $N$ e $\sum_{i=1}^N \phi(x_i)$ [^6].

Para um modelo canônico de família exponencial, dados $N$ pontos de dados i.i.d. $\mathcal{D} = (x_1, ..., x_N)$, a log-verossimilhança é [^6]:

$$ \log p(\mathcal{D}|\theta) = \theta^T \phi(\mathcal{D}) - N A(\theta) $$

Como $-A(\theta)$ é côncava em $\theta$ e $\theta^T \phi(\mathcal{D})$ é linear em $\theta$, vemos que a log-verossimilhança é côncava e, portanto, tem um máximo global único [^6]. Para derivar este máximo, usamos o fato de que a derivada da função de partição logarítmica produz o valor esperado da estatística suficiente (Seção 9.2.3) [^6]:

$$ \nabla_\theta \log p(\mathcal{D}|\theta) = \phi(\mathcal{D}) - N \mathbb{E}[\phi(X)] $$

Definindo este gradiente para zero, vemos que, no MLE, a média empírica das estatísticas suficientes deve ser igual às estatísticas suficientes esperadas teóricas do modelo, ou seja, $\theta$ deve satisfazer [^6]:

$$ \mathbb{E}[\phi(X)] = \frac{1}{N} \sum_{i=1}^N \phi(x_i) $$

Isso é chamado de **correspondência de momentos** [^7].

#### Bayes para a Família Exponencial

A análise Bayesiana exata é consideravelmente simplificada se a *prior* for conjugada à verossimilhança [^7]. Informalmente, isso significa que a *prior* $p(\theta|\tau)$ tem a mesma forma que a verossimilhança $p(\mathcal{D}|\theta)$ [^7]. Para que isso faça sentido, exigimos que a verossimilhança tenha estatísticas suficientes finitas, para que possamos escrever $p(\mathcal{D}|\theta) = p(s(\mathcal{D})|\theta)$ [^7]. Isso sugere que a única família de distribuições para a qual existem *priors* conjugadas é a família exponencial [^7].

A verossimilhança da família exponencial é dada por [^7]:

$$ p(\mathcal{D}|\theta) \propto g(\theta)^N \exp(\eta(\theta)^T s_N) $$

onde $s_N = \sum_{i=1}^N s(x_i)$ [^7]. Em termos dos parâmetros canônicos, isso se torna [^7]:

$$ p(\mathcal{D}|\eta) \propto \exp(N\eta^T \bar{s} - N A(\eta)) $$

onde $\bar{s} = \frac{1}{N} s_N$ [^7].

A *prior* conjugada natural tem a forma [^7]:

$$ p(\theta|\nu_0, \tau_0) \propto g(\theta)^{\nu_0} \exp(\eta(\theta)^T \tau_0) $$

Vamos escrever $\tau_0 = \nu_0 \bar{\tau}_0$, para separar o tamanho dos pseudo-dados *prior*, $\nu_0$, da média das estatísticas suficientes nesses pseudo-dados, $\bar{\tau}_0$ [^7]. Na forma canônica, a *prior* torna-se [^7]:

$$ p(\eta|\nu_0, \bar{\tau}_0) \propto \exp(\nu_0 \eta^T \bar{\tau}_0 - \nu_0 A(\eta)) $$

A *posterior* é dada por [^7]:

$$ p(\theta|\mathcal{D}) = p(\theta|\nu_N, \tau_N) = p(\theta|\nu_0 + N, \tau_0 + s_N) $$

Vemos que apenas atualizamos os hiperparâmetros adicionando [^7]. Na forma canônica, isso se torna [^7]:

$$ p(\eta|\mathcal{D}) \propto \exp(\eta^T (\nu_0 \bar{\tau}_0 + N\bar{s}) - (\nu_0 + N) A(\eta)) $$

$$ = p\left(\eta|\nu_0 + N, \frac{\nu_0 \bar{\tau}_0 + N\bar{s}}{\nu_0 + N}\right) $$

Vemos que os hiperparâmetros *posterior* são uma combinação convexa dos hiperparâmetros médios *prior* e da média das estatísticas suficientes [^7].

### Conclusão

A família exponencial fornece uma estrutura unificada para modelar uma ampla gama de distribuições de probabilidade [^1, 2]. Suas propriedades, como a existência de estatísticas suficientes e *priors* conjugadas, simplificam significativamente a inferência e o aprendizado [^1, 7]. A capacidade de expressar distribuições comuns como a Gaussiana, Bernoulli e Multinoulli dentro da família exponencial permite a aplicação de algoritmos e teoremas gerais, tornando-a uma ferramenta fundamental em *machine learning* e estatística [^1].

### Referências

[^1]: Page 281, Section 9.
[^2]: Page 282, Section 9.2.1.
[^3]: Page 283, Section 9.2.2.2.
[^4]: Page 284, Section 9.2.2.3.
[^5]: Page 285, Section 9.2.
[^6]: Page 286, Section 9.2.4.
[^7]: Page 287, Section 9.2.5.
<!-- END -->