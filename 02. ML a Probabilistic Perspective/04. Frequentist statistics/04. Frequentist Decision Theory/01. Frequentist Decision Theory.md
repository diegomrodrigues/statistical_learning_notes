## Frequentist Decision Theory: Estimadores e Funções de Risco

### Introdução
A teoria da decisão frequentista oferece uma estrutura para tomar decisões sob incerteza, utilizando uma função de perda e uma função de verossimilhança [^6.3]. Diferentemente da abordagem Bayesiana, ela dispensa o uso de uma *prior*, não fornecendo, portanto, um método automático para derivar um estimador ótimo. Isso implica que qualquer estimador ou procedimento de decisão $\delta : X \rightarrow A$ pode ser escolhido livremente [^6.3]. Este capítulo explora essa flexibilidade e as implicações da ausência de uma *prior* na teoria da decisão frequentista.

### Conceitos Fundamentais
Na teoria da decisão frequentista, a escolha de um estimador $\delta$ é fundamental. Dado um conjunto de dados $D$, uma estimativa de parâmetro $\hat{\theta}$ é calculada aplicando o estimador $\delta$ a $D$, tal que $\hat{\theta} = \delta(D)$ [^6.2]. O parâmetro $\theta$ é tratado como fixo, enquanto os dados $D$ são considerados aleatórios, o oposto da abordagem Bayesiana [^6.2].

A avaliação da qualidade de um estimador frequentista é realizada através da sua **função de risco** ou **perda esperada**, definida como:

$$R(\theta^*, \delta) = E_{p(D|\theta^*)} [L(\theta^*, \delta(D))] = \int L(\theta^*, \delta(D))p(D|\theta^*)dD$$

onde:
*   $R(\theta^*, \delta)$ representa o risco do estimador $\delta$ quando o verdadeiro valor do parâmetro é $\theta^*$.
*   $L(\theta^*, \delta(D))$ é a função de perda, que quantifica a penalidade associada a estimar $\theta^*$ como $\delta(D)$.
*   $p(D|\theta^*)$ é a função de verossimilhança, que representa a probabilidade de observar os dados $D$ dado que o verdadeiro valor do parâmetro é $\theta^*$.
*   A integral é calculada sobre todos os possíveis conjuntos de dados $D$ [^6.9].

É crucial notar que a função de risco é calculada em relação à distribuição amostral do estimador, ou seja, considerando todos os possíveis conjuntos de dados que poderiam ser observados sob o verdadeiro valor do parâmetro $\theta^*$ [^6.1].

Em contraste, a abordagem Bayesiana calcula a perda esperada posterior:

$$ρ(α|D, π) = E_{p(θ|D,π)} [L(θ, α)] = \int_{\Theta} L(θ, α)p(θ|D, π)dθ$$

onde a expectativa é tomada em relação à distribuição posterior de $\theta$ dado os dados observados $D$ e a *prior* $\pi$ [^6.10].

A principal diferença entre as duas abordagens reside em como a incerteza é tratada. A abordagem Bayesiana calcula a média sobre $\theta$ (que é desconhecido) e condiciona em $D$ (que é conhecido), enquanto a abordagem frequentista calcula a média sobre $D$ (ignorando os dados observados) e condiciona em $\theta^*$ (que é desconhecido) [^6.10].

Uma consequência importante da definição frequentista é que a função de risco não pode ser computada na prática, pois o verdadeiro valor de $\theta^*$ é desconhecido [^6.10]. Isso impede a comparação direta de diferentes estimadores com base em seus riscos frequentistas.

#### Risco de Bayes
Para contornar a dificuldade de comparar estimadores devido ao desconhecimento de $\theta^*$, uma abordagem é introduzir uma *prior* $p(\theta^*)$ e definir o **risco de Bayes** ou **risco integrado** de um estimador $\delta$ como:

$$R_B(\delta) = E_{p(\theta^*)} [R(\theta^*, \delta)] = \int R(\theta^*, \delta)p(\theta^*)d\theta^*$$

Um **estimador de Bayes** ou **regra de decisão de Bayes** é aquele que minimiza o risco esperado:

$$\delta_B = \underset{\delta}{\operatorname{argmin}} R_B(\delta)$$

O risco integrado também é chamado de **risco pre-posterior**, pois é calculado antes de observar os dados e pode ser útil para o planejamento de experimentos [^6.11].

O Teorema 6.3.1 [^6.12] estabelece uma conexão importante entre as abordagens Bayesiana e frequentista: um estimador de Bayes pode ser obtido minimizando a perda esperada posterior para cada $x$.

#### Risco Minimax
Uma alternativa ao risco de Bayes, que dispensa a necessidade de uma *prior*, é o conceito de **risco minimax**. O **risco máximo** de um estimador $\delta$ é definido como:

$$R_{max}(\delta) = \underset{\theta^*}{\operatorname{max}} R(\theta^*, \delta)$$

Uma **regra minimax** é aquela que minimiza o risco máximo:

$$\delta_{MM} = \underset{\delta}{\operatorname{argmin}} R_{max}(\delta)$$

Em outras palavras, o estimador minimax é aquele que tem o menor risco no pior caso possível.

### Conclusão

A teoria da decisão frequentista, ao evitar o uso de *priors*, oferece flexibilidade na escolha de estimadores, mas enfrenta desafios na comparação e otimização desses estimadores devido à dependência do verdadeiro valor do parâmetro, que é desconhecido. Estratégias como o risco de Bayes e o risco minimax são propostas como alternativas para superar essas limitações, cada uma com suas próprias vantagens e desvantagens. A conexão entre as abordagens Bayesiana e frequentista, conforme estabelecido no Teorema 6.3.1, destaca a importância de considerar ambas as perspectivas na tomada de decisões estatísticas.

### Referências
[^6.1]: Introduction
[^6.2]: Sampling distribution of an estimator
[^6.3]: Frequentist decision theory
[^6.9]: Having chosen an estimator, we define its expected loss or risk as follows:
[^6.10]: We see that the Bayesian approach averages over θ (which is unknown) and conditions on D (which is known), whereas the frequentist approach averages over D (thus ignoring the observed data), and conditions on 0* (which is unknown).
[^6.11]: How do we choose amongst estimators? We need some way to convert R(0*, δ) into a single measure of quality, R(d), which does not depend on knowing 0*. One approach is to put a prior on 0*, and then to define Bayes risk or integrated risk of an estimator as follows:
[^6.12]: Theorem 6.3.1. A Bayes estimator can be obtained by minimizing the posterior expected loss for each x.

<!-- END -->