## Frequentist Decision Theory: Risk, Minimaxity, and Admissibility

### Introdução
Em estatística frequentista, a **teoria da decisão** difere significativamente da abordagem Bayesiana. Enquanto a teoria Bayesiana da decisão utiliza uma *distribuição a priori* para calcular uma perda esperada *a posteriori* e derivar um estimador ótimo, a abordagem frequentista não incorpora um *prior* [^6]. Isso implica que a escolha de um estimador ou procedimento de decisão $\delta: X \rightarrow A$ é arbitrária, necessitando de critérios alternativos para comparar estimadores, como **risco**, **minimaxidade** e **admissibilidade** [^6]. Este capítulo explora esses conceitos fundamentais da teoria da decisão frequentista, contrastando-os com a abordagem Bayesiana, conforme introduzido no Capítulo 5 [^1].

### Conceitos Fundamentais

#### Risco (Expected Loss)
Dado um estimador $\delta$, o **risco** $R(\theta^*, \delta)$ é definido como a perda esperada sob a distribuição amostral induzida pelo verdadeiro parâmetro $\theta^*$, conforme expresso na equação [^9]:
$$\nR(\theta^*, \delta) = E_{p(D|\theta^*)}[L(\theta^*, \delta(D))] = \int L(\theta^*, \delta(D))p(D|\theta^*)dD\n$$
onde $L(\theta^*, \delta(D))$ é a função de perda, e $D$ representa os dados amostrados da distribuição "da natureza", caracterizada pelo parâmetro $\theta^*$. Diferentemente da abordagem Bayesiana, onde a expectativa é tomada em relação à distribuição *a posteriori*, a abordagem frequentista calcula a expectativa em relação à distribuição amostral do estimador, condicionada ao verdadeiro parâmetro $\theta^*$.

A principal limitação do risco frequentista é que ele depende do verdadeiro parâmetro $\theta^*$, que é desconhecido. Isso impede a comparação direta de diferentes estimadores com base em seu risco frequentista [^10].

#### Risco de Bayes (Integrated Risk)
Para contornar a dependência do risco frequentista em relação ao parâmetro desconhecido $\theta^*$, uma abordagem é colocar uma *distribuição a priori* $p(\theta^*)$ sobre $\theta^*$ e definir o **risco de Bayes** ou **risco integrado** de um estimador como [^11]:
$$\nR_B(\delta) = E_{p(\theta^*)}[R(\theta^*, \delta)] = \int R(\theta^*, \delta)p(\theta^*)d\theta^*\n$$
Um **estimador de Bayes** ou **regra de decisão de Bayes** é aquele que minimiza o risco esperado [^12]:
$$\n\delta_B = \underset{\delta}{\text{argmin}} \\ R_B(\delta)\n$$
O risco integrado é também chamado de **risco *preposterior***, uma vez que é calculado antes de observarmos os dados. Minimizar esse risco pode ser útil no planejamento de experimentos [^12].

**Teorema 6.3.1.** Um estimador de Bayes pode ser obtido minimizando a perda esperada *a posteriori* para cada $x$ [^12].

*Prova.*
$$\nR_B(\delta) = \int \sum_x \sum_y L(y, \delta(x))p(x, y|\theta^*)p(\theta^*)d\theta^* = \sum_x \sum_y \int L(y, \delta(x))p(x, y, \theta^*)d\theta^* = \sum_x \sum_y L(y, \delta(x))p(y|x)dy \\ p(x) = \sum_x \rho(\delta(x)|x) \\ p(x)\n$$
Para minimizar a expectativa geral, basta minimizar o termo interno para cada $x$, então a nossa regra de decisão é escolher [^17]:
$$\delta_B(x) = \underset{\alpha \in A}{\text{argmin}} \\ \rho(\alpha|x) \\ \blacksquare$$

**Teorema 6.3.2.** (Wald, 1950). Toda regra de decisão admissível é uma regra de decisão de Bayes com respeito a alguma distribuição *a priori*, possivelmente imprópria [^17].

#### Risco Minimax
Uma alternativa ao risco de Bayes, que não requer a escolha de uma *distribuição a priori*, é o **risco minimax**. O risco máximo de um estimador é definido como [^18]:
$$\nR_{max}(\delta) = \underset{\theta^*}{\text{max}} \\ R(\theta^*, \delta)\n$$
Uma **regra minimax** é aquela que minimiza o risco máximo [^19]:
$$\n\delta_{MM} = \underset{\delta}{\text{argmin}} \\ R_{max}(\delta)\n$$
Estimadores minimax têm um certo apelo, mas são computacionalmente difíceis e excessivamente pessimistas. Em situações estatísticas, pode-se demonstrar que todos os estimadores minimax são equivalentes a estimadores de Bayes sob um *prior* menos favorável [^17].

#### Estimadores Admissíveis
Um estimador $\delta_1$ domina $\delta_2$ se $R(\theta, \delta_1) \leq R(\theta, \delta_2)$ para todo $\theta \in \Theta$, com a desigualdade sendo estrita para algum $\theta$. Um estimador é dito admissível se não for estritamente dominado por nenhum outro estimador [^17].

**Teorema 6.3.3.** Seja $X \sim N(\theta, 1)$ e considere estimar $\theta$ sob perda quadrática. Seja $\delta_1(x) = \theta_0$, uma constante independente dos dados. Este é um estimador admissível [^20].

*Prova.* Suponha que não. Então existe algum outro estimador $\delta_2$ com menor risco, então $R(\theta^*, \delta_2) \leq R(\theta^*, \delta_1)$, onde a desigualdade deve ser estrita para algum $\theta^*$. Suponha que o parâmetro verdadeiro seja $\theta^* = \theta_0$. Então $R(\theta^*, \delta_1) = 0$, e
$$R(\theta^*, \delta_2) = \int(\delta_2(x) - \theta_0)^2p(x|\theta_0)dx$$
Como $0 \leq R(\theta^*, \delta_2) \leq R(\theta^*, \delta_1)$ para todo $\theta^*$, e $R(\theta_0, \delta_1) = 0$, temos $R(\theta_0, \delta_2) = 0$ e então $\delta_2(x) = \theta_0 = \delta_1(x)$. Assim, a única maneira de $\delta_2$ evitar ter um risco maior do que $\delta_1$ em algum ponto específico $\theta_0$ é sendo igual a $\delta_1$. Portanto, não há outro estimador $\delta_2$ com risco estritamente menor, então $\delta_2$ é admissível. $\blacksquare$

### Conclusão

A teoria da decisão frequentista oferece uma estrutura para avaliar e comparar estimadores sem depender de distribuições *a priori*. Os conceitos de **risco**, **minimaxidade** e **admissibilidade** fornecem diferentes perspectivas sobre as propriedades desejáveis de um estimador. Embora a abordagem frequentista apresente desafios, como a necessidade de conhecer o verdadeiro parâmetro para calcular o risco, ela continua sendo uma ferramenta valiosa na estatística, especialmente em situações onde a subjetividade da escolha de um *prior* é indesejável. No entanto, como será discutido no Capítulo 6.6, a estatística frequentista exibe várias formas de comportamentos estranhos e indesejáveis, conhecidos como patologias [^21].

### Referências
[^1]: Seção 6.1
[^6]: Seção 6.3
[^9]: Equação 6.9
[^10]: Seção 6.3
[^11]: Equação 6.11
[^12]: Equação 6.12
[^17]: Seção 6.3.2
[^18]: Equação 6.18
[^19]: Equação 6.19
[^20]: Teorema 6.3.3
[^21]: Seção 6.6

<!-- END -->