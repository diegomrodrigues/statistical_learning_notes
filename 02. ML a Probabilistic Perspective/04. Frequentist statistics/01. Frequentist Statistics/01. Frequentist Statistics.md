## Frequentist Statistics: Uma Abordagem Clássica

### Introdução
Este capítulo explora a **estatística frequentista**, uma abordagem à inferência estatística que evita tratar parâmetros como variáveis aleatórias, em contraste com a abordagem Bayesiana [^6]. A estatística frequentista, também conhecida como estatística clássica ou ortodoxa [^6.1], baseia-se no conceito de **distribuição amostral**, que é a distribuição de um estimador quando aplicado a múltiplos conjuntos de dados amostrados da mesma distribuição verdadeira, mas desconhecida [^6.1]. É essa noção de variação através de tentativas repetidas que forma a base para modelar a incerteza usada pela abordagem frequentista [^6.1].

### Conceitos Fundamentais

Na estatística frequentista, uma **estimativa de parâmetro** $\hat{\theta}$ é computada aplicando um **estimador** $\delta$ a alguns dados $D$, de forma que $\hat{\theta} = \delta(D)$ [^6.2]. O parâmetro é visto como fixo e os dados como aleatórios, o oposto exato da abordagem Bayesiana [^6.2]. A incerteza na estimativa do parâmetro pode ser medida computando a **distribuição amostral do estimador** [^6.2].

Para entender este conceito, imagine amostrar muitos conjuntos de dados diferentes $D^{(s)}$ de algum modelo verdadeiro, $p(\cdot|\theta^*)$, ou seja, deixe $D^{(s)} = \\{x_i\\}_{i=1}^N$, onde $x_i \sim p(\cdot|\theta^*)$, e $\theta^*$ é o parâmetro verdadeiro [^6.2]. Aqui, $s = 1:S$ indexa o conjunto de dados amostrado, e $N$ é o tamanho de cada conjunto de dados [^6.2]. Agora aplique o estimador $\delta(\cdot)$ a cada $D^{(s)}$ para obter um conjunto de estimativas, $\\{\delta(D^{(s)})\\}$ [^6.2]. Quando deixamos $S \rightarrow \infty$, a distribuição induzida em $\delta(\cdot)$ é a **distribuição amostral do estimador** [^6.2].

#### Bootstrap
O **bootstrap** é uma técnica de Monte Carlo simples para aproximar a distribuição amostral [^6.2.1]. Isto é particularmente útil em casos onde o estimador é uma função complexa dos parâmetros verdadeiros [^6.2.1]. A ideia é simples: se conhecêssemos os parâmetros verdadeiros $\theta^*$, poderíamos gerar muitos (digamos $S$) conjuntos de dados falsos, cada um de tamanho $N$, da distribuição verdadeira, $x \sim p(\cdot|\theta^*)$, para $s = 1:S$, $i = 1:N$ [^6.2.1]. Poderíamos então computar nosso estimador de cada amostra, $\hat{\theta}_s = \delta(x_{1:N}^{(s)})$, e usar a distribuição empírica das amostras resultantes como nossa estimativa da distribuição amostral [^6.2.1]. Como $\theta$ é desconhecido, a ideia do **bootstrap paramétrico** é gerar as amostras usando $\hat{\theta}(D)$ em vez disso [^6.2.1]. Uma alternativa, chamada de **bootstrap não paramétrico**, é amostrar o $x_i$ (com reposição) dos dados originais $D$, e então computar a distribuição induzida como antes [^6.2.1].

#### Teoria Assintótica para o MLE
Em alguns casos, a distribuição amostral para alguns estimadores pode ser computada analiticamente [^6.2.2]. Em particular, pode ser mostrado que, sob certas condições, quando o tamanho da amostra tende ao infinito, a distribuição amostral do **Estimador de Máxima Verossimilhança (MLE)** torna-se Gaussiana [^6.2.2]. Informalmente, o requisito para que este resultado se mantenha é que cada parâmetro no modelo chegue a "ver" uma quantidade infinita de dados, e que o modelo seja identificável [^6.2.2].

O centro da Gaussiana será o MLE $\hat{\theta}$ [^6.2.2]. Intuitivamente, a variância do estimador estará (inversamente) relacionada à quantidade de curvatura da superfície de verossimilhança em seu pico [^6.2.2]. Se a curvatura é grande, o pico será "afiado" e a variância baixa; neste caso, a estimativa é "bem determinada" [^6.2.2]. Por outro lado, se a curvatura é pequena, o pico será quase "plano", então a variância é alta [^6.2.2].

Formalizando esta intuição, define-se a **função score** como o gradiente do log-verossimilhança avaliado em algum ponto $\theta$:\n$$\ns(\theta) \triangleq \nabla_\theta \log p(D|\theta)|_{\hat{\theta}} \qquad (6.1)\n$$\nDefine-se a **matriz de informação observada** como o gradiente da função score negativa, ou equivalentemente, o Hessiano do NLL:\n$$\nJ(\hat{\theta}(D)) \triangleq -\nabla s(\theta) = -\nabla_\theta^2 \log p(D|\theta)|_{\hat{\theta}} \qquad (6.2)\n$$\nEm 1D, isto torna-se\n$$\nJ(\hat{\theta}(D)) = -\frac{d^2}{d\theta^2} \log p(D|\theta)|_{\hat{\theta}} \qquad (6.3)\n$$\nIsto é apenas uma medida da curvatura da função log-verossimilhança em $\hat{\theta}$ [^6.2.2].

Como estamos estudando a distribuição amostral, $D = (x_1, ..., x_N)$ é um conjunto de variáveis aleatórias [^6.2.2]. A **matriz de informação de Fisher** é definida como o valor esperado da matriz de informação observada:\n$$\nI_N(\theta|\theta^*) \triangleq \mathbb{E}_{\theta^*} [J(\hat{\theta}|D)] \qquad (6.4)\n$$\nOnde $\mathbb{E}_{\theta^*} [f(D)] \triangleq \frac{1}{N} \sum_{i=1}^N f(x_i)p(x_i|\theta^*)$ é o valor esperado da função $f$ quando aplicada a dados amostrados de $\theta^*$ [^6.2.2]. Frequentemente, $\theta^*$, representando o "parâmetro verdadeiro" que gerou os dados, é assumido como conhecido, então apenas escrevemos $I_N(\theta) \triangleq I_N(\theta|\theta^*)$ para abreviar [^6.2.2]. Além disso, é fácil ver que $I_N(\hat{\theta}) = NI_1(\hat{\theta})$, porque o log-verossimilhança para uma amostra de tamanho $N$ é apenas $N$ vezes "mais íngreme" que o log-verossimilhança para uma amostra de tamanho 1 [^6.2.2]. Então podemos descartar o subscrito 1 e apenas escrever $I(\hat{\theta}) \triangleq I_1(\hat{\theta})$ [^6.2.2]. Esta é a notação que é usualmente usada [^6.2.2].

Agora, deixe $\hat{\theta}_{MLE}(D)$ ser o MLE, onde $D \sim \theta^*$ [^6.2.2]. Pode ser mostrado que\n$$\n\theta \rightarrow N(\theta^*, I_N(\theta^*)^{-1}) \qquad (6.5)\n$$\nquando $N \rightarrow \infty$ (ver, por exemplo, (Rice 1995, p265) para uma prova) [^6.2.2]. Dizemos que a distribuição amostral do MLE é *assintoticamente normal* [^6.2.2].

E quanto à variância do MLE, que pode ser usada como alguma medida de confiança no MLE? Infelizmente, $\theta^*$ é desconhecido, então não podemos avaliar a variância da distribuição amostral [^6.2.2]. No entanto, podemos aproximar a distribuição amostral substituindo $\theta^*$ por $\hat{\theta}$ [^6.2.2]. Consequentemente, os **erros padrão aproximados** de $\theta_k$ são dados por\n$$\nse_k \approx \sqrt{I_N(\hat{\theta})_{kk}^{-1}} \qquad (6.6)\n$$\n

### Conclusão
Este capítulo forneceu uma visão geral da estatística frequentista, contrastando-a com a abordagem Bayesiana. Exploramos o conceito fundamental de distribuição amostral, métodos para aproximá-la, como o bootstrap, e a teoria assintótica do MLE. A compreensão desses conceitos é crucial para a aplicação e interpretação de métodos estatísticos em diversas áreas, incluindo machine learning.

### Referências
[^6]: Frequentist statistics, also known as classical or orthodox statistics, is an approach to statistical inference that avoids treating parameters as random variables, differing from the Bayesian approach which uses priors and Bayes\' rule.
[^6.1]: It relies on the concept of a sampling distribution, which is the distribution of an estimator when applied to multiple datasets sampled from the same true but unknown distribution, thus forming the basis for modeling uncertainty based on variation across repeated trials.
[^6.2]: In frequentist statistics, a parameter estimate o is computed by applying an estimator 8 to some data D, so e = d(D). The parameter is viewed as fixed and the data as random, which is the exact opposite of the Bayesian approach. The uncertainty in the parameter estimate can be measured by computing the sampling distribution of the estimator.
[^6.2.1]: The bootstrap is a simple Monte Carlo technique to approximate the sampling distribution. This is particularly useful in cases where the estimator is a complex function of the true parameters.
[^6.2.2]: In some cases, the sampling distribution for some estimators can be computed analytically. In particular, it can be shown that, under certain conditions, as the sample size tends to infinity, the sampling distribution of the MLE becomes Gaussian.

<!-- END -->