## Empirical Risk Minimization and Overfitting

### Introdução
Este capítulo explora o conceito de **Empirical Risk Minimization (ERM)** dentro do contexto mais amplo de propriedades desejáveis de estimadores. O objetivo do ERM é encontrar um procedimento de decisão que minimize o risco empírico, que é a perda média sobre os dados de treinamento [^650]. No entanto, essa abordagem pode levar ao *overfitting*, um problema crucial em machine learning que será detalhado.

### Conceitos Fundamentais

O ERM surge da teoria da decisão frequentista, que busca uma função de perda e uma verossimilhança, mas não utiliza um *prior* [^63]. Assim, não há uma maneira automática de derivar um estimador ótimo, diferentemente da abordagem Bayesiana. Em vez disso, na abordagem frequentista, somos livres para escolher qualquer estimador ou procedimento de decisão $\delta: \mathcal{X} \rightarrow \mathcal{A}$ que desejarmos [^63].

A ideia central do ERM é substituir a verdadeira distribuição de dados, $p^*$, pela distribuição empírica, $p_{emp}$, derivada dos dados de treinamento [^647]. Assim, o risco frequentista, que é definido como:

$$R(p^*, \delta) = \mathbb{E}_{(x,y) \sim p^*}[L(y, \delta(x))] = \sum_x \sum_y L(y, \delta(x)) p^*(x, y)$$

é aproximado pelo risco empírico:

$$R_{emp}(\mathcal{D}, \delta) = \frac{1}{N} \sum_{i=1}^N L(y_i, \delta(x_i))$$

onde $L(y, \delta(x))$ é a função de perda, $y$ é a resposta verdadeira (mas desconhecida), $\delta(x)$ é a predição do modelo para a entrada $x$ e $\mathcal{D}$ representa os dados de treinamento [^649]. O objetivo do ERM é encontrar o $\delta$ que minimiza o risco empírico:

$$hat{\delta}_{ERM}(\mathcal{D}) = \underset{\delta}{\text{argmin}} \\ R_{emp}(\mathcal{D}, \delta)$$

No entanto, minimizar diretamente o risco empírico pode levar ao *overfitting* [^652]. Isso ocorre porque o risco empírico é igual ao risco de Bayes se o *prior* sobre a distribuição da natureza for exatamente igual à distribuição empírica [^652]. Em outras palavras, o modelo se ajusta tão bem aos dados de treinamento que perde a capacidade de generalizar para novos dados.

Para mitigar o problema de *overfitting*, uma técnica comum é adicionar uma penalidade de complexidade à função objetivo, resultando no **Regularized Risk Minimization (RRM)** [^653]:

$$R\'(\mathcal{D}, \delta) = R_{emp}(\mathcal{D}, \delta) + \lambda C(\delta)$$

onde $C(\delta)$ mede a complexidade da função de predição $\delta(x)$ e $\lambda$ controla a força da penalidade de complexidade [^653]. Se a função de perda for a log-verossimilhança negativa e o regularizador for um *prior* logarítmico negativo, o RRM é equivalente à estimativa MAP [^653].

As duas questões principais no RRM são: como medimos a complexidade e como escolhemos $\lambda$ [^653]? Para modelos lineares, podemos definir a complexidade em termos de seus graus de liberdade [^653]. Para modelos mais gerais, podemos usar a dimensão VC [^653]. Para escolher $\lambda$, podemos usar métodos como validação cruzada [^653].

### Conclusão

O Empirical Risk Minimization (ERM) é uma abordagem fundamental para encontrar procedimentos de decisão que minimizem a perda nos dados de treinamento [^650]. No entanto, a minimização direta do risco empírico pode levar ao *overfitting*, onde o modelo se ajusta muito bem aos dados de treinamento, mas não generaliza bem para novos dados [^652]. Para mitigar esse problema, o Regularized Risk Minimization (RRM) adiciona uma penalidade de complexidade à função objetivo, incentivando modelos mais simples que generalizam melhor [^653].

### Referências
[^63]: Frequentist decision theory, In frequentist or classical decision theory, there is a loss function and a likelihood, but there is no prior and hence no posterior or posterior expected loss.
[^647]: R(p*, δ) = E(x,y)~p∗ [L(y, δ(x)] = ∑∑L(y, δ(x))p*(x, y) where p∗ represents “nature\'s distribution”.
[^649]: Remp(D,D) R(pemp, 8) = 1/N ΣL(Yi, δ(xi))
[^650]: Empirical risk minimization (ERM) is the task of finding a decision procedure to minimize the empirical risk.
[^652]: Note that the empirical risk is equal to the Bayes risk if our prior about “nature\'s distribution" is that it is exactly equal to the empirical distribution (Minka 2001b): E [R(p*, δ)|p* = Pemp] = Remp(D, δ) Therefore minimizing the empirical risk will typically result in overfitting.
[^653]: R\'(D, d) = Remp(D, δ) + AC(δ) where C(8) measures the complexity of the prediction function δ(x) and A controls the strength of the complexity penalty.
<!-- END -->