## O Trade-off Viés-Variância
### Introdução
Em estatística frequentista, a escolha de um estimador envolve a consideração de diversas propriedades desejáveis [^6.4]. No entanto, muitas vezes, não é possível otimizar todas essas propriedades simultaneamente, levando a *trade-offs* importantes. Um dos *trade-offs* mais fundamentais é o *trade-off* viés-variância, que surge ao tentar minimizar o erro quadrático médio (MSE) de um estimador [^6.4.4]. Este capítulo explora em detalhes este *trade-off*, demonstrando como a redução do viés pode aumentar a variância, e vice-versa, e como encontrar um equilíbrio adequado para minimizar o MSE.

### Conceitos Fundamentais
O **erro quadrático médio (MSE)** é uma métrica comum para avaliar a qualidade de um estimador. Ele mede a média do quadrado da diferença entre o estimador e o valor real do parâmetro que se deseja estimar. Matematicamente, o MSE é definido como:

$$ MSE(\hat{\theta}) = E[(\hat{\theta} - \theta^*)^2] $$

onde $\hat{\theta}$ é o estimador, $\theta^*$ é o valor verdadeiro do parâmetro e $E[\cdot]$ denota o valor esperado [^6.4.4].

O *trade-off* viés-variância surge da decomposição do MSE em duas componentes: o **viés** (bias) e a **variância**. O viés mede a diferença entre o valor esperado do estimador e o valor verdadeiro do parâmetro [^6.4.2]:

$$ bias(\hat{\theta}) = E[\hat{\theta}] - \theta^* $$

A variância, por outro lado, mede a dispersão do estimador em torno de seu valor esperado:

$$ var(\hat{\theta}) = E[(\hat{\theta} - E[\hat{\theta}])^2] $$

Como demonstrado em [^6.4.4], o MSE pode ser decomposto da seguinte forma:

$$ E[(\hat{\theta} - \theta^*)^2] = E[(\hat{\theta} - E[\hat{\theta}])^2] + (E[\hat{\theta}] - \theta^*)^2 $$

$$ MSE(\hat{\theta}) = var[\hat{\theta}] + bias^2(\hat{\theta}) $$

Essa decomposição revela que o MSE é a soma da variância do estimador e do quadrado do seu viés [^6.4.4]. Isso implica que minimizar o MSE requer um equilíbrio entre essas duas componentes.

**Em outras palavras**:

> O *trade-off* viés-variância ilustra que o erro quadrático médio (MSE) pode ser decomposto em variância mais viés ao quadrado, MSE = variância + viés², indicando que pode ser sensato usar um estimador viesado se ele reduzir a variância o suficiente para minimizar o erro quadrático [^Contexto].

**Estimadores Viesados:** Um estimador é considerado **viesado** se seu valor esperado não coincide com o valor verdadeiro do parâmetro. Embora possa parecer contra-intuitivo, o uso de estimadores viesados pode ser benéfico em certas situações. A ideia central é que, ao introduzir um viés controlado, podemos reduzir significativamente a variância do estimador, resultando em um MSE menor.

**Exemplo:** Estimando a média de uma Gaussiana [^6.4.4.1]

Considere o problema de estimar a média $\theta^*$ de uma distribuição Gaussiana com variância $\sigma^2$ conhecida. O estimador de máxima verossimilhança (MLE) para a média é a média amostral $\bar{x}$, que é não viesada e tem variância $\sigma^2/N$ [^6.4.4.1].

No entanto, podemos usar um estimador *a posteriori* (MAP) sob uma *prior* Gaussiana da forma $N(\theta_0, \sigma^2/\kappa_0)$ [^6.4.4.1]. O estimador MAP é dado por:

$$ \hat{\theta} = \frac{N}{N + \kappa_0}\bar{x} + \frac{\kappa_0}{N + \kappa_0}\theta_0 = w\bar{x} + (1 - w)\theta_0 $$

onde $w = \frac{N}{N + \kappa_0}$ controla o peso dado à média amostral e à *prior*. Este estimador é viesado, com viés dado por:

$$ E[\hat{\theta}] - \theta^* = (1 - w)(\theta_0 - \theta^*) $$

e variância:

$$ var[\hat{\theta}] = w^2\frac{\sigma^2}{N} $$

Observa-se que, ao aumentar $\kappa_0$ (ou seja, ao fortalecer a *prior*), o viés aumenta, mas a variância diminui [^6.4.4.1]. O *trade-off* viés-variância reside na escolha do valor de $\kappa_0$ que minimiza o MSE.

### Conclusão
O *trade-off* viés-variância é um conceito fundamental na teoria da estimação. Ele destaca a importância de equilibrar o viés e a variância ao escolher um estimador. Em muitos casos, o uso de estimadores viesados pode levar a um menor erro quadrático médio, especialmente quando a variância é significativamente reduzida. A escolha do estimador ideal depende do contexto específico do problema e da importância relativa do viés e da variância. Técnicas como regularização [^6.4.4.2] e *shrinkage* [^6.3.3.2] são frequentemente utilizadas para controlar o *trade-off* viés-variância e melhorar o desempenho dos estimadores.
### Referências
[^6.4]: Desirable properties of estimators
[^6.4.4]: The bias-variance tradeoff
[^6.4.2]: Unbiased estimators
[^6.4.4.1]: Example: estimating a Gaussian mean
[^6.3.3.2]: Stein's paradox *
[^6.4.4.2]: Example: ridge regression
[^Context]: Trecho do contexto fornecido

<!-- END -->