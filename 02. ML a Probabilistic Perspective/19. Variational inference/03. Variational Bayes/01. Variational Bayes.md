## Variational Bayes (VB)

### Introdução
Este capítulo dedica-se ao estudo detalhado do Variational Bayes (VB), um método de inferência aproximada utilizado quando os parâmetros do modelo são desconhecidos. Como mencionado anteriormente, a inferência exata em modelos gráficos é frequentemente impraticável devido à sua complexidade computacional [^2]. Variational Bayes surge como uma alternativa, oferecendo uma aproximação determinística para a inferência, que busca um equilíbrio entre a precisão e a velocidade [^1]. Este capítulo irá explorar os fundamentos teóricos do VB e suas aplicações, aprofundando-se em detalhes técnicos e matemáticos.

### Conceitos Fundamentais
O Variational Bayes (VB) é uma técnica de inferência aproximada que busca encontrar uma distribuição *q(θ)* que se aproxima da distribuição *a posteriori* verdadeira, mas intratável, *p(θ|D)*, onde *θ* representa os parâmetros do modelo e *D* os dados observados [^1, 2]. A ideia central do VB reside na otimização de uma função objetivo que mede a similaridade entre *q(θ)* e *p(θ|D)*.

A aproximação VB se baseia em duas premissas principais [^12]:
1. **Aproximação Fatorial:** Assume-se que a distribuição *a posteriori* pode ser fatorada em um produto de distribuições marginais:
   $$p(\theta|D) \approx \prod_k q(\theta_k)$$
   Essa fatoração simplifica significativamente o problema de inferência, permitindo que cada fator *q(θk)* seja otimizado independentemente.

2. **Otimização da Divergência KL:** A similaridade entre *q(θ)* e *p(θ|D)* é medida pela divergência de Kullback-Leibler (KL), que quantifica a diferença entre duas distribuições de probabilidade [^2]:
   $$KL(q||p) = \sum_x q(x) \log \frac{q(x)}{p(x)}$$
   O objetivo do VB é minimizar a divergência KL entre *q(θ)* e *p(θ|D)*, buscando a distribuição *q(θ)* que melhor se aproxima da verdadeira *a posteriori*.

No contexto do Variational Bayes, a distribuição *p*(x) é a distribuição verdadeira, mas intratável, e *q*(x) é uma aproximação escolhida de uma família tratável, como uma Gaussiana multivariada ou uma distribuição fatorada [^2]. A escolha da família tratável para *q*(x) é crucial, pois ela determina a complexidade computacional do problema de otimização [^2]. O objetivo é otimizar os parâmetros livres de *q*(x) para que ela seja "similar" a *p*(x) [^2].

A função de custo óbvia a ser minimizada é a divergência KL:
$$KL(p^*||q) = \sum_x p^*(x) \log \frac{p^*(x)}{q(x)}$$ [^2]
No entanto, essa abordagem é difícil de computar, pois calcular a esperança em relação a *p**(x)* é considerado intratável [^2]. Uma alternativa natural é a divergência KL reversa:
$$KL(q||p^*) = \sum_x q(x) \log \frac{q(x)}{p^*(x)}$$ [^2]
A principal vantagem dessa abordagem é que computar a esperança em relação a *q*(x) é tratável, escolhendo uma forma adequada para *q* [^2].

Infelizmente, a Equação 21.2 ainda é intratável, pois mesmo avaliar *p**(x) = p(x|D)* pontualmente é difícil, pois requer avaliar a constante de normalização intratável *Z = p(D)* [^2]. No entanto, usualmente a distribuição não normalizada *p̃(x) = p(x, D) = p**(x)Z* é tratável para computar [^2]. Portanto, definimos uma nova função objetivo como segue:
$$J(q) \triangleq KL(q||p)$$ [^2]
onde estamos ligeiramente abusando da notação, já que *p* não é uma distribuição normalizada [^2]. Substituindo a definição de KL, obtemos
$$J(q) = \sum_x q(x) \log \frac{q(x)}{p(x)} = \sum_x q(x) \log \frac{q(x)}{Zp^*(x)} = \sum_x q(x) \log \frac{q(x)}{p^*(x)} - \log Z = KL(q||p^*) - \log Z$$ [^2]
Como *Z* é uma constante, ao minimizar *J(q)*, forçaremos *q* a se tornar próxima de *p*** [^2]. Como a divergência KL é sempre não negativa, vemos que *J(q)* é um limite superior para o NLL (log-verossimilhança negativa):
$$J(q) = KL(q||p^*) - \log Z \ge - \log Z = - \log p(D)$$ [^2]
Alternativamente, podemos tentar maximizar a seguinte quantidade (em (Koller and Friedman 2009), isso é referido como o funcional de energia), que é um limite inferior para o log da verossimilhança dos dados:
$$L(q) \triangleq -J(q) = -KL(q||p^*) + \log Z \le \log Z = \log p(D)$$ [^2]
Como esse limite é justo quando *q = p***, vemos que a inferência variacional está intimamente relacionada ao EM (ver Seção 11.4.7) [^2].

Variational Bayes (VB) é um método usado quando os parâmetros do modelo são desconhecidos. Aplica-se uma aproximação totalmente fatorada $p(θ|D) ≈ ∏_k q(θ_k)$ para inferir os próprios parâmetros e também é conhecido como ensemble learning. Resulta em um método onde computamos uma distribuição posterior sobre os parâmetros em vez de estimativas pontuais. A posterior variacional é determinada pela forma da verossimilhança e da prior e a forma ótima é obtida olhando para o log-conjunto de dados completo, ignorando termos que não envolvem *z* e tomando expectativas do que sobrou em relação a todas as variáveis ocultas, exceto para *z*.

### Conclusão
O Variational Bayes (VB) oferece uma abordagem poderosa e flexível para a inferência aproximada em modelos estatísticos complexos. Ao contrário dos métodos de estimação pontual, o VB fornece uma distribuição *a posteriori* sobre os parâmetros do modelo, permitindo a quantificação da incerteza e a tomada de decisões mais robustas. Este capítulo explorou os fundamentos teóricos do VB, suas vantagens e desvantagens, e suas aplicações em diversos contextos. O VB continua a ser uma área de pesquisa ativa, com o desenvolvimento de novas técnicas e algoritmos que visam melhorar a precisão e a eficiência da inferência variacional.
### Referências
[^1]: Variational inference. *Pattern Recognition and Machine Learning*, C. Bishop, 2006.
[^2]: Chapter 21. Variational inference
<!-- END -->