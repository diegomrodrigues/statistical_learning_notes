## Aplicações da Aproximação Variacional Local na Regressão Logística Variacional

### Introdução
Este capítulo explora uma aplicação específica dos **limites variacionais locais** (local variational bounds) na regressão logística variacional [^756]. Como mencionado anteriormente, a inferência variacional é uma técnica poderosa para aproximar distribuições posteriores complexas [^731]. Em muitos modelos, a função de verossimilhança não é conjugada com a *prior* (distribuição a priori), tornando a computação da posterior exata intratável [^731]. A regressão logística variacional é um exemplo onde a verossimilhança logística não é conjugada com a *prior* gaussiana, exigindo abordagens aproximadas [^756].

### Conceitos Fundamentais
Na regressão logística, o objetivo é modelar a probabilidade de uma variável categórica (ou binária) em função de um conjunto de *features* (variáveis preditoras). A função de verossimilhança, dada por:

$$
p(y|X, w) = \prod_{i=1}^{N} \exp[y_i \eta_i - lse(\eta_i)]
$$

onde $\eta_i = X_i w$ e $lse(\eta_i)$ é a função *log-sum-exp* (lse) [^757], definida como:

$$
lse(\eta) = \log \left(1 + \sum_{m=1}^{M} e^{\eta_m} \right)
$$

A dificuldade surge porque a função *lse* não é conjugada com uma *prior* gaussiana sobre os pesos $w$ [^757]. Para contornar essa dificuldade, utilizamos *limites variacionais locais* para aproximar a função de verossimilhança por uma função mais tratável, tipicamente uma gaussiana [^756].

Uma abordagem comum é utilizar o limite quadrático de Bohning para a função *log-sum-exp* [^758]:

$$
lse(\eta) \leq \frac{1}{2} \eta^T A_i \eta - b_i^T \eta + c_i
$$

onde $A_i$, $b_i$ e $c_i$ são definidos em termos de um parâmetro variacional $\psi_i$ [^758]. Este limite transforma a verossimilhança original em uma forma "gaussiana", permitindo a computação aproximada da posterior gaussiana [^756]. O uso desse limite leva a um modelo de observação "gaussianizado":

$$
p(y_i | x_i, w) \geq f(x_i, \psi_i) \mathcal{N}(\tilde{y}_i | X_i w, A_i^{-1})
$$

onde $\tilde{y}_i = A_i^{-1}(b_i + y_i)$ é uma pseudo-medição [^758].

O objetivo da inferência variacional é então maximizar um limite inferior na *log-verossimilhança marginal* (log marginal likelihood) [^759]:

$$
\mathcal{L}(q) = \mathbb{E}_q[\log p(w|D)] + \mathbb{E}_q \left[ \sum_{i=1}^{N} \log p(y_i | x_i, w) \right]
$$

onde $q(w)$ é uma aproximação gaussiana da posterior $p(w|D)$ [^759].  Este processo envolve otimizar os parâmetros da aproximação gaussiana $q(w)$ (média $m_N$ e covariância $V_N$) e os parâmetros variacionais $\psi_i$ [^759].  O algoritmo itera entre atualizar a posterior aproximada e os parâmetros variacionais até a convergência [^759].

### Conclusão
A aplicação de *limites variacionais locais* na regressão logística variacional permite aproximar a distribuição posterior dos parâmetros do modelo, mesmo quando a verossimilhança não é conjugada com a *prior*. Ao derivar limites inferiores "gaussianos" para a função *log-sum-exp*, podemos transformar o problema de inferência em um problema mais tratável, resultando em aproximações gaussianas para a posterior [^756]. Essa técnica é particularmente útil em aplicações como regressão logística multiclasse e *multi-task learning*, onde a modelagem precisa da incerteza dos parâmetros é crucial [^757].
<!-- END -->

### Referências
[^731]: 21.1 Introduction
[^756]: 21.8 Local variational bounds *
[^757]: 21.8.1.1 Variational logistic regression
[^758]: 21.8.2 Bohning\'s quadratic bound to the log-sum-exp function
[^759]: 21.8.2.1 Applying Bohning\'s bound to multinomial logistic regression
<!-- END -->