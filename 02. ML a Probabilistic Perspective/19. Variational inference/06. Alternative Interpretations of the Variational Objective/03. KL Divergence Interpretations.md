## Forward e Reverse KL Divergence na Inferência Variacional

### Introdução
No contexto da inferência variacional, o objetivo é aproximar uma distribuição posterior $p^*(x)$ que é intratável por uma distribuição $q(x)$ de uma família tratável [^732]. A escolha da divergência de Kullback-Leibler (KL) como função de custo tem um impacto significativo nas propriedades da aproximação resultante [^732]. Como a divergência KL não é simétrica, minimizar $KL(p^*||q)$ leva a um comportamento diferente de minimizar $KL(q||p)$ [^733]. Este capítulo explora as implicações de usar a divergência KL *forward* e *reverse* no contexto da inferência variacional, com foco em suas tendências a superestimar ou subestimar o suporte da distribuição verdadeira [^733].

### Conceitos Fundamentais

#### Forward KL Divergence (M-Projection)
A divergência KL *forward*, denotada como $KL(p||q)$, também é conhecida como **M-projection** ou **moment projection** [^733]. O objetivo é minimizar a divergência de $p$ para $q$, ou seja, encontrar uma distribuição $q$ que seja o mais próxima possível de $p$ no sentido da divergência KL *forward* [^733]. Matematicamente, é expressa como:

$$KL(p||q) = \sum_x p(x) \ln \frac{p(x)}{q(x)}$$

Uma propriedade fundamental da M-projection é sua tendência a **superestimar o suporte da distribuição verdadeira** $p$ [^733]. Isso significa que $q(x) > 0$ sempre que $p(x) > 0$ [^733]. Em outras palavras, a M-projection garante que a distribuição aproximada $q$ atribua probabilidade positiva a todas as regiões onde a distribuição verdadeira $p$ tem probabilidade positiva [^733]. Isso a torna *zero avoiding* para $q$ [^733].

A razão para essa tendência é que a divergência KL *forward* penaliza fortemente os casos em que $q(x)$ é zero enquanto $p(x)$ é positivo. Para evitar essa penalidade, a distribuição aproximada $q$ tende a cobrir todo o suporte de $p$, mesmo que isso signifique atribuir probabilidade a regiões onde $p$ tem baixa probabilidade [^733].

#### Reverse KL Divergence (I-Projection)
A divergência KL *reverse*, denotada como $KL(q||p)$, também é conhecida como **I-projection** ou **information projection** [^733]. O objetivo é minimizar a divergência de $q$ para $p$, ou seja, encontrar uma distribuição $q$ que seja o mais próxima possível de $p$ no sentido da divergência KL *reverse* [^733]. Matematicamente, é expressa como:

$$KL(q||p) = \sum_x q(x) \ln \frac{q(x)}{p(x)}$$

Ao contrário da M-projection, a I-projection tende a **subestimar o suporte da distribuição verdadeira** $p$ [^733]. Isso significa que $q(x) = 0$ sempre que $p(x) = 0$ [^733]. Em outras palavras, a I-projection força a distribuição aproximada $q$ a ser zero onde a distribuição verdadeira $p$ é zero [^733]. Isso a torna *zero forcing* para $q$ [^733].

A razão para essa tendência é que a divergência KL *reverse* penaliza fortemente os casos em que $p(x)$ é zero enquanto $q(x)$ é positivo. Para evitar essa penalidade, a distribuição aproximada $q$ tende a se concentrar nas regiões onde $p$ tem alta probabilidade, negligenciando as regiões onde $p$ tem baixa probabilidade [^733].

#### Comparação e Implicações
A escolha entre M-projection e I-projection depende das características da distribuição verdadeira $p$ e dos objetivos da inferência [^733].

*   **M-Projection:** É preferível quando é crucial cobrir todo o suporte de $p$, mesmo que isso signifique superestimar a probabilidade em algumas regiões. É útil quando se deseja evitar a omissão de regiões importantes do espaço de dados [^733].
*   **I-Projection:** É preferível quando é importante concentrar-se nas regiões de alta probabilidade de $p$ e evitar a atribuição de probabilidade a regiões onde $p$ é zero. É útil quando se deseja obter uma aproximação mais precisa da forma da distribuição verdadeira nas regiões de maior interesse [^733].

Quando a distribuição verdadeira é multimodal e a distribuição aproximada é unimodal, a M-projection pode levar a resultados ruins, pois a distribuição aproximada tende a se posicionar entre os picos da distribuição verdadeira, em uma região de baixa densidade [^733]. Nesses casos, a I-projection pode ser mais adequada, pois tende a se concentrar em um dos picos da distribuição verdadeira [^733].

### Conclusão
A escolha entre divergência KL *forward* (M-projection) e *reverse* (I-projection) na inferência variacional tem um impacto significativo nas propriedades da aproximação resultante [^733]. A M-projection tende a superestimar o suporte da distribuição verdadeira, enquanto a I-projection tende a subestimá-lo [^733]. A escolha da divergência KL mais apropriada depende das características da distribuição verdadeira e dos objetivos da inferência [^733].

### Referências
[^732]: Capítulo 21, Seção 21.2
[^733]: Capítulo 21, Seção 21.2.2

<!-- END -->