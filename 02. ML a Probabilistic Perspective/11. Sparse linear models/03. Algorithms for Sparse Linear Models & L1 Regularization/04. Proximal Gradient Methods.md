## Proximal Gradient Methods for Sparse Linear Models

### Introdução
Este capítulo explora métodos para otimizar modelos lineares esparsos, um tópico introduzido na Seção 3.5.4 [^1]. Métodos de gradiente proximal são adequados para problemas de larga escala e são baseados no uso do operador proximal dentro de uma rotina de descida de gradiente. O presente capítulo se concentra nos detalhes e aplicações dos métodos de gradiente proximal, com ênfase em sua relevância para modelos esparsos com regularização L1.

### Conceitos Fundamentais

**Métodos de Gradiente Proximal** são uma classe de algoritmos de otimização que estendem o método de descida de gradiente tradicional para problemas onde a função objetivo é a soma de duas funções: uma função convexa diferenciável $L(\theta)$ e uma função convexa (possivelmente não diferenciável) $R(\theta)$ [^13.66]. O objetivo é minimizar:

$$ f(\theta) = L(\theta) + R(\theta) $$

onde $L(\theta)$ representa a perda (loss) e $R(\theta)$ a regularização.

**Operador Proximal:** O operador proximal de uma função convexa $R$ é definido como [^13.68]:

$$ \text{prox}_R(y) = \underset{z}{\text{argmin}} \left\{ R(z) + \frac{1}{2} ||z - y||^2 \right\} $$

Intuitivamente, o operador proximal retorna um ponto $z$ que minimiza $R$, mas também permanece próximo a $y$. Em métodos iterativos, $y$ geralmente representa a iteração anterior, e o operador proximal garante que a nova iteração não se afaste muito da anterior.

**Interpretação:** O operador proximal busca um ponto que minimize a função de regularização $R(z)$ enquanto permanece "próximo" ao ponto $y$. A proximidade é medida pela norma Euclidiana.

**Algoritmo Básico:** O algoritmo de gradiente proximal itera da seguinte forma [^13.77]:

$$ \theta_{k+1} = \underset{z}{\text{argmin}} \left\{ R(z) + L(\theta_k) + \nabla L(\theta_k)^T (z - \theta_k) + \frac{1}{2t_k} ||z - \theta_k||^2 \right\} $$

onde $t_k$ é o tamanho do passo (step size). Essa atualização pode ser reescrita usando o operador proximal como:

$$ \theta_{k+1} = \text{prox}_{t_k R} (\theta_k - t_k \nabla L(\theta_k)) $$

Aqui, $\theta_k - t_k \nabla L(\theta_k)$ representa um passo de descida de gradiente na função $L$, e $\text{prox}_{t_k R}$ ajusta esse passo para levar em consideração a regularização $R$.

**Escolha do Tamanho do Passo:** A escolha do tamanho do passo $t_k$ é crucial para a convergência do algoritmo. Uma abordagem comum é usar uma busca linear (line search) para encontrar um $t_k$ que garanta uma diminuição suficiente na função objetivo. Alternativamente, pode-se usar um tamanho de passo fixo, desde que seja suficientemente pequeno para garantir a convergência. Uma estratégia de escolha para $t_k$, é o método de Barzilai-Borwein (BB) ou *spectral stepsize* [^13.82].

**Exemplos de Operadores Proximais:**

*   **Regularização L1 ($R(\theta) = \lambda ||\theta||_1$):** O operador proximal é dado por [^13.70]:
    $$     \text{prox}_R(\theta) = \text{soft}(\theta, \lambda)     $$
    onde $\text{soft}(\theta, \lambda)$ é o operador de *soft thresholding*, definido como:
    $$     \text{soft}(\theta_j, \lambda) =     \begin{cases}     \theta_j - \lambda & \text{se } \theta_j > \lambda \\     0 & \text{se } |\theta_j| \leq \lambda \\     \theta_j + \lambda & \text{se } \theta_j < -\lambda     \end{cases}     $$
    O *soft thresholding* leva a soluções esparsas, pois zera os coeficientes menores que $\lambda$.

*   **Regularização L0 ($R(\theta) = \lambda ||\theta||_0$):** O operador proximal é dado por [^13.71]:
    $$     \text{prox}_R(\theta) = \text{hard}(\theta, \sqrt{2\lambda})     $$
    onde $\text{hard}(\theta, \sqrt{2\lambda})$ é o operador de *hard thresholding*, definido como:
    $$     \text{hard}(\theta_j, \sqrt{2\lambda}) =     \begin{cases}     \theta_j & \text{se } |\theta_j| > \sqrt{2\lambda} \\     0 & \text{se } |\theta_j| \leq \sqrt{2\lambda}     \end{cases}     $$

*   **Restrição em um Conjunto Convexo ($R(\theta) = I_C(\theta)$):** O operador proximal é a projeção no conjunto $C$ [^13.72]:
    $$     \text{prox}_R(\theta) = \text{proj}_C(\theta) = \underset{z \in C}{\text{argmin}} ||z - \theta||^2     $$

**Método de Nesterov:** Uma versão acelerada do método de gradiente proximal é o método de Nesterov, que pode ser obtido expandindo a aproximação quadrática em torno de um ponto diferente do valor do parâmetro mais recente. As atualizações são dadas por [^13.83, 13.84, 13.85]:

$$ \theta_{k+1} = \text{prox}_{t_k R} (\phi_k - t_k \nabla L(\phi_k)) $$

$$ \phi_k = \theta_k + \frac{k-1}{k+2} (\theta_k - \theta_{k-1}) $$

onde $\phi_k$ é um ponto de extrapolação.

### Conclusão
Os métodos de gradiente proximal oferecem uma abordagem flexível e eficiente para otimizar modelos lineares esparsos, especialmente em problemas de larga escala. Sua capacidade de lidar com funções de regularização não diferenciáveis, como a norma L1, os torna particularmente adequados para induzir esparsidade. As variações aceleradas, como o método de Nesterov, podem melhorar ainda mais a velocidade de convergência. A escolha do operador proximal e do tamanho do passo são fatores críticos para o desempenho do algoritmo, e várias estratégias podem ser empregadas para otimizar esses aspectos.

### Referências
[^1]: Capítulo 13: Sparse linear models
[^13.66]: Vandenberghe, 2011; Yang et al. 2010
[^13.68]: Vandenberghe, 2011; Yang et al. 2010
[^13.70]: Vandenberghe, 2011; Yang et al. 2010
[^13.71]: Vandenberghe, 2011; Yang et al. 2010
[^13.72]: Vandenberghe, 2011; Yang et al. 2010
[^13.77]: Vandenberghe, 2011; Yang et al. 2010
[^13.78]: Vandenberghe, 2011; Yang et al. 2010
[^13.79]: Vandenberghe, 2011; Yang et al. 2010
[^13.80]: Vandenberghe, 2011; Yang et al. 2010
[^13.82]: Barzilai and Borwein 1988; Fletcher 2005; Raydan 1997
[^13.83]: Nesterov 2004; Tseng 2008
[^13.84]: Nesterov 2004; Tseng 2008
[^13.85]: Nesterov 2004; Tseng 2008
<!-- END -->