## Online Gradient Descent

### Introdução
O aprendizado online (online learning) apresenta um paradigma onde os dados chegam sequencialmente, e o modelo é atualizado a cada nova observação, em vez de processar um *batch* de dados de uma só vez [^261]. Este capítulo explora o algoritmo de **Online Gradient Descent (OGD)**, uma técnica fundamental para otimizar modelos neste cenário [^262]. OGD adapta-se bem a *streaming data* e pode ser aplicado mesmo quando o conjunto de dados é muito grande para caber na memória [^261]. OGD é um algoritmo para aprendizado online que atualiza os parâmetros usando o gradiente da função de perda a cada passo [^262]. O passo de projeção é necessário apenas se o parâmetro deve ser restringido a viver em um certo subconjunto de $R^D$ [^262].

### Conceitos Fundamentais

#### Algoritmo Online Gradient Descent (OGD)
No OGD, a cada passo *k*, o algoritmo recebe uma amostra $z_k$ e atualiza os parâmetros $\theta$ usando o gradiente da função de perda $f(\theta, z_k)$ [^262]. A atualização é dada por:

$$ \theta_{k+1} = \text{proj}_{\mathcal{V}}(\theta_k - \eta_k g_k) $$

Onde:
*   $\theta_k$ são os parâmetros no passo *k* [^262].
*   $\eta_k$ é o tamanho do passo (learning rate) no passo *k* [^262].
*   $g_k = \nabla f(\theta_k, z_k)$ é o gradiente da função de perda em $\theta_k$ [^262].
*   $\text{proj}_{\mathcal{V}}(v)$ é a projeção do vetor *v* no conjunto $\mathcal{V}$ [^262].

O passo de **projeção** é crucial quando os parâmetros $\theta$ devem pertencer a um conjunto restrito $\mathcal{V} \subset \mathbb{R}^D$ [^262]. Sem a projeção, as atualizações poderiam levar os parâmetros para fora deste conjunto, invalidando o modelo [^262].

#### Regret Minimization
Em aprendizado online, uma métrica comum é o **regret**, que quantifica a perda acumulada do algoritmo em relação à melhor escolha de parâmetros *a posteriori* [^262]. O regret é definido como:

$$ \text{regret}_k = \frac{1}{k} \sum_{t=1}^{k} f(\theta_t, z_t) - \min_{\theta} \frac{1}{k} \sum_{t=1}^{k} f(\theta, z_t) $$

O objetivo do OGD é minimizar o regret ao longo do tempo [^262].

#### Stochastic Optimization e Risco
Em vez de minimizar o regret em relação ao passado, podemos querer minimizar a perda esperada no futuro, que é o objetivo da **otimização estocástica** [^262]. O objetivo é minimizar:

$$ f(\theta) = \mathbb{E}[f(\theta, z)] $$

onde a expectativa é tomada sobre os dados futuros [^262]. OGD pode ser usado para otimizar objetivos estocásticos, resultando no algoritmo **Stochastic Gradient Descent (SGD)** [^262].

#### Taxa de Aprendizagem (Learning Rate)
A escolha da taxa de aprendizagem $\eta_k$ é fundamental para a convergência do OGD [^247]. Uma taxa muito pequena pode levar a uma convergência lenta, enquanto uma taxa muito grande pode causar oscilações e divergência [^247]. Condições suficientes para a convergência do SGD são dadas pelas condições de Robbins-Monro [^263]:

$$ \sum_{k=1}^{\infty} \eta_k = \infty, \quad \sum_{k=1}^{\infty} \eta_k^2 < \infty $$

Uma escolha comum para a taxa de aprendizagem é $\eta_k = (\tau_0 + k)^{-\kappa}$, onde $\tau_0 \geq 0$ e $\kappa \in (0.5, 1]$ [^263].

#### Adagrad: Taxas de Aprendizagem por Parâmetro
Uma limitação do SGD é o uso da mesma taxa de aprendizagem para todos os parâmetros [^263]. O algoritmo **Adagrad** adapta a taxa de aprendizagem para cada parâmetro individualmente, com base em sua curvatura [^263]. A atualização do parâmetro $i$ no passo $k+1$ é dada por:

$$ \theta_i(k+1) = \theta_i(k) - \frac{\eta}{\tau_0 + \sqrt{s_i(k)}} g_i(k) $$

onde $s_i(k) = s_i(k-1) + g_i(k)^2$ é a soma dos quadrados dos gradientes para o parâmetro $i$ até o passo *k* [^263].

### Conclusão

O Online Gradient Descent (OGD) é uma ferramenta versátil e fundamental no aprendizado online e na otimização estocástica [^262]. Sua capacidade de se adaptar a *streaming data* e sua relação com o Stochastic Gradient Descent (SGD) o tornam essencial para uma variedade de aplicações [^261, 262]. A escolha cuidadosa da taxa de aprendizagem e a consideração de variantes como o Adagrad são cruciais para garantir a convergência e o desempenho do algoritmo [^263].

### Referências
[^247]:  Bishop, C. M. (2006). *Pattern recognition and machine learning*. Springer.
[^261]: Bishop, C. M. (2006). *Pattern recognition and machine learning*. Springer.
[^262]: Bishop, C. M. (2006). *Pattern recognition and machine learning*. Springer.
[^263]: Bishop, C. M. (2006). *Pattern recognition and machine learning*. Springer.
<!-- END -->