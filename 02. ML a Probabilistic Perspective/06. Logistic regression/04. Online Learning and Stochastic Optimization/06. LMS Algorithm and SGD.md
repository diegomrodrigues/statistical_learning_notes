## O Algoritmo LMS: Um Caso de SGD para Regressão Linear Online

### Introdução
Este capítulo explora o algoritmo **Least Mean Squares (LMS)** como um exemplo de aplicação do **Stochastic Gradient Descent (SGD)** para o cálculo do **Maximum Likelihood Estimator (MLE)** em regressão linear de forma online [^20]. O LMS é um método iterativo que atualiza os pesos do modelo com base na diferença entre a resposta predita e a resposta verdadeira [^20].

### Conceitos Fundamentais

#### Regressão Linear e MLE
Em regressão linear, o objetivo é encontrar a melhor relação linear entre as variáveis independentes (preditores) e a variável dependente (resposta). O MLE busca os parâmetros que maximizam a probabilidade dos dados observados, dado o modelo. Em regressão linear, sob a suposição de erros Gaussianos, o MLE é equivalente a minimizar a soma dos quadrados dos erros.

#### Stochastic Gradient Descent (SGD)
O SGD é um algoritmo iterativo de otimização usado para encontrar o mínimo de uma função de custo [^20]. Em vez de usar todo o conjunto de dados para calcular o gradiente (como no *batch gradient descent*), o SGD usa apenas um subconjunto dos dados (ou mesmo um único ponto de dados) para estimar o gradiente em cada iteração. Isso torna o SGD computacionalmente mais eficiente, especialmente para grandes conjuntos de dados, e permite que ele seja aplicado em cenários de aprendizado online.

#### O Algoritmo LMS
O algoritmo LMS é uma aplicação específica do SGD para o problema de regressão linear [^20]. A atualização dos pesos no LMS é baseada no gradiente estocástico do erro quadrático instantâneo.

Dado um conjunto de dados de treinamento $(x_i, y_i)$, onde $x_i$ é o vetor de características e $y_i$ é a resposta correspondente, o objetivo é encontrar um vetor de pesos $\theta$ que minimize o erro quadrático médio. O algoritmo LMS atualiza os pesos iterativamente da seguinte forma [^20]:

$$theta_{k+1} = \theta_k - \eta_k (\hat{y}_k - y_k)x_k$$

onde:

*   $\theta_{k+1}$ é o vetor de pesos na iteração $k+1$.
*   $\theta_k$ é o vetor de pesos na iteração $k$.
*   $\eta_k$ é a taxa de aprendizado (step size) na iteração $k$ [^3].
*   $\hat{y}_k = \theta_k^T x_k$ é a resposta predita pelo modelo na iteração $k$.
*   $y_k$ é a resposta verdadeira.
*   $x_k$ é o vetor de características.

A intuição por trás dessa atualização é simples: se a predição $\hat{y}_k$ é maior que a resposta verdadeira $y_k$, então o termo $(\hat{y}_k - y_k)$ é positivo, e os pesos são ajustados na direção oposta ao vetor de características $x_k$. Se a predição é menor que a resposta verdadeira, os pesos são ajustados na direção de $x_k$. A taxa de aprendizado $\eta_k$ controla a magnitude desse ajuste.

#### Taxa de Aprendizado (Learning Rate)
A escolha da taxa de aprendizado $\eta_k$ é crucial para o sucesso do algoritmo LMS [^3]. Se $\eta_k$ for muito grande, o algoritmo pode oscilar e não convergir. Se $\eta_k$ for muito pequeno, a convergência pode ser muito lenta. Algumas condições suficientes para a convergência do SGD são conhecidas como as **condições de Robbins-Monro** [^17]:

$$sum_{k=1}^{\infty} \eta_k = \infty, \quad \sum_{k=1}^{\infty} \eta_k^2 < \infty$$

Essas condições garantem que o algoritmo eventualmente explore todo o espaço de parâmetros, mas com uma taxa de aprendizado que diminui ao longo do tempo. Uma escolha comum para $\eta_k$ é $\eta_k = (\tau_0 + k)^{-\kappa}$, onde $\tau_0 \geq 0$ e $\kappa \in (0.5, 1]$ [^17].

#### Vantagens e Desvantagens do LMS

**Vantagens:**

*   **Simplicidade:** O algoritmo LMS é extremamente simples de implementar e entender.
*   **Eficiência Computacional:** Cada iteração do LMS requer apenas um pequeno número de operações, tornando-o adequado para grandes conjuntos de dados e aplicações online.
*   **Aprendizado Online:** O LMS pode ser usado para atualizar o modelo em tempo real, à medida que novos dados chegam [^20].

**Desvantagens:**

*   **Convergência Lenta:** Em alguns casos, o LMS pode convergir lentamente, especialmente se a taxa de aprendizado for muito pequena.
*   **Sensibilidade à Taxa de Aprendizado:** A escolha da taxa de aprendizado pode ser difícil e requer ajuste cuidadoso [^3].
*   **Não Lida Bem com Dados Não Estacionários:** Se a distribuição dos dados mudar ao longo do tempo, o LMS pode ter dificuldade em se adaptar.
*   **Requer múltiplos passes nos dados para encontrar o ótimo**[^21].

#### Normalização
Para melhorar a estabilidade e a taxa de convergência do LMS, uma técnica comum é normalizar o vetor de características $x_k$ antes de atualizar os pesos. Isso pode ser feito dividindo $x_k$ por sua norma Euclidiana.

#### Relação com outros Algoritmos
O algoritmo LMS está intimamente relacionado com outros algoritmos de otimização, como o algoritmo **Recursive Least Squares (RLS)** [^21]. O RLS, baseado no filtro de Kalman, usa informações de segunda ordem para encontrar o ótimo em um único passo, enquanto o LMS requer múltiplos passos através dos dados.

### Conclusão
O algoritmo LMS é uma ferramenta fundamental no campo do aprendizado online e otimização estocástica [^20]. Sua simplicidade e eficiência computacional o tornam uma escolha popular para uma ampla gama de aplicações, desde processamento de sinais até aprendizado de máquina. Embora tenha algumas limitações, como a sensibilidade à taxa de aprendizado e a dificuldade em lidar com dados não estacionários, o LMS continua sendo um algoritmo valioso para problemas de regressão linear online.

### Referências
[^20]: Texto original: "The LMS (least mean squares) algorithm is an example of SGD used to compute the MLE for linear regression in an online fashion. It updates the weights based on the difference between the predicted and true responses."
[^3]: Página 247: "...where nk is the step size or learning rate. The main issue in gradient descent is: how should we set the step size? This turns out to be quite tricky. If we use a constant learning rate, but make it too small, convergence will be very slow, but if we make it too large, the method can fail to converge at all."
[^17]: Página 263: "These are known as the Robbins-Monro conditions: Σηk = ∞, Σηk^2 < ∞. The set of values of nk over time is called the learning rate schedule. Various formulas are used, such as ηκ = 1/k, or the following (Bottou 1998; Bach and Moulines 2011): ηκ = (το + k)¯к where το ≥ 0 slows down early iterations of the algorithm, and к∈ (0.5, 1] controls the rate at which old values of are forgotten."
[^21]: Página 265: "Note that LMS may require multiple passes through the data to find the optimum. By contrast, the recursive least squares algorithm, which is based on the Kalman filter and which uses second-order information, finds the optimum in a single pass (see Section 18.2.3). See also Exercise 7.7."
<!-- END -->