## Stochastic Gradient Descent for Logistic Regression

### Introdução
Este capítulo explora o **Stochastic Gradient Descent (SGD)** como uma técnica de otimização para ajustar os parâmetros de um modelo de regressão logística. SGD é particularmente útil em cenários de *online learning* e quando se lida com grandes conjuntos de dados, onde o cálculo do gradiente completo se torna computacionalmente proibitivo. O SGD é uma variante do *gradient descent* que utiliza uma única amostra ou um mini-batch de amostras para estimar o gradiente a cada iteração [^20]. Devido ao ruído adicionado, ele é frequentemente menos propenso a ficar preso em mínimos locais rasos [^20].

### Conceitos Fundamentais

#### Regressão Logística e Otimização
Como vimos anteriormente [^1, ^2], a regressão logística corresponde ao seguinte modelo de classificação binária:
$$ p(y|x, w) = Ber(y|sigm(w^Tx)) $$
O objetivo é encontrar os parâmetros **w** que melhor se ajustem aos dados de treinamento. Isso geralmente é feito maximizando a *log-likelihood* (ou minimizando a *negative log-likelihood*), que é expressa como [^2]:
$$ NLL(w) = \sum_{i=1}^{N} log(1 + exp(-y_iw^Tx_i)) $$
Ao contrário da regressão linear, a *MLE (Maximum Likelihood Estimate)* para regressão logística não tem uma forma fechada [^2]. Portanto, precisamos usar algoritmos de otimização iterativos para encontrar a solução.

#### Gradient Descent e suas Limitações
O *gradient descent* é um algoritmo iterativo que atualiza os parâmetros na direção oposta ao gradiente da função objetivo [^3]. A atualização é dada por:
$$ \theta_{k+1} = \theta_k - \eta_k g_k $$
onde $\theta_k$ são os parâmetros na iteração *k*, $\eta_k$ é o *step size* (ou *learning rate*), e $g_k$ é o gradiente da função objetivo [^3]. O principal problema com o *gradient descent* é a escolha do *step size*. Se $\eta_k$ for muito pequeno, a convergência será lenta, e se for muito grande, o método pode não convergir [^3].

#### Stochastic Gradient Descent (SGD)
O *Stochastic Gradient Descent (SGD)* é uma variante do *gradient descent* que aproxima o gradiente usando uma única amostra ou um mini-batch de amostras [^20]. Isso torna o SGD computacionalmente mais eficiente, especialmente para grandes conjuntos de dados. No entanto, a aproximação introduz ruído, o que pode levar a um comportamento oscilatório e dificultar a convergência [^20].

Em cada iteração *k*, o SGD seleciona aleatoriamente uma amostra $z_k$ e atualiza os parâmetros usando o gradiente da função objetivo avaliada nessa amostra:
$$ \theta_{k+1} = \theta_k - \eta_k \nabla f(\theta_k, z_k) $$
onde $f(\theta_k, z_k)$ é a função de perda para a amostra $z_k$ e $\nabla f(\theta_k, z_k)$ é o gradiente dessa função [^17].

#### Mini-Batch Gradient Descent
Uma abordagem intermediária entre o *gradient descent* e o SGD é o *mini-batch gradient descent*, que usa um pequeno conjunto de amostras (um "mini-batch") para estimar o gradiente [^20]. Isso reduz o ruído em comparação com o SGD, enquanto ainda é mais eficiente do que o *gradient descent*.

#### Learning Rate Schedules
A escolha do *learning rate* $\eta_k$ é crucial para a convergência do SGD. Um *learning rate* constante pode levar a oscilações ou convergência lenta [^3]. Portanto, é comum usar um *learning rate schedule*, que ajusta $\eta_k$ ao longo do tempo. As condições de Robbins-Monro fornecem algumas condições suficientes para a convergência do SGD [^19]:

$$ \sum_{k=1}^{\infty} \eta_k = \infty, \quad \sum_{k=1}^{\infty} \eta_k^2 < \infty $$

Uma escolha comum para o *learning rate schedule* é [^19]:
$$ \eta_k = (\tau_0 + k)^{-\kappa} $$

onde $\tau_0 \geq 0$ e $\kappa \in (0.5, 1]$.

#### AdaGrad
Uma abordagem mais sofisticada para ajustar o *learning rate* é usar métodos adaptativos, como o AdaGrad [^19]. O AdaGrad ajusta o *learning rate* para cada parâmetro individualmente, com base na magnitude dos gradientes passados [^19]. A atualização para o parâmetro *i* na iteração *k* é dada por [^19]:
$$ \theta_i(k+1) = \theta_i(k) - \eta \frac{g_i(k)}{\sqrt{s_i(k)} + \tau_0} $$
onde $g_i(k)$ é o gradiente do parâmetro *i* na iteração *k*, $s_i(k)$ é a soma dos quadrados dos gradientes passados para o parâmetro *i*, e $\tau_0$ é um termo de regularização para evitar a divisão por zero [^19].

### Vantagens e Desvantagens do SGD

**Vantagens:**
*   **Eficiência Computacional:** SGD é computacionalmente eficiente, especialmente para grandes conjuntos de dados, pois requer apenas o cálculo do gradiente para uma única amostra ou mini-batch em cada iteração [^20].
*   **Fuga de Mínimos Locais:** SGD é menos propenso a ficar preso em mínimos locais rasos devido ao ruído introduzido pela aproximação do gradiente [^20].

**Desvantagens:**
*   **Convergência Oscilatória:** O ruído no gradiente pode levar a um comportamento oscilatório e dificultar a convergência [^20].
*   **Sensibilidade ao Learning Rate:** A escolha do *learning rate* é crucial para a convergência do SGD, e um *learning rate* constante pode não ser ideal [^3].

### Conclusão
O Stochastic Gradient Descent é uma ferramenta poderosa para otimizar modelos de regressão logística, especialmente em cenários de *online learning* e com grandes conjuntos de dados. Embora apresente desafios como a escolha do *learning rate* e a convergência oscilatória, as vantagens em termos de eficiência computacional e a capacidade de escapar de mínimos locais rasos o tornam uma escolha popular na prática. Métodos adaptativos como o AdaGrad oferecem abordagens mais sofisticadas para ajustar o *learning rate* e melhorar a convergência.

### Referências
[^1]: Seção 8.1, "Logistic regression".
[^2]: Seção 8.3.1, "MLE".
[^3]: Seção 8.3.2, "Steepest descent".
[^17]: Seção 8.5, "Online learning and stochastic optimization".
[^19]: Seção 8.5.2.1, "Setting the step size".
[^20]: Seção 8.5.2.3, "SGD compared to batch learning".
<!-- END -->