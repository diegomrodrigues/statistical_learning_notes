## Stochastic Gradient Descent para Regressão Logística

### Introdução
Este capítulo aborda o **Stochastic Gradient Descent (SGD)** [^20] no contexto da Regressão Logística. Como vimos anteriormente [^8.3], a Regressão Logística, ao contrário da Regressão Linear, não possui uma solução analítica fechada para a estimativa de máxima verossimilhança (MLE). Portanto, algoritmos de otimização iterativos são necessários para encontrar os parâmetros do modelo [^8.3]. O SGD é uma alternativa eficiente ao *gradient descent* tradicional, especialmente útil para grandes conjuntos de dados [^20].

### Conceitos Fundamentais
**Stochastic Gradient Descent (SGD)** é um algoritmo de otimização iterativo usado para minimizar uma função de perda, atualizando os parâmetros do modelo com base no gradiente calculado a partir de um único ponto de dado ou um pequeno lote de pontos de dados [^20]. No contexto da Regressão Logística, o SGD busca otimizar a função de *negative log-likelihood (NLL)*, dada por [^8.2, 8.3, 8.4]:
$$
NLL(w) = \sum_{i=1}^{N} log(1 + exp(-y_i w^T x_i))
$$
onde $w$ representa os parâmetros do modelo, $x_i$ são as características do i-ésimo ponto de dados, e $y_i$ é a classe correspondente (codificada como -1 ou +1).

O SGD difere do *gradient descent* tradicional (também conhecido como *steepest descent*) [^8.3.2] porque, em vez de calcular o gradiente usando todos os pontos de dados em cada iteração, o SGD usa apenas um subconjunto aleatório (ou até mesmo um único ponto) [^20]. A regra de atualização para o SGD é [^20]:
$$
\theta_{k+1} = \theta_k - \eta \nabla f(\theta_k, z_k)
$$
onde $\theta_k$ representa os parâmetros na iteração *k*, $\eta$ é a *taxa de aprendizado* (ou *step size*) [^8.3.2], e $z_k$ é um ponto de dado selecionado aleatoriamente. $\nabla f(\theta_k, z_k)$ é o gradiente da função de perda calculado usando apenas o ponto de dado $z_k$.

O gradiente da *negative log-likelihood* para a Regressão Logística, usando um único ponto de dado $(x_i, y_i)$, é dado por:
$$
\nabla NLL(w, (x_i, y_i)) = - \frac{y_i x_i exp(-y_i w^T x_i)}{1 + exp(-y_i w^T x_i)}
$$
Portanto, a regra de atualização do SGD para a Regressão Logística é:
$$
w_{k+1} = w_k + \eta \frac{y_i x_i exp(-y_i w_k^T x_i)}{1 + exp(-y_i w_k^T x_i)}
$$
A escolha da *taxa de aprendizado* $\eta$ é crucial para a convergência do SGD [^8.3.2]. Se $\eta$ for muito grande, o algoritmo pode oscilar e não convergir. Se $\eta$ for muito pequeno, a convergência pode ser muito lenta [^8.3.2]. Existem várias estratégias para ajustar a taxa de aprendizado durante o treinamento, como *annealing* [^8.5.2.1] (reduzindo $\eta$ ao longo do tempo) ou métodos adaptativos como o **Adagrad** [^8.5.2.2].

O SGD, por usar uma estimativa ruidosa do gradiente, pode ajudar a escapar de mínimos locais rasos [^20]. O ruído introduzido pela amostragem aleatória dos dados pode permitir que o algoritmo "salte" para fora de regiões subótimas do espaço de parâmetros [^20].

#### Mini-Batch Gradient Descent
Uma variante comum do SGD é o **Mini-Batch Gradient Descent**, onde o gradiente é calculado usando um pequeno lote de pontos de dados em vez de um único ponto [^8.5.2.3]. Isso fornece uma estimativa mais estável do gradiente e pode levar a uma convergência mais rápida [^8.5.2.3]. O tamanho do lote é um hiperparâmetro que precisa ser ajustado [^8.5.2.3].

#### Critérios de Convergência
Determinar quando o SGD convergiu pode ser desafiador. Alguns critérios comuns incluem [^8.5.2.1]:
*   Monitorar a mudança na função de perda ao longo das iterações. Se a mudança for pequena, o algoritmo pode ter convergido.
*   Usar um conjunto de validação para monitorar o desempenho do modelo. Se o desempenho no conjunto de validação parar de melhorar, o algoritmo pode ter convergido.
*   Definir um número máximo de iterações.

#### Vantagens e Desvantagens
O SGD oferece várias vantagens:
*   **Eficiência computacional**: Cada iteração é rápida, pois apenas um subconjunto dos dados é usado [^20].
*   **Capacidade de escapar de mínimos locais**: O ruído no gradiente pode ajudar o algoritmo a evitar ficar preso em regiões subótimas [^20].

No entanto, o SGD também possui algumas desvantagens:
*   **Convergência ruidosa**: O algoritmo pode oscilar em torno do mínimo [^20].
*   **Sensibilidade à taxa de aprendizado**: A escolha da taxa de aprendizado pode ser crítica para a convergência [^8.3.2].
*   **Necessidade de ajuste de hiperparâmetros**: O tamanho do lote e a taxa de aprendizado precisam ser ajustados [^8.5.2.3, 8.3.2].

### Conclusão
O Stochastic Gradient Descent é uma ferramenta poderosa para otimizar modelos de Regressão Logística, especialmente em grandes conjuntos de dados [^20]. Embora exija um ajuste cuidadoso dos hiperparâmetros e possa exibir uma convergência ruidosa, sua eficiência computacional e capacidade de escapar de mínimos locais o tornam uma escolha popular na prática [^20]. Em continuidade com os tópicos abordados, a escolha entre *batch gradient descent*, *mini-batch gradient descent* e SGD dependerá das características específicas do conjunto de dados e dos recursos computacionais disponíveis. Métodos mais avançados, como os métodos *Quasi-Newton* [^8.3.5], podem oferecer uma convergência mais rápida e estável, mas a um custo computacional maior por iteração.

### Referências
[^20]: Stochastic gradient descent (SGD) is an iterative optimization algorithm used to minimize a loss function by updating the model parameters based on the gradient computed from a single data point or a small batch of data points. It is an optimization algorithm that updates parameters using the gradient computed from a single data point or a mini-batch, providing a noisy but efficient estimate of the gradient and helping to avoid shallow local minima. The update rule is \u03b8k+1 = \u03b8k - \u03b7\u2207f(\u03b8k, zk), where zk is a randomly selected data point.
[^8.3]: In this section, we discuss algorithms for estimating the parameters of a logistic regression model.
[^8.2]: As we discussed in Section 1.4.6, logistic regression corresponds to the following binary classification model: p(y|x, w) = Ber(y|sigm(w^x))
[^8.3.2]: Perhaps the simplest algorithm for unconstrained optimization is gradient descent, also known as steepest descent. This can be written as follows: 0k+1 = 0k - 7kgk where nk is the step size or learning rate. The main issue in gradient descent is: how should we set the step size? This turns out to be quite tricky.
[^8.5.2.3]: In this offline case, it is often better to compute the gradient of a mini-batch of B data cases. If B = 1, this is standard SGD, and if B = N, this is standard steepest descent. Typically B~100 is used.
[^8.5.2.1]: The need to adjust these tuning parameters is one of the main drawback of stochastic optimization.
[^8.3.5]: The mother of all second-order optimization algorithm is Newton's algorithm, which we discussed in Section 8.3.3. Unfortunately, it may be too expensive to compute H explicitly. Quasi-Newton methods iteratively build up an approximation to the Hessian using information gleaned from the gradient vector at each step.

<!-- END -->