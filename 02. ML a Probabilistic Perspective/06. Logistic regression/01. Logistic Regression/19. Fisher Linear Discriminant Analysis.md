## Fisher's Linear Discriminant Analysis em Regressão Logística

### Introdução
Este capítulo explora a técnica de **Fisher's Linear Discriminant Analysis (FLDA)** no contexto da **Regressão Logística**, ambos abordados no Capítulo 8 [^1]. Embora a regressão logística seja um modelo discriminativo, a FLDA oferece uma abordagem híbrida, combinando elementos de modelos generativos e discriminativos [^27]. Este capítulo detalha a formulação matemática da FLDA, suas limitações e sua interpretação probabilística, construindo sobre o conhecimento de modelos generativos e discriminativos previamente estabelecidos [^1].

### Conceitos Fundamentais

**Fisher's Linear Discriminant Analysis (FLDA)** é uma técnica de redução de dimensionalidade que busca a combinação linear de *features* que melhor separam duas ou mais classes [^27]. O objetivo da FLDA é maximizar a razão entre a variância entre classes (between-class variance) e a variância dentro das classes (within-class variance), projetando os dados em um espaço de menor dimensão enquanto preserva a separabilidade das classes [^27]. Em outras palavras, a FLDA busca uma matriz $W$ tal que os dados em baixa dimensão possam ser classificados da melhor forma possível usando um modelo de densidade condicional Gaussiana [^27].

Formalmente, a FLDA encontra a matriz de projeção $W$ que otimiza o seguinte critério [^27]:
$$\
J(W) = \frac{|W^T S_B W|}{|W^T S_W W|}
$$
onde:
- $S_B$ é a matriz de *scatter* entre classes (between-class scatter matrix)
- $S_W$ é a matriz de *scatter* dentro das classes (within-class scatter matrix)

Para o caso de duas classes, as matrizes $S_B$ e $S_W$ são definidas como [^29]:
$$\
S_B = (\mu_2 - \mu_1)(\mu_2 - \mu_1)^T
$$
$$\
S_W = \sum_{i:y_i=1} (x_i - \mu_1)(x_i - \mu_1)^T + \sum_{i:yi=2} (x_i - \mu_2)(x_i - \mu_2)^T
$$
onde $\mu_1$ e $\mu_2$ são as médias condicionais das classes [^29].

A solução para o problema de otimização acima é dada pelos autovetores generalizados de $S_W^{-1}S_B$ [^30]. No caso de duas classes, a direção ótima $w$ é dada por [^30]:
$$\
w = S_W^{-1}(\mu_2 - \mu_1)
$$
Essa direção $w$ representa o vetor que melhor separa as duas classes no espaço original dos dados.

**Limitações da FLDA**
Uma restrição importante da FLDA é que ela é limitada a, no máximo, $C-1$ dimensões, onde $C$ é o número de classes [^27]. Isso ocorre porque o *rank* da matriz de *scatter* entre classes $S_B$ é, no máximo, $C-1$ [^31]. Para problemas com um número de classes maior que a dimensionalidade dos dados, a FLDA não consegue explorar todas as direções de separação entre as classes.

**Interpretação Probabilística da FLDA**
Uma interpretação probabilística da FLDA pode ser obtida através do modelo *Heteroscedastic LDA (HLDA)* [^31].  Nesse modelo, os dados transformados $z_i = Wx_i$ são modelados com distribuições Gaussianas com médias específicas para cada classe e covariâncias que compartilham alguns componentes entre as classes [^31]. Formalmente [^31]:
$$\
p(z_i|\theta, y_i = c) = N(z_i|\mu_c, \Sigma_c)
$$
onde $\mu_c$ e $\Sigma_c$ são a média e a matriz de covariância para a classe $c$, respectivamente.  A matriz de covariância $\Sigma_c$ é estruturada de forma que apenas as primeiras $L$ componentes sejam específicas da classe, enquanto as componentes restantes são compartilhadas entre todas as classes [^31].

### Conclusão
A FLDA oferece uma técnica eficaz para redução de dimensionalidade e separação de classes, combinando aspectos de modelos generativos (através da análise de *scatter* entre e dentro de classes) e discriminativos (ao otimizar a separabilidade das classes) [^27, 31].  Embora a FLDA possua limitações em relação ao número de dimensões resultantes, sua interpretabilidade e eficiência computacional a tornam uma ferramenta valiosa em problemas de classificação [^27]. No contexto da regressão logística, a FLDA pode ser usada como um passo de pré-processamento para reduzir a dimensionalidade dos dados antes de aplicar o modelo de regressão logística, especialmente em situações onde a alta dimensionalidade pode levar a problemas de *overfitting* [^27].

### Referências
[^1]: Capítulo 8 do livro texto.
[^27]: Seção 8.6.3 do livro texto.
[^29]: Seção 8.6.3.1 do livro texto.
[^30]: Seção 8.6.3.2 do livro texto.
[^31]: Seção 8.6.3.3 do livro texto.
<!-- END -->