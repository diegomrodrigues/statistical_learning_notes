## 8.5.4 The Perceptron Algorithm

### Introdução
Este capítulo explora o algoritmo do perceptron como uma alternativa para ajustar modelos de regressão logística de forma online. O algoritmo do perceptron, historicamente significativo, oferece uma abordagem simples e intuitiva para classificação binária, embora existam métodos mais avançados disponíveis [^266].

### Conceitos Fundamentais
O algoritmo do perceptron é um método de aprendizado online para classificação binária. Em vez de otimizar a função de custo em lote (batch), como no caso da regressão logística padrão, o perceptron atualiza os pesos do modelo linear iterativamente com base em cada exemplo individual [^261].

A regra de atualização do perceptron é definida como [^266]:
$$ \theta_k = \theta_{k-1} + \eta_k y_i x_i $$
onde:
*   $\theta_k$ é o vetor de pesos na iteração *k*.
*   $\eta_k$ é a taxa de aprendizado (learning rate). No caso mais simples, $\eta_k = 1$ [^266].
*   $y_i \in \{-1, +1\}$ é a classe real do exemplo *i* [^266]. Note que o texto original usa $\{-1, +1\}$ ao invés de $\{0, 1\}$, o que simplifica a álgebra [^266].
*   $x_i$ é o vetor de características do exemplo *i*.

O algoritmo funciona da seguinte forma [^266]:
1.  Para cada exemplo ($x_i$, $y_i$) no conjunto de treinamento:
2.  Calcule a previsão $\hat{y}_i = \text{sign}(\theta^T x_i)$.
3.  Se a previsão estiver correta (ou seja, $\hat{y}_i = y_i$), não faça nada.
4.  Se a previsão estiver incorreta (ou seja, $\hat{y}_i \neq y_i$), atualize os pesos usando a regra de atualização acima.

**Convergência**:
O algoritmo do perceptron tem uma propriedade importante: se os dados forem linearmente separáveis, o algoritmo converge, ou seja, encontra um vetor de pesos $\theta$ que classifica corretamente todos os exemplos no conjunto de treinamento [^266]. No entanto, se os dados não forem linearmente separáveis, o algoritmo não converge e pode oscilar indefinidamente [^266].

**Relação com Regressão Logística**:
Embora o perceptron seja um algoritmo de classificação linear, ele difere da regressão logística em sua função de custo e método de otimização. A regressão logística usa a função de custo de entropia cruzada (cross-entropy) e a otimiza usando métodos como gradiente descendente [^245, ^246, ^247]. O perceptron, por outro lado, usa uma regra de atualização simples baseada no sinal do erro de previsão [^266].

**Algoritmos Modernos:**
O texto original aponta que existem maneiras melhores de treinar modelos de regressão logística (usando SGD, sem aproximação de gradiente, ou IRLS) [^266].

**Algoritmo 8.4: Perceptron Algorithm**
O pseudocódigo para o algoritmo do perceptron é apresentado no Algoritmo 8.4 [^267]:

1.  **Input**: Conjunto de dados linearmente separável $x_i \in \mathbb{R}^D$, $y_i \in \{-1, +1\}$ para $i = 1:N$.
2.  **Initialize** $\theta_0$.
3.  $k \leftarrow 0$.
4.  **repeat**
5.  $k \leftarrow k + 1$.
6.  $i \leftarrow k \mod N$.
7.  **if** $\hat{y}_i \neq y_i$ **then**
8.  $\quad \theta_{k+1} \leftarrow \theta_k + y_i x_i$.
9.  **else**
10. $\quad$ no-op.
11. **until** converged.

### Conclusão

O algoritmo do perceptron oferece uma abordagem simples e intuitiva para a classificação binária online. Embora possa não ser tão eficiente ou robusto quanto os métodos mais modernos, como a regressão logística otimizada com gradiente descendente, o perceptron serve como uma base importante no desenvolvimento de algoritmos de aprendizado de máquina. Além disso, é um exemplo de um algoritmo que pode ser usado onde computar $p(y|x, \theta)$ é mais caro do que computar argmax.

### Referências
[^245]: Seção 8.3 "Model fitting"
[^246]: Seção 8.3.1 "MLE"
[^247]: Seção 8.3.2 "Steepest descent"
[^261]: Seção 8.5 "Online learning and stochastic optimization"
[^266]: Seção 8.5.4 "The perceptron algorithm"
[^267]: Seção 8.6 "Generative vs discriminative classifiers"

<!-- END -->