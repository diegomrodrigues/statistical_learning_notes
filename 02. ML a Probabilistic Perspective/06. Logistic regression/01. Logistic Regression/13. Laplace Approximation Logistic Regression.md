## Laplace Approximation for Bayesian Logistic Regression

### Introdução
Em continuidade à discussão sobre regressão logística [^8], este capítulo se aprofundará na aplicação da **aproximação de Laplace** para realizar inferência Bayesiana nos parâmetros do modelo. Como visto anteriormente [^8.4], a regressão logística, diferentemente da regressão linear, não possui um *prior* conjugado conveniente, o que impede a obtenção de uma solução analítica exata para a distribuição *a posteriori* dos parâmetros. A aproximação de Laplace surge como uma alternativa para aproximar essa distribuição por uma Gaussiana, centrada no modo da distribuição *a posteriori*.

### Conceitos Fundamentais
A aproximação de Laplace é um método geral para aproximar distribuições de probabilidade por distribuições Gaussianas [^8.4.1]. No contexto da regressão logística Bayesiana, o objetivo é aproximar a distribuição *a posteriori* $p(\theta|D)$, onde $\theta$ representa os parâmetros do modelo e $D$ os dados observados. O método envolve os seguintes passos:

1.  **Definição da Função de Energia:** A função de energia $E(\theta)$ é definida como o negativo do logaritmo da distribuição *a posteriori* não normalizada [^8.4.1]:
    $$E(\theta) = - \log p(\theta, D)$$
    onde $p(\theta, D) = p(D|\theta)p(\theta)$.

2.  **Expansão em Série de Taylor:** A função de energia é expandida em uma série de Taylor de segunda ordem em torno do modo $\theta^*$ da distribuição *a posteriori*, que corresponde ao ponto de mínimo da função de energia [^8.4.1]:
    $$E(\theta) \approx E(\theta^*) + (\theta - \theta^*)^T g + \frac{1}{2} (\theta - \theta^*)^T H (\theta - \theta^*)$$
    onde $g$ é o gradiente e $H$ é a matriz Hessiana de $E(\theta)$ avaliados em $\theta^*$.

3.  **Aproximação Gaussiana:** Como $\theta^*$ é o modo, o gradiente $g$ se anula nesse ponto [^8.4.1]. A aproximação de Laplace resulta na seguinte distribuição Gaussiana [^8.4.1]:
    $$p(\theta|D) \approx \frac{1}{Z} \exp \left[ - \frac{1}{2} (\theta - \theta^*)^T H (\theta - \theta^*) \right] = \mathcal{N}(\theta|\theta^*, H^{-1})$$
    onde $Z$ é uma constante de normalização e $H^{-1}$ é a matriz de covariância da Gaussiana, estimada pela inversa da matriz Hessiana avaliada no modo.

4.  **Aproximação da Verossimilhança Marginal:** A aproximação de Laplace para a verossimilhança marginal $p(D)$ é dada por [^8.4.1]:
    $$p(D) \approx \exp(-E(\theta^*)) (2\pi)^{D/2} |H|^{-1/2}$$
    onde $D$ representa a dimensão do espaço de parâmetros.

**Derivação da Aproximação de Laplace:**

A aproximação de Laplace se baseia na aproximação da distribuição *a posteriori* por uma Gaussiana centrada no modo. A expansão de Taylor de segunda ordem da função de energia em torno do modo $\theta^*$ é crucial para essa aproximação. Ao truncar a série de Taylor na segunda ordem e desprezar os termos de ordem superior, assume-se que a função de energia se comporta aproximadamente como uma quadrática perto do modo. Essa aproximação é mais precisa quando a distribuição *a posteriori* é unimodal e aproximadamente Gaussiana.

**Cálculo da Hessiana:**

O cálculo da matriz Hessiana $H$ é um passo fundamental na aproximação de Laplace. A Hessiana representa a curvatura da função de energia no modo e, portanto, influencia diretamente a matriz de covariância da Gaussiana aproximada. Em problemas de alta dimensão, o cálculo e a inversão da Hessiana podem ser computacionalmente custosos. Nesses casos, podem ser utilizadas aproximações ou métodos de otimização que evitam o cálculo explícito da Hessiana, como os métodos *Quasi-Newton* [^8.3.5] (BFGS, L-BFGS) ou métodos de gradiente conjugado.

**Considerações Práticas:**

*   A aproximação de Laplace é mais precisa quando a distribuição *a posteriori* é aproximadamente Gaussiana e unimodal. Em distribuições multimodais ou com caudas pesadas, a aproximação pode ser inadequada.
*   A escolha do *prior* influencia a forma da distribuição *a posteriori* e, consequentemente, a precisão da aproximação de Laplace.
*   A identificação do modo $\theta^*$ é um passo crucial. Métodos de otimização eficientes são necessários para encontrar o mínimo global da função de energia.
*   Em problemas de alta dimensão, a computação da Hessiana e sua inversa pode ser desafiadora. Métodos de aproximação ou regularização podem ser necessários.

### Conclusão
A aproximação de Laplace oferece uma forma eficiente de realizar inferência Bayesiana em modelos de regressão logística, aproximando a distribuição *a posteriori* dos parâmetros por uma Gaussiana. Essa aproximação permite calcular a verossimilhança marginal e realizar previsões com intervalos de confiança [^8.4.4]. No entanto, é importante estar ciente das limitações da aproximação e considerar métodos alternativos quando a distribuição *a posteriori* se desvia significativamente de uma Gaussiana. Métodos como MCMC [^8.4] ou inferência variacional [^8.4] podem ser mais adequados nesses casos, embora com um custo computacional maior.

### Referências
[^8]: Capítulo 8, "Logistic Regression"
[^8.4]: Seção 8.4, "Bayesian Logistic Regression"
[^8.4.1]: Seção 8.4.1, "Laplace Approximation"
[^8.3.5]: Seção 8.3.5, "Quasi-Newton (variable metric) methods"
[^8.4.4]: Seção 8.4.4, "Approximating the posterior predictive"

<!-- END -->