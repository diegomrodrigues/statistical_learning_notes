## Feature Preprocessing in Discriminative Models

### Introdução
Modelos discriminativos, ao contrário dos generativos, oferecem flexibilidade no pré-processamento da entrada. Especificamente, *discriminative models allow us to preprocess the input in arbitrary ways, e.g., we can replace x with φ(x)* [^1]. Este capítulo explora as implicações e benefícios dessa capacidade no contexto da regressão logística e outros classificadores discriminativos.

### Conceitos Fundamentais

A capacidade de pré-processar a entrada em modelos discriminativos, substituindo **x** por **φ(x)**, permite a criação de *features* mais informativas e relevantes para a tarefa de classificação [^1]. Essa transformação **φ(x)** pode incluir:

1.  **Expansão de funções de base:** A transformação **φ(x)** pode expandir o espaço de *features* original, introduzindo não linearidades e permitindo que o modelo capture relações mais complexas nos dados. Por exemplo, funções de base radial (RBF) [^Figure 8.9] ou polinômios podem ser usados para criar um espaço de *features* de alta dimensão.

2.  **Seleção de *features*:** A transformação **φ(x)** pode selecionar um subconjunto de *features* originais que são mais relevantes para a tarefa de classificação, reduzindo a dimensionalidade e o ruído nos dados.

3.  **Engenharia de *features*:** A transformação **φ(x)** pode criar novas *features* combinando ou transformando as *features* originais, permitindo que o modelo capture relações complexas e interações entre as *features*.

Essa flexibilidade é uma vantagem significativa dos modelos discriminativos em relação aos generativos [^8.6.1]. Modelos generativos precisam modelar a distribuição conjunta **p(x, y)**, o que pode ser desafiador quando as *features* são altamente correlacionadas ou têm distribuições complexas. Modelos discriminativos, por outro lado, apenas precisam modelar a distribuição condicional **p(y|x)**, o que permite que eles se concentrem em aprender a relação entre as *features* e a variável de saída, sem se preocupar em modelar a distribuição das *features* em si.

A Figura 8.9 [^Figure 8.9] ilustra o uso de funções de base RBF para expandir o espaço de *features* em um modelo de regressão logística multinomial. A expansão das *features* permite que o modelo capture relações não lineares nos dados e obtenha maior precisão na classificação.

No contexto da regressão logística, a substituição de **x** por **φ(x)** na equação 8.1 [^8.1] resulta no seguinte modelo:

$$np(y|x, w) = Ber(y|sigm(w^T\phi(x)))$$

onde **φ(x)** é a transformação aplicada à entrada **x**.

O processo de ajuste do modelo envolve encontrar os parâmetros **w** que minimizam a *negative log-likelihood* (NLL), como definido nas equações 8.2, 8.3 e 8.4 [^8.2, 8.3, 8.4], usando algoritmos de otimização como *gradient descent*, *steepest descent* ou métodos de segunda ordem como o método de Newton [^8.3.1, 8.3.2, 8.3.3]. A escolha da transformação **φ(x)** pode ter um impacto significativo na complexidade do problema de otimização e na precisão do modelo resultante.

### Conclusão
A capacidade de pré-processar a entrada em modelos discriminativos, como a regressão logística, oferece flexibilidade e poder expressivo significativos. Ao escolher cuidadosamente a transformação **φ(x)**, podemos criar *features* mais informativas e relevantes para a tarefa de classificação, melhorando a precisão do modelo e sua capacidade de generalização. Essa flexibilidade é uma vantagem fundamental dos modelos discriminativos em relação aos generativos, que podem ser limitados pela necessidade de modelar a distribuição conjunta das *features* e da variável de saída.
### Referências
[^1]: Página 1, Capítulo 8, "Logistic regression"
[^8.1]: Página 1, Capítulo 8, "Logistic regression"
[^8.2]: Página 2, Capítulo 8, "Logistic regression"
[^8.3]: Página 2, Capítulo 8, "Logistic regression"
[^8.4]: Página 2, Capítulo 8, "Logistic regression"
[^8.3.1]: Página 2, Capítulo 8, "Logistic regression"
[^8.3.2]: Página 3, Capítulo 8, "Logistic regression"
[^8.3.3]: Página 5, Capítulo 8, "Logistic regression"
[^8.6.1]: Página 24, Capítulo 8, "Logistic regression"
[^Figure 8.9]: Página 25, Capítulo 8, "Logistic regression"
<!-- END -->