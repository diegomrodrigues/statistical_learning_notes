## Heavy Ball Method: Incorporating Momentum for Accelerated Optimization

### Introdução
O método *heavy ball*, também conhecido como **momentum**, é uma técnica de otimização que adiciona um termo de *momentum* à atualização do gradiente descendente [^249]. Esta adição tem como objetivo reduzir as oscilações (*zig-zagging*) e acelerar a convergência. A importância do termo de *momentum* é controlada por um parâmetro que varia de 0 a 1 [^249]. Este capítulo detalha o método *heavy ball*, explorando sua formulação, propriedades e relação com outros métodos de otimização.

### Conceitos Fundamentais
O método *heavy ball* modifica a atualização do gradiente descendente, introduzindo uma dependência da atualização anterior. A formulação geral é dada por [^248]:

$$ \theta_{k+1} = \theta_k - \eta_k g_k + \mu_k (\theta_k - \theta_{k-1}) $$

onde:
*   $\theta_{k+1}$ é o parâmetro atualizado no passo $k+1$.
*   $\theta_k$ é o parâmetro no passo anterior $k$.
*   $\eta_k$ é o *step size* ou *learning rate* no passo $k$.
*   $g_k$ é o gradiente da função objetivo no passo $k$, $g_k = \nabla f(\theta_k)$.
*   $\mu_k$ é o parâmetro de *momentum*, com $0 \leq \mu_k \leq 1$, que controla a importância do termo de *momentum* [^249].

O termo $\mu_k (\theta_k - \theta_{k-1})$ representa o *momentum*, que adiciona uma fração da atualização anterior à atualização atual. Este termo ajuda a suavizar a trajetória da otimização, reduzindo as oscilações e permitindo que o algoritmo avance mais rapidamente em direções consistentes.

A escolha do parâmetro de *momentum* $\mu_k$ é crucial. Um valor de $\mu_k$ próximo de 0 resulta em um comportamento semelhante ao gradiente descendente padrão, enquanto um valor de $\mu_k$ próximo de 1 dá mais peso à atualização anterior, permitindo que o algoritmo "ganhe velocidade" em direções consistentes.

**Análise da Convergência**

A convergência do método *heavy ball* depende da escolha apropriada dos parâmetros $\eta_k$ e $\mu_k$. Em geral, a análise da convergência é mais complexa do que para o gradiente descendente padrão, devido à dependência da atualização anterior. No entanto, sob certas condições, como a convexidade forte da função objetivo e a escolha adequada dos parâmetros, é possível garantir a convergência do método.

**Comparação com Gradiente Descendente**

O gradiente descendente, também conhecido como *steepest descent*, é um caso especial do método *heavy ball* quando $\mu_k = 0$ [^247]. A atualização do gradiente descendente é dada por [^247]:

$$ \theta_{k+1} = \theta_k - \eta_k g_k $$

Como discutido anteriormente, o gradiente descendente pode apresentar oscilações, especialmente em funções objetivo mal condicionadas. O método *heavy ball* mitiga este problema, adicionando o termo de *momentum* que ajuda a suavizar a trajetória da otimização [^249].

**Relação com Line Search**

Como vimos anteriormente, o *line search* é uma técnica para otimizar o *step size* $\eta_k$ em cada iteração [^248]. O *line search* busca o valor de $\eta_k$ que minimiza a função objetivo ao longo da direção de descida. No contexto do método *heavy ball*, o *line search* pode ser usado para otimizar tanto $\eta_k$ quanto $\mu_k$, embora a otimização conjunta de ambos os parâmetros possa ser computacionalmente custosa.

### Conclusão

O método *heavy ball* é uma técnica de otimização eficaz que adiciona um termo de *momentum* ao gradiente descendente para acelerar a convergência e reduzir as oscilações. A escolha apropriada do parâmetro de *momentum* $\mu_k$ é crucial para o desempenho do algoritmo. Embora a análise da convergência seja mais complexa do que para o gradiente descendente padrão, o método *heavy ball* pode ser uma escolha vantajosa em muitas aplicações, especialmente em funções objetivo mal condicionadas.

### Referências
[^247]: Seção 8.3.2, "Steepest descent", página 247.
[^248]: Página 248.
[^249]: Página 249.

<!-- END -->