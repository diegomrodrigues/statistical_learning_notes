## SVMs para Classificação Multi-Classe: Abordagens One-versus-the-Rest e One-versus-One

### Introdução
O Support Vector Machine (SVM) é inerentemente um classificador binário. No entanto, muitos problemas de classificação no mundo real envolvem mais de duas classes. Estender o SVM para lidar com cenários multi-classe requer abordagens específicas, sendo as mais comuns o *one-versus-the-rest* (OVR) e o *one-versus-one* (OVO) [^5]. Este capítulo explorará em detalhes essas duas estratégias, analisando seus prós e contras em termos de tempo de treinamento, tempo de teste e ambiguidade na classificação.

### Conceitos Fundamentais

#### One-versus-the-Rest (OVR)
A estratégia **OVR** consiste em treinar *C* classificadores binários, onde *C* é o número de classes no problema [^5]. Para cada classe *c*, um classificador é treinado para distinguir os exemplos da classe *c* dos exemplos de todas as outras classes combinadas.

*   **Treinamento:** Durante o treinamento, cada classificador $f_c(x)$ é treinado usando os exemplos da classe *c* como positivos e todos os outros exemplos como negativos [^5, 25].
*   **Classificação:** Durante a classificação, dado um novo exemplo *x*, cada classificador $f_c(x)$ produz uma pontuação. O exemplo é atribuído à classe com a maior pontuação [^25]. Formalmente, a classe prevista $\hat{y}$ é dada por:

    $$hat{y} = \arg\max_{c \in \{1, ..., C\}} f_c(x)$$

    onde $f_c(x)$ é a função discriminante do classificador para a classe *c*.
*   **Vantagens:** A principal vantagem do OVR é a sua simplicidade. Requer apenas o treinamento de *C* classificadores, o que pode ser computacionalmente eficiente em comparação com outras abordagens [^5].
*   **Desvantagens:** Uma das principais desvantagens do OVR é a possibilidade de regiões de espaço de entrada serem rotuladas ambiguamente [^25]. Isso ocorre quando um exemplo *x* recebe pontuações positivas por vários classificadores, tornando a decisão de qual classe atribuir incerta. Além disso, cada subproblema binário estará sujeito ao problema de desequilíbrio de classes (class imbalance problem) [^25]. Se uma classe for muito menor que as outras, o classificador pode ser tendencioso para as classes maiores.

#### One-versus-One (OVO)
A estratégia **OVO**, também conhecida como *all pairs*, consiste em treinar um classificador binário para cada par de classes [^5, 25]. Isso resulta no treinamento de $C(C-1)/2$ classificadores.

*   **Treinamento:** Durante o treinamento, para cada par de classes $(c, c')$, um classificador $f_{c,c'}(x)$ é treinado usando apenas os exemplos das classes *c* e *c'*.
*   **Classificação:** Durante a classificação, cada classificador $f_{c,c'}(x)$ "vota" na classe que acredita ser a correta para o exemplo *x*. O exemplo é atribuído à classe com o maior número de votos [^25]. Formalmente, a classe prevista $\hat{y}$ é dada por:

    $$hat{y} = \arg\max_{c \in \{1, ..., C\}} \sum_{c' \neq c} \mathbb{I}(f_{c,c'}(x) = c)$$

    onde $\mathbb{I}(\cdot)$ é a função indicadora, que retorna 1 se a condição for verdadeira e 0 caso contrário.
*   **Vantagens:** A principal vantagem do OVO é que cada classificador é treinado em um conjunto de dados menor e mais equilibrado, o que pode levar a classificadores mais precisos [^5].
*   **Desvantagens:** A principal desvantagem do OVO é o número significativamente maior de classificadores a serem treinados, o que pode ser proibitivo para problemas com muitas classes [^5]. Além disso, ainda pode haver ambiguidades na classificação, embora de natureza diferente do OVR [^25]. A complexidade no tempo de teste também aumenta, pois cada ponto de dados deve ser testado com $O(C^2)$ classificadores [^5, 25].

### Conclusão
Tanto as abordagens OVR quanto OVO têm seus méritos e deméritos. A escolha entre elas depende das características específicas do problema em questão, como o número de classes, o tamanho do conjunto de dados e os requisitos de tempo de treinamento e teste. OVR é mais simples e rápido de treinar, mas pode sofrer de ambiguidade e desequilíbrio de classes. OVO é mais preciso, mas requer um tempo de treinamento significativamente maior e ainda pode resultar em ambiguidades [^5, 25]. Em situações onde a incerteza é importante, métodos que retornam resultados probabilísticos são preferíveis [^14.5.2.3].

### Referências
[^5]: Capítulo 14 do livro texto.
[^25]: Seção 14.5.2.4 do livro texto.
<!-- END -->