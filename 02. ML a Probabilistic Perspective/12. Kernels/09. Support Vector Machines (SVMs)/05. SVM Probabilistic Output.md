## Saída Probabilística em Máquinas de Vetores de Suporte (SVMs)

### Introdução
Em continuidade ao estudo de **Support Vector Machines (SVMs)**, este capítulo explora a questão da saída probabilística, um aspecto crucial para a interpretação e aplicação prática desses modelos. Enquanto um classificador SVM tradicional produz uma classificação rígida, representada por $\hat{y}(x) = sign(f(x))$ [^502], muitas vezes é desejável obter uma medida de confiança associada a essa predição. Este capítulo detalha uma abordagem heurística para transformar a saída de um SVM em uma probabilidade, discutindo suas limitações e alternativas [^502].

### Conceitos Fundamentais

#### A Necessidade de Confiança nas Predições
A saída de um SVM, $f(x)$, representa a distância de uma amostra $x$ ao hiperplano de decisão [^502]. Embora o sinal de $f(x)$ determine a classe prevista, a magnitude de $f(x)$ não é diretamente interpretável como uma probabilidade. Em muitas aplicações, é fundamental ter uma medida de confiança na predição, permitindo, por exemplo, a tomada de decisões com base em um limiar de probabilidade ou a priorização de casos incertos para revisão manual.

#### A Abordagem Heurística de Platt Scaling
Uma técnica comum para converter a saída de um SVM em uma probabilidade é interpretar $f(x)$ como o *log-odds ratio* [^502]:
$$\
log \frac{p(y=0|x)}{p(y=1|x)}\
$$
Com essa interpretação, pode-se então converter a saída do SVM em uma probabilidade usando uma função sigmoide [^502]:
$$\
p(y = 1|x, \theta) = \sigma(af(x) + b)\
$$
onde $\sigma(z) = \frac{1}{1 + e^{-z}}$ é a função sigmoide, e $a$ e $b$ são parâmetros que precisam ser estimados [^502]. Este método é conhecido como **Platt Scaling** e foi proposto inicialmente em (Platt 2000) [^502].

#### Estimação dos Parâmetros a e b
Os parâmetros $a$ e $b$ são tipicamente estimados por **maximum likelihood** em um conjunto de validação separado [^502]. É crucial utilizar um conjunto de validação independente do conjunto de treinamento para evitar *overfitting* [^502]. Usar o conjunto de treinamento para estimar $a$ e $b$ leva a uma calibração excessivamente otimista das probabilidades, resultando em uma confiança irrealista nas predições.

#### Limitações do Platt Scaling
Apesar de sua simplicidade e popularidade, o Platt Scaling possui algumas limitações [^502]:
*   **Não é probabilisticamente justificado:**  Não há justificativa teórica para interpretar a saída de um SVM como um *log-odds ratio*.  A função de decisão do SVM é otimizada para maximizar a margem e não para produzir probabilidades bem calibradas [^502].
*   **Calibração subótima:** As probabilidades resultantes nem sempre são bem calibradas, o que significa que a confiança reportada não corresponde à precisão real do modelo [^502].
*   **Dependência da qualidade do SVM:** O desempenho do Platt Scaling depende da qualidade do modelo SVM subjacente. Um SVM mal treinado pode produzir probabilidades pouco confiáveis, mesmo após a calibração [^502].

Como mencionado no texto, *as probabilidades resultantes não são particularmente bem calibradas, pois não há nada no procedimento de treinamento do SVM que justifique interpretar f(x) como um log-odds ratio* [^502].

### Conclusão
Embora o Platt Scaling seja uma técnica amplamente utilizada para obter saídas probabilísticas de SVMs, é importante estar ciente de suas limitações e considerar alternativas, como os modelos probabilisticos discutidos anteriormente no capítulo, como **LIVM e RVM** [^487, 488]. Esses métodos oferecem uma abordagem mais natural e bem fundamentada para a estimação de probabilidades, embora possam ter custos computacionais mais elevados. A escolha da técnica apropriada depende dos requisitos específicos da aplicação e do compromisso entre precisão, calibração e eficiência computacional.

### Referências
[^502]: Capítulo 14, Kernels.

<!-- END -->