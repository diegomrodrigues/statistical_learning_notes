## Fisher Kernels: Exploiting Generative Models for Discriminative Power

### Introdução
Este capítulo explora os **Fisher kernels**, uma abordagem poderosa para derivar funções kernel a partir de modelos generativos probabilísticos [^485]. Diferentemente dos kernels tradicionais, que dependem de medidas de similaridade *ad hoc*, os Fisher kernels aproveitam a estrutura inerente dos dados capturada por um modelo generativo, resultando em kernels que são adaptados às características específicas dos dados. Esta abordagem permite que o modelo generativo seja usado não apenas para modelar a distribuição dos dados, mas também para definir uma medida de similaridade que pode ser usada em algoritmos discriminativos.

### Conceitos Fundamentais

Os Fisher kernels são definidos como [^485]:
$$\
\kappa(x, x') = g(x)^T F^{-1} g(x')
$$
onde:

*   $x$ e $x'$ são dois objetos a serem comparados.
*   $g(x)$ é o **vetor score** ou **gradiente do log-likelihood** avaliado no estimador de máxima verossimilhança (MLE) $\hat{\theta}$ [^485]:
    $$\
    g(x) = \nabla_{\theta} \log p(x|\theta)|_{\hat{\theta}}
    $$
*   $F$ é a **matriz de informação de Fisher**, que é essencialmente o Hessiano do log-likelihood avaliado em $\hat{\theta}$ [^485]:
    $$\
    F = \nabla \nabla \log p(x|\theta)|_{\hat{\theta}}
    $$

A intuição por trás do Fisher kernel é que $g(x)$ representa a direção no espaço de parâmetros em que $x$ gostaria que os parâmetros se movessem (a partir de $\hat{\theta}$) para maximizar sua própria verossimilhança [^485]. Em outras palavras, $g(x)$ indica como os parâmetros do modelo generativo devem ser ajustados para melhor acomodar o objeto $x$. A matriz de informação de Fisher, $F$, quantifica a curvatura do log-likelihood em torno do MLE $\hat{\theta}$ e serve como uma métrica no espaço de parâmetros.

A interpretação geométrica do Fisher kernel é que ele mede a similaridade entre dois objetos $x$ e $x'$ com base no alinhamento de seus vetores score $g(x)$ e $g(x')$, ponderado pela matriz de informação de Fisher $F$. Se os vetores score de $x$ e $x'$ apontam na mesma direção e a curvatura do log-likelihood nessa direção é pequena (ou seja, a informação de Fisher é grande), então $x$ e $x'$ são considerados similares. Por outro lado, se os vetores score apontam em direções opostas ou a curvatura do log-likelihood é grande, então $x$ e $x'$ são considerados dissimilares.

É importante notar que $\hat{\theta}$ é uma função de todos os dados, de modo que a similaridade de $x$ e $x'$ é computada no contexto de todos os dados também [^485]. Além disso, observe que só precisamos ajustar um modelo [^485].

### Conclusão

Os Fisher kernels fornecem uma maneira elegante e eficiente de combinar modelos generativos com algoritmos discriminativos. Ao derivar uma função kernel da estrutura de um modelo generativo, os Fisher kernels podem capturar as características específicas dos dados e produzir resultados melhores do que os kernels *ad hoc*. A interpretação geométrica do Fisher kernel fornece insights sobre como ele mede a similaridade entre objetos, e suas propriedades teóricas garantem que ele seja uma escolha razoável para uma ampla gama de aplicações.

### Referências
[^485]: Chapter 14. Kernels, Section 14.2.8.2 Fisher kernels.

<!-- END -->