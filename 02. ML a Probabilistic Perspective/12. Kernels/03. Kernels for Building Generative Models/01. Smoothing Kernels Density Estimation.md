## Smoothing Kernels for Non-Parametric Density Estimation

### Introdução
Este capítulo explora o uso de **smoothing kernels** na criação de estimativas de densidade não paramétricas, como a **kernel density estimation (KDE)** [^507]. A KDE é uma técnica fundamental para estimar a função de densidade de probabilidade de uma variável aleatória, sem assumir uma forma paramétrica específica para essa distribuição. Os smoothing kernels desempenham um papel crucial na KDE, definindo uma função que satisfaz propriedades como integrar a um, ter média zero e variância positiva [^507].

### Conceitos Fundamentais

Um **smoothing kernel** é definido como uma função de um único argumento, $k(x)$, que satisfaz as seguintes propriedades [^507]:
1.  **Normalização:** A integral do kernel sobre todo o seu domínio deve ser igual a um. Isto garante que a estimativa da densidade seja uma função de densidade de probabilidade válida:
    $$\
    \int k(x) \, dx = 1
    $$
2.  **Média Zero:** A integral de $x$ multiplicado pelo kernel deve ser igual a zero. Esta propriedade garante que o kernel seja centrado em torno de zero, o que é importante para evitar vieses na estimativa da densidade:
    $$\
    \int x \, k(x) \, dx = 0
    $$
3.  **Variância Positiva:** A integral de $x^2$ multiplicado pelo kernel deve ser maior que zero. Esta propriedade garante que o kernel tenha uma dispersão não nula, o que é importante para suavizar a estimativa da densidade:
    $$\
    \int x^2 \, k(x) \, dx > 0
    $$

Existem diversos exemplos de kernels que podem ser utilizados na KDE, cada um com suas próprias características e propriedades [^507]:
*   **Kernel Gaussiano:** É um dos kernels mais utilizados na KDE. É definido como:
    $$\
    k(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}
    $$
    O kernel gaussiano é diferenciável e tem suporte ilimitado [^507].
*   **Kernel Epanechnikov:** É um kernel com suporte compacto e definido como:
    $$\
    k(x) = \frac{3}{4} (1 - x^2) \mathbb{I}(|x| \le 1)
    $$
    onde $\mathbb{I}$ é a função indicadora. O kernel Epanechnikov tem suporte compacto, o que pode ser útil para eficiência computacional [^508]. No entanto, não é diferenciável nos limites do seu suporte [^508].
*   **Kernel Tri-cube:** É outro kernel com suporte compacto, definido como:
    $$\
    k(x) = \frac{70}{81} (1 - |x|^3)^3 \mathbb{I}(|x| \le 1)
    $$
    O kernel tri-cube tem suporte compacto e duas derivadas contínuas nos limites do seu suporte [^508].
*   **Kernel Boxcar (Uniforme):** É o kernel mais simples, correspondendo a uma distribuição uniforme:
    $$\
    k(x) = \frac{1}{2} \mathbb{I}(|x| \le 1)
    $$
    Este kernel tem suporte compacto, mas não é contínuo [^508].

Além da escolha do kernel, a **bandwidth** ($h$) é um parâmetro crucial na KDE, pois controla o grau de suavização da estimativa da densidade [^507]. Uma bandwidth pequena resulta em uma estimativa mais "irregular", enquanto uma bandwidth grande resulta em uma estimativa mais "suave" [^507]. A escolha da bandwidth é geralmente feita por meio de técnicas de validação cruzada ou outras heurísticas [^508].

A **kernel density estimation (KDE)** é uma técnica não paramétrica para estimar a função de densidade de probabilidade de uma variável aleatória [^507]. Dada uma amostra de dados $x_1, x_2, ..., x_N$, a estimativa da densidade é dada por:
$$\
\hat{p}(x) = \frac{1}{N} \sum_{i=1}^{N} k_h(x - x_i)
$$
onde $k_h(x) = \frac{1}{h} k(\frac{x}{h})$ é o kernel escalonado pela bandwidth $h$ [^507].

### Conclusão

Os smoothing kernels são ferramentas essenciais para a construção de modelos generativos não paramétricos, permitindo a estimativa da densidade de probabilidade de dados sem a necessidade de assumir uma forma paramétrica específica. A escolha do kernel e da bandwidth adequados é crucial para obter uma estimativa precisa e útil da densidade [^507]. A técnica de KDE, que utiliza smoothing kernels, oferece uma alternativa flexível e poderosa aos modelos paramétricos, especialmente em situações onde a forma da distribuição subjacente é desconhecida ou complexa [^507].

### Referências
[^507]: Seção 14.7.1
[^508]: Seção 14.7.2

<!-- END -->