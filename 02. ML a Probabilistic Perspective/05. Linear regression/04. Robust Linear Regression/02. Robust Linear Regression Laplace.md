## Robust Linear Regression com Distribuições de Cauda Pesada

### Introdução
Em regressão linear, assume-se frequentemente que o ruído nos dados segue uma distribuição Gaussiana. No entanto, essa suposição pode ser inadequada na presença de *outliers*, que podem distorcer significativamente as estimativas dos parâmetros do modelo. Uma abordagem para mitigar o impacto dos *outliers* é utilizar distribuições de cauda pesada, como a distribuição de Laplace, para modelar o ruído [^2]. Este capítulo explora o uso de distribuições de cauda pesada em regressão linear robusta.

### Conceitos Fundamentais
A regressão linear padrão modela a relação entre uma variável dependente $y$ e uma variável independente $x$ como:

$$
p(y|x, \theta) = \mathcal{N}(y|w^Tx, \sigma^2) \quad (7.1)
$$

onde $\theta$ representa os parâmetros do modelo, $w$ são os pesos e $\sigma^2$ é a variância do ruído [^1]. A estimação dos parâmetros é frequentemente realizada por meio da maximização da verossimilhança, que, no caso da distribuição Gaussiana, equivale à minimização da soma dos quadrados dos resíduos (RSS) [^2]:

$$
RSS(w) = \sum_{i=1}^{N} (y_i - w^T x_i)^2 \quad (7.9)
$$

A presença de *outliers* pode inflar o valor de RSS, levando a um ajuste inadequado dos parâmetros [^7]. Para mitigar esse problema, a regressão linear robusta substitui a distribuição Gaussiana por uma distribuição de cauda pesada, que atribui maior probabilidade aos *outliers*, reduzindo seu impacto nas estimativas dos parâmetros [^7].

A distribuição de Laplace é uma escolha comum para modelar o ruído em regressão linear robusta. A função de densidade de probabilidade da distribuição de Laplace é dada por [^7]:

$$
p(y|x, w, b) \propto \exp(-\frac{1}{b} |y - w^T x|) \quad (7.24)
$$

onde $b$ é um parâmetro de escala. A utilização da distribuição de Laplace na regressão linear robusta leva à minimização da soma dos valores absolutos dos resíduos [^7]:

$$
l(w) = \sum_{i} |r_i(w)| \quad (7.25)
$$

onde $r_i = y_i - w^T x_i$ é o $i$-ésimo resíduo.

A minimização da soma dos valores absolutos dos resíduos é menos sensível a *outliers* do que a minimização da soma dos quadrados dos resíduos, tornando a regressão linear robusta mais resistente à presença de dados atípicos [^7].

#### Linear Programming Formulation

A minimização da soma dos valores absolutos dos resíduos pode ser formulada como um problema de programação linear (LP) [^8]. Para isso, introduzimos variáveis auxiliares $r_i^+$ e $r_i^-$ tais que [^8]:

$$
r_i = r_i^+ - r_i^- \quad (7.26)
$$

e impomos as restrições $r_i^+ \geq 0$ e $r_i^- \geq 0$. O problema de otimização se torna [^8]:

$$
\min_{w, r^+, r^-} \sum_i (r_i^+ + r_i^-) \quad \text{s.t.} \quad y_i = w^T x_i + r_i^+ - r_i^- \quad (7.27)
$$

Este problema pode ser resolvido utilizando solvers de programação linear [^8].

#### Huber Loss Function

Uma alternativa à distribuição de Laplace é a função de perda de Huber, que combina a robustez da distribuição de Laplace com a suavidade da distribuição Gaussiana [^8]. A função de perda de Huber é definida como [^8]:

$$
L_H(r, \delta) = \begin{cases}
\frac{r^2}{2} & \text{se } |r| \leq \delta \\
\delta |r| - \frac{\delta^2}{2} & \text{se } |r| > \delta
\end{cases} \quad (7.29)
$$

onde $\delta$ é um parâmetro que controla a transição entre o comportamento quadrático e linear. A função de perda de Huber é diferenciável em todos os pontos, o que facilita a otimização [^8].

### Conclusão
A regressão linear robusta com distribuições de cauda pesada oferece uma alternativa eficaz à regressão linear padrão na presença de *outliers*. A distribuição de Laplace e a função de perda de Huber são duas opções populares para modelar o ruído em regressão linear robusta. A escolha da distribuição ou função de perda depende das características específicas dos dados e dos objetivos da análise. O uso de programação linear ou métodos de otimização suaves permite a estimação eficiente dos parâmetros do modelo, mesmo na presença de dados atípicos.

### Referências
[^1]: Section 7.2: Model specification
[^2]: Section 7.3: Maximum likelihood estimation (least squares)
[^7]: Section 7.4: Robust linear regression
[^8]: Section 7.4: Robust linear regression

<!-- END -->