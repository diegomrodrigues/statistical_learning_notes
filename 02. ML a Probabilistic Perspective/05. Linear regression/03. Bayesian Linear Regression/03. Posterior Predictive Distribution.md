## Distribuição Preditiva Posterior em Regressão Linear Bayesiana

### Introdução
Em regressão linear Bayesiana, além de estimar os parâmetros do modelo, é crucial quantificar a incerteza associada às previsões. A **distribuição preditiva posterior** fornece uma maneira de fazer isso, incorporando tanto a incerteza nos parâmetros do modelo quanto o ruído de observação. Este capítulo explora em detalhes a distribuição preditiva posterior em regressão linear Bayesiana, baseando-se no modelo de regressão linear definido em [^1].

### Conceitos Fundamentais

A distribuição preditiva posterior, denotada por $p(y|x, D, \sigma^2)$, representa a distribuição de probabilidade de uma nova observação *y* dado um novo ponto de entrada *x*, os dados de treinamento *D* e a variância do ruído $\sigma^2$. Essa distribuição é obtida integrando a função de verossimilhança sobre a distribuição posterior dos parâmetros do modelo [^1].

Formalmente, a distribuição preditiva posterior é dada por:

$$ p(y|x, D, \sigma^2) = \int N(y|x^T w, \sigma^2) N(w|w_N, V_N) dw $$

onde:
*   $N(y|x^T w, \sigma^2)$ é a função de verossimilhança, representando a probabilidade de *y* dado *x* e os parâmetros *w* e $\sigma^2$ [^1].
*   $N(w|w_N, V_N)$ é a distribuição posterior dos parâmetros *w*, com média $w_N$ e covariância $V_N$ [^1].

A integral acima resulta em uma distribuição Gaussiana [^1]:

$$ p(y|x, D, \sigma^2) = N(y|x^T w_N, \sigma^2(x)) $$

onde a variância $\sigma^2(x)$ é dada por:

$$ \sigma^2(x) = \sigma^2 + x^T V_N x $$

A variância $\sigma^2(x)$ possui duas componentes importantes [^1]:
1.  $\sigma^2$: Representa a variância do ruído de observação, inerente ao processo de medição ou à própria natureza dos dados.
2.  $x^T V_N x$: Representa a incerteza nos parâmetros do modelo *w*, refletida pela covariância posterior $V_N$. Essa incerteza é modulada pela entrada *x*, indicando que a incerteza preditiva pode variar dependendo da localização do ponto de entrada no espaço de características.

A inclusão da incerteza nos parâmetros é uma característica fundamental da abordagem Bayesiana, fornecendo uma estimativa mais realista da incerteza preditiva em comparação com métodos de estimativa de ponto, como a estimativa de máxima verossimilhança (MLE) [^1]. Em contraste com a aproximação *plug-in*, que utiliza uma estimativa pontual dos parâmetros para fazer previsões, a distribuição preditiva posterior integra sobre todas as possíveis configurações de parâmetros, ponderadas por sua probabilidade posterior.

### Conclusão

A distribuição preditiva posterior em regressão linear Bayesiana é uma ferramenta poderosa para quantificar a incerteza nas previsões, incorporando tanto o ruído de observação quanto a incerteza nos parâmetros do modelo. A variância da distribuição preditiva posterior depende tanto da variância do ruído quanto da incerteza nos parâmetros, proporcionando uma estimativa mais realista da incerteza preditiva. Essa abordagem é particularmente útil em aplicações como aprendizado ativo, onde a quantificação da incerteza é crucial para a seleção de pontos de dados informativos para treinamento.

### Referências
[^1]: Capítulo 7 do texto fornecido.
<!-- END -->