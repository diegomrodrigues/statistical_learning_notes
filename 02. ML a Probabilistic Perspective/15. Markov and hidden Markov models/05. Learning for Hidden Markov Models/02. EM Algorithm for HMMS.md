## O Algoritmo EM para HMMs: Baum-Welch

### Introdução
Este capítulo explora o algoritmo Expectation-Maximization (EM) aplicado a Hidden Markov Models (HMMs), conhecido como algoritmo de Baum-Welch, no contexto onde as variáveis de estado oculto $z_t$ não são observadas [^1]. Este cenário é análogo ao ajuste de modelos de mistura [^1]. O algoritmo de Baum-Welch é um método iterativo para encontrar estimativas de máxima verossimilhança (MLE) ou estimativas a posteriori máximas (MAP) dos parâmetros de um HMM quando os dados observacionais são incompletos ou possuem variáveis latentes [^6]. O algoritmo alterna entre um passo de Expectation (E), onde a função de log-verossimilhança esperada dos dados completos é computada, e um passo de Maximization (M), onde essa função é maximizada, normalizando as contagens esperadas para as matrizes de transição (A) e de estado inicial ($\pi$) e atualizando os parâmetros do modelo de observação (B) [^1].

### Conceitos Fundamentais

O algoritmo de Baum-Welch é uma aplicação específica do algoritmo EM para o caso de HMMs. Para entender o algoritmo, é crucial revisar os componentes de um HMM e a estrutura geral do algoritmo EM.

**Componentes de um HMM:**

*   **Estados Ocultos ($z_t$):** Uma sequência de variáveis aleatórias discretas, onde $z_t \in \{1, ..., K\}$ representa o estado em um instante de tempo *t* [^15].
*   **Observações ($x_t$):** Uma sequência de variáveis aleatórias que são emitidas a partir dos estados ocultos. As observações podem ser discretas ou contínuas [^16].
*   **Matriz de Transição (A):** Uma matriz *K x K* onde $A_{ij} = p(z_t = j | z_{t-1} = i)$ representa a probabilidade de transição do estado *i* para o estado *j* [^1]. Cada linha da matriz A soma 1, caracterizando uma matriz estocástica [^1].
*   **Distribuição Inicial ($\pi$):** Um vetor de tamanho *K* onde $\pi_i = p(z_1 = i)$ representa a probabilidade de o HMM iniciar no estado *i* [^1].
*   **Modelo de Observação (B):** Define a probabilidade de emitir uma observação $x_t$ dado o estado $z_t$. A forma de B depende do tipo de observação. Se as observações são discretas, B é uma matriz de observação onde $B_{kl} = p(x_t = l | z_t = k)$ [^16]. Se as observações são contínuas, B pode ser parametrizado por uma distribuição gaussiana condicional, $p(x_t | z_t = k, \theta) = N(x_t | \mu_k, \Sigma_k)$ [^16].

**Algoritmo EM para HMMs:**

O objetivo do algoritmo EM é encontrar os parâmetros $\theta = (\pi, A, B)$ que maximizam a verossimilhança dos dados observados $X = (x_1, ..., x_T)$ quando as variáveis de estado oculto $Z = (z_1, ..., z_T)$ são desconhecidas [^1]. O algoritmo EM itera entre os passos E e M até a convergência [^1].

*   **Passo E (Expectation):** Neste passo, calcula-se a função de log-verossimilhança esperada dos dados completos, dado os parâmetros atuais $\theta^{old}$ [^1]. Isso envolve calcular as probabilidades a posteriori das variáveis de estado oculto, dado as observações e os parâmetros atuais [^1]:

    $$Q(\theta, \theta^{old}) = \sum_Z p(Z | X, \theta^{old}) \log p(X, Z | \theta)$$

    Na prática, calcular essa soma diretamente é inviável devido ao número exponencial de possíveis sequências de estados. Em vez disso, utiliza-se o algoritmo forward-backward para calcular as probabilidades suavizadas de nós e arestas [^22]:

    *   $\gamma_{i,t}(j) = p(z_t = j | x_{1:T_i}, \theta)$ [^22]
    *   $\xi_{i,t}(j, k) = p(z_{t-1} = j, z_t = k | x_{1:T_i}, \theta)$ [^22]

    Essas probabilidades são usadas para calcular as contagens esperadas $E[N_k]$, $E[N_{jk}]$ e $E[N_j]$ [^30]:

    *   $E[N_k] = \sum_{i=1}^N p(z_{i1} = k | x_i, \theta^{old})$ [^30]
    *   $E[N_{jk}] = \sum_{i=1}^N \sum_{t=2}^{T_i} p(z_{i,t-1} = j, z_{i,t} = k | x_i, \theta^{old})$ [^30]
    *   $E[N_j] = \sum_{i=1}^N \sum_{t=1}^{T_i} p(z_{i,t} = j | x_i, \theta^{old})$ [^30]

*   **Passo M (Maximization):** Neste passo, os parâmetros $\theta$ são atualizados para maximizar a função $Q(\theta, \theta^{old})$ calculada no passo E [^1]. Isso envolve encontrar os valores de $\pi$, A e B que maximizam a verossimilhança esperada, dadas as contagens esperadas [^1].

    *   **Atualização de $\pi$:** A distribuição inicial é atualizada normalizando as contagens esperadas do primeiro estado [^30]:

        $$pi_k = \frac{E[N_k]}{N}$$

    *   **Atualização de A:** A matriz de transição é atualizada normalizando as contagens esperadas das transições entre estados [^30]:

        $$A_{jk} = \frac{E[N_{jk}]}{\sum_{k'} E[N_{jk'}]}$$

    *   **Atualização de B:** A atualização do modelo de observação B depende da forma da distribuição de observação. Se as observações são discretas, a matriz de observação é atualizada normalizando as contagens esperadas das emissões [^30]:

        $$B_{jl} = \frac{E[M_{jl}]}{E[N_j]}$$

        Onde $E[M_{jl}] = \sum_{i=1}^N \sum_{t:x_{i,t}=l}^{T_i} \gamma_{i,t}(j)$ [^31].

        Se as observações são contínuas e modeladas por gaussianas, as médias e covariâncias são atualizadas usando as contagens esperadas e as observações [^31]:

        $$mu_k = \frac{E[x_k]}{E[N_k]}$$

        $$Sigma_k = \frac{E[(xx)^T] - E[N_k] \mu_k \mu_k^T}{E[N_k]}$$
*   **Convergência:** Os passos E e M são repetidos até que a mudança na função de log-verossimilhança $Q(\theta, \theta^{old})$ seja menor que um limiar predefinido, indicando a convergência [^1].

### Conclusão

O algoritmo de Baum-Welch é uma ferramenta poderosa para aprender os parâmetros de HMMs quando os dados de estado oculto são desconhecidos [^1]. Ele permite modelar sequências complexas e descobrir padrões latentes nos dados [^16]. Embora o algoritmo garanta convergência para um máximo local da função de verossimilhança, a escolha de uma boa inicialização é crucial para evitar ficar preso em soluções subótimas [^32]. Além disso, existem métodos bayesianos para a estimação de parâmetros em HMMs que podem ser mais robustos e fornecer informações mais completas sobre a incerteza do modelo [^32].

### Referências
[^1]: Capítulo 17
[^6]: Capítulo 17
[^15]: Capítulo 17
[^16]: Capítulo 17
[^22]: Capítulo 17
[^30]: Capítulo 17
[^31]: Capítulo 17
[^32]: Capítulo 17
<!-- END -->