## Distribuição Limite em Cadeias de Markov

### Introdução
Este capítulo explora a condição de existência de uma distribuição limite em cadeias de Markov, um conceito fundamental na análise do comportamento assintótico desses modelos. O objetivo é fornecer uma compreensão rigorosa e detalhada das condições sob as quais uma cadeia de Markov converge para uma distribuição estacionária independente do estado inicial.

### Conceitos Fundamentais
Uma **cadeia de Markov** possui uma **distribuição limite** se a probabilidade de estar em um estado *j* após *n* passos, denotada por $\pi_j = \lim_{n \to \infty} A_{ij}^n$, existe e é independente do estado inicial *i* [^598]. Formalmente, isso significa que:

$$pi_j = \lim_{n \to \infty} A_{ij}^n$$

onde $A_{ij}^n$ representa o elemento *(i, j)* da matriz de transição *A* elevada à potência *n*. A existência dessa distribuição implica que, a longo prazo, a distribuição sobre os estados se torna independente do estado inicial [^598]:

$$P(X_t = j) = \sum_i P(X_0 = i) A_{ij}(t) \to \pi_j \text{ as } t \to \infty$$

Aqui, $P(X_t = j)$ é a probabilidade de estar no estado *j* no tempo *t*, e $P(X_0 = i)$ é a probabilidade inicial de estar no estado *i*. A convergência para $\pi_j$ indica que a cadeia "esquece" sua condição inicial à medida que o tempo tende ao infinito.

**Definição Formal:**

Uma cadeia de Markov tem uma distribuição limite se:

1.  O limite $\lim_{n \to \infty} A_{ij}^n$ existe para todo *i* e *j*.
2.  O limite é independente de *i*, ou seja, o valor do limite é o mesmo para qualquer estado inicial *i*.

**Teorema 17.2.1** [^598]: *Toda cadeia de Markov de estado finito irredutível (singularmente conectada) e aperiódica tem uma distribuição limite, que é igual a π, sua distribuição estacionária única.*

**Irredutibilidade:** Uma cadeia de Markov é **irredutível** se é possível alcançar qualquer estado a partir de qualquer outro estado em um número finito de passos [^598]. Em outras palavras, o diagrama de transição de estados deve ser uma componente singularmente conectada.

**Aperiodicidade:** Um estado *i* é **aperiódico** se o máximo divisor comum (gcd) dos tempos de retorno possíveis ao estado *i* é 1 [^598]. Formalmente:

$$d(i) = gcd\{t : A_{ii}(t) > 0\} = 1$$

Uma cadeia é aperiódica se todos os seus estados são aperiódicos. Uma condição suficiente (mas não necessária) para garantir a aperiodicidade é que cada estado tenha um *self-loop*.

**Regularidade:** Uma cadeia é **regular** se existe um inteiro *n* tal que $A_{ij}^n > 0$ para todo *i* e *j* [^598]. Isso significa que é possível ir de qualquer estado para qualquer outro estado em *n* passos. As condições suficientes para garantir a regularidade são que a cadeia seja irredutível e que cada estado tenha uma auto-transição.

**Distribuição Estacionária:** Uma distribuição $\pi$ é **estacionária** se satisfaz a equação $\pi = \pi A$ [^597], onde *A* é a matriz de transição. Isso significa que se a cadeia começa com a distribuição $\pi$, ela permanecerá em $\pi$ para sempre.

**Recorrência:** Um estado é **recorrente** se, partindo dele, a probabilidade de retornar a ele é 1 [^599]. Uma cadeia é recorrente se todos os seus estados são recorrentes.

**Teorema 17.2.2** [^599]: *Toda cadeia de Markov ergódica irredutível (singularmente conectada) tem uma distribuição limite, que é igual a π, sua distribuição estacionária única.*

**Ergodicidade:** Um estado é **ergódico** se é aperiódico, recorrente e *non-null*. Uma cadeia é ergódica se todos os seus estados são ergódicos.

**Detailed Balance:** Uma cadeia de Markov é **time reversible** se existe uma distribuição $\pi$ tal que $\pi_i A_{ij} = \pi_j A_{ji}$ [^599].

**Teorema 17.2.3** [^599]: *Se uma cadeia de Markov com matriz de transição A é regular e satisfaz detailed balance com relação à distribuição π, então π é uma distribuição estacionária da cadeia.*

### Conclusão
A existência de uma distribuição limite é crucial para a análise do comportamento a longo prazo de cadeias de Markov. As condições de irredutibilidade, aperiodicidade e recorrência garantem que a cadeia convirja para uma distribuição estacionária única, independente do estado inicial. A compreensão desses conceitos é essencial para a modelagem e análise de sistemas dinâmicos estocásticos em diversas áreas, como biologia computacional, processamento de linguagem natural e previsão de séries temporais [^589].

### Referências
[^589]: Chapter 17. Markov and hidden Markov models.
[^597]: 17.2. Markov models.
[^598]: 17.2. Markov models.
[^599]: 17.2. Markov models.
<!-- END -->