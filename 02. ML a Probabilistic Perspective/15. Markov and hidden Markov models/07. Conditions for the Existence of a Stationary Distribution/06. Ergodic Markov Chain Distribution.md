## Ergodicidade e Distribuições Limite em Cadeias de Markov

### Introdução
Este capítulo explora o conceito de **ergodicidade** em cadeias de Markov e sua relação com a existência de uma **distribuição limite**. Como veremos, a ergodicidade garante que a cadeia de Markov atinja um estado de equilíbrio estatístico, onde a distribuição de probabilidade dos estados se torna independente do estado inicial. Este conceito é crucial para entender o comportamento de longo prazo de cadeias de Markov e suas aplicações em diversas áreas [^1].

### Conceitos Fundamentais

**Estado Ergodico:** Um estado em uma cadeia de Markov é dito *ergódico* se ele for **aperiódico**, **recorrente** e **não-nulo** [^1]. Vamos detalhar cada um desses termos:
*   **Aperiodicidade:** Um estado *i* é dito aperiodic se o maior divisor comum (greatest common divisor - gcd) dos tempos de retorno possíveis a esse estado for 1 [^598]. Formalmente, $d(i) = gcd\{t: A_{ii}(t) > 0\} = 1$ [^598], onde $A_{ii}(t)$ é a probabilidade de retornar ao estado *i* em *t* passos. Em termos mais simples, não existe um padrão regular no qual o estado *i* é visitado.
*   **Recorrência:** Um estado *i* é *recorrente* se, partindo de *i*, a probabilidade de retornar a *i* em algum momento é 1 [^599]. Em outras palavras, a cadeia *sempre* retornará a esse estado eventualmente.
*   **Não-Nulidade:** Um estado *i* é *não-nulo* (non-null recurrent) se o tempo esperado para retornar a esse estado é finito [^599]. Isso significa que, embora a cadeia sempre retorne ao estado *i*, não leva um tempo infinito para fazê-lo.

**Cadeia de Markov Ergódica:** Uma cadeia de Markov é dita *ergódica* se *todos* os seus estados são ergódicos [^1].

**Distribuição Limite:** Uma cadeia de Markov tem uma *distribuição limite* se a probabilidade de estar em um estado *j* após *n* passos converge para um valor que é independente do estado inicial *i* [^598]. Formalmente, $\pi_j = \lim_{n \to \infty} A_{ij}(n)$ existe e é independente de *i* para todo *j* [^598].

**Distribuição Estacionária:** Uma distribuição $\pi$ é dita *estacionária* para uma cadeia de Markov com matriz de transição $A$ se $\pi = \pi A$ [^597]. Isso significa que, se a cadeia começa com a distribuição $\pi$, ela permanecerá nessa distribuição em todos os momentos futuros.

**Teorema Fundamental:** Uma cadeia de Markov *irredutível* (singly connected) e *ergódica* possui uma *distribuição limite* única, que é igual à sua *distribuição estacionária* única, denotada por $\pi$ [^1]. Este teorema é crucial porque garante a existência e unicidade de um estado de equilíbrio para cadeias de Markov ergódicas.

**Prova do Teorema 17.2.1:**
O teorema 17.2.1 afirma que toda cadeia de Markov de estado finito, *irredutível* e *aperiódica* tem uma distribuição limite, que é igual a sua distribuição estacionária única [^598]. Uma cadeia *regular* é aquela cuja matriz de transição $A$ satisfaz $A^n_{ij} > 0$ para algum inteiro $n$ e todos os $i, j$ [^598].

Uma cadeia regular tem uma distribuição estacionária única [^598].

*Prova:*
Seja $A$ uma matriz de transição regular. Então existe um $n$ tal que $A^n_{ij} > 0$ para todo $i, j$. Isso implica que a cadeia é irredutível (pois podemos ir de qualquer estado para qualquer outro em $n$ passos) e aperiodic (pois cada estado tem um self-loop após $n$ passos).

Como a cadeia é irredutível, existe uma única solução $\pi$ para a equação $\pi = \pi A$ (a distribuição estacionária) [^597].

Agora, considere a sequência de distribuições $\pi_t = \pi_0 A^t$, onde $\pi_0$ é a distribuição inicial. Como a cadeia é regular, $\lim_{t \to \infty} \pi_t = \pi$, independentemente de $\pi_0$. Portanto, a cadeia tem uma distribuição limite que é igual a sua distribuição estacionária única. $\blacksquare$

**Exemplo:**
Considere a cadeia de Markov de dois estados com matriz de transição
$$
A = \begin{pmatrix}
1-\alpha & \alpha \\
\beta & 1-\beta
\end{pmatrix}
$$
onde $0 < \alpha, \beta < 1$ [^590]. Esta cadeia é irredutível e aperiodic. A distribuição estacionária $\pi = (\pi_1, \pi_2)$ pode ser encontrada resolvendo o sistema de equações $\pi = \pi A$ e $\pi_1 + \pi_2 = 1$ [^597]. A solução é $\pi_1 = \frac{\beta}{\alpha + \beta}$ e $\pi_2 = \frac{\alpha}{\alpha + \beta}$. Como a cadeia é irredutível e aperiodic, ela também é ergodic, e sua distribuição limite é igual a $\pi$.

### Conclusão
A ergodicidade é uma propriedade fundamental de cadeias de Markov que garante a convergência para uma distribuição limite única. Este conceito é essencial para modelar sistemas dinâmicos que exibem comportamento de longo prazo previsível. O teorema que relaciona ergodicidade, irredutibilidade e a existência de uma distribuição limite fornece uma base teórica sólida para a análise e aplicação de cadeias de Markov em uma ampla gama de disciplinas.

### Referências
[^1]: Texto fornecido na questão.
[^590]: Capítulo 17, "Markov and hidden Markov models".
[^597]: Capítulo 17, "Markov and hidden Markov models".
[^598]: Capítulo 17, "Markov and hidden Markov models".
[^599]: Capítulo 17, "Markov and hidden Markov models".
<!-- END -->