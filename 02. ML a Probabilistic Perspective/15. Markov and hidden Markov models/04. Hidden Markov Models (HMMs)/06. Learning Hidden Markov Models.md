## Aprendizado em Hidden Markov Models (HMMs)

### Introdução

Este capítulo explora o aprendizado em **Hidden Markov Models (HMMs)**, um tópico fundamental em modelagem de sequências [^603]. Como vimos anteriormente, um HMM consiste em uma cadeia de Markov de tempo discreto com estados ocultos *zt* ∈ {1, ..., *K*} e um modelo de observação *p(xt|zt)* [^603, 604]. Nosso foco será em estimar os parâmetros *θ* = (*π*, *A*, *B*), onde *π(i)* é a distribuição do estado inicial, *A(i,j)* é a matriz de transição e *B* são os parâmetros das densidades condicionais à classe *p(xt | zt = j)* [^603]. Abordaremos dois cenários principais: o aprendizado com sequências de estados ocultos observadas e o aprendizado com estados ocultos não observados, onde o algoritmo Expectation-Maximization (EM), também conhecido como Baum-Welch, é empregado [^603]. Adicionalmente, exploraremos métodos bayesianos para a estimação de parâmetros em HMMs [^620].

### Conceitos Fundamentais

#### Estimativa de Máxima Verossimilhança (MLE) com Dados Completos

No cenário ideal em que as sequências de estados ocultos são observadas, a estimativa dos parâmetros *θ* torna-se direta [^603]. Podemos calcular as **MLEs (Maximum Likelihood Estimates)** para *π* e *A* de forma análoga à Seção 17.2.2.1 [^603, 592, 593].

A probabilidade de uma sequência particular de comprimento *T* é dada por [^592]:

$$
p(x_{1:T}|\theta) = \pi(x_1)A(x_1, x_2) \dots A(x_{T-1}, x_T) = \prod_{j=1}^{K} \pi_j^{I(x_1=j)} \prod_{t=2}^{T} \prod_{j=1}^{K} \prod_{k=1}^{K} A_{jk}^{I(x_t=k, x_{t-1}=j)}
$$

onde $I(\cdot)$ é a função indicadora. A log-verossimilhança para um conjunto de sequências $D = \{x_1, ..., x_N\}$, onde $x_i = (x_{i1}, \dots, x_{iT_i})$ é uma sequência de comprimento $T_i$, é dada por [^592]:

$$
\log p(D|\theta) = \sum_{i=1}^{N} \log p(x_i|\theta) = \sum_{j} N_j \log \pi_j + \sum_{j} \sum_{k} N_{jk} \log A_{jk}
$$

onde $N_j = \sum_{i=1}^{N} I(x_{i1} = j)$ e $N_{jk} = \sum_{i=1}^{N} \sum_{t=1}^{T_i-1} I(x_{i,t} = j, x_{i,t+1} = k)$ [^592].

As MLEs são então obtidas por [^593]:

$$
\hat{\pi}_j = \frac{N_j}{\sum_j N_j}, \quad \hat{A}_{jk} = \frac{N_{jk}}{\sum_k N_{jk}}
$$

A estimativa de *B* dependerá da forma do modelo de observação [^603]. Se cada estado tiver uma distribuição multinoulli associada, com parâmetros *Bjl* = *p(Xt = l | Zt = j)*, onde *l* ∈ {1, ..., *L*} representa o símbolo observado, a MLE é dada por [^617]:

$$
B_{jl} = \frac{N_{jl}}{N_j}
$$

onde *Njl* é o número de vezes que o símbolo *l* é observado no estado *j*, e *Nj* é o número total de vezes que o estado *j* é visitado [^617]. Se cada estado tiver uma distribuição Gaussiana associada, as MLEs para a média *μk* e a covariância *Σk* são dadas por [^618]:

$$
\mu_k = \frac{\sum_{i=1}^{N} \sum_{t=1}^{T_i} I(z_{i,t} = k) x_{i,t}}{N_k}, \quad \Sigma_k = \frac{\sum_{i=1}^{N} \sum_{t=1}^{T_i} I(z_{i,t} = k) (x_{i,t} - \mu_k)(x_{i,t} - \mu_k)^T}{N_k}
$$

#### Algoritmo EM (Baum-Welch) com Dados Incompletos

Quando as sequências de estados ocultos não são observadas, o algoritmo EM é usado para estimar os parâmetros *θ* [^603]. O algoritmo EM itera entre dois passos [^603]:

1.  **E-step (Expectation):** Calcula a expectativa da log-verossimilhança completa, dada a observação e a estimativa atual dos parâmetros *θold* [^618].
2.  **M-step (Maximization):** Encontra os parâmetros *θ* que maximizam a expectativa calculada no E-step [^618].

A função objetivo a ser maximizada é [^618]:

$$
Q(\theta, \theta^{old}) = \sum_{k=1}^{K} E[N_k] \log \pi_k + \sum_{j=1}^{K} \sum_{k=1}^{K} E[N_{jk}] \log A_{jk} + \sum_{i=1}^{N} \sum_{t=1}^{T_i} \sum_{k=1}^{K} p(z_{i,t} = k | x_i, \theta^{old}) \log p(x_{i,t} | k)
$$

onde *E[Nk]*, *E[Njk]* e *p(zi,t = k | xi, θold)* são calculados usando os algoritmos forwards-backwards [^618].

No **E-step**, as probabilidades smoothed node e edge são calculadas usando os algoritmos forwards-backwards [^619]:

$$
\gamma_{i,t}(j) = p(z_t = j | x_{i, 1:T_i}, \theta)
$$
$$
\xi_{i,t}(j, k) = p(z_{t-1} = j, z_t = k | x_{i, 1:T_i}, \theta)
$$

No **M-step**, as estimativas para *π*, *A* e *B* são atualizadas normalizando os expected counts [^619]:

$$
\hat{\pi}_k = \frac{E[N_k]}{N}
$$

$$
\hat{A}_{jk} = \frac{E[N_{jk}]}{\sum_{k'} E[N_{jk'}]}
$$

Para um modelo de observação multinoulli, a estimativa para *B* é [^619]:

$$
\hat{B}_{jl} = \frac{E[M_{jl}]}{E[N_j]}
$$

onde

$$
E[M_{jl}] = \sum_{i=1}^{N} \sum_{t=1}^{T_i} \gamma_{i,t}(j) I(x_{i,t} = l)
$$

Para um modelo de observação Gaussiano, as estimativas para *μk* e *Σk* são atualizadas como [^619]:

$$
\mu_k = \frac{E[x_k]}{E[N_k]}, \quad \Sigma_k = \frac{E[x x^T]_k - E[N_k] \mu_k \mu_k^T}{E[N_k]}
$$

onde

$$
E[x_k] = \sum_{i=1}^{N} \sum_{t=1}^{T_i} \gamma_{i,t}(k) x_{i,t}, \quad E[x x^T]_k = \sum_{i=1}^{N} \sum_{t=1}^{T_i} \gamma_{i,t}(k) x_{i,t} x_{i,t}^T
$$

É crucial inicializar os parâmetros cuidadosamente para evitar ficar preso em ótimos locais [^619]. Técnicas comuns incluem usar dados totalmente rotulados, ignorar as dependências de Markov inicialmente ou usar reinicializações aleatórias [^620].

#### Métodos Bayesianos para Estimativa de HMMs

Além da estimativa MAP via EM, métodos bayesianos oferecem uma abordagem mais completa para a estimação de parâmetros em HMMs [^620]. Esses métodos permitem incorporar conhecimento prévio e quantificar a incerteza sobre os parâmetros [^620].

Uma abordagem é usar o Variational Bayes EM (VBEM), onde o E-step usa o forwards-backwards com as médias posteriores dos parâmetros, e o M-step atualiza os parâmetros das distribuições conjugadas a posteriori [^620].

Outra abordagem é usar o MCMC (Markov Chain Monte Carlo), especificamente o Block Gibbs Sampling. Neste método, amostramos *z1:T* condicionalmente aos dados e aos parâmetros, usando forwards-filtering, backwards-sampling, e então amostramos os parâmetros de suas distribuições a posteriori, condicionalmente aos caminhos latentes amostrados [^620].

### Conclusão

Este capítulo apresentou os fundamentos do aprendizado em HMMs, abordando tanto o cenário com dados completos quanto o cenário com dados incompletos. O algoritmo EM (Baum-Welch) fornece uma abordagem iterativa para encontrar estimativas de máxima verossimilhança para os parâmetros do modelo quando as sequências de estados ocultos não são observadas. Além disso, métodos bayesianos oferecem uma estrutura mais flexível para incorporar conhecimento prévio e quantificar a incerteza sobre os parâmetros. Os métodos de aprendizado discutidos aqui são essenciais para aplicar HMMs em uma ampla gama de aplicações, como reconhecimento de fala, bioinformática e modelagem de séries temporais [^603, 605, 606].

### Referências

[^603]: Page 603, Chapter 17
[^604]: Page 604, Chapter 17
[^592]: Page 592, Chapter 17
[^593]: Page 593, Chapter 17
[^617]: Page 617, Chapter 17
[^618]: Page 618, Chapter 17
[^619]: Page 619, Chapter 17
[^620]: Page 620, Chapter 17
[^605]: Page 605, Chapter 17
[^606]: Page 606, Chapter 17
<!-- END -->