## Inferência em Modelos Ocultos de Markov (HMMs)

### Introdução
Este capítulo detalha os métodos de **inferência** em Modelos Ocultos de Markov (HMMs). A inferência em HMMs envolve a computação da sequência de estados ocultos, dado os dados observados [^1]. Existem diferentes tipos de inferência, incluindo *filtering*, *smoothing* e *MAP estimation* [^1].

### Conceitos Fundamentais

#### Tipos de Inferência
1.  **Filtering (Filtragem):** Envolve computar o estado de crença $p(z_t | x_{1:t})$ *online*, ou recursivamente, à medida que os dados chegam. Isso é feito aplicando a regra de Bayes de forma sequencial [^1]. O *filtering* é útil em aplicações onde é necessário estimar o estado atual do sistema em tempo real, como no rastreamento de objetos ou no reconhecimento de fala *online* [^1].

    O algoritmo *forwards* [^1] é usado para computar recursivamente as marginais filtradas, $p(z_t|x_{1:t})$ em um HMM. Este algoritmo possui dois passos:
    1.  **Predição:** Computa a densidade preditiva de um passo à frente, atuando como o novo *prior* para o tempo $t$ [^1]:
        $$p(z_t = j|x_{1:t-1}) = \sum_i p(z_t = j|z_{t-1} = i)p(z_{t-1} = i|x_{1:t-1}) \quad [^1]$$
    2.  **Atualização:** Absorve os dados observados do tempo $t$ usando a regra de Bayes [^1]:
        $$         \begin{aligned}         \alpha_t(j) &\triangleq p(z_t = j|x_{1:t}) = p(z_t = j|x_t, x_{1:t-1}) \quad [^1] \\         &= \frac{1}{Z_t} p(x_t|z_t = j, x_{1:t-1}) p(z_t = j|x_{1:t-1}) \quad [^1]         \end{aligned}         $$
        Onde $Z_t$ é a constante de normalização [^1]:
        $$Z_t \triangleq p(x_t|x_{1:t-1}) = \sum_j p(z_t = j|x_{1:t-1}) p(x_t|z_t = j) \quad [^1]$$
        Este processo é conhecido como ciclo predizer-atualizar [^1]. A distribuição $p(z_t|x_{1:t})$ é chamada de estado de crença (filtrado) no tempo $t$ [^1].

2.  **Smoothing (Suavização):** Envolve computar $p(z_t | x_{1:T})$ *offline*, dado toda a evidência [^1]. A *suavização* reduz a incerteza ao condicionar os dados passados e futuros. Isso permite uma estimativa mais precisa do estado em um determinado momento, considerando todo o contexto disponível [^1].

    O algoritmo *forwards-backwards* [^1] é usado para computar as marginais suavizadas, $p(z_t = j|x_{1:T})$ usando inferência *offline*. O algoritmo explora a decomposição da cadeia em duas partes, o passado e o futuro, condicionando em $z_t$ [^1]:
    $$p(z_t = j|x_{1:T}) \propto p(z_t = j, x_{t+1:T}|x_{1:t}) \propto p(z_t = j|x_{1:t})P(x_{t+1:T}|z_t = j,x_{1:t}) \quad [^1]$$
    Seja $\alpha_t(j) = p(z_t = j|x_{1:t})$ o estado de crença filtrado. Também, defina
    $$beta_t(j) \triangleq p(x_{t+1:T}|z_t = j) \quad [^1]$$
    como a verossimilhança condicional da evidência futura dado que o estado oculto no tempo $t$ é $j$. Finalmente, defina
    $$gamma_t(j) \triangleq p(z_t = j|x_{1:T}) \quad [^1]$$
    como a marginal posterior suavizada desejada. Da Equação anterior, temos
    $$gamma_t(j) \propto \alpha_t(j)\beta_t(j) \quad [^1]$$

3.  **MAP (Maximum A Posteriori) Estimation (Estimação MAP):** Envolve computar $\arg \max_{z_{1:T}} p(z_{1:T} | x_{1:T})$, que é a sequência de estados mais provável [^1]. Também é conhecido como *Viterbi decoding*. A estimação MAP é usada para encontrar a trajetória mais provável através dos estados ocultos, dada a sequência de observações [^1].

    O algoritmo de *Viterbi* [^1] pode ser usado para computar a sequência de estados mais provável em um modelo gráfico com estrutura de cadeia, i.e., computar
    $$z^* = \arg \max_{z_{1:T}} p(z_{1:T}|x_{1:T}) \quad [^1]$$
    Isto é equivalente a computar o caminho mais curto através do diagrama de *trellis*. Para maximizar sobre os caminhos que terminam em estado $j$ no tempo $t$, nós temos que maximizar sobre os caminhos para algum estado $i$ no tempo $t-1$, seguido por uma transição de $i$ para $j$ [^1]:
    $$delta_t(j) = \max_i \delta_{t-1}(i)\psi(i, j)\phi_t(j) \quad [^1]$$
    Nós também mantemos o controle do estado anterior mais provável para cada possível estado que terminamos em [^1]:
    $$a_t(j) = \arg \max_i \delta_{t-1}(i)\psi(i, j)\phi_t(j) \quad [^1]$$

#### Relação entre MAP e MPM
É importante notar que a sequência de estados *jointly* mais provável não é necessariamente a mesma que a sequência dos estados *marginally* mais prováveis [^1]. O primeiro é dado pela Equação anterior, e é o que o Viterbi computa, enquanto o último é dado pelo *maximizer of posterior marginals* (MPM) [^1]:
$$hat{z} = (\arg \max_{z_1} p(z_1|x_{1:T}), ..., \arg \max_{z_T} p(z_T|x_{1:T})) \quad [^1]$$
A vantagem da estimativa *joint* MAP é que é sempre globalmente consistente [^1].

### Conclusão
A inferência em HMMs é uma ferramenta poderosa para analisar sequências de dados, permitindo estimar os estados ocultos do sistema e fazer previsões sobre o futuro. Os métodos de *filtering*, *smoothing* e *MAP estimation* oferecem diferentes perspectivas sobre o problema, cada um com suas próprias vantagens e desvantagens. A escolha do método apropriado depende da aplicação específica e dos requisitos de tempo real.

### Referências
[^1]: Murphy, Kevin P. *Probabilistic Machine Learning: An Introduction*. MIT Press, 2022.
<!-- END -->