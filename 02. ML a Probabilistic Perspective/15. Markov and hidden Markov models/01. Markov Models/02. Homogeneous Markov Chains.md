## Homogeneous Markov Chains: Time Invariance and Parameter Tying

### Introdução
Este capítulo se aprofunda no estudo das **cadeias de Markov homogêneas**, também conhecidas como cadeias *estacionárias* ou *invariantes no tempo* [^1]. Como introduzido anteriormente, as cadeias de Markov são modelos probabilísticos para sequências de observações [^1]. Aqui, exploraremos como a propriedade de homogeneidade simplifica a modelagem e permite a representação de processos estocásticos com um número fixo de parâmetros [^1]. A homogeneidade, alcançada através do *parameter tying* [^1], implica que a função de transição não se altera com o tempo, um conceito fundamental para a aplicação de modelos de Markov em diversas áreas, como biologia computacional, processamento de linguagem natural e previsão de séries temporais [^1]. Em continuidade ao conceito de cadeias de Markov introduzido na seção 10.2.2 [^1], este capítulo detalha as implicações e aplicações da homogeneidade, fornecendo uma base sólida para a compreensão de modelos mais complexos, como os Modelos Ocultos de Markov (HMMs).

### Conceitos Fundamentais

**Definição de Cadeia de Markov Homogênea:**
Uma cadeia de Markov é dita homogênea (ou estacionária) se a probabilidade de transição de um estado para outro não depende do tempo [^1]. Matematicamente, isso significa que a função de transição $p(X_t | X_{t-1})$ é independente de *t* [^1]. Em outras palavras, a probabilidade de estar no estado *j* no tempo *t*, dado que estávamos no estado *i* no tempo *t-1*, é a mesma para todos os tempos *t*.

**Parameter Tying:**
A homogeneidade é alcançada através do *parameter tying*, onde os mesmos parâmetros são compartilhados entre múltiplas variáveis [^1]. Isso reduz significativamente o número de parâmetros necessários para modelar o processo estocástico, tornando o modelo mais tratável e menos propenso a *overfitting*.

**Representação Matricial:**
Quando os estados são discretos, $X_t \in \{1, ..., K\}$ [^1], a função de transição $p(X_t | X_{t-1})$ pode ser representada por uma matriz *K x K* chamada **matriz de transição**, denotada por **A** [^1]. O elemento $A_{ij}$ da matriz **A** representa a probabilidade de transição do estado *i* para o estado *j*, ou seja, $A_{ij} = p(X_t = j | X_{t-1} = i)$ [^1]. Cada linha da matriz de transição soma 1, refletindo o fato de que, a partir de um determinado estado, o sistema deve se mover para algum outro estado com probabilidade 1: $\sum_{j} A_{ij} = 1$ [^1]. Uma matriz com essa propriedade é chamada de **matriz estocástica** [^1].

**Exemplo:**
Considere uma cadeia de Markov com dois estados, representada pelo diagrama de estados na Figura 17.1(a) [^2]. A matriz de transição correspondente é dada por:
$$ A = \begin{pmatrix} 1 - \alpha & \alpha \\ \beta & 1 - \beta \end{pmatrix} $$
onde $\alpha$ é a probabilidade de transição do estado 1 para o estado 2, e $\beta$ é a probabilidade de transição do estado 2 para o estado 1 [^2].

**n-step Transition Matrix:**
A probabilidade de transição de um estado *i* para um estado *j* em *n* passos é dada pelo elemento $A_{ij}(n)$ da **n-step transition matrix** $A(n)$ [^2], definida como:
$$ A_{ij}(n) = p(X_{t+n} = j | X_t = i) $$
A **Chapman-Kolmogorov equation** [^2] permite calcular $A_{ij}(m + n)$ [^2] a partir de $A(m)$ e $A(n)$ [^2]:
$$ A_{ij}(m + n) = \sum_{k=1}^{K} A_{ik}(m) A_{kj}(n) $$
Em notação matricial:
$$ A(m + n) = A(m) A(n) $$
Daí,
$$ A(n) = A^n $$
Isso significa que a matriz de transição de *n* passos pode ser obtida elevando-se a matriz de transição **A** à potência *n* [^2].

**Estado Estacionário:**

Uma das propriedades importantes das cadeias de Markov homogêneas é a existência de uma **distribuição estacionária** $\pi$, que representa a distribuição de probabilidade dos estados após um longo período de tempo [^8]. Formalmente, $\pi$ é um vetor linha tal que:

$$pi = \pi A$$

Isso significa que, se a distribuição inicial dos estados for $\pi$, a distribuição dos estados permanecerá $\pi$ em todos os tempos futuros. Para encontrar a distribuição estacionária, podemos resolver o sistema de equações lineares $\pi = \pi A$ sujeito à restrição $\sum_i \pi_i = 1$ [^9].

### Conclusão

As cadeias de Markov homogêneas fornecem uma estrutura poderosa e flexível para modelar processos estocásticos sequenciais [^1]. A propriedade de homogeneidade, implementada através do *parameter tying*, simplifica a modelagem e permite a representação de sistemas complexos com um número gerenciável de parâmetros [^1]. A representação matricial e as equações de Chapman-Kolmogorov facilitam a análise e a simulação dessas cadeias, enquanto a existência de uma distribuição estacionária fornece informações importantes sobre o comportamento a longo prazo do sistema [^2, 8]. A compreensão detalhada das cadeias de Markov homogêneas é fundamental para o estudo de modelos mais avançados, como os Modelos Ocultos de Markov (HMMs), que exploraremos em capítulos subsequentes [^1].

### Referências
[^1]: Capítulo 17, Markov and hidden Markov models, página 587.
[^2]: Capítulo 17, Markov and hidden Markov models, página 588.
[^8]: Capítulo 17, Markov and hidden Markov models, página 596.
[^9]: Capítulo 17, Markov and hidden Markov models, página 597.
<!-- END -->