## Maximum Likelihood Estimation (MLE) para Modelos de Markov

### Introdução
Este capítulo explora o uso da **Maximum Likelihood Estimation (MLE)** na estimação da matriz de transição em Modelos de Markov, com foco em técnicas para lidar com o problema de *zero-counts* [^1]. Modelos de Markov são modelos probabilísticos para sequências de observações [^2], como em processamento de linguagem natural [^2], e a MLE é um método fundamental para aprender os parâmetros desses modelos a partir de dados.

### Conceitos Fundamentais

#### Modelos de Markov e Matriz de Transição
Um **Modelo de Markov** assume que o estado atual, $X_t$, captura toda a informação relevante para prever o futuro [^2]. Em outras palavras, o futuro é independente do passado dado o presente. Se os estados são discretos, $X_t \in \{1, ..., K\}$, a distribuição condicional $p(X_t | X_{t-1})$ pode ser representada por uma **matriz de transição** **A**, onde $A_{ij} = p(X_t = j | X_{t-1} = i)$ é a probabilidade de transitar do estado *i* para o estado *j* [^2]. Cada linha da matriz **A** soma 1, tornando-a uma **matriz estocástica** [^2].  A matriz de transição **A** define completamente a dinâmica do Modelo de Markov.

#### Maximum Likelihood Estimation (MLE)
A **Maximum Likelihood Estimation (MLE)** é um método para estimar os parâmetros de um modelo estatístico maximizando a função de *likelihood*, que representa a probabilidade dos dados observados dado o modelo e seus parâmetros [^1]. No contexto de Modelos de Markov, o objetivo é estimar a matriz de transição **A** a partir de dados de treinamento.

Dado um conjunto de sequências de treinamento, podemos calcular as contagens normalizadas de transições entre estados [^1]. Sejam $N_j$ o número de ocorrências iniciais do estado *j* e $N_{jk}$ o número de transições do estado *j* para o estado *k* [^1]. Então, as estimativas de MLE para as probabilidades de estado inicial e para as probabilidades de transição são dadas por [^1]:

$$ \hat{\pi}_j = \frac{N_j}{\sum_j N_j} $$

$$ \hat{A}_{jk} = \frac{N_{jk}}{\sum_k N_{jk}} $$

onde $\hat{\pi}_j$ é a estimativa de MLE para a probabilidade do estado inicial *j* e $\hat{A}_{jk}$ é a estimativa de MLE para a probabilidade de transição do estado *j* para o estado *k* [^1].

A probabilidade de uma sequência particular de comprimento *T* é dada por [^4]:
$$ p(x_{1:T}|\theta) = \pi(x_1)A(x_1, x_2) \dots A(x_{T-1}, x_T) $$
$$ p(x_{1:T}|\theta) = \prod_{j=1}^{K} (\pi_j)^{\mathbb{I}(x_1=j)} \prod_{t=2}^{T} \prod_{j=1}^{K} \prod_{k=1}^{K} (A_{jk})^{\mathbb{I}(x_t=k, x_{t-1}=j)} $$
onde $\mathbb{I}$ é a função indicadora.

O log-likelihood de um conjunto de *N* sequências é [^4]:
$$ \log p(\mathcal{D}|\theta) = \sum_{i=1}^{N} \log p(x_i|\theta) = \sum_{j} N_j \log \pi_j + \sum_{j} \sum_{k} N_{jk} \log A_{jk} $$

#### O Problema de Zero-Counts
Um problema comum com a MLE é o problema de *zero-counts*, que ocorre quando uma transição particular nunca é observada nos dados de treinamento, resultando em uma probabilidade estimada de zero [^1]. Isso pode ser problemático, especialmente com grandes espaços de estados, pois pode levar a *overfitting* [^5]. Por exemplo, se $N_{jk} = 0$ para algum par (j, k), então $\hat{A}_{jk} = 0$, o que significa que a transição do estado *j* para o estado *k* é considerada impossível pelo modelo, mesmo que essa transição possa ser possível na realidade [^5].

#### Técnicas de Smoothing
Para lidar com o problema de *zero-counts*, várias técnicas de *smoothing* são usadas para ajustar as estimativas de MLE e evitar probabilidades de zero [^1]. Uma técnica simples é o **add-one smoothing**, onde adicionamos um a todas as contagens empíricas antes de normalizar [^5]. A justificativa Bayesiana para isso é dada na Seção 3.3.4.1 [^5]. No entanto, o add-one smoothing assume que todos os n-gramas são igualmente prováveis, o que não é realista [^5].

Uma abordagem mais sofisticada é o **deleted interpolation**, que define a matriz de transição como uma combinação convexa das frequências de bigramas e unigramas [^6]:

$$ A_{jk} = (1 - \lambda) f_{jk} + \lambda f_k $$

onde $f_{jk} = N_{jk} / N_j$ são as frequências de bigramas, $f_k = N_k / N$ são as frequências de unigramas e $\lambda$ é um parâmetro de interpolação [^6]. O termo $\lambda$ é geralmente definido por validação cruzada [^6]. Existe também uma técnica intimamente relacionada chamada *backoff smoothing* [^6]; a ideia é que, se $f_{jk}$ for muito pequeno, "recuamos" para uma estimativa mais confiável, ou seja, $f_k$ [^6].

Outra abordagem é usar **priors Bayesianos** para regularizar as estimativas de MLE. Por exemplo, podemos usar um prior de Dirichlet independente em cada linha da matriz de transição [^6]:

$$ A_j \sim Dir(\alpha_0 m_1, \dots, \alpha_0 m_K) = Dir(\alpha_0 \mathbf{m}) = Dir(\alpha) $$

onde $A_j$ é a linha *j* da matriz de transição, $\mathbf{m}$ é a média *a priori* (satisfazendo $\sum_k m_k = 1$) e $\alpha_0$ é a força *a priori* [^6]. A *posteriori* é dada por [^6]:

$$ A_j \sim Dir(\alpha + N_j) $$

onde $N_j = (N_{j1}, \dots, N_{jK})$ é o vetor que registra o número de vezes que transitamos do estado *j* para cada um dos outros estados [^6].

A densidade preditiva *posteriori* é [^6]:

$$ p(X_{t+1} = k | X_t = j, \mathcal{D}) = \hat{A}_{jk} = \frac{N_{jk} + \alpha m_k}{N_j + \alpha_0} = (1 - \lambda_j) f_{jk} + \lambda_j m_k $$

onde $\lambda_j = \frac{\alpha}{N_j + \alpha_0}$ [^6].

### Conclusão
A Maximum Likelihood Estimation (MLE) é um método fundamental para estimar as matrizes de transição em Modelos de Markov [^1]. No entanto, o problema de *zero-counts* pode levar a estimativas ruins, especialmente com grandes espaços de estados [^1]. Técnicas de *smoothing*, como *add-one smoothing* e *deleted interpolation*, podem ser usadas para lidar com esse problema [^1]. Além disso, priors Bayesianos podem ser usados para regularizar as estimativas de MLE e melhorar o desempenho do modelo [^6].

### Referências
[^1]: Texto fornecido.
[^2]: Seção 17.2, "Markov models".
[^4]: Seção 17.2.2.1, "MLE for Markov language models".
[^5]: Seção 17.2, "Markov models".
[^6]: Seção 17.2.2.2, "Empirical Bayes version of deleted interpolation".
<!-- END -->