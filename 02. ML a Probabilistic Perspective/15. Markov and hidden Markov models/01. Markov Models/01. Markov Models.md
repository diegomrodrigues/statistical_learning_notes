## Markov Models: Uma Análise Detalhada

### Introdução
Este capítulo explora em profundidade os **Modelos de Markov** (*Markov Models*), que são modelos probabilísticos para sequências de observações. A característica fundamental desses modelos é a propriedade de Markov, onde o estado futuro depende apenas do estado atual [^1]. Esta propriedade simplifica significativamente a distribuição conjunta de uma sequência de estados, tornando o estado atual uma *estatística suficiente* para a predição [^1].

Como mencionado na Seção 10.2.2 [^1], a ideia central por trás de uma cadeia de Markov é que $X_t$ captura toda a informação relevante para prever o futuro. Este capítulo se baseará nessa premissa, aprofundando-se nas implicações e aplicações dos Modelos de Markov.

### Conceitos Fundamentais

A **propriedade de Markov** é matematicamente expressa como [^1]:
$$
p(X_{1:T}) = p(X_1) \prod_{t=2}^{T} p(X_t | X_{t-1})
$$
onde $X_{1:T}$ representa a sequência de estados de 1 até $T$, $p(X_1)$ é a distribuição inicial, e $p(X_t | X_{t-1})$ é a probabilidade de transição do estado $X_{t-1}$ para o estado $X_t$.

Quando os *time steps* são discretos, a distribuição conjunta pode ser escrita como [^1]:
$$
p(X_{1:T}) = p(X_1)p(X_2|X_1)p(X_3|X_2)... = p(X_1) \prod_{t=2}^{T} p(X_t|X_{t-1})
$$
Este modelo é conhecido como **cadeia de Markov** ou **modelo de Markov** [^1].

Se a função de transição $p(X_t|X_{t-1})$ é independente do tempo, a cadeia é chamada **homogênea**, **estacionária** ou **time-invariant** [^1]. Isso é um exemplo de **parameter tying**, uma vez que o mesmo parâmetro é compartilhado por múltiplas variáveis [^1]. Esta suposição permite modelar um número arbitrário de variáveis usando um número fixo de parâmetros; tais modelos são chamados **processos estocásticos** [^1].

Quando as variáveis observadas são discretas, ou seja, $X_t \in \{1, ..., K\}$, o modelo é chamado **cadeia de Markov de estado discreto** ou **cadeia de Markov de estado finito** [^1]. A distribuição condicional $p(X_t|X_{t-1})$ pode ser escrita como uma matriz $K \times K$, conhecida como **matriz de transição** **A**, onde $A_{ij} = p(X_t = j | X_{t-1} = i)$ é a probabilidade de ir do estado *i* para o estado *j* [^1]. Cada linha da matriz soma 1, $\sum_j A_{ij} = 1$, portanto, é chamada de **matriz estocástica** [^1].

**Visualização:** Uma cadeia de Markov estacionária e de estado finito é equivalente a um **autômato estocástico** [^2]. É comum visualizar tais autômatos por meio de um grafo direcionado, onde os nós representam estados e as setas representam transições legais, ou seja, elementos não-zero de **A**. Isso é conhecido como um **diagrama de transição de estados** [^2]. Os pesos associados aos arcos são as probabilidades [^2].

**n-step Transition Matrix:** O elemento $A_{ij}$ da matriz de transição especifica a probabilidade de ir de *i* para *j* em um passo. A **matriz de transição de *n* passos** $A(n)$ é definida como [^2]:
$$
A_{ij}(n) = p(X_{t+n} = j | X_t = i)
$$
que é a probabilidade de ir de *i* para *j* em exatamente *n* passos. Obviamente, $A(1) = A$. As **equações de Chapman-Kolmogorov** afirmam que [^2]:
$$
A_{ij}(m + n) = \sum_{k=1}^{K} A_{ik}(m) A_{kj}(n)
$$
Em palavras, a probabilidade de ir de *i* para *j* em *m + n* passos é a probabilidade de ir de *i* para *k* em *m* passos, e então de *k* para *j* em *n* passos, somado sobre todos os *k*. Podemos escrever o acima como uma multiplicação de matrizes [^2]:
$$
A(m + n) = A(m)A(n)
$$
Portanto [^2]:
$$
A(n) = A A(n - 1) = A A A(n - 2) = ... = A^n
$$
Assim, podemos simular múltiplos passos de uma cadeia de Markov "elevando ao quadrado" a matriz de transição [^2].

### Conclusão

Os Modelos de Markov fornecem uma estrutura poderosa e flexível para modelar sequências de observações. A propriedade de Markov, juntamente com conceitos como matrizes de transição, diagramas de estado e equações de Chapman-Kolmogorov, permitem a análise e predição de sistemas dinâmicos com dependências temporais. As aplicações dos Modelos de Markov são vastas e incluem áreas como biologia computacional, processamento de linguagem natural e previsão de séries temporais [^1]. A capacidade de modelar dependências sequenciais de forma eficiente e a interpretabilidade dos parâmetros tornam os Modelos de Markov uma ferramenta valiosa para modelagem e análise de dados.

### Referências
[^1]: Page 1, Markov and hidden Markov models, Chapter 17
[^2]: Page 2, Markov and hidden Markov models, Chapter 17
<!-- END -->