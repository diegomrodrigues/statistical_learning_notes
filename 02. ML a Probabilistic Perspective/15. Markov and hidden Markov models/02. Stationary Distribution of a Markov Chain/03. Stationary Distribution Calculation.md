## Métodos para Determinação da Distribuição Estacionária em Cadeias de Markov

### Introdução
A determinação da **distribuição estacionária** ($\pi$) de uma **cadeia de Markov** é um problema fundamental em diversas áreas, desde a modelagem de sistemas físicos até a análise de algoritmos [^596]. A distribuição estacionária, também conhecida como *distribuição invariante* ou *distribuição de equilíbrio* [^597], representa a distribuição de probabilidade para a qual a cadeia converge a longo prazo, independentemente da distribuição inicial [^597]. Este capítulo explora diferentes métodos para calcular $\pi$, detalhando as bases teóricas e as implicações práticas de cada abordagem.

### Conceitos Fundamentais

Antes de mergulharmos nos métodos de cálculo, é crucial relembrar alguns conceitos já introduzidos. Uma **cadeia de Markov** é um processo estocástico que satisfaz a *propriedade de Markov*, ou seja, o estado futuro depende apenas do estado presente, e não do histórico passado [^590, 596]. Uma cadeia de Markov é dita **homogênea**, **estacionária** ou *time-invariant* se a função de transição $p(X_t|X_{t-1})$ é independente do tempo [^589]. Quando os estados são discretos, a transição entre estados pode ser representada por uma **matriz de transição** $A$, onde $A_{ij} = p(X_t = j | X_{t-1} = i)$ representa a probabilidade de transitar do estado $i$ para o estado $j$ [^589]. A matriz $A$ é uma **matriz estocástica**, pois cada linha soma 1, ou seja, $\sum_j A_{ij} = 1$ [^589].

A *n-step transition matrix* $A(n)$ é definida como $A_{ij}(n) = p(X_{t+n} = j | X_t = i)$ [^590], que é a probabilidade de ir do estado $i$ para o estado $j$ em exatamente $n$ passos. As equações de **Chapman-Kolmogorov** [^590] estabelecem que $A(m+n) = A(m)A(n)$ [^590], e, portanto, $A(n) = A^n$ [^590]. Isso permite simular múltiplos passos de uma cadeia de Markov elevando a matriz de transição à potência apropriada [^590].

A **distribuição estacionária** $\pi$ é definida como uma distribuição que satisfaz a equação $\pi = \pi A$ [^597], ou seja, uma vez que a cadeia atinge essa distribuição, ela permanece inalterada ao longo do tempo [^597]. Para que uma cadeia de Markov possua uma distribuição estacionária única, ela deve ser **irreducível** (singly connected), significando que é possível alcançar qualquer estado a partir de qualquer outro estado [^598], e **aperiódica**, significando que não há um padrão cíclico nos retornos a um determinado estado [^598]. Uma cadeia **ergódica** é aquela que é aperiódica, recorrente e *non-null* [^599]. O **Teorema 17.2.2** [^599] afirma que toda cadeia de Markov ergódica e irreducível possui uma distribuição limitante, que é igual à sua distribuição estacionária única.

### Métodos de Cálculo da Distribuição Estacionária

Existem diferentes abordagens para calcular a distribuição estacionária $\pi$. Apresentaremos duas delas:

1.  **Solução da Equação de Autovetor:** [^597]
    Este método se baseia na propriedade de que $\pi$ é um autovetor da matriz de transição $A$ associado ao autovalor 1. Matematicamente, isso se expressa como:

    $$A^T v = v$$

    onde $v$ é o autovetor correspondente ao autovalor 1. Para obter a distribuição estacionária $\pi$, normalizamos $v$ para que seus elementos somem 1:

    $$pi = v^T$$

    Este método é direto e eficiente quando a matriz $A$ é pequena e os autovalores e autovetores podem ser calculados analiticamente ou numericamente. No entanto, para cadeias de Markov com um grande número de estados, o cálculo de autovetores pode se tornar computacionalmente caro.

2.  **Solução do Sistema Linear:** [^597]
    Uma abordagem mais geral envolve a solução de um sistema linear derivado da equação $\pi = \pi A$. Rearranjando, obtemos:

    $$pi(I - A) = 0$$

    onde $I$ é a matriz identidade. Adicionamos a restrição de que os elementos de $\pi$ devem somar 1:

    $$pi 1_{K \times 1} = 1$$

    onde $1_{K \times 1}$ é um vetor coluna de uns de dimensão $K$, sendo $K$ o número de estados. Como o sistema é *overconstrained*, substituímos uma das colunas de $(I - A)$ por um vetor de uns para obter uma nova matriz $M$. Definimos um vetor $r = [0, 0, ..., 1]$, onde o 1 está na última posição, correspondendo à coluna substituída. Resolvemos então o sistema linear:

    $$pi M = r$$

    Este sistema pode ser resolvido utilizando métodos numéricos padrão, como eliminação de Gauss ou decomposição LU. Este método é mais robusto que o método do autovetor, especialmente para cadeias com probabilidades de transição nulas, que podem levar a autovetores complexos [^597].

    Para uma cadeia de 3 estados [^597], o sistema linear a ser resolvido é:

    $$\     (\pi_1 \\ \pi_2 \\ \pi_3)\     \begin{pmatrix}\     1-A_{11} & -A_{12} & 1 \\\\\     -A_{21} & 1-A_{22} & 1 \\\\\     -A_{31} & -A_{32} & 1\     \end{pmatrix}\     = (0 \\ 0 \\ 1)\     $$

### Conclusão

A determinação da distribuição estacionária é um passo crucial na análise de cadeias de Markov, permitindo a compreensão do comportamento do sistema a longo prazo. Os métodos apresentados, incluindo a solução da equação de autovetor e a solução do sistema linear, oferecem diferentes abordagens com suas próprias vantagens e desvantagens. A escolha do método mais adequado depende das características específicas da cadeia de Markov, como o número de estados e a estrutura da matriz de transição.

### Referências
[^589]: Seção 17.2.1, "Transition matrix"
[^590]: Página 590, "Chapter 17. Markov and hidden Markov models"
[^596]: Seção 17.2.3, "Stationary distribution of a Markov chain *"
[^597]: Seção 17.2.3.2, "Computing the stationary distribution"
[^598]: Seção 17.2.3.3, "When does a stationary distribution exist? *"
[^599]: Seção 17.2.3.4, "Detailed balance"
<!-- END -->