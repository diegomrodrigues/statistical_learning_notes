## Conditional Independence Assumptions in Graphical Models

### Introdução
Em modelos gráficos, a representação eficiente de distribuições conjuntas complexas é uma tarefa fundamental. Uma das chaves para essa eficiência reside na exploração de **assunções de independência condicional (CI)** [^308]. Este capítulo explora o conceito de independência condicional e como essas assunções podem ser utilizadas para simplificar a representação e inferência em modelos gráficos direcionados (DGMs), também conhecidos como redes Bayesianas [^309].

### Conceitos Fundamentais

**Independência Condicional (CI)**
Formalmente, duas variáveis aleatórias $X$ e $Y$ são condicionalmente independentes dado $Z$, denotado por $X \perp Y | Z$, se e somente se a distribuição conjunta condicional pode ser fatorada como um produto de distribuições marginais condicionais [^308]:
$$
X \perp Y | Z \Leftrightarrow p(X, Y | Z) = p(X | Z)p(Y | Z)
$$
Esta definição implica que, uma vez que o valor de $Z$ é conhecido, o conhecimento de $Y$ não fornece informações adicionais sobre $X$, e vice-versa [^308].

**Representação Compacta de Distribuições Conjuntas**

A importância das assunções de independência condicional reside na sua capacidade de simplificar a representação de distribuições conjuntas [^308]. Sem essas assunções, a representação da distribuição conjunta de $V$ variáveis discretas, cada uma com $K$ estados, requereria $O(K^V)$ parâmetros [^308]. No entanto, ao identificar e explorar as independências condicionais, é possível fatorar a distribuição conjunta em um produto de distribuições condicionais menores, reduzindo significativamente o número de parâmetros necessários [^308].

**Exemplo: Cadeia de Markov**

Um exemplo clássico é a cadeia de Markov de primeira ordem [^308]. Nesta estrutura, assume-se que o futuro é independente do passado, dado o presente. Formalmente, $X_{t+1} \perp X_{1:t-1} | X_t$.  Usando essa assunção e a regra da cadeia, a distribuição conjunta pode ser escrita como [^308]:
$$
p(x_{1:V}) = p(x_1) \prod_{t=2}^{V} p(x_t | x_{t-1})
$$
Neste caso, a distribuição conjunta é representada por uma distribuição inicial $p(x_1)$ e uma matriz de transição de estados $p(x_t | x_{t-1})$ [^308]. Se cada variável $x_t$ possui $K$ estados, a representação requer $O(K^2)$ parâmetros, em vez de $O(K^V)$ [^308].

**Modelos Gráficos e Independência Condicional**

Modelos gráficos, como os DGMs, utilizam grafos para representar as relações de dependência e independência entre variáveis aleatórias [^308]. Os nós do grafo representam as variáveis, e a ausência de arestas indica assunções de independência condicional. Em particular, a **estrutura do grafo codifica as assunções de CI** que são utilizadas para fatorar a distribuição conjunta [^308].

**A Propriedade de Markov Ordenada**

Para DGMs, a propriedade de Markov ordenada estabelece que um nó é condicionalmente independente de seus predecessores (em uma ordenação topológica) dados seus pais [^308, 310]. Matematicamente, isso é expresso como:

$$
X_s \perp X_{pred(s)} \setminus X_{pa(s)} | X_{pa(s)}
$$

onde $pred(s)$ denota os predecessores do nó $s$ e $pa(s)$ denota os pais do nó $s$ [^310].

**d-separação**

Um critério gráfico importante para determinar a independência condicional em DGMs é a **d-separação** [^324]. Dois conjuntos de nós $A$ e $B$ são d-separados dado um conjunto $E$ se todos os caminhos não direcionados entre $A$ e $B$ são "bloqueados" por $E$. Um caminho é bloqueado se contém [^324]:

1.  Uma cadeia $s \rightarrow m \rightarrow t$ ou $s \leftarrow m \leftarrow t$, onde $m \in E$ [^324].
2.  Um garfo $s \leftarrow m \rightarrow t$, onde $m \in E$ [^324].
3.  Um colisor $s \rightarrow m \leftarrow t$, onde $m \notin E$ e nenhum descendente de $m$ pertence a $E$ [^324].

Se $A$ e $B$ são d-separados dado $E$, então $X_A \perp X_B | X_E$ [^324].

**Explicando a d-separação**

A d-separação é uma ferramenta crucial para identificar independências condicionais a partir da estrutura do grafo. Ela permite determinar quais variáveis são independentes dado o conhecimento de outras, sem a necessidade de calcular explicitamente as distribuições condicionais [^324].

**Markov Blanket**

O **Markov blanket** de um nó $t$ em um DGM é o conjunto de nós que torna $t$ condicionalmente independente de todos os outros nós no grafo [^327]. Este conjunto consiste nos pais de $t$, os filhos de $t$ e os co-pais de $t$ (outros pais dos filhos de $t$) [^327, 328].

### Conclusão

As assunções de independência condicional são fundamentais para a representação e manipulação eficiente de distribuições conjuntas em modelos gráficos [^308]. Através da exploração dessas independências, é possível fatorar a distribuição conjunta em componentes menores e mais tratáveis, reduzindo a complexidade computacional e permitindo a inferência em problemas de grande escala [^308]. O conceito de d-separação fornece um critério gráfico para identificar essas independências, tornando os modelos gráficos uma ferramenta poderosa para modelagem probabilística [^324].

### Referências
[^308]: Chapter 10. Directed graphical models (Bayes nets), p. 308
[^309]: Chapter 10. Directed graphical models (Bayes nets), p. 309
[^310]: Chapter 10. Directed graphical models (Bayes nets), p. 310
[^324]: Chapter 10. Directed graphical models (Bayes nets), p. 324
[^327]: Chapter 10. Directed graphical models (Bayes nets), p. 327
[^328]: Chapter 10. Directed graphical models (Bayes nets), p. 328
<!-- END -->