## Aprofundando na Assunção de Markov e Cadeias de Markov

### Introdução
Este capítulo se aprofunda na **assunção de Markov**, um conceito crucial na simplificação de modelos gráficos e na modelagem de sequências temporais. A assunção de Markov, como veremos, é um tipo específico de independência condicional que possibilita a representação eficiente de distribuições conjuntas complexas. Este capítulo explora a assunção de Markov e suas implicações, culminando no conceito de **cadeias de Markov**.

### Conceitos Fundamentais

A **assunção de Markov** postula que *o futuro é independente do passado, dado o presente* [^2]. Formalmente, isso é expresso como:

$$x_{t+1} \perp X_{1:t-1} | x_t$$

onde $x_{t+1}$ representa o estado no tempo $t+1$, $X_{1:t-1}$ representa a sequência de estados do tempo $1$ até $t-1$, e $x_t$ representa o estado no tempo $t$ [^2]. Em outras palavras, para prever o próximo estado, apenas o estado atual é relevante; informações sobre estados anteriores não fornecem informações adicionais.

Essa assunção simplifica drasticamente a representação da distribuição conjunta [^2]. Sem a assunção de Markov, a distribuição conjunta de uma sequência de $V$ variáveis seria:

$$p(x_{1:V}) = p(x_1)p(x_2|x_1)p(x_3|x_1,x_2)p(x_4|x_1,x_2,x_3)...p(x_V|x_{1:V-1})$$

onde $p(x_t|x_{1:t-1})$ torna-se cada vez mais complexo à medida que $t$ aumenta [^1]. Com a assunção de Markov, essa distribuição conjunta se torna:

$$p(x_{1:V}) = p(x_1) \prod_{t=1}^{V} p(x_t|x_{t-1})$$

Essa simplificação leva ao conceito de **cadeias de Markov** [^2]. Uma cadeia de Markov de primeira ordem é caracterizada por duas componentes principais [^2]:

1.  Uma **distribuição inicial** sobre estados: $p(x_1 = i)$, que especifica a probabilidade de cada estado possível no tempo inicial.
2.  Uma **matriz de transição de estados**: $p(x_t = j | x_{t-1} = i)$, que define a probabilidade de transição de um estado $i$ no tempo $t-1$ para um estado $j$ no tempo $t$.

A matriz de transição $T$ é uma **matriz estocástica**, o que significa que ela satisfaz as seguintes condições [^1]:

*   $\sum_{j} T_{ij} = 1$ para todas as linhas $i$ (a soma das probabilidades de transição de um estado para todos os outros estados é igual a 1).
*   $0 \leq T_{ij} \leq 1$ para todas as entradas (todas as probabilidades de transição estão entre 0 e 1).

**Exemplo:**

Considere uma cadeia de Markov com dois estados, $A$ e $B$. A distribuição inicial pode ser $p(x_1 = A) = 0.6$ e $p(x_1 = B) = 0.4$. A matriz de transição pode ser:

$$ T = \begin{bmatrix}   0.7 & 0.3 \\   0.2 & 0.8 \end{bmatrix} $$

Onde $T_{11} = 0.7$ é a probabilidade de permanecer no estado $A$ dado que o estado anterior era $A$, $T_{12} = 0.3$ é a probabilidade de transitar do estado $A$ para o estado $B$, e assim por diante.

É possível relaxar um pouco a assunção de Markov adicionando uma dependência de $x_{t-2}$ para $x_t$ [^6]. Isso é chamado de **cadeia de Markov de segunda ordem**. A distribuição conjunta correspondente tem a seguinte forma [^6]:

$$p(x_{1:T}) = p(x_1, x_2) \prod_{t=3}^{T} p(x_t | x_{t-1}, x_{t-2})$$

### Conclusão

A assunção de Markov é uma ferramenta poderosa para simplificar a modelagem de sequências temporais, permitindo a representação eficiente de distribuições conjuntas complexas. As cadeias de Markov, resultantes dessa assunção, fornecem um framework flexível para modelar uma variedade de fenômenos sequenciais. No entanto, é importante estar ciente das limitações da assunção de Markov, especialmente quando existem dependências de longo alcance entre estados. Em tais casos, modelos mais complexos, como os Modelos Ocultos de Markov (HMMs), podem ser mais apropriados, como será discutido nos próximos capítulos [^6].

### Referências
[^1]: Capítulo 10, Introduction to Graphical Models
[^2]: Capítulo 10, Introduction to Graphical Models
[^6]: Capítulo 10, Introduction to Graphical Models
<!-- END -->