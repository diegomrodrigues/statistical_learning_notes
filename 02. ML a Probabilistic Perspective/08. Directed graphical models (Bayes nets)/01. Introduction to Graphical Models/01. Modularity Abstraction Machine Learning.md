## Modularity and Abstraction in Machine Learning: Factorization and Averaging in Graphical Models

### Introdução
Em machine learning, a capacidade de lidar com sistemas complexos de forma eficiente é crucial. Dois princípios fundamentais que facilitam essa gestão são a **modularidade** e a **abstração** [^1]. Estes princípios são implementados na teoria da probabilidade através de dois mecanismos principais: **factorização** e **averaging** [^1]. Neste capítulo, exploraremos como esses conceitos se manifestam e são utilizados em modelos gráficos direcionados (DGMs), também conhecidos como redes Bayesianas. A modularidade permite quebrar um problema complexo em partes menores e mais gerenciáveis, enquanto a abstração permite focar nos aspectos mais relevantes do problema, ignorando detalhes desnecessários. A aplicação destes princípios, através da factorização e do averaging, em modelos probabilísticos, permite uma representação compacta e eficiente de distribuições conjuntas complexas, tornando a inferência e o aprendizado mais tratáveis.

### Conceitos Fundamentais

#### Factorização
A **factorização** é um dos pilares para lidar com a complexidade em modelos gráficos. A *chain rule of probability* [^2] demonstra como qualquer distribuição conjunta pode ser expressa como um produto de distribuições condicionais:
$$\np(x_{1:V}) = p(x_1)p(x_2|x_1)p(x_3|x_{1:2})...p(x_V|x_{1:V-1})\n$$
onde $V$ é o número de variáveis [^2]. No entanto, representar as distribuições condicionais $p(x_t|x_{1:t-1})$ torna-se rapidamente intratável à medida que $t$ aumenta [^2]. A fatorização, dentro do contexto de DGMs, introduz **assunções de independência condicional (CI)** para simplificar essa representação [^3]. Essas assunções permitem que cada variável dependa apenas de um subconjunto de outras variáveis, os seus *pais* no grafo, em vez de depender de todas as variáveis anteriores [^4].

Um exemplo de factorização é a propriedade de Markov de primeira ordem [^3], onde o futuro é independente do passado dado o presente: $x_{t+1} \perp x_{1:t-1} | x_t$. A partir dessa assunção, a distribuição conjunta pode ser escrita como:
$$\np(x_{1:V}) = p(x_1) \prod_{t=1}^{V} p(x_t|x_{t-1})\n$$
Esta é a forma da distribuição para uma cadeia de Markov de primeira ordem [^3].

Em geral, um DGM codifica assunções de independência condicional através da sua estrutura gráfica [^4]. Os nós representam variáveis aleatórias, e a ausência de arestas representa assunções de independência condicional. A *ordered Markov property* [^4] afirma que, dada uma ordem topológica dos nós, uma variável é independente de seus predecessores não-pais:

$$\nx_s \perp x_{pred(s) \setminus pa(s)} | x_{pa(s)}\n$$

onde $pa(s)$ representa os pais do nó $s$, e $pred(s)$ representa os predecessores de $s$ na ordenação. Desta forma, a distribuição conjunta pode ser fatorada como o produto das distribuições condicionais de cada nó dado seus pais:

$$\np(x_{1:V} | G) = \prod_{t=1}^{V} p(x_t | x_{pa(t)})\n$$

onde $G$ representa a estrutura do grafo [^5].

#### Averaging
O princípio de **averaging** surge naturalmente no contexto da inferência probabilística [^1]. Quando queremos estimar uma variável desconhecida, dado um conjunto de dados observados, calculamos a distribuição posterior sobre essa variável, integrando sobre todas as outras variáveis desconhecidas. Matematicamente, isso corresponde a marginalizar a distribuição conjunta sobre as variáveis de *nuisance* [^14].
$$\np(x_q | x_v, \theta) = \sum_{x_n} p(x_q, x_n | x_v, \theta)\n$$
onde $x_q$ são as variáveis de *query*, $x_v$ são as variáveis observadas, $x_n$ são as variáveis de *nuisance*, e $\theta$ são os parâmetros do modelo [^14].

O averaging também se manifesta no aprendizado Bayesiano [^14], onde os parâmetros do modelo são tratados como variáveis aleatórias com uma distribuição *prior*. Em vez de encontrar uma única estimativa de ponto para os parâmetros, calculamos a distribuição posterior sobre os parâmetros, dado os dados. Isso permite levar em conta a incerteza sobre os parâmetros e evitar o overfitting. No entanto, este processo de marginalização pode ser computacionalmente custoso, especialmente para modelos complexos.

#### Independência Condicional e d-separação
A estrutura de um DGM codifica assunções de independência condicional. O conceito de **d-separação** [^18] fornece um critério gráfico para determinar se dois conjuntos de nós são condicionalmente independentes, dado um terceiro conjunto. Formalmente, dois conjuntos de nós $A$ e $B$ são d-separados dado um conjunto $E$ se cada caminho não direcionado entre cada nó $a \in A$ e cada nó $b \in B$ é d-separado por $E$ [^18]. Um caminho $P$ é d-separado por $E$ se alguma das seguintes condições for verdadeira [^18]:
1.  $P$ contém uma cadeia $s \rightarrow m \rightarrow t$ ou $s \leftarrow m \leftarrow t$, onde $m \in E$
2.  $P$ contém um fork $s \leftarrow m \rightarrow t$, onde $m \in E$
3.  $P$ contém um collider (v-structure) $s \rightarrow m \leftarrow t$, onde $m \notin E$ e nenhum descendente de $m$ está em $E$.

O algoritmo de Bayes ball [^18] é um método gráfico para verificar a d-separação.

#### Modularity
A modularidade em DGMs se refere à capacidade de construir modelos complexos combinando componentes menores e bem definidos. Cada componente, ou módulo, representa uma parte específica do sistema que estamos modelando e pode ser projetado e analisado independentemente dos outros componentes. As assunções de independência condicional permitem que esses módulos interajam apenas através de um conjunto limitado de variáveis, simplificando a inferência e o aprendizado.

Por exemplo, considere o *alarm network* [^7] para diagnóstico médico, que modela as relações entre várias variáveis medidas em uma unidade de terapia intensiva (UTI), como a frequência respiratória de um paciente e sua pressão arterial. O modelo consiste em 37 variáveis e 504 parâmetros, mas a estrutura modular permite que os médicos se concentrem em subconjuntos específicos de variáveis relevantes para um determinado diagnóstico.

#### Abstraction
A abstração, neste contexto, significa simplificar o modelo, focando nos aspectos mais importantes e ignorando os detalhes irrelevantes. Isso pode ser feito através de várias técnicas, como a introdução de variáveis latentes [^6] que representam conceitos abstratos ou a agregação de variáveis relacionadas em um único nó.

Um exemplo de abstração é o modelo de Hidden Markov (HMM) [^6], onde existe um processo oculto subjacente que gera as observações. As variáveis ocultas representam estados abstratos do sistema, enquanto as observações representam medidas ruidosas desses estados. Ao modelar o sistema em termos de estados abstratos, podemos reduzir a complexidade do modelo e facilitar a inferência.

### Conclusão

A modularidade e a abstração são princípios cruciais para lidar com a complexidade em machine learning. Em modelos gráficos, esses princípios são implementados através da fatorização e do averaging. A fatorização permite representar distribuições conjuntas complexas como o produto de distribuições condicionais mais simples, enquanto o averaging permite integrar sobre variáveis desconhecidas para obter distribuições posteriores sobre as variáveis de interesse. As assunções de independência condicional codificadas na estrutura do grafo permitem que esses modelos capturem as relações importantes entre as variáveis, ao mesmo tempo em que mantêm a complexidade computacional sob controle. Ao explorar esses princípios, podemos construir modelos mais eficientes e interpretáveis para uma ampla gama de aplicações.

### Referências
[^1]: Section 10.1
[^2]: Section 10.1.1
[^3]: Section 10.1.2
[^4]: Section 10.1.3
[^5]: Section 10.2
[^6]: Section 10.2.2
[^7]: Section 10.2.3
[^14]: Section 10.3
[^18]: Section 10.5.1

<!-- END -->