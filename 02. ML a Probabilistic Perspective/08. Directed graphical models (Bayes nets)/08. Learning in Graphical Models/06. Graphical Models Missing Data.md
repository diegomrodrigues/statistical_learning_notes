## Lidando com Dados Faltantes e Variáveis Ocultas em Modelos Gráficos

### Introdução
Em muitos cenários práticos envolvendo modelos gráficos, nos deparamos com a situação em que alguns dados estão faltando ou certas variáveis são latentes (ocultas). Essa incompletude de dados introduz complexidades significativas tanto na inferência quanto no aprendizado. Especificamente, a presença de dados faltantes ou variáveis ocultas impede a fatoração da função de verossimilhança e resulta em funções não convexas, exigindo técnicas de otimização mais sofisticadas para encontrar estimativas ótimas locais. Além disso, a inferência Bayesiana torna-se ainda mais desafiadora, muitas vezes necessitando de métodos de inferência aproximada [^323]. Este capítulo explora essas dificuldades e as abordagens para lidar com elas, baseando-se nos conceitos de modelos gráficos direcionados (DGMs), independência condicional e inferência probabilística previamente discutidos [^308, ^309, ^319].

### Conceitos Fundamentais

#### Impacto dos Dados Faltantes e Variáveis Ocultas
Quando os dados estão completos, ou seja, todas as variáveis são observadas, a função de verossimilhança para um DGM se decompõe em um produto de termos, um para cada família no gráfico [^322]. Essa decomposição simplifica significativamente o processo de aprendizado, permitindo a estimativa independente dos parâmetros para cada distribuição condicional de probabilidade (CPD) [^322].

No entanto, na presença de dados faltantes ou variáveis ocultas, a verossimilhança não mais se decompõe dessa maneira [^323]. A necessidade de marginalizar sobre as variáveis não observadas introduz dependências complexas entre todos os parâmetros do modelo. Matematicamente, se denotarmos $x_v$ como as variáveis visíveis (observadas) e $x_h$ como as variáveis ocultas, a verossimilhança é dada por:

$$p(x_v|\theta) = \sum_{x_h} p(x_v, x_h|\theta)$$

onde $\theta$ representa os parâmetros do modelo. A soma sobre todas as configurações possíveis das variáveis ocultas torna a função de verossimilhança mais complexa e, em geral, não convexa.

#### Não Convexidade da Função de Verossimilhança
A não convexidade da função de verossimilhança implica que existem múltiplos ótimos locais. Isso significa que algoritmos de otimização, como o gradiente descendente, podem convergir para uma solução subótima, dependendo da inicialização dos parâmetros [^323]. Portanto, é crucial empregar estratégias de otimização mais robustas e explorar diferentes inicializações para tentar encontrar o ótimo global ou uma solução próxima dele.

#### Estimativas de Máxima Verossimilhança (ML) e Máximo a Posteriori (MAP)
Dada a não convexidade da verossimilhança, a estimativa de máxima verossimilhança (ML) e a estimativa de máximo a posteriori (MAP) tornam-se desafiadoras [^323]. A estimativa ML busca encontrar os parâmetros $\theta$ que maximizam a verossimilhança dos dados observados:

$$hat{\theta}_{ML} = \arg \max_{\theta} p(x_v|\theta)$$

Enquanto a estimativa MAP incorpora um conhecimento prévio sobre os parâmetros através de uma distribuição a priori $p(\theta)$:

$$hat{\theta}_{MAP} = \arg \max_{\theta} p(x_v|\theta)p(\theta)$$

Em ambos os casos, a otimização requer a utilização de algoritmos iterativos que podem ficar presos em ótimos locais. Algumas técnicas comuns incluem:

*   **Gradiente Descendente:** Um método iterativo que atualiza os parâmetros na direção do gradiente da função objetivo [^323].
*   **Método de Newton:** Um método de segunda ordem que utiliza a Hessiana da função objetivo para uma convergência mais rápida, mas computacionalmente mais caro.
*   **Algoritmo EM (Expectation-Maximization):** Um algoritmo iterativo específico para problemas com variáveis latentes, que alterna entre uma etapa de Expectation (E), onde se calcula a distribuição das variáveis latentes dado os dados observados e os parâmetros atuais, e uma etapa de Maximization (M), onde se atualizam os parâmetros maximizando a verossimilhança esperada [^323].

#### Inferência Bayesiana Aproximada
A inferência Bayesiana completa busca calcular a distribuição posterior dos parâmetros dado os dados observados:

$$p(\theta|x_v) = \frac{p(x_v|\theta)p(\theta)}{p(x_v)}$$

onde $p(x_v) = \int p(x_v|\theta)p(\theta) d\theta$ é a evidência, que muitas vezes é intratável [^323]. Na presença de dados faltantes ou variáveis ocultas, o cálculo exato da distribuição posterior é frequentemente impossível, exigindo o uso de técnicas de inferência aproximada. Algumas abordagens comuns incluem:

*   **Aproximações Variacionais:** Busca aproximar a distribuição posterior por uma família de distribuições mais simples, otimizando os parâmetros dessa família para minimizar uma medida de divergência entre a aproximação e a posterior verdadeira [^318].
*   **Métodos de Monte Carlo via Cadeias de Markov (MCMC):** Simula amostras da distribuição posterior através da construção de uma cadeia de Markov cuja distribuição estacionária é a posterior desejada [^328].
*   **Inferência de Expectação Propagação (EP):** Uma técnica que aproxima cada fator na distribuição conjunta por uma distribuição exponencial, iterativamente atualizando os parâmetros dessas distribuições para minimizar uma divergência [^323].

### Conclusão
Lidar com dados faltantes e variáveis ocultas em modelos gráficos é uma tarefa complexa que requer o emprego de técnicas de otimização sofisticadas e métodos de inferência aproximada. A não convexidade da função de verossimilhança e a intratabilidade da inferência Bayesiana exata impõem desafios significativos, mas as abordagens discutidas neste capítulo fornecem um conjunto de ferramentas para enfrentar esses desafios. A escolha da técnica mais apropriada depende das características específicas do modelo e dos dados, bem como das restrições computacionais. As seções posteriores do livro [^323] devem detalhar essas abordagens em maior profundidade.

### Referências
[^308]: Chapter 10. Directed graphical models (Bayes nets), page 308.
[^309]: Chapter 10. Directed graphical models (Bayes nets), page 309.
[^318]: Chapter 10. Directed graphical models (Bayes nets), page 318.
[^319]: Chapter 10. Directed graphical models (Bayes nets), page 319.
[^322]: Chapter 10. Directed graphical models (Bayes nets), page 322.
[^323]: Chapter 10. Directed graphical models (Bayes nets), page 323.
[^328]: Chapter 10. Directed graphical models (Bayes nets), page 328.
<!-- END -->