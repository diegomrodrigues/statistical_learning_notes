## Aprendizado em Modelos Gráficos Direcionados com Dados Completos

### Introdução
Este capítulo aborda o aprendizado em modelos gráficos direcionados (DGMs), com foco específico na simplificação que ocorre quando se dispõe de dados completos. DGMs, também conhecidos como redes Bayesianas [^3], oferecem uma estrutura poderosa para representar distribuições conjuntas de probabilidade, explorando relações de dependência condicional entre variáveis. A capacidade de aprender a partir de dados é crucial para a aplicação prática desses modelos. Quando todos os dados estão disponíveis (ou seja, nenhuma variável está oculta ou ausente), o processo de aprendizado se torna consideravelmente mais simplificado devido à decomposição da função de verossimilhança.

### Conceitos Fundamentais
Considere um DGM onde todas as variáveis são totalmente observadas. A função de verossimilhança $p(D | \theta)$, que representa a probabilidade dos dados $D$ dado os parâmetros $\theta$ do modelo, pode ser decomposta com base na estrutura do grafo [^16]:

$$p(D | \theta) = \prod_{t} p(D_t | \theta_t)$$

onde $D_t$ representa os dados associados ao nó $t$ e seus pais, e $\theta_t$ representa os parâmetros associados a essa família. Esta decomposição é uma consequência direta da *propriedade de Markov ordenada* [^4], que afirma que um nó depende apenas de seus pais imediatos, e não de todos os seus predecessores na ordenação topológica do grafo.

Para ilustrar, considere o exemplo do classificador Naive Bayes [^5, 15], onde as features são condicionalmente independentes dada a classe. A distribuição conjunta pode ser escrita como:

$$p(y, x) = p(y) \prod_{j=1}^{D} p(x_j|y)$$

onde $y$ é a variável de classe e $x_j$ são as features. A decomposição da verossimilhança neste caso permite estimar os parâmetros $p(y)$ e $p(x_j|y)$ independentemente, simplificando significativamente o processo de aprendizado.

**Teorema da Decomposição da Verossimilhança:** Se a estrutura do grafo de um DGM é conhecida e os dados são completos, então a função de verossimilhança pode ser decomposta em um produto de verossimilhanças locais, uma para cada nó e seus pais.

*Prova:*
A decomposição da verossimilhança é uma consequência da propriedade de Markov ordenada [^4] e da *regra da cadeia* da probabilidade [^1]. A propriedade de Markov ordenada afirma que um nó é condicionalmente independente de seus não descendentes dados seus pais. A regra da cadeia permite escrever a distribuição conjunta como um produto de condicionais. Combinando esses dois conceitos, obtemos a decomposição da verossimilhança. $\blacksquare$

**Implicações da Decomposição:**
1.  **Aprendizado Paralelo:** A decomposição permite que o aprendizado dos parâmetros $\theta_t$ para cada nó $t$ seja realizado independentemente dos outros nós. Isso possibilita o uso de técnicas de aprendizado paralelo, reduzindo significativamente o tempo de treinamento.
2.  **Simplificação do Cálculo:** A estimativa de máxima verossimilhança (MLE) ou a estimativa a posteriori máxima (MAP) pode ser realizada de forma mais eficiente, pois envolve otimizar funções de verossimilhança menores e independentes.
3.  **Prioris Conjugadas:** Quando se utilizam priors conjugadas para os parâmetros $\theta_t$, a distribuição a posteriori também se torna fatorada [^16], facilitando a inferência Bayesiana.

### Conclusão
A decomposição da verossimilhança em DGMs com dados completos é um resultado fundamental que simplifica significativamente o processo de aprendizado. Ao explorar a estrutura do grafo e a propriedade de Markov ordenada, é possível dividir o problema de aprendizado em subproblemas menores e independentes. Isso não apenas reduz a complexidade computacional, mas também permite o uso de técnicas de aprendizado paralelo e a aplicação de priors conjugadas para uma inferência Bayesiana mais eficiente. O entendimento deste conceito é essencial para a aplicação prática de DGMs em diversos domínios, onde a disponibilidade de dados completos pode ser garantida.

### Referências
[^1]: Capítulo 10, Seção 10.1.1
[^3]: Capítulo 10, Seção 10.1.5
[^4]: Capítulo 10, Seção 10.1.5
[^5]: Capítulo 10, Seção 10.2.1
[^15]: Capítulo 10, Seção 10.4.1
[^16]: Capítulo 10, Seção 10.4.2
<!-- END -->