## Estimativa de Parâmetros em Modelos Gráficos

### Introdução
Em modelos gráficos, o processo de **aprendizado** envolve a estimativa dos parâmetros $\theta$ do modelo. Uma abordagem comum é calcular a estimativa de **Máxima A Posteriori (MAP)** dos parâmetros, dados os dados observados [^320]. Este capítulo detalha este processo, explorando a sua formulação matemática e implicações.

### Conceitos Fundamentais

A estimativa MAP dos parâmetros $\theta$ é dada por [^320]:

$$hat{\theta} = \underset{\theta}{\operatorname{argmax}} \sum_{i=1}^{N} \log p(x_{i,v}|\theta) + \log p(\theta)$$

onde:
*   $x_{i,v}$ representa as variáveis visíveis no caso *i* [^320].
*   $p(x_{i,v}|\theta)$ é a verossimilhança dos dados visíveis, dado os parâmetros $\theta$ [^320].
*   $p(\theta)$ é a distribuição *a priori* sobre os parâmetros $\theta$ [^320].
*   *N* é o número de amostras [^320].

O primeiro termo, $\sum_{i=1}^{N} \log p(x_{i,v}|\theta)$, representa a **log-verossimilhança** dos dados, enquanto o segundo termo, $\log p(\theta)$, representa o **logaritmo da distribuição a priori** dos parâmetros [^320]. A estimativa MAP busca encontrar os parâmetros que maximizam a combinação da verossimilhança dos dados e a plausibilidade dos parâmetros, conforme expressa pela distribuição *a priori* [^320].

Se assumirmos uma distribuição *a priori* uniforme, ou seja, $p(\theta) \propto 1$, a estimativa MAP se reduz à estimativa de **Máxima Verossimilhança (MLE)** [^320]:

$$hat{\theta} = \underset{\theta}{\operatorname{argmax}} \sum_{i=1}^{N} \log p(x_{i,v}|\theta)$$

A escolha da distribuição *a priori* $p(\theta)$ é crucial na estimativa MAP. Uma distribuição *a priori* informativa pode regularizar a solução e evitar *overfitting*, especialmente quando os dados são escassos [^320]. No entanto, uma distribuição *a priori* mal escolhida pode introduzir um *bias* indesejado na estimativa.

A distinção entre inferência e aprendizado em modelos gráficos é que a inferência calcula (funções de) $p(x_h|x_v, \theta)$, onde $x_v$ são os nós visíveis, $x_h$ são os nós escondidos e $\theta$ são os parâmetros do modelo, assumidos como conhecidos. O aprendizado geralmente significa calcular uma estimativa MAP dos parâmetros dados os dados [^320].

Se adotarmos uma visão Bayesiana, os parâmetros são variáveis desconhecidas e também devem ser inferidos. Portanto, para um Bayesiano, não há distinção entre inferência e aprendizado. De fato, podemos simplesmente adicionar os parâmetros como nós ao gráfico, condicionar em D e, em seguida, inferir os valores de todos os nós [^320].

Nesta visão, a principal diferença entre variáveis ocultas e parâmetros é que o número de variáveis ocultas cresce com a quantidade de dados de treinamento (já que geralmente há um conjunto de variáveis ocultas para cada caso de dados observados), enquanto o número de parâmetros geralmente é fixo (pelo menos em um modelo paramétrico) [^320]. Isso significa que devemos integrar as variáveis ocultas para evitar o *overfitting*, mas podemos nos safar com técnicas de estimativa pontual para parâmetros, que são menores em número [^320].

#### Aprendizado com Dados Completos
Se todas as variáveis forem totalmente observadas em cada caso, então não há dados ausentes e não há variáveis ocultas, dizemos que os dados estão completos [^322]. Para um DGM com dados completos, a verossimilhança é dada por [^322]:

$$p(\mathcal{D}|\theta) = \prod_{i=1}^N p(x_i|\theta) = \prod_{i=1}^N \prod_{t=1}^V p(x_{it}|x_{i,pa(t)}, \theta_t) = \prod_{t=1}^V p(\mathcal{D}_t|\theta_t)$$

onde $\mathcal{D}_t$ são os dados associados ao nó *t* e seus pais, isto é, a *t*-ésima família. Este é um produto de termos, um por CPD. Dizemos que a verossimilhança se decompõe de acordo com a estrutura do gráfico [^322].

Agora, suponha que o *a priori* também se fatora [^322]:

$$p(\theta) = \prod_{t=1}^V p(\theta_t)$$

Então, claramente, o posterior também se fatora [^322]:

$$p(\theta|\mathcal{D}) \propto p(\mathcal{D}|\theta)p(\theta) = \prod_{t=1}^V p(\mathcal{D}_t|\theta_t)p(\theta_t)$$

Isto significa que podemos computar o posterior de cada CPD independentemente. Em outras palavras, *a priori* fatorado mais verossimilhança fatorada implica posterior fatorado [^322].

#### Aprendizado com dados ausentes e/ou latentes

Se tivermos dados ausentes e/ou variáveis ocultas, a verossimilhança não se fatora mais e, de fato, não é mais convexa, como explicamos em detalhe na Seção 11.3 [^323]. Isso significa que normalmente só podemos computar uma estimativa ML ou MAP localmente ótima. A inferência Bayesiana dos parâmetros é ainda mais difícil. Discutimos técnicas de inferência aproximadas adequadas em capítulos posteriores [^323].

### Conclusão

A estimativa de parâmetros em modelos gráficos é um passo crucial para a construção de modelos preditivos e inferenciais robustos [^320]. A escolha entre MLE e MAP, bem como a seleção da distribuição *a priori*, dependem das características dos dados e dos objetivos da modelagem [^320]. Em situações com dados faltantes, o aprendizado se torna mais complexo.

### Referências
[^320]: Capítulo 10, Directed graphical models (Bayes nets), página 320.
[^322]: Capítulo 10, Directed graphical models (Bayes nets), página 322.
[^323]: Capítulo 10, Directed graphical models (Bayes nets), página 323.
<!-- END -->