## Terminologia de Grafos em Modelos Gráficos Direcionados

### Introdução
Este capítulo explora a terminologia fundamental associada a grafos, com foco especial em Modelos Gráficos Direcionados (DGMs), também conhecidos como redes bayesianas [^3]. A compreensão desses termos é crucial para a representação e manipulação de distribuições de probabilidade conjuntas, bem como para a modelagem da independência condicional entre variáveis [^2].

### Conceitos Fundamentais

Um **grafo** $G$ é definido como um par ordenado $G = (V, E)$, onde $V$ é um conjunto de **nós** (ou vértices) e $E$ é um conjunto de **arestas** [^3]. Em DGMs, os nós representam variáveis aleatórias, e as arestas direcionadas indicam dependências probabilísticas entre essas variáveis [^2].

**Termos Chave:**
*   **Pai (Parent):** Em um grafo direcionado, um **pai** de um nó $s$ é qualquer nó $t$ que tem uma aresta direcionada para $s$. Formalmente, o conjunto de pais de $s$ é definido como $pa(s) = \\{t : G(t, s) = 1\\}$ [^3].
*   **Filho (Child):** Em um grafo direcionado, um **filho** de um nó $s$ é qualquer nó $t$ para o qual existe uma aresta direcionada saindo de $s$. Formalmente, o conjunto de filhos de $s$ é definido como $ch(s) = \\{t : G(s, t) = 1\\}$ [^3].
*   **Família (Family):** A **família** de um nó $s$ em um grafo direcionado é o conjunto que consiste no próprio nó $s$ e seus pais. Formalmente, $fam(s) = \\{s\\} \cup pa(s)$ [^3].
*   **Raiz (Root):** Uma **raiz** em um grafo direcionado é um nó que não tem pais [^3].
*   **Folha (Leaf):** Uma **folha** em um grafo direcionado é um nó que não tem filhos [^3].
*   **Ancestrais (Ancestors):** Os **ancestrais** de um nó $t$ são todos os nós que se conectam a $t$ através de um caminho direcionado. Formalmente, $anc(t) = \\{s : s \leadsto t\\}$ [^3].
*   **Descendentes (Descendants):** Os **descendentes** de um nó $s$ são todos os nós que podem ser alcançados a partir de $s$ através de caminhos direcionados. Formalmente, $desc(s) = \\{t : s \leadsto t\\}$ [^3].
*   **Vizinhos (Neighbors):** Os **vizinhos** de um nó $s$ são todos os nós que estão diretamente conectados a $s$ através de uma aresta. Formalmente, $nbr(s) = \\{t : G(s, t) = 1 \lor G(t, s) = 1\\}$ [^3].
*   **Grau (Degree):** O **grau** de um nó é o número de seus vizinhos. Em grafos direcionados, distinguimos entre o **grau de entrada (in-degree)**, que é o número de pais, e o **grau de saída (out-degree)**, que é o número de filhos [^3].

**Representação Matricial:**

Um grafo pode ser representado por sua **matriz de adjacência** $G(s, t)$, onde $G(s, t) = 1$ se existe uma aresta de $s$ para $t$, e $G(s, t) = 0$ caso contrário [^3]. Usualmente, assume-se que $G(s, s) = 0$, indicando a ausência de auto-loops [^3].

**Grafos Acíclicos Direcionados (DAGs):**

Um **grafo acíclico direcionado (DAG)** é um grafo direcionado que não contém ciclos direcionados [^3]. A propriedade fundamental dos DAGs é que seus nós podem ser ordenados de forma que os pais venham antes dos filhos. Esse ordenamento é conhecido como **ordenação topológica** ou **ordenação total** [^3].

**Modelos Gráficos Direcionados (DGMs):**

Um **modelo gráfico direcionado (DGM)** é um modelo probabilístico cuja estrutura é representada por um DAG. Os nós do grafo representam variáveis aleatórias, e a ausência de arestas codifica **assunções de independência condicional (CI)** [^2]. A distribuição conjunta de probabilidade pode ser fatorada de acordo com a estrutura do grafo. A **propriedade de Markov ordenada** estabelece que um nó depende apenas de seus pais imediatos, e não de todos os seus predecessores na ordenação [^4]. Matematicamente:

$$\
X_s \perp X_{pred(s) \setminus pa(s)} | X_{pa(s)}
$$

onde $pa(s)$ representa os pais do nó $s$, e $pred(s)$ representa os predecessores de $s$ na ordenação [^4].

### Conclusão

A terminologia de grafos fornece uma base sólida para a compreensão e manipulação de DGMs. Os conceitos de pais, filhos, ancestrais, descendentes e vizinhos são essenciais para a construção e interpretação de modelos probabilísticos complexos. A propriedade de Markov ordenada, juntamente com as assunções de independência condicional, permite uma representação eficiente e compacta de distribuições de probabilidade conjuntas [^4].

### Referências
[^2]: Chapter 10. Directed graphical models (Bayes nets) - Introduction
[^3]: Chapter 10. Directed graphical models (Bayes nets) - Graph terminology
[^4]: Chapter 10. Directed graphical models (Bayes nets) - Directed graphical models
<!-- END -->