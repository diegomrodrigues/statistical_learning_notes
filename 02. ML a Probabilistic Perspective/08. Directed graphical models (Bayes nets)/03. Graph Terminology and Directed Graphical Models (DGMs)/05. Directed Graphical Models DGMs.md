## Directed Graphical Models (Bayes Nets)

### Introdução
Este capítulo explora os **Directed Graphical Models (DGMs)**, também conhecidos como **Bayesian networks** ou **belief networks**, uma ferramenta fundamental para representar distribuições de probabilidade conjuntas de maneira compacta, aproveitando as relações de independência condicional entre as variáveis [^1]. O foco será na estrutura e propriedades dessas redes, com ênfase na propriedade de ordenação topológica e na propriedade de Markov ordenada.

### Conceitos Fundamentais
**Directed Graphical Models (DGMs)** são modelos gráficos cujo grafo é um **directed acyclic graph (DAG)** [^1]. Um DAG é um grafo dirigido que não contém ciclos [^1, 4]. Em um DGM, os nós representam variáveis aleatórias e as arestas direcionadas representam dependências probabilísticas entre essas variáveis. A ausência de uma aresta entre dois nós indica uma suposição de independência condicional [^1, 2].

A representação compacta da distribuição conjunta é alcançada através da **chain rule** da probabilidade [^1]:

$$ p(x_{1:V}) = p(x_1)p(x_2|x_1)p(x_3|x_1, x_2)...p(x_V|x_{1:V-1}) $$

onde $V$ é o número de variáveis [^1]. No entanto, essa expressão se torna rapidamente complexa, especialmente quando $t$ aumenta em $p(x_t|x_{1:t-1})$ [^1].

A solução para essa complexidade reside nas **conditional independence (CI) assumptions** [^2]. Duas variáveis $X$ e $Y$ são condicionalmente independentes dado $Z$, denotado por $X \perp Y | Z$, se e somente se a distribuição conjunta condicional puder ser escrita como um produto de distribuições marginais condicionais [^2]:

$$ X \perp Y | Z \Leftrightarrow p(X, Y | Z) = p(X | Z)p(Y | Z) $$

Essa propriedade permite simplificar a representação da distribuição conjunta, considerando apenas as dependências relevantes [^2].

**Topological Ordering:** Uma propriedade crucial dos DAGs é que seus nós podem ser ordenados de tal forma que os pais precedam os filhos [^1, 4]. Essa ordenação, conhecida como **topological ordering** ou **total ordering**, permite definir a **ordered Markov property** [^1, 4].

**Ordered Markov Property:** Dada uma ordenação topológica, a ordered Markov property afirma que um nó depende apenas de seus pais imediatos, e não de todos os seus predecessores na ordenação [^4]:

$$ X_s \perp X_{pred(s)} \setminus X_{pa(s)} | X_{pa(s)} $$

onde $pa(s)$ representa os pais do nó $s$, e $pred(s)$ representa os predecessores de $s$ na ordenação [^4]. Essa propriedade é uma generalização natural da Markov property de primeira ordem para cadeias [^2, 4].

Para melhor ilustrar, considere o exemplo da Figura 10.1(a) [^3]. Uma possível ordenação topológica é (1, 2, 3, 4, 5). De acordo com a ordered Markov property:
*   $p(x_1)$ não depende de nenhum outro nó, pois é a raiz.
*   $p(x_2|x_1)$ depende apenas de $x_1$.
*   $p(x_3|x_1)$ depende apenas de $x_1$.
*   $p(x_4|x_2, x_3)$ depende apenas de $x_2$ e $x_3$.
*   $p(x_5|x_3)$ depende apenas de $x_3$.

Portanto, a distribuição conjunta pode ser expressa como:

$$ p(x_{1:5}) = p(x_1)p(x_2|x_1)p(x_3|x_1)p(x_4|x_2, x_3)p(x_5|x_3) $$

Essa fatoração simplifica significativamente a representação e o cálculo da distribuição conjunta [^5].

**Terminologia Adicional:**

*   **Parent:** Os pais de um nó são todos os nós que alimentam diretamente esse nó [^3].
*   **Child:** Os filhos de um nó são todos os nós que são alimentados diretamente por esse nó [^3].
*   **Family:** A família de um nó consiste no nó em si e em seus pais [^3].
*   **Root:** Um nó sem pais [^3].
*   **Leaf:** Um nó sem filhos [^3].
*   **Ancestors:** Todos os nós que podem alcançar um determinado nó seguindo as arestas direcionadas para trás [^3].
*   **Descendants:** Todos os nós que podem ser alcançados a partir de um determinado nó seguindo as arestas direcionadas para frente [^3].

### Conclusão
Os Directed Graphical Models oferecem uma estrutura poderosa para representar e manipular distribuições de probabilidade conjuntas complexas. Ao explorar as relações de independência condicional e a propriedade de Markov ordenada, os DGMs permitem uma representação compacta e eficiente de modelos probabilísticos. A ordenação topológica desempenha um papel fundamental na definição da propriedade de Markov ordenada, que simplifica a fatoração da distribuição conjunta. Os conceitos e definições apresentados neste capítulo fornecem a base para a compreensão e aplicação de DGMs em uma variedade de problemas de modelagem, inferência e aprendizado.

### Referências
[^1]: Directed graphical models (DGMs), also known as Bayesian networks or belief networks, are graphical models whose graph is a directed acyclic graph (DAG) used to represent a joint probability distribution by making conditional independence assumptions. DAGs possess a key property: nodes can be ordered such that parents precede children, known as topological ordering, enabling the definition of the ordered Markov property.
[^2]: The key to efficiently representing large joint distributions is to make some assumptions about conditional independence (CI). Recall from Section 2.2.4 that X and Y are conditionally independent given Z, denoted X | Y|Z, if and only if (iff) the conditional joint can be written as a product of conditional marginals, i.e., X |Y|Z ⇔ p(X,Y|Z) = p(X|Z)p(Y|Z)
[^3]: Graph terminology Before we continue, we must define a few basic terms, most of which are very intuitive.
[^4]: The key property of DAGs is that the nodes can be ordered such that parents come before children. This is called a topological ordering, and it can be constructed from any DAG. Given such an order, we define the ordered Markov property to be the assumption that a node only depends on its immediate parents, not on all predecessors in the ordering, i.e., Xs Xpred(s)\pa(s) Xpa(s)
[^5]: For example, the DAG in Figure 10.1(a) encodes the following joint distribution: p(x1:5) = p(x1)p(x2|x1)p(x3|X1)P(X4|X2, X3)P(X5|X3)

<!-- END -->