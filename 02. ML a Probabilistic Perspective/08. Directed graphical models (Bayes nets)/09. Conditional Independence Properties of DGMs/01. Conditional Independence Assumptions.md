## Conditional Independence Properties in Directed Graphical Models

### Introdução
Os modelos gráficos direcionados (DGMs) são fundamentados em um conjunto de suposições de independência condicional (CI) [^324]. Estas suposições fornecem uma estrutura para representar de forma compacta distribuições conjuntas complexas, explorando as relações de dependência e independência entre as variáveis. Este capítulo detalha as propriedades de independência condicional inerentes aos DGMs, com foco na d-separação e no algoritmo da Bayes ball para determinar as independências globais.

### Conceitos Fundamentais

**Independência Condicional (CI)**: Em um modelo gráfico, a independência condicional é fundamental para a estrutura e inferência. A notação $X_A \perp_G X_B | X_C$ significa que o conjunto de variáveis $X_A$ é independente de $X_B$ dado $X_C$ no grafo $G$ [^324]. $I(G)$ denota o conjunto de todas as declarações de independência condicional codificadas pelo grafo [^324].

**I-map (Mapa de Independência)**: Um grafo $G$ é um I-map para uma distribuição $p$ se $I(G) \subseteq I(p)$, onde $I(p)$ é o conjunto de todas as declarações de independência condicional que valem para a distribuição $p$ [^324]. Em outras palavras, o grafo não afirma nenhuma independência condicional que não seja verdadeira na distribuição.

**Minimal I-map**: Um grafo $G$ é um I-map minimal para uma distribuição $p$ se $G$ é um I-map para $p$, e não existe um subgrafo $G' \subset G$ que também seja um I-map para $p$ [^324].

**d-separação**: A d-separação é um critério gráfico para determinar a independência condicional em DGMs [^324]. Um caminho não direcionado $P$ é d-separado por um conjunto de nós $E$ se uma das seguintes condições for verdadeira [^324]:

1.  $P$ contém uma cadeia $s \rightarrow m \rightarrow t$ ou $s \leftarrow m \leftarrow t$, onde $m \in E$.
2.  $P$ contém um garfo $s \leftarrow m \rightarrow t$, onde $m \in E$.
3.  $P$ contém um *collider* ou estrutura-v $s \rightarrow m \leftarrow t$, onde $m \notin E$ e nenhum descendente de $m$ está em $E$.

Um conjunto de nós $A$ é d-separado de um conjunto de nós $B$ dado um conjunto $E$ se cada caminho não direcionado de cada nó $a \in A$ para cada nó $b \in B$ é d-separado por $E$ [^324].

**Relação entre d-separação e independência condicional**: Em um DGM, a independência condicional pode ser definida em termos de d-separação [^324]:
$$X_A \perp_G X_B | X_E \Leftrightarrow A \text{ é d-separado de } B \text{ dado } E$$

**Algoritmo Bayes Ball**: O algoritmo Bayes ball é um método gráfico para verificar a d-separação [^324]. Os nós em $E$ são "sombreados" para indicar que são observados. Bolas são colocadas em cada nó em $A$ e "saltam" pelo grafo de acordo com as seguintes regras [^324]:

1.  Uma bola pode passar por uma cadeia se o nó intermediário não estiver sombreado.
2.  Uma bola pode passar por um garfo se o nó intermediário não estiver sombreado.
3.  Uma bola não pode passar por uma estrutura-v, a menos que o nó intermediário ou um de seus descendentes esteja sombreado.

Se nenhuma bola alcançar nenhum nó em $B$, então $A$ é d-separado de $B$ dado $E$.

**Justificativa das Regras de Bayes Ball**: As regras de Bayes ball podem ser justificadas considerando as estruturas básicas de cadeia, garfo e estrutura-v [^324].

1.  **Cadeia**: Considere a estrutura de cadeia $X \rightarrow Y \rightarrow Z$. A distribuição conjunta é $p(x, y, z) = p(x)p(y|x)p(z|y)$. Se condicionarmos em $y$, então $x$ e $z$ são independentes: $p(x, z|y) = p(x|y)p(z|y)$ [^325].
2.  **Garfo**: Considere a estrutura de garfo $X \leftarrow Y \rightarrow Z$. A distribuição conjunta é $p(x, y, z) = p(y)p(x|y)p(z|y)$. Se condicionarmos em $y$, então $x$ e $z$ são independentes: $p(x, z|y) = p(x|y)p(z|y)$ [^325].
3.  **Estrutura-V**: Considere a estrutura-v $X \rightarrow Y \leftarrow Z$. A distribuição conjunta é $p(x, y, z) = p(x)p(z)p(y|x, z)$. Se não condicionarmos em $y$, então $x$ e $z$ são independentes: $p(x, z) = p(x)p(z)$ [^326]. No entanto, se condicionarmos em $y$, então $x$ e $z$ tornam-se dependentes.

**Propriedades de Markov**: Existem três propriedades de Markov para DGMs: a propriedade global de Markov (d-separação), a propriedade local de Markov direcionada e a propriedade ordenada de Markov [^327]. Estas propriedades são equivalentes e descrevem as independências no modelo.

**Cobertor de Markov**: O cobertor de Markov de um nó $t$ é o conjunto de nós que tornam $t$ condicionalmente independente de todos os outros nós no grafo [^327]. O cobertor de Markov consiste nos pais, filhos e co-pais (outros pais dos filhos) de $t$ [^327].

**Condicional completo**: A expressão resultante é chamada de condicional completo de $t$, e será importante ao estudar a amostragem de Gibbs [^328].

### Conclusão
As suposições de independência condicional são a pedra angular dos modelos gráficos direcionados, permitindo a representação compacta de distribuições conjuntas e inferência eficiente. O critério de d-separação e o algoritmo Bayes ball fornecem ferramentas para determinar as independências condicionais codificadas em um DGM. Compreender estas propriedades é crucial para projetar e interpretar DGMs para diversas aplicações.

### Referências
[^324]: Capítulo 10, Directed graphical models (Bayes nets), página 324.
[^325]: Capítulo 10, Directed graphical models (Bayes nets), página 325.
[^326]: Capítulo 10, Directed graphical models (Bayes nets), página 326.
[^327]: Capítulo 10, Directed graphical models (Bayes nets), página 327.
[^328]: Capítulo 10, Directed graphical models (Bayes nets), página 328.

<!-- END -->