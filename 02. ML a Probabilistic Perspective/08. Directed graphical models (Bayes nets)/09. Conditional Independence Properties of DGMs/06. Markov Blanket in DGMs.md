## Markov Blanket em Modelos Gráficos Direcionados

### Introdução
Em modelos gráficos direcionados (DGMs), a compreensão das relações de dependência condicional é crucial para inferência e modelagem eficientes. O conceito de **Markov blanket** desempenha um papel fundamental na identificação de quais variáveis são relevantes para inferir o estado de uma variável específica, dado o conhecimento de outras variáveis no modelo. Este capítulo explora em detalhes o Markov blanket em DGMs, definindo-o e demonstrando sua importância.

### Conceitos Fundamentais

O **Markov blanket** de um nó *t* em um DGM, denotado como *mb(t)*, é o conjunto de nós que tornam *t* condicionalmente independente de todos os outros nós no grafo. Em outras palavras, dado o Markov blanket de *t*, o estado de *t* é independente de qualquer nó fora desse conjunto [^327].

Formalmente, o Markov blanket de um nó *t* é definido como a união de três conjuntos de nós [^327]:

1.  Os **pais** de *t*, denotado como *pa(t)*.
2.  Os **filhos** de *t*, denotado como *ch(t)*.
3.  Os **co-pais** de *t*, denotado como *copa(t)*, que são outros nós que também são pais dos filhos de *t*.

Portanto, a definição matemática do Markov blanket é dada por [^328]:

$$mb(t) = ch(t) \cup pa(t) \cup copa(t)$$

Para ilustrar, considere o DGM na Figura 10.11 [^327]. O Markov blanket do nó 5 é dado por [^328]:

$$mb(5) = \{6, 7\} \cup \{2, 3\} \cup \{4\} = \{2, 3, 4, 6, 7\}$$

Neste exemplo, 4 é um co-pai de 5 porque eles compartilham um filho em comum, nomeadamente 7 [^328].

**Justificativa do Markov Blanket**

Para entender por que os co-pais estão no Markov blanket, considere a derivação da probabilidade condicional completa *p(x<sub>t</sub>|x<sub>-t</sub>)*, onde *x<sub>-t</sub>* representa todas as variáveis no grafo, exceto *x<sub>t</sub>* [^328]. Ao derivar essa probabilidade, todos os termos que não envolvem *x<sub>t</sub>* se cancelam entre o numerador e o denominador. Isso nos deixa com um produto de distribuições de probabilidade condicionais (CPDs) que contêm *x<sub>t</sub>* em seu *scope* [^328].

Matematicamente [^328]:

$$p(x_t|x_{-t}) \propto p(x_t|x_{pa(t)}) \prod_{s \in ch(t)} p(x_s|x_{pa(s)})$$

O lado direito da equação acima envolve apenas os pais de *t* (*pa(t)*) e os filhos de *t* (*ch(t)*), bem como os pais dos filhos de *t* (*pa(s)*). Esses pais dos filhos de *t* são os co-pais de *t*.

**Exemplo**

No DGM da Figura 10.11, a probabilidade condicional completa de x<sub>5</sub> é [^328]:

$$p(x_5|x_{-5}) \propto p(x_5|x_2, x_3)p(x_6|x_3, x_5)p(x_7|x_4, x_5, x_6)$$

A expressão resultante é chamada de **condicional completa** de *t*, e provará ser importante ao estudar a amostragem de Gibbs (Seção 24.2) [^328].

### Conclusão

O Markov blanket é uma ferramenta essencial para simplificar a inferência em DGMs, permitindo que nos concentremos apenas nas variáveis mais relevantes para determinar o estado de um nó específico. Ao identificar os pais, filhos e co-pais de um nó, podemos efetivamente isolar as dependências condicionais e realizar inferências mais eficientes. A compreensão do Markov blanket é fundamental para algoritmos como a amostragem de Gibbs e para a análise das propriedades de independência condicional em DGMs.

### Referências
[^327]: Capítulo 10, Directed graphical models (Bayes nets), página 327.
[^328]: Capítulo 10, Directed graphical models (Bayes nets), página 328.
<!-- END -->