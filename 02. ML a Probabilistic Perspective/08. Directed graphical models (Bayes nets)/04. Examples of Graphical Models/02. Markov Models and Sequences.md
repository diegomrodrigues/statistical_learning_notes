## Markov Models in Graphical Models

### Introdução
Este capítulo explora modelos gráficos, com foco especial em **Markov Models** e suas variações. Os modelos de Markov são fundamentais para representar sequências onde o futuro depende apenas do passado imediato, simplificando a modelagem de sistemas complexos [^308]. Entender esses modelos é crucial para diversas aplicações, desde análise de sequências genômicas até processamento de linguagem natural [^312]. A **cadeia de Markov** de primeira ordem, definida pela propriedade de que o estado futuro depende apenas do estado presente, é a base para modelos mais complexos. Modelos de Markov de ordem superior incorporam dependências de múltiplos estados passados [^308, 312].

### Conceitos Fundamentais

#### Cadeia de Markov
Uma **cadeia de Markov** é caracterizada pela propriedade de que, dado o estado presente, o futuro é independente do passado. Formalmente, essa *condição de independência condicional* pode ser expressa como $x_{t+1} \perp x_{1:t-1} | x_t$ [^308]. Essa propriedade simplifica significativamente a modelagem de sequências, pois permite fatorar a distribuição conjunta de uma sequência $x_{1:V}$ como:

$$p(x_{1:V}) = p(x_1) \prod_{t=2}^{V} p(x_t | x_{t-1})$$

onde $p(x_1)$ representa a distribuição inicial sobre os estados, e $p(x_t | x_{t-1})$ é a matriz de transição de estados [^308].

#### Markov de Ordem Superior
A **cadeia de Markov de primeira ordem** pode ser estendida para capturar dependências de estados mais distantes no passado. Em um modelo de Markov de ordem *n*, o estado futuro depende dos *n* estados passados mais recentes [^308, 312]. A distribuição conjunta para um modelo de segunda ordem (n=2) é dada por:

$$p(x_{1:T}) = p(x_1, x_2) \prod_{t=3}^{T} p(x_t | x_{t-1}, x_{t-2})$$

onde $p(x_1, x_2)$ define a distribuição conjunta dos dois primeiros estados [^312]. A generalização para ordem *n* é direta, mas o número de parâmetros cresce exponencialmente com *n*, o que pode levar a problemas de *overfitting* se não houver dados suficientes [^308].

#### Modelos Ocultos de Markov (HMMs)
Quando a dependência de longo alcance entre as observações é uma preocupação, mas a construção de modelos de ordem superior se torna impraticável, uma alternativa é o uso de **Hidden Markov Models (HMMs)** [^312]. Em um HMM, assume-se que existe um processo oculto subjacente que segue uma cadeia de Markov de primeira ordem, e as observações são geradas a partir desse processo oculto [^312].

Formalmente, um HMM é definido por:
- Uma sequência de estados ocultos $z_{1:T}$, onde $z_t$ segue uma cadeia de Markov de primeira ordem: $p(z_t | z_{t-1})$.
- Uma sequência de observações $x_{1:T}$, onde cada observação $x_t$ depende apenas do estado oculto correspondente $z_t$: $p(x_t | z_t)$.

A distribuição conjunta para um HMM é dada por:

$$p(x_{1:T}, z_{1:T}) = p(z_1) \prod_{t=2}^{T} p(z_t | z_{t-1}) \prod_{t=1}^{T} p(x_t | z_t)$$

onde $p(z_1)$ é a distribuição inicial sobre os estados ocultos, $p(z_t | z_{t-1})$ é o *modelo de transição* e $p(x_t | z_t)$ é o *modelo de observação* [^312].

#### Propriedade de Markov Ordenada
Em um **Directed Acyclic Graph (DAG)**, a propriedade de Markov ordenada estabelece que um nó é condicionalmente independente de seus predecessores não-pais, dado seus pais [^310]. Formalmente:

$$x_s \perp X_{pred(s)} \setminus X_{pa(s)} | X_{pa(s)}$$

onde $pred(s)$ são os predecessores do nó $s$ em uma ordenação topológica, e $pa(s)$ são os pais do nó $s$ [^310]. Essa propriedade é uma generalização da propriedade de Markov para cadeias a grafos arbitrários [^310].

### Conclusão

Os modelos de Markov representam uma classe poderosa de modelos gráficos para sequências. A escolha entre um modelo de Markov de ordem superior, um HMM, ou outras variações depende da estrutura das dependências nos dados e da disponibilidade de dados para estimar os parâmetros do modelo [^308, 312]. A propriedade de Markov ordenada fornece uma base teórica para entender as independências condicionais em modelos gráficos direcionados, permitindo a construção de modelos mais eficientes e interpretáveis [^310].

### Referências
[^308]: Chapter 10. Directed graphical models (Bayes nets), Introduction, Chain rule, Conditional independence.
[^310]: Chapter 10. Directed graphical models (Bayes nets), Directed graphical models.
[^312]: Chapter 10. Directed graphical models (Bayes nets), Markov and hidden Markov models.
<!-- END -->