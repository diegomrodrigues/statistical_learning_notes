## O Modelo de Potts

### Introdução
O **Modelo de Potts** surge como uma generalização do **Modelo de Ising** para múltiplos estados discretos, encontrando aplicações notáveis em segmentação de imagens [^6]. Enquanto o Modelo de Ising se restringe a dois estados (e.g., spin para cima ou para baixo), o Modelo de Potts expande essa capacidade, permitindo representar sistemas com *K* estados distintos. Este capítulo explora as características e aplicações do Modelo de Potts, com ênfase em seu uso como *prior* em problemas de segmentação de imagens [^11].

### Conceitos Fundamentais

#### Definição Formal
No Modelo de Potts, cada variável $y_t$ pode assumir um dos *K* estados discretos: $y_t \in \{1, 2, ..., K\}$ [^11]. A função potencial, $\psi_{st}(y_s, y_t)$, quantifica a compatibilidade entre os estados de dois nós vizinhos, *s* e *t*, e é definida como:
$$
\psi_{st}(y_s, y_t) =
\begin{cases}
exp(J) & \text{se } y_s = y_t \\
0 & \text{caso contrário}
\end{cases}
$$
onde *J* é um parâmetro que controla a força da associação entre estados iguais. Um valor positivo de *J* incentiva nós vizinhos a terem o mesmo rótulo, enquanto um valor negativo desencoraja essa similaridade.

#### Interpretação e Aplicações
A função potencial do Modelo de Potts favorece configurações onde nós vizinhos compartilham o mesmo estado [^11]. Essa propriedade torna o modelo particularmente adequado para tarefas onde se espera que elementos vizinhos possuam características semelhantes, como é o caso da segmentação de imagens.

Em segmentação de imagens, o Modelo de Potts pode ser empregado como um *prior* para encorajar que pixels vizinhos possuam o mesmo rótulo, indicando que pertencem ao mesmo segmento [^11]. Essa *prior* pode ser combinada com um termo de *likelihood* que mede a compatibilidade de cada pixel com os diferentes segmentos, resultando em um modelo completo para segmentação.

#### Combinação com Termo de *Likelihood*
Para usar o Modelo de Potts em segmentação de imagens, é comum combiná-lo com um termo de *likelihood* que avalia a probabilidade de observar o valor de um pixel, $x_t$, dado o rótulo correspondente, $y_t$ [^11]. A distribuição conjunta é definida como:
$$
p(y, x|\theta) = p(y|J) \prod_{t} p(x_t|y_t, \theta_t) = \frac{1}{Z(J)} \prod_{s \sim t} \psi(y_s, y_t; J) \prod_{t} p(x_t|y_t, \theta)
$$

onde:
*   $p(y|J)$ é o *prior* de Potts sobre os rótulos,
*   $p(x_t|y_t = k, \theta)$ é a probabilidade de observar o pixel $x_t$ dado que pertence à classe *k*,
*   *Z(J)* é a função de partição que garante que a distribuição conjunta some um.

O termo de *likelihood* pode ser modelado usando uma distribuição Gaussiana ou uma densidade não paramétrica [^11].

#### Transição de Fase
Assim como no Modelo de Ising, o Modelo de Potts exibe um fenômeno de **transição de fase** [^11]. Para valores de *J* acima de um limiar crítico ($J > 1.44$ para um modelo em grade 2D), grandes *clusters* de pixels com o mesmo rótulo tendem a se formar. Abaixo desse limiar ($J < 1.44$), predominam *clusters* menores. No ponto crítico ($J = 1.44$), observa-se uma mistura de *clusters* grandes e pequenos.

### Conclusão
O Modelo de Potts oferece uma generalização flexível do Modelo de Ising, permitindo modelar sistemas com múltiplos estados discretos [^11]. Sua aplicação como *prior* em segmentação de imagens demonstra sua utilidade em problemas onde a similaridade entre elementos vizinhos é um fator importante [^11]. A capacidade de controlar a força da associação entre estados através do parâmetro *J*, juntamente com o fenômeno de transição de fase, confere ao Modelo de Potts uma rica dinâmica e aplicabilidade em diversos contextos [^11].

### Referências
[^6]: An influential paper (Geman and Geman 1984), which introduced the idea of a Gibbs sampler (Section 24.2), proposed using the Potts model as a prior for image segmentation, but the results in their paper are misleading because they did not run their Gibbs sampler for long enough. See Figure 24.10 for a vivid illustration of this point.
[^11]: It is easy to generalize the Ising model to multiple discrete states, yt ∈ {1,2,..., K}. It is common to use a potential function of the following form:\ne0 0\nVst(Ys, Yt)\n0 eJ 0\n0 0 eJ\nThis is called the Potts model.5 If J > 0, then neighboring nodes are encouraged to have the same label. Some samples from this model are shown in Figure 19.8. We see that for J > 1.44, large clusters occur, for J < 1.44, many small clusters occur, and at the critical value of K = 1.44, there is a mix of small and large clusters. This rapid change in behavior as we vary a parameter of the system is called a phase transition, and has been widely studied in the physics community. An analogous phenomenon occurs in the Ising model; see (MacKay 2003, ch 31) for details.\nThe Potts model can be used as a prior for image segmentation, since it says that neighboring pixels are likely to have the same discrete label and hence belong to the same segment. We can combine this prior with a likelihood term as follows:\np(y, x|0) = p(y|J) [ P(Xt|Yt, Ө 0) =\nt\n1\nZ(J)\n(Ys, Yt; J) [P(XtYt, 0)\nПψ(Уа,\ns~t\nt\nwhere p(xt|Yt = k, 0) is the probability of observing pixel xt given that the corresponding segment belongs to class k. This observation model can be modeled using a Gaussian or a non-parametric density. (Note that we label the hidden nodes yt and the observed nodes xt, to be compatible with Section 19.6.)

<!-- END -->