## Treinamento de SSVMs com Métodos de Subgradiente Estocástico

### Introdução
Este capítulo explora o treinamento de **Structural Support Vector Machines (SSVMs)** utilizando **métodos de subgradiente estocástico**. Em contraste com os métodos de *cutting plane* discutidos anteriormente [^698], que requerem a solução de um programa quadrático (QP) a cada iteração, os métodos de subgradiente estocástico oferecem uma alternativa computacionalmente mais eficiente para lidar com grandes conjuntos de dados [^700].

### Conceitos Fundamentais

Os métodos de subgradiente estocástico atualizam iterativamente os pesos do modelo com base no gradiente de um único exemplo de treinamento [^700]. Essa abordagem contrasta com os métodos de *batch gradient descent*, que calculam o gradiente usando todos os exemplos de treinamento. A natureza estocástica dos métodos de subgradiente permite uma convergência mais rápida, especialmente em grandes conjuntos de dados, pois cada atualização de peso é baseada em uma amostra aleatória dos dados [^700].

**Algoritmos Exemplares:**

1.  **Structured Perceptron Algorithm:** Uma extensão do algoritmo perceptron tradicional para problemas de saída estruturada [^700]. A cada iteração, o algoritmo prediz a saída para um exemplo de treinamento e atualiza os pesos se a previsão estiver incorreta. A atualização de peso é dada por:

    $$     w_{k+1} = w_k + \phi(y,x) - \phi(\hat{y}, x)     $$

    onde $w_k$ são os pesos na iteração $k$, $\phi(y,x)$ é o vetor de características conjuntas para a saída correta $y$ e a entrada $x$, e $\phi(\hat{y}, x)$ é o vetor de características conjuntas para a saída prevista $\hat{y}$ e a entrada $x$ [^701].
2.  **Pegasos Algorithm:** Um algoritmo de subgradiente estocástico específico para SVMs, que pode ser estendido para SSVMs [^701]. O algoritmo Pegasos minimiza a seguinte função objetivo:

    $$     f(w) = \sum_{i=1}^{N} \max_{\hat{y}_i} [L(y_i, \hat{y}_i) + w^T \phi(x_i, \hat{y}_i)] - w^T \phi(x_i, y_i) + \lambda ||w||^2     $$

    onde $L(y_i, \hat{y}_i)$ é a função de perda, $\lambda$ é um parâmetro de regularização e $||w||^2$ é a norma $L_2$ dos pesos. O algoritmo Pegasos realiza atualizações de subgradiente estocásticas para minimizar esta função objetivo [^701].

**Algoritmos Online:**

Tanto o algoritmo do perceptron estruturado quanto o *stochastic gradient descent* (SGD) são exemplos de algoritmos online. Algoritmos online processam exemplos de treinamento sequencialmente e atualizam os pesos do modelo após cada exemplo [^700]. Essa abordagem os torna adequados para cenários onde os dados chegam em fluxo ou onde o conjunto de dados é muito grande para caber na memória [^700].

### Conclusão
Os métodos de subgradiente estocástico fornecem uma abordagem escalável e eficiente para o treinamento de SSVMs, especialmente quando se lida com grandes conjuntos de dados [^700]. Algoritmos como o *structured perceptron* e o Pegasos oferecem alternativas viáveis aos métodos de *cutting plane*, permitindo o treinamento de modelos complexos de saída estruturada com recursos computacionais limitados [^701].

### Referências
[^700]: Chapter 19. Undirected graphical models (Markov random fields), page 700.
[^701]: Chapter 19. Undirected graphical models (Markov random fields), page 701.
[^698]: Chapter 19. Undirected graphical models (Markov random fields), page 698.

<!-- END -->