## A Conexão da Distribuição de Gibbs com Modelos Gráficos Não Direcionados e Física Estatística

### Introdução
Este capítulo explora a profunda conexão entre **Modelos Gráficos Não Direcionados** (UGMs) e conceitos da **física estatística**, especificamente através da **distribuição de Gibbs** [^6]. UGMs, também conhecidos como **Campos Aleatórios de Markov** (MRFs) ou **redes de Markov** [^1], oferecem uma abordagem alternativa aos **Modelos Gráficos Direcionados** (DGMs), ou redes Bayesianas [^1]. A distribuição de Gibbs serve como uma ponte entre a representação probabilística de UGMs e a modelagem de sistemas físicos, onde a probabilidade de um estado é proporcional a $exp(-E(y))$, com $E(y)$ representando a energia associada a esse estado [^6].

### Conceitos Fundamentais

A **distribuição de Gibbs**, também conhecida como **distribuição de Boltzmann**, desempenha um papel fundamental na modelagem de sistemas em equilíbrio térmico na física estatística [^6]. Em UGMs, ela oferece uma maneira de expressar a probabilidade conjunta de um conjunto de variáveis aleatórias discretas ou contínuas. A distribuição de Gibbs é definida como:

$$ p(y|\theta) = \frac{1}{Z(\theta)} exp(-E(y|\theta)) $$

onde:
*   $y$ representa um estado específico do sistema (uma atribuição de valores a todas as variáveis no modelo).
*   $E(y|\theta)$ é a função de energia do estado $y$, parametrizada por $\theta$ [^6].
*   $Z(\theta)$ é a função de partição, que garante que a distribuição de probabilidade seja normalizada [^6].
*   $\theta$ representa os parâmetros do modelo [^6].

A função de partição $Z(\theta)$ é dada por:

$$ Z(\theta) = \sum_{y} exp(-E(y|\theta)) $$

para variáveis discretas, ou

$$ Z(\theta) = \int exp(-E(y|\theta)) dy $$

para variáveis contínuas.

**Conexão com Energia:**
A beleza da distribuição de Gibbs reside na sua conexão com a noção de energia. Estados com alta probabilidade correspondem a configurações de baixa energia, refletindo o princípio fundamental de que sistemas tendem a minimizar sua energia [^6]. Isso é particularmente útil em problemas onde a energia pode ser interpretada como uma medida de "quão bem" uma configuração se encaixa em um conjunto de restrições ou padrões.

**Potenciais de Clique:**
Em UGMs, a função de energia $E(y|\theta)$ é frequentemente expressa como uma soma de potenciais de clique [^5]:

$$ E(y|\theta) = \sum_{c \in C} E(y_c|\theta_c) $$

onde:
*   $C$ é o conjunto de cliques (subconjuntos de nós completamente conectados) no grafo [^6].
*   $y_c$ são as variáveis no clique $c$ [^5].
*   $E(y_c|\theta_c)$ é o potencial de energia associado ao clique $c$, parametrizado por $\theta_c$ [^5].

Essa representação permite que a função de energia seja expressa de forma modular, capturando interações locais entre as variáveis.

**Hammersley-Clifford Theorem:**
O **Hammersley-Clifford Theorem** [^6] formaliza a equivalência entre a representação de um UGM através de potenciais de clique e as propriedades de independência condicional expressas pelo grafo. O teorema afirma que uma distribuição positiva $p(y) > 0$ satisfaz as propriedades de independência condicional de um grafo não direcionado $G$ se e somente se $p$ pode ser representada como um produto de fatores, um por clique maximal, isto é:

$$ p(y|\theta) = \frac{1}{Z(\theta)} \prod_{c \in C} \psi_c(y_c|\theta_c) $$

onde $\psi_c(y_c|\theta_c) = exp(-E(y_c|\theta_c))$ é o potencial de clique.

**Modelos Baseados em Energia (Energy-Based Models):**
Modelos que utilizam a distribuição de Gibbs são conhecidos como **modelos baseados em energia** [^6]. Esses modelos são amplamente utilizados em física, bioquímica e em diversas áreas de machine learning [^6].

**Pairwise MRF:**
Em alguns casos, é possível restringir a parametrização aos pares de nós adjacentes no grafo [^6]. Isso leva a um **Pairwise MRF**, onde a distribuição de probabilidade é expressa como:

$$ p(y|\theta) \propto \prod_{s \sim t} \psi_{st}(y_s, y_t) $$

onde $s \sim t$ indica que os nós $s$ e $t$ são vizinhos no grafo [^6].

### Conclusão

A distribuição de Gibbs fornece uma estrutura poderosa para conectar UGMs com princípios da física estatística. Ao associar estados do sistema com níveis de energia, ela permite a modelagem de interações complexas entre variáveis, enquanto o Hammersley-Clifford Theorem garante a consistência entre a representação probabilística e as propriedades de independência condicional expressas pelo grafo. O uso de potenciais de clique e a representação pairwise oferecem flexibilidade na modelagem de diferentes tipos de interações. Modelos baseados em energia, derivados da distribuição de Gibbs, encontram aplicações em diversas áreas, desde a física até o aprendizado de máquina.

### Referências
[^1]: Chapter 19. Undirected graphical models (Markov random fields).
[^5]: Section 19.3. Parameterization of MRFs.
[^6]: Section 19.3.1. The Hammersley-Clifford theorem.
<!-- END -->