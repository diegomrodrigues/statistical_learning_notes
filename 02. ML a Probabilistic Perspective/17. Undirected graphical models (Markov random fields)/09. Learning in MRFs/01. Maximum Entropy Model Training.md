## Treinamento de Modelos de Máxima Entropia com Métodos de Gradiente

### Introdução
Este capítulo aborda o treinamento de **Maximum Entropy models** (MaxEnt models) em Markov Random Fields (MRFs) utilizando métodos de gradiente. Expandindo os conceitos de aprendizado em MRFs, exploraremos como otimizar os parâmetros de um modelo de MaxEnt para que a distribuição empírica das features corresponda às predições do modelo, um processo conhecido como *moment matching* [^677].

### Conceitos Fundamentais
Em um MRF com forma log-linear [^676], a probabilidade de uma configuração **y** dado um vetor de parâmetros **θ** é definida como:
$$ p(\mathbf{y}|\mathbf{\theta}) = \frac{1}{Z(\mathbf{\theta})} \exp \left( \sum_c \mathbf{\theta}_c^T \mathbf{\phi}_c(\mathbf{y}) \right) $$
onde *c* indexa os cliques, **Φc(y)** é o vetor de features associado ao clique *c*, e *Z(θ)* é a função de partição que garante que a distribuição seja normalizada [^676].

O objetivo do treinamento é encontrar os parâmetros **θ** que maximizam a log-verossimilhança escalada, *l(θ)*, dada por [^677]:
$$ l(\mathbf{\theta}) = \frac{1}{N} \sum_i \log p(\mathbf{y}_i|\mathbf{\theta}) = \frac{1}{N} \sum_i \left( \sum_c \mathbf{\theta}_c^T \mathbf{\phi}_c(\mathbf{y}_i) - \log Z(\mathbf{\theta}) \right) $$
onde **yi** representa a i-ésima observação no conjunto de treinamento.

Para maximizar *l(θ)*, podemos usar métodos de gradiente. O gradiente da log-verossimilhança em relação a **θc** é dado por [^677]:
$$ \frac{\partial l}{\partial \mathbf{\theta}_c} = \frac{1}{N} \sum_i \left( \mathbf{\phi}_c(\mathbf{y}_i) - \mathbb{E}[\mathbf{\phi}_c(\mathbf{y})] \right) $$
Este gradiente consiste em dois termos:
1.  O **termo *clamped***: $\frac{1}{N} \sum_i \mathbf{\phi}_c(\mathbf{y}_i)$, que é a média das features observadas nos dados de treinamento.
2.  O **termo *unclamped*** ou *contrastive*: $\mathbb{E}[\mathbf{\phi}_c(\mathbf{y})]$, que é o valor esperado das features sob a distribuição do modelo. Este termo requer inferência no modelo para ser computado [^677].

No ótimo, o gradiente é zero, e a distribuição empírica das features corresponde às predições do modelo. Este conceito é conhecido como ***moment matching*** [^677]:
$$ \mathbb{E}_{p_{emp}}[\mathbf{\phi}_c(\mathbf{y})] = \mathbb{E}_{p(\mathbf{y}|\mathbf{\theta})}[\mathbf{\phi}_c(\mathbf{y})] $$

**Desafios e Soluções**
1.  **Computação do Termo *Unclamped***: O cálculo de $\mathbb{E}[\mathbf{\phi}_c(\mathbf{y})]$ geralmente é intratável, pois requer somar sobre todas as possíveis configurações de **y**. Métodos de aproximação, como Monte Carlo Markov Chain (MCMC), são frequentemente usados [^680].
2.  **Convergência Lenta**: O treinamento de UGMs (Undirected Graphical Models) é tipicamente mais lento que o treinamento de DGMs (Directed Graphical Models) devido à necessidade de inferência em cada passo do gradiente [^677].
3.  **Overfitting**: Para evitar overfitting, é importante utilizar regularização, como priors Gaussianos ou regularização L1 [^693].

**Algoritmos de Otimização**
1.  **Gradiente Descendente Estocástico (SGD)**: Uma variação comum é usar SGD com amostragem de Monte Carlo para aproximar as expectativas do modelo [^680]. O algoritmo envolve ajustar os pesos **θ** iterativamente usando mini-batches dos dados de treinamento e amostras geradas pelo modelo.
2.  **SML (Stochastic Maximum Likelihood)**: Uma técnica para acelerar o treinamento é inicializar as cadeias MCMC em seus valores anteriores, em vez de começar do zero a cada passo [^680]. Isso é baseado na ideia de que a distribuição muda apenas ligeiramente entre iterações consecutivas.

### Conclusão
O treinamento de modelos de Máxima Entropia em MRFs usando métodos de gradiente envolve a maximização da log-verossimilhança escalada, garantindo que a distribuição empírica das features corresponda às predições do modelo. Embora o processo possa ser computacionalmente intensivo devido à necessidade de inferência e à computação da função de partição, técnicas como MCMC e SGD, juntamente com estratégias de regularização, podem tornar o treinamento mais eficiente e robusto. O conceito de *moment matching* fornece uma motivação teórica para esses algoritmos, garantindo que o modelo aprenda a capturar as estatísticas importantes dos dados.

### Referências
[^676]: Capítulo 19, página 666.
[^677]: Capítulo 19, página 677.
[^680]: Capítulo 19, página 680.
[^693]: Capítulo 19, página 693.
<!-- END -->