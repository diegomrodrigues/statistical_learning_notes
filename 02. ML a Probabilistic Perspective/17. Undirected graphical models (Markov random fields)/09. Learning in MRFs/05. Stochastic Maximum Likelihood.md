## Stochastic Maximum Likelihood for Learning in MRFs

### Introdução
Este capítulo se concentra em um método específico para o aprendizado em Markov Random Fields (MRFs), o Stochastic Maximum Likelihood (SML). Como vimos anteriormente, a estimação de parâmetros em MRFs é computacionalmente desafiadora devido à necessidade de calcular a função de partição [^1]. O SML oferece uma aproximação para lidar com essa dificuldade, combinando amostragem de Monte Carlo com stochastic gradient descent.

### Conceitos Fundamentais

O Stochastic Maximum Likelihood (SML) é uma técnica utilizada para aproximar as expectativas do modelo em MRFs utilizando amostragem de Monte Carlo e stochastic gradient descent [^1]. A dificuldade na estimação de parâmetros em MRFs reside no cálculo da função de partição, $Z(\theta)$, que é necessária para normalizar a distribuição de probabilidade [^1]:

$$
p(y|\theta) = \frac{1}{Z(\theta)} \prod_{c \in C} \psi_c(y_c|\theta_c)
$$

onde $C$ é o conjunto de cliques (conjuntos maximais de nós completamente conectados) no grafo, $y_c$ são as variáveis na clique $c$, $\psi_c$ é a função potencial associada à clique $c$, e $\theta_c$ são os parâmetros associados a esta função [^1].

O SML busca otimizar os parâmetros $\theta$ do modelo, aproximando o gradiente da log-verossimilhança [^1]. O gradiente da log-verossimilhança escalonada (scaled log-likelihood) é dado por [^1]:

$$
\frac{\partial \ell}{\partial \theta_c} = \frac{1}{N} \sum_i \left[ \phi_c(y_i) - \frac{\partial}{\partial \theta_c} \log Z(\theta) \right]
$$

onde $\ell(\theta)$ é a log-verossimilhança escalonada, $N$ é o número de amostras, e $\phi_c(y)$ são as estatísticas suficientes [^1]. A derivada do log da função de partição é a expectativa das estatísticas suficientes sob a distribuição do modelo [^1]:

$$
\frac{\partial \log Z(\theta)}{\partial \theta_c} = E_{\theta}[\phi_c(y)] = \sum_y \phi_c(y) p(y|\theta)
$$

Substituindo na equação do gradiente, obtemos [^1]:

$$
\frac{\partial \ell}{\partial \theta_c} = \frac{1}{N} \sum_i \left[ \phi_c(y_i) - E_{\theta}[\phi_c(y)] \right]
$$

O termo $\phi_c(y_i)$ é chamado de **clamped term**, pois fixa $y$ aos seus valores observados. O termo $E_{\theta}[\phi_c(y)]$ é chamado de **unclamped term** ou **contrastive term** e requer inferência no modelo [^1].

A dificuldade reside em calcular essa expectativa, pois requer somar sobre todas as possíveis configurações de $y$. O SML aproxima essa expectativa usando amostragem de Monte Carlo [^1]:

$$
E_{\theta}[\phi(y)] \approx \hat{E}(\phi(y)) = \frac{1}{S} \sum_{s=1}^S \phi(y^{s,k})
$$

onde $y^{s,k}$ são amostras geradas usando MCMC [^1]. Para aumentar a eficiência, o SML inicializa a cadeia MCMC em seu valor anterior, $y^{s,k-1}$ [^1]. Isso é válido porque $p(y|\theta^k)$ é provavelmente próximo de $p(y|\theta^{k-1})$, já que os parâmetros mudam apenas um pouco [^1].

O algoritmo SML pode ser resumido da seguinte forma [^1]:
1. Inicializar os pesos $\theta$ aleatoriamente [^1].
2. Para cada época [^1]:
    1. Para cada minibatch de tamanho B [^1]:
        1. Para cada amostra s = 1: S [^1]:
            1. Amostrar $y^{s,k} \sim p(y|\theta^k)$ [^1].
        2. Estimar $\hat{E}(\phi(y)) = \frac{1}{S} \sum_{s=1}^S \phi(y^{s,k})$ [^1].
        3. Para cada caso de treinamento i no minibatch [^1]:
            1. $g_{ik} = \phi(y_i) - \hat{E}(\phi(y))$ [^1].
        4. $g_k = \frac{1}{B} \sum_{i \in B} g_{ik}$ [^1].
        5. $\theta_{k+1} = \theta_k - \eta g_k$ [^1].

A taxa de aprendizado $\eta$ é diminuída ao longo do tempo [^1]. Este algoritmo é conhecido como Stochastic Maximum Likelihood ou SML [^1]. Existe um algoritmo intimamente relacionado chamado persistent contrastive divergence, que é discutido na seção 27.7.2.5 [^1].

### Conclusão

O Stochastic Maximum Likelihood (SML) oferece uma abordagem prática para o aprendizado de parâmetros em MRFs, contornando a dificuldade computacional do cálculo da função de partição. Ao combinar amostragem de Monte Carlo com stochastic gradient descent e inicializar a cadeia MCMC com valores anteriores, o SML torna-se uma ferramenta eficiente para a estimação de modelos complexos em domínios onde MRFs são aplicáveis.

### Referências
[^1]:  (Todas as informações foram extraídas do contexto fornecido.)
<!-- END -->