## Métodos Aproximados para Estimativas de Máxima Verossimilhança (MLEs) em MRFs

### Introdução
Em modelos de Markov Random Fields (MRFs), a inferência exata é frequentemente intratável, o que torna necessário o uso de métodos aproximados para calcular as estimativas de máxima verossimilhança (MLEs). Este capítulo explora duas abordagens principais: pseudo-verossimilhança e máxima verossimilhança estocástica. A pseudo-verossimilhança maximiza o produto das condicionais completas, enquanto a máxima verossimilhança estocástica utiliza amostragem de Monte Carlo para aproximar as expectativas do modelo [^1].

### Conceitos Fundamentais

#### A Necessidade de Métodos Aproximados
A estimação de parâmetros em MRFs é um desafio devido à complexidade computacional da função de partição, $Z(\theta)$ [^6]. O cálculo exato do gradiente da log-verossimilhança requer a computação de expectativas sob a distribuição do modelo, o que envolve somar sobre todas as configurações possíveis das variáveis [^18]. Em modelos onde a inferência é intratável, essa soma torna-se impraticável, motivando a busca por alternativas computacionalmente mais eficientes [^1].

#### Pseudo-Verossimilhança
A **pseudo-verossimilhança** (PL) é uma alternativa à MLE que maximiza o produto das condicionais completas [^1, 18]. Em vez de modelar a distribuição conjunta $p(y|\theta)$ diretamente, a PL foca em modelar cada variável condicionalmente às suas vizinhas, $p(y_d|y_{-d})$ [^18, 19]. A função objetivo da pseudo-verossimilhança é dada por:

$$ \ell_{CPL}(\theta) \triangleq \sum_y p_{emp}(y) \sum_{d=1}^D \log p(y_d|y_{-d}, \theta) = \frac{1}{N} \sum_{i=1}^N \sum_{d=1}^D \log p(y_{id}|y_{i, -d}, \theta) $$

onde $p_{emp}(y)$ é a distribuição empírica dos dados, $D$ é o número de variáveis, e $p(y_d|y_{-d}, \theta)$ é a condicional completa da variável $y_d$ dado o restante das variáveis $y_{-d}$ [^18].

A vantagem da PL é que a computação de cada condicional completa requer apenas somar sobre os estados de uma única variável, o que é computacionalmente mais tratável do que calcular a função de partição [^19]. No entanto, a PL pode apresentar inconsistências e não converge necessariamente para a MLE verdadeira [^19].

Em Gaussian MRFs, a PL é equivalente à MLE [^19]. No entanto, esta equivalência não se mantém em geral [^19]. Uma desvantagem da PL é que ela é difícil de aplicar a modelos com variáveis ocultas [^19]. Além disso, cada nó assume que seus vizinhos têm valores conhecidos [^19].

#### Máxima Verossimilhança Estocástica
A **máxima verossimilhança estocástica** (SML) é um método aproximado que usa amostragem de Monte Carlo para aproximar as expectativas do modelo necessárias para calcular o gradiente da log-verossimilhança [^1, 18, 20]. O gradiente da log-verossimilhança para um MRF totalmente observado é dado por:

$$ \nabla \ell(\theta) = \frac{1}{N} \sum_i [\phi(y_i) - \mathbb{E}_{\theta}[\phi(y)]] $$

onde $\phi(y)$ é o vetor de características [^19]. A SML aproxima a expectativa $\mathbb{E}_{\theta}[\phi(y)]$ usando amostras geradas por MCMC [^20]. O algoritmo SML envolve os seguintes passos:

1.  Inicializar os pesos $\theta$ aleatoriamente [^20].
2.  Para cada minibatch de tamanho $B$:
    *   Para cada amostra $s = 1:S$:
        *   Amostrar $y^{s,k} \sim p(y|\theta^k)$ [^20].
    *   Estimar $\hat{\mathbb{E}}(\phi(y)) = \frac{1}{S} \sum_{s=1}^S \phi(y^{s,k})$ [^20].
    *   Para cada caso de treinamento $i$ no minibatch:
        *   Calcular $g_{ik} = \phi(y_i) - \hat{\mathbb{E}}(\phi(y))$ [^20].
    *   Calcular $g_k = \frac{1}{|B|} \sum_{i \in B} g_{ik}$ [^20].
    *   Atualizar $\theta^{k+1} = \theta^k - \eta g_k$ [^20].
    *   Diminuir o tamanho do passo $\eta$ [^20].

A SML é mais precisa que a PL, mas também mais computacionalmente intensiva, pois requer a execução de MCMC para cada atualização do gradiente [^20]. Para acelerar a convergência, é comum inicializar a cadeia MCMC com o valor anterior, aproveitando o fato de que a distribuição muda gradualmente [^20].

### Conclusão

Os métodos aproximados para MLEs em MRFs, como a pseudo-verossimilhança e a máxima verossimilhança estocástica, são ferramentas essenciais quando a inferência exata é intratável. A pseudo-verossimilhança oferece uma alternativa computacionalmente eficiente, enquanto a máxima verossimilhança estocástica busca uma aproximação mais precisa através da amostragem de Monte Carlo. A escolha do método depende do compromisso entre precisão e custo computacional, bem como das características específicas do modelo e dos dados [^1, 18, 19, 20].

### Referências
[^1]: Koller, D., & Friedman, N. (2009). *Probabilistic graphical models: principles and techniques*. MIT press.
[^6]: Capítulo 19 do texto base.
[^18]: Seção 19.5.3 do texto base.
[^19]: Seção 19.5.4 do texto base.
[^20]: Seção 19.5.5 do texto base.
<!-- END -->