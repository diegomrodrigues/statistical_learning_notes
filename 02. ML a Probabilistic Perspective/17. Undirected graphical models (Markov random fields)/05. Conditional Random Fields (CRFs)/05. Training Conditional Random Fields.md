## Treinamento de CRFs

### Introdução
Em modelos gráficos não direcionados, como os **Conditional Random Fields (CRFs)**, o treinamento envolve a otimização dos parâmetros do modelo com base nos dados de treinamento disponíveis. Diferentemente dos modelos generativos, os CRFs são modelos discriminativos que modelam diretamente a probabilidade condicional $p(y|x)$, onde $y$ representa as variáveis de saída (rótulos) e $x$ representa as variáveis de entrada (observações) [^684]. Este capítulo detalha o processo de treinamento para CRFs, com foco na otimização baseada em gradiente.

### Conceitos Fundamentais

#### Função de Log-Verossimilhança Escalonada
O treinamento de CRFs envolve a modificação da otimização baseada em gradiente de MRFs para o caso CRF de uma maneira direta [^692]. Em particular, a **log-verossimilhança escalonada** é dada por [^692]:
$$\nl(w) = \frac{1}{N}\sum_i \log p(y_i|x_i, w) = \frac{1}{N}\sum_i \left[ \sum_c w^T\phi_c(y_i, x_i) - \log Z(w, x_i) \right]\n$$
onde:
*   $N$ é o número de amostras de treinamento.
*   $y_i$ é a saída (rótulo) para a $i$-ésima amostra.
*   $x_i$ é a entrada (observação) para a $i$-ésima amostra.
*   $w$ é o vetor de parâmetros do modelo.
*   $\phi_c(y_i, x_i)$ é a função de característica associada ao clique $c$ para a $i$-ésima amostra.
*   $Z(w, x_i)$ é a função de partição, que garante que a distribuição de probabilidade seja normalizada.

#### Gradiente da Log-Verossimilhança
O **gradiente da log-verossimilhança** em relação a um parâmetro específico $w_c$ é dado por [^692]:
$$\n\frac{\partial l}{\partial w_c} = \frac{1}{N}\sum_i \left[ \phi_c(y_i, x_i) - E[\phi_c(y, x_i)] \right]\n$$
onde $E[\phi_c(y, x_i)]$ é o valor esperado da função de característica $\phi_c(y, x_i)$ sob a distribuição condicional $p(y|x_i, w)$.

#### Inferência Durante o Treinamento
Uma característica distintiva do treinamento de CRFs é a necessidade de realizar a **inferência** para cada caso de treinamento dentro de cada etapa de gradiente [^692]. Isso é necessário para calcular o valor esperado $E[\phi_c(y, x_i)]$. A inferência envolve encontrar a atribuição mais provável para as variáveis de saída $y$ dado as variáveis de entrada $x_i$ e os parâmetros atuais $w$.

#### Custo Computacional
A necessidade de realizar a inferência para cada caso de treinamento torna o treinamento de CRFs $O(N)$ vezes mais lento do que o treinamento de modelos Markov Random Field (MRF) generativos [^692]. Isso ocorre porque o custo computacional da inferência é significativo e deve ser repetido para cada amostra de treinamento em cada iteração do algoritmo de otimização.

#### Normalização Global
A solução de utilizar CRFs tem um preço: não obtemos uma distribuição de probabilidade válida sobre $y$ até que tenhamos visto a frase inteira, pois somente então podemos normalizar sobre todas as configurações [^692]. Isso significa que a normalização é global, ao contrário dos modelos generativos onde a normalização pode ser local.

### Conclusão

O treinamento de CRFs envolve a otimização da função de log-verossimilhança escalonada usando métodos baseados em gradiente. O cálculo do gradiente requer a inferência para cada amostra de treinamento em cada etapa de gradiente, o que torna o treinamento computacionalmente intensivo. No entanto, a capacidade de modelar diretamente a probabilidade condicional $p(y|x)$ e incorporar características globais torna os CRFs uma ferramenta poderosa para uma variedade de tarefas de modelagem sequencial e estruturada.

### Referências
[^692]: Capítulo 19, Undirected graphical models (Markov random fields), página 692
[^684]: Capítulo 19, Undirected graphical models (Markov random fields), página 684

<!-- END -->