## Normalized Cut for Spectral Clustering

### Introdução
Em continuidade ao contexto de **Spectral Clustering**, este capítulo se aprofunda no conceito de **Normalized Cut (Ncut)** [^891], uma função de custo crucial para particionar grafos de forma eficaz. Diferentemente de cortes simples que podem isolar nós individuais, o Ncut busca equilibrar o tamanho dos clusters resultantes, garantindo que nenhum cluster seja desproporcionalmente pequeno. Esta abordagem é particularmente útil quando os nós dentro de cada cluster são similares, mas diferentes dos nós em outros clusters [^891].

### Conceitos Fundamentais

O **Normalized Cut (Ncut)** é definido como [^891]:

$$ Ncut(A_1,..., A_K) = \sum_{k=1}^{K} \frac{cut(A_k, \overline{A_k})}{vol(A_k)} $$

onde:

*   $A_1, ..., A_K$ representam os $K$ clusters nos quais o grafo é particionado.
*   $cut(A_k, \overline{A_k})$ é a soma dos pesos das arestas que conectam o cluster $A_k$ ao seu complemento $\overline{A_k}$, ou seja, $cut(A_k, \overline{A_k}) = \sum_{i \in A_k, j \in \overline{A_k}} w_{ij}$ [^891].
*   $vol(A_k)$ é o volume do cluster $A_k$, definido como a soma dos graus ponderados dos nós em $A_k$, ou seja, $vol(A_k) = \sum_{i \in A_k} d_i$, onde $d_i = \sum_{j=1}^{N} w_{ij}$ é o grau ponderado do nó $i$ [^891].

O objetivo do Ncut é minimizar a soma normalizada dos cortes entre os clusters [^891]. A normalização pelo volume dos clusters evita que o algoritmo favoreça a criação de clusters pequenos e isolados.

A minimização do Ncut pode ser vista como um problema de busca por vetores binários $c_i \in \{0, 1\}^N$, onde $c_{ik} = 1$ se o ponto $i$ pertence ao cluster $k$ [^891]. No entanto, este problema é NP-difícil [^891]. Uma abordagem comum é relaxar a restrição de que os vetores $c_i$ sejam binários, permitindo que assumam valores reais [^891]. Essa relaxação transforma o problema em um problema de autovetor, conhecido como *spectral clustering* [^891].

O *spectral clustering* se baseia na teoria espectral de grafos, que envolve a análise dos autovetores da matriz Laplaciana do grafo [^891]. A matriz Laplaciana é definida como $L = D - W$, onde $D$ é uma matriz diagonal contendo os graus ponderados dos nós e $W$ é a matriz de pesos das arestas [^891].

A matriz Laplaciana normalizada pode ser definida de duas formas [^892]:

1.  $L_{rw} = D^{-1}L = I - D^{-1}W$, que é uma matriz estocástica onde cada linha soma um [^892].
2.  $L_{sym} = D^{-1/2}LD^{-1/2} = I - D^{-1/2}WD^{-1/2}$, que é uma matriz simétrica [^892].

Os autovetores correspondentes aos menores autovalores de $L$ (ou $L_{rw}$ ou $L_{sym}$) fornecem informações sobre a estrutura de clusters do grafo [^892]. Em particular, os autovetores associados ao autovalor 0 são indicadores das componentes conexas do grafo [^891].

**Teorema 25.4.1 [^891]:** *O conjunto de autovetores de $L$ com autovalor 0 é gerado pelos vetores indicadores $1_{A_1}, ..., 1_{A_K}$, onde $A_k$ são as $K$ componentes conexas do grafo.*

A prova deste teorema demonstra que, se $f$ é um autovetor com autovalor 0, então $f$ é constante em todos os vértices conectados por um caminho no grafo. Assim, para grafos com $K$ componentes conexas, existem $K$ funções indicadoras que "selecionam" as componentes conexas [^892].

O algoritmo geral para *spectral clustering* envolve os seguintes passos [^892]:

1.  Calcular a matriz Laplaciana (normalizada ou não) do grafo.
2.  Calcular os $K$ primeiros autovetores $u_1, ..., u_K$ da matriz Laplaciana.
3.  Construir a matriz $U = [u_1, ..., u_K]$, onde cada coluna corresponde a um autovetor.
4.  Para cada nó $i$, seja $y_i \in \mathbb{R}^K$ a $i$-ésima linha de $U$.
5.  Aplicar o algoritmo K-means aos vetores $y_i$ para agrupar os nós em $K$ clusters.
6.  Atribuir o nó $i$ ao cluster $k$ se a linha $i$ de $Y$ foi atribuída ao cluster $k$.

### Conclusão

O Normalized Cut (Ncut) oferece uma abordagem robusta para particionar grafos, evitando a criação de clusters desequilibrados [^891]. Ao normalizar o custo do corte pelo volume dos clusters, o Ncut incentiva a formação de clusters com tamanhos comparáveis [^891]. A relaxação do problema de otimização do Ncut leva ao *spectral clustering*, uma técnica poderosa que utiliza a teoria espectral de grafos para identificar a estrutura de clusters [^891]. Os autovetores da matriz Laplaciana fornecem uma representação dos nós que pode ser agrupada usando algoritmos como o K-means [^892].

### Referências

[^891]: Capítulo 25, Clustering, Seção 25.4, Spectral clustering.
[^892]: Capítulo 25, Clustering, Seção 25.4.2, Normalized graph Laplacian.

<!-- END -->