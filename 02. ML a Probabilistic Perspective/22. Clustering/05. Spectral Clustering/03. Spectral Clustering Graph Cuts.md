## Spectral Clustering e Cortes de Grafos

### Introdução
Este capítulo explora o conceito de **Spectral Clustering**, uma técnica poderosa para agrupar dados que se baseia na teoria dos grafos e na análise espectral de matrizes. Em particular, focaremos na formulação do problema de clustering como um problema de *graph cut* [^890], onde o objetivo é particionar um grafo ponderado em clusters, minimizando o "custo" dos cortes entre esses clusters.

### Conceitos Fundamentais
O *Spectral Clustering* utiliza cortes de grafos em um grafo não direcionado ponderado $W$ derivado da matriz de similaridade $S$ para particionar os dados em $K$ clusters [^890]. A ideia central é transformar o problema de clustering em um problema de otimização em grafos.

**Definição do Grafo Ponderado $W$**:
Dado um conjunto de dados, constrói-se um grafo $W$ onde cada nó representa um ponto de dado e o peso das arestas entre os nós $i$ e $j$, denotado por $W_{ij}$, reflete a similaridade entre os pontos $i$ e $j$. A matriz de similaridade $S$ [^1] é usada para definir esses pesos.  A similaridade pode ser calculada de diversas formas, como a distância Euclidiana [^876] ou outras medidas de dissimilaridade convertidas em similaridade. Frequentemente, apenas as $k$ vizinhanças mais próximas de cada ponto são consideradas para criar um grafo esparso, o que acelera os cálculos [^890].

**Cortes de Grafos e a Função Objetivo**:
O objetivo do *Spectral Clustering* é encontrar uma partição dos nós do grafo em $K$ clusters, $A_1, A_2, ..., A_K$, de tal forma que as arestas entre os clusters tenham um peso total mínimo. Isso é formalizado pela função *cut* [^890]:

$$ cut(A_1, ..., A_K) = \frac{1}{2} \sum_{k=1}^{K} W(A_k, \overline{A_k})$$

onde $W(A, B)$ é a soma dos pesos das arestas entre os conjuntos de nós $A$ e $B$, e $\overline{A_k}$ é o complemento do conjunto $A_k$. A função $cut(A_1, ..., A_K)$ mede o "custo" total de cortar as arestas entre os clusters.

**Problemas com o Critério *cut***:
Minimizar diretamente o *cut* pode levar a soluções degeneradas, onde um ou mais clusters são muito pequenos, contendo apenas alguns pontos isolados [^891]. Para mitigar esse problema, utiliza-se o conceito de *normalized cut* (Ncut).

**Normalized Cut (Ncut)**:
O *Ncut* normaliza o *cut* pelo "volume" dos clusters, onde o volume de um cluster $A$ é definido como a soma dos graus dos nós em $A$ [^891]:

$$Ncut(A_1, ..., A_K) = \sum_{k=1}^{K} \frac{cut(A_k, \overline{A_k})}{vol(A_k)}$$

onde $vol(A) = \sum_{i \in A} d_i$ e $d_i = \sum_{j=1}^{N} W_{ij}$ é o grau do nó $i$ [^891]. O *Ncut* busca equilibrar o tamanho dos clusters, evitando soluções onde clusters pequenos são isolados do resto do grafo.

**Formulação Matricial e Relaxação do Problema**:
O problema de minimizar o *Ncut* pode ser formulado em termos de vetores binários $c_i \in \{0, 1\}^N$, onde $c_{ik} = 1$ se o ponto $i$ pertence ao cluster $k$ e $0$ caso contrário [^891]. No entanto, essa formulação é NP-difícil. Uma abordagem comum é relaxar a restrição de que $c_i$ seja binário e permitir que assuma valores reais [^891]. Essa relaxação transforma o problema em um problema de autovalores, que pode ser resolvido eficientemente.

**O Laplaciano do Grafo**:
O *Spectral Clustering* faz uso do Laplaciano do grafo, uma matriz que captura a estrutura de conectividade do grafo [^891]. O Laplaciano do grafo $L$ é definido como:

$$L = D - W$$

onde $D$ é uma matriz diagonal com os graus dos nós na diagonal, $D_{ii} = d_i$. Existem também versões normalizadas do Laplaciano, como $L_{rw} = D^{-1}L$ e $L_{sym} = D^{-\frac{1}{2}}LD^{-\frac{1}{2}}$ [^892].

**Autovetores e Clustering**:
Os autovetores do Laplaciano do grafo contêm informações sobre a estrutura do grafo e podem ser usados para realizar o clustering [^891]. Em particular, os autovetores correspondentes aos menores autovalores de $L$ (ou os maiores autovetores de $W$) são usados para representar os dados em um espaço de dimensão reduzida, onde o clustering pode ser realizado com algoritmos como o K-means [^892].

**Algoritmo Geral do Spectral Clustering**:
1. **Construir a matriz de similaridade** $S$ a partir dos dados [^1].
2. **Construir o grafo ponderado** $W$ a partir de $S$ [^890].
3. **Calcular o Laplaciano do grafo** $L$ (ou uma versão normalizada) [^891].
4. **Calcular os $K$ menores autovetores** de $L$ [^892].
5. **Formar a matriz $U$** com os autovetores como colunas [^892].
6. **Aplicar o algoritmo K-means** às linhas de $U$ para obter os clusters [^892].

### Conclusão
O *Spectral Clustering* oferece uma abordagem flexível e poderosa para o clustering de dados, especialmente quando os clusters não são convexos ou linearmente separáveis. Ao transformar o problema de clustering em um problema de *graph cut*, o *Spectral Clustering* pode capturar a estrutura global dos dados e produzir resultados de alta qualidade. As diferentes versões do Laplaciano do grafo e as técnicas de normalização permitem adaptar o algoritmo a diferentes tipos de dados e estruturas de grafo.

### Referências
[^876]: Capítulo 25, Seção 25.1.1
[^890]: Capítulo 25, Seção 25.4
[^1]: Capítulo 25, Seção 25.1
[^891]: Capítulo 25, Seção 25.4
[^892]: Capítulo 25, Seção 25.4
<!-- END -->