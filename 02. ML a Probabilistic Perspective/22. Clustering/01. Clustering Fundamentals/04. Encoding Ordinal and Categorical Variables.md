## Codificação e Distâncias para Variáveis Ordinais e Categóricas em Clustering

### Introdução
Em algoritmos de *clustering*, a forma como as variáveis são representadas e as medidas de (dis)similaridade utilizadas têm um impacto significativo nos resultados. Este capítulo detalha abordagens específicas para lidar com variáveis ordinais e categóricas, que frequentemente aparecem em conjuntos de dados do mundo real. A escolha adequada da codificação e da função de distância é crucial para extrair *clusters* significativos e interpretáveis [^1].

### Conceitos Fundamentais

#### Variáveis Ordinais
As **variáveis ordinais** representam dados que possuem uma ordem inerente, mas as distâncias entre os valores não são uniformemente definidas [^2]. Exemplos típicos incluem escalas de avaliação como "baixo", "médio" e "alto". Para aplicar funções de dissimilaridade quantitativas a essas variáveis, é comum codificá-las como números reais.

A codificação padrão [^2] envolve mapear os valores ordinais para um intervalo numérico, geralmente entre 0 e 1. Se houver *k* valores possíveis, eles podem ser representados como $1/k, 2/k, ..., k/k$. Por exemplo, para a escala {baixo, médio, alto}, poderíamos usar a codificação {1/3, 2/3, 3/3}.

Após a codificação, qualquer função de dissimilaridade adequada para variáveis quantitativas pode ser aplicada [^2]. Funções comuns incluem a **distância Euclidiana**, onde a dissimilaridade entre dois objetos $x_i$ e $x_{i'}$ para um atributo *j* é definida como:

$$Delta_j(x_{ij}, x_{i'j}) = (x_{ij} - x_{i'j})^2$$

Outra alternativa é a **distância de city block** ($l_1$):

$$Delta_j(x_{ij}, x_{i'j}) = |x_{ij} - x_{i'j}|$$

A escolha entre essas funções depende das características dos dados e do efeito desejado da dissimilaridade. A distância Euclidiana enfatiza maiores diferenças, enquanto a distância de city block é mais robusta a *outliers* [^2].

#### Variáveis Categóricas
As **variáveis categóricas** representam dados que não possuem uma ordem inerente. Exemplos incluem cores (vermelho, verde, azul) ou tipos de produtos (A, B, C) [^2]. A abordagem mais comum para medir a dissimilaridade entre variáveis categóricas é atribuir uma distância de 1 se os valores forem diferentes e 0 se forem iguais.

Formalmente, se $x_{ij}$ e $x_{i'j}$ são os valores do atributo *j* para os objetos $x_i$ e $x_{i'}$, então a dissimilaridade é definida como:

$$ \Delta_j(x_{ij}, x_{i'j}) = \begin{cases}     0, & \text{se } x_{ij} = x_{i'j} \\     1, & \text{se } x_{ij} \neq x_{i'j} \end{cases} $$

Para conjuntos de dados com múltiplos atributos categóricos, a **distância de Hamming** é frequentemente utilizada [^2]. Ela quantifica o número de atributos em que dois objetos diferem:

$$Delta(x_i, x_{i'}) = \sum_{j=1}^D I(x_{ij} \neq x_{i'j})$$
onde *D* é o número total de atributos categóricos e $I(\cdot)$ é uma função indicadora que retorna 1 se a condição for verdadeira e 0 caso contrário.

### Conclusão
A correta representação e a escolha da função de distância são etapas cruciais no processo de *clustering*, especialmente quando se lida com variáveis ordinais e categóricas. A codificação de variáveis ordinais como números reais permite o uso de funções de dissimilaridade quantitativas, enquanto a distância de Hamming é uma medida eficaz para variáveis categóricas. A seleção da abordagem mais adequada depende das características específicas dos dados e dos objetivos da análise de *clustering*.

### Referências
[^1]: Clustering is the process of grouping similar objects together. There are two kinds of inputs we might use. In similarity-based clustering, the input to the algorithm is an N × N dissimilarity matrix or distance matrix D.
[^2]: For ordinal variables, such as {low, medium, high}, it is standard to encode the values as real-valued numbers, say 1/3,2/3,3/3 if there are 3 possible values. One can then apply any dissimilarity function for quantitative variables, such as squared distance. For categorical variables, such as {red, green, blue}, we usually assign a distance of 1 if the features are different, and a distance of 0 otherwise. Summing up over all the categorical features gives Δ(xi, xi') = ∑j I(xij ≠ xi'j).

<!-- END -->