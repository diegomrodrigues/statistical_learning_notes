## Dirichlet Process Mixture Models: Definição e Propriedades do Processo de Dirichlet

### Introdução
Em continuidade ao estudo de modelos de *clustering*, particularmente aqueles baseados em modelos probabilísticos [^877], este capítulo se aprofunda nos **Dirichlet Process Mixture Models (DPMMs)**, com foco no **Processo de Dirichlet (DP)** como um componente fundamental [^879]. Exploraremos a definição formal do DP, suas propriedades e como ele é utilizado para construir modelos de mistura infinitos, superando as limitações dos modelos de mistura finitos [^879].

### Conceitos Fundamentais
O Processo de Dirichlet (DP) é uma distribuição sobre medidas de probabilidade, denotada como $G: \Theta \rightarrow \mathbb{R}^+$ [^882]. Ele é definido implicitamente pela seguinte propriedade: para qualquer partição finita $(T_1, ..., T_k)$ de $\Theta$, a distribuição conjunta das medidas de probabilidade atribuídas a cada partição segue uma distribuição de Dirichlet [^882]:
$$(G(T_1), ..., G(T_k)) \sim Dir(\alpha H(T_1), ..., \alpha H(T_k))$$
onde:
- $\alpha$ é o **parâmetro de concentração**, um escalar positivo que controla a dispersão da distribuição em torno da medida base [^882].
- $H$ é a **medida base**, uma distribuição de probabilidade sobre $\Theta$ que representa a expectativa *a priori* para a distribuição $G$ [^882].

Em outras palavras, o DP garante que a probabilidade atribuída a qualquer conjunto $T_i$ seja uma variável aleatória com uma distribuição Beta [^882]:
$$G(T_i) \sim Beta(\alpha H(T_i), \alpha \sum_{j \neq i} H(T_j))$$
Essa propriedade de consistência é crucial para a definição do DP.

**Concentração e Medida Base**
O parâmetro de concentração $\alpha$ desempenha um papel fundamental na forma da distribuição $G$. Se $\alpha$ for grande, a distribuição $G$ tenderá a ser semelhante à medida base $H$. Por outro lado, se $\alpha$ for pequeno, $G$ será mais dispersa e concentrada em alguns poucos valores [^882]. A medida base $H$ influencia a localização dos valores em que $G$ se concentra. Ela representa a nossa crença *a priori* sobre onde os dados estão localizados [^882].

**Natureza Discreta**
Uma propriedade importante do DP é que amostras retiradas dessa distribuição são discretas com probabilidade um [^884]. Isso significa que a distribuição $G$ atribuirá probabilidade positiva apenas a um conjunto discreto de pontos em $\Theta$. Essa propriedade é fundamental para a utilização do DP em modelos de mistura [^884].

**Representação Construtiva: Stick-Breaking**
Uma forma útil de visualizar e construir amostras do DP é através do método *stick-breaking* [^883]. Nesse método, geramos uma sequência infinita de pesos $\pi_k$ da seguinte forma:
$$begin{aligned} \beta_k &\sim Beta(1, \alpha) \\ \pi_k &= \beta_k \prod_{l=1}^{k-1} (1 - \beta_l) = \beta_k \left(1 - \sum_{l=1}^{k-1} \pi_l\right) \end{aligned}$$
onde $\beta_k$ são variáveis Beta independentes e $\pi_k$ são os pesos resultantes. Esses pesos somam um, garantindo que representem uma distribuição de probabilidade [^883].

Em seguida, amostramos uma sequência infinita de parâmetros $\theta_k$ da medida base $H$:
$$theta_k \sim H$$
Finalmente, construímos a distribuição $G$ como uma soma ponderada de funções delta de Dirac centradas nos parâmetros $\theta_k$:
$$G(\theta) = \sum_{k=1}^{\infty} \pi_k \delta_{\theta_k}(\theta)$$
Essa representação explicita a natureza discreta da distribuição $G$ e permite a construção de modelos de mistura com um número infinito de componentes [^884].

**Chinese Restaurant Process (CRP)**
Outra representação útil do DP é o **Chinese Restaurant Process (CRP)** [^884]. Imagine um restaurante chinês com um número infinito de mesas. Cada cliente (dado) que entra no restaurante escolhe uma mesa da seguinte forma:
- O primeiro cliente senta-se na primeira mesa.
- O cliente $N+1$ senta-se em uma mesa já ocupada com probabilidade proporcional ao número de clientes já sentados nessa mesa ($N_k$).
- O cliente $N+1$ senta-se em uma nova mesa com probabilidade proporcional ao parâmetro de concentração $\alpha$.

Formalmente, a probabilidade de o cliente $N+1$ sentar-se na mesa $k$ é dada por [^884]:
$$p(z_{N+1} = k | z_{1:N}, \alpha) = \begin{cases} \frac{N_k}{\alpha + N} & \text{se a mesa } k \text{ já está ocupada} \\ \frac{\alpha}{\alpha + N} & \text{se a mesa } k \text{ é nova} \end{cases}$$
onde $z_i$ representa a mesa em que o cliente $i$ se senta. Essa representação é equivalente ao DP e fornece uma forma intuitiva de entender como os dados são agrupados em clusters [^884].

### Conclusão
O Processo de Dirichlet (DP) é uma ferramenta poderosa para modelagem não paramétrica, especialmente em modelos de mistura [^879]. Sua capacidade de inferir automaticamente o número de componentes em um modelo de mistura, juntamente com suas representações construtivas (stick-breaking e CRP), o torna uma escolha atraente para problemas de *clustering* [^884]. Nos próximos capítulos, exploraremos como o DP é utilizado na construção de Dirichlet Process Mixture Models (DPMMs) e como esses modelos podem ser aplicados a uma variedade de problemas de análise de dados.

### Referências
[^877]: 25.1 Introduction
[^879]: 25.2 Dirichlet process mixture models
[^882]: 25.2.2 The Dirichlet process
[^883]: 25.2.2.1 Stick breaking construction of the DP
[^884]: 25.2.2.2 The Chinese restaurant process (CRP)

<!-- END -->