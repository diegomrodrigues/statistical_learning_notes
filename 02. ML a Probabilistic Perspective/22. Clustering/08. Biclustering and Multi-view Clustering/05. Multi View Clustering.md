## Multi-View Clustering: Modeling Multiple Roles

### Introdução
O objetivo do *clustering* é agrupar objetos semelhantes [^1]. Em contraste com as abordagens tradicionais de *clustering*, o *multi-view clustering* reconhece que os objetos podem pertencer a diferentes grupos, dependendo do subconjunto de *features* utilizado [^903]. Este capítulo explora o conceito de *multi-view clustering*, aprofundando-se nas suas motivações e nas abordagens para modelar a atribuição de objetos a diferentes *clusters* com base em diferentes conjuntos de *features*.

### Conceitos Fundamentais

O *biclustering* ou *coclustering* [^903] é uma técnica relacionada que agrupa simultaneamente as linhas e colunas de uma matriz de dados. No entanto, o *biclustering* restringe cada objeto (linha) a pertencer a apenas um *cluster*. O *multi-view clustering* relaxa essa restrição, permitindo que um objeto tenha múltiplos papéis e, portanto, pertença a diferentes *clusters*, dependendo do subconjunto de *features* considerado [^903].

**Motivação para Multi-View Clustering:**
A motivação para o *multi-view clustering* surge da observação de que os objetos no mundo real frequentemente exibem características multifacetadas. Por exemplo, no *dataset* de animais mencionado [^903], um animal pode ser agrupado com base em características anatômicas (por exemplo, mamíferos, répteis) ou com base em características comportamentais (por exemplo, predadores, presas). O *multi-view clustering* permite capturar essas diferentes perspectivas, atribuindo um objeto a diferentes *clusters* com base nos subconjuntos de *features* relevantes.

**Modelagem de Multi-View Clustering:**
Uma abordagem para modelar o *multi-view clustering* envolve particionar as colunas (features) em V grupos ou *views*, denotados por $c_j \in \{1, ..., V\}$, onde $j \in \{1, ..., D\}$ indexa as *features* [^903]. Em seguida, para cada partição das colunas (ou seja, cada *view*), particionamos as linhas usando um Processo de Dirichlet (DP), ilustrado na Figura 25.19(a) [^903]. Seja $r_{iv} \in \{1, ..., K^{(v)}\}$ o *cluster* ao qual a *i*-ésima linha pertence na *v*-ésima *view*. Finalmente, tendo particionado as linhas e colunas, geramos os dados assumindo que todas as linhas e colunas dentro de um bloco são i.i.d. O modelo pode ser definido mais precisamente da seguinte forma [^903]:
$$
p(c, r, D) = p(c)p(r|c)p(D|r, c) \quad [25.63]
$$
onde
$$
p(c) = DP(\alpha) \quad [25.64]
$$
$$
p(r|c) = \prod_{v=1}^{V(c)} DP(r_v|\beta) \quad [25.65]
$$
$$
p(D|r, c, \theta) = \prod_{v=1}^{V(c)} \prod_{j:c_j=v} \prod_{k=1}^{K(r_v)} \prod_{i:r_{iv}=k} \int \left(\prod p(x_{ij}|\theta_{jk})\right)p(\theta_{jk}) d\theta_{jk} \quad [25.66]
$$
onde $DP(\alpha)$ representa um Processo de Dirichlet com parâmetro $\alpha$ [^879], $V(c)$ representa o número de *views*, e $K(r_v)$ representa o número de *clusters* na *v*-ésima *view*.

**Inferência e Aprendizado:**
A estimativa de MAP aproximada pode ser feita usando busca estocástica [^905], e a inferência aproximada pode ser feita usando *Variational Bayes* ou amostragem de Gibbs [^905]. Os hiperparâmetros $\alpha$ e $\beta$, que controlam o número de partições de colunas e linhas, respectivamente, podem ser inferidos usando *Metropolis-Hastings* (MH) [^905].

### Conclusão

O *multi-view clustering* oferece uma abordagem flexível e poderosa para agrupar objetos que exibem características multifacetadas. Ao permitir que os objetos pertençam a diferentes *clusters*, dependendo do subconjunto de *features* considerado, o *multi-view clustering* pode revelar padrões e relações mais sutis nos dados do que as abordagens tradicionais de *clustering*.

### Referências
[^1]: Clustering is the process of grouping similar objects together.
[^879]: In this section, we discuss infinite mixture models, in which we do not impose any a priori bound on K. To do this, we will use a non-parametric prior based on the Dirichlet process (DP).
[^903]: Multi-view clustering assigns objects to different clusters depending on the subset of features used, modeling the phenomenon where objects can have multiple roles.
[^905]: Approximate MAP estimation can be done using stochastic search (Shafto et al. 2006), and approximate inference can be done using variational Bayes (Guan et al. 2010) or Gibbs sampling (Mansinghka et al. 2011).
<!-- END -->