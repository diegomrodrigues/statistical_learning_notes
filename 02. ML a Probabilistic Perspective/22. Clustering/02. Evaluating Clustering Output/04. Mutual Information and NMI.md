## Mutual Information for Evaluating Clustering Output

### Introdução
A avaliação da qualidade dos resultados de um algoritmo de *clustering* é uma tarefa complexa, especialmente em cenários de aprendizado não supervisionado [^877]. Uma abordagem comum é utilizar métricas externas, que comparam o *clustering* obtido com uma referência pré-existente, como rótulos de classe conhecidos [^877]. Este capítulo explora o uso da **informação mútua (MI)** e da **informação mútua normalizada (NMI)** como medidas para quantificar a similaridade entre diferentes *clusterings* [^878].

### Conceitos Fundamentais
#### Informação Mútua (MI)
A informação mútua (MI) quantifica a quantidade de informação compartilhada entre duas estruturas de *clustering*, denotadas como U e V [^878]. Em outras palavras, ela mede a dependência entre as atribuições de *cluster* nos dois *clusterings* [^878]. A MI é calculada utilizando as probabilidades conjuntas $p_{uv}(i, j)$, as probabilidades marginais $p_u(i)$ e $p_v(j)$, onde:

*   $p_{uv}(i, j)$ representa a probabilidade de um objeto pertencer ao *cluster* $i$ em U e ao *cluster* $j$ em V [^878].
*   $p_u(i)$ representa a probabilidade de um objeto pertencer ao *cluster* $i$ em U [^878].
*   $p_v(j)$ representa a probabilidade de um objeto pertencer ao *cluster* $j$ em V [^879].

A fórmula para calcular a informação mútua $I(U, V)$ é dada por [^878]:
$$ I(U, V) = \sum_{i} \sum_{j} p_{uv}(i, j) \log \left[ \frac{p_{uv}(i, j)}{p_u(i)p_v(j)} \right] $$
A MI assume valores maiores quando há uma forte dependência entre os dois *clusterings*, indicando que eles compartilham uma quantidade significativa de informação [^878]. No entanto, a MI bruta pode ser influenciada pelo número de *clusters* em cada *clustering* e pela entropia dos *clusterings* [^879].

#### Informação Mútua Normalizada (NMI)
Para mitigar as limitações da MI bruta, a informação mútua normalizada (NMI) ajusta a MI para levar em conta a entropia dos *clusterings* [^878]. A NMI fornece uma medida padronizada de informação compartilhada, tornando-a adequada para comparar *clusterings* com diferentes números de *clusters* [^878].

A NMI é calculada como [^878]:
$$ NMI(U, V) = \frac{I(U, V)}{\sqrt{\frac{(H(U) + H(V))}{2}}} $$
onde $H(U)$ e $H(V)$ são as entropias dos *clusterings* U e V, respectivamente [^878]. A entropia de um *clustering* mede a incerteza ou aleatoriedade na atribuição de *clusters* [^879]. A fórmula para a entropia de um *clustering* U é dada por:
$$ H(U) = - \sum_{i} p_u(i) \log(p_u(i)) $$
A NMI varia entre 0 e 1, onde 0 indica que os *clusterings* são independentes e 1 indica que os *clusterings* são idênticos [^879]. A NMI é uma métrica útil para comparar *clusterings* obtidos por diferentes algoritmos ou com diferentes parâmetros [^878].

### Conclusão
A informação mútua (MI) e a informação mútua normalizada (NMI) são ferramentas valiosas para avaliar e comparar resultados de algoritmos de *clustering* [^878]. A NMI, em particular, oferece uma medida padronizada que leva em consideração a entropia dos *clusterings*, permitindo comparações mais justas entre diferentes estruturas de *clusters* [^878]. Ao utilizar MI e NMI, é possível quantificar a similaridade entre um *clustering* obtido e uma referência externa, ou entre diferentes *clusterings* gerados por diferentes abordagens [^878].

[^877]: 25.1 Introduction
[^878]: 25.1.2.3 Mutual information
[^879]: 25.2. Dirichlet process mixture models
<!-- END -->