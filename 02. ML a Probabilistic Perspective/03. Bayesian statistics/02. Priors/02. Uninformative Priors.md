## Priors Não Informativos

### Introdução
No contexto da estatística Bayesiana, a escolha do *prior* é fundamental, influenciando a inferência sobre parâmetros desconhecidos [^1]. Enquanto *priors* informativos incorporam conhecimento prévio específico, *priors* não informativos visam minimizar o impacto de suposições *a priori*, permitindo que os dados "falem por si" [^1, 5.4.1]. Este capítulo explora a construção e as propriedades de *priors* não informativos, abordando as sutilezas envolvidas em sua definição e as implicações para a inferência Bayesiana.

### Conceitos Fundamentais

**Definição e Objetivo**

Um *prior* não informativo, também conhecido como *prior* não informativo ou *prior* objetivo, busca representar a ausência de informação prévia sobre um parâmetro [^5.4.1]. O objetivo é que a distribuição *posterior* seja predominantemente influenciada pelos dados observados, e não por crenças *a priori* [^1, 5.4.1].

**Tipos de Priors Não Informativos**

1.  **Distribuição Uniforme:** A abordagem mais intuitiva é usar uma distribuição uniforme sobre o espaço de parâmetros [^1, 5.4.1]. Por exemplo, para um parâmetro $\theta \in [0,1]$, um *prior* uniforme seria $p(\theta) = 1$, representando igual probabilidade para todos os valores possíveis [^1].
2.  **Prior de Beta(1,1):** De acordo com o contexto, Beta(1,1) também se comporta como uma distribuição uniforme [^1, 5.4.1].
3.  **Prior de Haldane:** O *prior* de Haldane é um *prior* impróprio, significando que a sua integral não converge para 1 [^1]. O *prior* de Haldane é definido como $Beta(0,0)$ [^1, 5.4.2.1]. Embora impróprio, ele pode levar a *posteriores* próprios, desde que os dados forneçam informações suficientes [^1]. Especificamente, no contexto de um modelo de Bernoulli, o *posterior* será próprio desde que observemos pelo menos uma "cara" e pelo menos uma "coroa" [^1].

**Desafios e Sutilezas**

A construção de *priors* não informativos não é isenta de desafios:

1.  **Invariância à Reparametrização:** Um *prior* que é uniforme em uma parametrização pode não ser uniforme em outra [^3, 5.2.1.4]. Por exemplo, um *prior* uniforme para a média $\mu$ de uma distribuição normal não implica um *prior* uniforme para $\mu^2$ [^3].
2.  **Impropriedade:** Alguns *priors* não informativos são *impróprios*, o que significa que sua integral sobre o espaço de parâmetros é infinita [^1, 5.4.2]. Embora *priors* impróprios possam levar a *posteriores* próprios, eles exigem cuidado, pois nem sempre garantem resultados válidos [^1].
3.  **Subjetividade Residual:** Mesmo *priors* que se pretendem não informativos podem introduzir alguma forma de subjetividade [^5.4.1]. A escolha da distribuição uniforme, por exemplo, reflete uma crença de que todos os valores no intervalo são igualmente plausíveis *a priori*, o que pode não ser apropriado em todos os contextos [^5.4.1].

**Jeffreys Priors**
Uma abordagem para construir *priors* não informativos que sejam invariantes à reparametrização é usar os *priors* de Jeffreys [^18, 5.4.2]. O *prior* de Jeffreys é proporcional à raiz quadrada da informação de Fisher, $p(\theta) \propto \sqrt{I(\theta)}$ [^18, 5.4.2]. A informação de Fisher mede a curvatura esperada da função de log-verossimilhança e, portanto, reflete a quantidade de informação que os dados fornecem sobre o parâmetro [^18, 5.4.2].

**Sensibilidade e Análise de Robustez**

Dada a potencial influência dos *priors* nos resultados Bayesianos, é crucial realizar análises de sensibilidade [^1, 5.4.1]. Isso envolve avaliar como as inferências mudam sob diferentes escolhas de *priors*, incluindo *priors* informativos e não informativos [^1, 5.4.1]. Se as conclusões forem robustas em relação a uma ampla gama de *priors*, aumenta a confiança nos resultados [^1, 5.4.1].

### Conclusão

*Priors* não informativos representam uma ferramenta valiosa na análise Bayesiana, permitindo que os dados guiem a inferência com o mínimo de influência *a priori* [^1, 5.4.1]. No entanto, sua construção exige cuidado e consideração das sutilezas envolvidas [^5.4.1]. A escolha do *prior* não informativo apropriado depende do contexto específico e das propriedades desejadas, como invariância à reparametrização [^3, 5.2.1.4] e a garantia de um *posterior* próprio [^1, 5.4.2]. A análise de sensibilidade é essencial para avaliar a robustez das conclusões e garantir uma interpretação confiável dos resultados Bayesianos [^1, 5.4.1].

### Referências
[^1]: Bayesian statistics.
[^3]: 5.2.1.4 MAP estimation is not invariant to reparameterization *\
[^18]: 5.4.2 Jeffreys priors *\
[^5.4.1]: 5.4.1 Uninformative priors
[^5.4.2]: 5.4.2 Jeffreys priors *\
[^5.4.2.1]: 5.4.2.1 Example: Jeffreys prior for the Bernoulli and multinoulli

<!-- END -->