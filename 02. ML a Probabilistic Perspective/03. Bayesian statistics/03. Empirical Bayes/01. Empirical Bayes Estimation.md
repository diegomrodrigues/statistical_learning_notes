## Empirical Bayes: Estimativa de Hiperparâmetros em Modelos Hierárquicos Bayesianos

### Introdução
Este capítulo explora o método de **Empirical Bayes (EB)**, também conhecido como *maximum likelihood tipo II*, uma técnica para estimar **hiperparâmetros** em modelos Bayesianos hierárquicos. A abordagem EB maximiza a *marginal likelihood* em relação aos hiperparâmetros, oferecendo uma aproximação computacionalmente mais eficiente para a inferência Bayesiana completa [^5]. Este capítulo se baseia nos conceitos de estatística Bayesiana introduzidos anteriormente [^1], incluindo modelos probabilísticos, priors, e a computação de estimativas MAP (Maximum a Posteriori) [^1].

### Conceitos Fundamentais

O Empirical Bayes oferece uma alternativa à especificação completa de priors em modelos hierárquicos [^23]. Em vez de atribuir priors não informativos [^16] ou hierárquicos [^23] aos hiperparâmetros, o EB estima esses parâmetros diretamente dos dados, maximizando a *marginal likelihood* [^8].

A ideia central é que, em um modelo hierárquico, os parâmetros de nível inferior são condicionados aos hiperparâmetros [^23]. A *marginal likelihood* representa a probabilidade dos dados integrados em relação a esses parâmetros [^8, 15]:

$$
p(D|\eta) = \int p(D|\theta)p(\theta|\eta)d\theta
$$

onde:
*   $D$ representa os dados observados.
*   $\theta$ são os parâmetros do modelo.
*   $\eta$ são os hiperparâmetros.

A abordagem EB consiste em encontrar o valor de $\eta$ que maximiza $p(D|\eta)$ [^24, 25]:

$$
\hat{\eta} = \underset{\eta}{\text{argmax}} \ p(D|\eta) = \underset{\eta}{\text{argmax}} \ \int p(D|\theta)p(\theta|\eta)d\theta
$$

Após encontrar $\hat{\eta}$, este valor é usado como uma estimativa pontual dos hiperparâmetros. A distribuição posterior dos parâmetros $\theta$ pode então ser aproximada como [^25]:

$$
p(\theta|D) \approx p(\theta|D, \hat{\eta})
$$

Essa aproximação simplifica a inferência, evitando a necessidade de especificar um prior para $\eta$ [^23] e integrar sobre todos os possíveis valores de $\eta$ [^24].

**Exemplo: Modelo Beta-Binomial**

No contexto do modelo Beta-Binomial, onde $p(\theta|D) = Beta(\theta|a', b')$ [^12], com $a' = a + N_1$ e $b' = b + N_0$, o EB pode ser usado para estimar os hiperparâmetros $a$ e $b$ maximizando a *marginal likelihood* [^12, 25]:

$$
p(D|a, b) = \prod_{i=1}^{N} \frac{B(a + x_i, b + N_i - x_i)}{B(a, b)}
$$

onde $B(\cdot, \cdot)$ é a função Beta [^12].

**Exemplo: Modelo Gaussiano-Gaussiano**

No contexto do modelo Gaussiano-Gaussiano, onde assumimos que os $\theta_j$ vêm de um prior comum, $N(\mu, \tau^2)$ [^26], a *marginal likelihood* é dada por [^26, 27]:

$$
p(D|\mu, \tau^2, \sigma^2) = \prod_{j=1}^{D} N(x_j|\mu, \tau^2 + \sigma^2)
$$

Os hiperparâmetros $\mu$ e $\tau^2$ podem ser estimados usando os MLEs usuais para uma Gaussiana [^28]:

$$
\hat{\mu} = \frac{1}{D}\sum_{j=1}^{D} x_j
$$

$$
\hat{\tau}^2 = \text{max}\{0, s^2 - \sigma^2\}
$$

### Conclusão

O Empirical Bayes oferece uma abordagem prática para a estimação de hiperparâmetros em modelos Bayesianos hierárquicos, equilibrando a flexibilidade da inferência Bayesiana com a eficiência computacional [^5]. Embora viole o princípio de que os priors devem ser escolhidos independentemente dos dados [^25], o EB pode ser visto como uma aproximação computacionalmente barata da inferência Bayesiana completa [^5, 25]. A escolha entre EB e uma abordagem Bayesiana totalmente hierárquica depende do problema específico, dos recursos computacionais disponíveis e das necessidades de modelagem [^5, 23].

### Referências
[^1]: Seção 5.1, Introdução à Estatística Bayesiana.
[^5]: Seção 5.6, Empirical Bayes.
[^8]: Seção 5.3, Bayesian model selection.
[^12]: Seção 5.3.2.1, Beta-binomial model.
[^15]: Seção 5.3.2, Computing the marginal likelihood (evidence).
[^16]: Seção 5.4.1, Uninformative priors.
[^23]: Seção 5.5, Hierarchical Bayes.
[^24]: Seção 5.5.1, Example: modeling related cancer rates.
[^25]: Seção 5.6. Empirical Bayes.
[^26]: Seção 5.6.2, Example: Gaussian-Gaussian model.
[^27]: Seção 5.6.2.1, Example: predicting baseball scores.
[^28]: Seção 5.6.2, Example: Gaussian-Gaussian model.
<!-- END -->