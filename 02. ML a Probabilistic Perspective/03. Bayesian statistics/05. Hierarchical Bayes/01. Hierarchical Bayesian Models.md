## Hierarchical Bayesian Models: Borrowing Statistical Strength

### Introdução
Em estatística Bayesiana, modelos hierárquicos representam uma extensão poderosa das abordagens tradicionais, permitindo a modelagem de dados complexos com múltiplas camadas de incerteza. Uma característica fundamental desses modelos é a capacidade de "emprestar força estatística" entre diferentes grupos ou níveis de dados. Este capítulo explora em profundidade esse conceito, focando especialmente em como cidades com poucos dados podem se beneficiar de informações provenientes de cidades com dados mais ricos [^55].

### Conceitos Fundamentais
**Modelos Bayes Hierárquicos (MBH)** são caracterizados pela presença de múltiplos níveis de quantidades desconhecidas. A estrutura hierárquica é definida por:
1.  Um *modelo de dados*, que descreve a distribuição das observações condicionais aos parâmetros.
2.  Um *modelo de parâmetros*, que especifica uma distribuição *a priori* sobre os parâmetros, condicionada a *hiperparâmetros*.
3.  Um *modelo de hiperparâmetros*, que atribui uma distribuição *a priori* aos hiperparâmetros.

Essa estrutura permite que os parâmetros dos diferentes grupos (e.g., cidades) compartilhem informações através da distribuição *a priori* comum, controlada pelos hiperparâmetros [^55].

#### Empréstimo de Força Estatística
O conceito de **empréstimo de força estatística** é central para a utilidade dos MBH. Ele se manifesta quando a inferência sobre um grupo (e.g., uma cidade com poucos dados) é influenciada pelos dados de outros grupos (e.g., cidades com muitos dados). Esse fenômeno ocorre devido à estrutura hierárquica, onde os hiperparâmetros da distribuição *a priori* comum são estimados usando os dados de todos os grupos. Isso leva a uma *regularização* ou *shrinkage* das estimativas dos parâmetros individuais em direção à média populacional, especialmente para grupos com poucos dados [^55].

#### Formalização Matemática
Considere o exemplo de modelagem de taxas de câncer em várias cidades [^55]. Seja $x_i$ o número de pessoas que morreram de câncer na cidade $i$, e $N_i$ o número total de pessoas na cidade $i$. Assumimos que $x_i \sim Bin(N_i, \theta_i)$, onde $\theta_i$ é a taxa de câncer na cidade $i$.

Em uma abordagem não hierárquica, estimaríamos $\theta_i$ independentemente para cada cidade. No entanto, em um MBH, assumimos que os $\theta_i$ são amostrados de uma distribuição comum, por exemplo, $\theta_i \sim Beta(a, b)$, onde $a$ e $b$ são hiperparâmetros. O modelo completo é então:

$$ \begin{aligned} x_i &\sim Bin(N_i, \theta_i) \\ \theta_i &\sim Beta(a, b) \\ a, b &\sim p(a, b) \end{aligned} $$
onde $p(a, b)$ é uma distribuição *a priori* sobre os hiperparâmetros $a$ e $b$. A inferência sobre $\theta_i$ envolve o cálculo da distribuição *a posteriori* $p(\theta_i | x, N, a, b)$, que é influenciada tanto pelos dados locais ($x_i$ e $N_i$) quanto pela distribuição *a priori* $Beta(a, b)$, que por sua vez é estimada usando os dados de todas as cidades.

#### Inferência e Regularização
A inferência Bayesiana em MBH geralmente envolve métodos computacionais como *Markov Chain Monte Carlo (MCMC)* para amostrar da distribuição *a posteriori*. As estimativas *a posteriori* das taxas de câncer $\theta_i$ são *regularizadas* em direção à média populacional, $\frac{a}{a+b}$. A quantidade de *shrinkage* é inversamente proporcional ao tamanho da amostra $N_i$: cidades com amostras menores experimentam maior *shrinkage* [^55].

#### Empirical Bayes
Uma abordagem computacionalmente mais eficiente para estimar os hiperparâmetros é a *Empirical Bayes (EB)*, também conhecida como *type-II maximum likelihood* [^55]. Em EB, os hiperparâmetros são estimados maximizando a *marginal likelihood*:

$$ \hat{\eta} = \underset{\eta}{\operatorname{argmax}} \int p(D|\theta)p(\theta|\eta)d\theta $$
onde $\eta$ representa os hiperparâmetros, $D$ os dados, e $\theta$ os parâmetros. Uma vez que os hiperparâmetros são estimados, eles são tratados como fixos, e a inferência sobre os parâmetros é realizada condicionalmente a esses valores. Embora EB seja computacionalmente mais simples do que a inferência Bayesiana completa, ela não leva em conta a incerteza sobre os hiperparâmetros.

### Conclusão
Os modelos Bayes Hierárquicos oferecem uma abordagem flexível e poderosa para modelar dados complexos com múltiplos níveis de variação. A capacidade de emprestar força estatística entre diferentes grupos ou níveis de dados é particularmente útil em situações onde alguns grupos têm poucos dados. Esse empréstimo de força estatística é alcançado através da estrutura hierárquica do modelo, onde os hiperparâmetros da distribuição *a priori* comum são estimados usando os dados de todos os grupos. Isso leva a uma regularização das estimativas dos parâmetros individuais em direção à média populacional, especialmente para grupos com poucos dados. As abordagens de inferência incluem métodos computacionais como MCMC e EB, cada um com suas próprias vantagens e desvantagens.

### Referências
[^55]: Página 171 do texto original.
<!-- END -->