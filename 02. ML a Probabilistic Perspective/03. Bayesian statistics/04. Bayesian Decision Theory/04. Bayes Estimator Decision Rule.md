## Bayes Estimator e Regra de Decisão Bayesiana

### Introdução
Este capítulo explora em profundidade o conceito de **Bayes estimator**, também conhecido como **regra de decisão Bayesiana**, um elemento central na teoria da decisão Bayesiana. A teoria da decisão Bayesiana, como vimos na introdução do capítulo 5 [^1], é um pilar fundamental da estatística Bayesiana, que se concentra em utilizar a distribuição *a posteriori* para sumarizar o conhecimento sobre variáveis desconhecidas. Em continuidade com a discussão sobre como resumir distribuições *a posteriori* [^2], este capítulo detalha como a teoria da decisão nos permite escolher entre diferentes métodos de sumarização [^2], especificando uma função de perda que quantifica as consequências de diferentes decisões. A seção 5.7 do texto aborda a teoria da decisão, que fornece a base para a definição e aplicação do estimador de Bayes.

### Conceitos Fundamentais
O **Bayes estimator** ou **regra de decisão Bayesiana** é formalmente definido como [^29]:
$$delta(x) = \underset{a \in A}{\text{arg min }} \rho(a|x)$$
onde:
- $\delta(x)$ representa a ação ótima a ser tomada dado a observação $x$.
- $A$ é o espaço de ações possíveis.
- $\rho(a|x)$ é a perda esperada *a posteriori* associada à ação $a$ dado $x$.

Em outras palavras, o estimador de Bayes seleciona a ação $a$ que minimiza a perda esperada *a posteriori*. A perda esperada *a posteriori* é dada por [^29]:
$$rho(a|x) = \mathbb{E}_{p(y|x)}[L(y, a)] = \sum_y L(y, a)p(y|x)$$
onde $L(y, a)$ é a função de perda que quantifica a incompatibilidade entre a ação $a$ e o verdadeiro estado da natureza $y$, e $p(y|x)$ é a distribuição *a posteriori* de $y$ dado $x$.

**Entendendo a Função de Perda**
A função de perda $L(y, a)$ desempenha um papel crucial na determinação do estimador de Bayes. Ela reflete as preferências do tomador de decisão e quantifica as consequências de tomar diferentes ações em diferentes estados da natureza. A escolha da função de perda é, portanto, um passo fundamental na aplicação da teoria da decisão Bayesiana.

**Exemplos de Funções de Perda Comuns**
O texto cita exemplos de funções de perda comumente usadas em aprendizado de máquina [^29]:
1. **Perda 0-1 (Zero-Um)**: Esta função de perda é definida como:
   $$L(y, a) = I(y \ne a) = \begin{cases} 0, & \text{se } a = y \\\\ 1, & \text{se } a \ne y \end{cases}$$
   onde $I(\cdot)$ é a função indicadora. Esta função de perda é frequentemente usada em problemas de classificação, onde o objetivo é minimizar o número de erros de classificação.

2. **Perda Quadrática (L2)**: Esta função de perda é definida como:
   $$L(y, a) = (y - a)^2$$
   Esta função de perda é comumente usada em problemas de regressão, onde o objetivo é minimizar o erro quadrático médio.

3. **Perda Absoluta (L1)**: Esta função de perda é definida como:
   $$L(y, a) = |y - a|$$
   Esta função de perda é mais robusta a *outliers* do que a perda quadrática e é frequentemente usada quando se deseja minimizar o erro absoluto médio.

**Estimadores de Bayes para Diferentes Funções de Perda**
O texto continua a explorar como diferentes funções de perda levam a diferentes estimadores de Bayes [^29]:

*   **Perda 0-1:** O estimador de Bayes que minimiza a perda 0-1 é o **MAP (Maximum A Posteriori) estimator**, que seleciona a ação com a maior probabilidade *a posteriori*:
    $$y^*(x) = \underset{y \in Y}{\text{arg max }} p(y|x)$$
*   **Perda Quadrática:** O estimador de Bayes que minimiza a perda quadrática é a **média *a posteriori***:
    $$hat{y} = \mathbb{E}[y|x] = \int yp(y|x) dy$$
*   **Perda Absoluta:** O estimador de Bayes que minimiza a perda absoluta é a **mediana *a posteriori***, um valor $a$ tal que $P(y < a|x) = P(y \ge a|x) = 0.5$.

**Exemplo Ilustrativo**
Considere um problema de classificação binária, onde $y \in \{0, 1\}$ e desejamos classificar uma observação $x$. Suponha que a distribuição *a posteriori* seja $p(y=1|x) = 0.7$ e $p(y=0|x) = 0.3$.

*   **Usando a perda 0-1**, o estimador de Bayes seria $\delta(x) = 1$, pois $p(y=1|x) > p(y=0|x)$.
*   **Se estivéssemos usando a perda quadrática** e estimando uma probabilidade, o estimador de Bayes seria $\delta(x) = \mathbb{E}[y|x] = 1 \cdot 0.7 + 0 \cdot 0.3 = 0.7$.

### Conclusão
O estimador de Bayes é uma ferramenta poderosa na teoria da decisão Bayesiana, fornecendo uma maneira sistemática de selecionar ações ótimas com base em crenças *a posteriori* e funções de perda. A escolha da função de perda é crucial, pois ela reflete as preferências do tomador de decisão e influencia diretamente o estimador de Bayes resultante. Como vimos, diferentes funções de perda levam a diferentes estimadores, como o estimador MAP, a média *a posteriori* e a mediana *a posteriori*, cada um adequado para diferentes tipos de problemas e preferências.

Ao longo deste capítulo, foram apresentados conceitos que se baseiam nos fundamentos da estatística Bayesiana e da teoria da probabilidade, demonstrando a importância de uma base sólida nessas áreas para a compreensão e aplicação da teoria da decisão Bayesiana.
### Referências
[^1]: Página 1, "Bayesian statistics"
[^2]: Página 1, "Summarizing posterior distributions"
[^29]: Página 177, "Bayes estimators for common loss functions"
<!-- END -->