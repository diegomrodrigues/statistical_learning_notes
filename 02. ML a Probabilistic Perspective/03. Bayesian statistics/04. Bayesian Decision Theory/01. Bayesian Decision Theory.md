## Bayesian Decision Theory: Converting Beliefs into Actions

### Introdução
Este capítulo explora a **Bayesian Decision Theory (BDT)**, um framework fundamental para transformar crenças probabilísticas em ações otimizadas. A BDT formaliza problemas de decisão como *jogos contra a natureza*, onde o objetivo é escolher a ação que minimiza a perda esperada, levando em conta a incerteza inerente ao estado do mundo [^28]. A BDT será discutida no contexto de estatística Bayesiana, onde a inferência é baseada na distribuição *a posteriori* [^1].

### Conceitos Fundamentais
A Bayesian Decision Theory fornece um framework para converter crenças em ações, formalizando problemas de decisão como jogos contra a natureza [^28]. Isso envolve escolher uma ação $a$ de um espaço de ações $A$ para minimizar a perda esperada *a posteriori*, que é calculada com base em uma função de perda $L(y, a)$ e a distribuição *a posteriori* $p(y|x)$ [^28]. Formaliza qualquer problema de decisão estatística dado como um jogo contra a natureza [^28].

A **função de perda** $L(y, a)$ quantifica a penalidade associada a tomar a ação $a$ quando o verdadeiro estado da natureza é $y$ [^28]. Diferentes funções de perda levam a diferentes decisões ótimas. Por exemplo, a *perda 0-1* ($L(y, a) = I(y \neq a)$) penaliza igualmente todos os erros, enquanto a *perda quadrática* ($L(y, a) = (y - a)^2$) penaliza erros maiores de forma mais severa [^28].

A **distribuição *a posteriori*** $p(y|x)$ representa nossa crença sobre o estado da natureza $y$ dado os dados observados $x$ [^28]. Ela é obtida combinando a distribuição *a priori* $p(y)$ com a função de verossimilhança $p(x|y)$ usando o teorema de Bayes [^1].

O objetivo da BDT é encontrar a **ação ótima** $a^*$ que minimiza a *perda esperada a posteriori* [^28]:
$$a^* = \underset{a \in A}{\text{argmin }} \mathbb{E}_{p(y|x)}[L(y, a)] = \underset{a \in A}{\text{argmin }} \sum_{y} L(y, a)p(y|x)$$
Se $y$ é contínuo, a soma é substituída por uma integral [^28].

Diferentes funções de perda levam a diferentes **estimadores de Bayes** [^28]:
*   A perda 0-1 é minimizada pelo **estimador MAP (Maximum A Posteriori)**, que escolhe o valor de $y$ com a maior probabilidade *a posteriori* [^29]:
    $$a^* = \underset{y \in Y}{\text{argmax }} p(y|x)$$
*   A perda quadrática é minimizada pela **média *a posteriori*** [^31]:
    $$a^* = \mathbb{E}[y|x] = \int yp(y|x)dy$$
*   A perda absoluta ($L(y,a) = |y - a|$) é minimizada pela **mediana *a posteriori*** [^31].

A BDT também pode ser estendida para lidar com **opções de rejeição**, onde o classificador pode optar por não classificar um exemplo se estiver muito incerto [^30]. Isso é útil em aplicações sensíveis ao risco, como medicina e finanças, onde é melhor admitir a incerteza do que cometer um erro [^30].

Em problemas de classificação binária, a BDT leva ao conceito de **ROC curves (Receiver Operating Characteristic)** e **precision-recall curves**, que são ferramentas para avaliar o desempenho de classificadores em diferentes tradeoffs entre falsos positivos e falsos negativos [^32, 34].

### Conclusão
A Bayesian Decision Theory oferece um framework rigoroso e flexível para tomar decisões sob incerteza. Ao formalizar problemas de decisão como jogos contra a natureza e ao usar a distribuição *a posteriori* para quantificar a incerteza, a BDT permite que tomemos decisões ótimas que minimizam a perda esperada. Os conceitos apresentados neste capítulo são essenciais para entender como converter crenças probabilísticas em ações eficazes em uma ampla gama de aplicações.

### Referências
[^1]: 5 Bayesian statistics.
[^28]: 5.7 Bayesian decision theory.
[^29]: 5.7.1 Bayes estimators for common loss functions.
[^30]: 5.7.1.2 Reject option
[^31]: 5.7.1.3 Posterior mean minimizes l2 (quadratic) loss
[^32]: 5.7.2.1 ROC curves and all that
[^34]: 5.7.2.2 Precision recall curves
<!-- END -->