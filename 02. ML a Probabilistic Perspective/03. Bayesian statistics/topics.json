{
  "topics": [
    {
      "topic": "Bayesian Statistics",
      "sub_topics": [
        "Bayesian statistics uses the posterior distribution, denoted as p(\u03b8|D), to summarize knowledge about unknown variables (\u03b8) given observed data (D), providing a comprehensive framework for statistical inference that contrasts with frequentist approaches. This approach incorporates prior beliefs and updates them with observed data, offering an alternative to classical statistics. The posterior distribution concisely summarizes what is known about unknown quantities, offering a more intuitive and visualizable representation compared to the full joint distribution. This distribution is central to Bayesian inference, allowing for the quantification of uncertainty and the incorporation of prior knowledge.",
        "MAP (Maximum a Posteriori) estimation computes a point estimate of an unknown quantity by identifying the posterior mode, which reduces to an optimization problem often solvable by efficient algorithms. It maximizes the posterior probability argmax p(\u03b8|D) given observed data D and prior beliefs and can be interpreted as a regularizer in non-Bayesian contexts. However, MAP estimation lacks a measure of uncertainty, which can lead to overconfident predictions and difficulties in risk-averse situations. It also depends on how the probability distribution is parameterized, meaning that changing from one representation to an equivalent one can alter the result. This lack of invariance to reparameterization is undesirable because the units of measurement should not affect the outcome. The mode can be an atypical point, especially in skewed distributions.",
        "Credible intervals provide a measure of confidence in a scalar quantity by defining a range that contains a specified percentage of the posterior probability mass, offering a Bayesian alternative to frequentist confidence intervals. A 100(1 \\u2212 \\u03b1)% credible interval represents a contiguous region that contains 1 \\u2212 \\u03b1 of the posterior probability mass. Central intervals, where (1 \\u2212 \\u03b1)/2 mass is in each tail, are commonly used. Highest Posterior Density (HPD) regions offer an alternative to central intervals by defining a region containing the most probable points that constitute 100(1 \\u2212 \\u03b1)% of the probability mass. HPD regions address the limitation of central intervals, which may include points with lower probability density than points outside the interval. In 1D, the HPD region is sometimes called a highest density interval or HDI.",
        "Bayesian model selection addresses the challenge of choosing the best model from a set of models with varying complexity. One approach is to use cross-validation to estimate the generalization error of each candidate model. A more efficient approach is to compute the posterior over models, p(m|D), using the marginal likelihood, also known as the integrated likelihood or evidence for model m. Bayesian Occam's razor favors simpler models that adequately explain the data by integrating out parameters rather than maximizing them. This principle protects against overfitting, as complex models that can predict many things must spread their probability mass thinly, resulting in lower probability for any given dataset compared to simpler models. The Bayesian Information Criterion (BIC) approximates the log marginal likelihood, penalizing model complexity and preventing overfitting. It has the form of a penalized log likelihood, where the penalty term depends on the model's complexity.",
        "Uninformative priors aim to minimize the impact of prior assumptions, letting the data speak for itself, but designing such priors can be tricky and may still influence the posterior distribution. Jeffreys priors are a general technique for creating non-informative priors based on the Fisher information, providing a measure of the curvature of the expected negative log likelihood. They are proportional to the square root of the Fisher information. Scale invariant priors, such as p(s) \\u221d 1/s for a scale parameter, ensure that the probability mass assigned to an interval remains the same under scaling, maintaining consistent inferences under unit changes. Robust priors with heavy tails avoid forcing parameter estimates too close to the prior mean, providing a more reliable inference in the presence of outliers or uncertainty. Mixtures of conjugate priors offer a compromise between computational convenience and flexibility, allowing approximation of any kind of prior and simplifying computation while encoding prior knowledge.",
        "Hierarchical Bayesian models use hyper-parameters and priors on priors to represent multiple levels of unknown quantities, allowing data-poor cities to 'borrow statistical strength' from data-rich ones. Empirical Bayes approximates the posterior on hyper-parameters with a point estimate, providing a computationally cheap approximation to inference in hierarchical Bayesian models but violating the principle that the prior should be chosen independently of the data.",
        "Bayesian decision theory uses probability theory to convert beliefs into actions, formalizing statistical decision problems as a game against nature with a loss function that measures the compatibility of actions and hidden states. A decision procedure or policy, \\u03b4: X \\u2192 A, specifies the optimal action for each possible input by minimizing the expected loss, where the loss function measures the incompatibility between the action and the true state. The maximum expected utility principle guides rational behavior by maximizing the expected utility (negative loss) and minimizing the posterior expected loss. Bayes estimators for common loss functions, such as MAP estimate minimizing 0-1 loss and posterior mean minimizing l2 (quadratic) loss, provide optimal actions based on specific loss criteria. The false positive vs false negative tradeoff in binary decision problems is addressed by considering the costs of each type of error and using ROC curves to study the tradeoff without choosing a specific threshold. ROC curves plot the true positive rate (TPR) vs the false positive rate (FPR) as the threshold varies, summarizing the quality of a classification system. Precision recall curves are used when trying to detect a rare event, plotting precision vs recall as the threshold varies, measuring the fraction of detections that are actually positive and the fraction of positives that are actually detected. False discovery rates are used when discovering a rare phenomenon using high throughput measurement, controlling the posterior expected false discovery rate using the direct posterior probability approach. Sequential decision theory deals with multi-stage or sequential decision problems, where one decision depends on the previous ones, and is related to reinforcement learning. Reject option is an action in classification problems where we refuse to classify the example as any of the specified classes; it is used when p(y|x) is very uncertain, and is useful in risk-averse domains."
      ]
    },
    {
      "topic": "Priors",
      "sub_topics": [
        "Priors are a controversial but unavoidable aspect of Bayesian statistics, representing prior beliefs about parameters and influencing posterior inference. Prior distributions embody assumptions about the parameters before observing the data. While these assumptions are subjective, they provide a structured way to incorporate existing knowledge or beliefs into the analysis.",
        "Uninformative priors aim to minimize the impact of prior assumptions, letting the data speak for itself, but designing such priors can be tricky. They can be uniform distribution, Beta(1,1). The Haldane prior is an improper prior, meaning it does not integrate to 1. However, as long as we see at least one head and at least one tail, the posterior will be proper.",
        "Jeffreys priors provide a general-purpose technique for creating non-informative priors, based on the Fisher information and invariant to re-parameterization.",
        "Scale invariant priors, such as p(s) \\u221d 1/s for a scale parameter, ensure that the probability mass assigned to an interval remains the same under scaling, maintaining consistent inferences under unit changes.",
        "Robust priors, such as Cauchy priors, have heavy tails to avoid undue influence on the result, preventing the model from being overly influenced by the prior mean. These priors typically have heavy tails, which avoids forcing the posterior too close to the prior mean. Examples include the Cauchy prior, which is less sensitive to outliers than Gaussian priors.",
        "Mixtures of conjugate priors combine the benefits of computational convenience and flexibility, allowing approximation of any prior and simplifying posterior computations. They are also conjugate. Conjugate priors simplify computation, while mixtures can approximate a wide range of prior beliefs. This approach offers a good compromise between computational efficiency and the ability to encode prior knowledge.",
        "Hierarchical Bayes involves placing a prior on the hyper-parameters of the prior, enabling data-driven learning of prior parameters and borrowing statistical strength across related parameters."
      ]
    },
    {
      "topic": "Empirical Bayes",
      "sub_topics": [
        "Empirical Bayes (EB), also known as type-II maximum likelihood, is an approach to estimating hyper-parameters in hierarchical Bayesian models. This involves maximizing the marginal likelihood with respect to the hyper-parameters, providing a computationally cheaper approximation to full Bayesian inference.",
        "In EB, the prior is chosen by maximizing the marginal likelihood, which violates the principle that the prior should be independent of the data. EB can be viewed as a computationally efficient approximation to inference in hierarchical Bayesian models, where the hyper-parameters are estimated from the data.",
        "A beta-binomial model is used as an example to illustrate EB, where the hyper-parameters of the beta prior are estimated by maximizing the marginal likelihood. This results in a posterior mean that is a weighted average of the local MLE and the prior mean, with the weights determined by the estimated hyper-parameters.",
        "A Gaussian-Gaussian model is another example used to illustrate EB, where the hyper-parameters of the Gaussian prior are estimated by maximizing the marginal likelihood. This results in a posterior mean that is a shrunken estimate, with the degree of shrinkage determined by the estimated hyper-parameters.",
        "Variance stabilizing transformations are applied to better match the Gaussian assumption. Applying a variance stabilizing transform to x; to better match the Gaussian assumption"
      ]
    },
    {
      "topic": "Bayesian Decision Theory",
      "sub_topics": [
        "Bayesian decision theory provides a framework for converting beliefs into actions by formalizing decision problems as games against nature. This involves choosing an action a from an action space A to minimize the posterior expected loss, which is calculated based on a loss function L(y, a) and the posterior distribution p(y|x). It formalizes any given statistical decision problem as a game against nature.",
        "The decision procedure or policy, \\u03b4 : X \\u2192 A, specifies the optimal action for each possible input. By optimal, we mean the action that minimizes the expected loss.",
        "The maximum expected utility principle is the essence of what we mean by rational behavior. It is the action a that minimizes the posterior expected loss.",
        "The Bayes estimator, also called the Bayes decision rule, is given by \\u03b4(x) = arg min p(a|x) where a \\u2208 A. That is, the action a that minimizes the posterior expected loss.",
        "Common loss functions in Bayesian decision theory include 0-1 loss, which is minimized by the MAP estimate, and squared error (l2) loss, which is minimized by the posterior mean. The choice of loss function depends on the specific problem and the desired properties of the estimator.",
        "In binary decision problems, there is a tradeoff between false positives and false negatives. The optimal decision rule depends on the costs associated with each type of error, as reflected in the loss matrix. ROC curves and precision-recall curves provide tools for analyzing this tradeoff and selecting an appropriate threshold.",
        "The false discovery rate (FDR) is a measure used in multiple hypothesis testing to control the expected proportion of false positives among the discovered items. The direct posterior probability approach can be used to control the FDR by adapting the threshold \\u03c4 based on a desired FDR tolerance.",
        "Contextual bandits are a type of decision problem where an agent must choose an action from a set of options, each with an unknown reward function. Bayesian decision theory provides a framework for balancing exploration and exploitation in contextual bandits, using techniques such as UCB and Thompson sampling."
      ]
    },
    {
      "topic": "Hierarchical Bayes",
      "sub_topics": [
        "Hierarchical Bayesian models involve multiple levels of unknown quantities, with priors on the hyper-parameters, allowing data-poor cities to borrow statistical strength from data-rich ones.",
        "The full joint distribution can be written as p(D, \\u03b8, \\u03b7|N) = p(\\u03b7) \\u220f Bin(xi|Ni, \\u03b8i)Beta(\\u03b8i|\\u03b7) where \\u03b7 = (a, b). It is crucial that we infer \\u03b7 = (a, b) from the data.",
        "Empirical Bayes (EB) approximates the posterior on hyper-parameters with a point estimate, offering a computationally efficient approach to inference. This overall approach is called empirical Bayes (EB) or type-II maximum likelihood."
      ]
    }
  ]
}