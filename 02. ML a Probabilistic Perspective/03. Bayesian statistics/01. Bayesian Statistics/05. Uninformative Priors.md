## Priors Não Informativos em Estatística Bayesiana
### Introdução
Em Estatística Bayesiana, a escolha da *prior* (distribuição a priori) é crucial para a inferência, pois influencia diretamente a distribuição *posterior*. A distribuição *posterior* $p(\theta|D)$ é proporcional ao produto da *likelihood* $p(D|\theta)$ e da *prior* $p(\theta)$, onde $\theta$ representa os parâmetros do modelo e $D$ os dados observados [^1]. Este capítulo explora os *priors* não informativos, suas nuances e alternativas para mitigar o impacto de suposições a priori na inferência [^1].

### Conceitos Fundamentais
#### Priors Não Informativos
Os **priors não informativos** visam minimizar a influência das suposições iniciais, permitindo que os dados "falem por si" [^1]. No entanto, a construção de tais *priors* é complexa e pode, inadvertidamente, influenciar a distribuição *posterior* [^1]. A ideia central é encontrar uma distribuição *prior* que seja *vaga* ou *difusa*, de modo que a *likelihood* domine a distribuição *posterior*.

#### Priors de Jeffreys
Os **priors de Jeffreys** constituem uma técnica geral para criar *priors* não informativos baseada na **informação de Fisher** [^1]. A informação de Fisher, $I(\phi)$, fornece uma medida da curvatura da *expected negative log likelihood* [^1]:
$$ I(\phi) \triangleq -E\left[\frac{d^2 \log p(X|\phi)}{d\phi^2}\right] $$
Os *priors* de Jeffreys são proporcionais à raiz quadrada da informação de Fisher:
$$ p_\phi(\phi) \propto (I(\phi))^{\frac{1}{2}} $$
A motivação por trás dessa abordagem é que ela é *invariante por reparametrização*, ou seja, a forma do *prior* permanece a mesma, independentemente da parametrização utilizada [^18].

#### Priors Invariantes por Escala
Os **priors invariantes por escala** garantem que a massa de probabilidade atribuída a um intervalo permaneça a mesma sob escalonamento, mantendo inferências consistentes sob mudanças de unidades [^1]. Um exemplo comum é $p(s) \propto \frac{1}{s}$ para um parâmetro de escala $s$ [^1]. Essa propriedade é desejável quando não temos informações prévias sobre a magnitude do parâmetro [^18]. Seja $[A, B]$ um intervalo qualquer. A probabilidade atribuída a este intervalo é:
$$ \int_{A}^{B} p(s) ds = \int_{A}^{B} \frac{1}{s} ds = [\log s]_{A}^{B} = \log(B) - \log(A) $$
Se escalarmos o intervalo por um fator $c > 0$, o novo intervalo será $[\frac{A}{c}, \frac{B}{c}]$. A probabilidade atribuída a este novo intervalo é:
$$ \int_{\frac{A}{c}}^{\frac{B}{c}} p(s) ds = \int_{\frac{A}{c}}^{\frac{B}{c}} \frac{1}{s} ds = [\log s]_{\frac{A}{c}}^{\frac{B}{c}} = \log(\frac{B}{c}) - \log(\frac{A}{c}) = \log(B) - \log(c) - (\log(A) - \log(c)) = \log(B) - \log(A) $$
Portanto, a probabilidade atribuída ao intervalo permanece a mesma após o escalonamento, garantindo a invariância por escala [^18].

#### Priors Robustos
**Priors robustos** com caudas pesadas evitam forçar as estimativas dos parâmetros muito perto da média a priori, proporcionando uma inferência mais confiável na presença de *outliers* ou incerteza [^1]. A distribuição de Cauchy, $T(\theta|0,1,1)$, é um exemplo de *prior* robusto devido às suas caudas pesadas [^1]. Em contraste, *priors* Gaussianos podem ser excessivamente restritivos [^1].

#### Misturas de Priors Conjugados
**Misturas de priors conjugados** oferecem um compromisso entre conveniência computacional e flexibilidade, permitindo a aproximação de qualquer tipo de *prior* e simplificando o cálculo enquanto codificam o conhecimento *a priori* [^1]. Um *prior* conjugado é aquele que, quando combinado com a *likelihood*, resulta em uma *posterior* que pertence à mesma família de distribuições [^21].

### Conclusão
A escolha do *prior* é uma etapa fundamental na análise Bayesiana. *Priors* não informativos buscam minimizar o impacto das suposições *a priori*, mas sua construção requer cuidado [^1]. Os *priors* de Jeffreys oferecem uma abordagem sistemática, enquanto os *priors* invariantes por escala garantem consistência sob mudanças de unidades [^1]. *Priors* robustos são cruciais para lidar com *outliers*, e misturas de *priors* conjugados combinam flexibilidade e eficiência computacional [^1]. A seleção apropriada do *prior* depende do contexto do problema e do conhecimento *a priori* disponível [^1].

### Referências
[^1]: Capítulo 5 do texto fornecido.
[^18]: Seção 5.4.2.2 do texto fornecido.
[^21]: Seção 5.4.4 do texto fornecido.

<!-- END -->