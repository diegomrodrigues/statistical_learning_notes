## Scaling Up Structure Learning for Larger Graphs

### Introdução
Como vimos anteriormente, a aprendizagem da estrutura de modelos gráficos é um problema desafiador devido ao número exponencial de possíveis estruturas de grafos [^2]. No contexto de *Graphical Model Structure Learning*, este capítulo explora estratégias para lidar com grafos maiores, enfocando a aproximação da moda da distribuição a posteriori e outras funções relevantes [^26]. Dada a intratabilidade de métodos exatos para grafos com mais de 16 nós [^26], discutiremos abordagens aproximadas como *greedy hill climbing* e técnicas de amostragem.

### Conceitos Fundamentais

A principal dificuldade em *structure learning* é que o número de possíveis grafos cresce exponencialmente com o número de nós, denotado por *V* [^26]. Uma estimativa superior simples para o número de grafos é *O(2^(V(V-1)/2))* [^26]. Isso significa que calcular a distribuição a posteriori completa, *p(G|D)*, onde *G* representa a estrutura do grafo e *D* os dados, torna-se proibitivamente caro, tanto em termos de computação quanto de armazenamento [^26].

#### Aproximando a Moda da Distribuição a Posteriori
Para grafos pequenos, a *dynamic programming* pode ser usada para aproximar a moda da distribuição a posteriori, que corresponde ao grafo *MAP* (Maximum A Posteriori), dado por Ĝ ∈ argmax_G p(G|D) [^26]. No entanto, este método tem uma complexidade de tempo e espaço de *O(V^2V)* [^26], o que o torna inviável para grafos com mais de cerca de 16 nós.

Devido à limitação da *dynamic programming*, uma alternativa comum é o *greedy hill climbing* [^26]. Este método opera da seguinte forma:

1.  Começa com um grafo inicial.
2.  Em cada passo, propõe pequenas modificações ao grafo atual, como adicionar, remover ou inverter uma única aresta.
3.  Avalia a distribuição a posteriori *p(G|D)* para cada grafo vizinho resultante das modificações propostas.
4.  Move-se para o grafo vizinho que mais aumenta a distribuição a posteriori.
5.  Repete os passos 2-4 até atingir um máximo local, onde nenhuma modificação melhora a distribuição a posteriori.

O *greedy hill climbing* é uma abordagem heurística que não garante encontrar o grafo globalmente ótimo, mas é mais tratável computacionalmente para grafos maiores [^26].

#### Aproximando Outras Funções da Distribuição a Posteriori
Além de encontrar o grafo *MAP*, pode ser interessante aproximar outras funções da distribuição a posteriori para *knowledge discovery* [^26]. Duas funções importantes são:

*   **Probabilidade marginal da aresta:** *p(Gst = 1|D)*, que representa a probabilidade de uma aresta existir entre os nós *s* e *t*, dados os dados *D* [^26].
*   **Probabilidade de um caminho:** A probabilidade de existir um caminho entre os nós *s* e *t*, dados os dados *D*.

A *dynamic programming* pode ser usada para calcular estas probabilidades marginals, mas, como mencionado anteriormente, é limitada a grafos pequenos [^26]. Uma alternativa é usar técnicas de amostragem, como o algoritmo de *Metropolis Hastings*, para gerar amostras de grafos da distribuição a posteriori [^26]. Ao analisar as amostras geradas, podemos estimar as probabilidades marginais das arestas e dos caminhos.

#### Relevance Networks

Uma abordagem "quick and dirty" para *knowledge discovery* é usar *relevance networks* [^26]. Um *relevance network* visualiza a informação mútua entre pares de variáveis aleatórias. Primeiro, um limiar é escolhido. Então, uma aresta é desenhada de um nó *i* para um nó *j* se a informação mútua *I(Xi; Xj)* está acima deste limiar [^26]. No caso Gaussiano, *I(Xi; Xj) = -1/2 log(1 - ρij^2)*, onde *ρij* é o coeficiente de correlação [^26]. Assim, a rede essencialmente visualiza a matriz de covariância. Esta é conhecida como o *covariance graph* [^26].

#### Dependency Networks
Uma maneira simples e eficiente de aprender a estrutura do modelo gráfico é ajustar independentemente *D* distribuições condicionais completas esparsas *p(xt|x_-t)*. Isso é chamado de *dependency network* [^26]. As variáveis escolhidas constituem as entradas para o nó, ou seja, seu *Markov blanket* [^26]. A vantagem sobre os *relevance networks* é que as variáveis redundantes não serão selecionadas como entradas [^26].

### Conclusão
A aprendizagem da estrutura de modelos gráficos para grafos grandes é um problema desafiador que requer o uso de métodos aproximados [^26]. O *greedy hill climbing* e as técnicas de amostragem, como o *Metropolis Hastings*, oferecem alternativas viáveis para aproximar a moda da distribuição a posteriori e outras funções relevantes, como as probabilidades marginais das arestas e dos caminhos [^26]. Essas aproximações permitem identificar relacionamentos e conexões significativas em dados complexos, facilitando a *knowledge discovery* [^26]. Além disso, a escolha do método apropriado depende do tamanho do grafo, dos requisitos de precisão e dos recursos computacionais disponíveis.

### Referências
[^26]: Schmidt, M. (2023). *Graphical model structure learning*.
<!-- END -->