## Causal Models in Graphical Model Structure Learning

### Introdução
Este capítulo explora o uso de **modelos causais** na aprendizagem da estrutura de modelos gráficos, especificamente com foco em **DAGs (Directed Acyclic Graphs)** [^1]. Como vimos anteriormente, a aprendizagem da estrutura do modelo gráfico tem como objetivo descobrir a estrutura do modelo gráfico $p(G|D)$ a partir dos dados, onde $G$ representa a estrutura do grafo [^1]. Exploraremos como os modelos causais, baseados em DAGs, podem prever os efeitos de intervenções ou manipulações [^1].

### Conceitos Fundamentais
**Modelos causais** são usados para prever os efeitos de intervenções ou manipulações, representados por DAGs [^1]. A base desses modelos é a **causal Markov assumption**, que postula que A causa diretamente B se manipular A mudar B [^1].

**DAGs causais** assumem **causal sufficiency**, que implica que todas as variáveis relevantes estão incluídas no modelo [^1]. Esses DAGs podem responder a questões causais usando **perfect interventions**, representadas pelo **do calculus** de Pearl e **graph surgery** [^1].

**Graph surgery** envolve cortar os arcos que chegam aos nós definidos pela intervenção [^1]. Isso impede o fluxo de informação dos nós intervencionados de volta para seus pais, permitindo a inferência probabilística no grafo mutilado [^1]. Formalmente, o *Manipulation Theorem* [^26.6.1] (Pearl 2000; Spirtes et al. 2000) declara que, para calcular $p(X_i|do(X_j))$, para conjuntos de nós $i, j$, podemos realizar uma intervenção cirúrgica nos nós $X_j$ e, em seguida, usar a inferência probabilística padrão no grafo mutilado.

O **Simpson's paradox** demonstra que as relações estatísticas podem ser invertidas pela inclusão de fatores adicionais, exigindo raciocínio causal e a identificação de variáveis de confusão para resolver o paradoxo [^1]. Por exemplo, suponha que tomar um medicamento (C) torne a recuperação (E) mais provável, ou seja, $P(E|C) > P(E|\neg C)$. No entanto, ao condicionar o gênero (F), podemos observar que o medicamento torna a recuperação menos provável tanto para homens quanto para mulheres: $P(E|C, F) < P(E|\neg C, F)$ e $P(E|C, \neg F) < P(E|\neg C, \neg F)$ [^26.6.2]. Para resolver o paradoxo, precisamos ajustar para a variável de confusão, $F$, e examinar o efeito causal usando $P(E|do(C))$ [^26.6.2].

A **aprendizagem de estruturas DAG causais** envolve distinguir DAGs dentro da classe de equivalência usando dados intervencionais, onde certas variáveis foram definidas [^1]. Isso requer modificar os critérios de pontuação bayesiana para lidar com dados observacionais e experimentais mistos [^1].

### Conclusão
Os modelos causais oferecem uma estrutura poderosa para entender e prever os efeitos das intervenções em sistemas complexos. Ao incorporar a causal Markov assumption, causal sufficiency e técnicas como graph surgery e do-calculus, podemos resolver paradoxos como o de Simpson e aprender estruturas DAG causais a partir de dados observacionais e experimentais. A capacidade de distinguir entre DAGs dentro de sua classe de equivalência, utilizando dados intervencionais, é crucial para a descoberta do verdadeiro grafo causal [^1].

### Referências
[^1]: Contexto fornecido.
[^26.6.1]: Pearl, J. (2000). *Causality: Models, reasoning, and inference*. Cambridge University Press.
[^26.6.1]: Spirtes, P., Glymour, C., & Scheines, R. (2000). *Causation, prediction, and search*. MIT press.
[^26.6.2]: Pearl, J. (2000). *Causality: Models, reasoning, and inference*. Cambridge University Press.

<!-- END -->