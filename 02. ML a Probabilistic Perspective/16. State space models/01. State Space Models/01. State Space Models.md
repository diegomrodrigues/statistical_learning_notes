## State Space Models: Fundamentos e Aplicações

### Introdução
State Space Models (SSMs) fornecem uma estrutura poderosa para modelar dados de séries temporais e sistemas que evoluem ao longo do tempo, onde o estado do sistema é apenas parcialmente observado [^1]. SSMs generalizam Hidden Markov Models (HMMs) para estados ocultos contínuos, tornando-os aplicáveis a uma gama mais ampla de problemas [^1]. Este capítulo explora os fundamentos dos SSMs, suas aplicações e algoritmos de inferência associados, com foco em modelos lineares-Gaussianos (LG-SSMs) e suas extensões não lineares. Como vimos anteriormente [referência a um capítulo anterior sobre HMMs], a capacidade de modelar estados latentes e sua evolução temporal é crucial para entender e prever o comportamento de sistemas dinâmicos.

### Conceitos Fundamentais

Um SSM é definido por duas equações principais [^1]:

1.  **Equação de Transição:**
    $$z_t = g(u_t, z_{t-1}, \epsilon_t)$$
    onde $z_t$ representa o estado oculto no tempo $t$, $u_t$ é um sinal de controle opcional, $g$ é o modelo de transição, e $\epsilon_t$ é o ruído do sistema.
2.  **Equação de Observação:**
    $$y_t = h(z_t, u_t, \delta_t)$$
    onde $y_t$ é a observação no tempo $t$, $h$ é o modelo de observação, e $\delta_t$ é o ruído de observação.

Os parâmetros do modelo, denotados por $\theta$, são assumidos como conhecidos ou incluídos no estado oculto [^1]. O objetivo primário ao usar SSMs é estimar recursivamente o estado de crença $p(z_t|y_{1:t}, u_{1:t}, \theta)$ [^1].

**Modelo Linear-Gaussiano (LG-SSM)**

Um caso especial importante de SSM ocorre quando os modelos de transição e observação são lineares e os ruídos são Gaussianos [^1]. Neste caso, as equações se tornam:

1.  **Transição Linear:**
    $$z_t = A_t z_{t-1} + B_t u_t + \epsilon_t$$ [^1]
2.  **Observação Linear:**
    $$y_t = C_t z_t + D_t u_t + \delta_t$$ [^1]
3.  **Ruído Gaussiano do Sistema:**
    $$epsilon_t \sim \mathcal{N}(0, Q_t)$$ [^1]
4.  **Ruído Gaussiano de Observação:**
    $$delta_t \sim \mathcal{N}(0, R_t)$$ [^1]

Se os parâmetros $\theta_t = (A_t, B_t, C_t, D_t, Q_t, R_t)$ são independentes do tempo, o modelo é chamado *estacionário* [^1].

**Aplicações de SSMs**

SSMs têm uma vasta gama de aplicações, incluindo [^2, 3]:

*   **Rastreamento de Objetos:** SSMs e o filtro de Kalman foram originalmente desenvolvidos para rastrear objetos como aviões e mísseis a partir de medições ruidosas de radar [^2]. Um exemplo simplificado envolve modelar a posição e velocidade de um objeto em um plano 2D [^2].
*   **SLAM Robótico:** O problema de Simultaneous Localization and Mapping (SLAM) envolve um robô aprendendo um mapa de um ambiente desconhecido enquanto rastreia sua localização dentro desse mapa [^3].
*   **Previsão de Séries Temporais:** SSMs são adequados para modelar séries temporais escalares, criando modelos generativos de dados em termos de processos latentes [^7]. Exemplos incluem o modelo de nível local e modelos de tendência linear local [^7, 8].
*   **Modelos ARMA:** Os modelos Auto-Regressive Moving Average (ARMA) clássicos para previsão de séries temporais podem ser representados como SSMs [^9].

**Inferencia em LG-SSMs**

A inferência exata em LG-SSMs é possível usando o *filtro de Kalman*, um algoritmo para filtragem Bayesiana exata em modelos lineares-Gaussianos [^10]. O filtro de Kalman estima recursivamente a distribuição marginal posterior no tempo $t$ como [^10]:

$$p(z_t|y_{1:t}, u_{1:t}) = \mathcal{N}(z_t|\mu_t, \Sigma_t)$$

O algoritmo consiste em duas etapas principais [^11]:

1.  **Etapa de Predição:**
    $$p(z_t|y_{1:t-1}, u_{1:t}) = \int \mathcal{N}(z_t|A_t z_{t-1} + B_t u_t, Q_t) \mathcal{N}(z_{t-1}|\mu_{t-1}, \Sigma_{t-1}) dz_{t-1} = \mathcal{N}(z_t|\mu_{t|t-1}, \Sigma_{t|t-1})$$ [^11]
    $$mu_{t|t-1} = A_t \mu_{t-1} + B_t u_t$$ [^11]
    $$Sigma_{t|t-1} = A_t \Sigma_{t-1} A_t^T + Q_t$$ [^11]
2.  **Etapa de Medição (Atualização):**
    $$p(z_t|y_{t}, y_{1:t-1}, u_{1:t}) \propto p(y_t|z_t, u_t) p(z_t|y_{1:t-1}, u_{1:t}) = \mathcal{N}(z_t|\mu_t, \Sigma_t)$$ [^11]
    $$mu_t = \mu_{t|t-1} + K_t r_t$$ [^11]
    $$Sigma_t = (I - K_t C_t) \Sigma_{t|t-1}$$ [^11]
    onde $r_t$ é o resíduo ou inovação, e $K_t$ é a matriz de ganho de Kalman [^11].

**Algoritmo de Suavização de Kalman (Kalman Smoother)**

Enquanto o filtro de Kalman estima $p(z_t|y_{1:t})$, o *algoritmo de suavização de Kalman* computa $p(z_t|y_{1:T})$, onde $T$ é o final da série temporal [^13]. Isso permite uma estimativa mais precisa dos estados ocultos, condicionando tanto em dados passados quanto futuros [^13]. O algoritmo RTS smoother, nomeado em homenagem aos seus inventores Rauch, Tung e Striebel, é um método comum para realizar essa tarefa [^14].

**Inferência Aproximada para SSMs Não Lineares e Não Gaussianos**

Para modelos onde as funções de transição ou observação são não lineares, ou onde o ruído não é Gaussiano, a inferência exata não é possível. Várias técnicas de inferência aproximada podem ser usadas, incluindo [^17, 18]:

*   **Filtro de Kalman Estendido (EKF):** Lineariza as funções não lineares usando uma expansão de série de Taylor de primeira ordem em torno da estimativa de estado anterior [^18].
*   **Filtro de Kalman Não Escalonado (UKF):** Usa a transformação não escalonada para aproximar a distribuição Gaussiana passando um conjunto deterministicamente escolhido de pontos (pontos sigma) através das funções não lineares [^20].
*   **Filtragem de Densidade Assumida (ADF):** Aproxima a posterior por uma distribuição de uma certa forma conveniente, como uma Gaussiana, após cada etapa de atualização [^22].

### Conclusão
State Space Models oferecem uma estrutura flexível e poderosa para modelar sistemas dinâmicos e dados de séries temporais [^1]. Sua capacidade de lidar com estados ocultos contínuos e incorporar ruído torna-os aplicáveis a uma ampla gama de problemas [^1]. Embora a inferência exata seja possível para LG-SSMs usando o filtro de Kalman, técnicas de inferência aproximadas, como EKF e UKF, são necessárias para modelos não lineares e não Gaussianos [^10, 18]. A escolha do algoritmo de inferência depende das características específicas do modelo e dos requisitos de precisão. O algoritmo de suavização de Kalman, por sua vez, possibilita uma melhor estimativa dos estados ao considerar todo o intervalo de tempo.

### Referências
[^1]: Capítulo 18, Introdução.
[^2]: Capítulo 18, Seção 18.2.1.
[^3]: Capítulo 18, Seção 18.2.2.
[^7]: Capítulo 18, Seção 18.2.4.
[^8]: Capítulo 18, Seção 18.2.4.2.
[^9]: Capítulo 18, Seção 18.2.4.4.
[^10]: Capítulo 18, Seção 18.3.
[^11]: Capítulo 18, Seção 18.3.1.
[^13]: Capítulo 18, Seção 18.3.2.
[^14]: Capítulo 18, Seção 18.3.2.
[^17]: Capítulo 18, Seção 18.5.
[^18]: Capítulo 18, Seção 18.5.1.
[^20]: Capítulo 18, Seção 18.5.2.
[^22]: Capítulo 18, Seção 18.5.3.
<!-- END -->