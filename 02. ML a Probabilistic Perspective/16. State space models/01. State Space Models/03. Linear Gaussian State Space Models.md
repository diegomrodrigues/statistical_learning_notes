## Linear-Gaussian State Space Models: Uma Análise Detalhada

### Introdução
Este capítulo explora em profundidade os **Linear-Gaussian State Space Models (LG-SSMs)**, também conhecidos como **Linear Dynamical Systems (LDS)**, dentro do contexto mais amplo dos **State Space Models (SSMs)**. Como mencionado na introdução dos SSMs [^1], um SSM é análogo a um Hidden Markov Model (HMM), com a distinção crucial de que os estados ocultos são contínuos. Os LG-SSMs representam um caso especial onde todas as distribuições de probabilidade condicionais (CPDs) são linear-Gaussianas. Essa simplificação permite a inferência eficiente através do **filtro de Kalman**, tornando os LG-SSMs amplamente aplicáveis em diversas áreas [^1].

### Conceitos Fundamentais

Em um LG-SSM, o **modelo de transição** é definido como:
$$z_t = A_t z_{t-1} + B_t u_t + e_t$$ [^1, 3]
onde:
*   $z_t$ é o estado oculto no tempo $t$ [^1].
*   $A_t$ é a **matriz de transição** [^1].
*   $B_t$ é a **matriz de entrada** [^1].
*   $u_t$ é o **sinal de controle** [^1].
*   $e_t$ é o **ruído do sistema**, assumido como Gaussiano com média zero e covariância $Q_t$, ou seja, $e_t \sim N(0, Q_t)$ [^1, 5].

O **modelo de observação** é definido como:
$$y_t = C_t z_t + D_t u_t + \delta_t$$ [^1, 4]
onde:
*   $y_t$ é a observação no tempo $t$ [^1].
*   $C_t$ é a **matriz de observação** [^1].
*   $D_t$ é a **matriz de entrada** [^1].
*   $\delta_t$ é o **ruído de observação**, assumido como Gaussiano com média zero e covariância $R_t$, ou seja, $\delta_t \sim N(0, R_t)$ [^1, 6].

Um LG-SSM é considerado **estacionário** se os parâmetros $\theta_t = (A_t, B_t, C_t, D_t, Q_t, R_t)$ são independentes do tempo [^1].

**Observação:** A representação genérica de um SSM [^1], onde $z_t = g(u_t, z_{t-1}, e_t)$ e $y_t = h(z_t, u_t, \delta_t)$, é linearizada e gaussianizada no LG-SSM.

#### Aplicações

Os LG-SSMs encontram aplicações em diversos domínios. Um exemplo clássico é o **rastreamento de objetos** [^2]. Considere o rastreamento de um objeto em um plano 2D, onde $z_{1t}$ e $z_{2t}$ representam a localização horizontal e vertical do objeto, respectivamente, e $\dot{z}_{1t}$ e $\dot{z}_{2t}$ representam as velocidades correspondentes [^2]. O vetor de estado pode ser definido como $z_t = (z_{1t}, z_{2t}, \dot{z}_{1t}, \dot{z}_{2t})^T \in \mathbb{R}^4$ [^2, 7]. Assumindo que o objeto se move com velocidade constante, mas é perturbado por ruído Gaussiano aleatório, a dinâmica do sistema pode ser modelada como:

$$ \begin{bmatrix} z_{1t} \\\\ z_{2t} \\\\ \dot{z}_{1t} \\\\ \dot{z}_{2t} \end{bmatrix} = \begin{bmatrix} 1 & 0 & \Delta & 0 \\\\ 0 & 1 & 0 & \Delta \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} z_{1,t-1} \\\\ z_{2,t-1} \\\\ \dot{z}_{1,t-1} \\\\ \dot{z}_{2,t-1} \end{bmatrix} + \begin{bmatrix} \epsilon_{1t} \\\\ \epsilon_{2t} \\\\ \epsilon_{3t} \\\\ \epsilon_{4t} \end{bmatrix} $$ [^3, 8, 9]
onde $\epsilon_t \sim N(0, Q)$ é o ruído do sistema e $\Delta$ é o período de amostragem [^3]. Se observarmos apenas a localização do objeto, mas não sua velocidade, o modelo de observação pode ser definido como:

$$ \begin{bmatrix} y_{1t} \\\\ y_{2t} \end{bmatrix} = \begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \end{bmatrix} \begin{bmatrix} z_{1t} \\\\ z_{2t} \\\\ \dot{z}_{1t} \\\\ \dot{z}_{2t} \end{bmatrix} + \begin{bmatrix} \delta_{1t} \\\\ \delta_{2t} \end{bmatrix} $$ [^3, 10, 11]
onde $\delta_t \sim N(0, R)$ é o ruído de medição [^3].

Outra aplicação importante é o **Simultaneous Localization and Mapping (SLAM)** em robótica [^3].

#### Inferência com o Filtro de Kalman

A importância dos LG-SSMs reside no fato de que permitem a inferência exata, como será demonstrado [^2]. Especificamente, se o estado inicial de crença é Gaussiano, $p(z_1) = N(\mu_{1|0}, \Sigma_{1|0})$, então todos os estados de crença subsequentes também serão Gaussianos; denotamos eles por $p(z_t|y_{1:t}) = N(\mu_{t|t}, \Sigma_{t|t})$ [^2]. Essas quantidades podem ser computadas eficientemente utilizando o **filtro de Kalman** [^2].

**Algoritmo do Filtro de Kalman** [^10]

O filtro de Kalman é um algoritmo para filtragem Bayesiana exata para modelos de espaço de estados linear-Gaussianos [^10]. Ele representa a distribuição marginal posterior no tempo $t$ por:
$$p(z_t|y_{1:t}, u_{1:t}) = N(z_t|\mu_t, \Sigma_t)$$ [^10, 24]

**Etapa de Predição** [^11]

A etapa de predição é derivada diretamente [^11]:

$$ p(z_t|y_{1:t-1}, u_{1:t}) = \int N(z_t|A_t z_{t-1} + B_t u_t, Q_t) N(z_{t-1}|\mu_{t-1}, \Sigma_{t-1}) dz_{t-1} $$ [^11, 25]

$$ = N(z_t|\mu_{t|t-1}, \Sigma_{t|t-1}) $$ [^11, 26]
onde:
$$ \mu_{t|t-1} = A_t \mu_{t-1} + B_t u_t $$ [^11, 27]

$$ \Sigma_{t|t-1} = A_t \Sigma_{t-1} A_t^T + Q_t $$ [^11, 28]

**Etapa de Medição (Atualização)** [^11]

A etapa de medição é computada usando a regra de Bayes [^11]:

$$ p(z_t|y_t, y_{1:t-1}, u_{1:t}) \propto p(y_t|z_t, u_t) p(z_t|y_{1:t-1}, u_{1:t}) $$ [^11, 29]

$$ p(z_t|y_{1:t}, u_t) = N(z_t|\mu_t, \Sigma_t) $$ [^11, 30]

$$ \mu_t = \mu_{t|t-1} + K_t r_t $$ [^11, 31]

$$ \Sigma_t = (I - K_t C_t) \Sigma_{t|t-1} $$ [^11, 32]
onde $r_t$ é o **resíduo** ou **inovação**, dado pela diferença entre a observação predita e a observação real [^11]:

$$ r_t = y_t - \hat{y}_t $$ [^11, 33]

$$ \hat{y}_t = E[y_t|y_{1:t-1}, u_{1:t}] = C_t \mu_{t|t-1} + D_t u_t $$ [^11, 34]
e $K_t$ é a **matriz de ganho de Kalman**, dada por [^11]:

$$ K_t = \Sigma_{t|t-1} C_t^T S_t^{-1} $$ [^11, 35]
onde:

$$ S_t = cov[r_t|y_{1:t-1}, u_{1:t}] = E[(C_t z_t + \delta_t - \hat{y}_t)(C_t z_t + \delta_t - \hat{y}_t)^T |y_{1:t-1}, u_{1:t}] $$ [^11, 36, 37]

$$ = C_t \Sigma_{t|t-1} C_t^T + R_t $$ [^11, 38]

A matriz de ganho de Kalman também pode ser escrita como [^11]:
$$ K_t = \Sigma_{t|t-1} C_t^T (C_t \Sigma_{t|t-1} C_t^T + R_t)^{-1} = (\Sigma_{t|t-1}^{-1} + C_t^T R_t^{-1} C_t)^{-1} C_t^T R_t^{-1} $$ [^11, 39]

**Interpretação:** A atualização da média, $\mu_t = \mu_{t|t-1} + K_t r_t$, indica que a nova média é a média anterior mais um fator de correção, que é o produto do ganho de Kalman pelo resíduo [^11]. O ganho de Kalman pondera a importância do resíduo na atualização, dependendo da confiança nas previsões e nas observações [^12].

**Marginal Likelihood:** Como um subproduto do algoritmo, pode-se calcular a log-verossimilhança da sequência usando [^12]:

$$ log \ p(y_{1:T}|u_{1:T}) = \sum_t log \ p(y_t|y_{1:t-1}, u_{1:t}) $$ [^12, 40]
onde:

$$ p(y_t|y_{1:t-1}, u_{1:t}) = N(y_t|C_t \mu_{t|t-1}, S_t) $$ [^12, 41]

**Posterior Preditivo:** A densidade preditiva posterior de um passo à frente para as observações pode ser computada como [^12]:
$$ p(y_t|y_{1:t-1}, u_{1:t}) = \int N(y_t|C_t z_t, R) N(z_t|\mu_{t|t-1}, \Sigma_{t|t-1}) dz_t = N(y_t|C_t \mu_{t|t-1}, C_t \Sigma_{t|t-1} C_t^T + R) $$ [^12, 42, 43]

#### Suavização de Kalman

O filtro de Kalman descrito acima é útil para problemas de inferência online, como rastreamento [^13]. No entanto, em um cenário offline, podemos esperar até que todos os dados cheguem e, em seguida, computar $p(z_t|y_{1:T})$ [^13]. Ao condicionar em dados passados e futuros, nossa incerteza será significativamente reduzida [^13]. Isso é ilustrado na Figura 18.1(c) [^2], onde vemos que os elipsoides de covariância posterior são menores para a trajetória suavizada do que para a trajetória filtrada [^13].
O algoritmo para computar as estimativas suavizadas é chamado de **RTS smoother**, em homenagem aos seus inventores, Rauch, Tung e Striebel [^14].

### Conclusão

Os Linear-Gaussian State Space Models oferecem uma estrutura poderosa para modelar sistemas dinâmicos onde as relações são lineares e o ruído é Gaussiano. A aplicação do filtro de Kalman permite a inferência eficiente e exata, tornando-os uma ferramenta valiosa em diversas áreas, como rastreamento de objetos, robótica e previsão de séries temporais. Apesar das limitações impostas pelas suposições de linearidade e gaussianidade, as quais podem ser abordadas através de extensões como o Extended Kalman Filter (EKF) e o Unscented Kalman Filter (UKF), os LG-SSMs fornecem uma base sólida para a compreensão e modelagem de sistemas dinâmicos complexos.

### Referências
[^1]: Introdução aos State Space Models (SSMs)
[^2]: Aplicações de SSMs
[^3]: SSMs para rastreamento de objetos
[^4]: O modelo de observação em LG-SSMs
[^5]: O ruído do sistema é Gaussiano
[^6]: O ruído de observação é Gaussiano
[^7]: Representação do vetor de estado para rastreamento de objetos
[^8]: Dinâmica do sistema para rastreamento de objetos (Eq. 18.8)
[^9]: Dinâmica do sistema para rastreamento de objetos (Eq. 18.9)
[^10]: O Filtro de Kalman
[^11]: Inferência no LG-SSM
[^12]: Marginal Likelihood e Posterior Preditivo
[^13]: Algoritmo de Suavização de Kalman
[^14]: RTS Smoother

<!-- END -->