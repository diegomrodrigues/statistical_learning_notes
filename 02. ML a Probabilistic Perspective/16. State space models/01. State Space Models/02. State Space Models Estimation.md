## Estimação Recursiva do Estado de Crença em State Space Models

### Introdução
Em State Space Models (SSMs), um dos objetivos primários é estimar recursivamente o estado de crença, representado por $p(z_t | y_{1:t}, u_{1:t}, \theta)$ [^1]. Este estado de crença representa a distribuição de probabilidade do estado oculto $z_t$ em um dado instante *t*, condicionado em todas as observações passadas $y_{1:t}$, entradas $u_{1:t}$, e parâmetros $\theta$ do modelo. A estimação recursiva envolve converter crenças sobre estados ocultos em previsões sobre observáveis futuros, computando a distribuição preditiva *a posteriori* $p(y_{t+1} | y_{1:t})$ [^1]. Este capítulo explora em profundidade este processo fundamental, fornecendo uma visão abrangente para acadêmicos com conhecimento avançado em matemática, modelos estatísticos, otimização e análise de dados.

### Conceitos Fundamentais

#### Estado de Crença e Estimação Recursiva
O **estado de crença** $p(z_t | y_{1:t}, u_{1:t}, \theta)$ é a pedra angular da inferência em SSMs. Ele encapsula todo o conhecimento disponível sobre o estado do sistema em um dado momento, com base em dados passados. A estimação recursiva significa atualizar este estado de crença iterativamente à medida que novas observações se tornam disponíveis.  Este processo é análogo ao filtro de Kalman, que será descrito posteriormente na seção 18.3.1 [^3].

#### Distribuição Preditiva *a Posteriori*
A **distribuição preditiva *a posteriori*** $p(y_{t+1} | y_{1:t})$ é crucial para fazer previsões sobre observações futuras. Ela fornece uma distribuição de probabilidade sobre o que se espera observar no próximo instante, com base em todo o histórico de observações. Esta distribuição é obtida marginalizando o estado oculto, efetivamente integrando sobre todas as possíveis configurações do estado oculto ponderadas por sua probabilidade *a posteriori*.

#### Linear-Gaussian SSM (LG-SSM)
Um caso especial importante é o **Linear-Gaussian SSM (LG-SSM)** ou *linear dynamical system (LDS)* [^1]. Neste modelo, tanto a função de transição quanto a função de observação são lineares, e o ruído do sistema e o ruído de observação são Gaussianos. Especificamente, temos:
$$z_t = A_t z_{t-1} + B_t u_t + \epsilon_t$$
$$y_t = C_t z_t + D_t u_t + \delta_t$$
onde $\epsilon_t \sim \mathcal{N}(0, Q_t)$ e $\delta_t \sim \mathcal{N}(0, R_t)$ [^1].  A importância do LG-SSM reside no fato de que ele suporta inferência exata, como será visto. Se o estado de crença inicial for Gaussiano, todos os estados de crença subsequentes também serão Gaussianos [^2].

#### Filtro de Kalman
O **filtro de Kalman** é um algoritmo eficiente para realizar a estimação recursiva do estado de crença em LG-SSMs [^3]. Ele aproveita a estrutura linear-Gaussiana para computar analiticamente a distribuição *a posteriori* em cada instante de tempo. O filtro de Kalman consiste em duas etapas principais: **predição** e **atualização** [^11].

##### Etapa de Predição
Na etapa de predição, o filtro de Kalman projeta o estado de crença do instante anterior para o instante atual, usando o modelo de transição:
$$p(z_t | y_{1:t-1}, u_{1:t}) = \int \mathcal{N}(z_t | A_t z_{t-1} + B_t u_t, Q_t) \mathcal{N}(z_{t-1} | \mu_{t-1}, \Sigma_{t-1}) dz_{t-1} = \mathcal{N}(z_t | \mu_{t|t-1}, \Sigma_{t|t-1})$$
onde
$$\mu_{t|t-1} = A_t \mu_{t-1} + B_t u_t$$
$$\Sigma_{t|t-1} = A_t \Sigma_{t-1} A_t^T + Q_t$$
[^11].

##### Etapa de Atualização
Na etapa de atualização, o filtro de Kalman incorpora a nova observação $y_t$ para refinar o estado de crença previsto:
$$p(z_t | y_{1:t}, u_{1:t}) \propto p(y_t | z_t, u_t) p(z_t | y_{1:t-1}, u_{1:t}) = \mathcal{N}(z_t | \mu_t, \Sigma_t)$$
onde
$$\mu_t = \mu_{t|t-1} + K_t r_t$$
$$\Sigma_t = (I - K_t C_t) \Sigma_{t|t-1}$$
[^11]. Aqui, $r_t = y_t - \hat{y}_t$ é o resíduo ou inovação, e $K_t$ é a matriz de ganho de Kalman [^11].

#### Kalman Smoother
O **Kalman smoother** é uma extensão do filtro de Kalman que fornece estimativas mais precisas dos estados ocultos, aproveitando todas as observações disponíveis, tanto passadas quanto futuras [^3, 13].  Enquanto o filtro de Kalman estima $p(z_t | y_{1:t})$, o Kalman smoother estima $p(z_t | y_{1:T})$, onde *T* é o último instante de tempo. Este algoritmo é útil em cenários *offline*, onde todos os dados já foram coletados.

### Conclusão
A estimação recursiva do estado de crença é um processo fundamental em State Space Models, permitindo inferir informações sobre estados ocultos com base em observações passadas e presentes. O filtro de Kalman fornece uma solução eficiente e exata para LG-SSMs, enquanto o Kalman smoother aprimora ainda mais as estimativas, aproveitando informações futuras. Estes conceitos e algoritmos formam a base para muitas aplicações em áreas como rastreamento de objetos, previsão de séries temporais e robótica.

### Referências
[^1]: Página 631, "One of the primary goals in using SSMs is to recursively estimate the belief state, p(zt|y1:t, u1:t, 0). We will also discuss how to convert our beliefs about the hidden state into predictions about future observables by computing the posterior predictive p(yt+1|У1:t)."
[^2]: Página 632, "The LG-SSM is important because it supports exact inference. In particular, if the initial belief state is Gaussian, p(z₁) = N(μ1|0, Σ10), then all subsequent belief states will also be Gaussian; we will denote them by p(zt|y1:t) = N(μt\t, Σt|t)."
[^3]: Página 632, "We can compute these quantities efficiently using the celebrated Kalman filter, as we show in Section 18.3.1."
[^4]: Página 633, "We have now fully specified the model and can perform sequential Bayesian updating to compute p(zt|y1:t) using an algorithm known as the Kalman filter, to be described in Section 18.3.1."
[^5]: Página 633, "Figure 18.1(a) gives an example. The object moves to the right and generates an observation at each time step (think of “blips” on a radar screen). We observe these blips and filter out the noise by using the Kalman filter."
[^6]: Página 633, "To obtain the much smoother plot in Figure 18.1(c), we need to use the Kalman smoother, which computes P(Zty1:T)"
[^7]: Página 635, "If we assume the observation model p(ytzt, L) is linear-Gaussian, and we use a Gaussian motion model for p(xt|xt−1, ut), we can use a Kalman filter to maintain our belief state about the location of the robot and the location of the landmarks"
[^8]: Página 639, "This is thus a generalization of the classic constant linear trend model, an example of which is shown in the black line of Figure 18.6(b)."
[^9]: Página 640, "The Kalman filter is an algorithm for exact Bayesian filtering for linear-Gaussian state space models. We will represent the marginal posterior at time t by p(zt|y1:t, u1:t) = N(zt|μτ, Στ)"
[^10]: Página 640, "Since everything is Gaussian, we can perform the prediction and update steps in closed form, as we explain below. The resulting algorithm is the Gaussian analog of the HMM filter in Section 17.4.2."
[^11]: Página 641, "The prediction step is straightforward to derive: p(zt|y1:t-1, U1:t) = ∫ N(zi Arzt-1 + Bile, Qi)N (Zt-1|με-1, St-1)dzt-1 = Ν(2t|t|t-1, tt-1)"
[^12]: Página 641, "The measurement step can be computed using Bayes rule, as follows p(zt|yt, y1:t-1, U1:t) ∝ p(yt|Zt, ut)P(Zt|y1:t−1, u1:t)"
[^13]: Página 643, "In Section 18.3.1, we described the Kalman filter, which sequentially computes p(zt|y1:t) for each t. This is useful for online inference problems, such as tracking. However, in an offline setting, we can wait until all the data has arrived, and then compute p(zt|y1:T)."

<!-- END -->