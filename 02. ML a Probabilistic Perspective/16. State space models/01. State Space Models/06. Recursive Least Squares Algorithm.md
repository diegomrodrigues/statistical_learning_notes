## Recursive Least Squares (RLS) para Aprendizado de Parâmetros Online em Modelos de Espaço de Estados

### Introdução
Este capítulo explora o algoritmo **Recursive Least Squares (RLS)**, uma técnica fundamental para o aprendizado online de parâmetros em modelos de regressão linear utilizando **State Space Models (SSMs)** [^1]. Em contraste com algoritmos como o Least Mean Squares (LMS), o RLS oferece adaptação automática do tamanho do passo e converge para o posterior ótimo em uma única passagem pelos dados [^6]. O RLS é especialmente útil em cenários onde os dados chegam em fluxo contínuo e a adaptação rápida aos novos dados é essencial [^1].

### Conceitos Fundamentais

#### State Space Models (SSMs)
Como introduzido em [^1], um **SSM** é uma estrutura para modelar sistemas dinâmicos onde os estados são contínuos. O modelo genérico pode ser escrito como:

$$nz_t = g(u_t, z_{t-1}, \epsilon_t) \tag{18.1}$$

$$ny_t = h(z_t, u_t, \delta_t) \tag{18.2}$$

Onde $z_t$ é o estado oculto, $u_t$ é um sinal de controle opcional, $y_t$ é a observação, $g$ é o modelo de transição, $h$ é o modelo de observação, $\epsilon_t$ é o ruído do sistema e $\delta_t$ é o ruído da observação [^1]. Quando $g$ e $h$ são funções lineares e os ruídos são Gaussianos, o modelo é chamado de **Linear-Gaussian SSM (LG-SSM)** ou **Linear Dynamical System (LDS)** [^1].

#### Formulação do RLS como um Problema de Filtragem de Kalman
No contexto do RLS, os parâmetros de regressão são tratados como o estado oculto do SSM. Assumindo que esses parâmetros são constantes ao longo do tempo (ou variando lentamente), podemos definir as equações de estado e observação da seguinte forma:

*   **Equação de Estado:**
    $$theta_t = \theta_{t-1} \tag{18.12}$$
    Isso implica que o estado (parâmetros de regressão) não muda ao longo do tempo, ou seja, $A_t = I$ e $Q_t = 0I$ [^6].
*   **Equação de Observação:**
    $$ny_t = x_t^T \theta_t + \delta_t \tag{18.13}$$
    Aqui, $y_t$ é a observação, $x_t$ é o vetor de características e $\delta_t \sim \mathcal{N}(0, \sigma^2)$ é o ruído de observação [^6]. Assim, $C_t = x_t^T$ e $R_t = \sigma^2$ [^6].

#### Aplicação do Filtro de Kalman
Aplicar o filtro de Kalman a este modelo fornece uma maneira recursiva de atualizar as crenças posteriores sobre os parâmetros à medida que os dados chegam [^6]. A atualização do filtro de Kalman para a média posterior é dada por [^6]:

$$mu_t = A_t \mu_{t-1} + K_t (y_t - C_t A_t \mu_{t-1}) \tag{18.14}$$

onde $K_t$ é a matriz de ganho de Kalman. Usando as equações do filtro de Kalman [^11], podemos derivar uma forma explícita para as atualizações. O ganho de Kalman é dado por [^11]:

$$K_t = \Sigma_{t|t-1} C_t^T S_t^{-1} \tag{18.35}$$

onde $S_t$ é a covariância do resíduo ou inovação [^11]:

$$S_t = C_t \Sigma_{t|t-1} C_t^T + R_t \tag{18.38}$$

No nosso caso [^6]:
$$K_t = \frac{\Sigma_{t|t-1} x_t}{\sigma^2}$$

A atualização para os parâmetros torna-se [^6]:
$$theta_t = \theta_{t-1} + \frac{1}{\sigma^2} \Sigma_{t|t-1} x_t (y_t - x_t^T \theta_{t-1}) \tag{18.15}$$

Se aproximarmos $\Sigma_{t|t-1}$ com $\eta_t I$, recuperamos o algoritmo Least Mean Squares (LMS) [^6]. No entanto, no RLS, a matriz de covariância é atualizada recursivamente usando as equações do filtro de Kalman [^6, 11].

#### Vantagens do RLS sobre o LMS
O RLS oferece várias vantagens sobre o LMS [^1, 6]:

*   **Convergência Mais Rápida:** O RLS converge para o posterior ótimo em uma única passagem pelos dados [^1, 6], enquanto o LMS pode exigir múltiplas passagens [^6].
*   **Adaptação Automática do Tamanho do Passo:** O RLS ajusta automaticamente o tamanho do passo, eliminando a necessidade de ajuste manual, ao contrário do LMS [^1, 6].
*   **Desempenho Superior em Ambientes Não Estacionários:** Em ambientes onde os parâmetros do modelo mudam ao longo do tempo, o RLS pode adaptar-se mais rapidamente às mudanças do que o LMS [^6].

### Conclusão
O Recursive Least Squares (RLS) é uma ferramenta poderosa para o aprendizado online de parâmetros em modelos de regressão linear dentro do framework dos State Space Models (SSMs) [^1]. Sua capacidade de adaptação automática e convergência rápida o tornam uma escolha preferível em muitas aplicações em tempo real, onde os dados chegam em fluxo contínuo e a adaptação rápida é crucial [^1, 6]. A derivação do algoritmo RLS como um caso especial do filtro de Kalman oferece insights valiosos sobre suas propriedades e comportamento [^6, 11].

### Referências
[^1]: State space models
[^6]: Online parameter learning using recursive least squares
[^11]: Inference in LG-SSM
<!-- END -->