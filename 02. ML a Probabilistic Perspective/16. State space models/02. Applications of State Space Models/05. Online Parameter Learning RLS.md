## Online Parameter Learning with Recursive Least Squares in State Space Models

### Introdução
Este capítulo explora a aplicação de Modelos de Espaço de Estados (SSMs) para a aprendizagem online de parâmetros, com foco no uso do método dos Mínimos Quadrados Recursivos (RLS) [^6, ^18]. Em continuidade ao conceito de SSMs como generalizações de HMMs para estados contínuos [^1], trataremos os parâmetros do modelo como estados ocultos, permitindo que o filtro de Kalman seja utilizado para atualizar as estimativas desses parâmetros em tempo real [^18]. Este capítulo se baseia nos conceitos de SSMs lineares-Gaussianos (LG-SSMs) [^1], filtro de Kalman [^2, ^3], e aprendizado Bayesiano online [^6], e visa fornecer uma compreensão profunda de como essas técnicas podem ser combinadas para criar sistemas adaptativos e eficientes.

### Conceitos Fundamentais

#### Formulação do Problema
O objetivo é estimar os parâmetros de um modelo estatístico à medida que os dados chegam em fluxo contínuo [^18]. Em vez de realizar uma estimativa em lote (batch) após a coleta de todos os dados, o aprendizado online permite que o modelo se adapte continuamente a novas informações [^6]. Para realizar isso dentro da estrutura de SSM, os parâmetros do modelo são representados como estados ocultos [^18].

#### Modelagem com Espaço de Estados
Consideremos um modelo linear-Gaussiano, onde o estado oculto $z_t$ representa os parâmetros que desejamos estimar [^1, ^18]. O modelo pode ser definido pelas seguintes equações:

*   **Equação de Transição:** $z_t = A_t z_{t-1} + B_t u_t + \epsilon_t$ [^1, ^18]
*   **Equação de Observação:** $y_t = C_t z_t + D_t u_t + \delta_t$ [^1, ^18]

Onde:

*   $z_t$ é o vetor de estado oculto (parâmetros do modelo) no tempo $t$.
*   $y_t$ é a observação no tempo $t$.
*   $u_t$ é um sinal de entrada opcional no tempo $t$.
*   $A_t$ é a matriz de transição de estado.
*   $B_t$ é a matriz de entrada de controle.
*   $C_t$ é a matriz de observação.
*   $D_t$ é a matriz de entrada de observação.
*   $\epsilon_t \sim \mathcal{N}(0, Q_t)$ é o ruído do sistema.
*   $\delta_t \sim \mathcal{N}(0, R_t)$ é o ruído de observação.

No contexto de aprendizado online de parâmetros, geralmente assumimos que os parâmetros não mudam ao longo do tempo, o que simplifica a equação de transição [^6, ^18]. Isso implica que $A_t = I$ (matriz identidade) e $Q_t = 0$ (sem ruído do sistema), resultando em:

$z_t = z_{t-1}$ [^18]

#### Aplicação do Filtro de Kalman
O filtro de Kalman fornece um algoritmo recursivo para estimar o estado oculto $z_t$ dado o histórico de observações $y_{1:t}$ [^2, ^3, ^18]. Ele consiste em duas etapas principais: predição e atualização [^11].

1.  **Predição:** Estimar o estado e a covariância do erro *a priori* [^11].

    *   $\mu_{t|t-1} = A_t \mu_{t-1} + B_t u_t$ [^11, ^18]
    *   $\Sigma_{t|t-1} = A_t \Sigma_{t-1} A_t^T + Q_t$ [^11, ^18]

    Como estamos assumindo $A_t = I$ e $Q_t = 0$, as equações simplificam para:

    *   $\mu_{t|t-1} = \mu_{t-1}$
    *   $\Sigma_{t|t-1} = \Sigma_{t-1}$

2.  **Atualização:** Incorporar a nova observação $y_t$ para obter as estimativas *a posteriori* [^11].

    *   Resíduo ou Inovação: $r_t = y_t - \hat{y}_t$, onde $\hat{y}_t = C_t \mu_{t|t-1} + D_t u_t$ [^11]
    *   Matriz de Covariância do Resíduo: $S_t = C_t \Sigma_{t|t-1} C_t^T + R_t$ [^11]
    *   Ganho de Kalman: $K_t = \Sigma_{t|t-1} C_t^T S_t^{-1}$ [^11, ^18]
    *   Atualização do Estado: $\mu_t = \mu_{t|t-1} + K_t r_t$ [^11, ^18]
    *   Atualização da Covariância: $\Sigma_t = (I - K_t C_t) \Sigma_{t|t-1}$ [^11, ^18]

#### RLS como Caso Especial do Filtro de Kalman
O método dos Mínimos Quadrados Recursivos (RLS) surge como um caso especial do filtro de Kalman quando aplicado ao aprendizado online de parâmetros em um modelo linear [^18]. Para ver essa conexão, considere o modelo de regressão linear:

$y_t = x_t^T \theta + \delta_t$

Onde:

*   $y_t$ é a variável dependente no tempo $t$.
*   $x_t$ é o vetor de regressores (variáveis independentes) no tempo $t$.
*   $\theta$ é o vetor de parâmetros que desejamos estimar.
*   $\delta_t \sim \mathcal{N}(0, \sigma^2)$ é o ruído de observação com variância $\sigma^2$ [^18].

Neste caso, o vetor de estado $z_t$ corresponde aos parâmetros $\theta$, e a matriz de observação $C_t$ corresponde ao vetor de regressores $x_t^T$ [^18].  Assim, $A_t = I$, $Q_t = 0$, $C_t = x_t^T$, e $R_t = \sigma^2$ [^18]. As equações do filtro de Kalman se tornam:

*   Ganho de Kalman: $K_t = \Sigma_{t-1} x_t (x_t^T \Sigma_{t-1} x_t + \sigma^2)^{-1}$ [^11, ^18]
*   Atualização dos Parâmetros: $\theta_t = \theta_{t-1} + K_t (y_t - x_t^T \theta_{t-1})$ [^11, ^18]
*   Atualização da Covariância: $\Sigma_t = (I - K_t x_t^T) \Sigma_{t-1}$ [^11, ^18]

Essas equações são equivalentes às equações do algoritmo RLS [^18]. Uma forma alternativa para o Ganho de Kalman pode ser derivada usando o *matrix inversion lemma* [^11]:
$$ K_t = (\Sigma_{t-1}^{-1} + \frac{x_t x_t^T}{\sigma^2})^{-1}\frac{x_t}{\sigma^2} $$
A atualização dos parâmetros se torna [^11]:
$$ \theta_t = \theta_{t-1} + \Sigma_t \frac{x_t}{\sigma^2}(y_t - x_t^T\theta_{t-1}) $$

Se aproximarmos $\Sigma_{t|t-1}$ com $\eta_t I$, recuperamos o algoritmo *least mean squares* (LMS) [^7, ^18]. No LMS, precisamos especificar como adaptar o parâmetro de atualização $\eta_t$ para garantir a convergência ao MLE [^18]. Além disso, o algoritmo pode fazer várias passagens pelos dados [^18]. Por outro lado, o algoritmo RLS executa automaticamente a adaptação do tamanho do passo e converge para o posterior ideal em uma passagem pelos dados [^18].

#### Vantagens do RLS com Filtro de Kalman

*   **Adaptação em Tempo Real:** Permite que o modelo se adapte continuamente a novos dados [^18].
*   **Convergência Rápida:** Em geral, converge mais rapidamente do que outros algoritmos de aprendizado online, como o gradiente descendente estocástico [^18].
*   **Estimativas de Incerteza:** Fornece estimativas da incerteza associada aos parâmetros (matriz de covariância $\Sigma_t$) [^11].

#### Considerações Práticas
*   **Inicialização:** A escolha da distribuição inicial $p(z_1) = \mathcal{N}(\mu_{1|0}, \Sigma_{1|0})$ pode afetar o desempenho do algoritmo, especialmente no início do processo de aprendizado [^2]. Uma matriz de covariância inicial $\Sigma_{1|0}$ grande representa uma crença inicial fraca, permitindo que o algoritmo se adapte rapidamente aos novos dados [^2].
*   **Estabilidade Numérica:** Implementações práticas do filtro de Kalman empregam técnicas para garantir a estabilidade numérica, como o uso de filtros de raiz quadrada (square root filters) [^12].
*   **Complexidade Computacional:** A complexidade computacional do filtro de Kalman é $O(d^3)$, onde $d$ é a dimensão do estado oculto [^12]. Para problemas de alta dimensão, podem ser necessárias aproximações ou métodos de inferência variacional [^12].

### Conclusão

O uso do filtro de Kalman para aprendizado online de parâmetros, especialmente através do algoritmo RLS, oferece uma abordagem poderosa e flexível para a adaptação de modelos em tempo real [^18]. Ao tratar os parâmetros como estados ocultos em um SSM, podemos aproveitar as ferramentas bem estabelecidas da teoria de espaço de estados para inferência e aprendizado [^1]. Embora existam desafios computacionais e considerações práticas a serem levadas em conta, os benefícios do aprendizado online, da convergência rápida e das estimativas de incerteza tornam essa abordagem atraente para uma ampla gama de aplicações [^18]. Este capítulo forneceu uma base sólida para a compreensão e implementação dessas técnicas, preparando o terreno para a exploração de tópicos mais avançados, como modelos não lineares e não Gaussianos, que serão abordados em seções posteriores [^17].

### Referências

[^1]: Seção 18.1
[^2]: Seção 18.3
[^3]: Seção 18.3.1
[^6]: Seção 18.2.3
[^7]: Seção 8.5.3
[^11]: Seção 18.3.1.1, 18.3.1.2
[^12]: Seção 18.3.1.5
[^17]: Seção 18.5
[^18]: Seção 18.2.3

<!-- END -->