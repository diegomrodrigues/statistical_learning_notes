## Filtros de Kalman Estendidos (EKF) e Não-Centrados (UKF) para Modelos de Espaço de Estados Não-Lineares e Não-Gaussianos

### Introdução
Em modelos de espaço de estados (SSMs) lineares-Gaussianos (LG-SSMs), a inferência exata pode ser realizada utilizando o filtro de Kalman [^1, ^2, ^18]. No entanto, muitos sistemas de interesse prático exibem dinâmicas não-lineares e/ou ruído não-Gaussiano [^18]. Nesses casos, técnicas de inferência aproximadas são necessárias. Este capítulo explora duas abordagens comuns para inferência aproximada em SSMs não-lineares e não-Gaussianos: o Filtro de Kalman Estendido (EKF) e o Filtro de Kalman Não-Centrado (UKF) [^18]. Ambas as abordagens visam aproximar a *posterior* por uma Gaussiana.

### Conceitos Fundamentais

#### A Necessidade de Inferência Aproximada
Em SSMs não-lineares e não-Gaussianos, as equações do filtro de Kalman não se aplicam diretamente porque as distribuições *a posteriori* não são mais Gaussianas [^18]. A não-linearidade do modelo de transição ($g$) ou do modelo de observação ($h$) impede que as distribuições Gaussianas se propaguem analiticamente através das etapas de predição e atualização [^18].

#### Filtro de Kalman Estendido (EKF)
O EKF é uma técnica de linearização que aproxima as funções não-lineares $g$ e $h$ por suas expansões de Taylor de primeira ordem [^18]. Especificamente, considere um SSM da forma:

$$z_t = g(u_t, z_{t-1}) + \epsilon_t$$
$$y_t = h(z_t) + \delta_t$$

onde $\epsilon_t \sim \mathcal{N}(0, Q_t)$ e $\delta_t \sim \mathcal{N}(0, R_t)$ são ruídos Gaussianos.

O EKF lineariza $g$ e $h$ em torno das estimativas de estado anteriores, $\mu_{t-1|t-1}$, resultando em:

$$g(u_t, z_{t-1}) \approx g(u_t, \mu_{t-1|t-1}) + G_t(z_{t-1} - \mu_{t-1|t-1})$$

$$h(z_t) \approx h(\mu_{t|t-1}) + H_t(z_t - \mu_{t|t-1})$$

onde $G_t$ e $H_t$ são as matrizes Jacobianas de $g$ e $h$, respectivamente, avaliadas em $\mu_{t-1|t-1}$ e $\mu_{t|t-1}$ [^18]. As equações de atualização do EKF são então derivadas aplicando o filtro de Kalman padrão às versões linearizadas do modelo [^18].

As etapas de predição e atualização do EKF são dadas por [^18]:

**Predição:**

$$mu_{t|t-1} = g(u_t, \mu_{t-1|t-1})$$
$$Sigma_{t|t-1} = G_t \Sigma_{t-1|t-1} G_t^T + Q_t$$

**Atualização:**

$$K_t = \Sigma_{t|t-1} H_t^T (H_t \Sigma_{t|t-1} H_t^T + R_t)^{-1}$$
$$mu_t = \mu_{t|t-1} + K_t(y_t - h(\mu_{t|t-1}))$$
$$Sigma_t = (I - K_t H_t) \Sigma_{t|t-1}$$

#### Filtro de Kalman Não-Centrado (UKF)
O UKF, em contraste com o EKF, evita a linearização da função não linear [^18]. Em vez disso, o UKF utiliza a *unscented transformation* para aproximar a distribuição de probabilidade resultante de uma transformação não linear [^18].

A *unscented transformation* seleciona um conjunto de pontos amostrais deterministicamente escolhidos, chamados *sigma points*, que capturam a média e a covariância da distribuição *a priori* [^18]. Esses pontos *sigma* são então passados através da função não linear, e a média e covariância da *posterior* são aproximadas usando as amostras transformadas [^18].

O conjunto de pontos *sigma* $X$ é definido como [^18]:

$$X = \left\{ \mu, \mu + (\sqrt{(d + \lambda)\Sigma})_i, \mu - (\sqrt{(d + \lambda)\Sigma})_i \right\}$$

onde $\mu$ é a média, $\Sigma$ é a covariância, $d$ é a dimensão do espaço de estados, $\lambda = \alpha^2(d + \kappa) - d$ é um parâmetro de escala, $\alpha$ determina a propagação dos pontos *sigma* em torno de $\mu$, e $\kappa$ é um parâmetro secundário de escala [^18].

As etapas de predição e atualização do UKF são dadas por [^18]:

**Predição:**

1.  Gerar os pontos *sigma* $X_{t-1}$ com base em $\mu_{t-1|t-1}$ e $\Sigma_{t-1|t-1}$.
2.  Propagar os pontos *sigma* através da função de transição: $X_t^* = g(u_t, X_{t-1})$.
3.  Calcular a média e covariância preditas:

$$mu_{t|t-1} = \sum_{i=0}^{2d} w_i X_{t,i}^*$$
$$Sigma_{t|t-1} = \sum_{i=0}^{2d} w_i (X_{t,i}^* - \mu_{t|t-1})(X_{t,i}^* - \mu_{t|t-1})^T + Q_t$$

**Atualização:**

1.  Gerar pontos *sigma* $X_t$ com base em $\mu_{t|t-1}$ e $\Sigma_{t|t-1}$.
2.  Propagar os pontos *sigma* através da função de observação: $Y_t = h(X_t)$.
3.  Calcular a média e covariância da observação predita:

$$hat{y}_t = \sum_{i=0}^{2d} w_i Y_{t,i}$$
$$S_t = \sum_{i=0}^{2d} w_i (Y_{t,i} - \hat{y}_t)(Y_{t,i} - \hat{y}_t)^T + R_t$$

4.  Calcular a covariância cruzada:

$$Sigma_{xy} = \sum_{i=0}^{2d} w_i (X_{t,i} - \mu_{t|t-1})(Y_{t,i} - \hat{y}_t)^T$$

5.  Calcular o ganho de Kalman:

$$K_t = \Sigma_{xy} S_t^{-1}$$

6.  Atualizar a média e covariância:

$$mu_t = \mu_{t|t-1} + K_t(y_t - \hat{y}_t)$$
$$Sigma_t = \Sigma_{t|t-1} - K_t S_t K_t^T$$

### Conclusão
O EKF e o UKF são técnicas amplamente utilizadas para inferência aproximada em SSMs não-lineares e não-Gaussianos [^18]. O EKF, baseado na linearização de primeira ordem, é computacionalmente mais simples, mas pode apresentar desempenho inferior em sistemas altamente não-lineares [^18]. O UKF, utilizando a *unscented transformation*, geralmente fornece estimativas mais precisas, mas a um custo computacional ligeiramente maior [^18]. A escolha entre EKF e UKF depende das características específicas do sistema e das *trade-offs* entre precisão e custo computacional [^18].

### Referências
[^1]: seção 18.1
[^2]: seção 18.3
[^18]: seção 18.5
<!-- END -->