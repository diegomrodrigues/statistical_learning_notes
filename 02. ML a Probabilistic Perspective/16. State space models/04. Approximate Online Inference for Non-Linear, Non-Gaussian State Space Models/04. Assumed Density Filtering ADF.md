## Assumed Density Filtering (ADF) para Modelos de Espaço de Estados Não Lineares e Não Gaussianos

### Introdução
Em continuidade aos métodos de inferência aproximada para modelos de espaço de estados (SSMs) não lineares e não Gaussianos, este capítulo explora o Assumed Density Filtering (ADF) [^647]. Como vimos anteriormente, a inferência exata em SSMs não lineares e não Gaussianos é computacionalmente intratável, exigindo o uso de aproximações [^647]. O ADF oferece uma abordagem eficiente para a inferência online, mantendo uma distribuição aproximada da *belief state* ao longo do tempo [^647, 648]. Este capítulo detalha o funcionamento do ADF, suas vantagens e limitações, e comparações com outros métodos de inferência aproximada.

### Conceitos Fundamentais
O Assumed Density Filtering (ADF) é uma técnica de inferência aproximada que se baseia em um ciclo de três etapas: *predict-update-project* [^647]. A ideia central do ADF é aproximar a distribuição *a posteriori* por uma distribuição de uma forma conveniente, como uma Gaussiana, após cada etapa de atualização [^647].

1.  **Etapa de Predição:** Nesta etapa, a distribuição *a priori* do estado atual é predita com base no estado anterior e no modelo de transição [^641]. Matematicamente, esta etapa pode ser expressa como:
    $$     p(z_t | y_{1:t-1}, u_{1:t}) = \int N(z_t | A_t z_{t-1} + B_t u_t, Q_t) N(z_{t-1} | \mu_{t-1}, \Sigma_{t-1}) dz_{t-1}\     $$
    onde $z_t$ é o estado oculto, $y_{1:t-1}$ são as observações passadas, $u_{1:t}$ são os sinais de controle, $A_t$ é a matriz de transição, $B_t$ é a matriz de controle, $Q_t$ é a covariância do ruído do sistema, $\mu_{t-1}$ é a média do estado anterior e $\Sigma_{t-1}$ é a covariância do estado anterior [^641]. O resultado desta etapa é uma distribuição preditiva $p(z_t | y_{1:t-1}, u_{1:t})$ que é geralmente uma Gaussiana com média $\mu_{t|t-1}$ e covariância $\Sigma_{t|t-1}$ [^641].
2.  **Etapa de Atualização:** Nesta etapa, a distribuição preditiva é atualizada com base na observação atual $y_t$ usando a regra de Bayes [^614]. Matematicamente, esta etapa pode ser expressa como:
    $$     p(z_t | y_{1:t}, u_{1:t}) \propto p(y_t | z_t, u_t) p(z_t | y_{1:t-1}, u_{1:t})\     $$
    onde $p(y_t | z_t, u_t)$ é a função de verossimilhança, que descreve a probabilidade da observação dado o estado atual e o sinal de controle [^614]. O resultado desta etapa é a distribuição *a posteriori* $p(z_t | y_{1:t}, u_{1:t})$, que representa nossa crença sobre o estado atual após incorporar a nova observação [^614].
3.  **Etapa de Projeção:** A etapa de projeção é crucial no ADF. Após a etapa de atualização, a distribuição *a posteriori* resultante pode não pertencer à família de distribuições tratáveis (Q) que escolhemos [^652, 653]. Portanto, projetamos a *belief state* exata em uma distribuição da família tratável Q, minimizando a divergência de Kullback-Leibler (KL) [^647, 653]. Esta etapa garante que a distribuição *a posteriori* seja aproximada por uma distribuição que possa ser representada e manipulada eficientemente [^647]. Matematicamente, a etapa de projeção pode ser expressa como:
    $$     q(θ_t) = \underset{q \in Q}{\operatorname{argmin}} \operatorname{KL}(\hat{p}(θ_t) || q(θ_t))\     $$
    onde $\hat{p}(θ_t)$ é a distribuição *a posteriori* "exata" (mas intratável) e $q(θ_t)$ é a distribuição aproximada na família Q [^653].

**Minimização da Divergência de Kullback-Leibler (KL):**
A minimização da divergência KL é um passo essencial no ADF [^647, 653]. A divergência KL, definida como:

$$ KL(p||q) = \int p(x) \log \frac{p(x)}{q(x)} dx\ $$

mede a diferença entre duas distribuições de probabilidade $p(x)$ e $q(x)$ [^653]. No contexto do ADF, a minimização da divergência KL entre a distribuição *a posteriori* exata $\hat{p}(θ_t)$ e a distribuição aproximada $q(θ_t)$ garante que a aproximação seja a mais fiel possível à distribuição original, dentro das restrições da família de distribuições tratáveis Q [^653].

**ADF e Família Exponencial:**
Uma simplificação significativa ocorre quando a família de distribuições tratáveis Q pertence à família exponencial [^647, 653]. Neste caso, a minimização da divergência KL pode ser realizada através do *moment matching* [^647, 653]. O *moment matching* envolve igualar os momentos da distribuição aproximada $q(θ_t)$ aos momentos correspondentes da distribuição *a posteriori* exata $\hat{p}(θ_t)$ [^647]. Por exemplo, se Q é a família de distribuições Gaussianas, então igualamos a média e a covariância de $q(θ_t)$ à média e covariância de $\hat{p}(θ_t)$ [^647].

### Conclusão
O Assumed Density Filtering (ADF) oferece uma abordagem eficiente para a inferência online em modelos de espaço de estados não lineares e não Gaussianos [^647]. Ao aproximar a distribuição *a posteriori* por uma distribuição tratável após cada etapa de atualização, o ADF permite a inferência em tempo real, mantendo um nível razoável de precisão [^647]. A escolha da família de distribuições tratáveis Q é crucial para o desempenho do ADF, e a minimização da divergência KL garante que a aproximação seja a mais fiel possível à distribuição original [^647]. Em casos onde Q pertence à família exponencial, o *moment matching* simplifica significativamente o processo de minimização da divergência KL [^647].

### Referências
[^647]: Definição e descrição geral do Assumed Density Filtering (ADF).
[^648]: Introdução à necessidade de inferência aproximada em modelos não lineares e não Gaussianos.
[^614]: Explicação da regra de Bayes e sua aplicação na etapa de atualização.
[^652]: Descrição da etapa de projeção e sua importância para garantir a tratabilidade.
[^653]: Detalhes sobre a minimização da divergência de Kullback-Leibler (KL) e o *moment matching*.
<!-- END -->