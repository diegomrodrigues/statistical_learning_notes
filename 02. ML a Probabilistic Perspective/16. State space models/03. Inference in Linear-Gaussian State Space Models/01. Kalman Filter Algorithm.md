## O Filtro de Kalman

### Introdução
O Filtro de Kalman é um algoritmo crucial para a inferência Bayesiana exata em modelos de espaço de estados lineares-Gaussianos (LG-SSM) [^1]. Ele estima recursivamente a distribuição marginal posterior do estado oculto a cada passo de tempo, dadas as observações até aquele momento [^1]. Este capítulo explora em detalhes o Filtro de Kalman, suas aplicações e derivações matemáticas, construindo sobre os conceitos de modelos de espaço de estados (SSM) e a importância dos LG-SSMs.

### Conceitos Fundamentais

#### Modelos de Espaço de Estados Lineares-Gaussianos (LG-SSM)
Um modelo de espaço de estados (SSM) é análogo a um modelo oculto de Markov (HMM), com a distinção de que os estados ocultos são contínuos [^1]. Um SSM pode ser representado genericamente por:
$$
\begin{aligned}
z_t &= g(u_t, z_{t-1}, \epsilon_t) \\
y_t &= h(z_t, u_t, \delta_t)
\end{aligned}
$$
onde $z_t$ é o estado oculto, $u_t$ é um sinal de entrada opcional, $y_t$ é a observação, $g$ é o modelo de transição, $h$ é o modelo de observação, $\epsilon_t$ é o ruído do sistema no tempo $t$, e $\delta_t$ é o ruído da observação no tempo $t$ [^1]. Um caso especial importante de SSM é onde todas as distribuições condicionais de probabilidade (CPDs) são lineares-Gaussianas [^1]. Neste caso, assume-se:
*   Modelo de transição linear: $z_t = A_t z_{t-1} + B_t u_t + \epsilon_t$ [^1]
*   Modelo de observação linear: $y_t = C_t z_t + D_t u_t + \delta_t$ [^1]
*   Ruído do sistema Gaussiano: $\epsilon_t \sim N(0, Q_t)$ [^1]
*   Ruído da observação Gaussiano: $\delta_t \sim N(0, R_t)$ [^1]

Este modelo é chamado de LG-SSM ou sistema dinâmico linear (LDS) [^1]. Se os parâmetros $\theta_t = (A_t, B_t, C_t, D_t, Q_t, R_t)$ são independentes do tempo, o modelo é considerado estacionário [^1].

#### O Algoritmo do Filtro de Kalman
O Filtro de Kalman é um algoritmo para a filtragem Bayesiana exata em LG-SSMs [^10]. Ele representa a distribuição marginal posterior no tempo $t$ por $p(z_t | y_{1:t}, u_{1:t}) = N(z_t | \mu_t, \Sigma_t)$ [^10]. O Filtro de Kalman permite que os passos de predição e atualização sejam realizados em forma fechada [^10].

##### Passo de Predição
O passo de predição é derivado da seguinte forma:
$$
\begin{aligned}
p(z_t | y_{1:t-1}, u_{1:t}) &= \int N(z_t | A_t z_{t-1} + B_t u_t, Q_t) N(z_{t-1} | \mu_{t-1}, \Sigma_{t-1}) dz_{t-1} \\
&= N(z_t | \mu_{t|t-1}, \Sigma_{t|t-1})
\end{aligned}
$$
onde
$$
\begin{aligned}
\mu_{t|t-1} &= A_t \mu_{t-1} + B_t u_t \\
\Sigma_{t|t-1} &= A_t \Sigma_{t-1} A_t^T + Q_t
\end{aligned}
$$
##### Passo de Medição
O passo de medição é computado usando a regra de Bayes:
$$
p(z_t | y_t, y_{1:t-1}, u_{1:t}) \propto p(y_t | z_t, u_t) p(z_t | y_{1:t-1}, u_{1:t})
$$
Este passo resulta em:
$$
p(z_t | y_{1:t}, u_t) = N(z_t | \mu_t, \Sigma_t)
$$
onde
$$
\begin{aligned}
\mu_t &= \mu_{t|t-1} + K_t r_t \\
\Sigma_t &= (I - K_t C_t) \Sigma_{t|t-1}
\end{aligned}
$$
Aqui, $r_t$ é o resíduo ou inovação, dado pela diferença entre a observação predita e a observação real:
$$
\begin{aligned}
r_t &= y_t - \hat{y}_t \\
\hat{y}_t &= E[y_t | y_{1:t-1}, u_{1:t}] = C_t \mu_{t|t-1} + D_t u_t
\end{aligned}
$$
e $K_t$ é a matriz de ganho de Kalman, dada por:
$$
K_t = \Sigma_{t|t-1} C_t^T S_t^{-1}
$$
onde
$$
\begin{aligned}
S_t &= \text{cov}[r_t | y_{1:t-1}, u_{1:t}] \\
&= E[(C_t z_t + \delta_t - \hat{y}_t)(C_t z_t + \delta_t - \hat{y}_t)^T | y_{1:t-1}, u_{1:t}] \\
&= C_t \Sigma_{t|t-1} C_t^T + R_t
\end{aligned}
$$

#### Suavização de Kalman
O filtro de Kalman, conforme descrito na Seção 18.3.1 [^13], computa sequencialmente $p(z_t|y_{1:t})$ para cada $t$ [^13]. Isso é útil para problemas de inferência online, como rastreamento [^13]. No entanto, em um cenário offline, podemos esperar até que todos os dados tenham chegado e, em seguida, computar $p(z_t|y_{1:T})$ [^13]. Ao condicionar os dados passados e futuros, nossa incerteza será significativamente reduzida [^13]. Isso é ilustrado na Figura 18.1(c) [^2], onde vemos que os elipsóides de covariância posterior são menores para a trajetória suavizada do que para a trajetória filtrada [^13]. Os elipsóides são maiores no início e no final da trajetória, uma vez que os estados próximos ao limite não têm tantos vizinhos úteis dos quais tomar emprestado informações [^13].

### Conclusão
O Filtro de Kalman é uma ferramenta poderosa para a inferência em LG-SSMs, com aplicações que vão desde o rastreamento de objetos até a previsão de séries temporais [^2]. Sua capacidade de fornecer estimativas ótimas e recursivas do estado, juntamente com uma quantificação da incerteza, o torna indispensável em muitos domínios [^10].

### Referências
[^1]: D. Barber, *Bayesian Reasoning and Machine Learning*. Cambridge University Press, 2012.
[^2]: Figura 18.1 de D. Barber, *Bayesian Reasoning and Machine Learning*. Cambridge University Press, 2012.
[^10]: Seção 18.3.1 de D. Barber, *Bayesian Reasoning and Machine Learning*. Cambridge University Press, 2012.
[^13]: Seção 18.3.2 de D. Barber, *Bayesian Reasoning and Machine Learning*. Cambridge University Press, 2012.
<!-- END -->