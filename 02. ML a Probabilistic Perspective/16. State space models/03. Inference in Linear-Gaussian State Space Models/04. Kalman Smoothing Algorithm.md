## Suavização de Kalman: Inferência Offline em Modelos de Espaço de Estados Lineares-Gaussianos

### Introdução
Em modelos de espaço de estados lineares-gaussianos (LG-SSM), o objetivo principal é estimar o estado oculto $z_t$ dado um conjunto de observações $y_{1:t}$ [^1]. O filtro de Kalman, conforme discutido na Seção 18.3.1, fornece uma maneira eficiente de calcular recursivamente a distribuição posterior marginal $p(z_t|y_{1:t}, u_{1:t})$ [^10]. No entanto, em cenários offline, onde todos os dados $y_{1:T}$ estão disponíveis, podemos melhorar a precisão da estimativa de $z_t$ condicionando tanto em dados passados quanto futuros [^13]. Este capítulo explora o algoritmo de suavização de Kalman, também conhecido como *RTS smoother*, que computa $p(z_t | y_{1:T})$ para cada $t$, reduzindo significativamente a incerteza ao incorporar informações de todo o conjunto de dados [^13].

### Conceitos Fundamentais
O algoritmo de suavização de Kalman, também conhecido como *Rauch-Tung-Striebel (RTS) smoother*, é um método para estimar os estados de um modelo de espaço de estados linear, utilizando todas as observações disponíveis [^14]. Diferentemente do filtro de Kalman, que realiza a inferência online, o suavizador de Kalman opera offline, processando os dados em duas etapas: uma passagem para frente (filtering) e uma passagem para trás (smoothing) [^14].

#### Algoritmo
O algoritmo de suavização de Kalman envolve os seguintes passos:

1.  **Passagem para Frente (Kalman Filtering):**
    *   Utilizar o filtro de Kalman (Seção 18.3.1) para calcular as distribuições posteriores marginais $p(z_t|y_{1:t})$ para cada $t = 1, ..., T$ [^10]. Isso fornece as estimativas filtradas $\mu_{t|t}$ e $\Sigma_{t|t}$ [^10].
    *   As equações de predição e atualização do filtro de Kalman são dadas por [^11]:

        *   Predição:

            $$\
            p(z_t | y_{1:t-1}, u_{1:t}) = \mathcal{N}(z_t | \mu_{t|t-1}, \Sigma_{t|t-1})\
            $$

            $$\
            \mu_{t|t-1} = A_t \mu_{t-1|t-1} + B_t u_t\
            $$

            $$\
            \Sigma_{t|t-1} = A_t \Sigma_{t-1|t-1} A_t^T + Q_t\
            $$
        *   Atualização:

            $$\
            p(z_t | y_{1:t}, u_{1:t}) = \mathcal{N}(z_t | \mu_t, \Sigma_t)\
            $$

            $$\
            \mu_t = \mu_{t|t-1} + K_t r_t\
            $$

            $$\
            \Sigma_t = (I - K_t C_t) \Sigma_{t|t-1}\
            $$
            onde $K_t$ é o ganho de Kalman e $r_t$ é o resíduo ou inovação [^11].

2.  **Passagem para Trás (Smoothing):**
    *   Calcular as estimativas suavizadas $p(z_t|y_{1:T})$ para cada $t = T-1, ..., 1$, utilizando as estimativas filtradas obtidas na passagem para frente [^13].
    *   O suavizador RTS é inicializado com $\mu_{T|T}$ e $\Sigma_{T|T}$ do filtro de Kalman [^14].
    *   As equações de suavização são dadas por [^14]:

        $$\
        p(z_t|y_{1:T}) = \mathcal{N}(\mu_{t|T}, \Sigma_{t|T})\
        $$

        $$\
        \mu_{t|T} = \mu_{t|t} + J_t (\mu_{t+1|T} - \mu_{t+1|t})\
        $$

        $$\
        \Sigma_{t|T} = \Sigma_{t|t} + J_t (\Sigma_{t+1|T} - \Sigma_{t+1|t}) J_t^T\
        $$

        $$\
        J_t = \Sigma_{t|t} A_{t+1}^T \Sigma_{t+1|t}^{-1}\
        $$
        onde $J_t$ é o ganho de Kalman "para trás" [^14].

#### Derivação

A derivação do suavizador de Kalman envolve o uso da propriedade de Markov, que afirma que $z_t$ é independente de dados futuros $y_{t+1:T}$ dado $z_{t+1}$ [^14]. Matematicamente [^14]:

$$\
p(z_t | y_{1:T}) = \int p(z_t | z_{t+1}, y_{1:t}) p(z_{t+1} | y_{1:T}) dz_{t+1}\
$$

A distribuição conjunta $p(z_t, z_{t+1} | y_{1:t})$ pode ser expressa como [^14]:

$$\
p(z_t, z_{t+1} | y_{1:t}) = \mathcal{N} \left( \begin{bmatrix} z_t \\\\ z_{t+1} \end{bmatrix} ; \begin{bmatrix} \mu_{t|t} \\\\ \mu_{t+1|t} \end{bmatrix} , \begin{bmatrix} \Sigma_{t|t} & \Sigma_{t|t} A_{t+1}^T \\\\ A_{t+1} \Sigma_{t|t} & \Sigma_{t+1|t} \end{bmatrix} \right)\
$$

Condicionando $z_t$ em $z_{t+1}$ e $y_{1:t}$ e usando as regras para condicionamento de Gaussianas, obtemos [^14]:

$$\
p(z_t | z_{t+1}, y_{1:t}) = \mathcal{N}(\mu_{t|t} + J_t (z_{t+1} - \mu_{t+1|t}), \Sigma_{t|t} - J_t \Sigma_{t+1|t} J_t^T)\
$$

Finalmente, substituindo $p(z_{t+1} | y_{1:T})$ pela estimativa suavizada no passo $t+1$ e integrando, obtemos as equações de suavização apresentadas acima [^14].

### Conclusão
O algoritmo de suavização de Kalman (RTS smoother) é uma ferramenta poderosa para inferência offline em modelos de espaço de estados lineares-gaussianos [^13]. Ao condicionar tanto em dados passados quanto futuros, o suavizador de Kalman fornece estimativas mais precisas dos estados ocultos em comparação com o filtro de Kalman [^13]. Embora a suavização de Kalman não seja adequada para aplicações online, ela é valiosa em cenários onde todos os dados estão disponíveis e a precisão é primordial [^13]. É importante notar que, como mencionado na Seção 18.3.2, os elipsoides de covariância posteriores são menores para a trajetória suavizada do que para a trajetória filtrada, especialmente nas regiões onde o estado tem muitos vizinhos úteis dos quais tomar informações emprestadas [^13].

### Referências
[^1]: D. Barber, *Bayesian Reasoning and Machine Learning*. Cambridge University Press, 2012.
[^10]: Section 18.3.1
[^11]: Section 18.3.1.1, Section 18.3.1.2
[^13]: Section 18.3.2
[^14]: Section 18.3.2, Section 18.3.2.1, Section 18.3.2.2

<!-- END -->