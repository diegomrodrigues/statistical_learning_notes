## Inferência Bayesiana para a Média de uma MVN com Covariância Conhecida

### Introdução

Este capítulo explora a inferência Bayesiana dos parâmetros de uma Distribuição Normal Multivariada (MVN). Especificamente, focaremos na inferência da média $\mu$ de uma MVN, dado um conjunto de dados $D$ e a matriz de covariância $\Sigma$, assumindo que $\Sigma$ é conhecida [^1]. Este cenário é fundamental em diversas aplicações, e a análise Bayesiana nos permite quantificar a incerteza sobre $\mu$ através da distribuição *a posteriori*.

### Conceitos Fundamentais

**Distribuição *a posteriori* para $\mu$:**

Quando inferimos os parâmetros de uma MVN, a distribuição *a posteriori* de $\mu$ dado $D$ e $\Sigma$ é Gaussiana [^1]. Se utilizarmos um *prior* conjugado (Gaussiano), podemos derivar uma distribuição *a posteriori* Gaussiana para $\mu$ com base nos resultados da Section 4.4.2.2 [^1].

Dado um *prior* conjugado $p(\mu) = N(\mu|m_0, V_0)$ [^1], onde $m_0$ é a média *a priori* e $V_0$ é a variância *a priori*, a distribuição *a posteriori* para $\mu$ é dada por:

$$p(\mu|D, \Sigma) = N(\mu|m_N, V_N)$$

onde:

$$V_N^{-1} = V_0^{-1} + N\Sigma^{-1}$$
$$m_N = V_N (\Sigma^{-1}(N\bar{x}) + V_0^{-1} m_0)$$

Aqui, $N$ é o número de amostras em $D$, e $\bar{x}$ é a média amostral. $V_N$ representa a variância *a posteriori* e $m_N$ representa a média *a posteriori*.

**Derivação da Distribuição *a posteriori***

A derivação da distribuição *a posteriori* Gaussiana para $\mu$ segue os princípios da inferência Bayesiana [^1]. Começamos com a verossimilhança dos dados $p(D|\mu, \Sigma)$ e o *prior* $p(\mu)$. A distribuição *a posteriori* é proporcional ao produto da verossimilhança e do *prior*:

$$p(\mu|D, \Sigma) \propto p(D|\mu, \Sigma) p(\mu)$$

Dado que tanto a verossimilhança quanto o *prior* são Gaussianos, o produto também resulta em uma distribuição Gaussiana [^1]. Os parâmetros da *a posteriori* ($m_N$ e $V_N$) são obtidos completando o quadrado na expressão exponencial resultante, conforme detalhado na Section 4.4.2.2 [^1].

**Interpretação dos Resultados**

A média *a posteriori* $m_N$ é uma combinação ponderada da média *a priori* $m_0$ e da média amostral $\bar{x}$ [^1]. O peso relativo dessas duas quantidades é determinado pelas precisões (inversos das variâncias) dos *priors* e da verossimilhança [^1]. Se a variância *a priori* $V_0$ é pequena (alta confiança no *prior*), $m_N$ estará mais próxima de $m_0$. Se a variância *a priori* é grande (baixa confiança no *prior*), $m_N$ estará mais próxima de $\bar{x}$ [^1].

A variância *a posteriori* $V_N$ representa a incerteza restante sobre $\mu$ após observar os dados [^1]. Ela diminui à medida que o número de amostras $N$ aumenta, refletindo a redução da incerteza com mais informações [^1].

**Conexão com a Estimativa de Máxima Verossimilhança (MLE)**

Em um cenário com um *prior* não informativo (ou seja, $V_0 \rightarrow \infty$), a média *a posteriori* $m_N$ se iguala à estimativa de máxima verossimilhança (MLE) [^1]. Isso ocorre porque o *prior* não exerce influência, e a *a posteriori* é dominada pela verossimilhança dos dados [^1].

**Comportamento Assintótico da Variância *a posteriori***

A variância *a posteriori* diminui como $1/N$ [^1], o que é um resultado padrão da estatística frequentista. Isso significa que, à medida que o tamanho da amostra aumenta, a incerteza sobre $\mu$ diminui na taxa de $1/N$, independentemente da distribuição *a priori* [^1].

### Conclusão

A inferência Bayesiana para a média de uma MVN com covariância conhecida fornece uma estrutura flexível para incorporar conhecimento *a priori* e quantificar a incerteza sobre $\mu$ [^1]. A distribuição *a posteriori* Gaussiana permite uma interpretação intuitiva dos resultados, e a conexão com a MLE fornece uma ligação com a estatística frequentista. A análise apresentada neste capítulo forma a base para análises Bayesianas mais complexas envolvendo MVNs [^1].

### Referências
[^1]: Texto fornecido.
<!-- END -->