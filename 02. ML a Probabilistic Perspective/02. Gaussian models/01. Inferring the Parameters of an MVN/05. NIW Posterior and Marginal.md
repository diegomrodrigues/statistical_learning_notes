## Inferência Bayesiana com a Distribuição Normal-Inversa-Wishart para MVNs

### Introdução
Este capítulo aborda a inferência Bayesiana dos parâmetros de um modelo Gaussiano Multivariado (MVN), utilizando a distribuição Normal-Inversa-Wishart (NIW) como prior conjugada. A escolha de priors conjugadas simplifica o cálculo da distribuição posterior, permitindo uma análise mais tratável. Exploraremos como a distribuição NIW, definida como $NIW(\mu, \Sigma|m_0, \kappa_0, V_0, S_0)$ [^1], garante que a posterior também seja NIW, com parâmetros atualizados. Além disso, demonstraremos que a marginal posterior para $\mu$ segue uma distribuição t de Student multivariada.

### Conceitos Fundamentais

A inferência Bayesiana requer a especificação de uma **distribuição *a priori*** sobre os parâmetros do modelo. No contexto de MVNs, os parâmetros são a média $\mu$ e a matriz de covariância $\Sigma$. A distribuição Normal-Inversa-Wishart (NIW) é uma escolha comum como prior conjugada porque sua forma funcional garante que a distribuição *a posteriori* também pertença à mesma família, facilitando os cálculos.

A distribuição NIW é definida como o produto de uma distribuição normal para a média $\mu$ condicionada à covariância $\Sigma$ e uma distribuição Inversa-Wishart para $\Sigma$ [^4.200, 4.201]:
$$ NIW(\mu, \Sigma|m_0, \kappa_0, V_0, S_0) = \mathcal{N}(\mu|m_0, \frac{\Sigma}{\kappa_0}) \times IW(\Sigma|S_0, \nu_0)\ $$
onde:

*   $m_0$ é a média *a priori* para $\mu$
*   $\kappa_0$ controla a confiança na média *a priori*
*   $S_0$ é a matriz de escala *a priori* para $\Sigma$
*   $\nu_0$ são os graus de liberdade *a priori* para $\Sigma$

Após observar os dados $D = \{x_1, ..., x_N\}$, a distribuição *a posteriori* $p(\mu, \Sigma|D)$ é também NIW, com parâmetros atualizados [^4.209]:
$$ p(\mu, \Sigma|D) = NIW(\mu, \Sigma|m_N, \kappa_N, \nu_N, S_N)\ $$
onde:
$$ m_N = \frac{\kappa_0 m_0 + N \bar{x}}{\kappa_0 + N}\ $$
$$ \kappa_N = \kappa_0 + N\ $$
$$ \nu_N = \nu_0 + N\ $$
$$ S_N = S_0 + S + \frac{\kappa_0 N}{\kappa_0 + N} (\bar{x} - m_0)(\bar{x} - m_0)^T\ $$
Aqui, $\bar{x}$ é a média amostral e $S = \sum_{i=1}^N (x_i - \bar{x})(x_i - \bar{x})^T$ é a matriz de dispersão amostral.

A **marginal posterior** para $\mu$ obtida integrando sobre $\Sigma$ segue uma distribuição t de Student multivariada [^4.219]:
$$ p(\mu|D) = \int p(\mu, \Sigma|D) d\Sigma = T(\mu|m_N, \frac{S_N}{\kappa_N (\nu_N - D + 1)}, \nu_N - D + 1)\ $$
Esta distribuição t de Student multivariada reflete a incerteza sobre $\mu$ devido à incerteza sobre $\Sigma$.

### Conclusão

A utilização da distribuição Normal-Inversa-Wishart como prior conjugada simplifica a inferência Bayesiana para MVNs. A posterior resultante é também NIW, e a marginal posterior para $\mu$ segue uma distribuição t de Student multivariada. Esses resultados fornecem uma estrutura para quantificar a incerteza sobre os parâmetros do modelo e realizar previsões Bayesianas. Este framework é essencial para lidar com dados de alta dimensão e para mitigar o overfitting, como mencionado na seção 4.1.3 [^1]. O framework apresentado aqui pode ser estendido para lidar com cenários mais complexos, como a inferência em modelos hierárquicos Gaussianos, como será explorado em capítulos subsequentes.

### Referências
[^1]: Capítulo 4, Gaussian models.
<!-- END -->