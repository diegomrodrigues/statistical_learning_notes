## Inferência em Distribuições Gaussianas Conjuntas: Distribuições Marginais e Condicionais

### Introdução
Este capítulo explora a inferência em distribuições Gaussianas conjuntas, um tópico fundamental em modelos Gaussianos [^1]. Especificamente, focaremos na obtenção das distribuições **marginais** e **condicionais** a partir de uma distribuição Gaussiana conjunta [^4], detalhando as propriedades e as fórmulas relevantes. A capacidade de derivar essas distribuições é crucial para diversas aplicações, incluindo análise de dados, modelagem estatística e aprendizado de máquina [^1].

### Conceitos Fundamentais

#### Distribuições Marginais e Condicionais
Dada uma distribuição Gaussiana multivariada (MVN) [^1] conjunta $p(x_1, x_2)$, onde $x = (x_1, x_2)$, o objetivo é derivar as distribuições marginais $p(x_1)$ e $p(x_2)$, bem como as distribuições condicionais $p(x_1|x_2)$ e $p(x_2|x_1)$ [^4].

#### Teorema Fundamental
O teorema 4.3.1 [^4] estabelece que, se $x = (x_1, x_2)$ é conjuntamente Gaussiano com parâmetros:

$$\
\mu = \begin{pmatrix} \mu_1 \\\\ \mu_2 \end{pmatrix}, \quad
\Sigma = \begin{pmatrix} \Sigma_{11} & \Sigma_{12} \\\\ \Sigma_{21} & \Sigma_{22} \end{pmatrix}, \quad
\Lambda = \Sigma^{-1} = \begin{pmatrix} \Lambda_{11} & \Lambda_{12} \\\\ \Lambda_{21} & \Lambda_{22} \end{pmatrix}
$$

Então, as **marginais** são dadas por:

$$\
p(x_1) = N(x_1|\mu_1, \Sigma_{11}) \\\\
p(x_2) = N(x_2|\mu_2, \Sigma_{22})
$$

e a **condicional** $p(x_1|x_2)$ é uma Gaussiana com média e covariância condicionais [^4]:

$$\
p(x_1|x_2) = N(x_1|\mu_{1|2}, \Sigma_{1|2})
$$

onde

$$\
\mu_{1|2} = \mu_1 + \Sigma_{12} \Sigma_{22}^{-1} (x_2 - \mu_2) = \mu_1 - \Lambda_{11}^{-1} \Lambda_{12} (x_2 - \mu_2) = \Sigma_{1|2} (\Lambda_{11} \mu_1 - \Lambda_{12} (x_2 - \mu_2))
$$

e

$$\
\Sigma_{1|2} = \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21} = \Lambda_{11}^{-1}
$$

#### Interpretação
A distribuição marginal $p(x_1)$ é obtida extraindo as linhas e colunas correspondentes a $x_1$ da distribuição Gaussiana conjunta [^4]. A distribuição condicional $p(x_1|x_2)$ é uma Gaussiana com uma média condicional que é uma função linear de $x_2$, e uma matriz de covariância condicional que é independente de $x_2$ [^4].

#### Exemplo Bidimensional
Considere um exemplo bidimensional com a seguinte matriz de covariância [^4]:

$$\
\Sigma = \begin{pmatrix} \sigma_1^2 & \rho \sigma_1 \sigma_2 \\\\ \rho \sigma_1 \sigma_2 & \sigma_2^2 \end{pmatrix}
$$

A marginal $p(x_1)$ é uma Gaussiana unidimensional obtida projetando a distribuição conjunta sobre o eixo $x_1$ [^4]:

$$\
p(x_1) = N(x_1|\mu_1, \sigma_1^2)
$$

Se observarmos $x_2$, a condicional $p(x_1|x_2)$ é obtida *fatiando* a distribuição conjunta na linha $x_2 = x_2$ [^4]:

$$\
p(x_1|x_2) = N \left( x_1 \Big| \mu_1 + \frac{\rho \sigma_1}{\sigma_2} (x_2 - \mu_2), \sigma_1^2 - \frac{(\rho \sigma_1 \sigma_2)^2}{\sigma_2^2} \right)
$$

Se $\sigma_1 = \sigma_2 = \sigma$, então [^4]:

$$\
p(x_1|x_2) = N(x_1|\mu_1 + \rho(x_2 - \mu_2), \sigma^2(1 - \rho^2))
$$

### Conclusão
Este capítulo detalhou como derivar distribuições marginais e condicionais a partir de distribuições Gaussianas conjuntas [^4]. As fórmulas apresentadas são fundamentais para inferência em modelos Gaussianos e têm amplas aplicações em diversas áreas [^1]. A compreensão desses conceitos é essencial para a análise de dados e modelagem estatística em contextos onde as distribuições Gaussianas são predominantes [^1]. <!-- END -->