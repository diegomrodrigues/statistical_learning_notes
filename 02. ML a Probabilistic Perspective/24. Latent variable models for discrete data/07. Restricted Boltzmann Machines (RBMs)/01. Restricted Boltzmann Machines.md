## Restricted Boltzmann Machines: Advanced Perspectives

### Introdução
Este capítulo aprofunda o estudo das Restricted Boltzmann Machines (RBMs), modelos gráficos não direcionados com aplicações em diversas áreas, incluindo modelagem de linguagem e sistemas de recomendação. RBMs são um caso especial de Product of Experts (PoE) [^983], onde experts representam funções de potencial nas arestas, e nós ocultos especificam quais restrições estão ativas. Exploraremos as variedades de RBMs, métodos de aprendizado e suas aplicações, construindo sobre os conceitos apresentados anteriormente neste livro.

### Conceitos Fundamentais
#### Definição e Estrutura
Uma **Restricted Boltzmann Machine (RBM)** é um modelo gráfico não direcionado que consiste em duas camadas: uma camada de unidades visíveis (v) e uma camada de unidades ocultas (h) [^983]. A característica "restricted" refere-se à ausência de conexões intra-camada, ou seja, não há conexões entre unidades visíveis ou entre unidades ocultas. Essa estrutura bipartite simplifica a inferência e o aprendizado.

As RBMs são um caso especial de **Markov Random Fields (MRF)**, também conhecidos como Gibbs Random Fields [^referência futura]. A energia de uma configuração (v, h) em uma RBM binária é definida como [^985]:
$$ E(v, h; \theta) = -\sum_{r=1}^{R}\sum_{k=1}^{K} v_r h_k W_{rk} - \sum_{r=1}^{R} v_r b_r - \sum_{k=1}^{K} h_k c_k $$
onde:
- $v_r$ é o estado da unidade visível *r*.
- $h_k$ é o estado da unidade oculta *k*.
- $W_{rk}$ é o peso da conexão entre a unidade visível *r* e a unidade oculta *k*.
- $b_r$ é o bias da unidade visível *r*.
- $c_k$ é o bias da unidade oculta *k*.

A probabilidade conjunta da configuração (v, h) é dada por [^985]:
$$ p(v, h| \theta) = \frac{1}{Z(\theta)} \exp(-E(v, h; \theta)) $$
onde $Z(\theta)$ é a função de partição, que normaliza a distribuição de probabilidade.

#### Variedades de RBMs
Existem diversas variedades de RBMs, cada uma adequada para diferentes tipos de dados [^985]:

1.  **Binary RBM:** Tanto as unidades visíveis quanto as ocultas são binárias. Este é o tipo mais comum de RBM, adequado para dados binários ou binarizados.
2.  **Gaussian RBM:** As unidades visíveis são Gaussianas, enquanto as unidades ocultas são binárias. Adequado para dados de valor real. A energia é definida como [^985]:
    $$     E(v,h|0) = - \sum_{r=1}^{R}\sum_{k=1}^{K} W_{rk}h_k v_r - \sum_{r=1}^{R} \frac{(v_r - b_r)^2}{2} - \sum_{k=1}^{K} a_k h_k     $$
3.  **Categorical RBM:** As unidades visíveis são categóricas, representando variáveis discretas com múltiplos estados. A energia é definida como [^986]:
    $$     E(v,h; \theta) = -\sum_{r=1}^{R}\sum_{k=1}^{K}\sum_{c=1}^{C} h_k v_{rc} W_{rk}^c - \sum_{r=1}^{R}\sum_{c=1}^{C} v_{rc} b_r^c - \sum_{k=1}^{K} h_k c_k     $$

#### Aprendizado de RBMs
O aprendizado de RBMs envolve encontrar os parâmetros $\theta$ que maximizam a verossimilhança dos dados observados. A função de log-verossimilhança é dada por [^988]:
$$ l(\theta) = \frac{1}{N} \sum_{i=1}^{N} \log p(v_i|\theta) = \frac{1}{N} \sum_{i=1}^{N} -F(v_i; \theta) - \log Z(\theta) $$
onde $F(v; \theta)$ é a energia livre.

O gradiente da log-verossimilhança em relação aos pesos $W_{rk}$ é [^987]:
$$ \frac{\partial l}{\partial W_{rk}} = \frac{1}{N} \sum_{i=1}^{N} \mathbb{E}[v_r h_k | v_i, \theta] - \mathbb{E}[v_r h_k | \theta] $$
O cálculo exato do segundo termo (expectativa sob a distribuição do modelo) é computacionalmente intratável. Por isso, métodos aproximados são necessários.

##### Contrastive Divergence (CD)
**Contrastive Divergence (CD)** é um algoritmo eficiente para aproximar o gradiente na aprendizagem de RBMs [^987]. Em vez de calcular a expectativa sob a distribuição do modelo, o CD usa amostragem de Gibbs para estimar essa expectativa [^987].

O algoritmo CD-1 (uma iteração de CD) funciona da seguinte forma:

1.  Para cada amostra de dados $v$, calcule a distribuição das unidades ocultas $p(h|v)$.
2.  Amostre um vetor oculto $h$ da distribuição $p(h|v)$.
3.  Reconstrua o vetor visível $v'$ amostrando de $p(v|h)$.
4.  Calcule a distribuição das unidades ocultas $p(h'|v')$.
5.  Aproximar o gradiente usando as estatísticas de $v$, $h$, $v'$ e $h'$.

A atualização dos pesos é dada por [^987]:
$$ \Delta W_{rk} \propto \mathbb{E}[v_r h_k | v] - \mathbb{E}[v_r h_k | v'] $$
onde $v$ é um vetor de dados, $h$ é uma amostra das unidades ocultas dado $v$, $v'$ é uma reconstrução de $v$ dado $h$, e $h'$ é uma amostra das unidades ocultas dado $v'$.

### Conclusão
As Restricted Boltzmann Machines oferecem uma estrutura poderosa para modelar distribuições de probabilidade complexas. Suas variedades, como RBMs binárias, Gaussianas e categóricas, permitem a adaptação a diferentes tipos de dados. O algoritmo Contrastive Divergence fornece um meio eficiente de aprender os parâmetros do modelo. RBMs são blocos de construção essenciais para modelos generativos profundos e continuam sendo uma área ativa de pesquisa. <!-- END -->