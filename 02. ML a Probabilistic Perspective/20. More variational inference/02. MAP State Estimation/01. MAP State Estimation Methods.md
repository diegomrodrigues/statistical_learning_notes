## Técnicas para Estimação de Estado MAP em Modelos Gráficos Discretos

### Introdução
Este capítulo se aprofunda nas técnicas para encontrar a configuração mais provável de variáveis em modelos gráficos de estado discreto, um problema conhecido como **estimação de estado MAP (Maximum A Posteriori)** [^799]. Conforme mencionado na introdução do Capítulo 22 [^767], algoritmos para resolver o problema MAP são similares a métodos aproximados para computar marginais. Exploraremos abordagens como o relaxamento de programação linear, *max-product belief propagation*, e *graphcuts*, cada um com suas particularidades e aplicabilidades.

### Conceitos Fundamentais
A **estimação de estado MAP** busca encontrar a configuração $x^*$ que maximiza a probabilidade a posteriori $p(x|\theta)$, onde $\theta$ representa os parâmetros do modelo [^799]. Formalmente, o objetivo é encontrar:
$$ x^* = \arg \max_{x \in \mathcal{X}^m} p(x|\theta) = \arg \max_{x \in \mathcal{X}^m} \left( \sum_{i \in \mathcal{V}} \theta_i(x_i) + \sum_{f \in \mathcal{F}} \theta_f(x_f) \right) $$
onde $\mathcal{X}^m$ é o espaço de todas as configurações possíveis, $\mathcal{V}$ é o conjunto de nós, $\mathcal{F}$ é o conjunto de fatores, $\theta_i(x_i)$ são os potenciais de nó único e $\theta_f(x_f)$ são os potenciais de fator. Note que a função de partição $Z(\theta)$ não tem papel na estimação MAP [^799].

#### Relaxamento de Programação Linear
Uma abordagem para resolver o problema MAP é o **relaxamento de programação linear**, que envolve reescrever o objetivo em termos de parâmetros variacionais e relaxar o conjunto de restrições para um limite externo convexo [^799]. O objetivo pode ser reescrito como:
$$ \arg \max_{x \in \mathcal{X}^m} \theta^T \phi(x) = \arg \max_{\mu \in \mathcal{M}(G)} \theta^T \mu $$
onde $\phi(x)$ são as estatísticas suficientes e $\mu$ é um vetor de probabilidade no polítopo marginal $\mathcal{M}(G)$ [^799]. A dificuldade reside no fato de que $\mathcal{M}(G)$ geralmente tem um número de facetas que é exponencial no número de nós. A estratégia padrão é relaxar as restrições, permitindo que o vetor de probabilidade $\mu$ resida dentro de um limite externo convexo $\mathcal{L}(G)$ [^799]:
$$ \max_{x \in \mathcal{X}^m} \theta^T \phi(x) \leq \max_{\tau \in \mathcal{L}(G)} \theta^T \tau $$
Se a solução for integral, é exata; caso contrário, é uma aproximação [^800].

#### Max-Product Belief Propagation
Outra abordagem é utilizar o **max-product belief propagation**, que considera o limite de temperatura zero da distribuição de probabilidade [^800]. Nesse limite, o operador de soma se torna o operador de máximo. O objetivo MAP pode ser aproximado considerando o limite de temperatura zero da distribuição de probabilidade $\mu$, onde a probabilidade concentra toda a sua massa em seu modo. O objetivo é então dado por:
$$ A(\theta) \triangleq \max_{\mu \in \mathcal{M}(G)} \theta^T \mu + \mathcal{H}(\mu) $$
Considere uma temperatura inversa $\beta$ tendendo ao infinito:
$$ \lim_{\beta \to +\infty} \frac{A(\beta\theta)}{\beta} = \max_{\mu \in \mathcal{M}(G)} \theta^T \mu $$
No limite de temperatura zero, o operador de soma se torna o operador máximo, resultando em um método chamado max-product belief propagation [^800].

#### Graphcuts
**Graphcuts** fornecem outro método para encontrar estimativas de estado MAP, utilizando algoritmos de *max flow/min cut*, particularmente para nós binários e potenciais restritos [^801].  Esta técnica é especialmente útil em problemas de visão computacional [^801]. Começamos considerando um MRF binário onde as energias de aresta têm a seguinte forma:
$$ E_{uv}(x_u, x_v) = \begin{cases} 0 & \text{se } x_u = x_v \\ \lambda_{uv} & \text{se } x_u \neq x_v \end{cases} $$
onde $\lambda_{uv} \geq 0$ é o custo da aresta [^801]. Construímos um grafo com o mesmo conjunto de nós que o MRF, mais dois nós distintos: a fonte *s* e o sumidouro *t* [^801]. Se $E_u(1) = 0$, adicionamos a aresta $x_u \rightarrow t$ com custo $E_u(0)$. Se $E_u(0) = 0$, adicionamos a aresta $x_u \rightarrow s$ com custo $E_u(1)$ [^801]. Finalmente, para cada par de variáveis conectadas no MRF, adicionamos arestas $x_u \rightarrow x_v$ e $x_v \rightarrow x_u$, ambas com custo $\lambda_{uv} \geq 0$ [^801].

### Conclusão
Este capítulo explorou diversas técnicas para a estimação de estado MAP em modelos gráficos discretos. O relaxamento de programação linear oferece uma abordagem teórica sólida, enquanto o *max-product belief propagation* fornece uma alternativa heurística. Os *graphcuts* são particularmente eficazes para modelos com nós binários e potenciais submodulares. A escolha da técnica depende das características específicas do modelo gráfico e das exigências de precisão e eficiência computacional.

### Referências
[^767]: Introdução do Capítulo 22.
[^799]: Trecho do texto sobre MAP state estimation.
[^800]: Trecho do texto sobre relaxamento de programação linear.
[^801]: Trecho do texto sobre Graphcuts.
<!-- END -->