## Belief Propagation on Factor Graphs

### Introdução
Este capítulo explora a aplicação do **Belief Propagation (BP)** em *factor graphs*, uma representação gráfica que unifica modelos direcionados e não direcionados, simplificando algoritmos de *message passing* [^769]. Como vimos anteriormente no contexto de *mean field inference* [^767], a inferência aproximada é crucial para lidar com a complexidade de modelos gráficos. O *loopy belief propagation (LBP)*, uma aplicação do algoritmo BP em grafos com loops, apresenta desafios em termos de convergência e exatidão [^767]. A representação de modelos em *factor graphs* permite lidar com potenciais de clique de ordem superior, incluindo modelos direcionados [^769].

### Conceitos Fundamentais
Um **factor graph** é um grafo bipartido não direcionado que consiste em dois tipos de nós:
*   **Nós de variável:** Representam as variáveis do modelo.
*   **Nós de fator:** Representam os fatores (funções) que definem as relações entre as variáveis.

Existe uma aresta entre uma variável e um fator se a variável é um argumento do fator [^769]. Por exemplo, considere a função $f(x_1, x_2, x_3, x_4) = f_{124}(x_1, x_2, x_4) f_{234}(x_2, x_3, x_4)$ [^769]. O *factor graph* correspondente teria nós de variável para $x_1, x_2, x_3, x_4$ e nós de fator para $f_{124}$ e $f_{234}$. A variável $x_1$ estaria conectada ao fator $f_{124}$, a variável $x_2$ estaria conectada a ambos os fatores, e assim por diante.

A **Belief Propagation (BP) em factor graphs** envolve a passagem de mensagens entre variáveis e fatores. Existem dois tipos de mensagens [^771]:

1.  **Mensagens de variáveis para fatores:** A mensagem de uma variável $x$ para um fator $f$ é o produto das mensagens recebidas de todos os outros fatores conectados a $x$:
    $$m_{x \rightarrow f}(x) = \prod_{h \in \text{nbr}(x) \setminus \{f\}} m_{h \rightarrow x}(x)$$
    onde $\text{nbr}(x)$ é o conjunto de fatores conectados à variável $x$ [^771].

2.  **Mensagens de fatores para variáveis:** A mensagem de um fator $f$ para uma variável $x$ é computada somando (ou integrando, no caso contínuo) sobre o produto do fator e as mensagens recebidas de todas as outras variáveis conectadas a $f$:
    $$m_{f \rightarrow x}(x) = \sum_{\mathbf{y}} f(x, \mathbf{y}) \prod_{y \in \text{nbr}(f) \setminus \{x\}} m_{y \rightarrow f}(y)$$
    onde $\text{nbr}(f)$ é o conjunto de variáveis conectadas ao fator $f$, e $\mathbf{y}$ representa todas as variáveis em $\text{nbr}(f) \setminus \{x\}$ [^771].

No final das iterações, a **crença (belief)** em cada variável é computada como o produto de todas as mensagens recebidas pelos fatores conectados a essa variável:
$$bel(x) \propto \prod_{f \in \text{nbr}(x)} m_{f \rightarrow x}(x)$$
[^771].

O algoritmo de *Belief Propagation* é iterativo. As mensagens são inicializadas (tipicamente com valores uniformes) e atualizadas repetidamente até que convirjam [^771]. A convergência não é garantida, especialmente em grafos com loops [^767].

### Conclusão
A aplicação de *Belief Propagation* em *factor graphs* oferece uma estrutura flexível para inferência em modelos gráficos complexos. Embora o *LBP* apresente desafios em grafos com loops, a representação em *factor graphs* facilita a aplicação de algoritmos aproximados e o desenvolvimento de métodos para melhorar a convergência e a exatidão. Como veremos em seções subsequentes, outras técnicas, como *generalized belief propagation* e *convex belief propagation* [^785], podem ser utilizadas para mitigar as limitações do *LBP* e obter resultados mais robustos.

### Referências
[^769]: Kschischang, F. R., Frey, B. J., & Loeliger, H. A. (2001). Factor graphs and the sum-product algorithm. *IEEE Transactions on Information Theory, 47*(2), 498-519.
[^767]: Weiss, Y. (2001). Understanding belief propagation. *Journal of Machine Learning Research, 2*(Jun), 463-489.
[^771]: Kschischang, F. R., Frey, B. J., & Loeliger, H. A. (2001). Factor graphs and the sum-product algorithm. *IEEE Transactions on Information Theory, 47*(2), 498-519.
[^785]: Wainwright, M. J., & Jordan, M. I. (2008b). Graphical models, exponential families, and variational inference. *Foundations and Trends in Machine Learning, 1*(1-2), 1-305.

<!-- END -->