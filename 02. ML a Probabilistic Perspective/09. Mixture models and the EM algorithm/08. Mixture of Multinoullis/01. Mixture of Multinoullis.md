## Mixture de Multinoullis para Modelagem de Dados Binários
### Introdução
Este capítulo explora a aplicação de **mixture models** para definir modelos de densidade para vetores binários D-dimensionais, utilizando um produto de Bernoullis como densidade condicional à classe [^340]. A introdução de variáveis latentes permite capturar correlações entre variáveis, aumentando o poder do modelo e permitindo a modelagem de dados complexos [^340]. Este tópico se encaixa no contexto mais amplo de **latent variable models (LVMs)** e **mixture models** em geral [^337, 338].

### Conceitos Fundamentais
#### Densidade Condicional à Classe
Para dados que consistem em vetores binários D-dimensionais, podemos definir um modelo de densidade usando um **mixture model** onde a densidade condicional à classe é um produto de Bernoullis [^340]. Matematicamente, isso é expresso como:
$$ p(\mathbf{x}_i|z_i = k, \boldsymbol{\theta}) = \prod_{j=1}^{D} \text{Ber}(x_{ij}|\mu_{jk}) = \prod_{j=1}^{D} \mu_{jk}^{x_{ij}} (1 - \mu_{jk})^{1-x_{ij}} $$
onde:
*   $\mathbf{x}_i$ é o *i*-ésimo vetor de bits D-dimensional [^340].
*   $z_i$ é a variável latente que indica a qual cluster o vetor $\mathbf{x}_i$ pertence [^337].
*   $k$ é o índice do cluster, variando de 1 a *K* [^337].
*   $\boldsymbol{\theta}$ representa os parâmetros do modelo [^340].
*   $\text{Ber}(x_{ij}|\mu_{jk})$ é a distribuição de Bernoulli para o *j*-ésimo bit no cluster *k* [^340].
*   $\mu_{jk}$ é a probabilidade de que o bit *j* esteja ligado (ativo) no cluster *k* [^340].

#### Variáveis Latentes e Poder do Modelo
A introdução de **variáveis latentes** ($z_i$) aumenta o poder do modelo, permitindo que ele capture estruturas mais complexas nos dados [^337, 340]. Em vez de modelar diretamente a distribuição dos vetores de bits, o modelo assume que eles são gerados a partir de um conjunto de *K* distribuições de Bernoulli, cada uma representando um cluster diferente [^337, 340]. A variável latente $z_i$ indica qual cluster gerou o vetor $\mathbf{x}_i$ [^337].

#### Média e Covariância da Mistura
A **média** e a **covariância** da distribuição da mistura são dadas por [^340]:

$$ E[\mathbf{x}] = \sum_{k=1}^{K} \pi_k \boldsymbol{\mu}_k $$

$$ \text{COV}[\mathbf{x}] = \sum_{k=1}^{K} \pi_k (\boldsymbol{\Sigma}_k + \boldsymbol{\mu}_k \boldsymbol{\mu}_k^T) - E[\mathbf{x}]E[\mathbf{x}]^T $$

onde:

*   $\pi_k$ é o peso da mistura para o cluster *k*, representando a probabilidade a priori de um ponto pertencer ao cluster *k* [^337].
*   $\boldsymbol{\mu}_k$ é o vetor de médias para o cluster *k*, com elementos $\mu_{jk}$ [^340].
*   $\boldsymbol{\Sigma}_k$ é a matriz de covariância para o cluster *k*, que no caso de um produto de Bernoullis, é uma matriz diagonal dada por $\boldsymbol{\Sigma}_k = \text{diag}(\mu_{jk}(1 - \mu_{jk}))$ [^340].

#### Captura de Correlações
Ao contrário de um único modelo de produto de Bernoullis, um **mixture model** pode capturar correlações entre variáveis, mesmo que as distribuições dos componentes sejam fatoradas [^340]. Isso ocorre porque a mistura permite que diferentes clusters capturem diferentes padrões de dependência entre as variáveis [^340]. Em outras palavras, cada cluster pode ter diferentes $\mu_{jk}$, permitindo modelar diferentes padrões de ativação de bits que, combinados, representam dependências complexas [^340].

### Conclusão
O uso de **mixture models** com produtos de Bernoullis oferece uma abordagem flexível e poderosa para modelar dados binários D-dimensionais [^340]. A introdução de **variáveis latentes** permite capturar correlações complexas entre variáveis, tornando esses modelos adequados para uma ampla gama de aplicações [^337, 340]. A capacidade de capturar correlações, mesmo com distribuições de componentes fatoradas, é uma vantagem significativa em relação aos modelos de produto de Bernoulli únicos [^340].

### Referências
[^337]: Seção 11.1, "Latent variable models".
[^338]: Figura 11.1, "A DGM with and without hidden variables".
[^340]: Seção 11.2.2, "Mixture of multinoullis".

<!-- END -->