## Ajuste de Modelos com Dados Faltantes: Uma Abordagem EM para MVN

### Introdução
Este capítulo aprofunda o tópico do ajuste de modelos estatísticos na presença de dados faltantes, com um foco especial na aplicação do algoritmo Expectation-Maximization (EM) para estimar os parâmetros de uma Multivariate Normal (MVN) [^1]. Em continuidade ao Capítulo 10, que introduziu modelos gráficos e suas aplicações na definição de distribuições de probabilidade conjuntas de alta dimensão [^1], exploraremos como lidar com a incompletude de dados, um problema comum em diversas áreas da ciência e engenharia. A ausência de dados completos complica a estimativa de máxima verossimilhança, e o algoritmo EM se apresenta como uma ferramenta iterativa poderosa para encontrar soluções ótimas locais [^1].

### Conceitos Fundamentais
**Dados Faltantes e Máxima Verossimilhança**

O ajuste de modelos com dados faltantes envolve a maximização da função de verossimilhança em relação aos dados observados, levando em consideração os componentes faltantes ou ocultos [^1]. Formalmente, se temos uma matriz de dados com "buracos", ou seja, valores faltantes, o objetivo é encontrar o vetor de parâmetros $\theta$ que maximiza a verossimilhança dos dados observados $X_v$, dado o padrão de observação $O$ [^1]:

$$ \theta = \underset{\theta}{\operatorname{argmax}} \\ p(X_v|\theta, O)\ $$

Sob a **Missing At Random (MAR)** assumption, a probabilidade dos dados observados pode ser expressa como o produto das probabilidades de cada observação individual $x_{iv}$ [^1]:

$$ p(X_v|\theta, O) = \prod_{i=1}^{N} p(x_{iv}|\theta)\ $$

**Algoritmo EM**

O algoritmo EM é uma técnica iterativa para encontrar estimativas de máxima verossimilhança em modelos com variáveis latentes ou dados faltantes [^1]. Ele alterna entre dois passos principais:

1.  **E-step (Expectation Step):** Calcula as estatísticas suficientes esperadas, dadas as estimativas atuais dos parâmetros. No contexto de uma MVN com dados faltantes, isso envolve estimar a média e a covariância dos dados faltantes, condicionados aos dados observados e aos parâmetros atuais [^1].
2.  **M-step (Maximization Step):** Utiliza as estatísticas suficientes esperadas calculadas no E-step para atualizar as estimativas dos parâmetros. Este passo envolve inserir as estatísticas esperadas nas equações usuais de MLE para atualizar as estimativas dos parâmetros [^1].

**Detalhes do E-Step**

No E-step, para cada caso $i$ com componentes observados $v$ e componentes faltantes $h$, calculamos a distribuição condicional dos dados faltantes $x_{ih}$ dados os dados observados $x_{iv}$ e os parâmetros atuais $\theta^{(t-1)}$ [^1]:

$$ x_{ih} | x_{iv}, \theta \sim \mathcal{N}(m_i, V_i)\ $$

onde $m_i$ e $V_i$ são a média condicional e a covariância condicional, respectivamente [^1]. Estas são calculadas usando as seguintes equações [^1]:

$$ m_i = \mu_h + \Sigma_{hv} \Sigma_{vv}^{-1} (x_{iv} - \mu_v)\ $$

$$ V_i = \Sigma_{hh} - \Sigma_{hv} \Sigma_{vv}^{-1} \Sigma_{vh}\ $$

As estatísticas suficientes esperadas são então calculadas como [^1]:

$$ \mathbb{E}[x_i] = (\mathbb{E}[x_{ih}]; x_{iv}) = (m_i; x_{iv})\ $$

$$ \mathbb{E}[x_i x_i^T] = \begin{pmatrix} \mathbb{E}[x_{ih}x_{ih}^T] & \mathbb{E}[x_{ih}] x_{iv}^T \\\\ x_{iv} \mathbb{E}[x_{ih}]^T & x_{iv} x_{iv}^T \end{pmatrix} = \begin{pmatrix} \mathbb{E}[x_{ih}] \mathbb{E}[x_{ih}]^T + V_i & m_i x_{iv}^T \\\\ x_{iv} m_i^T & x_{iv} x_{iv}^T \end{pmatrix}\ $$

**Detalhes do M-Step**

No M-step, as estimativas dos parâmetros $\mu$ e $\Sigma$ são atualizadas usando as estatísticas suficientes esperadas [^1]:

$$ \mu^{(t)} = \frac{1}{N} \sum_i \mathbb{E}[x_i]\ $$

$$ \Sigma^{(t)} = \frac{1}{N} \sum_i \mathbb{E}[x_i x_i^T] - \mu^{(t)} (\mu^{(t)})^T\ $$

Este processo iterativo continua até que a convergência seja alcançada, tipicamente definida por uma mudança suficientemente pequena na função de verossimilhança ou nas estimativas dos parâmetros [^1].

### Conclusão
O algoritmo EM oferece uma abordagem sistemática para lidar com dados faltantes no contexto do ajuste de uma MVN [^1]. Embora garanta convergência para um ótimo local, a escolha de uma inicialização adequada é crucial para evitar soluções subótimas [^1, 11.3.2]. Além disso, a aplicação da MAR assumption é fundamental para a validade do método [^1]. Em cenários onde a MAR assumption não se sustenta, técnicas mais avançadas como modelagem conjunta ou imputação múltipla podem ser necessárias. O próximo capítulo pode abordar modelos mais complexos e suas aplicações.

### Referências
[^1]: Texto fornecido.

<!-- END -->