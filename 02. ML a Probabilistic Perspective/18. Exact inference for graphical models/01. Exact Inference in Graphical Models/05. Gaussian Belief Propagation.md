## Gaussian Belief Propagation

### Introdução
O capítulo anterior explorou o algoritmo de *Belief Propagation* (BP) para árvores e sua generalização para grafos arbitrários por meio do algoritmo da *Junction Tree*. Expandindo sobre esses fundamentos, este capítulo se aprofunda no caso específico onde a distribuição conjunta é Gaussiana, apresentando o *Gaussian Belief Propagation* (Gaussian BP) [^710]. O Gaussian BP é uma especialização do BP que se aplica quando a distribuição de probabilidade condicional $p(x|v)$ é conjuntamente Gaussiana. Exploraremos como essa abordagem representa o modelo como um *Markov Random Field* (MRF) par a par Gaussiano e como as propriedades das distribuições Gaussianas simplificam os cálculos de inferência.

### Conceitos Fundamentais
O *Gaussian Belief Propagation* (Gaussian BP) é uma especialização do algoritmo de *Belief Propagation* (BP) que se aplica a modelos onde a distribuição conjunta é Gaussiana [^710]. Especificamente, o Gaussian BP é aplicável quando $p(x|v)$ é conjuntamente Gaussiana, onde $x$ representa as variáveis ocultas e $v$ as variáveis visíveis. Nesse contexto, o modelo é representado como um *Markov Random Field* (MRF) par a par Gaussiano, com potenciais de nós e arestas definidos usando funções exponenciais envolvendo matrizes de precisão e vetores de bias [^710].

**Representação do Modelo:**
1. **MRF Par a Par Gaussiano:** O modelo é expresso como um MRF onde as interações são definidas entre pares de variáveis.
2. **Potenciais de Nós e Arestas:** Os potenciais são definidos da seguinte forma [^710]:
   - *Potenciais de Nós*: $\psi_t(x_t) = \exp(-\frac{1}{2}A_{tt}x_t^2 + b_t x_t)$ [^710]
   - *Potenciais de Arestas*: $\psi_{st}(x_s, x_t) = \exp(-\frac{1}{2}x_s A_{st} x_t)$ [^710]
   Onde $A$ é a matriz de precisão e $b$ é o vetor de bias.

Com essa definição, o modelo geral assume a forma [^710]:
$$
p(x|v) \propto \exp(-\frac{1}{2}x^T A x + b^T x)
$$

**Mensagens e Marginais Gaussianas:**
No Gaussian BP, tanto as mensagens quanto as marginais são Gaussianas [^711]. Os cálculos envolvem multiplicar fatores Gaussianos e marginalizar variáveis de fatores Gaussianos conjuntos, utilizando propriedades bem conhecidas das distribuições Gaussianas [^711].

**Cálculos Chave:**
1. **Multiplicação de Gaussianas:** O produto de duas Gaussianas é uma Gaussiana [^711]:
   $$
   N(x|\mu_1, \Lambda_1^{-1}) \times N(x|\mu_2, \Lambda_2^{-1}) = CN(x|\mu, \Lambda^{-1})
   $$
   Onde:
   - $\Lambda = \Lambda_1 + \Lambda_2$ [^711]
   - $\mu = \Lambda^{-1}(\mu_1 \Lambda_1 + \mu_2 \Lambda_2)$ [^711]
   - $C$ é uma constante de normalização [^711].

2. **Marginalização de Gaussianas:** A marginalização de uma variável de uma Gaussiana conjunta também resulta em uma Gaussiana [^711]:
   $$
   \int \exp(-ax^2 + bx) dx = \sqrt{\pi/a} \exp(b^2/4a)
   $$

**Atualização das Crenças (Beliefs):**
As crenças nos nós são atualizadas multiplicando as mensagens recebidas de todos os vizinhos e a evidência local [^711]. A crença no nó $s$ é dada por [^711]:

$$
bel_s(x_s) = \psi_s(x_s) \prod_{t \in nbr(s)} m_{t \rightarrow s}(x_s) = N(x_s|\mu_s, \Lambda_s^{-1})
$$

Onde:
- $\Lambda_s = A_{ss} + \sum_{t \in nbr(s)} \Lambda_{ts}$ [^711]
- $\mu_s = \Lambda_s^{-1} (A_{ss} m_s + \sum_{t \in nbr(s)} \Lambda_{ts} \mu_{ts})$ [^711]

**Cálculo das Mensagens:**
As mensagens são calculadas marginalizando a variável do nó remetente, levando em consideração o potencial da aresta e a crença local [^712]:

$$
m_{s \rightarrow t}(x_t) = \int \psi_{st}(x_s, x_t) \psi_s(x_s) \prod_{u \in nbr(s) \setminus t} m_{u \rightarrow s}(x_s) dx_s
$$

Este cálculo resulta em uma Gaussiana [^712]:
$$
m_{s \rightarrow t}(x_t) = N(x_t | \mu_{st}, \Lambda_{st}^{-1})
$$

Onde os parâmetros são [^712]:
- $\Lambda_{st} = A_{st} \Lambda_{s \setminus t} / A_{st}$ [^712]
- $\mu_{st} = \Lambda_{st}^{-1} A_{st} \mu_{s \setminus t} / \Lambda_{st}$ [^712]

### Conclusão
O Gaussian BP oferece uma abordagem eficiente para realizar inferência exata em modelos Gaussianos quando o grafo é uma árvore. Ele explora a estrutura Gaussiana para simplificar os cálculos, mantendo a precisão. Embora o Gaussian BP seja exato apenas em árvores, ele pode ser aplicado de forma aproximada em grafos com ciclos, levando a algoritmos como o *loopy belief propagation*. Como mencionado anteriormente [^711], quando o grafo é loopy, as médias posteriores podem ainda ser exatas, mas as variâncias posteriores são frequentemente muito pequenas. O Gaussian BP fornece uma base sólida para entender e aplicar técnicas mais avançadas em modelos Gaussianos complexos.

### Referências
[^710]: Chapter 20, Exact inference for graphical models, page 710
[^711]: Chapter 20, Exact inference for graphical models, page 711
[^712]: Chapter 20, Exact inference for graphical models, page 712
<!-- END -->