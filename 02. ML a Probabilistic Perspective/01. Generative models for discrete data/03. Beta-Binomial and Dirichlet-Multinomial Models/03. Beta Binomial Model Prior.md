## Seleção e Propriedades da Priori Beta no Modelo Beta-Binomial

### Introdução

No contexto dos **modelos generativos para dados discretos** [^20], o modelo Beta-Binomial surge como uma ferramenta fundamental para a inferência sobre uma probabilidade desconhecida $\theta$, associada a processos que geram resultados binários [^21]. Como estabelecido na Seção 3.3.1, a verossimilhança (likelihood) para $N$ ensaios de Bernoulli independentes e identicamente distribuídos (iid) com parâmetro $\theta \in [0, 1]$ é dada por $p(D|\theta) = \theta^{N_1} (1 - \theta)^{N_0}$ [^8], onde $N_1$ e $N_0$ são as **estatísticas suficientes** [^10] que representam o número de sucessos ("heads") e fracassos ("tails"), respectivamente. De forma equivalente, para um número fixo de $N$ ensaios, a contagem de sucessos $N_1$ segue uma distribuição Binomial, $N_1 \sim Bin(N, \theta)$, cuja função de massa de probabilidade (pmf) é proporcional a $\theta^{N_1} (1 - \theta)^{N-N_1}$ [^9]. A inferência Bayesiana sobre o parâmetro $\theta$ requer a especificação de uma distribuição a priori, $p(\theta)$, que encapsule nosso conhecimento prévio sobre $\theta$ antes de observar os dados $D$ [^16]. Este capítulo foca na seleção e nas propriedades de uma priori adequada para $\theta$ no modelo Beta-Binomial, com ênfase na distribuição Beta e suas vantagens computacionais e interpretativas.

### Conceitos Fundamentais

#### Requisitos e Conveniência da Priori

A primeira exigência fundamental para a distribuição a priori de $\theta$ é que ela deve ter suporte sobre o intervalo $[0, 1]$, visto que $\theta$ representa uma probabilidade [^1]. Embora qualquer distribuição contínua definida neste intervalo pudesse, em princípio, ser utilizada, a complexidade matemática da inferência Bayesiana, que envolve a computação da distribuição a posteriori $p(\theta|D) \propto p(D|\theta)p(\theta)$ [^17], pode ser significativamente reduzida através de uma escolha criteriosa da priori. Seria conveniente, para facilitar os cálculos, que a priori tivesse a mesma forma funcional da verossimilhança [^1].

Consideremos uma forma geral para a priori que espelhe a estrutura da verossimilhança Bernoulli/Binomial:
$$ p(\theta) \propto \theta^{\gamma_1} (1 - \theta)^{\gamma_2} $$ [^2]
onde $\gamma_1$ e $\gamma_2$ são parâmetros que definem a forma da priori. Se adotarmos essa forma, o cálculo da posteriori torna-se uma simples adição nos expoentes:
$$ p(\theta|D) \propto p(D|\theta)p(\theta) \propto \left( \theta^{N_1} (1 - \theta)^{N_0} \right) \left( \theta^{\gamma_1} (1 - \theta)^{\gamma_2} \right) = \theta^{N_1+\gamma_1} (1 - \theta)^{N_0+\gamma_2} $$ [^3]
Esta propriedade, onde a distribuição a posteriori pertence à mesma família de distribuições da priori, é a definição de uma **priori conjugada** [^4].

#### A Priori Conjugada Beta e seus Hiperparâmetros

**Definição:** Uma priori é dita **conjugada** para uma dada verossimilhança se a distribuição a posteriori resultante pertencer à mesma família paramétrica da distribuição a priori [^4].

As **prioris conjugadas** são amplamente utilizadas na inferência Bayesiana porque simplificam significativamente a computação e facilitam a interpretação dos resultados [^4]. No caso da verossimilhança Bernoulli e Binomial, a priori conjugada natural é a **distribuição Beta** [^5], que já encontramos na Seção 2.4.5. A densidade de probabilidade da distribuição Beta é definida como:
$$ Beta(\theta|a, b) \propto \theta^{a-1}(1 - \theta)^{b-1} $$ [^5]
para $\theta \in [0, 1]$ e parâmetros $a > 0, b > 0$. Comparando com a forma geral $p(\theta) \propto \theta^{\gamma_1} (1 - \theta)^{\gamma_2}$, vemos que a distribuição Beta corresponde a $\gamma_1 = a-1$ e $\gamma_2 = b-1$.

Os parâmetros $a$ e $b$ da distribuição Beta a priori são denominados **hiperparâmetros** [^6]. Eles não são parâmetros do modelo original (que é $\theta$), mas sim parâmetros da distribuição a priori de $\theta$. A escolha de $a$ e $b$ permite codificar crenças prévias sobre o parâmetro $\theta$ [^6].

#### Interpretação e Especificação da Priori Beta

A conjugação da priori Beta com a verossimilhança Bernoulli/Binomial leva a uma posteriori que também é uma distribuição Beta:
$$ p(\theta|D) \propto Beta(\theta|N_1 + a, N_0 + b) $$ [^11]
Esta forma revela uma interpretação intuitiva e poderosa dos hiperparâmetros $a$ e $b$. Eles atuam como **pseudo contagens** (pseudo counts) [^12]: $a$ pode ser visto como o número de sucessos prévios (antes de ver os dados $D$) e $b$ como o número de fracassos prévios. A posteriori combina as contagens observadas ($N_1, N_0$) com as pseudo contagens da priori ($a, b$).

A força da priori, ou seu peso relativo em comparação com os dados, é medida pela **effective sample size** (tamanho efetivo da amostra) da priori, que é a soma das pseudo contagens, $a + b$ [^12]. Quanto maior $a+b$, mais informativa é a priori e mais dados são necessários para que a verossimilhança domine a posteriori [^12]. Como visto na Figura 3.6(a), uma priori fraca (Beta(2,2), $a+b=4$) é rapidamente "sobrepujada" pelos dados (likelihood), enquanto uma priori forte (Beta(5,2), $a+b=7$) exerce maior influência sobre a posteriori, resultando em um "compromisso" entre a priori e a verossimilhança (Figura 3.6(b)) [^12].

A especificação dos hiperparâmetros $a$ e $b$ depende do conhecimento prévio disponível. Por exemplo:
1.  Para codificar a crença de que $\theta$ tem média $0.7$ e desvio padrão $0.2$, podemos definir $a = 2.975$ e $b = 1.275$ (conforme detalhado no Exercício 3.15) [^6].
2.  Para codificar a crença de que $\theta$ tem média $0.15$ e que provavelmente ($\approx 95\\%$) está no intervalo $(0.05, 0.30)$, podemos encontrar $a = 4.5$ e $b = 25.5$ (conforme detalhado no Exercício 3.16) [^6].
A relação entre os hiperparâmetros e a média da priori é dada por $E[\theta] = m_1 = a / (a+b)$ [^14].

#### Priori Não Informativa

Em situações onde se sabe muito pouco sobre $\theta$ a priori, exceto que ele reside no intervalo $[0, 1]$, pode-se optar por uma **priori não informativa** [^7]. Uma escolha comum é a **priori uniforme** sobre $[0, 1]$ [^7]. É importante notar que a distribuição uniforme é um caso especial da distribuição Beta, obtido quando $a = b = 1$ [^7].
$$ Beta(\theta|1, 1) \propto \theta^{1-1}(1 - \theta)^{1-1} = \theta^0 (1 - \theta)^0 = 1 $$
Utilizar uma priori uniforme $Beta(1, 1)$ implica que a posteriori é $Beta(\theta|N_1+1, N_0+1)$. Isso se conecta à regra de sucessão de Laplace e à suavização "add-one" discutida na Seção 3.3.4.1 [^13]. Quando a priori é uniforme, a estimativa MAP (Maximum A Posteriori) converge para a estimativa de máxima verossimilhança (MLE), $\hat{\theta}_{MLE} = N_1/N$ [^13].

> **Caixa de Destaque:** A escolha da distribuição Beta $Beta(\theta|a, b)$ como priori para o parâmetro $\theta$ de uma verossimilhança Bernoulli ou Binomial é motivada por sua **conjugação**. Isso simplifica a inferência Bayesiana, resultando em uma posteriori $Beta(\theta|N_1+a, N_0+b)$, e permite uma interpretação intuitiva dos **hiperparâmetros** $a$ e $b$ como **pseudo contagens**, com $a+b$ representando o **tamanho efetivo da amostra** da priori [^4, ^5, ^6, ^11, ^12].

### Conclusão

A seleção da distribuição a priori é um passo crucial na modelagem Beta-Binomial Bayesiana. Demonstramos que a **distribuição Beta** é a escolha natural e computacionalmente conveniente devido à sua propriedade de **conjugação** com a verossimilhança Bernoulli/Binomial [^4, ^5]. Seus **hiperparâmetros**, $a$ e $b$, não apenas definem a forma da distribuição sobre o intervalo $[0, 1]$, mas também admitem uma interpretação direta como **pseudo contagens**, quantificando o conhecimento prévio em termos de um **tamanho efetivo de amostra** [^6, ^12]. A flexibilidade da distribuição Beta permite codificar uma vasta gama de crenças prévias, desde prioris **não informativas** (como a uniforme, $a=b=1$) até prioris fortemente informativas baseadas em conhecimento específico [^7, ^6]. Essa escolha facilita a atualização das crenças via regra de Bayes, levando a uma distribuição a posteriori Beta que integra de forma coerente a informação da priori com a evidência dos dados observados [^11], como explorado nas seções subsequentes sobre a posteriori e a distribuição preditiva posterior.

### Referências

[^1]: Page 10: We need a prior which has support over the interval [0,1]. To make the math easier, it would convenient if the prior had the same form as the likelihood
[^2]: Page 10: i.e., if the prior looked like $p(\theta) \propto \theta^{\gamma_1} (1 - \theta)^{\gamma_2}$
[^3]: Page 10: If this were the case, then we could easily evaluate the posterior by simply adding up the exponents: $p(\theta) \propto p(D|\theta)p(\theta) = \theta^{N_1} (1 - \theta)^{N_0} \theta^{\gamma_1} (1 - \theta)^{\gamma_2} = \theta^{N_1+\gamma_1} (1 - \theta)^{N_0+\gamma_2}$
[^4]: Page 10: When the prior and the posterior have the same form, we say that the prior is a **conjugate prior** for the corresponding likelihood. Conjugate priors are widely used because they simplify computation, and are easy to interpret, as we see below.
[^5]: Page 10: In the case of the Bernoulli, the conjugate prior is the beta distribution, which we encountered in Section 2.4.5: $Beta(\theta|a, b) \propto \theta^{a-1}(1 - \theta)^{b-1}$
[^6]: Page 10: The parameters of the prior are called **hyper-parameters**. We can set them in order to encode our prior beliefs. For example, to encode our beliefs that $\theta$ has mean 0.7 and standard deviation 0.2, we set $a = 2.975$ and $b = 1.275$ (Exercise 3.15). Or to encode our beliefs that $\theta$ has mean 0.15 and that we think it lives in the interval (0.05, 0.30) with probability, then we find $a = 4.5$ and $b = 25.5$ (Exercise 3.16).
[^7]: Page 10: If we know “nothing” about $\theta$, except that it lies in the interval [0, 1], we can use a uniform prior, which is a kind of uninformative prior (see Section 5.4.2 for details). The uniform distribution can be represented by a beta distribution with $a = b = 1$.
[^8]: Page 9: If the data are iid, the likelihood has the form $p(D|\theta) = \theta^{N_1} (1 - \theta)^{N_0}$
[^9]: Page 10: In this case, we have $N_1 \sim Bin(N, \theta)$, where Bin represents the binomial distribution, which has the following pmf: $Bin(k|n, \theta) \propto \theta^k (1-\theta)^{n-k}$ (proportionality derived from Eq 3.12 noting N choose k is constant wrt theta)
[^10]: Page 10: where we have $N_1 = \sum_{i=1}^N I(x_i = 1)$ heads and $N_0 = \sum_{i=1}^N I(x_i = 0)$ tails. These two counts are called the **sufficient statistics** of the data...
[^11]: Page 11: If we multiply the likelihood by the beta prior we get the following posterior (following Equation 3.14): $p(\theta|D) \propto Bin(N_1|\theta, N_0 + N_1)Beta(\theta|a, b) \propto Beta(\theta|N_1 + a, N_0 + b)$
[^12]: Page 11: In particular, the posterior is obtained by adding the prior hyper-parameters to the empirical counts. For this reason, the hyper-parameters are known as **pseudo counts**. The strength of the prior, also known as the **effective sample size** of the prior, is the sum of the pseudo counts, $a + b$; this plays a role analogous to the data set size, $N_1 + N_0 = N$. Figure 3.6(a) gives an example where we update a weak Beta(2,2) prior... Figure 3.6(b) gives an example where we update a strong Beta(5,2) prior... now we see that the posterior is a “compromise” between the prior and likelihood.
[^13]: Page 12: If we use a uniform prior, then the MAP estimate reduces to the MLE, which is just the empirical fraction of heads: $\hat{\theta}_{MLE} = N_1/N$.
[^14]: Page 12: Let $\alpha_0 = a + b$ be the equivalent sample size of the prior, which controls its strength, and let the prior mean be $m_1 = a/\alpha_0$. Then the posterior mean is given by $E[\theta|D] = \frac{\alpha_0 m_1 + N_1}{N + \alpha_0} = \dots = \lambda m_1 + (1-\lambda)\hat{\theta}_{MLE}$ where $\lambda = \alpha_0 / (N+\alpha_0)$.
[^15]: Page 12: The variance of the Beta posterior is given by $var[\theta|D] = \frac{(a + N_1)(b + N_0)}{(a + N_1 + b + N_0)^2(a + N_1 + b + N_0 + 1)}$
[^16]: Page 3: We will now provide a Bayesian explanation for this. (Introduces Likelihood, Prior, Posterior sections for concept learning)
[^17]: Page 4: The posterior is simply the likelihood times the prior, normalized. In this context we have $p(h|D) = \frac{p(D|h)p(h)}{\sum_{h\'} p(D, h\')}$
[^18]: Page 5: Note that the MAP estimate can be written as $\hat{h}_{MAP} = \text{argmax}_h p(D|h)p(h) = \text{argmax}_h [\log p(D|h) + \log p(h)]$\n[^19]: Page 3: We can capture such intution by assigning low prior probability to unnatural concepts. ... This subjective aspect of Bayesian reasoning...\n[^20]: Page 1: Chapter 3 Generative models for discrete data. 3.1 Introduction ... we focus on the case where the observed data are discrete symbols. We also discuss how to infer the unknown parameters $\theta$ of such models.\n[^21]: Page 8: 3.3 The beta-binomial model ... in many applications, the unknown parameters are continuous, so the hypothesis space is (some subset) of $\mathbb{R}^K$...\n
<!-- END -->