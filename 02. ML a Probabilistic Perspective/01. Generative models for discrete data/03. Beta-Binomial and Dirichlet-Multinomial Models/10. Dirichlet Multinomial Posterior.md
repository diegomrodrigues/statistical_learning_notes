## Inferência Posterior e Estimação MAP no Modelo Dirichlet-Multinomial

### Introdução

Em continuidade à nossa análise de modelos generativos para dados discretos, e expandindo o **modelo beta-binomial** apresentado anteriormente [^14] (Seção 3.3) para o caso de mais de duas categorias, abordamos agora o **modelo Dirichlet-Multinomial**. Este modelo é fundamental para analisar dados onde cada observação pertence a uma de $K$ classes distintas, como na modelagem de dados textuais ou bio sequências [^14]. Como vimos na Seção 3.3, a inferência Bayesiana para parâmetros contínuos, como as probabilidades $\theta_k$ de cada classe, requer a substituição de somas por integrais, mas as ideias básicas de especificação de verossimilhança e prior, e derivação da posterior e preditiva posterior, permanecem as mesmas [^9]. Este capítulo foca especificamente na derivação da distribuição posterior dos parâmetros $\theta = (\theta_1, ..., \theta_K)$ e na obtenção da estimativa **Maximum a Posteriori (MAP)**. Exploraremos como a conjugalidade entre a distribuição de Dirichlet e a verossimilhança Multinomial simplifica a inferência posterior e como a estimativa MAP pode ser derivada analiticamente utilizando a técnica dos multiplicadores de Lagrange para incorporar a restrição de que as probabilidades devem somar um.

### Conceitos Fundamentais

#### O Modelo Dirichlet-Multinomial: Verossimilhança e Prior

Consideremos um conjunto de dados $D = \{x_1, ..., x_N\}$, onde cada observação $x_i$ é uma variável categórica que pode assumir um dos $K$ valores possíveis, $x_i \in \{1, ..., K\}$ [^15]. Assumindo que os dados são i.i.d. (independentes e identicamente distribuídos) segundo uma distribuição Categórica (ou Multinomial para uma única extração) com vetor de parâmetros $\theta = (\theta_1, ..., \theta_K)$, onde $\theta_k$ é a probabilidade do evento $k$ e $\sum_{k=1}^K \theta_k = 1$, a **verossimilhança** dos dados observados é dada por:

$$np(D|\theta) = \prod_{i=1}^N p(x_i|\theta) \propto \prod_{k=1}^K \theta_k^{N_k} \quad (3.36) [^15]$$

Aqui, $N_k = \sum_{i=1}^N \mathbb{I}(x_i = k)$ é o número de vezes que o evento $k$ ocorreu no conjunto de dados $D$ [^15]. As contagens $N_k$ são as **estatísticas suficientes** para este modelo, análogo aos $N_1$ e $N_0$ no caso Bernoulli/Binomial [^10]. A verossimilhança para o modelo Multinomial, que considera a contagem de eventos em $N$ tentativas, tem a mesma forma funcional em relação a $\theta$, a menos de um fator constante [^15].

Para realizar a inferência Bayesiana sobre $\theta$, necessitamos de uma distribuição **prior** $p(\theta)$ que tenha suporte sobre o simplex de probabilidade $S_K = \{\theta \in \mathbb{R}^K | \theta_k \ge 0, \sum_{k=1}^K \theta_k = 1\}$. Idealmente, a prior deve ser **conjugada** à verossimilhança Multinomial para simplificar os cálculos da posterior [^15]. Como introduzido na Seção 2.5.4, a **distribuição de Dirichlet** satisfaz esses critérios [^15]. Utilizaremos, portanto, a seguinte prior de Dirichlet para $\theta$:

$$nDir(\theta|\alpha) = \frac{1}{B(\alpha)} \prod_{k=1}^K \theta_k^{\alpha_k - 1} \mathbb{I}(\theta \in S_K) \quad (3.37) [^15]$$

onde $\alpha = (\alpha_1, ..., \alpha_K)$ são os **hiperparâmetros** da prior (com $\alpha_k > 0$) e $B(\alpha) = \frac{\prod_{k=1}^K \Gamma(\alpha_k)}{\Gamma(\sum_{k=1}^K \alpha_k)}$ é a função Beta multinomial [^15]. Os hiperparâmetros $\alpha_k$ podem ser interpretados como **pseudo-contagens** (pseudo counts) que refletem nosso conhecimento prévio sobre as categorias [^11, ^16].

#### Derivação da Distribuição Posterior

A **distribuição posterior** $p(\theta|D)$ é obtida aplicando a regra de Bayes, multiplicando a verossimilhança pela prior:

$$np(\theta|D) \propto p(D|\theta) p(\theta) \quad (3.38) [^15]$$

Substituindo as expressões da verossimilhança (Eq. 3.36) e da prior de Dirichlet (Eq. 3.37):

$$np(\theta|D) \propto \left( \prod_{k=1}^K \theta_k^{N_k} \right) \left( \frac{1}{B(\alpha)} \prod_{k=1}^K \theta_k^{\alpha_k - 1} \right) \mathbb{I}(\theta \in S_K)$$

$$np(\theta|D) \propto \prod_{k=1}^K \theta_k^{N_k + \alpha_k - 1} \mathbb{I}(\theta \in S_K) \quad (3.39) [^15]$$

Reconhecemos que esta é a forma funcional de uma distribuição de Dirichlet com parâmetros atualizados. Portanto, a distribuição posterior é também uma Dirichlet:

$$np(\theta|D) = Dir(\theta | \alpha_1 + N_1, ..., \alpha_K + N_K) \quad (3.40) [^15]$$

> **Resultado Fundamental:** A distribuição posterior para os parâmetros $\theta$ no modelo Dirichlet-Multinomial é obtida simplesmente somando os hiperparâmetros da prior ($\alpha_k$) às contagens empíricas observadas ($N_k$) para cada categoria [^16].

Este resultado é uma manifestação direta da **conjugalidade** entre a prior de Dirichlet e a verossimilhança Multinomial. É análogo ao resultado obtido para o modelo Beta-Binomial, onde a posterior Beta é obtida somando os hiperparâmetros $a, b$ às contagens $N_1, N_0$ [^11] (Eq. 3.16). A soma dos hiperparâmetros da prior, $\alpha_0 = \sum_{k=1}^K \alpha_k$, pode ser vista como o **tamanho efetivo da amostra** (effective sample size) da prior [^11, ^16], controlando a força da prior em relação aos dados. Esta propriedade também facilita a **aprendizagem online** (online learning), onde a posterior após um lote de dados pode ser usada como prior para o próximo lote, de forma sequencial [^11] (Eq. 3.18-3.20).

#### Estimação Maximum a Posteriori (MAP)

Embora a distribuição posterior completa $p(\theta|D)$ represente nossa incerteza sobre $\theta$, muitas vezes desejamos uma estimativa pontual. A estimativa **Maximum a Posteriori (MAP)** corresponde ao modo da distribuição posterior, ou seja, o valor de $\theta$ que maximiza $p(\theta|D)$. Para encontrar o modo da distribuição de Dirichlet posterior $Dir(\theta|\alpha')$, onde $\alpha'_k = \alpha_k + N_k$, precisamos maximizar $\prod_{k=1}^K \theta_k^{\alpha'_k - 1}$ sujeito à restrição $\sum_{k=1}^K \theta_k = 1$. Como o logaritmo é uma função monotônica, podemos equivalentemente maximizar o logaritmo da posterior:

$$log p(\theta|D) = \sum_{k=1}^K (\alpha_k + N_k - 1) \log \theta_k + \text{constante}$$

Devemos impor a restrição $\sum_{k=1}^K \theta_k = 1$. Isso pode ser feito usando um **multiplicador de Lagrange** $\lambda$ [^16]. A função Lagrangiana $\mathcal{L}(\theta, \lambda)$ é dada por (usando a notação $N'_k = N_k + \alpha_k - 1$ para simplificar, ligeiramente diferente da Eq. 3.41 que inclui o log da verossimilhança e log da prior separadamente mas leva ao mesmo resultado):

$$mathcal{L}(\theta, \lambda) = \sum_{k=1}^K (N_k + \alpha_k - 1) \log \theta_k + \lambda \left( 1 - \sum_{k=1}^K \theta_k \right)$$

Para encontrar o máximo, tomamos as derivadas parciais em relação a cada $\theta_k$ e a $\lambda$ e as igualamos a zero. A derivada em relação a $\lambda$ simplesmente recupera a restrição:

$$frac{\partial \mathcal{L}}{\partial \lambda} = 1 - \sum_{k=1}^K \theta_k = 0 \quad (\text{análogo a Eq. } 3.42) [^16]$$

A derivada em relação a $\theta_k$ é:

$$frac{\partial \mathcal{L}}{\partial \theta_k} = \frac{N_k + \alpha_k - 1}{\theta_k} - \lambda = 0 \quad (\text{análogo a Eq. } 3.43) [^16]$$

Isso implica que:

$$N_k + \alpha_k - 1 = \lambda \theta_k \quad (\text{análogo a Eq. } 3.44) [^16]$$

Somando ambos os lados sobre $k = 1, ..., K$:

$$sum_{k=1}^K (N_k + \alpha_k - 1) = \sum_{k=1}^K \lambda \theta_k = \lambda \sum_{k=1}^K \theta_k$$

Usando a restrição $\sum_{k=1}^K \theta_k = 1$:

$$sum_{k=1}^K N_k + \sum_{k=1}^K \alpha_k - \sum_{k=1}^K 1 = \lambda$$

$$N + \alpha_0 - K = \lambda \quad (\text{análogo a Eq. } 3.46) [^16]$$

onde $N = \sum N_k$ é o número total de observações e $\alpha_0 = \sum \alpha_k$ é o tamanho efetivo da amostra da prior [^16]. Substituindo $\lambda$ de volta na equação para $\theta_k$:

$$hat{\theta}_{k, MAP} = \frac{N_k + \alpha_k - 1}{\lambda} = \frac{N_k + \alpha_k - 1}{N + \alpha_0 - K} \quad (3.47) [^16]$$

Esta é a estimativa MAP para os parâmetros do modelo Multinomial com uma prior de Dirichlet.

> **Nota:** A derivação assume que $N_k + \alpha_k \ge 1$ para todos $k$. A restrição $\theta_k \ge 0$ não precisa ser explicitamente imposta com um multiplicador de Lagrange adicional, pois a forma do gradiente $(\frac{N_k + \alpha_k - 1}{\theta_k} - \lambda)$ garante que valores negativos de $\theta_k$ não maximizariam o objetivo (e o logaritmo não estaria definido). Se $N_k + \alpha_k - 1 < 0$ (o que só pode ocorrer se $N_k=0$ e $0 < \alpha_k < 1$), a função objetivo tenderia a $-\infty$ quando $\theta_k \to 0$, mas a solução ótima pode ainda resultar em $\hat{\theta}_{k, MAP}=0$ se $N_k=0$ e $\alpha_k=1$ [^16] (ver nota de rodapé 2 na p. 80).

A estimativa MAP tem uma interpretação intuitiva: ela ajusta as contagens observadas $N_k$ pelas pseudo-contagens $\alpha_k$ da prior (menos 1). Se usarmos uma **prior uniforme**, que corresponde a $\alpha_k = 1$ para todo $k$ (ou seja, $Dir(\theta|1, ..., 1)$), então $\alpha_0 = K$. Neste caso, a estimativa MAP se reduz a:

$$hat{\theta}_{k, MAP} (\text{com prior uniforme}) = \frac{N_k + 1 - 1}{N + K - K} = \frac{N_k}{N} \quad (3.48) [^16]$$

Este é exatamente o estimador de **Máxima Verossimilhança (MLE)**, que corresponde à fração empírica das vezes que a categoria $k$ foi observada [^16]. A utilização de uma prior de Dirichlet com $\alpha_k > 1$ (como a prior de Laplace, $\alpha_k=1+\epsilon$, ou mais geralmente $\alpha_k > 1$) atua como uma forma de regularização ou **suavização (smoothing)**, evitando que as probabilidades estimadas sejam zero para categorias não observadas na amostra ($N_k=0$), o que é crucial para evitar problemas como o **problema de contagem zero** (zero count problem) ou o **paradoxo do cisne negro** (black swan paradox) [^13]. Isso é particularmente importante em domínios como modelagem de linguagem, onde a esparsidade dos dados é alta [^17]. A estimativa MAP difere da **média posterior** $E[\theta_k|D] = \frac{\alpha_k + N_k}{\alpha_0 + N}$ (Eq. 3.51) [^17], embora ambas convirjam para o MLE com dados suficientes [^5]. Na prática, a média posterior tende a sofrer menos de overfitting do que a estimativa MAP ou MLE em regimes de poucos dados [^22]. $\blacksquare$

### Conclusão

Este capítulo detalhou a inferência Bayesiana para o modelo Dirichlet-Multinomial. Demonstramos que, devido à conjugalidade, a distribuição posterior dos parâmetros $\theta$ é uma Dirichlet, obtida pela simples adição das pseudo-contagens da prior às contagens empíricas dos dados. Além disso, derivamos a estimativa MAP para $\theta$ utilizando multiplicadores de Lagrange para incorporar a restrição fundamental de que as probabilidades devem somar um. A estimativa MAP resultante, $\hat{\theta}_{k, MAP} = (N_k + \alpha_k - 1) / (N + \alpha_0 - K)$, fornece uma estimativa pontual útil que incorpora conhecimento prévio através dos hiperparâmetros $\alpha_k$ e atua como uma forma de suavização em comparação com a estimativa de máxima verossimilhança. Esses resultados são pilares para a aplicação de métodos Bayesianos em diversos problemas envolvendo dados categóricos discretos.

### Referências

[^1]: Página 65, Seção 3.1
[^2]: Página 66, Seção 3.2
[^3]: Página 67, Seção 3.2.1
[^4]: Página 68, Seção 3.2.3
[^5]: Página 69, Seção 3.2.3
[^6]: Página 70, Seção 3.2.3
[^7]: Página 71, Seção 3.2.4
[^8]: Página 72, Seção 3.2.5, 3.3
[^9]: Página 73, Seção 3.3
[^10]: Página 74, Seção 3.3.1, 3.3.2
[^11]: Página 75, Seção 3.3.3
[^12]: Página 76, Seção 3.3.3.1, 3.3.3.2
[^13]: Página 77, Seção 3.3.4.1
[^14]: Página 78, Seção 3.4
[^15]: Página 79, Seção 3.4.1, 3.4.2, 3.4.3
[^16]: Página 80, Seção 3.4.3
[^17]: Página 81, Seção 3.4.4, 3.4.4.1
[^18]: Página 82, Seção 3.5
[^19]: Página 83, Seção 3.5.1.1
[^20]: Página 84, Seção 3.5.1.2
[^21]: Página 85, Seção 3.5.2
[^22]: Página 86, Seção 3.5.2
[^23]: Página 87, Seção 3.5.4
[^24]: Página 88, Seção 3.5.5
[^25]: Página 89, Seção 3.5.5, Exercícios
[^26]: Página 90, Exercícios
[^27]: Página 91, Exercícios
[^28]: Página 92, Exercícios
[^29]: Página 93, Exercícios
[^30]: Página 94, Exercícios
[^31]: Página 95, Exercícios
<!-- END -->