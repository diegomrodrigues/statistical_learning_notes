## O Modelo Beta-Binomial para Inferência Bayesiana

### Introdução

Como exploramos anteriormente no contexto da aprendizagem de conceitos Bayesianos, especificamente no exemplo do *number game* [^1], [^2], abordamos a inferência sobre um espaço de hipóteses discreto, $h \in H$. Nesses cenários, o objetivo era determinar a probabilidade de diferentes regras ou conceitos discretos, dados os exemplos observados. No entanto, muitas aplicações em modelagem generativa para dados discretos envolvem a inferência sobre parâmetros desconhecidos que são **contínuos** [^8]. O espaço de hipóteses, neste caso, não é um conjunto finito de regras, mas sim um subconjunto de $R^K$, onde $K$ é o número de parâmetros [^8]. Esta transição de espaços de hipóteses discretos para contínuos requer a substituição de somas por integrais, mas as ideias fundamentais da inferência Bayesiana permanecem as mesmas [^9].

Neste capítulo, focaremos em um dos modelos fundamentais para este tipo de inferência: o **modelo beta-binomial**. Este modelo é central para o problema de inferir a probabilidade $\theta$ de uma moeda resultar em "caras" (heads), dado uma série de lançamentos observados [^9]. Embora possa parecer um exemplo trivial, o modelo beta-binomial constitui a base para muitos métodos mais avançados que serão considerados posteriormente, incluindo classificadores **naive Bayes** e **modelos de Markov** [^9]. Historicamente, este problema é de grande importância, sendo o exemplo analisado no artigo original de Bayes em 1763 e posteriormente generalizado por Pierre-Simon Laplace [^9].

Seguiremos a receita Bayesiana padrão: especificaremos a **likelihood** e o **prior**, e então derivaremos as distribuições **posterior** e **posterior preditiva** [^9].

### Conceitos Fundamentais

#### Likelihood

Consideremos um cenário onde observamos uma sequência de $N$ lançamentos de moeda independentes e identicamente distribuídos (iid), $D = \{x_1, ..., x_N\}$. Cada observação $X_i$ segue uma distribuição de Bernoulli, $X_i \sim \text{Ber}(\theta)$, onde $X_i = 1$ representa "caras" (*heads*) e $X_i = 0$ representa "coroas" (*tails*). O parâmetro $\theta \in [0, 1]$ é a taxa (probabilidade) desconhecida de "caras" [^9].

Assumindo que os dados são iid, a função de **likelihood** para o conjunto de dados $D$ é dada por:
$$ p(D|\theta) = \prod_{i=1}^{N} p(x_i|\theta) = \prod_{i=1}^{N} \theta^{x_i} (1-\theta)^{1-x_i} $$
Esta expressão pode ser simplificada contando o número total de "caras", $N_1 = \sum_{i=1}^{N} I(x_i = 1)$, e o número total de "coroas", $N_0 = \sum_{i=1}^{N} I(x_i = 0)$, onde $N = N_1 + N_0$. A likelihood torna-se então:
$$ p(D|\theta) = \theta^{N_1} (1-\theta)^{N_0} \quad (3.11) [^9] $$
As contagens $N_1$ e $N_0$ são chamadas de **estatísticas suficientes** (*sufficient statistics*) dos dados, pois contêm toda a informação em $D$ necessária para inferir $\theta$ [^10]. Formalmente, $s(D)$ é uma estatística suficiente para $D$ se $p(\theta|D) = p(\theta|s(D))$ [^10].

Alternativamente, se considerarmos que os dados consistem na contagem $N_1$ de "caras" observada em um número fixo $N$ de tentativas, temos $N_1 \sim \text{Bin}(N, \theta)$, onde $\text{Bin}$ representa a distribuição Binomial com função de massa de probabilidade (pmf):
$$ \text{Bin}(k|n, \theta) = \binom{n}{k} \theta^k (1-\theta)^{n-k} \quad (3.12) [^10] $$
Como o coeficiente binomial $\binom{N}{N_1}$ é uma constante independente de $\theta$, a likelihood para o modelo de amostragem Binomial é proporcional à likelihood do modelo de Bernoulli [^10]:
$$ p(N_1|N, \theta) \propto \theta^{N_1} (1-\theta)^{N_0} $$
Portanto, as inferências sobre $\theta$ serão as mesmas, quer observemos a sequência completa de ensaios $D = \{x_1, ..., x_N\}$ ou apenas as contagens $D = (N_1, N)$ [^10].

#### Prior

Para realizar a inferência Bayesiana, precisamos especificar uma distribuição **prior** $p(\theta)$ que reflita nossas crenças sobre $\theta$ antes de observar os dados. Esta prior deve ter suporte no intervalo $[0, 1]$ [^10].

Para simplificar a matemática, é conveniente escolher uma prior que tenha a mesma forma funcional da likelihood. Se a prior tiver a forma:
$$ p(\theta) \propto \theta^{\gamma_1} (1-\theta)^{\gamma_2} \quad (3.13) [^10] $$
para alguns parâmetros $\gamma_1, \gamma_2$, então a posterior, que é proporcional ao produto da likelihood pela prior, também terá esta forma:
$$ p(\theta|D) \propto p(D|\theta)p(\theta) \propto \left( \theta^{N_1} (1-\theta)^{N_0} \right) \left( \theta^{\gamma_1} (1-\theta)^{\gamma_2} \right) = \theta^{N_1+\gamma_1} (1-\theta)^{N_0+\gamma_2} \quad (3.14) [^10] $$
Quando a prior e a posterior pertencem à mesma família de distribuições, dizemos que a prior é uma **prior conjugada** (*conjugate prior*) para a likelihood correspondente [^10]. Priors conjugadas são amplamente utilizadas porque simplificam a computação e são fáceis de interpretar [^10].

No caso da likelihood Bernoulli/Binomial, a prior conjugada é a **distribuição Beta**, que encontramos na Seção 2.4.5 [^10]:
$$ \text{Beta}(\theta|a, b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{a-1} (1-\theta)^{b-1} \propto \theta^{a-1} (1-\theta)^{b-1} \quad (3.15) [^10] $$
onde $\Gamma(\cdot)$ é a função Gama, e $a, b > 0$ são os **hiperparâmetros** da prior [^10]. Podemos definir $a$ e $b$ para codificar nossas crenças prévias sobre $\theta$. Por exemplo, para codificar a crença de que $\theta$ tem média 0.7 e desvio padrão 0.2, podemos definir $a=2.975$ e $b=1.275$ (Exercício 3.15) [^10].

Se soubermos "muito pouco" sobre $\theta$, exceto que $\theta \in [0, 1]$, podemos usar uma **prior uniforme**, que é um tipo de **prior não informativa** (*uninformative prior*) (ver Seção 5.4.2 para detalhes) [^10]. A distribuição uniforme em $[0, 1]$ pode ser representada por uma distribuição Beta com $a=1$ e $b=1$ [^10].

#### Posterior

Multiplicando a likelihood (Bernoulli ou Binomial) pela prior Beta, obtemos a distribuição **posterior** para $\theta$. Seguindo a Equação (3.14), a posterior não normalizada é $\theta^{N_1+a-1} (1-\theta)^{N_0+b-1}$. Reconhecemos esta como a forma de uma distribuição Beta. Portanto, a posterior normalizada é:
$$ p(\theta|D) = \text{Beta}(\theta | N_1+a, N_0+b) \quad (3.16) [^11] $$
> A distribuição posterior é obtida simplesmente adicionando os hiperparâmetros da prior ($a, b$) às contagens empíricas ($N_1, N_0$) [^11]. Por esta razão, os hiperparâmetros $a$ e $b$ são frequentemente interpretados como **pseudo contagens** (*pseudo counts*) [^11].

A "força" da prior, também conhecida como o **tamanho efetivo da amostra** (*effective sample size*) da prior, é a soma das pseudo contagens, $a+b$. Este valor desempenha um papel análogo ao tamanho do conjunto de dados, $N = N_1 + N_0$ [^11].

A Figura 3.6(a) [^11] ilustra a atualização de uma prior Beta(2, 2) fraca (uniforme, mas com tamanho efetivo 4) com uma função de likelihood acentuada (correspondente a $N_1=3, N_0=17$). A posterior resultante, Beta(5, 19), é quase idêntica à likelihood, indicando que os dados "dominaram" a prior fraca [^11]. Em contraste, a Figura 3.6(b) [^11] mostra a atualização de uma prior Beta(5, 2) forte (com média $\approx 0.71$, tamanho efetivo 7) com uma likelihood ($N_1=11, N_0=13$). Aqui, a posterior, Beta(16, 15), é um "compromisso" (*compromise*) entre a prior e a likelihood [^11].

É importante notar que a atualização Bayesiana pode ser feita sequencialmente. Suponha que temos dois conjuntos de dados, $D_a$ com estatísticas suficientes $(N_1^a, N_0^a)$ e $D_b$ com $(N_1^b, N_0^b)$. Atualizar em modo *batch* com os dados combinados $D = D_a \cup D_b$, com estatísticas $N_1 = N_1^a + N_1^b$ e $N_0 = N_0^a + N_0^b$, resulta em [^11]:
$$ p(\theta|D_a, D_b) \propto p(D_a, D_b|\theta) p(\theta) \propto \theta^{N_1} (1-\theta)^{N_0} \theta^{a-1} (1-\theta)^{b-1} = \text{Beta}(\theta|N_1+a, N_0+b) \quad (3.17) [^11] $$
Em modo sequencial, primeiro atualizamos com $D_a$ para obter $p(\theta|D_a) = \text{Beta}(\theta|N_1^a+a, N_0^a+b)$. Usando esta posterior como prior para $D_b$, obtemos [^11]:
$$ p(\theta|D_a, D_b) \propto p(D_b|\theta) p(\theta|D_a) \propto \theta^{N_1^b} (1-\theta)^{N_0^b} \theta^{N_1^a+a-1} (1-\theta)^{N_0^a+b-1} $$
$$ \propto \theta^{N_1^b + N_1^a + a - 1} (1-\theta)^{N_0^b + N_0^a + b - 1} = \text{Beta}(\theta|N_1+a, N_0+b) \quad (3.18-3.20) [^11] $$
A equivalência entre atualização em batch e sequencial torna a inferência Bayesiana particularmente adequada para **aprendizagem online** (*online learning*) [^11].

#### Inferência e Estimativas Pontuais

A distribuição posterior $p(\theta|D)$ encapsula toda a nossa incerteza sobre $\theta$ após observar $D$. Frequentemente, desejamos resumir esta distribuição com estimativas pontuais.

A **média posterior** é dada por (usando a fórmula da média da distribuição Beta):
$$ \bar{\theta} = E[\theta|D] = \frac{N_1+a}{N_1+a+N_0+b} = \frac{N_1+a}{N+a+b} \quad (3.23) [^12] $$
Podemos reescrever a média posterior para mostrar que ela é uma combinação convexa da média da prior e da estimativa de máxima verossimilhança (MLE). Seja $\alpha_0 = a+b$ o tamanho efetivo da amostra da prior e $m_1 = a/\alpha_0$ a média da prior. A **MLE** é simplesmente a fração empírica de "caras", $\hat{\theta}_{MLE} = N_1/N$ (Eq 3.22) [^12]. Então, a média posterior é:
$$ E[\theta|D] = \frac{\alpha_0 m_1 + N_1}{N+\alpha_0} = \frac{\alpha_0}{N+\alpha_0} m_1 + \frac{N}{N+\alpha_0} \frac{N_1}{N} = \lambda m_1 + (1-\lambda) \hat{\theta}_{MLE} \quad (3.24) [^12] $$
onde $\lambda = \alpha_0 / (N+\alpha_0)$ é a razão entre o tamanho efetivo da amostra da prior e o tamanho efetivo da amostra da posterior ($N+\alpha_0$). Quanto mais fraca a prior (menor $\alpha_0$), menor $\lambda$, e mais próxima a média posterior estará da MLE [^12].

A **moda posterior**, ou estimativa **MAP** (*maximum a posteriori*), é o valor de $\theta$ que maximiza $p(\theta|D)$. Para a posterior Beta$(\theta|N_1+a, N_0+b)$, a moda é (da Equação 2.62) [^12]:
$$ \hat{\theta}_{MAP} = \frac{N_1+a-1}{N_1+a-1 + N_0+b-1} = \frac{N_1+a-1}{N+a+b-2} \quad (3.21) [^12] $$
Note que se usarmos uma prior uniforme ($a=b=1$), a estimativa MAP se reduz a $\hat{\theta}_{MAP} = N_1/N$, que é a MLE [^12].

Além das estimativas pontuais, é crucial quantificar nossa incerteza. A **variância posterior** é uma medida dessa incerteza. Para a posterior Beta$(\theta|N_1+a, N_0+b)$, a variância é [^12]:
$$ \text{var}[\theta|D] = \frac{(N_1+a)(N_0+b)}{(N_1+a+N_0+b)^2 (N_1+a+N_0+b+1)} = \frac{(N_1+a)(N_0+b)}{(N+a+b)^2 (N+a+b+1)} \quad (3.25) [^12] $$
Para $N \gg a, b$, esta expressão pode ser simplificada. Seja $\hat{\theta} \approx N_1/N$ a MLE. Então $N_1 \approx N\hat{\theta}$ e $N_0 \approx N(1-\hat{\theta})$. A variância se torna aproximadamente [^12]:
$$ \text{var}[\theta|D] \approx \frac{N\hat{\theta} N(1-\hat{\theta})}{(N)^2 (N+1)} \approx \frac{N^2 \hat{\theta}(1-\hat{\theta})}{N^3} = \frac{\hat{\theta}(1-\hat{\theta})}{N} \quad (3.26) [^12] $$
O desvio padrão posterior ("barra de erro") é então $\sigma = \sqrt{\text{var}[\theta|D]} \approx \sqrt{\hat{\theta}(1-\hat{\theta})/N}$ (Eq 3.27) [^12]. A incerteza diminui a uma taxa de $1/\sqrt{N}$. Note que a variância é maximizada quando $\theta=0.5$ e minimizada quando $\theta$ está próximo de 0 ou 1, o que significa que é mais fácil ter certeza de que uma moeda é viciada do que ter certeza de que ela é justa [^13].

#### Distribuição Preditiva Posterior

Até agora, focamos na inferência sobre o parâmetro desconhecido $\theta$. Frequentemente, o objetivo final é prever dados observáveis futuros [^7], [^13]. A **distribuição preditiva posterior** (*posterior predictive distribution*) fornece a probabilidade de uma nova observação $\tilde{x}$, dada a informação dos dados $D$.

Consideremos a previsão da probabilidade de "caras" em um *único* ensaio futuro. Isso é obtido marginalizando $\theta$ sobre sua distribuição posterior:
$$ p(\tilde{x}=1|D) = \int_0^1 p(\tilde{x}=1|\theta) p(\theta|D) d\theta \quad (3.28) [^13] $$
Como $p(\tilde{x}=1|\theta) = \theta$ e $p(\theta|D) = \text{Beta}(\theta|N_1+a, N_0+b)$, temos:
$$ p(\tilde{x}=1|D) = \int_0^1 \theta \text{Beta}(\theta|N_1+a, N_0+b) d\theta = E[\theta|D] \quad (3.29) [^13] $$
Portanto, a probabilidade preditiva de "caras" é simplesmente a média posterior de $\theta$, que calculamos anteriormente como $(N_1+a)/(N+a+b)$ [^13].

> **Overfitting e o Paradoxo do Cisne Negro:** Se usássemos uma estimativa pontual como a MLE para fazer previsões, $p(\tilde{x}|D) \approx \text{Ber}(\tilde{x}|\hat{\theta}_{MLE})$, poderíamos encontrar problemas com tamanhos de amostra pequenos. Por exemplo, se observarmos $N=3$ coroas seguidas ($N_1=0, N_0=3$), a MLE é $\hat{\theta}_{MLE}=0/3=0$. Usando esta estimativa, preveríamos que "caras" são impossíveis ($p(\tilde{x}=1|D) = 0$) [^13]. Este é o **problema da contagem zero** (*zero count problem*) ou **problema de dados esparsos** (*sparse data problem*), que ocorre frequentemente quando estimamos contagens a partir de pequenas quantidades de dados [^13]. Este problema é análogo ao **paradoxo do cisne negro** (*black swan paradox*) na filosofia, que ilustra o problema da **indução**: como tirar conclusões gerais sobre o futuro a partir de observações específicas do passado [^13].

A solução Bayesiana evita este problema. Usando a média preditiva posterior com uma prior uniforme ($a=b=1$), obtemos a **regra de sucessão de Laplace** (*Laplace\'s rule of succession*):
$$ p(\tilde{x}=1|D) = \frac{N_1+1}{N_1+1+N_0+1} = \frac{N_1+1}{N+2} \quad (3.30) [^13] $$
Esta regra justifica a prática comum de adicionar 1 às contagens empíricas antes de normalizar, uma técnica conhecida como **suavização add-one** (*add-one smoothing*) [^13]. Note que usar a estimativa MAP (com $a=b=1$) não teria este efeito suavizador, pois ela se reduziria à MLE [^13].

Podemos também prever o número de "caras", $x$, em $M$ ensaios futuros. A distribuição preditiva é dada por:
$$ p(x|D, M) = \int_0^1 p(x|\theta, M) p(\theta|D) d\theta = \int_0^1 \text{Bin}(x|\theta, M) \text{Beta}(\theta|N_1+a, N_0+b) d\theta \quad (3.31) [^14] $$
A integral resultante define a **distribuição Beta-Binomial** (composta) [^14]:
$$ p(x|D, M) = \text{Bb}(x | N_1+a, N_0+b, M) \triangleq \binom{M}{x} \frac{B(x+N_1+a, M-x+N_0+b)}{B(N_1+a, N_0+b)} \quad (3.34) [^14] $$
onde $B(\cdot, \cdot)$ é a função Beta. A média desta distribuição é $E[x|D, M] = M \times E[\theta|D] = M \frac{N_1+a}{N+a+b}$ (Eq 3.35) [^14], consistente com a previsão para um único ensaio (Eq 3.29) quando $M=1$.

A Figura 3.7 [^14] compara a distribuição preditiva Beta-Binomial (Bayesiana) com a aproximação *plug-in* usando a estimativa MAP. A previsão Bayesiana tem caudas mais longas, distribuindo a massa de probabilidade de forma mais ampla, o que a torna menos propensa a **overfitting** e a paradoxos do tipo cisne negro [^14]. Em contraste, a aproximação plug-in pode subestimar a incerteza.

### Conclusão

O modelo beta-binomial é uma ferramenta fundamental na inferência Bayesiana, permitindo-nos atualizar nossas crenças sobre uma proporção desconhecida $\theta$ à medida que observamos dados de ensaios de Bernoulli. Demonstramos como especificar a likelihood (Bernoulli/Binomial) e uma prior conjugada (Beta), resultando em uma posterior que também é uma distribuição Beta. Esta conjugação simplifica enormemente os cálculos e fornece interpretações intuitivas em termos de pseudo contagens e tamanho efetivo da amostra.

Exploramos como derivar estimativas pontuais (média e moda posterior) e medidas de incerteza (variância posterior). Crucialmente, derivamos a distribuição preditiva posterior, mostrando como a abordagem Bayesiana, através da marginalização sobre a incerteza do parâmetro, leva a previsões mais robustas (como a regra de Laplace e a distribuição Beta-Binomial), evitando problemas como o da contagem zero, comuns em estimativas de máxima verossimilhança com dados esparsos.

Este modelo serve como um bloco de construção essencial para modelos mais complexos, como os classificadores **naive Bayes** [^9], [^18] (que empregam princípios semelhantes para estimar probabilidades condicionais de características) e a generalização direta para múltiplos resultados, o **modelo Dirichlet-Multinomial** [^14], que exploraremos a seguir.

### Referências

[^1]: Page 1, Section 3.2 Bayesian concept learning
[^2]: Page 2, Figure 3.1 and surrounding text
[^3]: Page 3, Section 3.2.1 Likelihood
[^4]: Page 3, Section 3.2.2 Prior
[^5]: Page 4, Section 3.2.3 Posterior
[^6]: Page 5, MAP vs MLE discussion
[^7]: Page 7, Section 3.2.4 Posterior predictive distribution
[^8]: Page 8, Section 3.3 The beta-binomial model, Introduction
[^9]: Page 9, Section 3.3 The beta-binomial model, Introduction and Section 3.3.1 Likelihood
[^10]: Page 10, Sufficient Statistics and Section 3.3.2 Prior
[^11]: Page 11, Section 3.3.3 Posterior
[^12]: Page 12, Section 3.3.3.1 Posterior mean and mode, Section 3.3.3.2 Posterior variance
[^13]: Page 13, Section 3.3.4 Posterior predictive distribution, Section 3.3.4.1 Overfitting and the black swan paradox
[^14]: Page 14, Section 3.3.4.2 Predicting the outcome of multiple future trials
[^18]: Page 18, Section 3.5 Naive Bayes classifiers (as referenced foundationally)
<!-- END -->