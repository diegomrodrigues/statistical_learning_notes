## Capítulo 3: Inferência Posterior no Modelo Beta-Binomial

### Introdução

Nos capítulos anteriores, estabelecemos os fundamentos da modelagem generativa para dados discretos e a inferência Bayesiana. Exploramos como a regra de Bayes permite atualizar nossas crenças sobre parâmetros desconhecidos à luz de dados observados. O modelo Beta-Binomial é um exemplo canônico e fundamental neste contexto, frequentemente utilizado para modelar a incerteza sobre uma probabilidade de sucesso $\theta$ (como a probabilidade de uma moeda dar "cara") com base em observações de ensaios de Bernoulli (ou equivalentemente, contagens Binomiais). Este capítulo foca especificamente na derivação e análise da **distribuição posterior** para o parâmetro $\theta$ dentro deste modelo. Investigaremos como a combinação de uma verossimilhança Binomial com um prior Beta resulta em uma posterior tratável, exploraremos a interpretação dos seus parâmetros, suas propriedades de atualização e a derivação da estimativa **Maximum A Posteriori (MAP)**.

### Conceitos Fundamentais

#### Derivação da Distribuição Posterior

O cerne da inferência Bayesiana reside na atualização do conhecimento prévio (prior) com a informação contida nos dados (likelihood) para obter o conhecimento atualizado (posterior). No modelo Beta-Binomial, assumimos que os dados $D$ consistem em $N_1$ sucessos (e.g., caras) e $N_0$ falhas (e.g., coroas) em um total de $N = N_0 + N_1$ ensaios independentes de Bernoulli com parâmetro $\theta$. A função de verossimilhança (likelihood) para $\theta$, dados $N_1$ e $N_0$, é proporcional a uma distribuição Binomial:
$$ p(D|\theta) \propto \theta^{N_1} (1-\theta)^{N_0} $$
Esta forma funcional captura a probabilidade de observar os dados $D$ para um dado valor de $\theta$.

Para completar a especificação Bayesiana, precisamos de uma distribuição a priori $p(\theta)$ sobre o parâmetro $\theta \in [0, 1]$. A escolha natural e computacionalmente conveniente é a distribuição Beta, $Beta(\theta|a, b)$, que é conjugada à verossimilhança Binomial. A forma da distribuição Beta é:
$$ p(\theta) = Beta(\theta|a, b) \propto \theta^{a-1} (1-\theta)^{b-1} $$
onde $a > 0$ e $b > 0$ são os **hiperparâmetros** do prior, que codificam nossa crença inicial sobre $\theta$.

A distribuição posterior $p(\theta|D)$ é obtida aplicando a regra de Bayes, que afirma que a posterior é proporcional ao produto da verossimilhança pelo prior [^1]. Assim, temos:
$$ p(\theta|D) \propto p(D|\theta) p(\theta) $$
Substituindo as formas funcionais da verossimilhança Binomial e do prior Beta [^2]:
$$ p(\theta|D) \propto \left( \theta^{N_1} (1-\theta)^{N_0} \right) \times \left( \theta^{a-1} (1-\theta)^{b-1} \right) $$
Combinando os termos com a mesma base:
$$ p(\theta|D) \propto \theta^{N_1 + a - 1} (1-\theta)^{N_0 + b - 1} $$
Reconhecemos imediatamente que esta é a forma do *kernel* de uma distribuição Beta com parâmetros atualizados $\alpha\' = N_1 + a$ e $\beta\' = N_0 + b$. Portanto, a distribuição posterior é:
$$ p(\theta|D) = Beta(\theta|N_1 + a, N_0 + b) $$
[^3]. Este resultado demonstra a **conjugação** do prior Beta com a verossimilhança Binomial: a posterior pertence à mesma família de distribuições do prior, facilitando enormemente a análise e a computação.

#### Interpretação dos Hiperparâmetros e Força do Prior

A forma da distribuição posterior $Beta(\theta|N_1 + a, N_0 + b)$ oferece uma interpretação intuitiva. Os parâmetros da posterior são simplesmente a soma das contagens observadas ($N_1$ e $N_0$) com os hiperparâmetros do prior ($a$ e $b$). Por esta razão, os hiperparâmetros $a$ e $b$ são frequentemente interpretados como **pseudo counts** (contagens fictícias ou pseudocontagens) [^4]. O hiperparâmetro $a$ pode ser visto como o número de sucessos "imaginários" observados antes de coletar os dados reais, e $b$ como o número de falhas "imaginárias".

A magnitude total dos pseudo counts, $a + b$, quantifica a **força do prior** [^5], também conhecida como o **effective sample size** (tamanho amostral efetivo) do prior. Um valor maior de $a+b$ indica um prior mais forte ou mais informativo, que exigirá mais dados para ser significativamente alterado. Em contraste, um valor menor de $a+b$ corresponde a um prior mais fraco ou menos informativo, que será mais facilmente dominado pela verossimilhança à medida que o tamanho da amostra $N = N_0 + N_1$ aumenta.

#### Atualização Sequencial e Online Learning

Uma propriedade extremamente útil da inferência Bayesiana com priors conjugados, como no modelo Beta-Binomial, é que a atualização da posterior pode ser feita sequencialmente. Suponha que temos dois conjuntos de dados, $D_a$ com contagens $(N_{1a}, N_{0a})$ e $D_b$ com contagens $(N_{1b}, N_{0b})$. Poderíamos atualizar o prior $Beta(\theta|a, b)$ com os dados combinados $D = D_a \cup D_b$, que tem contagens totais $(N_{1a}+N_{1b}, N_{0a}+N_{0b})$. A posterior resultante seria $Beta(\theta | (N_{1a}+N_{1b}) + a, (N_{0a}+N_{0b}) + b)$.

Alternativamente, poderíamos primeiro atualizar o prior com $D_a$, obtendo a posterior intermediária $p(\theta|D_a) = Beta(\theta|N_{1a}+a, N_{0a}+b)$. Em seguida, usando esta posterior como um novo prior, atualizamos com $D_b$. A posterior final seria:
$$ p(\theta|D_a, D_b) \propto p(D_b|\theta) p(\theta|D_a) $$
$$ p(\theta|D_a, D_b) \propto \theta^{N_{1b}}(1-\theta)^{N_{0b}} \times \theta^{(N_{1a}+a)-1}(1-\theta)^{(N_{0a}+b)-1} $$
$$ p(\theta|D_a, D_b) \propto \theta^{N_{1b} + N_{1a} + a - 1} (1-\theta)^{N_{0b} + N_{0a} + b - 1} $$
$$ p(\theta|D_a, D_b) = Beta(\theta | (N_{1a}+N_{1b}) + a, (N_{0a}+N_{0b}) + b) $$
Observamos que o resultado é idêntico ao obtido com a atualização em lote (batch). Esta equivalência entre atualização sequencial e em lote é uma consequência direta da comutatividade e associatividade da adição (nos expoentes) [^6].

> **Caixa de Destaque:** A equivalência entre atualização sequencial e em lote torna a inferência Bayesiana com modelos conjugados particularmente adequada para cenários de **online learning** [^7]. À medida que novos dados chegam, a distribuição posterior pode ser atualizada incrementalmente, usando a posterior anterior como o prior para o novo dado, sem a necessidade de reprocessar todo o histórico de dados.

#### Estimativa Maximum A Posteriori (MAP)

Embora a distribuição posterior completa $p(\theta|D)$ represente nosso estado de conhecimento atualizado sobre $\theta$, muitas vezes é útil resumir essa distribuição com uma estimativa pontual. Uma escolha comum é a estimativa **Maximum A Posteriori (MAP)**, que corresponde ao valor de $\theta$ que maximiza a densidade de probabilidade posterior, ou seja, a moda da distribuição posterior.

Para a distribuição posterior $p(\theta|D) = Beta(\theta|\alpha\', \beta\')$, com $\alpha\' = N_1 + a$ e $\beta\' = N_0 + b$, a moda é conhecida (assumindo $\alpha\', \beta\' > 1$) e dada por:
$$ \hat{\theta}_{mode} = \frac{\alpha\' - 1}{\alpha\' + \beta\' - 2} $$
Substituindo os valores de $\alpha\'$ e $\beta\'$, obtemos a estimativa MAP para $\theta$:\
$$ \hat{\theta}_{MAP} = \frac{(N_1 + a) - 1}{(N_1 + a) + (N_0 + b) - 2} = \frac{N_1 + a - 1}{N_1 + N_0 + a + b - 2} $$
Lembrando que $N = N_1 + N_0$, a fórmula é:
$$ \hat{\theta}_{MAP} = \frac{N_1 + a - 1}{N + a + b - 2} $$
[^8]. A estimativa MAP pode ser vista como um equilíbrio entre o prior e a verossimilhança, incorporando tanto as contagens observadas quanto as pseudo counts do prior.

É instrutivo considerar o caso especial de um prior uniforme, $Beta(\theta|1, 1)$, que representa uma ausência de conhecimento prévio específico (dentro da família Beta). Neste caso, $a=1$ e $b=1$. Substituindo na fórmula da MAP:
$$ \hat{\theta}_{MAP} = \frac{N_1 + 1 - 1}{N + 1 + 1 - 2} = \frac{N_1}{N} $$
Este resultado é precisamente a estimativa de **Maximum Likelihood Estimate (MLE)** para o parâmetro Binomial, que é a simples proporção de sucessos observados. Portanto, a estimativa MAP se reduz à MLE quando um prior uniforme é utilizado [^9]. Isso ocorre porque, com um prior uniforme, $p(\theta)$ é constante no intervalo [0,1], e maximizar a posterior $p(\theta|D) \propto p(D|\theta)p(\theta)$ torna-se equivalente a maximizar apenas a verossimilhança $p(D|\theta)$.

### Conclusão

Este capítulo detalhou a derivação e as propriedades da distribuição posterior no modelo Beta-Binomial. Demonstramos que a conjugação entre o prior Beta e a verossimilhança Binomial leva a uma posterior também Beta, $Beta(\theta|N_1+a, N_0+b)$. Discutimos a interpretação dos hiperparâmetros do prior como pseudo counts e a soma $a+b$ como a força do prior. Exploramos a equivalência crucial entre atualizações sequenciais e em lote, destacando a adequação do framework para online learning. Finalmente, derivamos a estimativa MAP, $\hat{\theta}_{MAP} = \frac{N_1 + a - 1}{N + a + b - 2}$, e mostramos sua relação com a estimativa MLE sob um prior uniforme. Essas propriedades fazem do modelo Beta-Binomial uma ferramenta poderosa e interpretável para a inferência Bayesiana sobre proporções.

### Referências

[^1]: The posterior distribution in the beta-binomial model is obtained by multiplying the likelihood by the beta prior
[^2]: resulting in $p(\theta|D) \propto Bin(N_1|\theta, N_0 + N_1)Beta(\theta|a, b)$
[^3]: $\propto Beta(\theta|N_1 + a, N_0 + b)$
[^4]: where the prior hyper-parameters act as pseudo counts
[^5]: and the strength of the prior is the sum of the pseudo counts, $a + b$.
[^6]: Updating the posterior sequentially is equivalent to updating in a single batch,
[^7]: making Bayesian inference well-suited to online learning,
[^8]: and the MAP estimate is given by $\hat{\theta}_{MAP} = \frac{a + N_1 - 1}{a + b + N - 2}$,
[^9]: which reduces to the MLE when a uniform prior is used.
<!-- END -->