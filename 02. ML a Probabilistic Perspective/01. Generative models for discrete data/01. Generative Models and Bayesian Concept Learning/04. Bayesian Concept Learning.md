## Capítulo 3.2.1: O Espaço de Versão na Indução Clássica e a Necessidade de Explicações Bayesianas

### Introdução

No âmbito da aprendizagem de conceitos, conforme introduzido na Seção 3.2 [^1], buscamos entender como um agente pode inferir o significado de um conceito, como uma propriedade aritmética no "number game" [^1], a partir de exemplos positivos. A abordagem clássica para este problema de **indução** postula a existência de um **espaço de hipóteses** ($H$) pré-definido, contendo todos os conceitos possíveis que o agente pode considerar [^3]. Dado um conjunto de dados observados $D$, a inferência clássica concentra-se em identificar quais hipóteses em $H$ são compatíveis com $D$. Este subconjunto é conhecido como **espaço de versão** (*version space*) [^4]. À medida que mais exemplos são observados, o espaço de versão tende a diminuir, refinando o conjunto de hipóteses plausíveis e aumentando a certeza sobre o conceito subjacente [^5]. Contudo, como exploraremos neste capítulo, a mera identificação de hipóteses consistentes é insuficiente. Ela não prescreve como combinar essas hipóteses para prever novas instâncias, nem explica por que certas generalizações consistentes são preferidas em detrimento de outras igualmente consistentes [^6]. Esta limitação aponta para a necessidade de uma abordagem Bayesiana, capaz de ponderar as hipóteses com base em sua plausibilidade e poder explicativo, especialmente ao lidar com o que podem parecer **coincidências suspeitas** (*suspicious coincidences*) nos dados [^7].

### Conceitos Fundamentais

#### A Abordagem Clássica: Espaço de Hipóteses e Espaço de Versão

A fundamentação da indução clássica reside na definição de um **espaço de hipóteses** $H$. Este espaço compreende o universo de conceitos que o aprendiz considera *a priori*. No contexto do "number game" [^1], $H$ poderia incluir conceitos como "números pares", "números ímpares", "números primos", "potências de dois", "números terminados em $j$" (para $0 \le j \le 9$), "todos os números entre 1 e 100", entre outros [^3]. Cada hipótese $h \in H$ corresponde a um subconjunto do domínio de interesse (neste caso, inteiros de 1 a 100).

Dado um conjunto de exemplos positivos $D = \\{x_1, ..., x_N\\}$, uma hipótese $h \in H$ é considerada **consistente** com $D$ se todos os exemplos em $D$ pertencem à extensão de $h$, ou seja, $x_i \in h$ para todo $i = 1, ..., N$. O **espaço de versão**, denotado como $VS_{H,D}$, é formalmente definido como o subconjunto de $H$ que contém todas as hipóteses consistentes com os dados $D$:
$$ VS_{H,D} = \\{h \in H \mid \forall x_i \in D, x_i \in h \\} $$
[^4]. Uma propriedade central do espaço de versão é que ele se contrai monotonicamente com o aumento dos dados. Se $D\' = D \cup \\{x_{N+1}\\}$, então $VS_{H,D\'} \subseteq VS_{H,D}$ [^5]. Este processo de eliminação de hipóteses inconsistentes reflete um aumento gradual da certeza sobre o conceito verdadeiro, assumindo que ele pertença a $H$.

#### Limitações da Abordagem Clássica e a Necessidade de Ponderação

Apesar de sua utilidade em restringir o conjunto de possibilidades, a abordagem do espaço de versão apresenta limitações significativas, como apontado no texto [^6]. Primeiramente, após observar um conjunto de dados $D$, o espaço de versão $VS_{H,D}$ pode conter múltiplas hipóteses. Se o objetivo é prever se um novo caso de teste $\tilde{x}$ pertence ao conceito $C$ (ou seja, classificar $\tilde{x}$), como devemos proceder? A abordagem clássica não oferece um mecanismo claro para combinar as previsões das diferentes hipóteses no espaço de versão. Por exemplo, após observar $D=\\{16\\}$, muitas regras são consistentes (e.g., "potências de 2", "potências de 4", "números pares", "números terminados em 6", "todos os números entre 1 e 100") [^6]. Qual delas usar para prever se 32 pertence ao conceito?

Em segundo lugar, mesmo quando o espaço de versão é significativamente reduzido, a preferência intuitiva por certas generalizações não é explicada. Considere o exemplo $D = \\{16, 8, 2, 64\\}$ [^2]. Hipóteses como $h_{two}$ = "potências de dois" e $h_{even}$ = "números pares" são ambas consistentes com $D$. Além disso, a hipótese $h\'$ = "potências de dois exceto 32" também é consistente. No entanto, intuitivamente, a hipótese "potências de dois" parece ser a explicação mais provável e a melhor base para generalização [^6]. O espaço de versão, por si só, trata todas essas hipóteses consistentes como igualmente válidas, falhando em capturar a preferência por $h_{two}$ ou explicar por que $h\'$ parece "conceptualmente não natural" [^13]. A questão crucial é: por que escolher $h_{two}$ e não $h_{even}$ ou $h\'$? [^6]. Esta falha em discriminar entre hipóteses consistentes com base em sua plausibilidade ou simplicidade exige uma explicação mais robusta, que a abordagem Bayesiana pode fornecer.

#### A Explicação Bayesiana: Likelihood e o Princípio do Tamanho

A estrutura Bayesiana oferece uma solução para as limitações do espaço de versão, introduzindo uma forma de ponderar as hipóteses consistentes. Um componente chave é a **likelihood** $p(D|h)$, que quantifica a probabilidade de observar os dados $D$ *assumindo* que a hipótese $h$ seja a verdadeira geradora dos dados. Para derivar $p(D|h)$ no contexto da aprendizagem de conceitos a partir de exemplos positivos, Tenenbaum introduz a **strong sampling assumption** [^8]: assume-se que os exemplos $D = \\{x_1, ..., x_N\\}$ são amostrados uniformemente ao acaso (com reposição) da extensão do conceito verdadeiro $C$. Se uma hipótese $h$ é considerada como candidata a ser o conceito verdadeiro, a probabilidade de amostrar um único exemplo $x_i$ de sua extensão é $1/|h|$, onde $|h|$ denota o tamanho (cardinalidade) da extensão de $h$. Assumindo amostragem independente, a likelihood de observar o conjunto de dados $D$ completo, dado $h$, é:
$$ p(D|h) = \left( \frac{1}{|h|} \right)^N $$
[^10]. Esta equação é válida apenas se $h$ for consistente com $D$ (i.e., $h \in VS_{H,D}$); caso contrário, $p(D|h) = 0$.

> Esta equação crucial incorpora o que Tenenbaum chama de **princípio do tamanho** (*size principle*), que significa que o modelo favorece a hipótese mais simples (menor extensão) consistente com os dados [^9]. Isso é mais comumente conhecido como a **Navalha de Occam** (*Occam\'s Razor*) [^11].

O princípio do tamanho fornece uma explicação quantitativa para a preferência por certas hipóteses consistentes. Retornando ao exemplo $D = \\{16, 8, 2, 64\\}$, comparamos as hipóteses $h_{two}$ ("potências de dois") e $h_{even}$ ("números pares"). A extensão de $h_{two}$ (entre 1 e 100) é $\\{2, 4, 8, 16, 32, 64\\}$, então $|h_{two}| = 6$. A extensão de $h_{even}$ é $\\{2, 4, ..., 100\\}$, então $|h_{even}| = 50$. Ambas são consistentes com $D$. Calculando as likelihoods para $N=4$:
$$ p(D|h_{two}) = (1/6)^4 \approx 7.7 \times 10^{-4} $$
$$ p(D|h_{even}) = (1/50)^4 = 1.6 \times 10^{-7} $$
[^12]. A likelihood de $h_{two}$ é quase 5000 vezes maior que a de $h_{even}$ [^12]. Este resultado formaliza a intuição de que observar apenas potências de dois, quando o conceito subjacente era supostamente "números pares", seria uma **coincidência suspeita** [^7]. A hipótese $h_{two}$ é preferida porque torna os dados observados muito mais prováveis do que $h_{even}$. Ela oferece uma explicação mais específica e, portanto, mais forte para os dados. A hipótese $h\'$ ("potências de dois exceto 32") teria $|h\'|=5$, resultando em uma likelihood ainda maior, $p(D|h\')=(1/5)^4 = 1.6 \times 10^{-3}$. No entanto, a abordagem Bayesiana completa (introduzida posteriormente no texto original, Seções 3.2.2 e 3.2.3) incorpora também uma probabilidade *a priori* $p(h)$, que pode atribuir menor peso a hipóteses "não naturais" como $h\'$, evitando o overfitting [^13, ^14].

### Conclusão

A abordagem clássica da indução via espaço de versão fornece um quadro inicial útil para a aprendizagem de conceitos, identificando o conjunto de hipóteses $H$ que são consistentes com os dados observados $D$ [^4]. O encolhimento do espaço de versão com mais dados reflete um processo de aprendizagem por eliminação [^5]. No entanto, esta abordagem é incompleta, pois não especifica como generalizar a partir de múltiplas hipóteses consistentes, nem explica a preferência humana por certas generalizações em detrimento de outras igualmente consistentes [^6]. A introdução da perspectiva Bayesiana, começando com a função de **likelihood** $p(D|h)$, aborda diretamente essas limitações. Ao incorporar a **strong sampling assumption** [^8] e o resultante **princípio do tamanho** [^9], a likelihood Bayesiana favorece hipóteses mais específicas (com menor extensão) que explicam os dados, formalizando o princípio da **Navalha de Occam** [^11] e quantificando a noção de **coincidências suspeitas** [^7]. Isso permite uma ponderação fundamentada das hipóteses dentro do espaço de versão, oferecendo uma explicação mais rica e robusta para a inferência indutiva, como demonstrado no "number game" [^12]. A análise da likelihood é um passo fundamental na construção de modelos Bayesianos completos para a aprendizagem de conceitos, que também incorporam probabilidades *a priori* e computam distribuições *a posteriori* sobre o espaço de hipóteses.

### Referências

[^1]: (Página 1, Seção 3.2) *For pedagogical purposes, we will consider a very simple example of concept learning called the **number game**, based on part of Josh Tenenbaum\'s PhD thesis (Tenenbaum 1999). The game proceeds as follows. I choose some simple arithmetical concept C, such as “prime number” or “a number between 1 and 10". I then give you a series of randomly chosen positive examples D = {x1,...,xN} drawn from C, and ask you whether some new test case \\(\tilde{x}\\) belongs to C, i.e., I ask you to classify \\(\tilde{x}\\).*
[^2]: (Página 2) *Now suppose I tell you that 8, 2 and 64 are also positive examples. Now you may guess that the hidden concept is “powers of two”. This is an example of **induction**.*
[^3]: (Página 2) *How can we explain this behavior and emulate it in a machine? The classic approach to induction is to suppose we have a **hypothesis space** of concepts, H, such as: odd numbers, even numbers, all numbers between 1 and 100, powers of two, all numbers ending in j (for 0 ≤ j ≤ 9), etc.*
[^4]: (Página 3) *The subset of H that is **consistent** with the data D is called the **version space**.*
[^5]: (Página 3) *As we see more examples, the version space shrinks and we become increasingly certain about the concept (Mitchell 1997).*
[^6]: (Página 3) *However, the version space is not the whole story. After seeing D = {16}, there are many consistent rules; how do you combine them to predict if \\(\tilde{x}\\) ∈ C? Also, after seeing D = {16, 8, 2, 64}, why did you choose the rule “powers of two” and not, say, “all even numbers”, or “powers of two except for 32", both of which are equally consistent with the evidence? We will now provide a Bayesian explanation for this.*
[^7]: (Página 3, Seção 3.2.1) *We must explain why we chose htwo "powers of two", and not, say, heven "even numbers" after seeing D = {16,8,2,64}, given that both hypotheses are consistent with the evidence. The key intuition is that we want to avoid **suspicious coincidences**. If the true concept was even numbers, how come we only saw numbers that happened to be powers of two?*
[^8]: (Página 3, Seção 3.2.1) *To formalize this, let us assume that examples are sampled uniformly at random from the extension of a concept. ... Tenenbaum calls this the **strong sampling assumption**.*
[^9]: (Página 3, Seção 3.2.1) *This crucial equation embodies what Tenenbaum calls the **size principle**, which means the model favors the simplest (smallest) hypothesis consistent with the data.*
[^10]: (Página 3, Seção 3.2.1, Equação 3.2) *p(D|h) = [1 / size(h)]^N = [1 / |h|]^N*
[^11]: (Página 3, Seção 3.2.1) *This is more commonly known as **Occam\'s razor**.¹* (Nota de rodapé 1: *William of Occam (also spelt Ockham) was an English monk and philosopher, 1288–1348.*)
[^12]: (Página 3, Seção 3.2.1) *To see how it works, let D = {16}. Then p(D|htwo) = 1/6, since there are only 6 powers of two less than 100, but p(D|heven) = 1/50, since there are 50 even numbers. So the likelihood that h = htwo is higher than if h = heven. After 4 examples, the likelihood of htwo is (1/6)⁴ = 7.7 × 10⁻⁴, whereas the likelihood of heven is (1/50)⁴ = 1.6 × 10⁻⁷. This is a likelihood ratio of almost 5000:1 in favor of htwo. This quantifies our earlier intuition that D = {16, 8, 2, 64} would be a very suspicious coincidence if generated by heven.*
[^13]: (Página 3, Seção 3.2.2) *However, the hypothesis h\' =“powers of two except 32” seems “conceptually unnatural”. We can capture such intution by assigning low prior probability to unnatural concepts.*
[^14]: (Página 4) *However, the “unnatural” concepts of “powers of 2, plus 37” and “powers of 2, except 32” have low posterior support, despite having high likelihood, due to the low prior.*

<!-- END -->