## Capítulo 3.2.3: A Probabilidade Posterior no Aprendizado Bayesiano de Conceitos

### Introdução

No contexto do **Aprendizado Bayesiano de Conceitos**, como exemplificado pelo *number game* introduzido anteriormente [^1], o objetivo central é inferir a natureza de um conceito desconhecido $C$ a partir de exemplos positivos $D = \\{x_1, \dots, x_N\\}$ extraídos desse conceito. Tendo estabelecido o espaço de hipóteses $H$ [^2] e definido as distribuições **prior** $p(h)$ [^3] e a **likelihood** $p(D|h)$ [^1], podemos agora abordar o núcleo da inferência Bayesiana: a **probabilidade posterior** $p(h|D)$. Esta quantidade representa a nossa crença atualizada sobre a validade de cada hipótese $h \in H$ após a observação dos dados $D$. Ela combina a plausibilidade inicial de uma hipótese (prior) com a evidência fornecida pelos dados (likelihood), fornecendo uma base racional para a aprendizagem e a generalização.

### Conceitos Fundamentais

**Definição e Cálculo da Probabilidade Posterior**

A probabilidade posterior de uma hipótese $h$ dados os dados $D$ é calculada utilizando a regra de Bayes. Formalmente, ela é definida como o produto da likelihood e do prior, normalizado pela probabilidade total dos dados (a evidência) [^4]:

> $$\
> p(h|D) = \frac{p(D|h)p(h)}{\sum_{h' \in H} p(D, h')} = \frac{p(D|h)p(h)}{p(D)} \quad \quad (3.3)\
> $$\
> [^4]

Nesta equação, $p(D|h)$ é a **likelihood** dos dados $D$ sob a hipótese $h$, $p(h)$ é a probabilidade **prior** da hipótese $h$, e o denominador $p(D) = \sum_{h' \in H} p(D, h')$ é a **evidência** ou probabilidade marginal dos dados, que atua como uma constante de normalização assegurando que as probabilidades posteriores somem 1 sobre todas as hipóteses em $H$.

No contexto específico do *number game*, assumindo a **strong sampling assumption** [^1], a likelihood é dada por $p(D|h) = [1/\text{size}(h)]^N = [1/|h|]^N$ se todos os exemplos em $D$ pertencem à extensão de $h$ (denotado por $D \subseteq h$), e 0 caso contrário. Podemos incorporar isso usando uma função indicadora $I(D \subseteq h)$, que é 1 se $D \subseteq h$ e 0 caso contrário. Assim, a fórmula da posterior torna-se [^4]:

$$\
p(h|D) = \frac{p(h) I(D \subseteq h) / |h|^N}{\sum_{h' \in H} p(h') I(D \subseteq h') / |h'|^N}\
$$
[^4]

Esta formulação captura explicitamente que apenas hipóteses consistentes com os dados ($I(D \subseteq h) = 1$) podem ter probabilidade posterior não nula.

**Interpretação e Interação entre Likelihood e Prior**

A probabilidade posterior $p(h|D)$ representa a crença racional atualizada sobre a hipótese $h$ à luz da evidência $D$. Ela reflete uma combinação ponderada entre a crença inicial $p(h)$ e a evidência empírica $p(D|h)$ [^5]. A interação entre esses dois componentes é fundamental:

1.  *Influência da Likelihood:* Se o prior $p(h)$ for uniforme sobre todas as hipóteses, a posterior será diretamente proporcional à likelihood, $p(h|D) \propto p(D|h)$ [^5]. Neste caso, as hipóteses que melhor explicam os dados (maior likelihood) terão maior probabilidade posterior. O **size principle** [^1], que favorece hipóteses com menor extensão (menor $|h|$), emerge diretamente da likelihood: hipóteses menores que contêm os dados $D$ são consideradas explicações mais fortes do que hipóteses maiores. Por exemplo, com $D=\\{16\\}$, a hipótese $h_{two}$ ("powers of two") tem $p(D|h_{two}) = 1/6$, enquanto $h_{even}$ ("even numbers") tem $p(D|h_{even}) = 1/50$. A likelihood favorece $h_{two}$ [^2].

2.  *Influência do Prior:* O prior $p(h)$ introduz um viés indutivo que reflete a plausibilidade inerente ou "naturalidade" de um conceito, independentemente dos dados [^3]. Hipóteses consideradas "conceptualmente não naturais", como "powers of 2, except 32", podem receber um prior baixo [^4]. Mesmo que tal hipótese tenha uma likelihood alta (por exemplo, se 32 estiver ausente dos dados), seu prior baixo pode resultar em um suporte posterior baixo [^5]. Isso ajuda a evitar o **overfitting** a coincidências nos dados [^7].

3.  *Balanço Dinâmico:* A posterior reflete o balanço entre prior e likelihood. Uma hipótese com prior alto mas likelihood baixo (por exemplo, "odd numbers" quando $D=\\{16\\}$) terá suporte posterior baixo [^5]. Inversamente, uma hipótese com likelihood alto mas prior muito baixo também terá suporte posterior baixo [^5]. A Figura 3.2 ilustra essa interação para $D=\\{16\\}$, mostrando como o prior e a likelihood se combinam para formar a posterior [^6, ^13].

**Comportamento com Mais Dados e a Estimativa MAP**

À medida que mais dados são observados (N aumenta), a influência da likelihood geralmente cresce exponencialmente, enquanto o prior permanece constante [^11]. Consequentemente, a distribuição posterior $p(h|D)$ tende a se tornar mais concentrada, ou *peaked*, em torno de uma única hipótese (ou um pequeno conjunto delas) [^8]. Este fenômeno é ilustrado na Figura 3.3 para $D = \\{16, 8, 2, 64\\}$, onde a posterior é fortemente dominada pela hipótese "powers of two", refletindo um "aha moment" do aprendiz [^7, ^15].

Nesse regime de dados suficientes, a inferência Bayesiana frequentemente converge para a seleção da hipótese com a maior probabilidade posterior. Esta é conhecida como a estimativa **Maximum A Posteriori (MAP)** [^8]:

$$\
\hat{h}_{MAP} = \underset{h \in H}{\operatorname{argmax}} p(h|D)\
$$
[^9]

A estimativa MAP pode ser encontrada maximizando o produto $p(D|h)p(h)$, ou equivalentemente, a soma dos logaritmos [^10]:

$$\
\hat{h}_{MAP} = \underset{h \in H}{\operatorname{argmax}} [\log p(D|h) + \log p(h)] \quad \quad (3.6)\
$$
[^10]

Quando a quantidade de dados $N$ é grande, o termo $\log p(D|h)$, que tipicamente cresce com $N$ (pois $p(D|h) \approx (1/|h|)^N$), domina o termo $\log p(h)$, que é constante em relação a $N$ [^11]. Neste caso, *os dados sobrepujam o prior* (*data overwhelms the prior*) [^12], e a estimativa MAP converge para a **Maximum Likelihood Estimate (MLE)** [^11]:

$$\
\hat{h}_{MLE} = \underset{h \in H}{\operatorname{argmax}} p(D|h) = \underset{h \in H}{\operatorname{argmax}} \log p(D|h) \quad \quad (3.7)\
$$
[^11]

Se a verdadeira hipótese geradora dos dados estiver contida no espaço de hipóteses $H$, tanto a estimativa MAP quanto a MLE convergirão para essa hipótese verdadeira com dados suficientes, tornando a inferência Bayesiana e a estimação por máxima verossimilhança **consistentes** (*consistent estimators*) [^14]. Diz-se também que o espaço de hipóteses é **identificável no limite** (*identifiable in the limit*) [^14].

**Relação com a Predição**

Embora a posterior $p(h|D)$ represente o estado interno de crença do aprendiz, seu valor prático reside na capacidade de fazer predições sobre novas instâncias $\tilde{x}$. A distribuição preditiva posterior $p(\tilde{x} \in C | D)$ (discutida em 3.2.4) utiliza a posterior sobre as hipóteses para ponderar as predições de cada hipótese individual, um processo conhecido como **Bayes Model Averaging (BMA)** [^17]. Alternativamente, pode-se usar uma **plug-in approximation** baseada na estimativa MAP $\hat{h}_{MAP}$ [^20]. A posterior $p(h|D)$ é, portanto, o elo crucial entre a observação de dados passados e a predição de eventos futuros.

### Conclusão

A probabilidade posterior $p(h|D)$ é o resultado fundamental da aplicação da regra de Bayes no aprendizado de conceitos. Ela quantifica a plausibilidade de cada hipótese $h$ após a observação dos dados $D$, integrando de forma coerente o conhecimento prévio encapsulado no prior $p(h)$ e a evidência empírica fornecida pela likelihood $p(D|h)$. A dinâmica entre prior e likelihood, governada pelo **size principle** e pela noção de "naturalidade conceitual", permite explicar fenômenos como a indução rápida a partir de poucos exemplos (e.g., o *number game*). Com dados suficientes, a posterior tende a se concentrar na estimativa MAP, que por sua vez converge para a MLE, ilustrando como as crenças Bayesianas são progressivamente refinadas pela evidência. Compreender a probabilidade posterior é, portanto, essencial para entender como um agente Bayesiano aprende e generaliza a partir de dados discretos.

### Referências

[^1]: Página 67, Seção 3.2.1 Likelihood.
[^2]: Página 66, Fim da Seção 3.2.
[^3]: Página 67, Seção 3.2.2 Prior.
[^4]: Página 68, Seção 3.2.3 Posterior, Equação (3.3).
[^5]: Página 68, Seção 3.2.3 Posterior, parágrafo após Equação (3.3).
[^6]: Página 69, Figura 3.2.
[^7]: Página 68, Seção 3.2.3 Posterior, parágrafo sobre Figura 3.3.
[^8]: Página 68, Seção 3.2.3 Posterior, último parágrafo antes da Equação (3.4).
[^9]: Página 68, Seção 3.2.3 Posterior, Equações (3.4) e (3.5).
[^10]: Página 69, Equação (3.6).
[^11]: Página 69, Equação (3.7) e texto anterior.
[^12]: Página 69, última frase antes da Seção 3.2.4 (implícito na convergência MAP->MLE). O texto diz explicitamente "data overwhelms the prior".
[^13]: Página 69, Legenda da Figura 3.2.
[^14]: Página 70, parágrafo após Figura 3.3.
[^15]: Página 70, Figura 3.3 e legenda.
[^16]: Página 71, Seção 3.2.4 Posterior predictive distribution, primeiro parágrafo.
[^17]: Página 71, Seção 3.2.4 Posterior predictive distribution, Equação (3.8) e texto seguinte.
[^18]: Página 71, Figura 3.4 e legenda.
[^19]: Página 71, Seção 3.2.4 Posterior predictive distribution, último parágrafo.
[^20]: Página 72, Equação (3.9) e texto seguinte.
[^21]: Página 72, parágrafo após Equação (3.9).
[^22]: Página 72, Seção 3.2.5 A more complex prior, Equação (3.10).

<!-- END -->