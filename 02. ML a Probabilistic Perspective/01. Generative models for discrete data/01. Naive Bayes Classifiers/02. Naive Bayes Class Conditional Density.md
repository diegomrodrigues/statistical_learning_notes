## Forma da Densidade Condicional de Classe em Classificadores Naive Bayes

### Introdução
Em classificadores Naive Bayes (NBC), a especificação da forma da densidade condicional de classe, $p(x|y = c, \theta)$, é crucial para determinar como os dados são modelados dentro de cada classe [^18]. Esta densidade define o tipo de dados que esperamos observar em cada classe e depende do tipo de cada *feature* ou característica. Este capítulo explora como diferentes tipos de *features* influenciam a escolha da distribuição para modelar a densidade condicional de classe.

### Conceitos Fundamentais

A escolha da distribuição para a densidade condicional de classe em um NBC depende do tipo de cada *feature* [^18]. A seguir, exploramos as opções mais comuns:

1.  **Features com Valores Reais:** Para *features* que assumem valores reais, a distribuição **Gaussiana** é frequentemente utilizada [^18]. Isso implica que, para cada classe *c*, assume-se que os valores da *feature* *j* são amostrados de uma distribuição normal com média $\mu_{jc}$ e variância $\sigma_{jc}^2$. Matematicamente, isso é expresso como:

    $$     p(x_j|y = c, \theta) = N(x_j|\mu_{jc}, \sigma_{jc}^2)     $$

    onde $N(x_j|\mu_{jc}, \sigma_{jc}^2)$ representa a densidade de probabilidade da distribuição Gaussiana avaliada em $x_j$ com média $\mu_{jc}$ e variância $\sigma_{jc}^2$. O modelo completo é então:

    $$     p(x|y = c, \theta) = \prod_{j=1}^{D} N(x_j|\mu_{jc}, \sigma_{jc}^2)     $$

    onde *D* é o número total de *features* [^18].

2.  **Features Binárias:** Para *features* binárias, que assumem valores 0 ou 1, a distribuição de **Bernoulli** é apropriada [^18]. Neste caso, cada *feature* representa a ocorrência ou não de um evento, e a probabilidade de ocorrência é modelada por um parâmetro $\theta_{jc}$ para cada classe *c*. O modelo resultante é conhecido como o **modelo Naive Bayes Bernoulli Multivariado**. A densidade condicional de classe é dada por:

    $$     p(x_j|y = c, \theta) = Ber(x_j|\theta_{jc}) = \theta_{jc}^{x_j} (1 - \theta_{jc})^{(1-x_j)}     $$

    onde $Ber(x_j|\theta_{jc})$ representa a probabilidade de $x_j$ dado $\theta_{jc}$, e o modelo completo é:

    $$     p(x|y = c, \theta) = \prod_{j=1}^{D} \theta_{jc}^{x_j} (1 - \theta_{jc})^{(1-x_j)}     $$

3.  **Features Categóricas:** Para *features* categóricas que podem assumir um de *K* valores possíveis, a distribuição **Multinoulli** é utilizada [^19]. Neste caso, $\theta_{jc}$ representa um histograma sobre os *K* possíveis valores para a *feature* *j* na classe *c*.  A densidade condicional de classe é dada por:

    $$     p(x_j|y = c, \theta) = Cat(x_j|\theta_{jc})     $$

    onde $Cat(x_j|\theta_{jc})$ representa a probabilidade de $x_j$ dado $\theta_{jc}$, e o modelo completo é:

    $$     p(x|y = c, \theta) = \prod_{j=1}^{D} Cat(x_j|\theta_{jc})     $$

### Conclusão
A escolha da forma da densidade condicional de classe em um classificador Naive Bayes é crucial e depende diretamente do tipo de cada *feature*. A utilização de distribuições Gaussianas para *features* com valores reais e distribuições de Bernoulli para *features* binárias são abordagens comuns e eficazes. A escolha apropriada garante que o modelo capture as características inerentes dos dados, permitindo uma classificação mais precisa e eficiente. A flexibilidade do NBC permite a combinação de diferentes tipos de *features*, tornando-o uma ferramenta versátil para diversos problemas de classificação [^19].

### Referências
[^18]: Page 82, Chapter 3
[^19]: Page 83, Chapter 3
<!-- END -->