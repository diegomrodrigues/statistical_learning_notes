## Bayesian Naive Bayes Classifiers: Addressing Overfitting with Factored Priors

### Introdução
Como discutido anteriormente, os classificadores Naive Bayes (NBCs) são modelos generativos simples e eficientes para a classificação de dados discretos [^82]. No entanto, a Estimativa de Máxima Verossimilhança (MLE) pode levar ao *overfitting*, especialmente quando o conjunto de dados é pequeno ou quando há muitas características (features) [^84]. Para mitigar esse problema, uma abordagem Bayesiana com *priors* (distribuições a priori) fatorados pode ser empregada [^85]. Este capítulo explora como a adoção de *priors* fatorados em NBCs Bayesianos aborda o *overfitting* e melhora a generalização.

### Conceitos Fundamentais

#### Overfitting e MLE em NBCs
A estimativa de máxima verossimilhança (MLE) em classificadores Naive Bayes pode levar ao *overfitting*, especialmente quando o conjunto de dados é limitado [^84]. O *overfitting* ocorre quando o modelo se ajusta muito aos dados de treinamento e, portanto, tem um desempenho ruim em dados não vistos. Em NBCs, o *overfitting* pode resultar em estimativas de probabilidade extremas (próximas de 0 ou 1) para determinadas características (features) em determinadas classes.

#### Abordagem Bayesiana com Priors Fatorados
Para combater o *overfitting*, uma abordagem Bayesiana é adotada [^85]. Em vez de encontrar uma única estimativa de ponto para os parâmetros, a inferência Bayesiana calcula uma distribuição posterior sobre os parâmetros, dada os dados e uma distribuição a priori. Um *prior* fatorado assume a forma:

$$np(\theta) = p(\pi) \prod_{j=1}^D \prod_{c=1}^C p(\theta_{jc})$$

onde:
- $\theta$ representa todos os parâmetros do modelo.
- $\pi$ é o *prior* da classe.
- $\theta_{jc}$ representa os parâmetros para a característica *j* na classe *c*.
- $D$ é o número de características (features).
- $C$ é o número de classes.

Essa fatoração assume que os parâmetros para diferentes características e classes são independentes a priori [^85].

#### Escolha de Priors Conjugados
Para simplificar os cálculos, *priors* conjugados são frequentemente usados. Um *prior* conjugado é uma distribuição que, quando multiplicada pela função de verossimilhança, resulta em uma distribuição posterior da mesma forma. Para NBCs com características (features) binárias, um *prior* de Dirichlet é usado para $\pi$, e *priors* Beta são usados para cada $\theta_{jc}$ [^85].

**Dirichlet Prior para o Prior da Classe ($\pi$)**:
O *prior* de Dirichlet é uma distribuição sobre o simplex de probabilidade, tornando-o adequado para modelar *priors* de classe. A distribuição de Dirichlet é parametrizada por um vetor $\alpha = (\alpha_1, \alpha_2, ..., \alpha_C)$, onde cada $\alpha_c > 0$. A densidade de probabilidade é dada por:

$$np(\pi|\alpha) = \frac{1}{B(\alpha)} \prod_{c=1}^C \pi_c^{\alpha_c - 1}$$

onde $B(\alpha)$ é a função Beta multivariada.

**Beta Prior para os Parâmetros da Característica ($\theta_{jc}$)**:
O *prior* Beta é uma distribuição sobre o intervalo [0, 1], tornando-o adequado para modelar probabilidades. A distribuição Beta é parametrizada por dois parâmetros de forma, $\beta_0$ e $\beta_1$, ambos maiores que 0. A densidade de probabilidade é dada por:

$$np(\theta_{jc}|\beta_0, \beta_1) = \frac{1}{B(\beta_0, \beta_1)} \theta_{jc}^{\beta_1 - 1} (1 - \theta_{jc})^{\beta_0 - 1}$$

onde $B(\beta_0, \beta_1)$ é a função Beta.

#### Add-One Smoothing (Suavização de Laplace)
Uma escolha comum para os parâmetros dos *priors* Beta e Dirichlet é usar *add-one smoothing* (também conhecido como suavização de Laplace). Isso significa definir todos os parâmetros $\alpha_c$ e $\beta_i$ para 1 [^85].

Para o *prior* de Dirichlet: $\alpha_c = 1$ para todas as classes *c*.

Para o *prior* Beta: $\beta_0 = \beta_1 = 1$ para todas as características *j* e classes *c*.

O *add-one smoothing* garante que nenhuma probabilidade seja exatamente zero, mesmo que uma característica (feature) não tenha sido observada em uma determinada classe nos dados de treinamento. Isso ajuda a evitar o problema do *black swan paradox* [^77], onde o modelo atribui probabilidade zero a uma classe se uma determinada característica (feature) não for observada nessa classe durante o treinamento.

#### Distribuição Posterior Fatorada
Com os *priors* conjugados, a distribuição posterior também é fatorada e pode ser expressa analiticamente [^85]. A distribuição posterior para os *priors* da classe é um Dirichlet, e a distribuição posterior para os parâmetros da característica é uma Beta.

##### Posterior para o Prior da Classe
A distribuição posterior para $\pi$ é dada por:

$$np(\pi|D) = Dir(N_1 + \alpha_1, ..., N_C + \alpha_C)$$

onde $N_c$ é o número de exemplos na classe *c* nos dados de treinamento *D*.

##### Posterior para os Parâmetros da Característica
A distribuição posterior para cada $\theta_{jc}$ é dada por:

$$np(\theta_{jc}|D) = Beta(N_{jc} + \beta_1, N_c - N_{jc} + \beta_0)$$

onde $N_{jc}$ é o número de vezes que a característica *j* tem valor 1 na classe *c* nos dados de treinamento *D*, e $N_c$ é o número total de exemplos na classe *c*.

#### Predição com NBCs Bayesianos
Durante o tempo de teste, a probabilidade de uma determinada classe é calculada integrando a distribuição posterior sobre os parâmetros [^85]. Isso é equivalente a calcular a média posterior dos parâmetros e usá-los para fazer previsões.

A probabilidade preditiva posterior é dada por:

$$np(y = c|x, D) \propto \pi_c \prod_{j=1}^D \theta_{jc}^{x_j} (1 - \theta_{jc})^{(1 - x_j)}$$

onde:
- $\pi_c = \frac{N_c + \alpha_c}{N + \sum_c \alpha_c}$ é a média posterior para o *prior* da classe.
- $\theta_{jc} = \frac{N_{jc} + \beta_1}{N_c + \beta_0 + \beta_1}$ é a média posterior para o parâmetro da característica.

### Conclusão

A adoção de uma abordagem Bayesiana com *priors* fatorados é uma maneira eficaz de evitar o *overfitting* em classificadores Naive Bayes [^85]. Usando *priors* de Dirichlet e Beta, e especialmente com a técnica de *add-one smoothing*, o modelo é regularizado, levando a melhores capacidades de generalização. O modelo resultante é menos propenso a fazer previsões extremas e mais robusto a dados não vistos [^77].

### Referências
[^82]: Capítulo 3, página 82
[^84]: Capítulo 3, página 84
[^85]: Capítulo 3, página 85
[^77]: Capítulo 3, página 77
<!-- END -->