## Incorporating Burstiness with the Dirichlet Compound Multinomial Model in Naive Bayes Classifiers

### Introdução
Em problemas de classificação de documentos, uma representação comum é utilizar vetores binários para indicar a presença de palavras, permitindo modelar a densidade condicional da classe usando um modelo de produto de Bernoulli ou uma distribuição multinomial que conta o número de ocorrências de cada palavra [^88]. No entanto, a distribuição multinomial assume que as ocorrências das palavras são independentes, o que nem sempre é verdade na prática. Para lidar com essa limitação, podemos substituir a densidade condicional da classe multinomial pela densidade **Dirichlet Compound Multinomial (DCM)**, que captura o fenômeno de *burstiness* [^88].

### Conceitos Fundamentais

#### Burstiness e a Necessidade do DCM
O fenômeno de *burstiness* refere-se à tendência de certas palavras ocorrerem em grupos dentro de um documento. Em outras palavras, observar uma ocorrência de uma palavra aumenta a probabilidade de observar outras ocorrências dessa mesma palavra [^88]. A distribuição multinomial padrão não consegue capturar essa dependência, pois assume que cada ocorrência de uma palavra é independente das outras.

A densidade DCM, por outro lado, modela a probabilidade de observar uma determinada contagem de palavras em um documento, levando em consideração a *burstiness*. Ela faz isso introduzindo uma distribuição de Dirichlet como um prior sobre os parâmetros da distribuição multinomial [^88].

#### Detalhes Matemáticos do DCM
A densidade DCM é definida como [^89]:
$$ p(\mathbf{x}_i | y_i = c, \boldsymbol{\alpha}) = \int Mu(\mathbf{x}_i | N_i, \boldsymbol{\theta}_c) Dir(\boldsymbol{\theta}_c | \boldsymbol{\alpha}_c) d\boldsymbol{\theta}_c = \frac{N_i! \prod_{j=1}^D \Gamma(x_{ij} + \alpha_{cj})}{\prod_{j=1}^D x_{ij}! \\ B(\boldsymbol{\alpha}_c)} $$

Onde:
*   $\mathbf{x}_i$ é o vetor de contagem de palavras para o documento *i*.
*   $y_i$ é a classe do documento *i*.
*   $c$ é o índice da classe.
*   $N_i$ é o número total de termos no documento *i*.
*   $\boldsymbol{\theta}_c$ é o vetor de probabilidades das palavras para a classe *c*.
*   $\boldsymbol{\alpha}_c$ é o vetor de parâmetros da distribuição de Dirichlet para a classe *c*.
*   $Mu(\mathbf{x}_i | N_i, \boldsymbol{\theta}_c)$ é a distribuição multinomial.
*   $Dir(\boldsymbol{\theta}_c | \boldsymbol{\alpha}_c)$ é a distribuição de Dirichlet.
*   $B(\boldsymbol{\alpha}_c)$ é a função Beta multivariada.

A intuição por trás dessa fórmula é que a distribuição de Dirichlet atua como um *prior* sobre os parâmetros da distribuição multinomial. Após observar uma ocorrência de uma palavra, as contagens *posteriores* são atualizadas, tornando outra ocorrência dessa palavra mais provável [^89].

#### Implementação no Naive Bayes
Para incorporar o DCM em um classificador Naive Bayes, substituímos a distribuição multinomial padrão pela densidade DCM. As etapas para construir um classificador Naive Bayes com DCM são as seguintes:

1.  **Estimar os parâmetros da distribuição de Dirichlet** $\boldsymbol{\alpha}_c$ para cada classe *c* a partir dos dados de treinamento. Existem métodos de estimação de parâmetros para a distribuição de Dirichlet, como o método dos momentos ou a estimação de máxima verossimilhança (MLE).

2.  **Calcular a probabilidade a posteriori** de cada classe *c* dado um novo documento $\mathbf{x}$ usando a regra de Bayes:

$$ p(y = c | \mathbf{x}, \boldsymbol{\alpha}) \propto p(y = c) p(\mathbf{x} | y = c, \boldsymbol{\alpha}) $$

Onde:

*   $p(y = c)$ é a probabilidade *a priori* da classe *c*.
*   $p(\mathbf{x} | y = c, \boldsymbol{\alpha})$ é a densidade DCM, calculada como mostrado acima.

3.  **Atribuir o documento à classe** com a maior probabilidade *a posteriori*.

#### Vantagens e Desvantagens do DCM
**Vantagens:**

*   Captura o fenômeno de *burstiness*, levando a uma melhor modelagem de documentos.
*   Geralmente, resulta em melhor precisão de classificação em comparação com o Naive Bayes multinomial padrão.

**Desvantagens:**

*   A estimação dos parâmetros da distribuição de Dirichlet pode ser computacionalmente mais complexa do que a estimação dos parâmetros da distribuição multinomial.
*   O modelo DCM tem mais parâmetros do que o modelo multinomial, o que pode levar a *overfitting* se o conjunto de dados de treinamento for pequeno.

### Conclusão
A substituição da distribuição multinomial pela densidade DCM em classificadores Naive Bayes representa uma melhoria significativa na modelagem de documentos, capturando o fenômeno de *burstiness* e, consequentemente, melhorando a precisão da classificação [^89]. Embora a estimação dos parâmetros possa ser mais complexa, os benefícios em termos de precisão geralmente superam as desvantagens.

### Referências
[^88]: Capítulo 3, Seção 3.5.5
[^89]: Capítulo 3, Seção 3.5
<!-- END -->