## Likelihood Function in Discrete Data

### Introdução
Este capítulo se concentra em modelos generativos para dados discretos, com foco em como inferir parâmetros desconhecidos $\theta$ desses modelos [^3]. Expandindo o conceito de aprendizado de conceito Bayesiano [^3], exploraremos a função de verossimilhança (likelihood) e sua aplicação. A função de verossimilhança quantifica a probabilidade de observar os dados fornecidos, assumindo que os dados são independentes e identicamente distribuídos (iid), dado o parâmetro $\theta$ [^introducao]. Neste capítulo, vamos nos aprofundar na função de verossimilhança para dados discretos.

### Conceitos Fundamentais

A **função de verossimilhança** desempenha um papel fundamental na inferência estatística, fornecendo uma medida de quão bem um determinado conjunto de parâmetros explica os dados observados [^introducao]. Matematicamente, a função de verossimilhança é expressa como:

$$ p(D|\theta) = \theta^{N_1} * (1 - \theta)^{N_0} $$

onde:
*   $D$ representa os dados observados.
*   $\theta$ é o parâmetro desconhecido que queremos estimar.
*   $N_1$ é o número de \'caras\' (sucessos) nos dados.
*   $N_0$ é o número de \'coroas\' (falhas) nos dados [^introducao].

Esta fórmula assume que os dados são independentes e identicamente distribuídos (iid), o que significa que cada ponto de dados é independente dos outros e todos seguem a mesma distribuição [^introducao].

**Exemplo: Lançamento de Moedas**

Considere o exemplo de lançar uma moeda várias vezes [^3]. Queremos estimar a probabilidade $\theta$ de obter \'cara\'. Se lançarmos a moeda $N$ vezes e observarmos $N_1$ \'caras\' e $N_0$ \'coroas\', a função de verossimilhança será:

$$ p(D|\theta) = \theta^{N_1} (1 - \theta)^{N_0} $$

Esta função nos diz quão provável é observar os resultados específicos que obtivemos, dado um valor específico de $\theta$.

**Estatísticas Suficientes**

Os valores $N_1$ e $N_0$ são chamados de **estatísticas suficientes** dos dados [^3]. Isso significa que eles contêm toda a informação relevante dos dados necessária para inferir $\theta$. Em outras palavras, não precisamos conhecer a sequência exata de \'caras\' e \'coroas\', apenas o número total de cada um.

Formalmente, dizemos que $s(D)$ é uma estatística suficiente para os dados $D$ se $p(\theta|D) = p(\theta|s(D))$ [^3]. Se usarmos um prior uniforme, isso é equivalente a dizer que $p(D|\theta) \propto p(s(D)|\theta)$ [^3]. Consequentemente, se tivermos dois conjuntos de dados com as mesmas estatísticas suficientes, inferiremos o mesmo valor para $\theta$ [^3].

**Verossimilhança Bernoulli**

Suponha que $X_i \sim Ber(\theta)$, onde $X_i = 1$ representa "caras", $X_i = 0$ representa "coroas" e $\theta \in [0, 1]$ é o parâmetro de taxa (probabilidade de caras) [^3]. Se os dados são iid, a verossimilhança tem a forma

$$\np(D|\theta) = \theta^{N_1}(1 - \theta)^{N_0}$$\n
onde $N_1$ é o número de caras e $N_0$ é o número de coroas.

**Função Log-Verossimilhança (Log-Likelihood)**

Em muitas aplicações práticas, é mais conveniente trabalhar com o logaritmo da função de verossimilhança, conhecido como função log-verossimilhança. Isso ocorre porque o logaritmo transforma produtos em somas, o que simplifica os cálculos e evita problemas de underflow numérico. A função log-verossimilhança correspondente ao nosso exemplo é:

$$ log \\, p(D|\theta) = N_1 log(\theta) + N_0 log(1 - \theta) $$

Maximizar a função log-verossimilhança é equivalente a maximizar a função de verossimilhança original, pois o logaritmo é uma função monotônica crescente.

**Exemplo: Estimativa de Máxima Verossimilhança (MLE)**
Para encontrar a estimativa de máxima verossimilhança (MLE) de $\theta$, derivamos a função log-verossimilhança em relação a $\theta$ e igualamos a zero:

$$ \frac{d}{d\theta} log \\, p(D|\theta) = \frac{N_1}{\theta} - \frac{N_0}{1 - \theta} = 0 $$

Resolvendo para $\theta$, obtemos:

$$ \hat{\theta}_{MLE} = \frac{N_1}{N_1 + N_0} $$

Este resultado mostra que a MLE de $\theta$ é simplesmente a proporção de \'caras\' no conjunto de dados.

### Conclusão

A função de verossimilhança é uma ferramenta essencial para inferência estatística, permitindo-nos estimar parâmetros desconhecidos com base nos dados observados [^introducao]. No contexto de modelos generativos para dados discretos, a função de verossimilhança quantifica a probabilidade de observar os dados, dado um conjunto específico de parâmetros. Ao maximizar a função de verossimilhança (ou equivalentemente, a função log-verossimilhança), podemos encontrar as estimativas de máxima verossimilhança dos parâmetros, que representam os valores que melhor explicam os dados [^3]. No contexto do aprendizado Bayesiano, a verossimilhança é combinada com um *prior* para calcular um *posterior*, que representa nossa crença atualizada sobre os parâmetros após observar os dados [^3].

### Referências
[^3]: Capítulo 3, "Generative models for discrete data"
[^introducao]: Introdução ao conceito de *likelihood*.
<!-- END -->