## Regularização em Redes Neurais Feedforward
### Introdução
As Redes Neurais Feedforward (MLPs) são modelos poderosos, mas propensos a *overfitting*, especialmente quando o número de nós é grande [^1]. Para mitigar este problema, técnicas de regularização são empregadas para promover modelos mais simples e melhorar a generalização [^1, 2, 3]. Este capítulo aborda as técnicas de regularização mais comuns em MLPs, nomeadamente *early stopping* e *weight decay*, e como elas se inserem no contexto da estimação MAP [^1].

### Conceitos Fundamentais

#### Overfitting e a Necessidade de Regularização
O *overfitting* ocorre quando um modelo se ajusta excessivamente aos dados de treinamento, capturando ruído e variações específicas da amostra que não se generalizam bem para dados não vistos [^1]. Em MLPs, o *overfitting* pode ser exacerbado pelo grande número de parâmetros, permitindo que o modelo memorize os dados de treinamento em vez de aprender padrões subjacentes [^1, 2].

#### Early Stopping
O *early stopping* é uma técnica de regularização que monitora o erro em um conjunto de validação durante o treinamento [^1, 3]. A ideia é interromper o treinamento quando o erro no conjunto de validação começar a aumentar, indicando que o modelo está começando a se ajustar demais aos dados de treinamento [^1, 3].

Formalmente, o processo de treinamento é interrompido na época $t^*$ tal que:

$$t^* = \underset{t}{\text{argmin}} \; \text{Erro}_{\text{validação}}(t)$$

onde $\text{Erro}_{\text{validação}}(t)$ é o erro no conjunto de validação na época $t$ [^1, 3].

**Caixa de Destaque:** O *early stopping* é uma técnica simples, mas eficaz, que não requer modificações na arquitetura do modelo ou na função de custo [^1, 3].

#### Weight Decay (Regularização L2)
O *weight decay*, também conhecido como regularização L2, impõe uma penalidade aos parâmetros do modelo durante o treinamento [^1, 3]. A penalidade é proporcional à soma dos quadrados dos pesos, incentivando pesos menores e modelos mais simples [^1, 3].

A função de custo regularizada é dada por:

$$J(\theta) = \text{NLL}(\theta) + \frac{\alpha}{2} ||\theta||_2^2$$

onde $\text{NLL}(\theta)$ é a *Negative Log-Likelihood*, $\theta$ representa os parâmetros do modelo, $\alpha$ é o parâmetro de regularização (força do *weight decay*), e $||\theta||_2^2$ é a norma L2 ao quadrado dos parâmetros [^1, 3].

A norma L2 ao quadrado é definida como:

$$||\theta||_2^2 = \sum_{i=1}^{P} \theta_i^2$$

onde $P$ é o número total de parâmetros no modelo [^1, 3].

**Caixa de Destaque:** O *weight decay* é equivalente a impor um *prior* Gaussiano N(0, α⁻¹I) nos parâmetros do modelo, dentro da estrutura da estimação MAP [^1].

#### Estimação MAP e Priors Gaussianos
A estimação MAP (Maximum A Posteriori) busca encontrar os parâmetros do modelo que maximizam a probabilidade *a posteriori*, que é proporcional ao produto da *likelihood* e do *prior* [^1]. Quando um *prior* Gaussiano N(0, α⁻¹I) é usado, a estimação MAP resulta na minimização da função de custo regularizada com *weight decay* [^1].

A probabilidade *a posteriori* é dada por:

$$p(\theta|D) \propto p(D|\theta)p(\theta)$$

onde $p(D|\theta)$ é a *likelihood* dos dados dado os parâmetros $\theta$, e $p(\theta)$ é o *prior* sobre os parâmetros [^1].

Se $p(\theta) = N(0, \alpha^{-1}I)$, então:

$$p(\theta|D) \propto \exp(-\text{NLL}(\theta)) \exp(-\frac{\alpha}{2} ||\theta||_2^2)$$

Maximizar $p(\theta|D)$ é equivalente a minimizar $J(\theta) = \text{NLL}(\theta) + \frac{\alpha}{2} ||\theta||_2^2$ [^1].

### Conclusão

As técnicas de regularização, como *early stopping* e *weight decay*, são essenciais para prevenir o *overfitting* em MLPs e melhorar sua capacidade de generalização [^1, 3]. O *early stopping* monitora o erro de validação e interrompe o treinamento quando o *overfitting* começa a ocorrer, enquanto o *weight decay* impõe uma penalidade aos pesos grandes, incentivando modelos mais simples [^1, 3]. O *weight decay* pode ser interpretado como a imposição de um *prior* Gaussiano nos parâmetros dentro da estrutura da estimação MAP [^1]. A escolha adequada do parâmetro de regularização $\alpha$ é crucial para o desempenho do modelo e pode ser feita através de validação cruzada ou métodos *empirical Bayes* [^1].

### Referências
[^1]: Página 1
[^2]: Página 2
[^3]: Página 3
<!-- END -->