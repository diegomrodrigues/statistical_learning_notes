## Adaptive Basis Function Models: A Deep Dive

### Introdução
Este capítulo explora os **Adaptive Basis-Function Models (ABM)**, uma alternativa poderosa aos métodos de kernel para a criação de modelos não lineares para regressão e classificação [^1]. Diferentemente dos métodos de kernel, que dependem da escolha de uma função kernel apropriada para medir a similaridade entre os dados, os ABMs aprendem diretamente *features* úteis dos dados de entrada [^1]. Este capítulo se aprofundará na estrutura, nas técnicas de estimação e em modelos específicos de ABMs, como Classification and Regression Trees (CART) e modelos *boosting*.

### Conceitos Fundamentais
Um ABM assume a forma [^1]:
$$
f(x) = w_0 + \sum_{i=1}^{M} w_i \phi_i(x)
$$
onde $\phi_i(x)$ representa as funções de base aprendidas, $w_i$ são os pesos associados a cada função de base, e $w_0$ é um termo de bias [^1]. O objetivo principal dos ABMs é eliminar a necessidade de *kernels* aprendendo diretamente *features* úteis dos dados de entrada [^1]. Tanto os coeficientes ($w_i$) quanto as funções de base ($\phi_i(x)$) são adaptados durante o processo de aprendizagem [^1].

As funções de base são tipicamente **paramétricas**, o que significa que são definidas por um conjunto de parâmetros $v_m$ que são aprendidos a partir dos dados [^1]. A função de base paramétrica pode ser escrita como [^1]:
$$
\phi_m(x) = \phi(x; v_m)
$$
O conjunto completo de parâmetros do modelo inclui tanto os pesos das funções de base quanto os parâmetros que definem as próprias funções de base, denotado por $\theta = (w_0, w_{1:M}, \{v_m\}_{m=1}^M)$ [^1].

A **estimação de $\theta$** frequentemente envolve a computação de uma **Maximum Likelihood Estimate (MLE) localmente ótima** ou uma **Maximum A Posteriori (MAP) estimate** [^1]. Isso ocorre porque o modelo é não linear nos parâmetros [^1]. A não linearidade permite a regressão e classificação não linear, dispensando a necessidade de *kernels* [^1].

#### Classification and Regression Trees (CART) como ABMs
Os Classification and Regression Trees (CART) podem ser vistos como um tipo específico de ABM [^2]. Em um modelo CART, o espaço de entrada é recursivamente particionado, e um modelo local é definido em cada região resultante [^2]. O modelo pode ser representado por uma árvore, com uma folha por região [^2].

A árvore CART particiona o espaço de entrada em regiões $R_m$, e a resposta em cada região é dada por um peso $w_m$ [^2]. Assim, o modelo CART pode ser expresso como [^2]:
$$
f(x) = \mathbb{E}[y|x] = \sum_{m=1}^{M} w_m I(x \in R_m) = \sum_{m=1}^{M} w_m \phi(x; v_m)
$$
onde $I(x \in R_m)$ é uma função indicadora que vale 1 se $x$ pertence à região $R_m$ e 0 caso contrário, e $v_m$ codifica a escolha da variável para dividir e o valor do limiar [^2].

#### Boosting
*Boosting* é um algoritmo ganancioso para ajustar modelos de função de base adaptativa da forma na Equação (16.3) [^1, 12]:
$$
f(x) = w_0 + \sum_{m=1}^{M} w_m \phi_m(x)
$$
onde os $\phi_m$ são gerados por um algoritmo chamado um *weak learner* ou *base learner* [^12]. O algoritmo funciona aplicando o *weak learner* sequencialmente a versões ponderadas dos dados, onde mais peso é dado a exemplos que foram classificados incorretamente por rodadas anteriores [^12].

Esse *weak learner* pode ser qualquer algoritmo de classificação ou regressão, mas é comum usar um modelo CART [^12]. Em 1998, o falecido Leo Breiman chamou de *boosting*, onde o *weak learner* é uma árvore de decisão rasa, o "melhor classificador *off-the-shelf* do mundo" [^12]. Isso é suportado por uma extensa comparação empírica de 10 classificadores diferentes em Caruana e Niculescu-Mizil 2006, que mostraram que as árvores de decisão impulsionadas eram as melhores tanto em termos de erro de classificação quanto em termos de produção de probabilidades bem calibradas, conforme julgado pelas curvas ROC [^12].

### Conclusão
Os Adaptive Basis-Function Models oferecem uma abordagem flexível e poderosa para a modelagem não linear [^1]. Ao aprender diretamente as *features* dos dados, os ABMs eliminam a necessidade de escolher funções de *kernel* apropriadas, permitindo que o modelo se adapte aos dados de forma mais eficaz [^1]. Modelos específicos, como CART e *boosting*, demonstram a versatilidade e o potencial dos ABMs em diversas aplicações [^2, 12].

### Referências
[^1]: Capítulo 16, Introdução e Seção 16.1
[^2]: Capítulo 16, Seção 16.2.1
[^12]: Capítulo 16, Seção 16.4
<!-- END -->