{
  "topics": [
    {
      "topic": "Adaptive Basis Function Models",
      "sub_topics": [
        "Adaptive basis-function models (ABM) learn useful features directly from input data, offering an alternative to kernel methods by creating models of the form f(x) = w\u2080 + \u03a3 w\u1d62\u03c6\u1d62(x), where \u03c6\u1d62(x) represents learned basis functions. ABMs aim to dispense with kernels altogether by directly learning useful features from the input data, expressed as a linear combination of basis functions, where the coefficients and the basis functions themselves are adapted during the learning process. The basis functions are typically parametric, meaning they are defined by a set of parameters v\u2098 that are learned from data, and the entire parameter set of the model includes both the weights of the basis functions and the parameters defining the basis functions themselves, denoted by \u03b8 = (w\u2080, w\u2081:M, {v\u2098}\u2098=\u2081). Estimating \u03b8 often involves computing a locally optimal Maximum Likelihood Estimate (MLE) or Maximum A Posteriori (MAP) estimate due to the model's non-linearity in the parameters, enabling nonlinear regression and classification and dispensing with kernels altogether. Parametric basis functions in ABMs can be written as \u03c6\u2098(x) = \u03c6(x; v\u2098), where v\u2098 represents the parameters, enabling a locally optimal Maximum Likelihood Estimation (MLE) or Maximum A Posteriori (MAP) estimation of \u03b8.",
        "Classification and Regression Trees (CART), also known as decision trees, recursively partition the input space and define a local model within each region, represented as a tree structure where each leaf corresponds to a region in the input space. CART models offer interpretability, handle mixed data types, are insensitive to monotone input transformations, perform automatic variable selection, are robust to outliers, and scale well. The CART approach involves axis-parallel splits to partition the input space into regions, associating a mean response with each region for regression or a distribution over class labels for classification, with the model expressed as f(x) = \u03a3 w\u2098I(x \u2208 R\u2098), where R\u2098 is the m'th region and w\u2098 is the mean response in that region. The result of axis-parallel splits partitions the space into regions, and a mean response is associated with each region, resulting in a piecewise constant surface. The model can be written as f(x) = E[y|x] = \u03a3 w\u2098I(x \u2208 R\u2098) = \u03a3 w\u2098\u03c6(x; v\u2098), where R\u2098 is the m'th region, w\u2098 is the mean response in that region, and v\u2098 encodes the choice of variable and threshold value for splitting. The first node checks if x1 is less than a threshold t1, leading to axis-parallel splits that partition the 2d space into regions, with the model expressed as f(x) = E[y|x] = \u03a3 WmI(x \u2208 Rm) = \u03a3 Wm\u03c6(x; vm).",
        "Growing a tree involves finding the optimal partitioning of the data, which is an NP-complete problem, so a greedy procedure is commonly used to compute a locally optimal Maximum Likelihood Estimate (MLE). The split function chooses the best feature and value for that feature by minimizing the cost function: (j*, t*) = argmin min cost({x\u1d62, y\u1d62 : x\u1d62\u2c7c < t}) + cost({x\u1d62, y\u1d62 : x\u1d62\u2c7c > t}). The cost function for a given dataset is defined as cost(D) = \u03a3(y\u1d62 - \u0233)\u00b2, where \u0233 is the mean of the response variable. Growing a tree involves recursively partitioning data, balancing data fragmentation, which can lead to overfitting, and the reduction in cost, which is defined as \u0394 = (cost(D) - (|DL|/|D|)cost(DL) + (|DR|/|D|)cost(DR)) / cost(D), with the process continuing until the tree exceeds maximum depth, the response distribution is homogeneous, or the number of examples is too small. The split function in CART chooses the best feature and its value by minimizing the cost function, defined as (j*, t*) = argmin\u2c7c\u2208{1,...,D} min\u209c\u2208T\u2c7c cost({x\u1d62, y\u1d62 : x\u1d62\u2c7c < t}) + cost({x\u1d62, y\u1d62 : x\u1d62\u2c7c > t}), where cost(D) = \u03a3\u1d62\u2208D(y\u1d62 \u2013 y)\u00b2 in the regression setting, and various methods exist for measuring the quality of a split in classification, including the misclassification rate, entropy, and Gini index. Methods like CART, C4.5, and ID3 are popular implementations that choose the best feature and value for splitting data based on cost functions.",
        "Classification cost involves fitting a multinoulli model to the data in the leaf satisfying the test X\u2c7c < t by estimating class-conditional probabilities \u03c0\u0302c = (1/|D|) \u03a3 I(y\u1d62 = c). Common error measures for evaluating a proposed partition include misclassification rate (1 - \u03c0\u0302c), entropy (H(\u03c0) = -\u03a3 \u03c0\u0302c log \u03c0\u0302c), and the Gini index (\u03a3 \u03c0\u0302c(1 - \u03c0\u0302c)). Minimizing entropy is equivalent to maximizing information gain between the test and the class label.",
        "To prevent overfitting, the tree-growing process can be stopped if the decrease in error is insufficient to justify the added complexity, although this can be myopic. A better approach is to grow a full tree and then perform pruning, which involves evaluating the cross-validated error on each subtree and picking the tree whose CV error is within 1 standard error of the minimum. Tree pruning prevents overfitting by stopping tree growth if the error decrease is insufficient or by pruning branches that minimally increase error, improving generalization and simplifying the model. Techniques like cross-validation help determine how far to prune by evaluating error on subtrees. To prevent overfitting in CART, we can stop growing the tree if the decrease in error is insufficient, or we can grow a full tree and then prune it, evaluating cross-validated error on each subtree and picking the tree whose cross-validated error is within one standard error of the minimum, as the optimal partitioning of data is NP-complete (Hyafil and Rivest 1976). Stopping heuristics in tree growing prevent overfitting by considering factors such as the reduction in cost being too small, the tree exceeding the maximum desired depth, the distribution of the response in either DL or DR being sufficiently homogeneous, or the number of examples in either DL or DR being too small.",
        "Ensemble methods like bagging (bootstrap aggregating) and random forests are used to reduce variance and improve predictive accuracy by training multiple trees on different subsets of the data and/or randomly chosen subsets of input variables, decorrelating the base learners to enhance variance reduction. Random forests reduce variance by averaging multiple estimates from different trees trained on different subsets of the data, chosen randomly with replacement. This technique, called bagging, can result in highly correlated predictors, so random forests decorrelate the base learners by learning trees based on a randomly chosen subset of input variables. Bagging, or bootstrap aggregating, involves re-running the learning algorithm on different subsets of the data, while random forests decorrelate base learners by randomly selecting input variables. However, CART models may have lower predictive accuracy and can be unstable due to the hierarchical tree-growing process, making them high variance estimators, which can be addressed using random forests.",
        "Kernel methods are utilized to construct nonlinear models for regression and classification, where the prediction f(x) is a function of input x and weights w, based on a kernel function \u03ba that measures similarity between data points and prototypes. Kernel methods rely on kernel functions to measure the similarity between data vectors, which can be challenging to define and computationally expensive. The effectiveness of kernel methods relies on a good kernel function to measure similarity between data vectors, and learning the parameters of a kernel function can be achieved by maximizing the marginal likelihood. Kernel methods offer a powerful approach to creating non-linear models for regression and classification, where the prediction is determined by a weighted sum of kernel functions evaluated at the input data points, effectively performing template matching against stored prototypes.",
        "Boosting is a greedy algorithm for fitting adaptive basis-function models, where the \u03c6\u2098 are generated by a weak learner or base learner. The algorithm applies the weak learner sequentially to weighted versions of the data, giving more weight to misclassified examples. The goal of boosting is to solve the optimization problem: min \u03a3 L(y\u1d62, f(x\u1d62)), where L(y, \u0177) is a loss function, and f is an ABM model. Boosting is a greedy algorithm that fits adaptive basis-function models by sequentially applying a weak learner to weighted versions of the data, focusing on examples misclassified by earlier rounds, and can be interpreted as gradient descent in function space. Boosting can be seen as a form of l1 regularization, which helps prevent overfitting by eliminating irrelevant features, and it maximizes the margin on the training data, as proven by (Schapire et al. 1998; Ratsch et al. 2001), and generalized to other loss functions, such as log-loss, by (Rosset et al. 2004).",
        "Forward stagewise additive modeling involves initializing f\u2080(x) and then, at each iteration m, computing (\u03b2\u2098, \u03b3\u2098) = argmin \u03a3 L(y\u1d62, f\u2098\u208b\u2081(x\u1d62) + \u03b2\u03c6(x; \u03b3)) and setting f\u2098(x) = f\u2098\u208b\u2081(x) + \u03b2\u2098\u03c6(x; \u03b3\u2098). This process is continued for a fixed number of iterations M, which is the main tuning parameter of the method. Early stopping can be used to prevent overfitting, or model selection criteria like AIC or BIC.",
        "In the regression setting, the cost is defined as cost(D) = \u03a3\u1d62\u2208D (y\u1d62 - \u0233)\u00b2, where \u0233 is the mean of the response variable. Alternatively, a linear regression model can be fit for each leaf, using features chosen on the path from the root and measuring residual error.",
        "Alternative convex upper bounds include exponential loss, defined by L(\u0177, f) = exp(-\u0177f), which has some computational advantages over logloss. This leads to the AdaBoost algorithm, which computes the optimal function to add as \u03c6\u2098 = argmin \u03a3 w\u1d62,\u2098 I(\u0177\u1d62 \u2260 \u03c6(x\u1d62)), where w\u1d62,\u2098 are weights. The weights at the next iteration become w\u1d62,\u2098\u208a\u2081 = w\u1d62,\u2098 exp(-\u03b2\u2098\u0177\u1d62\u03c6(x\u1d62)).",
        "Generalized Additive Models (GAMs) create nonlinear models with multiple inputs by summing functions of individual input variables, where each function can be modeled by a scatterplot smoother or regression splines, and the entire model can be mapped to a probability distribution using a link function. Multivariate Adaptive Regression Splines (MARS) extend GAMs by allowing for interaction effects, creating an ANOVA decomposition of the function and using a greedy search to decide which variables to add, fitting models using tensor product basis of regression splines."
      ]
    },
    {
      "topic": "Boosting",
      "sub_topics": [
        "Boosting is a greedy algorithm for fitting adaptive basis-function models, where weak learners or base learners are applied sequentially to weighted versions of the data, giving more weight to misclassified examples, and is supported by extensive empirical comparisons showing its effectiveness in terms of misclassification error and well-calibrated probabilities. The goal of boosting is to solve the optimization problem minf \u03a3 L(yi, f(xi)), where L(y, \u0177) is a loss function and f is an ABM model. The algorithm applies the weak learner sequentially to weighted versions of the data, giving more weight to misclassified examples. Boosting maximizes the margin on the training data. With squared error loss, the optimal estimate is f*(x) = argminf(x) = Ey|x[(Y \u2013 f(x))2] = E[Y|x]; for binary classification, logloss is often used, which provides a convex upper bound on 0-1 loss, and the optimal estimate is f*(x) = 1/2 log(p(\u0177 = 1|x) / p(\u0177 = \u22121|x)), where \u0177 \u2208 {\u22121,+1}.",
        "Forward stagewise additive modeling aims to solve the optimization problem of minimizing the sum of a loss function over the training data, where the model is an ABM, and if squared error loss is used, the optimal estimate is the conditional expectation E[Y|x].",
        "The boosting algorithm initializes by defining fo(x) = argmin \u03a3 L(yi, f(xi; 1)), then computes (\u03b2m, \u03b3m) = argmin \u03a3 L(yi, fm-1(xi) + \u03b2\u03c6(x; \u03b3)) at each iteration m, sets fm(x) = fm-1(x) + \u03b2m\u03c6(x; \u03b3m), and continues for a fixed number of iterations M, which is a tuning parameter. Forward stagewise additive modeling is used, where we do not go back and adjust earlier parameters, and we can perform \"partial updates\" of the form fm(x) = fm-1(x) + \u03bd\u03b2m\u03c6(x; \u03b3m), where 0 < \u03bd < 1 is a step-size parameter, commonly set to a small value (e.g., 0.1), in a technique called shrinkage.",
        "L2boosting is a boosting technique where squared error loss is used, and the new basis function is found by using the weak learner to predict the current residual, making it equivalent to least squares boosting. In the case of L2boosting with squared error loss, the loss has the form L(yi, fm-1(xi) + \u03b2\u03c6(xi; \u03b3)) = (rim \u2013 \u03c6(xi; \u03b3))2, where rim = yi \u2013 fm-1(xi) is the current residual, and we can find the new basis function by using the weak learner to predict rm.",
        "AdaBoost is a boosting algorithm for binary classification problems with exponential loss, where the optimal function to add is determined by applying the weak learner to a weighted version of the dataset, and the weights are updated based on the classification error. AdaBoost minimizes Lm(\u03c6) = \u03a3 exp[-yi(fm-1(xi) + \u03b2\u03c6(xi))] = \u03a3 wi,m exp(-\u03b2\u0177i\u03c6(xi)) at step m, where wi,m = exp(-yi.fm-1(xi)) is a weight applied to datacase i, and \u0177i \u2208 {\u22121,+1}, with the optimal function to add being \u03c6m = argmin \u03a3 Wi,mI(\u0177i \u2260 \u03c6(xi)), and \u03b2m = 1/2 log((1 \u2013 errm) / errm).",
        "LogitBoost addresses the issue of exponential loss putting too much weight on misclassified examples by using logloss instead, which punishes mistakes linearly and allows for the extraction of probabilities from the final learned function.",
        "Gradient boosting is a generic version of boosting that derives a new version of boosting for every different loss function, where the gradient is computed and a weak learner is fitted to approximate the negative gradient signal, offering a way to handle various loss functions including robust regression and Poisson regression."
      ]
    },
    {
      "topic": "Feedforward Neural Networks (Multilayer Perceptrons)",
      "sub_topics": [
        "Feedforward neural networks, also known as multilayer perceptrons (MLP), are a series of logistic regression models stacked on top of each other, with the final layer being either another logistic regression or a linear regression model, depending on whether the problem is classification or regression. MLPs are structured as a series of logistic regression models stacked on top of each other, using a non-linear activation or transfer function in the hidden layers to learn complex patterns. An MLP with two layers can be expressed as p(y|x, \u03b8) = N(y|w^Tz(x), \u03c3^2) and z(x) = g(Vx), where g is a non-linear activation or transfer function. The parameters of the MLP model are \u03b8 = (V, W), the first and second layer weight matrices, and the overall model can be written as xn \u2192 V an \u2192g zn \u2192W bn \u2192h \u0177n, where bn = Wzn is the pre-synaptic output layer, and \u0177n = h(bn) is the post-synaptic output layer, and the algorithm is known as backpropagation because the layer 1 errors can be computed by passing the layer 2 errors back through the W matrix. For example, if we have two layers, and we are solving a regression problem, the model has the form p(y|x, \u03b8) = N(y|w^Tz(x), \u03c3\u00b2), z(x) = g(Vx) = [g(v^T\u2081x),..., g(v^THx)], where g is a non-linear activation or transfer function.",
        "The hidden units in MLPs are for learning non-linear combinations of the original inputs, called feature extraction or feature construction, which is particularly useful when original features are not individually informative, and the hidden layer (a deterministic function of the input) is defined as z(x) = \u03c6(x, V), where H is the number of hidden units, V is the weight matrix from the inputs to the hidden nodes, and w is the weight vector from the hidden nodes to the output. The purpose of the hidden units is to learn non-linear combinations of the original inputs; this is called feature extraction or feature construction.",
        "Convolutional neural networks are a form of MLP particularly well-suited to 1D signals like speech or text, or 2D signals like images, and have local receptive fields, with weights tied or shared across the image to reduce the number of parameters, exhibiting translation invariance. A convolutional neural network is an MLP well-suited to 1D signals like speech or text, or 2D signals like images, in which the hidden units have local receptive fields and the weights are tied or shared across the image to reduce parameters, resulting in translation invariance, enabling the network to classify patterns regardless of their location inside the input image. CNNs achieve translation invariance by sharing weights across different locations in the input, allowing the network to detect patterns regardless of their position, which is crucial for tasks like image recognition where the location of an object within the image should not affect its classification. CNNs are a specialized type of MLP well-suited for processing data with a grid-like topology, such as images or audio, by using convolutional layers to automatically learn spatial hierarchies of features, enabling them to capture complex patterns with fewer parameters compared to fully connected networks.",
        "The backpropagation algorithm is used to compute the gradient vector of the NLL in MLPs by applying the chain rule of calculus, where the errors are computed locally and passed backwards through the network, allowing for the adjustment of weights to minimize the loss. The backpropagation algorithm (Rumelhart et al. 1986) enables fitting models with hidden layers, and involves computing the gradient vector of the Negative Log-Likelihood (NLL) by applying the chain rule of calculus, and for notational simplicity, we assume a model with just one hidden layer, where xn is the n'th input, an = Vxn is the pre-synaptic hidden layer, and zn = g(an) is the post-synaptic hidden layer. Backpropagation is an algorithm used to compute the gradient vector of the Negative Log-Likelihood (NLL) by applying the chain rule of calculus, allowing for efficient training of neural networks by iteratively adjusting the weights to minimize the error between predicted and actual outputs. The backpropagation algorithm is used to compute the gradient vector of the negative log-likelihood (NLL) by applying the chain rule of calculus, distinguishing between pre- and post-synaptic values of a neuron, and propagating errors back through the network.",
        "Regularization techniques like early stopping and weight decay are used to prevent overfitting in MLPs, where early stopping involves monitoring the error on a validation set and stopping the training procedure when the error starts to increase, and weight decay involves imposing a prior on the parameters to encourage smaller weights and simpler models. Regularization techniques, such as early stopping, weight decay, and consistent Gaussian priors, are used to prevent overfitting in MLPs by adding a penalty term to the NLL objective function that encourages smaller weights and simpler models. To prevent overfitting in neural networks, techniques such as early stopping (monitoring validation error), weight decay (L2 regularization), and consistent Gaussian priors are employed to encourage simpler models and improve generalization. As usual, the MLE can overfit, especially if the number of nodes is large. A simple way to prevent this is called early stopping, which means stopping the training procedure when the error on the validation set first starts to increase. Another way to prevent overfitting, that is more in keeping with the approaches used elsewhere in this book, is to impose a prior on the parameters, and then use MAP estimation. Regularization such as early stopping, which stops training when the error on the validation set increases, is used to prevent overfitting, and a prior on the parameters is imposed using MAP estimation, with a N(0, \u03b1\u207b\u00b9I) prior (equivalent to l2 regularization) being standard, where \u03b1 is the precision (strength) of the prior, and this is called weight decay.",
        "Bayesian inference methods, including Laplace approximation, hybrid Monte Carlo, and variational Bayes, can be used to estimate the posterior distribution over the parameters of an MLP, providing a more robust and principled approach to model fitting and uncertainty estimation. Bayesian inference, including methods like Laplace approximation, hybrid Monte Carlo, and variational Bayes, can be used to estimate the parameters of neural networks, providing a principled way to incorporate prior knowledge and quantify uncertainty.",
        "Consistent Gaussian priors can be used to improve the invariance property of MLPs by using different regularization strengths for the first and second layer weights, allowing the model to learn to predict the same function by suitably scaling its internal weights and bias terms. One can show that using the same regularization parameter for both the first and second layer weights results in the lack of a certain desirable invariance property. In particular, suppose we linearly scale and shift the inputs and/or outputs to a neural network regression model. Then we would like the model to learn to predict the same function, by suitably scaling its internal weights and bias terms.",
        "Semi-supervised embedding is an approach to regularize deep feedforward neural networks by encouraging the hidden layers to assign similar objects to similar representations, leveraging side information consisting of sets of pairs of similar and dissimilar objects. Semi-supervised embedding regularizes deep feedforward neural networks by encouraging hidden layers to assign similar objects to similar representations, leveraging side information about pairs of similar and dissimilar objects.",
        "Soft weight sharing regularizes parameters by encouraging similar weights to share statistical strength, often modeled using a mixture model to learn which parameters to group together, sharing the same mean and variance. Another way to regularize the parameters is to encourage similar weights to share statistical strength. But how do we know which parameters to group together? We can learn this, by using a mixture model. That is, we model p(\u03b8) as a mixture of (diagonal) Gaussians. Parameters that are assigned to the same cluster will share the same mean and variance and thus will have similar values (assuming the variance for that cluster is low).",
        "Automatic relevancy determination (ARD) is used to prune irrelevant input features in neural networks by assigning a hyperparameter to the weight vector leaving each node, effectively achieving a group lasso effect and performing variable selection in nonlinear models.",
        "A standard trick to further reduce the error rate is to expand the training set by including distorted versions of the original data, to encourage the network to be invariant to small changes that don't affect the identity of the digit. These can be created by applying a random flow field to shift pixels around.",
        "Unlike a GLM, the NLL of an MLP is a non-convex function of its parameters. Nevertheless, we can find a locally optimal ML or MAP estimate using standard gradient-based optimization methods.",
        "It is easy to see that the parameters of a neural network are not identifiable. For example, we can change the sign of the weights going into one of the hidden units, so long as we change the sign of all the weights going out of it; these effects cancel, since tanh is an odd function, so tanh(-a) = -tanh(a). There will be H such sign flip symmetries, leading to 2^H equivalent settings of the parameters."
      ]
    },
    {
      "topic": "Ensemble Learning",
      "sub_topics": [
        "Ensemble learning combines multiple base models to form a stronger model, where each base model gets a weighted vote, and is closely related to learning adaptive-basis function models. Ensemble learning techniques can be used for both classification and regression tasks. Ensemble learning is sometimes called a committee method, since each base model f\u2098 gets a weighted \u201cvote\u201d. The tunable parameters are the weights assigned to each base model. The weighted average of the predictions from each base model is then used as the final prediction. Ensemble learning refers to learning a weighted combination of base models of the form f(y|x, \u03c0) = \u03a3 w\u2098f\u2098(y|x), where the w\u2098 are tunable parameters. A neural net can be viewed as an ensemble method where fm represents the m'th hidden unit, and wm are the output layer weights, and boosting is a form of ensemble learning. It's important to note that BMA is not equivalent to ensemble learning (Minka 2000c).",
        "Stacking involves estimating the weights in the ensemble by minimizing the loss function, but to avoid overfitting, cross-validation is used, particularly the LOOCV estimate, where the predictor is obtained by training on data excluding the current data point. An obvious way to estimate the weights is to use w = argmin \u03a3 L(y\u1d62, \u03a3 w\u2098f\u2098(x)). However, this will result in overfitting, with w\u2098 being large for the most complex model. A simple solution to this is to use cross-validation. In particular, we can use the LOOCV estimate w = argmin \u03a3 L(y\u1d62, \u03a3 w\u2098f\u2098\u208b\u1d62(x)). Stacking estimates weights in the ensemble using w = argmin \u03a3 L(yi, \u03a3 Wm fm(x)), but this leads to overfitting, which can be addressed with cross-validation using w = argmin \u03a3 L(yi, \u03a3 Wm fm\u208bi(x)), where fm\u208bi(x) is the predictor obtained by training on data excluding (xi, yi). Stacking is an ensemble technique that estimates the weights of base models by minimizing the loss function, using cross-validation to prevent overfitting and improve robustness compared to standard BMA (Bayesian Model Averaging). Stacking is an ensemble technique where a meta-learner is trained to combine the predictions of multiple base learners. The meta-learner uses the predictions of the base learners as input features to make a final prediction. It aims to find the optimal way to weight and combine the base learner predictions.",
        "Error-correcting output codes (ECOC) is a form of ensemble learning used in multi-class classification, where the goal is to decode a symbol with C possible states using a bit vector of length B, and by designing codewords with maximal Hamming distance, the method becomes more resistant to misclassification. An interesting form of ensemble learning is known as error-correcting output codes or ECOC, which can be used in the context of multi-class classification. The idea is that we are trying to decode a symbol (namely the class label) which has C possible states. We could use a bit vector of length B = \u2308log\u2082 C\u2309 to encode the class label, and train B separate binary classifiers to predict each bit. Error-Correcting Output Codes (ECOC) are an interesting form of ensemble learning for multi-class classification, where if there are C possible states, we could use a bit vector of length B = [log2 C] to encode the class label, and train B separate binary classifiers to predict each bit, however, by using more bits, and by designing the codewords to have maximal Hamming distance from each other, we get a method that is more resistant to individual bit-flipping errors (misclassification). By encoding the class labels with bit vectors and training separate binary classifiers to predict each bit, ECOC can create a robust model that is resistant to misclassification. By encoding the class labels with bit vectors and training separate binary classifiers to predict each bit, ECOC can create a robust model that is resistant to misclassification.",
        "Bayes model averaging (BMA) involves making a weighted average of the predictions made by each model, but is often computationally infeasible, leading to approximations such as sampling a few models from the posterior or using the MAP model. In principle, we can now perform Bayesian inference to compute p(\u03c0|D); we then make predictions using p(y|x,D) = \u222b p(y|x, \u03c0)p(\u03c0|D)d\u03c0. However, it is much more common to use point estimation methods for \u03c0, as we saw above. Bayes Model Averaging (BMA) is an alternative to picking the best model, and can give better performance than any single model, where p(y|x, D) = \u03a3 p(y|x, m, D)p(m|D), but it's typically computationally infeasible, so a simple approximation is to sample a few models from the posterior, or to just use the MAP model.",
        "Experimental comparisons of different methods for classification and regression show that the best method depends on the inductive bias appropriate for the domain, and it is common to try several methods and see how they perform empirically, with boosted decision trees often performing well in low-dimensional feature spaces. The performance of different machine learning methods is often compared experimentally across various datasets and performance measures, considering threshold metrics, ordering/ranking metrics, and probability metrics.",
        "High-dimensional feature spaces often require feature selection, and Bayesian neural networks have shown success in such scenarios, but the choice of method depends on factors such as the dataset, metric, and performance measure."
      ]
    },
    {
      "topic": "Generalized Additive Models",
      "sub_topics": [
        "Generalized additive models (GAM) create a nonlinear model with multiple inputs: f(x) = a + f\u2081(x\u2081) + ... + fD(xD), where each f\u2c7c can be modeled by a scatterplot smoother, and f(x) can be mapped to p(y|x) using a link function, as in a GLM. In the regression setting, the objective becomes J(\u03b1, f\u2081,..., fD) = \u03a3 (y\u1d62 - \u03b1 - \u03a3 f\u2c7c(x\u1d62\u2c7c))\u00b2 + \u03a3 \u03bb\u2c7c \u222b f'\u2c7c(t\u2c7c)\u00b2dt\u2c7c, where \u03bb\u2c7c is the strength of the regularizer for f\u2c7c.",
        "To fit the model using MLE, the constant a is not uniquely identifiable, so the convention is to assume \u03a3 f\u2c7c(x\u1d62\u2c7c) = 0 for all j. The MLE for a is just a = (1/N) \u03a3 y\u1d62. To fit the rest of the model, we can center the responses (by subtracting a), and then iteratively update each f\u2c7c in turn, using as a target vector the residuals obtained by omitting term f\u2c7c: f\u2c7c := smoother({y\u1d62 - \u03a3 f\u2096(x\u1d62\u2096)}).",
        "The backfitting algorithm ensures the output is zero mean: f\u2c7c := f\u2c7c - (1/N) \u03a3 f\u2c7c(x\u1d62\u2c7c). If X has full column rank, the objective is convex (since each smoothing spline is a linear operator), so this procedure is guaranteed to converge to the global optimum.",
        "Multivariate adaptive regression splines (MARS) extend GAMs by allowing for interaction effects, creating an ANOVA decomposition: f(x) = \u03b2\u2080 + \u03a3 f\u2c7c(x\u2c7c) + \u03a3 f\u2c7c\u2096(x\u2c7c, x\u2096) + \u03a3 f\u2c7c\u2096\u2097(x\u2c7c, x\u2096, x\u2097) + .... Greedy search decides which variables to add. MARS uses a tensor product basis of regression splines to represent the multidimensional regression functions.",
        "To create a MARS function, we start with a set of candidate basis functions of the form C = {(x\u2c7c - t)\u208a, (t - x\u2c7c)\u208a : t \u2208 {X\u2081\u2c7c,...,XNj}, j = 1, ..., D}. These are linear splines where the knots are at all the observed values for that variable. We consider splines sloping up in both directions; this is called a reflecting pair."
      ]
    }
  ]
}