## Nonparametric Bootstrap and Bayes Correspondence

<imagem: Mapa mental abrangente conectando os m√©todos de infer√™ncia: Maximum Likelihood, Bootstrap (Param√©trico e N√£o Param√©trico), e Bayes. As setas devem mostrar as rela√ß√µes de equival√™ncia e aproxima√ß√£o sob certas condi√ß√µes, destacando as diferen√ßas no tratamento da incerteza e a incorpora√ß√£o de priors.>

### Introdu√ß√£o
Este cap√≠tulo explora a conex√£o profunda entre o **nonparametric bootstrap** e a infer√™ncia Bayesiana, dois m√©todos poderosos para quantificar a incerteza em estimativas de modelos [^8.1]. Enquanto o bootstrap, uma t√©cnica de reamostragem computacional, avalia a variabilidade atrav√©s da gera√ß√£o de amostras replicadas dos dados observados [^8.2.1], a infer√™ncia Bayesiana incorpora conhecimento *a priori* atrav√©s de distribui√ß√µes probabil√≠sticas, atualizando essas cren√ßas com a observa√ß√£o dos dados [^8.3]. Vamos detalhar a equival√™ncia assint√≥tica entre o bootstrap n√£o param√©trico e o m√©todo Bayesiano com *prior* n√£o informativa, fornecendo um entendimento abrangente e profundo sobre a base te√≥rica e as nuances pr√°ticas de cada um.

### Conceitos Fundamentais
Para construir uma base s√≥lida, √© essencial explorar os conceitos fundamentais que sustentam o *nonparametric bootstrap* e a infer√™ncia Bayesiana.

**Conceito 1: Bootstrap N√£o Param√©trico** O bootstrap n√£o param√©trico, introduzido em [^8.2.1], √© um m√©todo de reamostragem que avalia a incerteza da estimativa, simulando amostras a partir dos dados de treinamento observados, em vez de assumir uma distribui√ß√£o te√≥rica dos dados. Ele permite que a variabilidade dos estimadores seja aproximada sem assumir uma forma param√©trica para a distribui√ß√£o subjacente dos dados [^8.2.1]. Em ess√™ncia, a reamostragem com reposi√ß√£o da amostra original, gera r√©plicas que replicam a distribui√ß√£o emp√≠rica dos dados, e a partir dessas r√©plicas, a distribui√ß√£o da estat√≠stica de interesse √© estimada. O bootstrap se torna uma ferramenta √∫til para avaliar a incerteza em situa√ß√µes onde a teoria assint√≥tica n√£o pode ser aplicada, ou quando as distribui√ß√µes amostrais exatas s√£o desconhecidas. Por exemplo, na regress√£o n√£o linear, o bootstrap pode simular a incerteza associada aos par√¢metros do modelo [^8.2.1].

> üí° **Exemplo Num√©rico:** Considere um conjunto de dados com 10 observa√ß√µes de uma vari√°vel $X = [2, 4, 5, 8, 9, 12, 14, 16, 18, 20]$. Queremos estimar a m√©dia da popula√ß√£o ($\mu$) e sua incerteza.
>
> 1. **Amostra Original:** $X = [2, 4, 5, 8, 9, 12, 14, 16, 18, 20]$; M√©dia da amostra $\hat{\mu} = 10.8$
> 2. **Reamostragem Bootstrap:**  Geramos, por exemplo, 5 amostras bootstrap ($B=5$) retirando com reposi√ß√£o da amostra original:
>    - $X^{*1} = [4, 8, 14, 2, 18, 9, 20, 5, 12, 14]$; $\hat{\mu}^{*1} = 10.6$
>    - $X^{*2} = [16, 5, 2, 20, 8, 12, 9, 14, 5, 18]$; $\hat{\mu}^{*2} = 10.9$
>    - $X^{*3} = [2, 14, 12, 4, 16, 8, 5, 18, 9, 20]$; $\hat{\mu}^{*3} = 10.8$
>    - $X^{*4} = [8, 9, 16, 20, 4, 12, 14, 18, 2, 5]$; $\hat{\mu}^{*4} = 10.8$
>    - $X^{*5} = [18, 12, 14, 2, 5, 9, 8, 20, 4, 16]$; $\hat{\mu}^{*5} = 10.8$
> 3. **Distribui√ß√£o Bootstrap:** A distribui√ß√£o emp√≠rica das m√©dias bootstrap $\hat{\mu}^{*b} = [10.6, 10.9, 10.8, 10.8, 10.8]$ nos fornece uma ideia da variabilidade da m√©dia amostral.
> 4. **Estimativa da Incerteza:** Podemos usar o desvio padr√£o das m√©dias bootstrap para estimar o erro padr√£o da m√©dia amostral, neste exemplo o desvio padr√£o amostral seria 0.11. Em geral, aumentamos o n√∫mero de amostras bootstrap para obter uma estimativa mais precisa.
> ```python
> import numpy as np
>
> X = np.array([2, 4, 5, 8, 9, 12, 14, 16, 18, 20])
> B = 1000  # N√∫mero de amostras bootstrap
> bootstrap_means = []
>
> for _ in range(B):
>     X_star = np.random.choice(X, size=len(X), replace=True)
>     bootstrap_means.append(np.mean(X_star))
>
> std_error = np.std(bootstrap_means)
> print(f"Erro padr√£o estimado pelo bootstrap: {std_error:.4f}")
> ```

```mermaid
graph LR
    subgraph "Bootstrap Resampling Process"
        direction TB
        A["Original Sample: X"]
        B["Resample with Replacement: X*1"]
        C["Resample with Replacement: X*2"]
        D["Resample with Replacement: X*B"]
        E["Statistic: Œ∏ÃÇ*1 = f(X*1)"]
        F["Statistic: Œ∏ÃÇ*2 = f(X*2)"]
        G["Statistic: Œ∏ÃÇ*B = f(X*B)"]
        H["Bootstrap Distribution: {Œ∏ÃÇ*1, Œ∏ÃÇ*2, ..., Œ∏ÃÇ*B}"]

        A --> B
        A --> C
        A --> D
        B --> E
        C --> F
        D --> G
        E & F & G --> H
    end
```

**Lemma 1:** A distribui√ß√£o amostral do bootstrap n√£o param√©trico converge, sob condi√ß√µes de regularidade, para a verdadeira distribui√ß√£o assint√≥tica do estimador, conforme o tamanho da amostra original aumenta [^8.2.1]. 
  
  *Prova:* Seja $\hat{\theta}$ um estimador de um par√¢metro $\theta$, baseado em uma amostra $Z = \{z_1, \ldots, z_N\}$. O bootstrap n√£o param√©trico gera B amostras bootstrap, $Z^{*b}$, $b = 1, \ldots, B$, cada uma com N amostras retiradas com reposi√ß√£o de Z. Seja $\hat{\theta}^{*b}$ o estimador de $\theta$ calculado com $Z^{*b}$. A distribui√ß√£o amostral do bootstrap √© a distribui√ß√£o emp√≠rica de $\hat{\theta}^{*1}, \ldots, \hat{\theta}^{*B}$. Sob certas condi√ß√µes, a distribui√ß√£o amostral do bootstrap $\hat{\theta}^{*}$ converge para a distribui√ß√£o assint√≥tica de $\hat{\theta}$. $\blacksquare$

**Conceito 2: Infer√™ncia Bayesiana** A infer√™ncia Bayesiana √© uma abordagem para a infer√™ncia estat√≠stica que quantifica a incerteza sobre os par√¢metros do modelo por meio de distribui√ß√µes de probabilidade [^8.3].  Ao contr√°rio da infer√™ncia cl√°ssica, que trata os par√¢metros como valores fixos, a infer√™ncia Bayesiana modela os par√¢metros como vari√°veis aleat√≥rias com distribui√ß√µes de *prior*. Estas representam as nossas cren√ßas iniciais sobre o par√¢metro antes de observar os dados [^8.3]. A distribui√ß√£o *a posteriori* √© calculada aplicando o Teorema de Bayes, combinando o *prior* com a fun√ß√£o de verossimilhan√ßa, que quantifica a compatibilidade dos dados observados com os par√¢metros do modelo [^8.3]. A distribui√ß√£o *a posteriori* resume nossa cren√ßa atualizada sobre o par√¢metro, dada a evid√™ncia dos dados.

> üí° **Exemplo Num√©rico:** Vamos supor que queremos estimar a probabilidade de sucesso ($\theta$) de um evento bin√°rio (por exemplo, lan√ßamento de uma moeda). Temos 10 lan√ßamentos, com 7 sucessos ($s=7$) e 3 fracassos ($f=3$).
> 1. **Prior:** Come√ßamos com uma *prior* Beta($\alpha=1$, $\beta=1$), que √© uma distribui√ß√£o uniforme sobre o intervalo [0,1], indicando que n√£o temos muita informa√ß√£o inicial sobre o par√¢metro.
> 2. **Verossimilhan√ßa:** A fun√ß√£o de verossimilhan√ßa para dados bin√°rios √© a distribui√ß√£o binomial $P(Z|\theta) = \binom{N}{s} \theta^s (1-\theta)^f$. Nesse caso, $P(Z|\theta) = \binom{10}{7} \theta^7 (1-\theta)^3$
> 3. **Posterior:** A *posterior* √© proporcional a $P(\theta|Z) \propto P(Z|\theta)P(\theta)$. Como a *prior* e a verossimilhan√ßa s√£o distribui√ß√µes conjugadas, a *posterior* tamb√©m √© uma distribui√ß√£o Beta: $Beta(\alpha + s, \beta + f) = Beta(1+7, 1+3) = Beta(8, 4)$.
> 4. **Interpreta√ß√£o:** A *posterior* Beta(8,4) resume nossa cren√ßa atualizada sobre a probabilidade de sucesso. Podemos usar esta distribui√ß√£o para obter um intervalo de credibilidade, por exemplo, com 95% de probabilidade, e calcular a m√©dia da distribui√ß√£o *a posteriori* (que seria $\frac{8}{8+4}=0.66$)
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from scipy.stats import beta
>
> alpha_prior = 1
> beta_prior = 1
> successes = 7
> failures = 3
>
> alpha_posterior = alpha_prior + successes
> beta_posterior = beta_prior + failures
>
> x = np.linspace(0, 1, 100)
> posterior_pdf = beta.pdf(x, alpha_posterior, beta_posterior)
> prior_pdf = beta.pdf(x, alpha_prior, beta_prior)
>
> plt.plot(x, prior_pdf, label='Prior Beta(1, 1)')
> plt.plot(x, posterior_pdf, label='Posterior Beta(8, 4)')
> plt.xlabel('Theta (Probability of Success)')
> plt.ylabel('Probability Density')
> plt.legend()
> plt.title('Bayesian Inference for Binomial Data')
> plt.grid(True)
> plt.show()
>
> posterior_mean = alpha_posterior / (alpha_posterior + beta_posterior)
> print(f"M√©dia da posterior: {posterior_mean:.3f}")
> ```
>
> ```mermaid
> graph LR
> A[Prior Distribution P(Œ∏)] --> B(Update with Data Z);
> C[Likelihood P(Z|Œ∏)] --> B;
> B --> D[Posterior Distribution P(Œ∏|Z)];
> ```
```mermaid
graph TB
    subgraph "Bayesian Inference Flow"
        direction TB
        A["Prior Distribution: P(Œ∏)"]
        B["Likelihood Function: P(Z|Œ∏)"]
        C["Bayes' Theorem: P(Œ∏|Z) = P(Z|Œ∏)P(Œ∏) / ‚à´P(Z|Œ∏)P(Œ∏)dŒ∏"]
        D["Posterior Distribution: P(Œ∏|Z)"]

        A --> C
        B --> C
        C --> D
    end
```

**Corol√°rio 1:** A escolha de um *prior* n√£o informativo resulta em uma distribui√ß√£o *a posteriori* que √© amplamente determinada pelos dados, com pouco impacto da distribui√ß√£o *a priori* [^8.4]. A distribui√ß√£o *a posteriori*,  $P(\theta|Z)$, pode ser expressa por:
$$P(\theta|Z) = \frac{P(Z|\theta)P(\theta)}{\int P(Z|\theta)P(\theta) \, d\theta}$$
  Quando $P(\theta)$ √© n√£o informativa (constante) a posteriori √© $P(\theta|Z) \propto P(Z|\theta)$.

**Conceito 3: Maximum Likelihood (ML)** O m√©todo da m√°xima verossimilhan√ßa (ML), conforme introduzido em [^8.1], √© um procedimento para estimar os par√¢metros de um modelo probabil√≠stico encontrando os valores que maximizam a probabilidade dos dados observados [^8.2.2]. Em outras palavras, escolhemos os par√¢metros que tornam os dados observados "mais prov√°veis" sob o modelo adotado. Embora ML forne√ßa estimativas pontuais de par√¢metros, ele n√£o quantifica diretamente a incerteza da estimativa. As abordagens de ML, juntamente com o bootstrap param√©trico e an√°lises bayesianas com *priors* n√£o informativos tendem a concordar [^8.2.3].

> üí° **Exemplo Num√©rico:** Considere novamente o problema de estimar a probabilidade de sucesso de um evento bin√°rio. Temos os mesmos 10 lan√ßamentos, com 7 sucessos ($s=7$) e 3 fracassos ($f=3$).
>
> 1. **Verossimilhan√ßa:** A fun√ß√£o de verossimilhan√ßa para dados bin√°rios √© a distribui√ß√£o binomial $P(Z|\theta) = \binom{N}{s} \theta^s (1-\theta)^f$. Nesse caso, $P(Z|\theta) = \binom{10}{7} \theta^7 (1-\theta)^3$.
> 2. **M√°xima Verossimilhan√ßa:** Para encontrar a estimativa de m√°xima verossimilhan√ßa, maximizamos a fun√ß√£o de verossimilhan√ßa em rela√ß√£o a $\theta$. Equivalentemente podemos maximizar o log-verossimilhan√ßa: $\log L(\theta) = \log\binom{10}{7} + 7\log\theta + 3\log(1-\theta)$. A derivada em rela√ß√£o a $\theta$ √© $7/\theta - 3/(1-\theta) = 0$ que resulta em $\hat{\theta}_{ML} = \frac{7}{10} = 0.7$.
> 3. **Interpreta√ß√£o:** A estimativa de m√°xima verossimilhan√ßa √© a propor√ß√£o de sucessos observados, que nesse caso √© 0.7. ML nos fornece um √∫nico valor estimado, mas n√£o uma medida de incerteza.
>
> ```python
> import numpy as np
> from scipy.optimize import minimize
>
> successes = 7
> failures = 3
>
> def neg_log_likelihood(theta):
>   return - (successes * np.log(theta) + failures * np.log(1-theta))
>
> # Maximizar a verossimilhan√ßa √© equivalente a minimizar o negativo da log-verossimilhan√ßa
> result = minimize(neg_log_likelihood, 0.5, bounds=[(1e-6, 1-1e-6)])
>
> ml_estimate = result.x[0]
> print(f"Estimativa de m√°xima verossimilhan√ßa: {ml_estimate:.3f}")
> ```

> ‚ö†Ô∏è **Nota Importante**: O bootstrap n√£o param√©trico √© uma ferramenta de infer√™ncia flex√≠vel, que n√£o requer suposi√ß√µes sobre a distribui√ß√£o dos dados, sendo especialmente √∫til em modelos complexos [^8.2.3].

> ‚ùó **Ponto de Aten√ß√£o**: A escolha de um *prior* n√£o informativo em modelos Bayesianos leva a resultados assintoticamente equivalentes aos obtidos por ML, o que facilita a compara√ß√£o com m√©todos frequentistas [^8.4].

> ‚úîÔ∏è **Destaque**: A infer√™ncia Bayesiana quantifica a incerteza sobre os par√¢metros do modelo atrav√©s da distribui√ß√£o *a posteriori*, enquanto a ML fornece apenas estimativas pontuais [^8.3].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
<imagem: Diagrama comparativo mostrando o fluxo do processo de infer√™ncia: (a) Maximum Likelihood, focando na maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa, (b) Bootstrap n√£o param√©trico, destacando a reamostragem dos dados, e (c) Infer√™ncia Bayesiana, mostrando a atualiza√ß√£o da *a priori* para a distribui√ß√£o *a posteriori*. As setas devem ilustrar o fluxo de cada m√©todo, e caixas de texto resumir seus principais objetivos.>

A regress√£o linear, aplicada diretamente a uma matriz indicadora para tarefas de classifica√ß√£o, apresenta limita√ß√µes e desafios, especialmente em compara√ß√£o com outros m√©todos. No entanto, sua conex√£o com o bootstrap e infer√™ncia Bayesiana sob certas circunst√¢ncias √© not√°vel [^8.2.1]. A regress√£o linear minimiza a soma dos erros quadr√°ticos para um determinado conjunto de dados, obtendo par√¢metros por m√≠nimos quadrados [^8.2.1].
Em problemas de classifica√ß√£o, podemos aplicar regress√£o linear usando uma matriz de indicadores. Seja $Y$ uma vari√°vel resposta categ√≥rica com $K$ classes. Em vez de modelar diretamente a resposta, criamos uma matriz de indicadores $Y_{N \times K}$, onde $Y_{ik} = 1$ se a $i$-√©sima observa√ß√£o pertence √† classe $k$, e $0$ caso contr√°rio. Podemos ent√£o ajustar modelos lineares para cada uma das $K$ colunas da matriz de indicadores, atrav√©s de m√≠nimos quadrados [^8.2.1].
A estimativa dos par√¢metros $\beta$ √© dada por:
$$\hat{\beta} = (H^T H)^{-1} H^T Y$$
onde $H$ √© a matriz de design.
Uma das principais limita√ß√µes √© que este modelo n√£o imp√µe necessariamente que as predi√ß√µes $\hat{Y}$ estejam entre 0 e 1, o que √© necess√°rio para interpreta√ß√£o como probabilidades. Al√©m disso, esse modelo √© sens√≠vel a outliers e n√£o fornece diretamente uma medida de incerteza [^8.2.1].
Por√©m, sob certas condi√ß√µes, existe uma rela√ß√£o entre a regress√£o linear e outras abordagens, como o bootstrap e a infer√™ncia Bayesiana [^8.2.3]. O *nonparametric bootstrap*, ao reamostrar os dados de treino, pode ajudar a estimar a variabilidade das predi√ß√µes obtidas com a regress√£o linear. A infer√™ncia Bayesiana, por sua vez, pode quantificar a incerteza dos par√¢metros atrav√©s do uso de *prior*, levando a distribui√ß√µes *a posteriori* que capturam as incertezas associadas aos par√¢metros e, consequentemente, √†s predi√ß√µes.

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com 5 amostras e 2 features. A matriz de design √© $H = \begin{bmatrix} 1 & 2 & 1 \\ 1 & 3 & 2 \\ 1 & 4 & 1 \\ 1 & 5 & 3 \\ 1 & 6 & 2 \end{bmatrix}$ e a matriz de indicadores √© $Y = \begin{bmatrix} 1 \\ 0 \\ 1 \\ 0 \\ 1 \end{bmatrix}$.
>
> 1. **M√≠nimos Quadrados:** Primeiro, calculamos $H^T H$:
>    $$H^T H = \begin{bmatrix} 1 & 1 & 1 & 1 & 1 \\ 2 & 3 & 4 & 5 & 6 \\ 1 & 2 & 1 & 3 & 2 \end{bmatrix} \begin{bmatrix} 1 & 2 & 1 \\ 1 & 3 & 2 \\ 1 & 4 & 1 \\ 1 & 5 & 3 \\ 1 & 6 & 2 \end{bmatrix} = \begin{bmatrix} 5 & 20 & 9 \\ 20 & 90 & 41 \\ 9 & 41 & 19 \end{bmatrix}$$
> 2. Calculamos a inversa de $H^T H$: $(H^T H)^{-1} = \begin{bmatrix}  7.6  & -1.82  & -6.2 \\ -1.82  &  0.48 &  1.55 \\ -6.2    &  1.55 &  5.2  \end{bmatrix} $
> 3. Calculamos $H^T Y$: $H^T Y = \begin{bmatrix} 1 & 1 & 1 & 1 & 1 \\ 2 & 3 & 4 & 5 & 6 \\ 1 & 2 & 1 & 3 & 2 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \\ 1 \\ 0 \\ 1 \end{bmatrix} = \begin{bmatrix} 3 \\ 12 \\ 4 \end{bmatrix}$
> 4. Finalmente calculamos os par√¢metros $\hat{\beta}$:
>    $$\hat{\beta} = (H^T H)^{-1} H^T Y = \begin{bmatrix}  7.6  & -1.82  & -6.2 \\ -1.82  &  0.48 &  1.55 \\ -6.2    &  1.55 &  5.2  \end{bmatrix} \begin{bmatrix} 3 \\ 12 \\ 4 \end{bmatrix} = \begin{bmatrix} -18.34 \\ 4.26 \\ 15.38 \end{bmatrix}$$
> 5. **Interpreta√ß√£o:** Os valores de $\hat{\beta}$ obtidos s√£o os par√¢metros do modelo de regress√£o linear usado para classificar as observa√ß√µes. Esses coeficientes n√£o garantem predi√ß√µes entre 0 e 1. Usando esses par√¢metros, podemos obter a predi√ß√£o $\hat{y}_i = h_i^T \hat{\beta}$, onde $h_i$ √© a i-√©sima linha da matriz $H$.
> ```python
> import numpy as np
>
> H = np.array([[1, 2, 1],
>               [1, 3, 2],
>               [1, 4, 1],
>               [1, 5, 3],
>               [1, 6, 2]])
> Y = np.array([1, 0, 1, 0, 1])
>
> HT_H = H.T @ H
> HT_Y = H.T @ Y
> beta_hat = np.linalg.inv(HT_H) @ HT_Y
>
> print("Beta Estimado:", beta_hat)
> ```
>
> Para verificar os resultados, podemos calcular as previs√µes e o erro quadr√°tico m√©dio.
> ```python
> y_hat = H @ beta_hat
> mse = np.mean((Y - y_hat)**2)
> print("Previs√µes:", y_hat)
> print("Erro Quadr√°tico M√©dio:", mse)
> ```

```mermaid
graph LR
 subgraph "Least Squares Estimation"
    direction TB
    A["Design Matrix: H"]
    B["Indicator Matrix: Y"]
    C["Compute: H·µÄH"]
    D["Compute: (H·µÄH)‚Åª¬π"]
    E["Compute: H·µÄY"]
    F["Estimate Parameters: Œ≤ÃÇ = (H·µÄH)‚Åª¬πH·µÄY"]
    
    A --> C
    A --> E
    B --> E
    C --> D
    D & E --> F
 end
```

**Lemma 2:** Em problemas de regress√£o com erros Gaussianos, a estimativa de m√≠nimos quadrados (LS) √© id√™ntica √† estimativa de m√°xima verossimilhan√ßa (ML), conforme demonstrado em [^8.2.2].
 *Prova:* Para um modelo de regress√£o linear $Y = X\beta + \epsilon$, onde $\epsilon \sim N(0, \sigma^2I)$, a fun√ß√£o de verossimilhan√ßa √©:
$$L(\beta,\sigma^2|Y) = \prod_{i=1}^N \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_i - x_i^T\beta)^2}{2\sigma^2}\right)$$
A maximiza√ß√£o do logaritmo da verossimilhan√ßa em rela√ß√£o a $\beta$ resulta na mesma solu√ß√£o do problema de m√≠nimos quadrados:
$$\hat{\beta}_{ML} = \text{argmax}_\beta \sum_{i=1}^N (y_i - x_i^T\beta)^2$$
O que √© a solu√ß√£o de m√≠nimos quadrados. $\blacksquare$

**Corol√°rio 2:** Em modelos de regress√£o linear com erros Gaussianos, o bootstrap param√©trico, ao amostrar res√≠duos com distribui√ß√£o normal, coincide com o m√©todo de m√≠nimos quadrados [^8.2.2].
  *Prova:*  O bootstrap param√©trico amostra valores $y_i^*$ de acordo com $y_i^* = x_i^T\hat{\beta} + \epsilon_i^*$, onde $\epsilon_i^* \sim N(0, \hat{\sigma}^2)$. Ao repetir esse processo, a varia√ß√£o amostrada coincide com a varia√ß√£o proveniente do modelo linear de m√≠nimos quadrados, portanto as distribui√ß√µes s√£o as mesmas [^8.2.2].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem: Diagrama de Venn mostrando as intersec√ß√µes entre (a) Maximum Likelihood (ML), (b) Nonparametric Bootstrap, e (c) Infer√™ncia Bayesiana. A sobreposi√ß√£o representa os casos onde h√° equival√™ncia ou aproxima√ß√£o entre os m√©todos. As √°reas devem ser proporcionalmente dimensionadas com base na generalidade e aplicabilidade de cada t√©cnica.>
Em contextos de classifica√ß√£o, t√©cnicas de sele√ß√£o de vari√°veis e regulariza√ß√£o s√£o vitais para lidar com *overfitting* e melhorar a interpretabilidade dos modelos. Essas abordagens podem ser vistas como restri√ß√µes ou *priors* nos par√¢metros do modelo, e podem ser exploradas atrav√©s de *bootstrapping* ou infer√™ncia Bayesiana [^8.5]. 
Regulariza√ß√£o, como as penalidades L1 (Lasso) e L2 (Ridge), imp√µe restri√ß√µes aos par√¢metros do modelo durante a estimativa, o que leva √† esparsidade e/ou estabilidade dos coeficientes [^8.5.1]. A penalidade L1, por exemplo, tem o efeito de zerar alguns coeficientes, realizando automaticamente sele√ß√£o de vari√°veis.
O bootstrap pode ser empregado para avaliar o efeito da regulariza√ß√£o, gerando amostras reamostradas dos dados e ajustando os modelos regularizados em cada amostra [^8.2.3]. A distribui√ß√£o da regulariza√ß√£o nos resultados de v√°rias amostras bootstrap indica a estabilidade dos par√¢metros do modelo.
Na perspectiva Bayesiana, regulariza√ß√£o pode ser vista como um *prior* sobre os par√¢metros, que penaliza valores de coeficientes grandes, e modelos complexos. Por exemplo, usar um *prior* Laplace sobre os coeficientes em um modelo de regress√£o log√≠stica equivale a usar regulariza√ß√£o L1. A escolha do *prior* afeta a distribui√ß√£o *a posteriori* dos par√¢metros, o que permite que as incertezas dos par√¢metros, bem como o efeito da regulariza√ß√£o, sejam avaliadas dentro do *framework* Bayesiano [^8.4].
A conex√£o entre esses m√©todos surge no sentido de que todos visam lidar com a complexidade do modelo e o *overfitting*, embora por meios diferentes [^8.5].

> üí° **Exemplo Num√©rico:** Vamos demonstrar o uso de regulariza√ß√£o L1 e L2 em um problema de classifica√ß√£o com regress√£o log√≠stica. Vamos usar dados simulados para ilustrar o efeito das regulariza√ß√µes.
>
> 1. **Dados Simulados:** Criamos dados com 5 features, onde apenas 2 features s√£o relevantes para a classifica√ß√£o.
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import accuracy_score
>
> np.random.seed(42)
> X = np.random.rand(100, 5)
> beta_true = np.array([2, -3, 0, 0, 1])
> y_prob = 1 / (1 + np.exp(-X @ beta_true))
> y = np.random.binomial(1, y_prob)
>
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
> ```
> 2. **Regress√£o Log√≠stica sem Regulariza√ß√£o:**
> ```python
> logistic_no_reg = LogisticRegression(penalty=None, solver='lbfgs', max_iter=1000)
> logistic_no_reg.fit(X_train, y_train)
> y_pred_no_reg = logistic_no_reg.predict(X_test)
> accuracy_no_reg = accuracy_score(y_test, y_pred_no_reg)
> print(f'Acur√°cia sem regulariza√ß√£o: {accuracy_no_reg:.3f}')
> print(f'Coeficientes sem regulariza√ß√£o: {logistic_no_reg.coef_}')
> ```
> 3. **Regress√£o Log√≠stica com Regulariza√ß√£o L1 (Lasso):** Vamos usar um valor de $\lambda$ que for√ßa a sele√ß√£o de vari√°veis (par√¢metro C=1/$\lambda$).
> ```python
> logistic_l1 = LogisticRegression(penalty='l1', C=0.5, solver='liblinear', max_iter=1000)
> logistic_l1.fit(X_train, y_train)
> y_pred_l1 = logistic_l1.predict(X_test)
> accuracy_l1 = accuracy_score(y_test, y_pred_l1)
> print(f'Acur√°cia com regulariza√ß√£o L1: {accuracy_l1:.3f}')
> print(f'Coeficientes com regulariza√ß√£o L1: {logistic_l1.coef_}')
> ```
> 4. **Regress√£o Log√≠stica com Regulariza√ß√£o L2 (Ridge):** Vamos usar um valor de $\lambda$ que penalize grandes coeficientes (par√¢metro C=1/$\lambda$).
> ```python
> logistic_l2 = LogisticRegression(penalty='l2', C=0.5, solver='lbfgs', max_iter=1000)
> logistic_l2.fit(X_train, y_train)
> y_pred_l2 = logistic_l2.predict(X_test)
> accuracy_l2 = accuracy_score(y_test, y_pred_l2)
> print(f'Acur√°cia com regulariza√ß√£o L2: {accuracy_l2:.3f}')
> print(f'Coeficientes com regulariza√ß√£o L2: {logistic_l2.coef_}')
> ```
> 5. **Interpreta√ß√£o:** A regulariza√ß√£o L1 zerou alguns coeficientes (sele√ß√£o de vari√°veis) tornando o modelo mais simples. A regulariza√ß√£o L2 reduziu o valor dos coeficientes, tornando o modelo mais est√°vel. Podemos usar bootstrap para avaliar a variabilidade desses par√¢metros.
> ```mermaid
>  graph LR
>     A[Dados de Treinamento] --> B(Ajustar Regress√£o Log√≠stica Sem Regulariza√ß√£o);
>     A --> C(Ajustar Regress√£o Log√≠stica Com L1);
>     A --> D(Ajustar Regress√£o Log√≠stica Com L2);
>     B --> E[Acur√°cia e Coeficientes Sem Regulariza√ß√£o];
>     C --> F[Acur√°cia e Coeficientes Com Regulariza√ß√£o L1];
>     D --> G[Acur√°cia e Coeficientes Com Regulariza√ß√£o L2];
>
> ```
```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["Training Data: (X, y)"]
        B["Logistic Regression (No Regularization)"]
        C["Logistic Regression with L1 Regularization"]
        D["Logistic Regression with L2 Regularization"]
        E["Loss Function: J(Œ≤)"]
        F["L1 Penalty: Œª‚àë|Œ≤‚±º|"]
        G["L2 Penalty: Œª‚àëŒ≤‚±º¬≤"]
        H["Optimize: J(Œ≤)"]
        I["Sparse Coefficients"]
        J["Smaller Coefficients"]
        K["Model without Regularization"]
        L["Regularized Model (L1)"]
        M["Regularized Model (L2)"]

        A --> B
        A --> C
        A --> D
        B --> K
        C --> L
        D --> M

        B --> E
        C --> E
        D --> E
        C --> F
        D --> G
        E & F --> H
        E & G --> H
        H --> I
        H --> J

    end
```

**Lemma 3:** A penalidade L1 (Lasso) em regress√£o log√≠stica imp√µe esparsidade nos coeficientes, resultando em modelos mais simples e interpret√°veis.
 *Prova:*  A regulariza√ß√£o L1 adiciona a norma L1 dos par√¢metros (soma dos valores absolutos) √† fun√ß√£o custo.  Em um contexto de regress√£o log√≠stica, a fun√ß√£o custo √© dada por:
  $$J(\beta) = -\sum_{i=1}^N \left( y_i \log(p_i) + (1-y_i)\log(1-p_i) \right) + \lambda \sum_{j=1}^p |\beta_j|$$
  onde $p_i = \frac{1}{1+e^{-x_i^T\beta}}$ e $\lambda$ √© o par√¢metro de regulariza√ß√£o. A penalidade L1 leva a solu√ß√µes esparsas, pois os contornos da fun√ß√£o de penalidade s√£o angulares e a solu√ß√£o √≥tima tende a ocorrer em √¢ngulos que fazem alguns coeficientes serem nulos [^8.4.1]. $\blacksquare$

**Corol√°rio 3:** A penaliza√ß√£o L2 (Ridge) em regress√£o log√≠stica leva a coeficientes menores e modelos mais est√°veis.
  *Prova:*  A penalidade L2 adiciona o quadrado dos par√¢metros √† fun√ß√£o custo.  Em um contexto de regress√£o log√≠stica, a fun√ß√£o custo √© dada por:
  $$J(\beta) = -\sum_{i=1}^N \left( y_i \log(p_i) + (1-y_i)\log(1-p_i) \right) + \lambda \sum_{j=1}^p \beta_j^2$$
onde $p_i = \frac{1}{1+e^{-x_i^T\beta}}$ e $\lambda$ √© o par√¢metro de regulariza√ß√£o. A penalidade L2 leva a coeficientes menores, pois ela penaliza grandes valores absolutos dos coeficientes de forma quadr√°tica e assim os coeficientes s√£o reduzidos de forma mais homog√™nea [^8.5].

> ‚ö†Ô∏è **Ponto Crucial**: Regulariza√ß√£o L1 e L2 podem ser combinadas para aproveitar as vantagens de cada uma, conforme Elastic Net [^8.5], e podem ser exploradas usando o bootstrap.

### Separating Hyperplanes e Perceptrons
A ideia central por tr√°s dos *separating hyperplanes* √© encontrar um hiperplano que divida os pontos de dados em diferentes classes, maximizando a margem de separa√ß√£o [^8.5.2]. Este conceito √© fundamental para a compreens√£o dos *support vector machines* (SVM). O problema de otimiza√ß√£o pode ser resolvido usando m√©todos de programa√ß√£o quadr√°tica, que s√£o computacionalmente intensivos.
O *Perceptron* de Rosenblatt, por sua vez, √© um algoritmo para encontrar um hiperplano que separe os dados linearmente, usando