## Bagging Estimates: A Comprehensive Study

```mermaid
graph LR
    A["Bootstrap Sampling"] --> B{"Multiple Base Models"};
    B --> C["Model Training"];
    C --> D{"Aggregation"};
    D --> E["Bagging Estimate"];
    style E fill:#ccf
```

### Introdu√ß√£o
Este cap√≠tulo explora o conceito de **Bagging Estimates**, uma t√©cnica poderosa para melhorar a precis√£o e estabilidade de modelos estat√≠sticos, especialmente aqueles que s√£o sens√≠veis a pequenas mudan√ßas nos dados de treinamento [^8.7]. O Bagging, abrevia√ß√£o de **Bootstrap Aggregating**, utiliza o poder do *re-sampling* e da agrega√ß√£o para reduzir a vari√¢ncia de modelos inst√°veis, como √°rvores de decis√£o e outros m√©todos de aprendizado de m√°quina n√£o lineares. O m√©todo surge como uma ferramenta essencial para profissionais em estat√≠stica e aprendizado de m√°quina que buscam construir modelos robustos e generaliz√°veis.

### Conceitos Fundamentais
Para compreender o Bagging, √© crucial entender os conceitos fundamentais envolvidos, conforme detalhado no contexto [^8.1], [^8.2], [^8.7].

**Conceito 1: Bootstrap e Reamostragem**
O *bootstrap* √© uma t√©cnica de reamostragem que permite estimar a variabilidade de uma estat√≠stica amostral sem depender de suposi√ß√µes sobre a distribui√ß√£o subjacente da popula√ß√£o. Em vez de coletar v√°rias amostras independentes da popula√ß√£o original, o bootstrap gera v√°rias *amostras bootstrap* a partir da amostra original, por amostragem com reposi√ß√£o [^8.2.1]. Isso permite estimar a distribui√ß√£o amostral de uma estat√≠stica e, consequentemente, a vari√¢ncia de um modelo. O processo de reamostragem do bootstrap √© fundamental para a constru√ß√£o do *Bagging Estimates* [^8.7]. A ideia central √© que, ao reamostrar os dados de treinamento, podemos criar um conjunto de modelos ligeiramente diferentes, que, quando agregados, tendem a ter uma vari√¢ncia menor do que o modelo original.

> üí° **Exemplo Num√©rico:** Considere um conjunto de dados simples com 5 observa√ß√µes: `data = [2, 4, 5, 7, 9]`. Queremos estimar a m√©dia usando o bootstrap.
>
> 1.  **Amostragem Bootstrap:** Geramos, digamos, 3 amostras bootstrap com reposi√ß√£o:
>     *   `bootstrap_sample_1 = [2, 7, 9, 4, 2]`
>     *   `bootstrap_sample_2 = [4, 5, 5, 9, 7]`
>     *   `bootstrap_sample_3 = [9, 2, 7, 4, 5]`
> 2.  **C√°lculo das M√©dias:** Calculamos a m√©dia de cada amostra bootstrap:
>     *   `mean_1 = (2 + 7 + 9 + 4 + 2) / 5 = 4.8`
>     *   `mean_2 = (4 + 5 + 5 + 9 + 7) / 5 = 6.0`
>     *   `mean_3 = (9 + 2 + 7 + 4 + 5) / 5 = 5.4`
> 3.  **M√©dia das M√©dias:** A m√©dia bootstrap √© a m√©dia das m√©dias das amostras bootstrap:
>     *   `bootstrap_mean = (4.8 + 6.0 + 5.4) / 3 = 5.4`
>
> A m√©dia original dos dados √© `(2+4+5+7+9)/5 = 5.4`.  O bootstrap nos permitiu estimar a m√©dia atrav√©s de um processo de reamostragem, onde a m√©dia bootstrap converge para a m√©dia original quando o n√∫mero de amostras bootstrap tende ao infinito.

**Lemma 1:** Se $\hat{\theta}$ √© um estimador de um par√¢metro $\theta$ e $\hat{\theta}_1, \hat{\theta}_2, ..., \hat{\theta}_B$ s√£o estimadores bootstrap de $\theta$, ent√£o o estimador bootstrap m√©dio $\frac{1}{B} \sum_{b=1}^B \hat{\theta}_b$ √© uma aproxima√ß√£o para $E[\hat{\theta}]$, onde a esperan√ßa √© tomada sobre a distribui√ß√£o do bootstrap [^8.2.3].

```mermaid
graph TB
    subgraph "Bootstrap Estimator Convergence"
        A["Original Estimator: \$\\hat{\\theta}\$"]
        B["Bootstrap Estimators: \$\\hat{\\theta}_1, ..., \\hat{\\theta}_B\$"]
        C["Bootstrap Mean: \$\\frac{1}{B} \\sum_{b=1}^B \\hat{\\theta}_b\$"]
        D["Expected Value: \$E[\\hat{\\theta}]\$"]
        B --> C
        C --> D
        style D fill:#ccf
    end
```

*Prova:*
A prova √© baseada na defini√ß√£o de esperan√ßa e na amostragem com reposi√ß√£o. Se cada $\hat{\theta}_b$ √© gerado por uma amostra bootstrap e se assume que cada amostra bootstrap √© uma realiza√ß√£o da distribui√ß√£o subjacente, ent√£o a m√©dia das amostras bootstrap, $\frac{1}{B} \sum_{b=1}^B \hat{\theta}_b$, converge para $E[\hat{\theta}]$ quando $B \rightarrow \infty$. $\blacksquare$

**Conceito 2: Agrega√ß√£o de Modelos (Bagging)**
O *Bagging* ou *Bootstrap Aggregating* √© uma t√©cnica que combina as predi√ß√µes de v√°rios modelos constru√≠dos a partir de diferentes amostras bootstrap dos dados de treinamento [^8.7]. No caso de regress√£o, as predi√ß√µes s√£o tipicamente agregadas atrav√©s da m√©dia, enquanto que em classifica√ß√£o a agrega√ß√£o pode envolver a vota√ß√£o majorit√°ria ou a m√©dia das probabilidades previstas [^8.7]. O objetivo do bagging √© reduzir a vari√¢ncia de modelos inst√°veis (alta sensibilidade a pequenas mudan√ßas nos dados de treinamento) como √°rvores de decis√£o, e a m√©dia das predi√ß√µes tendem a ser mais est√°veis que a predi√ß√£o de um √∫nico modelo [^8.7.1].

> üí° **Exemplo Num√©rico:** Vamos supor que temos um modelo de regress√£o que preve o pre√ßo de casas e usamos Bagging com 3 amostras bootstrap. Para uma casa espec√≠fica com caracter√≠sticas $x$, temos as seguintes predi√ß√µes de cada modelo treinado nas amostras bootstrap:
>
> *   $f^*_1(x) = 320000$
> *   $f^*_2(x) = 350000$
> *   $f^*_3(x) = 335000$
>
> A predi√ß√£o do modelo Bagging seria:
>
> $\hat{f}_{bag}(x) = \frac{320000 + 350000 + 335000}{3} = 335000$
>
> A predi√ß√£o agregada pelo Bagging, 335000, √© mais est√°vel em compara√ß√£o com os modelos individuais. Cada modelo base pode variar dependendo da amostra, mas a agrega√ß√£o suaviza a vari√¢ncia e tende a fornecer um resultado mais confi√°vel.

**Corol√°rio 1:** Seja $f(x)$ a predi√ß√£o de um modelo ajustado nos dados de treinamento originais e seja $f^*_b(x)$ a predi√ß√£o de um modelo ajustado em uma amostra bootstrap $Z^*_b$. O estimador Bagging $\hat{f}_{bag}(x) = \frac{1}{B} \sum_{b=1}^B f^*_b(x)$ tem uma vari√¢ncia menor que o estimador original $f(x)$ em cen√°rios de modelos inst√°veis, como √°rvores de decis√£o [^8.7.1], [^8.7.2].

```mermaid
graph LR
    subgraph "Bagging Variance Reduction"
        A["Original Prediction: f(x)"]
        B["Bootstrap Predictions: f*_b(x)"]
        C["Bagged Prediction: \$\\hat{f}_{bag}(x) = \\frac{1}{B} \\sum_{b=1}^B f^*_b(x)\$"]
        A --> C
        B --> C
        style C fill:#ccf
    end
```

*Prova:*
A redu√ß√£o da vari√¢ncia ocorre porque o bagging substitui a predi√ß√£o inst√°vel $f(x)$ por uma m√©dia de v√°rias predi√ß√µes $f^*_b(x)$.  A vari√¢ncia da m√©dia de vari√°veis aleat√≥rias independentes √© sempre menor do que a vari√¢ncia de uma √∫nica vari√°vel aleat√≥ria quando agregamos v√°rias amostras e isso se traduz em menor vari√¢ncia para o estimador $\hat{f}_{bag}(x)$.

**Conceito 3: Modelos Base e Instabilidade**
O Bagging √© particularmente √∫til para modelos base que s√£o inst√°veis. √Årvores de decis√£o, por exemplo, s√£o modelos que tendem a variar muito com pequenas mudan√ßas nos dados de treinamento [^8.7.1]. Isso ocorre porque as √°rvores de decis√£o tendem a criar parti√ß√µes complexas e podem ser muito influenciadas por outliers ou pequenas perturba√ß√µes nos dados [^8.7.1]. A instabilidade de modelos base √© a principal raz√£o para a efic√°cia do Bagging. Em modelos lineares, como a regress√£o linear com um conjunto fixo de preditores, o bagging geralmente n√£o oferece melhorias significativas, j√° que o modelo em si √© est√°vel e n√£o varia muito quando treinado em diferentes amostras [^8.7].

> ‚ö†Ô∏è **Nota Importante**: O Bagging n√£o altera o vi√©s de um modelo, apenas a vari√¢ncia. Isso significa que o Bagging pode n√£o melhorar modelos com alto vi√©s, mas √© altamente eficaz em reduzir a vari√¢ncia de modelos com baixo vi√©s, mas alta vari√¢ncia [^8.7.2].
> ‚ùó **Ponto de Aten√ß√£o**: A independ√™ncia das amostras bootstrap √© uma suposi√ß√£o chave para a efic√°cia do Bagging. Se houver depend√™ncia forte entre as amostras, a redu√ß√£o de vari√¢ncia pode ser menor que o esperado. [^8.7.2]
> ‚úîÔ∏è **Destaque**: O Bagging √© uma t√©cnica de prop√≥sito geral que pode ser aplicada a diversos tipos de modelos base, desde que estes sejam inst√°veis. [^8.7]

### Regress√£o Linear e M√≠nimos Quadrados para Bagging
A regress√£o linear cl√°ssica, na sua forma padr√£o, n√£o se beneficia significativamente do Bagging, conforme mencionado no contexto [^8.7]. Isso ocorre porque os modelos de regress√£o linear, quando treinados com um conjunto fixo de preditores, s√£o inerentemente est√°veis. No entanto, se a regress√£o linear for utilizada como modelo base em um contexto mais complexo, onde a sele√ß√£o de vari√°veis √© feita por m√©todos como *best subsets* em regress√£o linear, ent√£o o Bagging pode trazer melhorias [^8.8]. O processo de Bagging envolve ajustar v√°rias regress√µes lineares em amostras bootstrap e, em seguida, agregar as predi√ß√µes. A f√≥rmula (8.51) [^8.7] continua sendo a base da agrega√ß√£o:
$$ \hat{f}_{bag}(x) = \frac{1}{B} \sum_{b=1}^B f^*_b(x) $$
Onde:
*   $\hat{f}_{bag}(x)$ √© a predi√ß√£o agregada do Bagging.
*   $f^*_b(x)$ √© a predi√ß√£o do modelo ajustado na $b$-√©sima amostra bootstrap.
*   $B$ √© o n√∫mero de amostras bootstrap.

Se a regress√£o linear for utilizada com sele√ß√£o de vari√°veis feita por meio de um algoritmo de *best subsets*, o ajuste de cada modelo base seleciona o melhor subconjunto de preditores, levando a modelos mais inst√°veis (i.e. modelos que mudam consideravelmente ao serem treinados com dados diferentes).

```mermaid
graph LR
    A["Training Data"] --> B["Bootstrap Sampling"];
    B --> C{"Linear Regression with Best Subsets"};
    C --> D["Prediction Model 1"];
    B --> E{"Linear Regression with Best Subsets"};
    E --> F["Prediction Model 2"];
    ...
    B --> G{"Linear Regression with Best Subsets"};
    G --> H["Prediction Model B"];
    D & F & H --> I["Aggregation (Average)"];
    I --> J["Final Prediction"];
    style J fill:#ccf
```

**Explica√ß√£o:** Este diagrama ilustra o processo de Bagging aplicado a modelos de regress√£o linear com sele√ß√£o de vari√°veis. As amostras bootstrap s√£o geradas, modelos lineares s√£o treinados com sele√ß√£o de *best subsets* em cada amostra, e as predi√ß√µes s√£o agregadas para formar a predi√ß√£o final, conforme descrito no contexto [^8.7], [^8.8].

> üí° **Exemplo Num√©rico:** Vamos considerar um conjunto de dados com 100 observa√ß√µes e 10 preditores. Queremos aplicar regress√£o linear com sele√ß√£o de vari√°veis (best subsets) como modelo base para Bagging. Para simplificar, vamos ilustrar com 3 amostras bootstrap:
>
> 1.  **Amostras Bootstrap:**
>     *   `bootstrap_sample_1`: Amostra de 100 observa√ß√µes com reposi√ß√£o do conjunto original.
>     *   `bootstrap_sample_2`: Outra amostra de 100 observa√ß√µes com reposi√ß√£o.
>     *   `bootstrap_sample_3`: Uma terceira amostra de 100 observa√ß√µes com reposi√ß√£o.
>
> 2.  **Modelos de Regress√£o Linear (Best Subsets):**
>     *   **Modelo 1:** Ajustamos um modelo de regress√£o linear na `bootstrap_sample_1` com sele√ß√£o de *best subsets*. Suponha que o modelo selecione os preditores $X_1, X_3, X_5$ e encontre os seguintes coeficientes: $\beta_1 = 2.1$, $\beta_3 = -0.5$, $\beta_5 = 1.2$. A predi√ß√£o seria: $\hat{y}_1 = 2.1X_1 - 0.5X_3 + 1.2X_5$
>     *   **Modelo 2:** Ajustamos um modelo em `bootstrap_sample_2`.  Neste caso, o modelo pode selecionar preditores diferentes, por exemplo, $X_2, X_4, X_6$. Suponha que encontremos $\beta_2 = 0.8$, $\beta_4 = 1.1$, $\beta_6 = -0.7$. A predi√ß√£o seria: $\hat{y}_2 = 0.8X_2 + 1.1X_4 - 0.7X_6$
>     *   **Modelo 3:** O modelo ajustado em `bootstrap_sample_3` seleciona os preditores $X_1, X_4, X_9$, com $\beta_1 = 1.5$, $\beta_4 = 0.9$, $\beta_9 = 0.6$. A predi√ß√£o seria: $\hat{y}_3 = 1.5X_1 + 0.9X_4 + 0.6X_9$.
>
> 3.  **Agrega√ß√£o:** Para um novo ponto $x$, calculamos as predi√ß√µes de cada modelo: $\hat{y}_1(x)$, $\hat{y}_2(x)$, e $\hat{y}_3(x)$. Em seguida, agregamos pela m√©dia: $\hat{y}_{bag}(x) = \frac{\hat{y}_1(x) + \hat{y}_2(x) + \hat{y}_3(x)}{3}$.
>
> Este exemplo ilustra como o Bagging, quando combinado com sele√ß√£o de vari√°veis, pode criar modelos mais robustos, com cada modelo base selecionando diferentes subconjuntos de preditores e, assim, reduzindo a vari√¢ncia da predi√ß√£o final.

**Lemma 2:** Se $f(x)$ √© um modelo de regress√£o linear est√°vel, a aplica√ß√£o do Bagging n√£o levar√° a uma redu√ß√£o significativa do erro de generaliza√ß√£o, dado que a vari√¢ncia do estimador original j√° √© baixa.

*Prova:*
A prova decorre da estabilidade dos modelos de regress√£o linear. Como a vari√¢ncia da predi√ß√£o em modelos de regress√£o linear est√°veis √© baixa, a agrega√ß√£o n√£o traz melhorias significativas, j√° que cada modelo bootstrap gera uma predi√ß√£o similar. $\blacksquare$

**Corol√°rio 2:** No caso em que a regress√£o linear √© combinada com sele√ß√£o de vari√°veis inst√°vel, o Bagging pode reduzir a vari√¢ncia das predi√ß√µes, resultando em um modelo final mais robusto.

*Prova:*
A sele√ß√£o de vari√°veis como *best subsets* cria modelos inst√°veis e a vari√¢ncia √© reduzida pela m√©dia das predi√ß√µes dos modelos treinados em amostras bootstrap diferentes. $\blacksquare$

"Em cen√°rios onde a sele√ß√£o de vari√°veis √© feita de maneira inst√°vel, o Bagging pode ser uma ferramenta valiosa para estabilizar as predi√ß√µes da regress√£o linear, reduzindo o risco de *overfitting* e melhorando a capacidade de generaliza√ß√£o do modelo".
"Ainda assim, √© importante notar que para um modelo de regress√£o linear bem comportado, o *gain* do Bagging √© baixo, conforme discutido no contexto [^8.7]."

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Bagging

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas que complementam o Bagging, especialmente em contextos de alta dimensionalidade. A regulariza√ß√£o, como penaliza√ß√µes $L_1$ e $L_2$, pode ser aplicada aos modelos base dentro do Bagging, para controlar a complexidade individual de cada modelo. A sele√ß√£o de vari√°veis tamb√©m pode ser combinada com o Bagging, onde cada modelo base pode escolher um subconjunto diferente de vari√°veis, criando modelos ainda mais diversos [^8.7], [^8.8]. Essas t√©cnicas adicionam uma camada de controle, tornando o processo mais robusto e menos propenso ao *overfitting*.

**Lemma 3:** Se os modelos base do bagging utilizam regulariza√ß√£o $L_1$, a esparsidade dos modelos base √© controlada, e o modelo final do bagging preserva uma estrutura de coeficientes mais simples, contribuindo para uma maior interpretabilidade.

```mermaid
graph LR
    subgraph "L1 Regularization in Bagging"
        A["Bootstrap Sample"] --> B{"L1 Regularized Base Model"}
        B --> C["Sparse Coefficients"]
        C --> D["Bagging Aggregation"]
        D --> E["Final Model with Reduced Complexity"]
        style E fill:#ccf
    end
```

*Prova:*
A regulariza√ß√£o $L_1$ (Lasso) induz a esparsidade dos coeficientes nos modelos base, tornando alguns coeficientes exatamente zero. A agrega√ß√£o dos modelos com coeficientes esparsos pode resultar em um modelo final mais interpretabilidade, pois destaca quais vari√°veis s√£o mais relevantes. $\blacksquare$

> üí° **Exemplo Num√©rico:** Vamos supor que cada modelo base no Bagging √© uma regress√£o linear com regulariza√ß√£o $L_1$ (Lasso). Para simplificar, vamos considerar 2 amostras bootstrap e um problema com 4 preditores ($X_1, X_2, X_3, X_4$):
>
> 1.  **Modelos Base com Regulariza√ß√£o L1 (Lasso):**
>
>     *   **Modelo 1:** Ajustamos na primeira amostra bootstrap, com regulariza√ß√£o $L_1$.  Suponha que o Lasso resulte nos seguintes coeficientes: $\beta_1 = 0.8$, $\beta_2 = 0$, $\beta_3 = -0.2$, $\beta_4 = 0$. A predi√ß√£o √©: $\hat{y}_1 = 0.8X_1 - 0.2X_3$
>     *   **Modelo 2:** Ajustamos na segunda amostra bootstrap, tamb√©m com regulariza√ß√£o $L_1$. Os coeficientes encontrados foram: $\beta_1 = 0$, $\beta_2 = 0.5$, $\beta_3 = 0$, $\beta_4 = 0.3$. A predi√ß√£o √©: $\hat{y}_2 = 0.5X_2 + 0.3X_4$.
>
> 2.  **Agrega√ß√£o:** Para um novo ponto $x$, calculamos as predi√ß√µes dos modelos: $\hat{y}_1(x)$ e $\hat{y}_2(x)$. Agregamos pela m√©dia:  $\hat{y}_{bag}(x) = \frac{\hat{y}_1(x) + \hat{y}_2(x)}{2}$.
>
> Observamos que os modelos base resultaram em modelos esparsos devido a regulariza√ß√£o $L_1$, com apenas alguns coeficientes n√£o nulos, o que facilita a interpretabilidade e auxilia a sele√ß√£o de vari√°veis relevantes.

**Corol√°rio 3:** A combina√ß√£o de Bagging com regulariza√ß√£o $L_2$ em cada modelo base leva √† redu√ß√£o da vari√¢ncia do modelo final, e a m√©dia de modelos regularizados com $L_2$ tende a ser mais est√°vel que modelos sem regulariza√ß√£o.

```mermaid
graph LR
    subgraph "L2 Regularization in Bagging"
        A["Bootstrap Sample"] --> B{"L2 Regularized Base Model"}
       B --> C["Reduced Coefficient Magnitude"]
        C --> D["Bagging Aggregation"]
       D --> E["Stable Final Model"]
       style E fill:#ccf
   end
```

*Prova:*
A regulariza√ß√£o $L_2$ (Ridge) reduz os coeficientes, o que contribui para a redu√ß√£o da vari√¢ncia, j√° que modelos base com menor magnitude em seus coeficientes tendem a ter menor vari√¢ncia. A agrega√ß√£o de modelos regularizados com $L_2$ resulta em um modelo final mais est√°vel. $\blacksquare$

> üí° **Exemplo Num√©rico:** Vamos usar o mesmo exemplo anterior, mas agora com regulariza√ß√£o $L_2$ (Ridge) nos modelos base:
>
> 1. **Modelos Base com Regulariza√ß√£o L2 (Ridge):**
>     *   **Modelo 1:** Ajustamos na primeira amostra bootstrap com regulariza√ß√£o $L_2$.  Suponha que o Ridge resulte nos seguintes coeficientes: $\beta_1 = 0.6$, $\beta_2 = 0.2$, $\beta_3 = -0.1$, $\beta_4 = 0.1$. A predi√ß√£o √©: $\hat{y}_1 = 0.6X_1 + 0.2X_2 - 0.1X_3 + 0.1X_4$. Note que o Ridge n√£o zera os coeficientes, apenas reduz sua magnitude.
>     *   **Modelo 2:** Ajustamos na segunda amostra bootstrap, tamb√©m com regulariza√ß√£o $L_2$. Os coeficientes encontrados foram: $\beta_1 = 0.1$, $\beta_2 = 0.4$, $\beta_3 = 0.2$, $\beta_4 = -0.2$. A predi√ß√£o √©: $\hat{y}_2 = 0.1X_1 + 0.4X_2 + 0.2X_3 - 0.2X_4$.
> 2.  **Agrega√ß√£o:** Para um novo ponto $x$, calculamos as predi√ß√µes dos modelos: $\hat{y}_1(x)$ e $\hat{y}_2(x)$. Agregamos pela m√©dia:  $\hat{y}_{bag}(x) = \frac{\hat{y}_1(x) + \hat{y}_2(x)}{2}$.
>
> Comparando com o exemplo anterior com regulariza√ß√£o $L_1$, a regulariza√ß√£o $L_2$ n√£o zera os coeficientes, mas reduz sua magnitude, o que torna os modelos mais est√°veis e contribui para a redu√ß√£o da vari√¢ncia ap√≥s a agrega√ß√£o.

> ‚ö†Ô∏è **Ponto Crucial**: A combina√ß√£o de Bagging com regulariza√ß√£o ou sele√ß√£o de vari√°veis deve ser cuidadosa. O n√≠vel de regulariza√ß√£o deve ser determinado usando valida√ß√£o cruzada, e a sele√ß√£o de vari√°veis deve ser feita de maneira que cada modelo base seja diverso o suficiente para beneficiar o modelo agregado.
> ‚ùó **Ponto de Aten√ß√£o**: O Bagging com modelos base muito complexos podem ainda levar ao *overfitting*. O balan√ßo entre complexidade dos modelos base e a diversidade introduzida pelo Bagging √© essencial para um modelo final robusto e generaliz√°vel.

### Separating Hyperplanes e Perceptrons com Bagging
Os Separating Hyperplanes, especialmente no contexto de *Support Vector Machines* (SVM), e os Perceptrons s√£o m√©todos que se beneficiam do Bagging quando aplicados a problemas complexos com fronteiras de decis√£o n√£o lineares ou com dados que levam a uma alta vari√¢ncia do modelo base [^8.7]. No caso dos Perceptrons, o Bagging pode ajudar a estabilizar o modelo, reduzindo a sensibilidade a pontos de dados individuais. Para SVMs, a agrega√ß√£o de m√∫ltiplos hiperplanos pode gerar uma fronteira de decis√£o mais robusta, especialmente em dados com ru√≠do [^8.7].

**Teorema 1:** Considere um problema de classifica√ß√£o com dados n√£o linearmente separ√°veis. Se o modelo base √© um Perceptron (ou SVM linear), o Bagging pode gerar um classificador agregado que se aproxima de uma fronteira de decis√£o n√£o linear mais complexa, a medida que o n√∫mero de amostras bootstrap aumenta.

```mermaid
graph LR
    subgraph "Bagging with Perceptrons"
        A["Non-linearly Separable Data"] --> B["Bootstrap Samples"]
        B --> C{"Perceptron Base Models"}
        C --> D["Linear Decision Boundaries"]
        D --> E["Bagging Aggregation (Voting)"]
        E --> F["Complex Non-linear Decision Boundary"]
        style F fill:#ccf
    end
```

*Prova:*
Cada modelo base √© ajustado em uma amostra bootstrap diferente e a combina√ß√£o desses modelos lineares podem levar a um modelo n√£o linear quando agregados. A variabilidade causada pelo bootstrap permite que o modelo agregado explore diferentes regi√µes do espa√ßo de caracter√≠sticas, resultando em uma fronteira de decis√£o final mais complexa.

> üí° **Exemplo Num√©rico:** Vamos considerar um problema de classifica√ß√£o bin√°ria com dados n√£o linearmente separ√°veis. Vamos aplicar Bagging com Perceptrons como modelo base.
>
> 1.  **Dados:** Suponha que temos dados com duas classes (0 e 1) em duas dimens√µes ($X_1$ e $X_2$), que n√£o s√£o separ√°veis por uma linha reta.
> 2.  **Modelos Base (Perceptrons):**
>     *   **Modelo 1:** Ajustamos um Perceptron na primeira amostra bootstrap. O Perceptron encontra uma fronteira de decis√£o linear que separa as classes de forma imperfeita.  A predi√ß√£o ser√°: $\hat{y}_1 = sign(w_1X_1 + w_2X_2 + b)$.
>     *   **Modelo 2:** Ajustamos um Perceptron na segunda amostra bootstrap.  O Perceptron pode encontrar uma fronteira de decis√£o linear ligeiramente diferente da anterior. A predi√ß√£o ser√°: $\hat{y}_2 = sign(w_1'X_1 + w_2'X_2 + b')$.
>     *   **Modelo 3... B:** Repetimos este processo para B amostras bootstrap.
>
> 3.  **Agrega√ß√£o:** Para um novo ponto $x$, cada Perceptron gera uma predi√ß√£o (0 ou 1). A predi√ß√£o final do Bagging √© dada pela vota√ß√£o majorit√°ria (a classe mais frequente entre os B modelos).
>
> Como cada Perceptron explora diferentes regi√µes do espa√ßo de caracter√≠sticas devido √†s amostras bootstrap, o classificador agregado do Bagging pode aproximar uma fronteira de decis√£o n√£o linear mais complexa que um √∫nico Perceptron.

### Pergunta Te√≥rica Avan√ßada (Exemplo): Qual o impacto do tamanho da amostra bootstrap no desempenho do Bagging?

**Resposta:**
O tamanho da amostra bootstrap tem um impacto significativo no desempenho do Bagging. Em geral, o tamanho da amostra bootstrap (normalmente igual ao tamanho da amostra original) deve ser grande o suficiente para capturar a variabilidade dos dados, mas n√£o t√£o grande a ponto de reproduzir a amostra original, o que n√£o adicionaria diversidade suficiente ao processo. A escolha do tamanho da amostra bootstrap deve considerar o compromisso entre diversidade e estabilidade, conforme discutido em [^8.7].

**Lemma 4:** √Ä medida que o tamanho da amostra bootstrap se aproxima do tamanho da amostra original, a vari√¢ncia do estimador do Bagging diminui.

```mermaid
graph LR
    subgraph "Bootstrap Sample Size Effect"
        A["Small Bootstrap Sample Size"] --> B["High Variance Base Model"]
         B --> C["High Bagging Variance"]
        A1["Bootstrap Sample Size ~ Original"] --> B1["Lower Variance Base Model"]
        B1 --> C1["Lower Bagging Variance"]
          C --> D ["Bagging Estimate"]
         C1 --> D
    end
```

*Prova:*
Quando o tamanho da amostra bootstrap √© muito menor que a amostra original, alguns dados s√£o frequentemente omitidos, gerando uma maior varia√ß√£o das predi√ß√µes e consequentemente do modelo. Por outro lado, se o tamanho da amostra bootstrap se aproxima do tamanho da amostra original, a vari√¢ncia se reduz. $\blacksquare$

**Corol√°rio 4:** Em problemas com pequena quantidade de dados, o uso de um tamanho de amostra bootstrap menor que o tamanho original pode adicionar diversidade e evitar o sobreajuste da amostra bootstrap original.

*Prova:*
Para amostras pequenas, amostras bootstrap que tem o mesmo tamanho da amostra original tendem a ter uma alta correla√ß√£o entre si, reduzindo a diversidade e o benef√≠cio do Bagging. Quando a amostra bootstrap √© menor, dados distintos s√£o omitidos, aumentando a diversidade dos modelos base. $\blacksquare$

> ‚ö†Ô∏è **Ponto Crucial**: A escolha do tamanho da amostra bootstrap deve ser feita com cuidado, considerando o tamanho da amostra original e a complexidade dos modelos base. Uma valida√ß√£o cruzada pode auxiliar na determina√ß√£o do tamanho ideal da amostra bootstrap.
> ‚ùó **Ponto de Aten√ß√£o**: Apesar da variabilidade dos modelos base, o m√©todo Bagging s√≥ beneficia modelos de baixa vari√¢ncia no limite quando $B \rightarrow \infty$. √â importante o n√∫mero de modelos base $B$ ser grande o suficiente para que o Bagging agregue as predi√ß√µes de forma efetiva.

### Conclus√£o
O Bagging √© uma ferramenta essencial para o desenvolvimento de modelos robustos e precisos em aprendizado de m√°quina. Atrav√©s da reamostragem bootstrap e da agrega√ß√£o de modelos, o Bagging reduz a vari√¢ncia e melhora a capacidade de generaliza√ß√£o dos modelos base, especialmente aqueles que s√£o inst√°veis. Embora o Bagging possa n√£o ser a solu√ß√£o ideal para todos os problemas, a sua efic√°cia em reduzir a vari√¢ncia de modelos inst√°veis o torna uma t√©cnica valiosa para profissionais em estat√≠stica e aprendizado de m√°quina. Conforme discutido no contexto [^8.7], √© crucial compreender as nuances do Bagging para aplic√°-lo de forma eficaz e obter os melhores resultados em cada cen√°rio espec√≠fico. O Bagging √© uma t√©cnica que fornece uma base s√≥lida para m√©todos mais avan√ßados, como *Random Forests*, que exploram a diversidade gerada pelo bootstrap de maneira ainda mais eficiente.

### Footnotes
[^8.1]: "For most of this book, the fitting (learning) of models has been achieved by minimizing a sum of squares for regression, or by minimizing cross-entropy for classification. In fact, both of these minimizations are instances of the maximum likelihood approach to fitting." *(Trecho de Model Inference and Averaging)*
[^8.2]: "In this chapter we provide a general exposition of the maximum likelihood approach, as well as the Bayesian method for inference. The bootstrap, introduced in Chapter 7, is discussed in this context, and its relation to maximum likelihood and Bayes is described. Finally, we present some related techniques for model averaging and improvement, including committee methods, bagging, stacking and bumping." *(Trecho de Model Inference and Averaging)*
[^8.2.1]: "The bootstrap method provides a direct computational way of assessing uncertainty, by sampling from the training data. Here we illustrate the bootstrap in a simple one-dimensional smoothing problem, and show its connection to maximum likelihood." *(Trecho de Model Inference and Averaging)*
[^8.2.3]: "In essence the bootstrap is a computer implementation of nonparametric or parametric maximum likelihood. The advantage of the bootstrap over the maximum likelihood formula is that it allows us to compute maximum likelihood estimates of standard errors and other quantities in settings where no formulas are available." *(Trecho de Model Inference and Averaging)*
[^8.7]: "Earlier we introduced the bootstrap as a way of assessing the accuracy of a parameter estimate or a prediction. Here we show how to use the bootstrap to improve the estimate or prediction itself. In Section 8.4 we investigated the relationship between the bootstrap and Bayes approaches, and found that the bootstrap mean is approximately a posterior average. Bagging further exploits this connection." *(Trecho de Model Inference and Averaging)*
[^8.7.1]: "Consider first the regression problem. Suppose we fit a model to our training data Z = {(X1,Y1), (X2,Y2), ..., (XN, yn)}, obtaining the prediction f(x) at input x. Bootstrap aggregation or bagging averages this prediction over a collection of bootstrap samples, thereby reducing its variance." *(Trecho de Model Inference and Averaging)*
[^8.7.2]: "The bagged estimate (8.51) will differ from the original estimate f(x) only when the latter is a nonlinear or adaptive function of the data. For example, to bag the B-spline smooth of Section 8.2.1, we average the curves in the bottom left panel of Figure 8.2 at each value of x. The B-spline smoother is linear in the data if we fix the inputs; hence if we sample using the parametric bootstrap in equation (8.6), then fbag(x) ‚Üí f(x) as B ‚Üí8 (Exercise 8.4). Hence bagging just reproduces the original smooth in the top left panel of Figure 8.2. The same is approximately true if we were to bag using the nonparametric bootstrap." *(Trecho de Model Inference and Averaging)*
[^8.8]: "Here we discuss Bayesian model averaging more generally. We have a set of candidate models Mm, m = 1,..., M for our training set Z. These models may be of the same type with different parameter values (e.g., subsets in linear regression), or different models for the same task (e.g., neural networks and regression trees)." *(Trecho de Model Inference and Averaging)*
