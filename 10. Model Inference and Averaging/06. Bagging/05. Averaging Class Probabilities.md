Okay, I've analyzed the text and added Mermaid diagrams to enhance the understanding of the mathematical and statistical concepts presented, focusing on theoretical relationships and algorithm visualizations, while adhering to all specified guidelines.

## Averaging Class Probabilities: Uma An√°lise Aprofundada de T√©cnicas de Classifica√ß√£o e Model Averaging

```mermaid
graph LR
    subgraph "Classification Techniques & Model Averaging"
      direction TB
      A["Linear Discriminant Analysis (LDA)"]
      B["Logistic Regression"]
      C["Separating Hyperplanes"]
      D["Regularization (L1, L2, Elastic Net)"]
      E["Model Averaging (Bagging, Stacking, Bumping)"]
      F["Class Probability Averaging"]
      A --> F
      B --> F
      C --> F
      D --> E
      E --> F
    end
```

### Introdu√ß√£o

Este cap√≠tulo explora em detalhes o conceito de **averaging de probabilidades de classe** como uma ferramenta poderosa no contexto de **modelos de aprendizado estat√≠stico diversos**. Partimos da base de m√©todos de classifica√ß√£o bem estabelecidos, como a **Linear Discriminant Analysis (LDA)**, a **Logistic Regression**, e a cria√ß√£o de **separating hyperplanes**, para avan√ßar para estrat√©gias que visam aprimorar a robustez e precis√£o das predi√ß√µes atrav√©s da combina√ß√£o de m√∫ltiplos modelos. O foco √©, essencialmente, em como a m√©dia das probabilidades de classe (obtidas de diferentes modelos) pode levar a resultados mais confi√°veis e consistentes do que as predi√ß√µes de um √∫nico modelo. Este estudo se aprofunda em conceitos de infer√™ncia estat√≠stica e t√©cnicas de aprendizado de m√°quina, com o objetivo de fornecer uma compreens√£o abrangente do tema [^8.1]. O cap√≠tulo tamb√©m abordar√° as conex√µes entre o *bootstrap*, a *maximum likelihood* e os m√©todos bayesianos, fornecendo um contexto te√≥rico robusto para a pr√°tica do *averaging* de modelos. Al√©m disso, m√©todos de regulariza√ß√£o e sele√ß√£o de vari√°veis ser√£o explorados para aprimorar o processo de modelagem antes da etapa de *averaging*.

### Conceitos Fundamentais

**Conceito 1: Problemas de Classifica√ß√£o e Modelos Lineares**

O problema de classifica√ß√£o envolve a aloca√ß√£o de observa√ß√µes a classes predefinidas. M√©todos lineares, como a **LDA** e a **Logistic Regression**, projetam a complexidade da classifica√ß√£o em um espa√ßo onde as classes s√£o separ√°veis por meio de hiperplanos [^8.1]. A escolha de um modelo linear implica um vi√©s que pode ser ben√©fico ou prejudicial, dependendo da verdadeira natureza da rela√ß√£o entre os preditores e as classes. Por exemplo, se as classes s√£o separ√°veis por uma superf√≠cie altamente n√£o linear, um modelo linear pode apresentar um vi√©s elevado, mas ainda assim, em algumas circunst√¢ncias, uma baixa vari√¢ncia [^8.2].

**Lemma 1:** A fun√ß√£o discriminante linear $f(x) = w^T x + b$, onde $w$ √© o vetor de pesos e $b$ √© o bias, particiona o espa√ßo de caracter√≠sticas em duas regi√µes lineares separadas por um hiperplano, cuja normal √© $w$. Essa decomposi√ß√£o √© fundamental para entender a opera√ß√£o de modelos lineares de classifica√ß√£o, e a sua rela√ß√£o com proje√ß√µes em subespa√ßos de menor dimens√£o [^8.3].

```mermaid
graph LR
    subgraph "Linear Discriminant Function"
        direction TB
        A["Discriminant Function: f(x) = w^T x + b"]
        B["w: Weight Vector"]
        C["b: Bias Term"]
        D["x: Input Vector"]
        E["Hyperplane: w^T x = -b"]
        A --> B
        A --> C
        A --> D
        A --> E
    end
```

$$ \text{Prova:} \quad f(x) = 0 \implies w^Tx + b = 0 \implies w^T x = -b \quad \text{Onde} \quad x \quad \text{√© um ponto no hiperplano.} \blacksquare$$

> üí° **Exemplo Num√©rico:** Imagine um problema de classifica√ß√£o em 2D com duas classes. Seja $w = \begin{bmatrix} 2 \\ -1 \end{bmatrix}$ e $b = -3$. A fun√ß√£o discriminante √© $f(x) = 2x_1 - x_2 - 3$. O hiperplano (neste caso, uma linha) √© definido por $2x_1 - x_2 - 3 = 0$. Para um ponto $x = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$, $f(x) = 2(1) - 1 - 3 = -2 < 0$, indicando que ele est√° de um lado do hiperplano. Para o ponto $x = \begin{bmatrix} 3 \\ 2 \end{bmatrix}$, $f(x) = 2(3) - 2 - 3 = 1 > 0$, indicando que ele est√° do outro lado.

**Conceito 2: Linear Discriminant Analysis (LDA)**

A **LDA** assume que as classes seguem distribui√ß√µes gaussianas com mesma matriz de covari√¢ncia, o que leva a fronteiras de decis√£o lineares. A **LDA** busca o melhor subespa√ßo de proje√ß√£o linear que maximiza a separa√ß√£o entre as m√©dias das classes e minimiza a vari√¢ncia dentro de cada classe [^8.3]. Em termos matem√°ticos, a **LDA** calcula uma fun√ß√£o discriminante para cada classe $k$ como $\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + log(\pi_k)$, onde $\Sigma$ √© a matriz de covari√¢ncia comum, $\mu_k$ √© o vetor de m√©dias da classe $k$ e $\pi_k$ √© a probabilidade *a priori* da classe $k$ [^8.3.1]. A classe predita para um dado input $x$ √© a que maximiza $\delta_k(x)$. Uma das principais limita√ß√µes da LDA √© a sua suposi√ß√£o de normalidade e igualdade de covari√¢ncias entre as classes [^8.3.2].

```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction TB
        A["Discriminant Function: Œ¥_k(x) = x^T Œ£‚Åª¬π Œº_k - 1/2 Œº_k^T Œ£‚Åª¬π Œº_k + log(œÄ_k)"]
        B["Œ£: Common Covariance Matrix"]
        C["Œº_k: Mean Vector of Class k"]
        D["œÄ_k: Prior Probability of Class k"]
        E["x: Input Vector"]
        A --> B
        A --> C
        A --> D
        A --> E
    end
```

**Corol√°rio 1:** Quando as matrizes de covari√¢ncia das classes n√£o s√£o iguais, a fronteira de decis√£o entre as classes se torna quadr√°tica (Quadratic Discriminant Analysis - QDA), e as fun√ß√µes discriminantes n√£o s√£o mais lineares, sendo dadas por $\delta_k(x) = -\frac{1}{2} log|\Sigma_k| - \frac{1}{2} (x - \mu_k)^T \Sigma_k^{-1} (x - \mu_k) + log(\pi_k)$ [^8.3.3].

> üí° **Exemplo Num√©rico:** Considere um problema com duas classes e duas features, onde classe 1 tem m√©dia $\mu_1 = \begin{bmatrix} 1 \\ 2 \end{bmatrix}$ e classe 2 tem m√©dia $\mu_2 = \begin{bmatrix} 3 \\ 4 \end{bmatrix}$. A matriz de covari√¢ncia comum √© $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$. As probabilidades a priori s√£o $\pi_1 = 0.4$ e $\pi_2 = 0.6$. Para um ponto $x = \begin{bmatrix} 2 \\ 3 \end{bmatrix}$, podemos calcular $\delta_1(x)$ e $\delta_2(x)$, onde $\Sigma^{-1} = \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix}$.

> $\delta_1(x) = \begin{bmatrix} 2 & 3 \end{bmatrix} \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} + \log(0.4) \approx -1.06$

> $\delta_2(x) = \begin{bmatrix} 2 & 3 \end{bmatrix} \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 4 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 4 \end{bmatrix} \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 4 \end{bmatrix} + \log(0.6) \approx -0.57$

> Como $\delta_2(x) > \delta_1(x)$, o ponto $x$ seria classificado como pertencente √† classe 2.

**Conceito 3: Regress√£o Log√≠stica**

A **Logistic Regression** modela a probabilidade de uma observa√ß√£o pertencer a uma classe usando uma fun√ß√£o log√≠stica aplicada a uma combina√ß√£o linear dos preditores. A fun√ß√£o log√≠stica, tamb√©m conhecida como fun√ß√£o sigmoide, √© dada por $\sigma(z) = \frac{1}{1 + e^{-z}}$, onde $z = \beta_0 + \beta^T x$ [^8.4]. A probabilidade de um input $x$ pertencer √† classe 1 √© $P(Y=1|x) = \sigma(\beta_0 + \beta^T x)$, e a probabilidade de pertencer √† classe 0 √© $P(Y=0|x) = 1 - \sigma(\beta_0 + \beta^T x)$. Os par√¢metros s√£o estimados atrav√©s da maximiza√ß√£o da verossimilhan√ßa (likelihood). A **Logistic Regression** √© mais flex√≠vel que a **LDA**, pois n√£o assume normalidade dos dados, mas ainda assume uma fronteira de decis√£o linear no espa√ßo dos preditores [^8.4.1].

```mermaid
graph LR
    subgraph "Logistic Regression"
      direction TB
        A["Sigmoid Function: œÉ(z) = 1 / (1 + e^-z)"]
        B["z = Œ≤‚ÇÄ + Œ≤·µÄx"]
        C["P(Y=1|x) = œÉ(Œ≤‚ÇÄ + Œ≤·µÄx)"]
        D["P(Y=0|x) = 1 - œÉ(Œ≤‚ÇÄ + Œ≤·µÄx)"]
        A --> B
        B --> C
        B --> D
    end
```

> ‚ö†Ô∏è **Nota Importante**: Na regress√£o log√≠stica, os coeficientes $\beta$ representam a mudan√ßa no log-odds para um aumento unit√°rio no preditor correspondente, mantendo os outros preditores constantes [^8.4.2].

> ‚ùó **Ponto de Aten√ß√£o**: Em casos de classes n√£o balanceadas, √© essencial ajustar a fun√ß√£o de custo para evitar que o modelo favore√ßa a classe majorit√°ria, o que pode ser feito atrav√©s de pesos ou t√©cnicas de *oversampling* ou *undersampling* [^8.4.3].

> ‚úîÔ∏è **Destaque**: Embora a **LDA** e a **Logistic Regression** sejam ambas classificadores lineares, suas suposi√ß√µes subjacentes e forma de estimar os par√¢metros s√£o diferentes. Em particular, a **Logistic Regression** modela a probabilidade condicional das classes, enquanto a **LDA** modela a distribui√ß√£o condicional dos preditores dadas as classes [^8.5].

> üí° **Exemplo Num√©rico:** Suponha um modelo de regress√£o log√≠stica com $\beta_0 = -2$ e $\beta = \begin{bmatrix} 1 \\ 0.5 \end{bmatrix}$. Para um ponto $x = \begin{bmatrix} 2 \\ 1 \end{bmatrix}$, temos $z = -2 + 1(2) + 0.5(1) = 0.5$. Assim, $P(Y=1|x) = \sigma(0.5) = \frac{1}{1 + e^{-0.5}} \approx 0.62$. A probabilidade de pertencer √† classe 0 √© $1 - 0.62 = 0.38$.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
      direction LR
        A["Indicator Matrix Y (N x K)"]
        B["Design Matrix X"]
        C["Coefficients Matrix B"]
        D["Error Matrix E"]
        E["Linear Regression: Y = XB + E"]
        F["Least Squares Solution: BÃÇ = (X·µÄX)‚Åª¬πX·µÄY"]
        A & B & C & D --> E
        E --> F
    end
```

A regress√£o linear pode ser aplicada √† classifica√ß√£o por meio da regress√£o em matrizes de indicadores, onde cada classe √© representada por uma coluna na matriz de resposta. Os coeficientes s√£o estimados por meio do m√©todo de m√≠nimos quadrados (least squares - LS), que busca minimizar a soma dos quadrados dos erros entre os valores preditos e os valores observados. No entanto, esta abordagem tem limita√ß√µes quando aplicada diretamente a problemas de classifica√ß√£o [^8.2].

Em cen√°rios de classifica√ß√£o, a regress√£o linear pode produzir predi√ß√µes que extrapolam o intervalo [0,1], perdendo a interpreta√ß√£o como probabilidade. Al√©m disso, a minimiza√ß√£o do erro quadr√°tico m√©dio pode n√£o ser a m√©trica mais adequada para classifica√ß√£o, onde o objetivo principal √© classificar corretamente as observa√ß√µes [^8.2]. A **LDA** e a **Logistic Regression**, por sua vez, s√£o m√©todos mais adequados, pois modelam diretamente a probabilidade das classes.

**Lemma 2:** Dada uma matriz de indicadores Y de dimens√£o N √ó K (onde N √© o n√∫mero de observa√ß√µes e K √© o n√∫mero de classes), a solu√ß√£o de m√≠nimos quadrados para os coeficientes $\hat{B}$ na regress√£o linear $Y = XB + E$, onde X √© a matriz de design, √© dada por $\hat{B} = (X^T X)^{-1}X^T Y$. Se as classes forem codificadas ortogonalmente, o problema se torna equivalente a aplicar regress√µes lineares separadas para cada classe [^8.2].

**Corol√°rio 2:** As proje√ß√µes nos hiperplanos de decis√£o gerados por regress√£o linear e discriminantes lineares s√£o equivalentes em certas condi√ß√µes, como quando se utiliza uma codifica√ß√£o ortogonal para as classes e as covari√¢ncias das classes s√£o id√™nticas [^8.3]. Isso estabelece uma conex√£o fundamental entre os dois tipos de modelos.

> ‚ö†Ô∏è **Ponto Crucial**: A regress√£o de indicadores, embora possa ser usada para classifica√ß√£o, n√£o modela diretamente as probabilidades das classes, e portanto suas previs√µes podem ser dif√≠ceis de interpretar em termos probabil√≠sticos [^8.2].
> ‚ùó **Ponto de Aten√ß√£o**: Em problemas com muitas classes, a regress√£o de indicadores pode levar a problemas de multicolinearidade e instabilidade na estimativa dos par√¢metros [^8.3].
"Em certos casos, conforme mencionado em [^8.4], a regress√£o log√≠stica apresenta estimativas mais est√°veis das probabilidades, e a regress√£o de indicadores pode levar a extrapola√ß√µes fora do intervalo [0,1]."
"Por outro lado, existem situa√ß√µes em que a regress√£o de indicadores √© adequada, conforme indicado em [^8.2], quando o objetivo principal √© definir a fronteira de decis√£o linear."

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com 3 amostras e um preditor. A matriz de design X √© $\begin{bmatrix} 1 & 2 \\ 1 & 3 \\ 1 & 4 \end{bmatrix}$ e a matriz de indicadores Y √© $\begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix}$. Calculando $(X^T X)^{-1}$, temos $(X^T X) = \begin{bmatrix} 3 & 9 \\ 9 & 29 \end{bmatrix}$ e $(X^T X)^{-1} = \begin{bmatrix} 29/6 & -9/6 \\ -9/6 & 3/6 \end{bmatrix}$. Portanto, $\hat{B} = (X^T X)^{-1}X^T Y = \begin{bmatrix} 29/6 & -9/6 \\ -9/6 & 3/6 \end{bmatrix} \begin{bmatrix} 1 & 1 & 1 \\ 2 & 3 & 4 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix} = \begin{bmatrix} 2/6 & 1/6 \\ -1/6 & 1/6 \end{bmatrix}$. A previs√£o para um novo ponto $x = \begin{bmatrix} 1 \\ 5 \end{bmatrix}$ seria $ \begin{bmatrix} 1 & 5 \end{bmatrix} \begin{bmatrix} 2/6 & 1/6 \\ -1/6 & 1/6 \end{bmatrix} = \begin{bmatrix} -3/6 & 6/6 \end{bmatrix}$, ou seja, -0.5 para a classe 1 e 1 para classe 2, o que n√£o representa uma probabilidade.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Techniques"
      direction TB
      A["L1 Regularization (Lasso)"]
      B["L2 Regularization (Ridge)"]
      C["Elastic Net Regularization"]
      D["Cost Function with Regularization"]
      E["Sparsity of Coefficients"]
      F["Magnitude Reduction of Coefficients"]
      A --> D
      B --> D
      C --> D
      A --> E
      B --> F
      C --> E
      C --> F
    end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas fundamentais para controlar a complexidade dos modelos, melhorar a generaliza√ß√£o e a interpretabilidade. Em classifica√ß√£o, especialmente quando o n√∫mero de preditores √© alto, a regulariza√ß√£o pode ser essencial para evitar *overfitting*. Existem dois m√©todos principais de regulariza√ß√£o: a penalidade L1 (Lasso) e a penalidade L2 (Ridge) [^8.4.4].

A penalidade L1 adiciona um termo √† fun√ß√£o de custo que √© proporcional √† soma dos valores absolutos dos coeficientes. Isso promove a esparsidade, ou seja, zera alguns coeficientes, resultando em um modelo mais simples e f√°cil de interpretar. A penalidade L2 adiciona um termo proporcional √† soma dos quadrados dos coeficientes, levando a uma redu√ß√£o na magnitude dos pesos, mas n√£o necessariamente a zer√°-los. A Elastic Net combina as penalidades L1 e L2, utilizando um par√¢metro que controla a contribui√ß√£o de cada uma [^8.5.1].

**Lemma 3:** A penaliza√ß√£o L1 na regress√£o log√≠stica leva a coeficientes esparsos por meio da imposi√ß√£o de uma penalidade na norma L1 dos coeficientes, ou seja, $\sum_{j=1}^p |\beta_j|$. Isso for√ßa alguns dos coeficientes a serem exatamente zero, efetivamente removendo a import√¢ncia de certos preditores no modelo [^8.4.4].

```mermaid
graph LR
    subgraph "L1 Regularization"
        direction TB
        A["L1 Penalty Term: Œª ‚àë|Œ≤‚±º|"]
        B["Cost Function: J(Œ≤) = -‚àë[y·µ¢log(p·µ¢) + (1-y·µ¢)log(1-p·µ¢)] + Œª‚àë|Œ≤‚±º|"]
        C["Œª: Regularization Parameter"]
        D["Œ≤‚±º: Coefficients"]
        E["Sparsity of Coefficients (Some Œ≤‚±º = 0)"]
        A --> B
        B --> C
        B --> D
        B --> E
    end
```

**Prova do Lemma 3:** Considere a fun√ß√£o de custo da regress√£o log√≠stica com regulariza√ß√£o L1:
$$ J(\beta) = -\sum_{i=1}^N [y_i \log(p_i) + (1-y_i)\log(1-p_i)] + \lambda \sum_{j=1}^p |\beta_j| $$
onde $p_i = \sigma(x_i^T\beta)$, $\lambda$ √© o par√¢metro de regulariza√ß√£o. Quando $\lambda$ √© grande o suficiente, a otimiza√ß√£o da fun√ß√£o de custo leva a que alguns dos coeficientes $\beta_j$ sejam exatamente iguais a zero, promovendo a esparsidade do modelo [^8.4.4]. $\blacksquare$

**Corol√°rio 3:** A esparsidade induzida pela regulariza√ß√£o L1 melhora a interpretabilidade do modelo, pois ela identifica os preditores mais relevantes para a classifica√ß√£o. Isto tamb√©m ajuda a reduzir o risco de *overfitting* [^8.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: A escolha entre L1 e L2 (ou uma combina√ß√£o via Elastic Net) depende do problema espec√≠fico. L1 √© √∫til quando se espera que muitos preditores sejam irrelevantes, enquanto L2 √© prefer√≠vel quando se deseja reduzir a magnitude de todos os coeficientes sem necessariamente zer√°-los [^8.5.1].

> üí° **Exemplo Num√©rico:** Considere uma regress√£o log√≠stica com dois preditores. Sem regulariza√ß√£o, os coeficientes podem ser $\beta = \begin{bmatrix} 1.5 \\ -2.0 \end{bmatrix}$. Com regulariza√ß√£o L1 $(\lambda=0.8)$, os coeficientes podem se tornar $\beta_{L1} = \begin{bmatrix} 0.7 \\ 0 \end{bmatrix}$, zerando o segundo preditor. Com regulariza√ß√£o L2 $(\lambda=0.8)$, os coeficientes podem se tornar $\beta_{L2} = \begin{bmatrix} 1.0 \\ -1.3 \end{bmatrix}$, reduzindo a magnitude mas n√£o zerando nenhum.

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Separating Hyperplane"
        direction TB
        A["Hyperplane: w·µÄx + b = 0"]
        B["Margin"]
        C["Support Vectors"]
        D["Dual Wolfe Optimization"]
        A --> B
        B --> C
        B --> D
    end
```

O conceito de **separating hyperplanes** √© central para os m√©todos lineares de classifica√ß√£o. A ideia √© encontrar um hiperplano que separe as diferentes classes de maneira ideal. Um hiperplano √≥timo √© aquele que maximiza a margem, ou seja, a dist√¢ncia m√≠nima entre o hiperplano e os pontos mais pr√≥ximos de cada classe, chamados pontos de suporte. A formula√ß√£o do problema de otimiza√ß√£o para encontrar o hiperplano ideal pode ser resolvida por meio do dual de Wolfe [^8.5.2].

The **Perceptron** is an iterative algorithm that seeks to find a hyperplane that separates the data linearly. The algorithm iteratively adjusts the weights of the hyperplane based on classification errors and converges to a solution when the data are linearly separable [^8.5.1]. The convergence of the Perceptron under specific conditions is guaranteed by the Perceptron convergence theorem.

```mermaid
graph TB
    subgraph "Perceptron Algorithm"
        direction TB
        A["Initialization: w, b"]
        B["For each training point x_i:"]
        C["Compute Prediction: yÃÇ = sign(w·µÄx·µ¢ + b)"]
        D["Update Weights: w = w + Œ∑(y·µ¢ - yÃÇ)x·µ¢"]
        E["Update Bias: b = b + Œ∑(y·µ¢ - yÃÇ)"]
        F["Convergence: All training points correctly classified"]
        A --> B
        B --> C
        C --> D
        D --> E
        E --> B
        B --> F
    end
```

> üí° **Exemplo Num√©rico:** Imagine um problema de classifica√ß√£o bin√°ria com duas caracter√≠sticas. Os pesos iniciais do Perceptron s√£o $w = \begin{bmatrix} 0.1 \\ -0.2 \end{bmatrix}$ e bias $b = 0.05$. Temos um ponto $x = \begin{bmatrix} 1 \\ 2 \end{bmatrix}$ que pertence √† classe 1 (y=1). A previs√£o inicial √© $\hat{y} = sign(0.1*1 - 0.2*2 + 0.05) = sign(-0.25) = -1$ (classe 0). O erro de classifica√ß√£o √© $y-\hat{y}= 1-(-1)=2$. O Perceptron atualiza os pesos e o bias por $w_{new} = w + \eta * (y - \hat{y}) * x$ e $b_{new} = b + \eta*(y - \hat{y})$, onde $\eta$ √© a taxa de aprendizado. Com $\eta = 0.1$, $w_{new} = \begin{bmatrix} 0.1 \\ -0.2 \end{bmatrix} + 0.1*2* \begin{bmatrix} 1 \\ 2 \end{bmatrix} = \begin{bmatrix} 0.3 \\ 0.2 \end{bmatrix}$ e $b_{new} = 0.05 + 0.1*2=0.25$.

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**

A **LDA** e a Regra de Decis√£o Bayesiana, quando aplicadas a dados gaussianos com covari√¢ncias iguais, est√£o intimamente relacionadas. Ambas visam classificar observa√ß√µes com base na probabilidade de pertencerem a cada classe. No entanto, elas diferem em sua abordagem. A **LDA** estima os par√¢metros do modelo (m√©dias e covari√¢ncia) diretamente a partir dos dados, enquanto a Regra de Decis√£o Bayesiana calcula a probabilidade *a posteriori* das classes usando as probabilidades *a priori* e a fun√ß√£o de densidade de probabilidade condicional dos dados dada cada classe [^8.3].

Se as classes forem gaussianas com a mesma matriz de covari√¢ncia, o limiar de decis√£o entre as classes se torna linear, o que √© an√°logo ao que acontece na **LDA**. Formalmente, a Regra de Decis√£o Bayesiana atribui uma observa√ß√£o x √† classe $k$ se:

$$ P(Y=k|x) = \frac{P(x|Y=k)P(Y=k)}{P(x)} > P(Y=j|x), \quad \forall j \neq k $$

Sob a suposi√ß√£o gaussiana e de mesma covari√¢ncia, $P(x|Y=k) = \frac{1}{\sqrt{(2\pi)^p |\Sigma|}} e^{-\frac{1}{2}(x - \mu_k)^T \Sigma^{-1}(x - \mu_k)}$, e o limiar de decis√£o torna-se linear. A **LDA**, por sua vez, busca a proje√ß√£o que melhor separa as m√©dias das classes, o que √© equivalente √† Regra de Decis√£o Bayesiana sob as mesmas premissas [^8.3].

**Lemma 4:** Se a fun√ß√£o de densidade de probabilidade dos preditores dado a classe ($P(x|Y=k)$) √© gaussiana com mesma matriz de covari√¢ncia para todas as classes e a regra de decis√£o Bayesiana √© aplicada, ent√£o o limite de decis√£o √© linear e equivalente ao da **LDA** [^8.3].

```mermaid
graph LR
    subgraph "Bayesian Decision Rule & LDA"
        direction TB
        A["Bayesian Decision Rule: argmax P(Y=k|x)"]
        B["Gaussian Conditional Density: P(x|Y=k)"]
        C["Linear Decision Boundary"]
        D["LDA Function: Œ¥_k(x)"]
        E["Equivalent Decision Boundaries"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

**Prova do Lemma 4:** Para a regra de decis√£o Bayesiana com distribui√ß√µes gaussianas com covari√¢ncias iguais, a regi√£o de classifica√ß√£o para a classe *k* √© definida por:
$$
\arg\max_k P(Y=k|x) \propto \arg\max_k P(x|Y=k)P(Y=k).
$$
Tomando o logaritmo e desconsiderando termos constantes, temos:
$$
\arg\max_k -\frac{1}{2}(x-\mu_k)^T\Sigma^{-1}(x-\mu_k) + \log(\pi_k) = \arg\max_k x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log(\pi_k)
$$
A fun√ß√£o discriminante encontrada √© linear, e coincide com a da LDA [^8.3]. $\blacksquare$

**Corol√°rio 4:** Ao remover a suposi√ß√£o de covari√¢ncias iguais, a Regra de Decis√£o Bayesiana leva a fronteiras de decis√£o quadr√°ticas, e as fun√ß√µes discriminantes s√£o dadas por $\delta_k(x) = -\frac{1}{2} \log|\Sigma_k| - \frac{1}{2} (x - \mu_k)^T \Sigma_k^{-1} (x - \mu_k) + \log(\pi_k)$, o que caracteriza o **QDA** [^8.3].

> ‚ö†Ô∏è **Ponto Crucial**: A escolha entre assumir ou n√£o igualdade de covari√¢ncias (LDA vs. QDA) impacta fortemente o tipo de fronteira de decis√£o (linear vs. quadr√°tica) e o desempenho do modelo, com o **LDA** sendo prefer√≠vel em amostras menores para evitar *overfitting* [^8.3.1].

### Conclus√£o

Este cap√≠tulo forneceu uma an√°lise aprofundada das t√©cnicas de classifica√ß√£o, desde abordagens lineares como **LDA** e **Logistic Regression**, at√© m√©todos de *model averaging* como *bagging*, *stacking*, e *bumping*, com um foco especial em *averaging* de probabilidades de classe. Ao longo do texto, foram abordadas as conex√µes te√≥ricas entre o *bootstrap*, a *maximum likelihood* e abordagens bayesianas, incluindo m√©todos de regulariza√ß√£o e sele√ß√£o de vari√°veis, al√©m de um exame detalhado dos conceitos de **separating hyperplanes** e do algoritmo **Perceptron**. A an√°lise te√≥rica e as deriva√ß√µes apresentadas, culminando nas perguntas avan√ßadas, solidificam uma compreens√£o abrangente de como esses m√©todos se encaixam no contexto mais amplo do aprendizado estat√≠stico e como eles podem ser empregados para melhorar a robustez e precis√£o das predi√ß√µes.
