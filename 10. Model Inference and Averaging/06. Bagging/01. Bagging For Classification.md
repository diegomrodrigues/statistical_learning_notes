## Bagging para Classifica√ß√£o: Uma An√°lise Aprofundada

```mermaid
graph LR
    subgraph "Bagging Overview"
        direction TB
        A["Original Dataset 'Z'"] --> B["Bootstrap Sampling (B times)"]
        B --> C["Bootstrap Sample 'Z*b' (for b=1 to B)"]
        C --> D["Train Classifier 'Gb(x)' on 'Z*b'"]
        D --> E["Aggregate Predictions ('Vota√ß√£o Majorit√°ria')"]
        E --> F["Final Prediction 'Gbag(x)'"]
    end
```

### Introdu√ß√£o

O conceito de **Bagging** (Bootstrap Aggregating), conforme brevemente mencionado em [^8.1] como uma t√©cnica para *model averaging and improvement*, √© uma metodologia poderosa para melhorar a precis√£o e a estabilidade de modelos de classifica√ß√£o, especialmente aqueles que s√£o intrinsecamente inst√°veis. O objetivo principal do bagging √© reduzir a vari√¢ncia de modelos de aprendizado de m√°quina, atrav√©s da combina√ß√£o de previs√µes de m√∫ltiplos modelos treinados em amostras bootstrap do conjunto de dados original. Este cap√≠tulo explorar√° em detalhes o mecanismo de bagging aplicado especificamente a problemas de classifica√ß√£o, comparando-o com outras t√©cnicas de ensemble learning e discutindo suas limita√ß√µes e vantagens. Os conceitos e resultados aqui apresentados ser√£o fundamentados nos t√≥picos do documento fornecido [^8.1], [^8.2], [^8.7] e [^8.8] e seus subitens.

### Conceitos Fundamentais

Para compreender o funcionamento do bagging em problemas de classifica√ß√£o, √© fundamental estabelecer alguns conceitos-chave:

**Conceito 1: Amostragem Bootstrap**

O bagging depende da gera√ß√£o de **amostras bootstrap**, que s√£o amostras aleat√≥rias do conjunto de dados original, obtidas com reposi√ß√£o [^8.2.1]. Formalmente, dado um conjunto de dados $Z = \{z_1, z_2, \ldots, z_N\}$, onde $z_i = (x_i, y_i)$, uma amostra bootstrap $Z^{*b}$ consiste em $N$ elementos amostrados de $Z$ com reposi√ß√£o.  Isso significa que cada amostra bootstrap ter√° o mesmo n√∫mero de exemplos que o conjunto de dados original, mas com algumas inst√¢ncias repetidas e outras ausentes. A nota√ß√£o $b$ aqui indexa o n√∫mero da amostra bootstrap, variando de $1$ a $B$, onde $B$ √© o n√∫mero total de amostras bootstrap que s√£o geradas.

> üí° **Exemplo Num√©rico:** Suponha que temos um conjunto de dados original com 5 inst√¢ncias: $Z = \{(x_1, y_1), (x_2, y_2), (x_3, y_3), (x_4, y_4), (x_5, y_5)\}$. Uma poss√≠vel amostra bootstrap $Z^{*1}$ pode ser $\{(x_2, y_2), (x_4, y_4), (x_2, y_2), (x_1, y_1), (x_5, y_5)\}$, onde $x_2$ foi amostrado duas vezes e $x_3$ n√£o foi amostrado. Uma segunda amostra $Z^{*2}$ pode ser $\{(x_1, y_1), (x_3, y_3), (x_5, y_5), (x_5, y_5), (x_2, y_2)\}$, com outras repeti√ß√µes.

**Lemma 1:** *Para um conjunto de dados finito, a probabilidade de uma inst√¢ncia espec√≠fica n√£o ser selecionada em uma amostra bootstrap de tamanho N √© $(1 - \frac{1}{N})^N$, e essa probabilidade tende a $e^{-1} \approx 0.368$ conforme $N$ tende ao infinito.* Isso indica que cerca de 36.8% das amostras originais n√£o s√£o inclu√≠das em uma dada amostra bootstrap. Essa propriedade garante a variabilidade entre as diferentes amostras bootstrap.

**Prova:**

A probabilidade de uma inst√¢ncia espec√≠fica *ser* selecionada em uma amostra bootstrap √© $\frac{1}{N}$. Portanto, a probabilidade de ela *n√£o ser* selecionada em uma √∫nica amostragem √© $1 - \frac{1}{N}$.  Se realizamos $N$ amostragem independentes, a probabilidade de que a inst√¢ncia nunca seja selecionada √© $(1 - \frac{1}{N})^N$.  No limite, conforme $N \rightarrow \infty$, esta express√£o tende para $e^{-1}$, que √© aproximadamente $0.368$. $\blacksquare$

**Conceito 2: Classificadores Individuais**

Com cada amostra bootstrap $Z^{*b}$, treinamos um modelo de classifica√ß√£o individual $G_b(x)$. Este pode ser qualquer classificador de aprendizado de m√°quina, como √°rvores de decis√£o, regress√£o log√≠stica ou redes neurais [^8.7], embora o bagging seja mais eficaz quando aplicado a classificadores inst√°veis (i.e., aqueles cuja varia√ß√£o no conjunto de treinamento resulta em modelos bastante distintos). A instabilidade destes classificadores contribui para a efic√°cia do bagging.

```mermaid
graph LR
    subgraph "Classifier Instability"
        direction TB
        A["Small changes in training data"] --> B["Large differences in 'G(x)' output"]
        B --> C["High variance in classifier predictions"]
    end
```

**Corol√°rio 1:** *A instabilidade de um classificador individual √© um fator crucial para a efic√°cia do bagging.* Quanto mais sens√≠vel o classificador for a pequenas mudan√ßas nos dados de treinamento, mais variados ser√£o os modelos treinados em diferentes amostras bootstrap, o que √© crucial para reduzir a vari√¢ncia do classificador de ensemble.

> üí° **Exemplo Num√©rico:** Considere o uso de √°rvores de decis√£o como classificadores base. √Årvores de decis√£o s√£o conhecidas por serem inst√°veis; pequenas altera√ß√µes no conjunto de treinamento (como as obtidas por bootstrap) podem levar a √°rvores de estrutura muito diferente. Se treinarmos uma √°rvore em $Z^{*1}$ e outra em $Z^{*2}$, elas podem gerar diferentes regras de decis√£o.

**Conceito 3: Agrega√ß√£o das Previs√µes**

A etapa final do bagging envolve a **agrega√ß√£o das previs√µes** dos classificadores individuais. No contexto da classifica√ß√£o, a agrega√ß√£o √© geralmente realizada atrav√©s da **vota√ß√£o majorit√°ria**: para um dado exemplo $x$, a classe predita pelo ensemble √© a classe mais frequentemente predita pelos classificadores individuais [^8.7]. Formalmente, a classifica√ß√£o final $G_{bag}(x)$ √© dada por:

$$G_{bag}(x) = \underset{k}{\mathrm{argmax}} \sum_{b=1}^B I(G_b(x) = k)$$

onde $k$ √© o √≠ndice da classe, $I(.)$ √© a fun√ß√£o indicadora, que √© igual a 1 se a condi√ß√£o for verdadeira e 0 caso contr√°rio. $G_b(x)$ √© a classe predita pelo $b$-√©simo classificador.

```mermaid
graph LR
    subgraph "Aggregation by Majority Vote"
    direction TB
    A["Individual predictions: 'G1(x), G2(x), ..., Gb(x)'"]
    B["Indicator function 'I(Gb(x) = k)' for each class 'k'"]
    C["Sum of indicator values across classifiers: 'sum(I(Gb(x) = k))' for each class 'k'"]
    D["'argmax' of the sum: 'Gbag(x) = argmax sum(I(Gb(x) = k))'"]
    A --> B
    B --> C
    C --> D
    end
```

> üí° **Exemplo Num√©rico:** Suponha que tenhamos $B=5$ classificadores treinados por bagging e 3 classes poss√≠veis: A, B, e C. Para um exemplo $x$, as predi√ß√µes s√£o: $G_1(x) = A$, $G_2(x) = B$, $G_3(x) = A$, $G_4(x) = C$, e $G_5(x) = A$.  A classe A foi predita 3 vezes, B uma vez e C uma vez. A vota√ß√£o majorit√°ria resulta em $G_{bag}(x) = A$.

> ‚ö†Ô∏è **Nota Importante:** A agrega√ß√£o de classifica√ß√µes por vota√ß√£o majorit√°ria, em muitos casos, n√£o produz estimativas de probabilidade adequadas, e a m√©dia direta das predi√ß√µes de probabilidade dos classificadores individuais pode levar a resultados menos vi√©sados [^8.7].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o: Analogia e Limita√ß√µes

A regress√£o linear, aplicada a uma matriz de indicadores (onde cada coluna representa uma classe), √© uma abordagem alternativa para problemas de classifica√ß√£o. A liga√ß√£o entre a regress√£o de indicadores e m√©todos de classifica√ß√£o, como o Linear Discriminant Analysis (LDA) e a regress√£o log√≠stica, √© not√°vel, pois todos buscam encontrar uma fronteira de decis√£o linear. Contudo, essa analogia tem limita√ß√µes importantes.

**Conex√£o com o Bagging**

Embora a regress√£o linear direta em uma matriz de indicadores n√£o seja o m√©todo de classifica√ß√£o mais est√°vel, ela pode ser usada como o classificador base dentro do framework do bagging. Cada modelo de regress√£o linear seria treinado em uma amostra bootstrap diferente, e as previs√µes poderiam ser combinadas (por exemplo, por vota√ß√£o majorit√°ria) como em um problema de classifica√ß√£o usual.

**Lemma 2:** *Sob certas condi√ß√µes (quando as classes s√£o bem separadas e h√° um n√∫mero suficiente de amostras), a fronteira de decis√£o obtida pela regress√£o linear da matriz de indicadores pode se assemelhar √†quela encontrada pelo LDA.* Isso √© an√°logo ao fato de que, em situa√ß√µes ideais, ambos os modelos podem gerar classificadores lineares eficazes, embora suas formula√ß√µes sejam bastante diferentes.

**Prova:**

Na regress√£o linear da matriz de indicadores, procuramos encontrar um modelo da forma $\hat{Y} = X\beta$, onde $X$ √© a matriz de dados e $\beta$ s√£o os par√¢metros do modelo.  Cada coluna de $\hat{Y}$ representa as probabilidades de pertin√™ncia a uma dada classe, sendo que a classe predita √© a que gera maior probabilidade.  O LDA, por sua vez, procura encontrar uma proje√ß√£o linear para separar as classes com base em uma an√°lise da matriz de covari√¢ncia.   Em situa√ß√µes onde as classes s√£o bem separadas e as vari√¢ncias dentro das classes s√£o homog√™neas, ambas as abordagens tendem a gerar fronteiras lineares similares, embora utilizem abordagens diferentes (m√≠nimos quadrados na regress√£o linear, e an√°lise de covari√¢ncia no LDA). $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com tr√™s classes (A, B, C). A matriz de indicadores teria tr√™s colunas, onde cada linha representa uma inst√¢ncia e possui um '1' na coluna correspondente √† sua classe e '0' nas outras. Por exemplo, uma inst√¢ncia da classe B seria representada por `[0, 1, 0]`. Uma regress√£o linear seria feita para prever cada coluna da matriz indicadora. Os outputs da regress√£o linear poderiam ser vistos como "scores" de pertin√™ncia √† classe. A classe predita seria aquela que obtiver o maior score.

**Corol√°rio 2:** *A principal limita√ß√£o da regress√£o linear para classifica√ß√£o reside em sua tend√™ncia a extrapolar, gerando probabilidades fora do intervalo [0,1], o que a torna inadequada para estimativas de probabilidade.* Al√©m disso, a regress√£o de indicadores n√£o lida de forma robusta com a multicolinearidade e a n√£o-linearidade dos dados [^8.2]. Essas limita√ß√µes s√£o atenuadas pelo bagging.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

A inclus√£o de m√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o na classifica√ß√£o √© crucial para lidar com problemas de alta dimensionalidade e evitar o sobreajuste, [^8.7] e esses m√©todos podem ser usados em conjunto com o bagging.

**Regulariza√ß√£o no Contexto do Bagging**

Dentro de um framework de bagging, regulariza√ß√£o, como penalidades L1 e L2, podem ser aplicadas *a cada classificador individual* treinado em uma amostra bootstrap [^8.2]. As penalidades L1, por exemplo, induzem esparsidade, o que pode levar a modelos mais simples e interpret√°veis. As penalidades L2, por sua vez, reduzem a magnitude dos coeficientes, aumentando a estabilidade.

```mermaid
graph LR
    subgraph "Regularization in Bagging"
        direction TB
        A["Bootstrap Sample 'Z*b'"] --> B["Train Classifier with Regularization: L1 or L2"]
        B --> C["Regularized Classifier 'Gb(x)'"]
    end
```

**Lemma 3:** *O uso da penalidade L1 em conjunto com o bagging pode levar a modelos mais interpret√°veis e robustos, selecionando as vari√°veis mais relevantes para a classifica√ß√£o.* A esparsidade induzida pela penalidade L1 simplifica a interpreta√ß√£o do modelo.

**Prova:**

A penalidade L1 adiciona um termo √† fun√ß√£o de perda, proporcional √† soma dos valores absolutos dos coeficientes: $L(w) + \lambda ||w||_1$, onde $L(w)$ √© a fun√ß√£o de perda, $w$ s√£o os par√¢metros do modelo e $\lambda$ √© um par√¢metro de regulariza√ß√£o. Essa penaliza√ß√£o for√ßa alguns coeficientes a serem exatamente zero, realizando a sele√ß√£o de vari√°veis e induzindo esparsidade.  Quando combinada com o bagging, essa abordagem ajuda a selecionar de forma mais est√°vel as vari√°veis mais importantes, resultando em modelos mais interpret√°veis. $\blacksquare$

> üí° **Exemplo Num√©rico:** Em um problema de classifica√ß√£o com muitas vari√°veis (features), digamos 100, poder√≠amos utilizar uma regress√£o log√≠stica regularizada com L1 como classificador base no bagging. A penalidade L1 ($\lambda$) for√ßaria alguns coeficientes a serem zero, efetivamente selecionando um subconjunto das vari√°veis mais relevantes para cada amostra bootstrap. Ao agregarmos os resultados, as vari√°veis que forem selecionadas com mais frequ√™ncia ser√£o consideradas as mais importantes para a classifica√ß√£o final.
```python
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Simula√ß√£o de dados com 100 features
np.random.seed(42)
X = np.random.rand(1000, 100)
y = np.random.randint(0, 2, 1000)

# Divis√£o em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fun√ß√£o para treinar um classificador com regulariza√ß√£o L1 em uma amostra bootstrap
def train_l1_classifier(X_train, y_train, lambda_val):
    n_samples = len(X_train)
    bootstrap_indices = np.random.choice(n_samples, size=n_samples, replace=True)
    X_bootstrap = X_train[bootstrap_indices]
    y_bootstrap = y_train[bootstrap_indices]
    
    model = LogisticRegression(penalty='l1', solver='liblinear', C=1/lambda_val, random_state=42)
    model.fit(X_bootstrap, y_bootstrap)
    return model

# Bagging com regulariza√ß√£o L1
B = 10
lambda_val = 0.1
models = [train_l1_classifier(X_train, y_train, lambda_val) for _ in range(B)]

# Previs√£o por vota√ß√£o majorit√°ria
def predict_bagging(X, models):
    predictions = np.array([model.predict(X) for model in models])
    ensemble_predictions = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=0, arr=predictions)
    return ensemble_predictions

y_pred = predict_bagging(X_test, models)
accuracy = accuracy_score(y_test, y_pred)
print(f"Acur√°cia do bagging com regulariza√ß√£o L1: {accuracy:.4f}")
```
**Corol√°rio 3:** *A regulariza√ß√£o L2 combinada com o bagging aumenta a estabilidade dos modelos, o que √© crucial quando os classificadores individuais s√£o inst√°veis.* A regulariza√ß√£o L2 reduz a vari√¢ncia dos par√¢metros do modelo.

> üí° **Exemplo Num√©rico:** Similar ao exemplo anterior, usar√≠amos a penalidade L2 (Ridge regression no caso de regress√£o, ou regulariza√ß√£o L2 na regress√£o log√≠stica). A penalidade L2 ($\lambda$) n√£o induz esparsidade mas reduz a magnitude dos coeficientes. Isso estabiliza os coeficientes do classificador base em cada amostra bootstrap, resultando em modelos mais consistentes.

> ‚ùó **Ponto de Aten√ß√£o:** O bagging n√£o resolve problemas relacionados ao vi√©s do modelo; portanto, modelos regularizados e selecionados corretamente ainda s√£o necess√°rios para garantir um bom desempenho geral da classifica√ß√£o. A combina√ß√£o de regulariza√ß√£o e bagging oferece uma solu√ß√£o mais completa.

### Separating Hyperplanes e Perceptrons: Paralelos e Diferen√ßas

O conceito de **separating hyperplanes** surge de classificadores lineares como o Perceptron e o SVM (Support Vector Machines), que buscam definir uma superf√≠cie linear √≥tima que separa as classes. Embora o Perceptron n√£o seja t√£o sofisticado quanto o SVM (especialmente em lidar com dados n√£o linearmente separ√°veis), ele ilustra a busca por hiperplanos de decis√£o.

**Separating Hyperplanes no Contexto do Bagging**

Cada amostra bootstrap pode levar a um hiperplano de separa√ß√£o diferente se o classificador base for o Perceptron. O bagging pode ajudar a estabilizar esses hiperplanos por meio da combina√ß√£o das previs√µes.
```mermaid
graph LR
    subgraph "Hyperplanes in Bagging"
        direction TB
    A["Bootstrap Sample 'Z*b'"] --> B["Train Perceptron 'Gb(x)'"]
    B --> C["Hyperplane 'Hb'"]
    end
```

> üí° **Exemplo Num√©rico:** Imagine um problema de classifica√ß√£o com duas classes visualizadas em um espa√ßo bidimensional. Se usarmos o Perceptron como classificador base em um framework de bagging, cada amostra bootstrap pode levar a um hiperplano de separa√ß√£o ligeiramente diferente. Em algumas amostras, o hiperplano pode estar mais inclinado, enquanto em outras pode estar mais horizontal. Ao combinar as previs√µes desses perceptrons via vota√ß√£o majorit√°ria, o bagging tende a gerar um classificador mais est√°vel.

### Pergunta Te√≥rica Avan√ßada: Como o Bagging Difere da Sele√ß√£o de Modelos Via Cross-Validation?

**Resposta:**

O bagging e a sele√ß√£o de modelos por cross-validation abordam diferentes aspectos da modelagem. Enquanto a sele√ß√£o de modelos via cross-validation busca selecionar o melhor modelo *entre* um conjunto de modelos candidatos [^8.2], o bagging n√£o realiza sele√ß√£o, mas sim combina *todos* os modelos treinados em amostras bootstrap.

```mermaid
graph LR
    subgraph "Bagging vs. Cross-Validation"
        direction TB
        A["Cross-Validation: Model Selection"] --> B["Evaluate several models"]
        B --> C["Select best model based on performance"]
        A --> D["Bagging: Model Aggregation"]
        D --> E["Train multiple models on bootstrap samples"]
        E --> F["Combine predictions of all models"]
    end
```

**Lemma 4:** *Cross-validation √© usada para avaliar e selecionar o melhor modelo, buscando um √∫nico modelo √≥timo. O bagging combina m√∫ltiplos modelos, buscando reduzir a vari√¢ncia das predi√ß√µes. Ambos s√£o √∫teis, mas abordam o problema de formas distintas.*

**Corol√°rio 4:** *Enquanto a cross-validation busca reduzir o vi√©s e encontrar o modelo com menor erro geral, o bagging visa reduzir a vari√¢ncia do modelo, o que √© mais relevante quando o modelo base √© inst√°vel.* Na pr√°tica, ambos podem ser complementares, onde a cross-validation pode ser usada para ajustar o modelo base e, em seguida, o bagging pode ser usado para aumentar a sua estabilidade.

> ‚ö†Ô∏è **Ponto Crucial:** A sele√ß√£o de modelos √© mais adequada quando h√° um n√∫mero razo√°vel de modelos claramente distingu√≠veis, enquanto o bagging √© mais apropriado quando os modelos base s√£o inst√°veis e a combina√ß√£o de m√∫ltiplas previs√µes pode reduzir a vari√¢ncia geral.

> üí° **Exemplo Num√©rico:** Para entender a diferen√ßa, imagine que temos 3 modelos de classifica√ß√£o diferentes: uma √°rvore de decis√£o simples, uma regress√£o log√≠stica e um SVM. Usando cross-validation, dividir√≠amos o dataset em k folds, treinar√≠amos cada modelo em k-1 folds e testar√≠amos em 1. No final, escolher√≠amos o modelo com melhor m√©trica de desempenho (acur√°cia, F1-score, etc.). J√° o bagging, pegaria o mesmo modelo (digamos, uma √°rvore de decis√£o), criaria B amostras bootstrap e treinar√° uma √°rvore para cada amostra. No final, usar√≠amos um ensemble para prever novos dados. O cross-validation escolhe um modelo, enquanto o bagging combina as predi√ß√µes de muitos modelos do mesmo tipo.

### Conclus√£o

O bagging √© uma t√©cnica de ensemble learning robusta e vers√°til para problemas de classifica√ß√£o, especialmente quando aplicada a classificadores inst√°veis. Este cap√≠tulo apresentou uma an√°lise aprofundada do conceito de bagging, explorando sua base te√≥rica, suas conex√µes com outros m√©todos e suas limita√ß√µes. A combina√ß√£o do bagging com t√©cnicas de regulariza√ß√£o e sele√ß√£o de vari√°veis, al√©m de considera√ß√µes sobre seus paralelos e diferen√ßas com m√©todos como o Perceptron e a sele√ß√£o de modelos por cross-validation, permite uma vis√£o abrangente sobre esta poderosa ferramenta. O entendimento completo do mecanismo de bagging e suas nuances permite a aplica√ß√£o informada desta t√©cnica em uma variedade de problemas pr√°ticos.

<!-- END DOCUMENT -->
[^8.1]: "In this chapter we provide a general exposition of the maximum likelihood approach, as well as the Bayesian method for inference. The bootstrap, introduced in Chapter 7, is discussed in this context, and its relation to maximum likelihood and Bayes is described. Finally, we present some related techniques for model averaging and improvement, including com- mittee methods, bagging, stacking and bumping." *(Trecho de <8. Model Inference and Averaging>)*
[^8.2]: "The bootstrap method provides a direct computational way of assessing uncertainty, by sampling from the training data." *(Trecho de <8.2.1 A Smoothing Example>)*
[^8.7]: "Earlier we introduced the bootstrap as a way of assessing the accuracy of a parameter estimate or a prediction. Here we show how to use the bootstrap to improve the estimate or prediction itself.  Consider first the regression problem. Suppose we fit a model to our training data Z = {(x1, y1), (x2, y2), ..., (xN, yN)}, obtaining the prediction f(x) at input x. Bootstrap aggregation or bagging averages this prediction over a collection of bootstrap samples, thereby reducing its variance. The bagged estimate is the average prediction at x from these B trees. Now suppose our tree produces a classifier G(x) for a K-class response. Here it is useful to consider an underlying indicator-vector function f(x), with value a single one and K ‚àí 1 zeroes, such that ƒú(x) = arg maxk f(x). Then the bagged estimate fbag(x) is a K-vector [p1(x), p2(x),..., pK(x)], with pk(x) equal to the proportion of trees predicting class k at x. The bagged classifier selects the class with the most ‚Äúvotes‚Äù from the B trees, Gbag(x) = arg maxk fbag(x). Often we require the class-probability estimates at x, rather than the classifications themselves. It is tempting to treat the voting proportions pk(x) as estimates of these probabilities. A simple two-class example shows that they fail in this regard. Suppose the true probability of class 1 at x is 0.75, and each of the bagged classifiers accurately predict a 1. Then p1(x) = 1, which is incorrect." *(Trechos de <8.7 Bagging>)*
[^8.8]: "Here we discuss Bayesian model averaging more generally. We have a set of candidate models Mm, m = 1,..., M for our training set Z. These models may be of the same type with different parameter values (e.g., subsets in linear regression), or different models for the same task (e.g., neural networks and regression trees)." *(Trecho de <8.8 Model Averaging and Stacking>)*
