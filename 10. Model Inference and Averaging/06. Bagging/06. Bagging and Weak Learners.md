## Bagging e Aprendizado com Classificadores Fracos

```mermaid
graph LR
    A["Bootstrap"] --> B["Multiple Training Datasets"]
    B --> C["Weak Learners"]
    C --> D["Aggregation"]
    D --> E["Strong Learner"]
```

### Introdu√ß√£o

O presente cap√≠tulo explora em profundidade a t√©cnica de **bagging** (bootstrap aggregating) e sua aplica√ß√£o no contexto de **aprendizado com classificadores fracos**, tamb√©m conhecidos como *weak learners*. Esta abordagem, fundamental no campo do *ensemble learning*, visa melhorar a performance preditiva e a estabilidade de modelos, atrav√©s da combina√ß√£o de m√∫ltiplos classificadores ou regressores, cada um com desempenho individual moderado [^8.7]. A ideia central √© que, ao agregar as previs√µes de diversos modelos treinados de maneira independente ou semi-independente, √© poss√≠vel reduzir a vari√¢ncia e obter um modelo final mais robusto e preciso [^8.7]. O **bootstrap**, uma t√©cnica de reamostragem, desempenha um papel crucial na gera√ß√£o dos diversos conjuntos de dados de treinamento necess√°rios para a implementa√ß√£o do bagging, fornecendo tamb√©m estimativas de incerteza [^8.2], [^8.7].

### Conceitos Fundamentais

**Conceito 1: Bootstrap e Reamostragem**

O **bootstrap** √© um m√©todo computacional que avalia a incerteza de estimativas amostrando repetidamente um conjunto de dados original [^8.2.1]. Em vez de assumir distribui√ß√µes te√≥ricas para as estat√≠sticas amostrais, o bootstrap simula a distribui√ß√£o amostral atrav√©s da cria√ß√£o de r√©plicas do conjunto de dados original. Cada r√©plica, ou conjunto de dados de bootstrap, √© obtida por amostragem com reposi√ß√£o do conjunto de dados original, com o mesmo n√∫mero de observa√ß√µes [^8.2.1]. Esta abordagem permite quantificar a variabilidade das estimativas e construir intervalos de confian√ßa, fornecendo uma alternativa n√£o param√©trica √† infer√™ncia estat√≠stica tradicional [^8.2.1].
*Um lemma fundamental para o bootstrap √© que, sob condi√ß√µes razo√°veis, a distribui√ß√£o das estimativas obtidas a partir de amostras de bootstrap converge para a distribui√ß√£o das estimativas obtidas no conjunto de dados original.*

**Lemma 1:** Seja $\hat{\theta}$ uma estimativa obtida de um conjunto de dados original $Z$ e $\hat{\theta}_b$ as estimativas obtidas a partir dos conjuntos de dados de bootstrap $Z^*_b$, onde $b = 1, ..., B$. Sob certas condi√ß√µes de regularidade, a distribui√ß√£o amostral de $\hat{\theta}$ pode ser aproximada pela distribui√ß√£o emp√≠rica de $\hat{\theta}_b$. Formalmente:
$$ \hat{\theta} \xrightarrow{d} \hat{\theta}_b, $$
onde $\xrightarrow{d}$ indica converg√™ncia em distribui√ß√£o e $\hat{\theta}_b$ representa a distribui√ß√£o das estimativas bootstrap.

```mermaid
graph TB
    subgraph "Lemma 1: Bootstrap Convergence"
        direction TB
        A["Original Data: Z"]
        B["Estimator: Œ∏ÃÇ"]
        C["Bootstrap Samples: Z*_b"]
        D["Bootstrap Estimators: Œ∏ÃÇ_b"]
        A --> B
        A --> C
        C --> D
        D --> E["Distribution of Œ∏ÃÇ_b converges to Distribution of Œ∏ÃÇ"]
    end
```

**Prova do Lemma 1:** A prova formal envolve conceitos de converg√™ncia estoc√°stica e condi√ß√µes de regularidade que garantem a consist√™ncia e a converg√™ncia da distribui√ß√£o emp√≠rica das amostras bootstrap. Essas condi√ß√µes asseguram que, conforme o n√∫mero de amostras bootstrap $B$ tende ao infinito, a distribui√ß√£o emp√≠rica de $\hat{\theta}_b$ se aproxima da distribui√ß√£o amostral de $\hat{\theta}$ [^8.2.1].  $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Suponha que temos um conjunto de dados original $Z = [2, 4, 6, 8, 10]$. Queremos estimar a m√©dia ($\hat{\theta}$) desse conjunto de dados. Usando o bootstrap com $B=3$, podemos gerar 3 conjuntos de dados de bootstrap, por exemplo:
>   - $Z^*_1 = [2, 2, 6, 8, 10]$
>   - $Z^*_2 = [4, 4, 6, 8, 8]$
>   - $Z^*_3 = [2, 4, 6, 10, 10]$
> As m√©dias de cada amostra de bootstrap s√£o:
>   - $\hat{\theta}_1 = (2+2+6+8+10)/5 = 5.6$
>   - $\hat{\theta}_2 = (4+4+6+8+8)/5 = 6$
>   - $\hat{\theta}_3 = (2+4+6+10+10)/5 = 6.4$
> A m√©dia do conjunto original √© $\hat{\theta} = (2+4+6+8+10)/5 = 6$. O bootstrap nos fornece uma distribui√ß√£o de m√©dias (5.6, 6, 6.4) que, sob condi√ß√µes de regularidade, se aproxima da distribui√ß√£o amostral da m√©dia original. Este exemplo demonstra como o bootstrap cria conjuntos de dados similares ao original, permitindo estimar a incerteza das estat√≠sticas.

**Conceito 2: Bagging e Agrega√ß√£o de Predi√ß√µes**

O **bagging** √© uma t√©cnica de *ensemble learning* que aplica o bootstrap para criar m√∫ltiplos conjuntos de dados de treinamento e treinar um modelo (classificador ou regressor) em cada um desses conjuntos [^8.7]. As previs√µes dos modelos individuais s√£o ent√£o combinadas atrav√©s de uma agrega√ß√£o, usualmente por vota√ß√£o (para classifica√ß√£o) ou por m√©dia (para regress√£o), para produzir uma previs√£o final mais est√°vel e precisa [^8.7]. O objetivo principal do bagging √© reduzir a vari√¢ncia, sem aumentar significativamente o vi√©s, resultando em um modelo com melhor desempenho de generaliza√ß√£o [^8.7].
*Um corol√°rio do bagging √© que, quando aplicado a m√©todos inst√°veis (como √°rvores de decis√£o), leva a melhorias substanciais no desempenho preditivo.*

**Corol√°rio 1:** Sejam $f_b(x)$ as previs√µes de um modelo treinado em cada conjunto de dados bootstrap $Z^*_b$. Ent√£o a previs√£o agregada $f_{bag}(x)$ obtida por bagging:
$$ f_{bag}(x) = \frac{1}{B} \sum_{b=1}^B f_b(x), $$
apresenta menor vari√¢ncia quando comparada com $f_b(x)$. Em particular:
$$ Var(f_{bag}(x)) \leq Var(f_b(x)).$$
Este corol√°rio mostra que a agrega√ß√£o das previs√µes reduz a variabilidade, contribuindo para modelos mais est√°veis e confi√°veis.

```mermaid
graph TB
    subgraph "Corol√°rio 1: Variance Reduction in Bagging"
        direction TB
        A["Individual Predictions: f_b(x)"]
        B["Bagging Aggregate: f_bag(x) = (1/B) * Œ£ f_b(x)"]
        C["Variance of f_b(x): Var(f_b(x))"]
        D["Variance of f_bag(x): Var(f_bag(x))"]
        B --> D
        A --> C
        C --> E["Var(f_bag(x)) ‚â§ Var(f_b(x))"]
        D --> E
    end
```

**Prova do Corol√°rio 1:** A vari√¢ncia da m√©dia de $B$ vari√°veis aleat√≥rias independentes e identicamente distribu√≠das √© igual a vari√¢ncia individual dividida por $B$. Portanto, $Var(\frac{1}{B}\sum_{b=1}^B f_b(x)) = \frac{1}{B}Var(f_b(x)) \leq Var(f_b(x))$, dado que $B \geq 1$, e se $f_b(x)$ forem independentes. Mesmo que n√£o totalmente independentes, em geral, observa-se redu√ß√£o da vari√¢ncia ao agregar. $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Suponha que treinamos 3 modelos de regress√£o linear ($B=3$) em diferentes amostras de bootstrap, obtendo as seguintes previs√µes para um dado $x$:
> - $f_1(x) = 5.2$
> - $f_2(x) = 6.8$
> - $f_3(x) = 5.8$
> A previs√£o agregada por bagging seria:
> $f_{bag}(x) = (5.2 + 6.8 + 5.8)/3 = 5.93$
> Agora, vamos assumir que as previs√µes individuais tem uma vari√¢ncia de $Var(f_b(x)) = 1$. Pelo corol√°rio 1, a vari√¢ncia de $f_{bag}(x)$ √© dada por:
> $Var(f_{bag}(x)) = \frac{1}{B} Var(f_b(x)) = \frac{1}{3} * 1 = 0.33$, se os modelos fossem independentes. Na pr√°tica, essa vari√¢ncia seria menor que $Var(f_b(x)) = 1$. A previs√£o agregada $f_{bag}(x) = 5.93$ √© uma estimativa mais est√°vel do que qualquer das previs√µes individuais. Isso mostra como o bagging reduz a vari√¢ncia.

**Conceito 3: Classificadores Fracos e Diversidade**

**Classificadores fracos** (ou *weak learners*) s√£o modelos de aprendizado que, individualmente, possuem desempenho preditivo moderado, geralmente pouco acima do acaso [^8.7]. A ideia central do bagging √© que a combina√ß√£o de muitos classificadores fracos, treinados em diferentes amostras de dados, pode resultar em um classificador forte e preciso [^8.7]. A diversidade entre os classificadores fracos √© crucial para o sucesso do bagging. Esta diversidade √© obtida atrav√©s da utiliza√ß√£o do bootstrap, que cria conjuntos de dados de treinamento ligeiramente diferentes para cada classificador [^8.7].
> ‚ö†Ô∏è **Nota Importante**: A diversidade √© fundamental para o bagging. Se os classificadores fracos forem muito similares, a agrega√ß√£o n√£o trar√° muitos benef√≠cios. **Refer√™ncia [^8.7]**.
> ‚ùó **Ponto de Aten√ß√£o**: O bagging n√£o elimina o vi√©s do classificador fraco, mas √© eficaz na redu√ß√£o da vari√¢ncia. **Conforme indicado em [^8.7]**.
> ‚úîÔ∏è **Destaque**: √Årvores de decis√£o s√£o um exemplo comum de classificador fraco que se beneficiam muito da aplica√ß√£o do bagging. **Baseado no t√≥pico [^8.7]**.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    A["Original Dataset"] --> B("Bootstrap Sampling")
    B --> C1["Dataset 1"]
    B --> C2["Dataset 2"]
    B --> C3["Dataset 3"]
    C1 --> D1["Weak Learner 1"]
    C2 --> D2["Weak Learner 2"]
    C3 --> D3["Weak Learner 3"]
    D1 --> E["Aggregation"]
    D2 --> E
    D3 --> E
    E --> F["Aggregated Classifier"]
    style B fill:#f9f,stroke:#333,stroke-width:2px
```

**Explica√ß√£o:** Este diagrama representa o processo do bagging, com o bootstrap gerando diferentes datasets que s√£o usados para treinar diversos classificadores fracos. As predi√ß√µes desses classificadores s√£o ent√£o agregadas para produzir o classificador final [^8.7].

A regress√£o linear pode ser usada em um contexto de classifica√ß√£o bin√°ria, onde as classes s√£o codificadas por valores num√©ricos (por exemplo, 0 e 1) e o modelo de regress√£o tenta predizer esses valores. No entanto, essa abordagem tem limita√ß√µes devido √† suposi√ß√£o de linearidade e pode gerar previs√µes fora do intervalo desejado (0 a 1), tornando dif√≠cil interpret√°-las como probabilidades [^8.2]. A regress√£o linear, nesse contexto, tamb√©m n√£o √© otimizada diretamente para a classifica√ß√£o, o que pode resultar em fronteiras de decis√£o sub√≥timas [^8.2]. No entanto, em conjunto com o bagging, a regress√£o linear pode fornecer um bom classificador, especialmente quando usada como um classificador fraco, uma vez que o objetivo √© reduzir a vari√¢ncia e o vi√©s na agrega√ß√£o [^8.7]. A t√©cnica de m√≠nimos quadrados √© utilizada para otimizar os par√¢metros do modelo de regress√£o.

**Lemma 2:** A combina√ß√£o de m√∫ltiplos modelos de regress√£o linear treinados em diferentes conjuntos de dados (bootstrap) por meio do bagging, pode levar a uma redu√ß√£o significativa da vari√¢ncia.
Sejam $f_b(x)$ as previs√µes de modelos de regress√£o linear treinados em cada conjunto de dados bootstrap $Z^*_b$. A previs√£o agregada $f_{bag}(x)$ √© dada por:
$$ f_{bag}(x) = \frac{1}{B} \sum_{b=1}^B f_b(x). $$
Ent√£o, a vari√¢ncia da previs√£o agregada $f_{bag}(x)$ √© menor do que a vari√¢ncia individual das previs√µes $f_b(x)$.
**Prova do Lemma 2:** Como cada modelo de regress√£o linear √© treinado em um conjunto de dados diferente devido ao bootstrap, suas previs√µes tendem a ter pequenas diferen√ßas. O bagging ao agregar as previs√µes por m√©dia, reduz a vari√¢ncia dessas diferen√ßas e converge para uma estimativa mais est√°vel e pr√≥xima do verdadeiro valor esperado da predi√ß√£o, $E[f_b(x)]$. Formalmente, $Var(f_{bag}(x)) = \frac{1}{B} Var(f_b(x)) $. $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Considere um problema de classifica√ß√£o bin√°ria com uma vari√°vel preditora. Usamos regress√£o linear como classificador fraco.
> Dados de treinamento:
> ```python
> import numpy as np
> from sklearn.linear_model import LinearRegression
>
> X = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])
> y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])
> ```
> 1.  **Bootstrap e Cria√ß√£o de Modelos:** Criamos $B=3$ amostras de bootstrap e treinamos um modelo linear em cada uma.
>
>   -  **Amostra 1:** $X_1 = [[2], [4], [5], [8], [9]], y_1 = [0, 0, 1, 1, 1]$. Modelo: $f_1(x) = -0.6 + 0.2x$
>   -  **Amostra 2:** $X_2 = [[1], [3], [6], [7], [10]], y_2 = [0, 0, 1, 1, 1]$. Modelo: $f_2(x) = -0.4 + 0.18x$
>   -  **Amostra 3:** $X_3 = [[2], [3], [5], [6], [8]], y_3 = [0, 0, 1, 1, 1]$. Modelo: $f_3(x) = -0.5 + 0.22x$
>
> 2.  **Previs√£o:** Para $x=6$, temos:
>     - $f_1(6) = -0.6 + 0.2*6 = 0.6$
>     - $f_2(6) = -0.4 + 0.18*6 = 0.68$
>     - $f_3(6) = -0.5 + 0.22*6 = 0.82$
> 3.  **Agrega√ß√£o:** A previs√£o agregada √©:
>   $f_{bag}(6) = (0.6 + 0.68 + 0.82) / 3 = 0.7$.
>
> O bagging suaviza as predi√ß√µes e geralmente resulta em um classificador mais robusto que os classificadores individuais. Observe que um modelo de regress√£o linear isolado poderia ter previs√µes fora do intervalo [0,1], enquanto o bagging em conjunto com o limiar de 0.5 fornece uma classifica√ß√£o mais est√°vel e com menor vari√¢ncia.

**Corol√°rio 2:** Em problemas de classifica√ß√£o, a regress√£o linear, embora n√£o ideal individualmente, pode ser utilizada no bagging para criar um conjunto de classificadores fracos. A diversidade introduzida pelo bootstrap e a agrega√ß√£o posterior melhoram a performance de classifica√ß√£o, aproximando-se de um classificador mais robusto.
A regress√£o linear em cada amostra de bootstrap produz uma superf√≠cie de decis√£o que pode ser ligeiramente diferente. A agrega√ß√£o dessas superf√≠cies via bagging leva a uma fronteira de decis√£o final mais est√°vel e menos sujeita a varia√ß√µes de pequenas perturba√ß√µes nos dados de treinamento.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Variable Selection and Regularization"
        direction TB
        A["Bagging with Bootstrap"] --> B["Variable Importance Analysis"]
        B --> C["Feature Frequency in Bootstrapped Models"]
         A --> D["Regularized Weak Learners (L1/L2)"]
         D --> E["Sparsity and Stability"]

    end
```

O bagging n√£o √© diretamente um m√©todo de sele√ß√£o de vari√°veis, mas o bootstrap pode ser usado para auxiliar na identifica√ß√£o das vari√°veis mais importantes em um modelo [^8.7]. Por exemplo, em √°rvores de decis√£o, a frequ√™ncia com que uma vari√°vel √© selecionada para dividir os n√≥s pode indicar sua import√¢ncia relativa [^8.7]. Em modelos de regress√£o, √© poss√≠vel avaliar a estabilidade dos coeficientes das vari√°veis atrav√©s das amostras bootstrap, identificando aquelas que t√™m maior influ√™ncia no resultado [^8.7].

A regulariza√ß√£o, como as penalidades L1 (Lasso) e L2 (Ridge), s√£o t√©cnicas para controlar a complexidade do modelo e evitar o sobreajuste. No contexto de bagging, a regulariza√ß√£o pode ser aplicada a cada modelo treinado nas amostras de bootstrap para garantir que cada classificador fraco n√£o se ajuste demasiadamente ao ru√≠do nos dados. A regulariza√ß√£o L1, por exemplo, pode promover a sele√ß√£o de um subconjunto de vari√°veis ao for√ßar alguns coeficientes a zero, enquanto a regulariza√ß√£o L2 reduz a magnitude dos coeficientes, tornando o modelo mais est√°vel [^8.7].

**Lemma 3:** A aplica√ß√£o da regulariza√ß√£o L1 a classificadores lineares em um contexto de bagging pode gerar modelos mais esparsos e interpret√°veis, uma vez que essa regulariza√ß√£o tende a for√ßar alguns coeficientes a zero, realizando a sele√ß√£o de vari√°veis.
Sejam $f_b(x)$ os classificadores lineares treinados em amostras de bootstrap usando a regulariza√ß√£o L1:
$$f_b(x) = \text{sign}(\beta_0 + \beta_1 x_1 + \ldots + \beta_p x_p),$$
onde a regulariza√ß√£o L1 for√ßa que muitos $\beta_i$ sejam iguais a zero. Em seguida, aplica-se a t√©cnica de bagging. Os modelos obtidos pela regulariza√ß√£o L1 e bagging, s√£o modelos com maior interpretabilidade.
**Prova do Lemma 3:** A penalidade L1, adicionada √† fun√ß√£o de custo da regress√£o linear, tem a propriedade de for√ßar a maioria dos coeficientes a zero.  No bagging, ao treinar diferentes classificadores lineares com L1, cada um ter√° um subconjunto de vari√°veis selecionado, proporcionando uma diversidade que, ao serem agregados, reduzem a vari√¢ncia mantendo a interpretabilidade de cada modelo individual. $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Suponha que temos um problema de classifica√ß√£o com 3 vari√°veis preditoras ($x_1, x_2, x_3$) e usamos regress√£o linear com regulariza√ß√£o L1 (Lasso) como classificador fraco. Criamos tr√™s amostras bootstrap e treinamos um modelo em cada uma:
>
> - **Amostra 1:** Modelo Lasso: $f_1(x) = \text{sign}(0.1 + 0.5x_1 + 0x_2 + 0.2x_3)$.  O Lasso zerou o coeficiente de $x_2$.
> - **Amostra 2:** Modelo Lasso: $f_2(x) = \text{sign}(0.2 + 0x_1 + 0.4x_2 + 0.3x_3)$.  O Lasso zerou o coeficiente de $x_1$.
> - **Amostra 3:** Modelo Lasso: $f_3(x) = \text{sign}(0.05 + 0.3x_1 + 0.1x_2 + 0x_3)$.  O Lasso zerou o coeficiente de $x_3$.
>
> Para um novo dado $x = [1, 1, 1]$, as previs√µes s√£o:
>
> - $f_1(x) = \text{sign}(0.1 + 0.5 + 0 + 0.2) = \text{sign}(0.8) = 1$
> - $f_2(x) = \text{sign}(0.2 + 0 + 0.4 + 0.3) = \text{sign}(0.9) = 1$
> - $f_3(x) = \text{sign}(0.05 + 0.3 + 0.1 + 0) = \text{sign}(0.45) = 1$
>
> A previs√£o agregada √© 1 (todos votaram em 1). Al√©m disso, podemos observar que $x_1$, $x_2$, e $x_3$ foram selecionadas pelo Lasso em diferentes amostras, indicando que todas as vari√°veis podem ser relevantes para o problema. Ao utilizar bagging com regulariza√ß√£o L1, conseguimos criar modelos esparsos e, simultaneamente, agregar previs√µes para reduzir a vari√¢ncia.

**Corol√°rio 3:**  A regulariza√ß√£o L2 em conjunto com o bagging garante que nenhum classificador fraco possua coeficientes muito grandes. Isso leva a uma redu√ß√£o da vari√¢ncia do modelo agregado.
Com a regulariza√ß√£o L2, os coeficientes tendem a ser pequenos, diminuindo a complexidade de cada classificador fraco. Ao combinar os classificadores fracos pelo bagging, o modelo final se torna mais est√°vel e tem melhor desempenho em dados de teste.

> üí° **Exemplo Num√©rico:**
> Utilizando o mesmo problema de classifica√ß√£o com 3 vari√°veis, agora aplicamos regress√£o linear com regulariza√ß√£o L2 (Ridge).
>
> - **Amostra 1:** Modelo Ridge: $f_1(x) = 0.1 + 0.4x_1 + 0.2x_2 + 0.3x_3$. Os coeficientes s√£o menores devido √† regulariza√ß√£o L2.
> - **Amostra 2:** Modelo Ridge: $f_2(x) = 0.15 + 0.3x_1 + 0.35x_2 + 0.25x_3$. Os coeficientes s√£o diferentes, mas com magnitudes menores.
> - **Amostra 3:** Modelo Ridge: $f_3(x) = 0.05 + 0.35x_1 + 0.25x_2 + 0.2x_3$. Os coeficientes s√£o novamente diferentes, mas todos com valores reduzidos.
>
> Para $x = [1, 1, 1]$, as previs√µes s√£o:
>
> - $f_1(x) = 0.1 + 0.4 + 0.2 + 0.3 = 1.0$
> - $f_2(x) = 0.15 + 0.3 + 0.35 + 0.25 = 1.05$
> - $f_3(x) = 0.05 + 0.35 + 0.25 + 0.2 = 0.85$
>
> A m√©dia √© $f_{bag}(x) = (1.0 + 1.05 + 0.85) / 3 = 0.966$.
>
> A regulariza√ß√£o L2 garante que cada classificador fraco n√£o tenha coeficientes muito grandes, reduzindo a vari√¢ncia do modelo agregado. O bagging, ao agregar esses modelos, resulta em uma predi√ß√£o mais est√°vel e menos propensa a overfitting.

### Separating Hyperplanes e Perceptrons

Hiperplanos separadores s√£o fronteiras lineares que podem ser usadas para dividir os dados em diferentes classes. O objetivo √© encontrar o hiperplano que maximiza a margem de separa√ß√£o entre as classes, buscando uma solu√ß√£o √≥tima que minimize o risco de classifica√ß√£o incorreta. O Perceptron, por sua vez, √© um algoritmo de aprendizado que busca iterativamente os pesos dos hiperplanos separadores [^8.5.2]. O bagging pode ser aplicado a classificadores baseados em hiperplanos, incluindo o Perceptron, para reduzir sua instabilidade. O bootstrap gera diferentes amostras de dados, cada uma com um hiperplano √≥timo ligeiramente diferente. A combina√ß√£o desses hiperplanos atrav√©s do bagging pode resultar em um classificador mais est√°vel e robusto [^8.5.2].

> üí° **Exemplo Num√©rico:**
> Suponha que estamos usando o Perceptron como classificador fraco para separar duas classes em um espa√ßo bidimensional.
>
> 1.  **Treinamento do Perceptron:**
>     - **Amostra 1:** Perceptron 1: $\text{sign}( -0.5 + 1.2x_1 - 0.8x_2)$
>     - **Amostra 2:** Perceptron 2: $\text{sign}( -0.3 + 1.0x_1 - 0.7x_2)$
>     - **Amostra 3:** Perceptron 3: $\text{sign}( -0.6 + 1.1x_1 - 0.9x_2)$
>
> 2.  **Previs√£o com Bagging:** Para um novo ponto $x = [2, 1]$:
>     - $f_1(x) = \text{sign}(-0.5 + 1.2 * 2 - 0.8 * 1) = \text{sign}(1.1) = 1$
>     - $f_2(x) = \text{sign}(-0.3 + 1.0 * 2 - 0.7 * 1) = \text{sign}(1.0) = 1$
>     - $f_3(x) = \text{sign}(-0.6 + 1.1 * 2 - 0.9 * 1) = \text{sign}(0.7) = 1$
>
> 3.  **Agrega√ß√£o:** O classificador agregado votaria em 1.
>
> O bagging ajuda a suavizar a fronteira de decis√£o do Perceptron, que √© muito sens√≠vel a pequenas mudan√ßas nos dados de treinamento, resultando em um classificador mais robusto.

### Pergunta Te√≥rica Avan√ßada: Qual a rela√ß√£o entre o bagging e a decomposi√ß√£o de vi√©s-vari√¢ncia?

**Resposta:**
O bagging √© uma t√©cnica que tem como objetivo principal a redu√ß√£o da vari√¢ncia, sem aumentar significativamente o vi√©s. Isso pode ser formalizado atrav√©s da decomposi√ß√£o do erro total em vi√©s e vari√¢ncia [^8.7].
A previs√£o de um modelo de aprendizado de m√°quina $f(x)$ pode ser escrita como:
$$E[(y-\hat{f}(x))^2] = Bias^2(\hat{f}(x)) + Var(\hat{f}(x)) + \sigma^2$$
onde $Bias^2(\hat{f}(x)) = (E[\hat{f}(x)] - y)^2$ √© o quadrado do vi√©s, $Var(\hat{f}(x)) = E[(\hat{f}(x) - E[\hat{f}(x)])^2]$ √© a vari√¢ncia, e $\sigma^2$ √© o erro irredut√≠vel.
Quando aplicada ao bagging, o efeito principal √© reduzir a vari√¢ncia. Formalmente, o bagging realiza uma m√©dia das previs√µes dos classificadores fracos. A vari√¢ncia da m√©dia de classificadores independentes √© dada por:
$$Var(\frac{1}{B} \sum_{b=1}^B f_b(x)) = \frac{1}{B} Var(f_b(x)).$$
Na pr√°tica, os classificadores n√£o s√£o perfeitamente independentes, mas o bagging ainda reduz a vari√¢ncia por meio da agrega√ß√£o. O vi√©s, por sua vez, n√£o √© alterado pelo bagging, pois a m√©dia das previs√µes mant√©m o mesmo vi√©s de cada classificador fraco.
**Lemma 4:** O bagging reduz a vari√¢ncia do classificador, sem alterar o vi√©s.
Seja $f(x)$ a fun√ß√£o verdadeira e $f_b(x)$ a previs√£o de cada classificador fraco ap√≥s o bootstrap. O estimador agregado $f_{bag}(x) = \frac{1}{B} \sum_{b=1}^B f_b(x)$ tem as seguintes propriedades:
$$Bias(f_{bag}(x)) = Bias(f_b(x))$$
$$Var(f_{bag}(x)) \leq Var(f_b(x)).$$
**Prova do Lemma 4:** O vi√©s do estimador agregado √© o vi√©s individual dos classificadores:
$$Bias(f_{bag}(x)) = E[f_{bag}(x)] - f(x) = E[\frac{1}{B}\sum_{b=1}^B f_b(x)] - f(x) = \frac{1}{B} \sum_{b=1}^B E[f_b(x)] - f(x) = E[f_b(x)] - f(x) = Bias(f_b(x)).$$
A vari√¢ncia do estimador agregado √© reduzida:
$$Var(f_{bag}(x)) = Var(\frac{1}{B}\sum_{b=1}^B f_b(x)) = \frac{1}{B^2} \sum_{b=1}^B Var(f_b(x)) = \frac{1}{B}Var(f_b(x))$$
Se os classificadores forem independentes, ou $Var(f_{bag}(x)) \leq Var(f_b(x))$, no caso geral. $\blacksquare$
**Corol√°rio 4:** O bagging √© eficaz para modelos com alta vari√¢ncia, como √°rvores de decis√£o n√£o podadas.
√Årvores de decis√£o n√£o podadas tem baixa estabilidade, sendo sens√≠veis a pequenas mudan√ßas nos dados de treinamento. O bagging reduz essa instabilidade ao suavizar as predi√ß√µes e gerar classificadores mais est√°veis.

```mermaid
graph TB
    subgraph "Lemma 4: Bias-Variance Decomposition in Bagging"
        direction TB
        A["True Function: f(x)"]
        B["Individual Weak Learner Prediction: f_b(x)"]
        C["Bagging Aggregation: f_bag(x) = (1/B) * Œ£ f_b(x)"]
        D["Bias of f_b(x): Bias(f_b(x))"]
        E["Bias of f_bag(x): Bias(f_bag(x))"]
        F["Variance of f_b(x): Var(f_b(x))"]
        G["Variance of f_bag(x): Var(f_bag(x))"]
        C --> E
        B --> D
        C --> G
        B --> F
        D --> H["Bias(f_bag(x)) = Bias(f_b(x))"]
        E --> H
         F --> I["Var(f_bag(x)) ‚â§ Var(f_b(x))"]
        G --> I
    end
```

> üí° **Exemplo Num√©rico:**
> Vamos simular a decomposi√ß√£o de vi√©s-vari√¢ncia com um exemplo.
>
> Suponha que a fun√ß√£o verdadeira seja $f(x) = 2x + 1$.  Geramos alguns dados com ru√≠do:
>
> ```python
> import numpy as np
>
> def true_function(x):
>    return 2 * x + 1
>
> np.random.seed(42)
> X = np.sort(np.random.rand(50) * 5) # X values from 0 to 5
> y_true = true_function(X)
> y_noisy = y_true + np.random.normal(0, 1, 50) # Adding noise
> ```
>
> 1.  **√Årvores de Decis√£o (Alta Vari√¢ncia):** Treinamos 3 √°rvores de decis√£o n√£o podadas em amostras de bootstrap e para $x=3$ obtemos:
>     - $f_1(3) = 6.8$
>     - $f_2(3) = 8.1$
>     - $f_3(3) = 7.2$
>
>     $f_{bag}(3) = (6.8 + 8.1 + 7.2) / 3 = 7.37$
>     O valor verdadeiro √© $f(3) = 2*3 + 1 = 7$.
>
>     $Bias = E[f_{bag}(3)] - f(3) = 7.37 - 7 = 0.37$.  Vamos considerar que $E[f_{bag}(3)] \approx 7.37$
>     $Var(f_b(3))$ √© alta e a vari√¢ncia de $f_{bag}(3)$ √© menor.
>
> 2. **Modelo Linear (Baixo Vi√©s):** Para fins de compara√ß√£o, um modelo linear simples pode ter as seguintes previs√µes
>     - $f_{linear}(3) = 7.1$
>     $Bias = E[f_{linear}(3)] - f(3) = 7.1 - 7 = 0.1$. A vari√¢ncia seria menor, por√©m o vi√©s seria maior que o bagging das √°rvores de decis√£o.
>
> A ideia √© demonstrar que, ao usar bagging, conseguimos reduzir a vari√¢ncia (as predi√ß√µes individuais de √°rvores de decis√£o s√£o mais dispersas), enquanto o vi√©s permanece aproximadamente o mesmo. O modelo linear tem um baixo vi√©s, mas a vari√¢ncia pode ser maior que o bagging com √°rvores.

### Conclus√£o
O bagging √© uma t√©cnica poderosa e vers√°til para melhorar o desempenho de modelos de aprendizado de m√°quina, especialmente quando usada em conjunto com classificadores fracos. A combina√ß√£o do bootstrap com a agrega√ß√£o de previs√µes permite reduzir a vari√¢ncia, resultando em modelos mais est√°veis e precisos, com melhor capacidade de generaliza√ß√£o. O bagging √© amplamente utilizado em diversas √°reas, desde classifica√ß√£o e regress√£o at√© an√°lise de dados complexos, sendo um componente fundamental das abordagens modernas de *ensemble learning*.

### Footnotes
[^8.1]: "For most of this book, the fitting (learning) of models has been achieved by minimizing a sum of squares for regression, or by minimizing cross-entropy for classification." *(Trecho de <Model Inference and Averaging>)*
[^8.2]: "The bootstrap method provides a direct computational way of assessing uncertainty, by sampling from the training data." *(Trecho de <Model Inference and Averaging>)*
[^8.2.1]: "Here we illustrate the bootstrap in a simple one-dimensional smoothing problem, and show its connection to maximum likelihood." *(Trecho de <Model Inference and Averaging>)*
[^8.3]:  "Suppose we divide to fit a cubic spline to the data, with three knots placed at the quartiles of the