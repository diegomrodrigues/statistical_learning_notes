## Bootstrap Aggregation: Bagging

```mermaid
graph TD
    subgraph "Bagging Overview"
        direction TB
        A["Original Dataset 'Z'"] --> B["Bootstrap Sampling (with replacement)"]
        B --> C["Multiple Bootstrap Datasets 'Z*b'"]
        C --> D["Train Model on Each 'Z*b' --> 'f*b(x)'"]
        D --> E["Aggregate Predictions 'f*b(x)' --> 'fbag(x)'"]
    end
```

### Introdu√ß√£o

O conceito de **Bootstrap Aggregation**, ou **Bagging**, emerge como uma poderosa t√©cnica no campo do aprendizado estat√≠stico, com foco na melhoria da precis√£o e estabilidade de modelos preditivos [^8.1]. Este cap√≠tulo explora em profundidade o Bagging, sua rela√ß√£o com o m√©todo Bootstrap, e como ele se encaixa em um contexto mais amplo de infer√™ncia e m√©dia de modelos [^8.2]. O objetivo principal do Bagging √© reduzir a vari√¢ncia de modelos inst√°veis, combinando as previs√µes de m√∫ltiplos modelos treinados em diferentes amostras de dados. Ao longo deste cap√≠tulo, examinaremos os fundamentos te√≥ricos do Bagging, suas aplica√ß√µes pr√°ticas e algumas das suas limita√ß√µes.

### Conceitos Fundamentais

**Conceito 1: O Bootstrap e a Avalia√ß√£o de Incerteza**

O m√©todo **Bootstrap** √© uma t√©cnica de reamostragem computacional que permite estimar a incerteza em uma estat√≠stica amostral, como a m√©dia ou um coeficiente de regress√£o. Essa t√©cnica envolve a cria√ß√£o de m√∫ltiplas amostras (bootstrap samples) por amostragem com reposi√ß√£o a partir dos dados de treinamento [^8.2.1]. Cada amostra bootstrap tem o mesmo tamanho do conjunto de dados original, mas cont√©m alguns dados repetidos e omite outros, permitindo uma avalia√ß√£o da variabilidade da estat√≠stica de interesse.

*A utiliza√ß√£o do Bootstrap para avaliar a incerteza reside na sua capacidade de simular a variabilidade que existiria se tiv√©ssemos acesso a muitos conjuntos de dados diferentes, todos originados da mesma popula√ß√£o*. O Bootstrap √© essencial para a constru√ß√£o de intervalos de confian√ßa e para a avalia√ß√£o da precis√£o de modelos estat√≠sticos [^8.1].

> üí° **Exemplo Num√©rico:** Imagine que temos um conjunto de dados com as alturas de 5 estudantes (em cm): `[165, 170, 175, 180, 185]`. Queremos estimar a m√©dia da altura e sua incerteza utilizando o Bootstrap.
>
> 1. **Amostras Bootstrap:** Criamos, digamos, 3 amostras bootstrap:
>    - Amostra 1: `[170, 170, 180, 165, 185]`
>    - Amostra 2: `[185, 175, 165, 180, 175]`
>    - Amostra 3: `[165, 175, 170, 185, 170]`
> 2. **Estimativa em cada amostra:** Calculamos a m√©dia para cada amostra:
>    - M√©dia da amostra 1: 174
>    - M√©dia da amostra 2: 176
>    - M√©dia da amostra 3: 173
> 3. **Estimativa da incerteza:** A vari√¢ncia das m√©dias bootstrap pode ser calculada conforme o Lemma 1, e essa vari√¢ncia representa a incerteza na estimativa da m√©dia da altura.

**Lemma 1: Estimativa da Vari√¢ncia via Bootstrap**

Dado um estimador $\hat{\theta}$ de um par√¢metro $\theta$ baseado em um conjunto de dados $Z = \{z_1, z_2, ..., z_N\}$, podemos usar o Bootstrap para estimar a vari√¢ncia de $\hat{\theta}$. Seja $\hat{\theta}^*_b$ o estimador de $\theta$ calculado sobre a *b-√©sima* amostra bootstrap $Z^*_b$. A vari√¢ncia bootstrap de $\hat{\theta}$ √© dada por:
$$Var_{boot}(\hat{\theta}) = \frac{1}{B-1}\sum_{b=1}^B (\hat{\theta}^*_b - \bar{\hat{\theta}^*})^2,$$
onde $\bar{\hat{\theta}^*} = \frac{1}{B}\sum_{b=1}^B \hat{\theta}^*_b$ e $B$ √© o n√∫mero de amostras bootstrap. Este lemma demonstra a utilidade pr√°tica do bootstrap para a estima√ß√£o de vari√¢ncias, especialmente quando a forma anal√≠tica da vari√¢ncia √© desconhecida ou muito complexa [^8.2.1]. $\blacksquare$
```mermaid
graph TD
    subgraph "Bootstrap Variance Calculation"
        direction TB
        A["Estimator 'Œ∏ÃÇ' from Data 'Z'"] --> B["Generate 'B' Bootstrap Samples 'Z*b'"]
        B --> C["Calculate 'Œ∏ÃÇ*b' for Each 'Z*b'"]
        C --> D["Calculate Average 'Œ∏ÃÇÃÑ*' = 1/B * Œ£(Œ∏ÃÇ*b)"]
        D --> E["Calculate Variance 'Var_boot(Œ∏ÃÇ)' = 1/(B-1) * Œ£(Œ∏ÃÇ*b - Œ∏ÃÇÃÑ*)¬≤"]
    end
```

> üí° **Exemplo Num√©rico (Continuando do exemplo anterior):**
>
> Usando as m√©dias calculadas nas 3 amostras bootstrap: 174, 176 e 173.
>
> 1. **M√©dia das m√©dias bootstrap:** $\bar{\hat{\theta}^*} = (174 + 176 + 173) / 3 = 174.33$
> 2. **Vari√¢ncia bootstrap:** $Var_{boot}(\hat{\theta}) = \frac{1}{3-1} [ (174-174.33)^2 + (176-174.33)^2 + (173-174.33)^2] = \frac{1}{2} [0.11 + 2.78 + 1.78] = 2.335$
>
> A raiz quadrada da vari√¢ncia bootstrap, $\sqrt{2.335} \approx 1.53$, nos daria um desvio padr√£o bootstrap que indica a incerteza em nossa estimativa da m√©dia da altura.

**Conceito 2: Agrega√ß√£o por Bootstrap (Bagging)**

O **Bagging** √© um m√©todo que utiliza o Bootstrap para melhorar o desempenho de modelos preditivos, especialmente aqueles que s√£o inst√°veis ou sujeitos a alta vari√¢ncia [^8.7]. Em ess√™ncia, o Bagging envolve:
1. Gerar m√∫ltiplos conjuntos de dados de treinamento, $Z^*_b$, por meio da amostragem com reposi√ß√£o dos dados originais $Z$ [^8.2.1].
2. Ajustar um modelo preditivo a cada conjunto de dados $Z^*_b$, obtendo uma cole√ß√£o de preditores $f^*_b(x)$.
3. Agregar as predi√ß√µes individuais $f^*_b(x)$ para obter a predi√ß√£o final $f_{bag}(x)$. Para problemas de regress√£o, a agrega√ß√£o √© feita por m√©dia, enquanto em problemas de classifica√ß√£o, pode ser por vota√ß√£o majorit√°ria ou pela m√©dia das probabilidades de classe [^8.7].

O Bagging tem como principal objetivo reduzir a vari√¢ncia dos modelos preditivos, melhorando assim a precis√£o das predi√ß√µes. A ideia central √© que ao agregar as predi√ß√µes de v√°rios modelos, as oscila√ß√µes individuais de cada um tendem a cancelar, levando a uma predi√ß√£o mais est√°vel [^8.1].

**Corol√°rio 1: Redu√ß√£o da Vari√¢ncia com Bagging**
A agrega√ß√£o de modelos realizada pelo Bagging tende a reduzir a vari√¢ncia das predi√ß√µes, conforme demonstrado no t√≥pico [^8.7]. Ao combinarmos m√∫ltiplas predi√ß√µes, o erro total do modelo se torna mais est√°vel e menos sens√≠vel a pequenas mudan√ßas nos dados de treinamento. Este corol√°rio estabelece a justificativa matem√°tica para o uso do Bagging em problemas com modelos de alta vari√¢ncia.

**Conceito 3: Bagging e a Infer√™ncia Bayesiana**

Embora o Bagging seja uma t√©cnica essencialmente frequentista, ele tem uma conex√£o interessante com a infer√™ncia bayesiana [^8.7]. Especificamente, a m√©dia bootstrap pode ser vista como uma aproxima√ß√£o da m√©dia *a posteriori* em uma an√°lise bayesiana n√£o param√©trica [^8.4]. Em modelos gaussianos, a an√°lise bayesiana com priors n√£o informativos tendem a concordar com o bootstrap param√©trico [^8.4].

> ‚ö†Ô∏è **Nota Importante:** *A rela√ß√£o entre Bootstrap e m√©todos bayesianos fornece uma vis√£o interessante sobre a interpreta√ß√£o de resultados e constru√ß√£o de intervalos de confian√ßa.* [^8.4]
>
> ‚ùó **Ponto de Aten√ß√£o:** *Embora o Bagging geralmente reduza a vari√¢ncia, ele n√£o √© uma cura universal, e em alguns casos espec√≠ficos pode n√£o ser eficaz*. [^8.7]
>
> ‚úîÔ∏è **Destaque:** *Bagging tende a se beneficiar de modelos n√£o lineares, como √°rvores de decis√£o, em compara√ß√£o com modelos lineares.* [^8.7]

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Bagging with Linear Regression"
        direction TB
        A["Original Dataset 'Z'"] --> B["Bootstrap Samples 'Z*b'"]
        B --> C["Train Linear Regression '≈∑_b(x)' on each 'Z*b'"]
         C --> D["Aggregate Predictions '≈∑_b(x)' using Average/Voting"]
    end
```

A rela√ß√£o entre regress√£o linear e Bagging n√£o √© imediata, j√° que o Bagging √© usado para melhorar modelos complexos, e regress√£o linear √© um modelo simples. Contudo, √© poss√≠vel aplicar a regress√£o linear como um modelo base no Bagging. [^8.2.1] A regress√£o linear, quando utilizada como um modelo base no Bagging, tem a forma:
$$ \hat{y}_b(x) = \beta_0 + \beta_1x_1 + \beta_2x_2 + \ldots + \beta_px_p$$
onde $\hat{y}_b(x)$ √© a previs√£o para a b-√©sima amostra bootstrap, $x_1, x_2, \ldots, x_p$ s√£o os preditores, e $\beta_0, \beta_1, \ldots, \beta_p$ s√£o os coeficientes. Para problemas de classifica√ß√£o, uma abordagem seria aplicar a regress√£o linear sobre uma matriz de indicadores [^8.1] e depois usar o resultado da regress√£o para derivar uma decis√£o de classe. O Bagging, ent√£o, combina os resultados das v√°rias regress√µes lineares feitas nas amostras bootstrap.

> üí° **Exemplo Num√©rico:** Suponha que temos dados de classifica√ß√£o bin√°ria com uma vari√°vel preditora $x$ e uma vari√°vel alvo $y$ (0 ou 1):
>
> | $x$    | $y$    |
> | ------ | ------ |
> | 1      | 0      |
> | 2      | 0      |
> | 3      | 1      |
> | 4      | 1      |
> | 5      | 1      |
>
> 1. **Amostras Bootstrap:** Criamos 2 amostras bootstrap:
>  - Amostra 1: `[(2, 0), (4, 1), (1, 0), (5, 1), (3, 1)]`
>  - Amostra 2: `[(1, 0), (3, 1), (5, 1), (2, 0), (4, 1)]`
> 2. **Regress√£o Linear:** Ajustamos um modelo de regress√£o linear (utilizando Ordinary Least Squares - OLS) a cada amostra, convertendo a vari√°vel y em uma vari√°vel real.
>  - Modelo 1: Obtemos $\hat{y}_1(x) = -0.4 + 0.3x$.
>  - Modelo 2: Obtemos $\hat{y}_2(x) = -0.6 + 0.35x$.
> 3. **Agrega√ß√£o:** Para classificar um novo ponto, por exemplo, $x = 3.5$:
>   - Modelo 1: $\hat{y}_1(3.5) = -0.4 + 0.3 * 3.5 = 0.65$
>   - Modelo 2: $\hat{y}_2(3.5) = -0.6 + 0.35 * 3.5 = 0.625$
> 4. **Previs√£o Final:** Agregamos as previs√µes (por exemplo, fazendo a m√©dia):
> $\hat{y}_{bag}(3.5) = (0.65 + 0.625) / 2 = 0.6375$. Para classificar, poder√≠amos usar um limiar de 0.5: como 0.6375 > 0.5, a classe prevista seria 1.
>
> Note que este √© um exemplo simplificado, com poucas amostras bootstrap e poucos dados.

O foco do Bagging reside no aumento da estabilidade, especialmente quando o modelo base (regress√£o linear, neste caso) √© combinado com outros, o que √© adequado para situa√ß√µes com alta variabilidade nos dados de entrada [^8.7]. Se os dados forem lineares e est√°veis, o Bagging pode n√£o trazer tantos benef√≠cios em compara√ß√£o com modelos mais complexos [^8.7].

**Lemma 2: Limita√ß√µes do Bagging com Modelos Lineares**
Se a fun√ß√£o de predi√ß√£o $f(x)$ √© linear no dataset de treinamento, o Bagging utilizando o parametric bootstrap n√£o vai alterar a predi√ß√£o final quando o n√∫mero de amostras bootstrap vai para o infinito. Isso √© porque as predi√ß√µes $f_b^*(x)$ ser√£o quase iguais ao $f(x)$, e a m√©dia das predi√ß√µes vai convergir para $f(x)$ [^8.7].
$$\lim_{B \to \infty} \frac{1}{B}\sum_{b=1}^B f^*_b(x) = f(x)$$
Este lemma estabelece uma restri√ß√£o quando se utiliza o Bagging em modelos lineares. $\blacksquare$
```mermaid
graph LR
    subgraph "Lemma 2: Bagging Limit on Linear Models"
        direction LR
        A["Linear Function f(x)"] --> B["Bootstrap Samples 'Z*b'"]
        B --> C["Linear Predictions 'f*b(x)'"]
        C --> D["As 'B' -> ‚àû, average 'f*b(x)' -> f(x)"]
    end
```

**Corol√°rio 2: Benef√≠cios do Bagging em Modelos N√£o-Lineares**
Contrariamente, o Bagging √© mais eficiente em modelos n√£o lineares, tais como √°rvores de decis√£o e redes neurais, porque nesses casos as predi√ß√µes variam consideravelmente entre as amostras bootstrap, e a agrega√ß√£o leva a resultados mais est√°veis e precisos [^8.7]. Este corol√°rio ressalta a import√¢ncia de se escolher um modelo base adequado ao usar o Bagging.

"Em cen√°rios onde a regress√£o linear √© est√°vel e os dados s√£o bem comportados, o Bagging pode n√£o trazer grande melhoria. No entanto, em datasets com alta variabilidade, a combina√ß√£o de m√∫ltiplos modelos lineares pode reduzir o erro quadr√°tico m√©dio" [^8.7].

"√â essencial avaliar a adequa√ß√£o do modelo base ao utilizar o Bagging; para modelos simples, o impacto ser√° menor do que com modelos n√£o-lineares, conforme apontado em [^8.7]".

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph TB
    subgraph "Bagging with Feature Selection & Regularization"
      direction TB
        A["Original Dataset 'Z'"] --> B["Bootstrap Samples 'Z*b'"]
        B --> C["Feature Selection on each 'Z*b'"]
        C --> D["Regularized Model Training on each 'Z*b'"]
        D --> E["Aggregate Predictions"]
    end
```

A sele√ß√£o de vari√°veis e regulariza√ß√£o s√£o importantes para evitar o overfitting e melhorar a generaliza√ß√£o de modelos de classifica√ß√£o. Em um contexto de Bagging, esses m√©todos podem ser aplicados em cada modelo base constru√≠do com uma amostra bootstrap [^8.7]. Por exemplo, na regress√£o log√≠stica, a regulariza√ß√£o $L_1$ ou $L_2$ (ou ambas) pode ser incorporada para controlar a magnitude dos coeficientes e a complexidade do modelo [^8.2.1]. Essa regulariza√ß√£o √© aplicada *dentro* de cada modelo constru√≠do sobre uma amostra bootstrap, o que torna o processo de sele√ß√£o mais robusto.

> üí° **Exemplo Num√©rico:** Imagine que estamos construindo um modelo de regress√£o log√≠stica para classificar se um cliente vai comprar um produto (1) ou n√£o (0), com base em duas vari√°veis: tempo de navega√ß√£o no site ($x_1$) e n√∫mero de visitas ($x_2$).
>
>1.  **Dados:** Suponha que temos um conjunto de dados original.
>2.  **Bootstrap Samples:** Criamos amostras bootstrap. Para cada amostra, aplicamos a regress√£o log√≠stica com regulariza√ß√£o L1:
>
>    $\hat{\beta}_{b,L1} = \underset{\beta}{\operatorname{argmin}} \left[ -\sum_{i=1}^N y_i \log(\sigma(\beta^T x_i)) + (1-y_i)\log(1-\sigma(\beta^Tx_i)) + \lambda \sum_{j=1}^p|\beta_j| \right]$
>
>    Onde:
>    - $\sigma(\beta^Tx_i)$ √© a fun√ß√£o log√≠stica.
>    - $\lambda$ √© o par√¢metro de regulariza√ß√£o (escolhemos $\lambda=0.1$).
>
>    Para cada amostra, encontramos coeficientes ($\beta_0, \beta_1, \beta_2$). Devido ao L1, alguns coeficientes podem ser exatamente 0.
>
>    - Amostra 1: $\beta_0 = -2.0$, $\beta_1 = 0.5$, $\beta_2 = 0$ (a vari√°vel $x_2$ n√£o foi considerada importante neste modelo).
>    - Amostra 2: $\beta_0 = -1.5$, $\beta_1 = 0$, $\beta_2 = 0.6$ (a vari√°vel $x_1$ n√£o foi considerada importante neste modelo).
>    - Amostra 3: $\beta_0 = -1.8$, $\beta_1 = 0.3$, $\beta_2 = 0.2$ (ambas as vari√°veis foram consideradas importantes).
>
>3. **Agrega√ß√£o:** Ao prever a probabilidade para um novo cliente com, por exemplo, $x_1 = 2$ e $x_2 = 3$, calculamos a probabilidade para cada modelo e agregamos (fazendo a m√©dia):
>
>    - Modelo 1: $\sigma(-2 + 0.5*2 + 0*3) = \sigma(-1) = 0.27$
>    - Modelo 2: $\sigma(-1.5 + 0*2 + 0.6*3) = \sigma(0.3) = 0.57$
>    - Modelo 3: $\sigma(-1.8 + 0.3*2 + 0.2*3) = \sigma(-0.6) = 0.35$
>    - Probabilidade Agregada: $(0.27+0.57+0.35)/3 = 0.397$. O cliente √© classificado como n√£o comprando (0), se usarmos um limiar de 0.5.
>
>   Note que em cada amostra, o modelo L1 pode selecionar um subconjunto de vari√°veis, o que leva a modelos mais esparsos. A agrega√ß√£o desses modelos resulta em uma predi√ß√£o robusta.

A incorpora√ß√£o de m√©todos de sele√ß√£o de vari√°veis dentro do processo de bagging pode tamb√©m ser feita, selecionando diferentes vari√°veis relevantes para cada amostra bootstrap. Esta abordagem pode levar a modelos base mais diversificados e robustos [^8.7].

**Lemma 3: Regulariza√ß√£o e Esparsidade no Bagging**

Considerando uma regulariza√ß√£o L1 no modelo base de regress√£o log√≠stica, a aplica√ß√£o do Bagging com regulariza√ß√£o L1 leva a um conjunto de modelos base esparsos, onde muitos coeficientes s√£o nulos. A decis√£o final agregada ser√° baseada em um conjunto de modelos com diferentes conjuntos de vari√°veis relevantes, que pode melhorar a interpretabilidade e precis√£o do modelo final [^8.4].
$$ \hat{\beta}_{b,L1} = \underset{\beta}{\operatorname{argmin}} \left[ -\sum_{i=1}^N y_i \log(\sigma(\beta^T x_i)) + (1-y_i)\log(1-\sigma(\beta^Tx_i)) + \lambda \sum_{j=1}^p|\beta_j| \right] $$
Este lemma estabelece como a regulariza√ß√£o L1 contribui para a esparsidade dos modelos base dentro do framework do Bagging. $\blacksquare$
```mermaid
graph TB
    subgraph "Lemma 3: L1 Regularization in Bagging"
        direction TB
        A["Loss Function with L1 Regularization: 'argmin_Œ≤[... + ŒªŒ£|Œ≤_j|]'"]
        A --> B["Bootstrap Samples 'Z*b'"]
        B --> C["Sparse Models from L1 on Each Sample 'Œ≤ÃÇ_b,L1'"]
        C --> D["Aggregated Prediction Based on Sparse Models"]
    end
```

**Prova do Lemma 3:**
O termo de regulariza√ß√£o L1, $\lambda \sum_{j=1}^p|\beta_j|$, penaliza a complexidade do modelo ao adicionar um termo que for√ßa os coeficientes a serem zero. Ao minimizar a fun√ß√£o de custo, muitos coeficientes ser√£o empurrados para zero, resultando em um modelo esparso. Aplicar o Bagging sobre esses modelos esparsos leva a um conjunto diversificado de vari√°veis selecionadas em diferentes amostras bootstrap, o que pode melhorar o poder de predi√ß√£o e a interpretabilidade do modelo final. A aplica√ß√£o da regulariza√ß√£o L1 nas amostras bootstrap garante modelos mais simples e robustos. [^8.4]. $\blacksquare$

**Corol√°rio 3: Estabilidade e Interpretabilidade com Regulariza√ß√£o L1 e L2**

A utiliza√ß√£o de regulariza√ß√£o (L1 ou L2 ou ambas) dentro do Bagging leva a modelos mais est√°veis e, em alguns casos, mais interpret√°veis. A regulariza√ß√£o L2 reduz a vari√¢ncia dos coeficientes, enquanto a L1 promove a sele√ß√£o de vari√°veis, levando a modelos mais robustos, como abordado em [^8.7]. A combina√ß√£o de m√©todos de regulariza√ß√£o e Bagging ajuda a criar modelos que generalizam melhor e t√™m menos propens√£o a overfitting.

> ‚ö†Ô∏è **Ponto Crucial:** *A combina√ß√£o de L1 e L2 (Elastic Net) pode ser √∫til para balancear a sele√ß√£o de vari√°veis e a redu√ß√£o de vari√¢ncia, levando a modelos mais est√°veis e precisos. Conforme indicado em [^8.7]*.
>
### Separating Hyperplanes e Perceptrons
```mermaid
graph TB
    subgraph "Bagging with Perceptrons"
        direction TB
        A["Original Dataset 'Z'"] --> B["Bootstrap Samples 'Z*b'"]
        B --> C["Train Perceptron on each 'Z*b'"]
        C --> D["Aggregate Perceptron Predictions by Voting"]
    end
```

O conceito de hiperplanos separadores n√£o est√° diretamente ligado ao Bagging da forma como os modelos n√£o lineares est√£o. O Bagging √© uma t√©cnica de agrega√ß√£o de modelos inst√°veis. A ideia de *separating hyperplanes*, em si, j√° √© um m√©todo est√°vel para classifica√ß√£o linear. Entretanto, se tomarmos o Perceptron, um classificador linear, como modelo base, poder√≠amos aplicar o Bagging. O Bagging n√£o altera a linearidade do modelo, mas combina as decis√µes de m√∫ltiplos Perceptrons treinados em dados de bootstrap, que podem levar a uma fronteira de decis√£o mais robusta [^8.7].

> üí° **Exemplo Num√©rico:** Suponha que temos um problema de classifica√ß√£o bin√°ria com duas caracter√≠sticas ($x_1$ e $x_2$), onde queremos encontrar um hiperplano separador usando Perceptrons.
>
> 1. **Dados:** Temos um conjunto de dados n√£o linearmente separ√°vel.
> 2. **Bootstrap Samples:** Criamos v√°rias amostras bootstrap e para cada amostra treinamos um Perceptron.
>  - Perceptron 1 (Amostra 1): Encontra um hiperplano com pesos $w_1 = 0.5$, $w_2 = -0.3$, bias = -0.2
>  - Perceptron 2 (Amostra 2): Encontra um hiperplano com pesos $w_1 = 0.4$, $w_2 = -0.2$, bias = -0.3
>  - Perceptron 3 (Amostra 3): Encontra um hiperplano com pesos $w_1 = 0.6$, $w_2 = -0.4$, bias = -0.1
> 3.  **Agrega√ß√£o:** Para classificar um novo ponto, $x = (2, 1)$, cada Perceptron faz sua predi√ß√£o e agregamos usando uma vota√ß√£o majorit√°ria:
>   - Perceptron 1: $0.5 * 2 - 0.3 * 1 - 0.2 = 0.5$. Classifica como classe 1
>   - Perceptron 2: $0.4 * 2 - 0.2 * 1 - 0.3 = 0.3$. Classifica como classe 1
>   - Perceptron 3: $0.6 * 2 - 0.4 * 1 - 0.1 = 0.7$. Classifica como classe 1
> 4.  **Previs√£o Final:** Como todos os modelos votaram na classe 1, a classe agregada √© 1.
>
>  Ao agregar as decis√µes, podemos obter uma classifica√ß√£o mais robusta do que com apenas um Perceptron treinado no conjunto de dados completo.

A ideia central de hiperplanos separadores √© encontrar um hiperplano que divida as classes em um espa√ßo de caracter√≠sticas, e esse conceito n√£o muda com o uso do Bagging [^8.7]. Entretanto, se o dataset n√£o for linearmente separ√°vel, o uso do Perceptron e do Bagging pode trazer alguma melhora na precis√£o e estabilidade do modelo final.

### Pergunta Te√≥rica Avan√ßada: Qual a rela√ß√£o entre Bagging e a ideia de "Wisdom of Crowds"?

**Resposta:**
O conceito de **Wisdom of Crowds**, como mencionado em [^8.7], refere-se √† ideia de que a agrega√ß√£o de m√∫ltiplas opini√µes independentes leva a uma estimativa mais precisa do que qualquer opini√£o individual. O Bagging explora essa ideia no contexto de aprendizado de m√°quina: cada amostra bootstrap e modelo resultante podem ser vistos como uma opini√£o ou estimativa independente da fun√ß√£o de predi√ß√£o. Ao agregar essas estimativas, o Bagging se beneficia da diversidade dos modelos, o que leva a uma redu√ß√£o da vari√¢ncia e melhora na precis√£o da predi√ß√£o final. Entretanto, o Bagging n√£o garante a total independ√™ncia dos modelos, como √© o caso da sabedoria das multid√µes, dado que todos os modelos s√£o treinados utilizando o mesmo dataset.

**Lemma 4:**  Em cen√°rios ideais onde os modelos base s√£o independentes e n√£o enviesados, o erro da m√©dia das predi√ß√µes tende a ser menor do que o erro de qualquer modelo individual. [^8.7]. Isso pode ser demonstrado ao analisar a vari√¢ncia da m√©dia dos estimadores, que ser√° menor do que a vari√¢ncia de cada estimador individual se eles forem independentes:
$$Var(\frac{1}{B} \sum_{b=1}^B \hat{f}_b(x)) = \frac{1}{B} Var(\hat{f}_b(x))$$
Esta f√≥rmula demonstra como a vari√¢ncia √© reduzida ao agregar m√∫ltiplos modelos independentes. $\blacksquare$
```mermaid
graph LR
    subgraph "Lemma 4: Wisdom of Crowds in Bagging"
        direction LR
        A["Independent Unbiased Models 'fÃÇ_b(x)'"] --> B["Variance of Individual Models: Var(fÃÇ_b(x))"]
        B --> C["Variance of Aggregated Prediction: Var(1/B * Œ£fÃÇ_b(x)) = 1/B * Var(fÃÇ_b(x))"]
        C --> D["Aggregated Prediction Variance < Individual Model Variance"]
    end
```

**Corol√°rio 4:** O sucesso do Bagging depende de qu√£o diversos s√£o os modelos base. Modelos que s√£o muito correlacionados n√£o trazem tanto benef√≠cio da agrega√ß√£o. No entanto, o Bagging √© uma forma eficiente de utilizar o poder da agrega√ß√£o para melhorar modelos que s√£o inst√°veis e que possuem alta vari√¢ncia [^8.7].

> ‚ö†Ô∏è **Ponto Crucial**: A independ√™ncia dos modelos base √© um fator crucial para a efic√°cia do Bagging, o que justifica t√©cnicas como o Random Forests, que visam a reduzir a correla√ß√£o entre os modelos. [^8.7]

### Conclus√£o

O Bagging se apresenta como uma t√©cnica poderosa para reduzir a vari√¢ncia de modelos preditivos, especialmente aqueles que s√£o inst√°veis, tais como as √°rvores de decis√£o. Ao agregar as predi√ß√µes de modelos constru√≠dos em amostras bootstrap, o Bagging estabiliza o processo de predi√ß√£o e leva a resultados mais precisos e robustos. O Bagging √© uma t√©cnica que explora a sabedoria das multid√µes no contexto de aprendizado de m√°quina [^8.7], sendo √∫til em cen√°rios onde h√° alta vari√¢ncia e necessita-se estabilidade no processo de predi√ß√£o. Ao longo deste cap√≠tulo, exploramos a fundo os conceitos te√≥ricos e aplica√ß√µes do Bagging, estabelecendo um fundamento s√≥lido para sua compreens√£o e aplica√ß√£o.

<!-- END DOCUMENT -->
### Footnotes
[^8.1]: "In this chapter we provide a general exposition of the maximum likeli-
hood approach, as well as the Bayesian method for inference. The boot-
strap, introduced in Chapter 7, is discussed in this context, and its relation
to maximum likelihood and Bayes is described. Finally, we present some
related techniques for model averaging and improvement, including com-
mittee methods, bagging, stacking and bumping." *(Trecho de <Model Inference and Averaging>)*
[^8.2]: "The bootstrap method provides a direct computational way of assessing
uncertainty, by sampling from the training data." *(Trecho de <Model Inference and Averaging>)*
[^8.2.1]: "Here we illustrate the
bootstrap in a simple one-dimensional smoothing problem, and show its
connection to maximum likelihood." *(Trecho de <Model Inference and Averaging>)*
[^8.7]: "Earlier we introduced the bootstrap as a way of assessing the accuracy of a
parameter estimate or a prediction. Here we show how to use the bootstrap
to improve the estimate or prediction itself. In Section 8.4 we investigated
the relationship between the bootstrap and Bayes approaches, and found
that the bootstrap mean is approximately a posterior average. Bagging
further exploits this connection." *(Trecho de <Model Inference and Averaging>)*
[^8.4]: "In essence the bootstrap is a computer implementation of nonparametric or
parametric maximum likelihood. The advantage of the bootstrap over the
maximum likelihood formula is that it allows us to compute maximum like-
lihood estimates of standard errors and other quantities in settings where
no formulas are available." *(Trecho de <Model Inference and Averaging>)*
