## Maximization over Parameter Space

<imagem: Diagrama complexo que ilustra o espa√ßo de par√¢metros, com m√∫ltiplos m√≠nimos locais e um m√°ximo global, al√©m de trajet√≥rias de algoritmos de otimiza√ß√£o como gradient descent e EM convergindo para diferentes pontos>

### Introdu√ß√£o

A busca pelo modelo ideal, ou seja, aquele que melhor se ajusta aos dados observados, √© um desafio fundamental no aprendizado estat√≠stico. Frequentemente, essa busca √© formulada como um problema de **maximiza√ß√£o sobre o espa√ßo de par√¢metros** [^8.1]. Isso significa que desejamos encontrar os valores dos par√¢metros de um modelo que tornem os dados observados o mais prov√°veis poss√≠vel, dado o modelo. Essa abordagem, conhecida como **Maximum Likelihood Estimation (MLE)**, √© a base de muitos m√©todos estat√≠sticos e de machine learning. Este cap√≠tulo explora os conceitos e t√©cnicas relacionados √† maximiza√ß√£o sobre o espa√ßo de par√¢metros, com foco especial nos m√©todos de **bootstrap, infer√™ncia de m√°xima verossimilhan√ßa, m√©todos bayesianos, o algoritmo EM, MCMC, bagging, stacking e bumping**, buscando conex√µes entre eles e suas aplica√ß√µes. O objetivo √© fornecer uma compreens√£o profunda de como esses m√©todos buscam otimizar os par√¢metros de modelos para melhorar a performance e a interpretabilidade.

### Conceitos Fundamentais

Para entender a maximiza√ß√£o sobre o espa√ßo de par√¢metros, precisamos primeiro definir alguns conceitos cruciais:

**Conceito 1: Espa√ßo de Par√¢metros**
O espa√ßo de par√¢metros, denotado como $\Theta$, √© o conjunto de todos os poss√≠veis valores que os par√¢metros do nosso modelo podem assumir. Cada ponto em $\Theta$ representa uma configura√ß√£o espec√≠fica do modelo. O objetivo da maximiza√ß√£o sobre o espa√ßo de par√¢metros √© encontrar o ponto em $\Theta$ que melhor se ajusta aos dados [^8.1]. Em regress√£o linear, por exemplo, o espa√ßo de par√¢metros √© definido pelos coeficientes de regress√£o, enquanto em redes neurais, ele √© definido pelos pesos e biases. A complexidade e a dimensionalidade do espa√ßo de par√¢metros impactam diretamente a dificuldade do problema de otimiza√ß√£o, podendo levar a m√∫ltiplos m√≠nimos locais. √â importante notar que a busca em espa√ßos de par√¢metros de alta dimens√£o exige t√©cnicas de otimiza√ß√£o eficientes para encontrar solu√ß√µes satisfat√≥rias. A rela√ß√£o entre o vi√©s e a vari√¢ncia de um modelo tamb√©m √© afetada pela escolha e ajuste dos par√¢metros nesse espa√ßo, sendo necess√°rio um equil√≠brio cuidadoso para evitar overfitting ou underfitting.

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o linear simples $y = \beta_0 + \beta_1 x$. O espa√ßo de par√¢metros $\Theta$ √© o plano 2D definido por $(\beta_0, \beta_1)$. Cada par de valores $(\beta_0, \beta_1)$ define uma reta diferente. Encontrar os melhores par√¢metros significa buscar, nesse espa√ßo, o ponto $(\beta_0, \beta_1)$ que minimiza o erro quadr√°tico m√©dio nos dados. Imagine que temos os dados:
```python
import numpy as np
import matplotlib.pyplot as plt

x = np.array([1, 2, 3, 4, 5])
y = np.array([2, 4, 5, 4, 5])
```
Um poss√≠vel espa√ßo de par√¢metros seria explorar diferentes combina√ß√µes de $\beta_0$ e $\beta_1$ para encontrar aquela que melhor se ajusta aos dados.
```python
from sklearn.linear_model import LinearRegression

X = x.reshape(-1, 1)
model = LinearRegression()
model.fit(X, y)
beta_0 = model.intercept_
beta_1 = model.coef_[0]

print(f"Beta_0: {beta_0:.2f}, Beta_1: {beta_1:.2f}")

plt.scatter(x,y, label="Dados Observados")
x_range = np.linspace(min(x),max(x),100)
y_range = beta_0 + beta_1*x_range
plt.plot(x_range, y_range, color = "red", label=f"Reta ajustada: y = {beta_0:.2f} + {beta_1:.2f}x")
plt.xlabel("x")
plt.ylabel("y")
plt.legend()
plt.show()
```
Este gr√°fico mostra a reta ajustada aos dados, onde os par√¢metros $(\beta_0, \beta_1)$ foram encontrados via minimiza√ß√£o do erro quadr√°tico m√©dio.

**Lemma 1:** A condi√ß√£o necess√°ria para um ponto $\theta^*$ ser um m√°ximo (ou m√≠nimo) local de uma fun√ß√£o diferenci√°vel $f(\theta)$ √© que o gradiente de $f$ em $\theta^*$ seja zero, ou seja, $\nabla f(\theta^*) = 0$. A prova desse lemma segue da defini√ß√£o de derivada e de extremos locais de uma fun√ß√£o. A an√°lise dos pontos onde o gradiente √© zero √© essencial para encontrar candidatos a extremos em problemas de otimiza√ß√£o, e nesse caso, a m√°xima verossimilhan√ßa. A rela√ß√£o do conceito de **gradient ascent (descendente)** est√° diretamente ligada √† dire√ß√£o de maior crescimento (ou decrescimento) da fun√ß√£o em um ponto dado.
```mermaid
graph TB
    subgraph "Lemma 1: Condition for Local Extrema"
        direction TB
        A["f(Œ∏) Differentiable Function"]
        B["Œ∏* is a Local Max or Min"]
        C["Necessary Condition: ‚àáf(Œ∏*) = 0"]
        A --> B
        B --> C
    end
```

**Conceito 2: Infer√™ncia de M√°xima Verossimilhan√ßa (Maximum Likelihood Inference)**
A infer√™ncia de m√°xima verossimilhan√ßa √© um m√©todo para estimar os par√¢metros de um modelo probabil√≠stico. A ideia central √© escolher os par√¢metros que tornam os dados observados *o mais prov√°veis poss√≠veis*. Matematicamente, isso √© expresso atrav√©s da **fun√ß√£o de verossimilhan√ßa (likelihood function)**, denotada por $L(\theta; Z)$, onde $\theta$ s√£o os par√¢metros do modelo e $Z$ representa os dados observados [^8.2.2]. A fun√ß√£o de verossimilhan√ßa √© dada pelo produto das probabilidades (ou densidades de probabilidade) de cada observa√ß√£o:
$$
L(\theta; Z) = \prod_{i=1}^{N} g_{\theta}(z_i)
$$
onde $g_{\theta}(z_i)$ √© a probabilidade (ou densidade) da i-√©sima observa√ß√£o $z_i$ dada pelos par√¢metros $\theta$. O estimador de m√°xima verossimilhan√ßa √© o valor de $\theta$ que maximiza essa fun√ß√£o, ou equivalentemente, o logaritmo da fun√ß√£o de verossimilhan√ßa (log-likelihood), $l(\theta; Z)$. A escolha do logaritmo simplifica a otimiza√ß√£o, transformando produtos em somas, o que √© computacionalmente mais conveniente.
```mermaid
graph LR
    subgraph "Maximum Likelihood Inference"
        direction LR
        A["Data: Z"]
        B["Model Parameters: Œ∏"]
        C["Likelihood Function: L(Œ∏; Z) = ‚àè g_Œ∏(z_i)"]
        D["Log-Likelihood: l(Œ∏; Z) = log(L(Œ∏; Z))"]
        E["MLE Estimator: argmax_Œ∏ l(Œ∏; Z)"]
        A & B --> C
        C --> D
        D --> E
    end
```

> üí° **Exemplo Num√©rico:** Considere um conjunto de dados $Z = \{2.1, 2.8, 3.5, 3.9, 4.6\}$ que segue uma distribui√ß√£o normal com m√©dia $\mu$ e desvio padr√£o $\sigma = 1$. A fun√ß√£o de verossimilhan√ßa √©:
$$
L(\mu; Z) = \prod_{i=1}^{5} \frac{1}{\sqrt{2\pi}} e^{-\frac{(z_i - \mu)^2}{2}}
$$
O log-verossimilhan√ßa √©:
$$
l(\mu; Z) = \sum_{i=1}^{5} \left[ -\frac{1}{2} \ln(2\pi) - \frac{(z_i - \mu)^2}{2} \right]
$$
Para encontrar o estimador de m√°xima verossimilhan√ßa para $\mu$, precisamos maximizar essa fun√ß√£o. Tomando a derivada em rela√ß√£o a $\mu$ e igualando a zero, obtemos:
$$
\frac{\partial l}{\partial \mu} = \sum_{i=1}^{5} (z_i - \mu) = 0
$$
Resolvendo para $\mu$, temos:
$$
\hat{\mu} = \frac{1}{5} \sum_{i=1}^{5} z_i = \frac{2.1 + 2.8 + 3.5 + 3.9 + 4.6}{5} = 3.38
$$
Portanto, o estimador de m√°xima verossimilhan√ßa para a m√©dia $\mu$ √© a m√©dia amostral 3.38.

**Corol√°rio 1:** A vari√¢ncia do estimador de m√°xima verossimilhan√ßa (MLE), sob certas condi√ß√µes de regularidade, pode ser aproximada pela inversa da matriz de informa√ß√£o de Fisher, dada por:
$$
Var(\hat{\theta}) \approx I(\theta)^{-1}
$$
onde $I(\theta)$ √© a matriz de informa√ß√£o de Fisher. Essa matriz, calculada em torno do estimador de m√°xima verossimilhan√ßa, fornece uma medida da precis√£o do estimador [^8.2.2].
```mermaid
graph LR
    subgraph "Corollary 1: Variance of MLE"
        direction LR
        A["Fisher Information Matrix: I(Œ∏)"]
        B["MLE Estimator: Œ∏ÃÇ"]
        C["Variance Approximation: Var(Œ∏ÃÇ) ‚âà I(Œ∏)‚Åª¬π"]
        A --> C
        B --> C
    end
```

> üí° **Exemplo Num√©rico:** No exemplo anterior, com dados normais e desvio padr√£o conhecido ($\sigma=1$), a informa√ß√£o de Fisher para a m√©dia $\mu$ √© dada por $I(\mu) = \frac{n}{\sigma^2} = \frac{5}{1^2} = 5$. A vari√¢ncia do estimador de m√°xima verossimilhan√ßa (a m√©dia amostral) √© ent√£o aproximada por:
$$
Var(\hat{\mu}) \approx I(\mu)^{-1} = \frac{1}{5} = 0.2
$$
A raiz quadrada desta vari√¢ncia, $\sqrt{0.2} \approx 0.447$, √© o desvio padr√£o estimado do estimador $\hat{\mu}$, indicando que a estimativa da m√©dia tem uma incerteza de aproximadamente 0.447.

**Conceito 3: Bootstrap e M√°xima Verossimilhan√ßa**
O m√©todo de bootstrap √© uma t√©cnica de reamostragem que permite avaliar a incerteza associada √†s estimativas de par√¢metros ou previs√µes, sem a necessidade de suposi√ß√µes param√©tricas fortes [^8.2.1]. Ao gerar m√∫ltiplas amostras bootstrap a partir dos dados originais e estimar um modelo para cada uma delas, o bootstrap nos permite criar uma distribui√ß√£o emp√≠rica dos estimadores. Essa distribui√ß√£o pode ent√£o ser usada para construir intervalos de confian√ßa ou avaliar a variabilidade de previs√µes. O bootstrap est√° intimamente ligado √† m√°xima verossimilhan√ßa porque, em muitos casos, a distribui√ß√£o bootstrap converge para a distribui√ß√£o do estimador de m√°xima verossimilhan√ßa. Particularmente, o bootstrap param√©trico, que gera dados com base em um modelo MLE, tem rela√ß√£o com a infer√™ncia de m√°xima verossimilhan√ßa [^8.2.2].
```mermaid
graph LR
    subgraph "Bootstrap and MLE"
        direction LR
        A["Original Data"]
        B["Bootstrap Resamples"]
        C["Model Estimation per Resample"]
        D["Empirical Distribution of Estimators"]
        E["Inference (CI, Variability)"]
		F["MLE Model"]
		B --> C
        A --> B
        C --> D
        D --> E
		F --> B
		F -.-> E
    end
```

> ‚ö†Ô∏è **Nota Importante**: O bootstrap √© uma ferramenta valiosa para avaliar a incerteza, especialmente em situa√ß√µes onde as suposi√ß√µes param√©tricas s√£o question√°veis, como discutido em [^8.2.1].

> ‚ùó **Ponto de Aten√ß√£o**: √â crucial entender a diferen√ßa entre bootstrap param√©trico e n√£o param√©trico. O primeiro simula novos dados com base no modelo ajustado, enquanto o segundo reamostra diretamente dos dados originais [^8.2.1].

> ‚úîÔ∏è **Destaque**: Em modelos com erros gaussianos aditivos, o bootstrap param√©trico concorda com a estimativa de m√≠nimos quadrados, como indicado em [^8.2.2].

> üí° **Exemplo Num√©rico:** Usando o exemplo anterior da regress√£o linear, podemos aplicar o bootstrap n√£o param√©trico. Geramos, por exemplo, 1000 amostras bootstrap do conjunto de dados original, cada uma com o mesmo n√∫mero de pontos que o conjunto original, obtidas por amostragem com reposi√ß√£o. Para cada amostra bootstrap, estimamos os coeficientes de regress√£o $\beta_0$ e $\beta_1$ e calculamos as m√©dias, para observar a variabilidade das estimativas.
```python
import numpy as np
import pandas as pd
from sklearn.utils import resample

x = np.array([1, 2, 3, 4, 5])
y = np.array([2, 4, 5, 4, 5])
data = pd.DataFrame({'x': x, 'y': y})

n_iterations = 1000
beta0_estimates = []
beta1_estimates = []
for _ in range(n_iterations):
    bootstrap_sample = resample(data)
    X_bootstrap = bootstrap_sample['x'].values.reshape(-1, 1)
    y_bootstrap = bootstrap_sample['y'].values
    model_bootstrap = LinearRegression()
    model_bootstrap.fit(X_bootstrap, y_bootstrap)
    beta0_estimates.append(model_bootstrap.intercept_)
    beta1_estimates.append(model_bootstrap.coef_[0])

beta0_estimates_np = np.array(beta0_estimates)
beta1_estimates_np = np.array(beta1_estimates)

print(f"Desvio padr√£o Bootstrap beta0: {beta0_estimates_np.std():.3f}")
print(f"Desvio padr√£o Bootstrap beta1: {beta1_estimates_np.std():.3f}")

plt.hist(beta0_estimates, bins = 20, alpha = 0.5, label = "Beta 0")
plt.hist(beta1_estimates, bins = 20, alpha = 0.5, label = "Beta 1")
plt.legend()
plt.xlabel("Valor")
plt.ylabel("Frequ√™ncia")
plt.show()
```
A distribui√ß√£o das estimativas de $\beta_0$ e $\beta_1$ permite avaliar a incerteza das estimativas. O desvio padr√£o das amostras bootstrap nos d√° uma ideia da incerteza da estimativa de $\beta_0$ e $\beta_1$.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

<imagem: Diagrama de fluxo mostrando a aplica√ß√£o da regress√£o linear a uma matriz de indicadores para problemas de classifica√ß√£o, com passos como codifica√ß√£o das classes, estima√ß√£o dos coeficientes, aplica√ß√£o da regra de decis√£o e avalia√ß√£o dos resultados, incluindo um destaque das limita√ß√µes devido ao problema do "masking">

```mermaid
flowchart TD
  subgraph "Regress√£o de Indicadores"
    A["Codificar Classes"] --> B["Estimar Coeficientes via LS"]
    B --> C["Aplicar Regra de Decis√£o"]
    C --> D["Comparar com M√©todos Probabil√≠sticos"]
    D --> E["Analisar Limita√ß√µes e o 'masking problem'"]
  end
```
**Explica√ß√£o:** Este diagrama representa o fluxo do processo de regress√£o de indicadores e como ele se relaciona √† classifica√ß√£o, **conforme descrito nos t√≥picos [^8.1] e [^8.2]**.

A regress√£o linear pode ser aplicada a problemas de classifica√ß√£o atrav√©s da **regress√£o em matriz de indicadores**. Em vez de prever um valor num√©rico, como em problemas de regress√£o tradicional, busca-se prever a classe de um dado input usando uma matriz que codifica as classes como vari√°veis indicadoras. Se temos $K$ classes, criamos uma matriz $Y$ de dimens√µes $N \times K$ onde $N$ √© o n√∫mero de observa√ß√µes. Cada linha de $Y$ cont√©m um "1" na coluna correspondente √† classe da observa√ß√£o e "0" nas demais. O objetivo √© modelar cada coluna de $Y$ usando um modelo linear com os inputs como preditores. Formalmente, para cada observa√ß√£o $i$ e classe $k$:
$$
Y_{ik} = \beta_{0k} + \beta_{1k} x_{i1} + \beta_{2k} x_{i2} + \ldots + \beta_{pk} x_{ip} + \epsilon_{ik}
$$
onde $Y_{ik}$ √© o valor da vari√°vel indicadora para a i-√©sima observa√ß√£o na k-√©sima classe, $x_{ij}$ √© o valor da j-√©sima feature na i-√©sima observa√ß√£o, e $\beta_{jk}$ s√£o os coeficientes do modelo.

Ap√≥s ajustar o modelo de regress√£o, podemos prever as probabilidades de cada observa√ß√£o pertencer a uma classe. Para a i-√©sima observa√ß√£o e a k-√©sima classe, a probabilidade prevista √© dada por $\hat{Y}_{ik}$. A classe prevista para cada observa√ß√£o ser√° aquela com a maior probabilidade prevista.

No entanto, este m√©todo tem limita√ß√µes. A regress√£o linear assume que a rela√ß√£o entre as vari√°veis explicativas e a vari√°vel resposta √© linear, e que os erros s√£o gaussianos e independentes. Em muitos problemas de classifica√ß√£o, essas suposi√ß√µes n√£o se verificam, o que pode levar a resultados sub√≥timos, como overfitting em classes com muitos outliers ou com o problema do *masking*, onde classes intermedi√°rias podem ser negligenciadas em favor de classes extremas [^8.3].

**Lemma 2:** O ajuste dos coeficientes $\beta$ por m√≠nimos quadrados para o problema da regress√£o de matriz de indicadores resulta em encontrar um hiperplano de decis√£o linear em cada classe. A demonstra√ß√£o deste lemma pode ser feita com a deriva√ß√£o das equa√ß√µes normais, que minimizam o erro quadr√°tico m√©dio e mostram que a solu√ß√£o √© linear em rela√ß√£o aos dados de entrada, conforme descrito em [^8.2].
```mermaid
graph TB
    subgraph "Lemma 2: Linear Decision Hyperplane"
        direction TB
        A["Indicator Matrix Regression"]
        B["Least Squares Fit for Œ≤"]
        C["Resulting Linear Decision Hyperplane"]
        A --> B
        B --> C
    end
```

**Corol√°rio 2:** Em certas condi√ß√µes, a proje√ß√£o de um dado ponto sobre os hiperplanos de decis√£o (resultantes da regress√£o linear da matriz de indicadores) se relaciona √† decis√£o de classe no problema de classifica√ß√£o, proporcionando uma forma de interpretar e classificar os resultados, baseando-se no Lemma 2.

Apesar das limita√ß√µes, a regress√£o linear na matriz de indicadores pode ser uma abordagem √∫til para problemas de classifica√ß√£o, especialmente quando o principal objetivo √© a obten√ß√£o de uma fronteira de decis√£o linear. Em cen√°rios onde as predi√ß√µes de probabilidade s√£o cruciais, m√©todos como a regress√£o log√≠stica podem ser mais adequados, pois imp√µem a restri√ß√£o de que os valores preditos se situem entre 0 e 1 [^8.4].

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com tr√™s classes (A, B, e C) e duas features ($x_1$ e $x_2$). Temos um conjunto de dados com 6 amostras:
```python
import numpy as np
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 1.1]])
Y_classes = np.array(['A', 'A', 'B', 'B', 'C', 'C'])
```
Primeiro, codificamos as classes usando uma matriz de indicadores:
```python
from sklearn.preprocessing import LabelBinarizer
encoder = LabelBinarizer()
Y_encoded = encoder.fit_transform(Y_classes)

print("Matriz de indicadores Y_encoded:")
print(Y_encoded)
```
A matriz resultante √©:
```
[[1 0 0]
 [1 0 0]
 [0 1 0]
 [0 1 0]
 [0 0 1]
 [0 0 1]]
```
Agora, ajustamos um modelo de regress√£o linear para cada coluna de Y_encoded.
```python
models = []
for k in range(Y_encoded.shape[1]):
    model = LinearRegression()
    model.fit(X, Y_encoded[:,k])
    models.append(model)
```
Para um novo ponto, por exemplo, $x_{new} = [6, 5]$, calculamos as probabilidades de cada classe e classificamos:
```python
x_new = np.array([6, 5]).reshape(1, -1)
predicted_probabilities = []
for model in models:
    predicted_probabilities.append(model.predict(x_new)[0])

predicted_probabilities = np.array(predicted_probabilities)
predicted_class_index = np.argmax(predicted_probabilities)
predicted_class = encoder.classes_[predicted_class_index]

print(f"Probabilidades preditas para cada classe: {predicted_probabilities}")
print(f"Classe predita: {predicted_class}")
```
O output mostra as probabilidades preditas para cada classe e a classe predita com a maior probabilidade. O problema do 'masking' poderia ocorrer se, por exemplo, a classe C fosse pouco representada ou mais pr√≥xima das classes A ou B no espa√ßo de features, fazendo com que a regress√£o linear n√£o a reconhecesse adequadamente.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

<imagem: Mapa mental que conecta os conceitos de sele√ß√£o de vari√°veis, regulariza√ß√£o (L1 e L2), suas aplica√ß√µes em regress√£o log√≠stica e a rela√ß√£o com a interpretabilidade e sparsity de modelos de classifica√ß√£o>
```mermaid
graph TB
    subgraph "Regularization in Classification"
        direction TB
        A["Feature Selection"]
        B["L1 Regularization"]
        C["L2 Regularization"]
        D["Logistic Regression"]
        E["Model Interpretability"]
        F["Sparsity"]
        A --> D
        B --> D
        C --> D
        D --> E
        B --> F
    end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas importantes para melhorar a performance e a interpretabilidade de modelos de classifica√ß√£o, especialmente em situa√ß√µes com um grande n√∫mero de features [^8.5]. A sele√ß√£o de vari√°veis visa identificar e reter apenas as vari√°veis mais relevantes, enquanto a regulariza√ß√£o imp√µe penalidades aos coeficientes do modelo para evitar overfitting e promover a sparsity.

Na classifica√ß√£o, especialmente em modelos como a regress√£o log√≠stica, a regulariza√ß√£o √© implementada atrav√©s da adi√ß√£o de termos de penaliza√ß√£o √† fun√ß√£o de log-verossimilhan√ßa [^8.4.4]. Por exemplo, a regulariza√ß√£o $L_1$ adiciona uma penalidade proporcional ao valor absoluto dos coeficientes:
$$
l(\theta;Z) - \lambda \sum_{j=1}^{p} |\beta_j|
$$
onde $\lambda$ √© um par√¢metro de regulariza√ß√£o que controla a for√ßa da penalidade, e $\beta_j$ s√£o os coeficientes do modelo. Esta penaliza√ß√£o tende a "zerar" alguns coeficientes, promovendo a sparsity, o que facilita a interpreta√ß√£o do modelo. Por outro lado, a regulariza√ß√£o $L_2$ adiciona uma penalidade proporcional ao quadrado dos coeficientes:
$$
l(\theta;Z) - \lambda \sum_{j=1}^{p} \beta_j^2
$$
A penaliza√ß√£o $L_2$ reduz o valor dos coeficientes, evitando overfitting, sem necessariamente zer√°-los [^8.5]. Ambas as regulariza√ß√µes s√£o muito utilizadas em cen√°rios de alta dimensionalidade. √â importante ressaltar que, muitas vezes, a combina√ß√£o das penaliza√ß√µes L1 e L2 (Elastic Net) pode proporcionar um bom compromisso entre sparsity e performance, como apontado em [^8.5]. A escolha adequada do par√¢metro de regulariza√ß√£o, muitas vezes, √© feita usando m√©todos de valida√ß√£o cruzada, de modo a otimizar o ajuste do modelo.

**Lemma 3:** Em modelos lineares como a regress√£o log√≠stica, a penaliza√ß√£o L1 pode induzir sparsity nos coeficientes, demonstrando que em busca por solu√ß√µes √≥timas, um certo n√∫mero de par√¢metros s√£o levados a zero, removendo features menos relevantes. Esta demostra√ß√£o pode ser feita a partir da an√°lise das subgradientes da fun√ß√£o objetivo modificada, incorporando o termo de penaliza√ß√£o L1 e sua influ√™ncia sobre o otimizador, conforme descrito em [^8.4.4].
```mermaid
graph TB
    subgraph "Lemma 3: L1 Regularization and Sparsity"
        direction TB
        A["L1 Penalized Logistic Regression"]
        B["Subgradients Analysis"]
        C["Coefficients Driven to Zero"]
         D["Feature Selection"]
        A --> B
        B --> C
         C --> D
    end
```

**Prova do Lemma 3:** A fun√ß√£o objetivo da regress√£o log√≠stica regularizada com L1 √©:
$$
J(\beta) = -l(\beta) + \lambda \sum_{j=1}^{p} |\beta_j|
$$
onde $l(\beta)$ √© a log-verossimilhan√ßa. O termo de penaliza√ß√£o L1 $\lambda \sum_{j=1}^{p} |\beta_j|$ introduz uma n√£o diferenciabilidade na fun√ß√£o objetivo nos pontos em que $\beta_j=0$. Para encontrar o m√≠nimo desta fun√ß√£o, precisamos utilizar o conceito de subgradiente. A subgradiente do termo de penaliza√ß√£o $|\beta_j|$ √© igual a -1 se $\beta_j < 0$, 1 se $\beta_j > 0$, e um valor entre -1 e 1 se $\beta_j=0$. Portanto, para que o vetor de par√¢metros minimize a fun√ß√£o objetivo, o subgradiente da fun√ß√£o objetivo deve conter o vetor zero. Isso faz com que um subconjunto dos coeficientes $\beta_j$ seja levado a zero, promovendo a sparsity. $\blacksquare$

**Corol√°rio 3:** A propriedade de sparsity induzida pela regulariza√ß√£o L1 resulta em modelos mais interpret√°veis, pois apenas as vari√°veis mais relevantes para a classifica√ß√£o possuem coeficientes n√£o nulos, como visto em [^8.4.4] e [^8.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: A combina√ß√£o das penalidades L1 e L2 (Elastic Net) permite explorar vantagens de ambas as abordagens, conforme discutido em [^8.5].

> üí° **Exemplo Num√©rico:**  Vamos aplicar a regulariza√ß√£o L1 e L2 em um problema de classifica√ß√£o com regress√£o log√≠stica. Usaremos o mesmo dataset da se√ß√£o anterior mas adicionaremos algumas features irrelevantes.
```python
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelBinarizer
import matplotlib.pyplot as plt
import pandas as pd


X = np.array([[1, 2, 0.1, 0.2], [1.5, 1.8, 0.2, 0.3], [5, 8, 0.3, 0.1], [8, 8, 0.4, 0.5], [1, 0.6, 0.5, 0.1], [9, 1.1, 0.6, 0.2]])
Y_classes = np.array(['A', 'A', 'B', 'B', 'C', 'C'])
```
Criamos um dataframe para visualiza√ß√£o:
```python
df = pd.DataFrame(X, columns=['x1', 'x2', 'x3', 'x4'])
df['class'] = Y_classes
print(df)
```
Vamos treinar modelos com L1 e L2:
```python
encoder = LabelBinarizer()
Y_encoded = encoder.fit_transform(Y_classes)

model_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1)
model_l1.fit(X, Y_encoded)

model_l2 = LogisticRegression(penalty='l2', C=1)
model_l2.fit(X, Y_encoded)
```
Aqui C √© o inverso da lambda de regulariza√ß√£o. A inspe√ß√£o dos coeficientes nos d√°:
```python
print("Coeficientes L1:")
print(model_l1.coef_)
print("Coeficientes L2:")
print(model_l2.coef_)
```
A regulariza√ß√£o L1 tende a gerar coeficientes nulos, indicando features irrelevantes (nesse caso, x3 e x4), enquanto a L2 reduz os valores de todos os coeficientes. Podemos observar que os coeficientes das features x3 e x4 foram reduzidos a 0 com a regulariza√ß√£o L1, indicando que essas features foram consideradas irrelevantes para a classifica√ß√£o. A regulariza√ß√£o L2 reduziu os valores de todos os coeficientes.

### Separating Hyperplanes e Perceptrons

<imagem: Diagrama ilustrando o conceito de hiperplanos separadores, com diferentes margens de separa√ß√£o entre as classes, mostrando como a otimiza√ß√£o da margem leva √† defini√ß√£o de hiperplanos √≥timos, e um exemplo da opera√ß√£o do perceptron para ajuste do hiperplano>
```mermaid
graph TB
    subgraph "Separating Hyperplanes and Perceptrons"
        direction TB
        A["Separating Hyperplane: w^T x + b = 0"]
        B["Margin Maximization"]
        C["Support Vector Machines (SVM)"]
        D["Perceptron Algorithm"]
        E["Iterative Hyperplane Adjustment"]
        A --> B
        B --> C
        A --> D
        D --> E
    end
```

A ideia central por tr√°s dos **separating hyperplanes** √© encontrar um hiperplano que divida o espa√ßo de features de forma a separar as diferentes classes de forma √≥tima. A ideia de **maximizar a margem** de separa√ß√£o (a dist√¢ncia entre o hiperplano e os pontos mais pr√≥ximos de cada classe, os chamados vetores de suporte) leva √† formula√ß√£o de um problema de otimiza√ß√£o que pode ser resolvido usando programa√ß√£o quadr√°tica [^8.5.2]. Formalmente, um hiperplano de separa√ß√£o pode ser definido como:

$$
w^T x + b = 0
$$

onde $w$ √© o vetor normal ao hiperplano, $x$ √© um vetor de features, e $b$ √© o bias. O objetivo √© encontrar $w$ e $b$ tais que todos os pontos de uma classe estejam de um lado do hiperplano e todos os pontos de outra classe estejam do outro lado, com a maior margem poss√≠vel. Essa formula√ß√£o leva ao conceito de **m√°quina de vetores de suporte (SVM)**, que √© capaz de encontrar hiperplanos √≥timos, mesmo em casos onde os dados n√£o s√£o linearmente separ√°veis. A solu√ß√£o do problema de otimiza√ß√£o do SVM geralmente √© encontrada no dual de Wolfe, que √© matematicamente mais f√°cil de tratar.

O **Perceptron** de Rosenblatt √© um algoritmo de aprendizado supervisionado que busca encontrar um hiperplano que separa linearmente duas classes [^8.5.1]. O perceptron √© um algoritmo iterativo que come√ßa com um hiperplano aleat√≥rio e o ajusta iterativamente, de acordo com os erros de classifica√ß√£o. Se um ponto √© classificado erroneamente, o hiperplano √© ajustado na dire√ß√£o desse ponto para tentar classific√°-lo corretamente. Formalmente, a atualiza√ß√£o dos pesos em uma itera√ß√£o *t+1* pode ser expressa como:

$$
w^{t+1} = w^{t} + \eta y_i x_i
$$
onde $\eta$ √© a taxa de aprendizagem e $y_i$ √© o r√≥tulo da i-√©sima amostra (-1 ou 1). Sob certas condi√ß√µes, o perceptron converge para um hiperplano que separa linearmente as classes. No entanto, √© importante notar que o perceptron n√£o garante encontrar o hiperplano com maior margem.

> üí° **Exemplo Num√©rico:** Consideremos um problema de classifica√ß√£o bin√°ria com duas features. Inicializamos os pesos ($w$) e bias ($b$) aleatoriamente:
```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Perceptron

X = np.array([[1, 2], [2, 1], [3, 3], [5, 2], [6, 3], [7, 1]])
y = np.array([-1, -1, -1, 1, 1, 1])
```
Aplicamos o perceptron:
```python
perceptron = Perceptron(max_iter=1000, tol=1e-3, eta0=0.1)
perceptron.fit(X, y)
w = perceptron.coef_[0]
b = perceptron.intercept_[0]

print(f"Vetor normal ao hiperplano: w = {w}")
print(f"Bias: b = {b}")

x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1

xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),
                     np.arange(y_min, y_max, 0.02))
Z = perceptron.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)
plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha=0.8)
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu, edgecolors='k')
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.title("Fronteira de decis√£o do Perceptron")
plt.show()
```
Ap√≥s a converg√™ncia do Perceptron, o output exibe o vetor normal ao hiperplano w e o bias b, determinando o hiperplano separador encontrado. O gr√°fico mostra a fronteira de decis√£o entre as duas classes.

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**

A **Linear Discriminant Analysis (LDA)** e a **regra de decis√£o Bayesiana** s√£o m√©todos de classifica√ß√£o que, sob a suposi√ß√£o de distribui√ß√µes Gaussianas com covari√¢ncias iguais, tornam-se equivalentes em muitos cen√°rios. Em outras palavras, a decis√£o de classe resultante da aplica√ß√£o de ambas as abordagens √© a mesma. A LDA estima par√¢metros que maximizam a separa√ß√£o entre classes, enquanto a regra de decis√£o Bayesiana minimiza o risco de classifica√ß√£o errada.
```mermaid
graph TB
    subgraph "LDA vs. Bayesian Decision Rule"
         direction TB
        A["Assumptions: Gaussian distributions with equal covariances"]
        B["Linear Discriminant Analysis (LDA)"]
        C["Bayesian Decision Rule"]
		D["LDA maximises class separation"]
		E["Bayesian decision minimises classification risk"]
        F["Equivalent Class Decisions"]
		A --> B
		A --> C
		B --> D
		C --> E
        D & E --> F
    end
```

A LDA assume que os dados de cada classe s√£o gerados por uma distribui√ß√£o normal multivariada com m√©dias diferentes ($\mu_k$ para a classe k) mas com a mesma matriz de covari√¢ncia $\Sigma$, ou seja, $X | Y=k \sim N(\mu