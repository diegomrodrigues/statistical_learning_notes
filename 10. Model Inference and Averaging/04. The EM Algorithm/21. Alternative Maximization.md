## Model Inference and Averaging: Alternative Maximization Procedures
<imagem: Um mapa mental complexo que conecta o EM Algorithm com m√©todos de sampling como o Gibbs Sampling, mostrando como diferentes abordagens de maximiza√ß√£o e infer√™ncia se relacionam com o modelo de mistura Gaussiana.>

### Introdu√ß√£o
Neste cap√≠tulo, exploramos m√©todos de infer√™ncia e modelagem, focando em abordagens de *maximum likelihood* e Bayesianas, bem como em t√©cnicas de *model averaging* e aprimoramento. A maioria dos modelos apresentados neste livro foram ajustados por meio da minimiza√ß√£o de soma de quadrados para regress√£o ou da minimiza√ß√£o de entropia cruzada para classifica√ß√£o [^8.1]. Essas abordagens s√£o inst√¢ncias do m√©todo de *maximum likelihood*. Aqui, apresentamos uma exposi√ß√£o geral do *maximum likelihood*, do m√©todo Bayesiano e do *bootstrap* [^8.1]. Al√©m disso, exploramos t√©cnicas relacionadas para a m√©dia e o aprimoramento de modelos, como m√©todos de comit√™, *bagging*, *stacking* e *bumping* [^8.1]. Este cap√≠tulo visa aprofundar o conhecimento em m√©todos avan√ßados de infer√™ncia, permitindo uma compreens√£o mais ampla e detalhada sobre diferentes estrat√©gias de otimiza√ß√£o e modelagem.

### Conceitos Fundamentais
**Conceito 1: Maximum Likelihood**
O m√©todo de **Maximum Likelihood** (ML) busca encontrar os par√¢metros de um modelo que maximizam a probabilidade dos dados observados. Formalmente, dado um conjunto de dados $Z = \{z_1, z_2, \ldots, z_N\}$ e um modelo param√©trico $g_\theta(z)$ definido por um conjunto de par√¢metros $\theta$, a fun√ß√£o de verossimilhan√ßa $L(\theta; Z)$ √© dada por:

$$L(\theta; Z) = \prod_{i=1}^{N} g_\theta(z_i)$$ [^8.2.2]

```mermaid
graph LR
    subgraph "Likelihood Function Decomposition"
        direction TB
        A["Likelihood Function: L(Œ∏; Z)"]
        B["Individual Probability: g_Œ∏(z_i)"]
        C["Product of Probabilities:  ‚àè (from i=1 to N) g_Œ∏(z_i)"]
        A --> C
        C --> B
    end
```

O objetivo √© encontrar o valor de $\theta$ que maximiza essa fun√ß√£o de verossimilhan√ßa, ou equivalentemente, sua log-verossimilhan√ßa $l(\theta; Z) = \sum_{i=1}^{N} \log g_\theta(z_i)$ [^8.2.2]. O estimador de m√°xima verossimilhan√ßa √©, portanto, dado por:

$$\hat{\theta}_{ML} = \arg \max_\theta l(\theta; Z)$$

No contexto da regress√£o linear com erros Gaussianos, a estimativa por m√≠nimos quadrados √© equivalente √† estimativa de m√°xima verossimilhan√ßa [^8.2.2]. Para dados com distribui√ß√£o normal com m√©dia $\mu$ e vari√¢ncia $\sigma^2$, a fun√ß√£o de verossimilhan√ßa √© dada por:

$$ g_{\theta}(z) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(z-\mu)^2}{2\sigma^2}} $$

A t√©cnica de *Maximum Likelihood* √© um m√©todo fundamental na infer√™ncia estat√≠stica e, apesar de amplamente utilizada, possui certas limita√ß√µes. Em particular, ela n√£o considera incertezas *a priori* nos par√¢metros, e suas estimativas pontuais podem ser sens√≠veis a *outliers* [^8.2.2].

> üí° **Exemplo Num√©rico:**
> Vamos considerar um exemplo simples com dados Gaussianos. Suponha que temos 5 observa√ß√µes: $Z = \{2.1, 2.8, 3.5, 3.2, 2.4\}$. Assumindo que esses dados seguem uma distribui√ß√£o normal com m√©dia $\mu$ e vari√¢ncia $\sigma^2$, vamos estimar esses par√¢metros usando *Maximum Likelihood*.
> A fun√ß√£o de log-verossimilhan√ßa √©:
> $$l(\mu, \sigma^2; Z) = \sum_{i=1}^{5} \log \left(\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(z_i-\mu)^2}{2\sigma^2}}\right)$$
> Simplificando:
> $$l(\mu, \sigma^2; Z) = -\frac{5}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{5} (z_i - \mu)^2$$
> Para encontrar $\hat{\mu}_{ML}$, calculamos a m√©dia amostral:
> $$\hat{\mu}_{ML} = \frac{1}{5} \sum_{i=1}^{5} z_i = \frac{2.1 + 2.8 + 3.5 + 3.2 + 2.4}{5} = 2.8$$
> Para encontrar $\hat{\sigma}^2_{ML}$, usamos:
> $$\hat{\sigma}^2_{ML} = \frac{1}{5} \sum_{i=1}^{5} (z_i - \hat{\mu}_{ML})^2$$
> $$\hat{\sigma}^2_{ML} = \frac{(2.1-2.8)^2 + (2.8-2.8)^2 + (3.5-2.8)^2 + (3.2-2.8)^2 + (2.4-2.8)^2}{5}$$
> $$\hat{\sigma}^2_{ML} = \frac{0.49 + 0 + 0.49 + 0.16 + 0.16}{5} = 0.26$$
> Portanto, as estimativas de m√°xima verossimilhan√ßa s√£o $\hat{\mu}_{ML} = 2.8$ e $\hat{\sigma}^2_{ML} = 0.26$. Note que esta √© uma estimativa pontual e n√£o expressa a incerteza nos par√¢metros.

**Lemma 1:**
A solu√ß√£o de m√≠nimos quadrados para um modelo linear com erros aditivos Gaussianos √© equivalente √† solu√ß√£o de *maximum likelihood* para os par√¢metros do modelo, incluindo a vari√¢ncia do erro.

*Prova*:
Considere um modelo linear $Y = X\beta + \epsilon$, onde $\epsilon \sim N(0, \sigma^2)$. A fun√ß√£o de verossimilhan√ßa para $N$ observa√ß√µes independentes √©:
$$L(\beta,\sigma^2 | Y, X) = \prod_{i=1}^{N} \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left( -\frac{(y_i - x_i^T\beta)^2}{2\sigma^2} \right)$$
A log-verossimilhan√ßa correspondente √©:
$$l(\beta,\sigma^2 | Y, X) = -\frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{N} (y_i - x_i^T\beta)^2$$

```mermaid
graph LR
    subgraph "Log-Likelihood Decomposition"
        direction LR
        A["Log-Likelihood: l(Œ≤, œÉ¬≤ | Y, X)"]
        B["Constant Term: -(N/2)log(2œÄœÉ¬≤)"]
        C["Error Term: -(1/(2œÉ¬≤))‚àë(y·µ¢ - x·µ¢·µÄŒ≤)¬≤"]
        A --> B
        A --> C
    end
```
Para maximizar a log-verossimilhan√ßa, podemos maximizar os termos que dependem de $\beta$ e $\sigma^2$ separadamente. Maximizando em rela√ß√£o a $\beta$ significa minimizar o termo $\sum_{i=1}^{N} (y_i - x_i^T\beta)^2$, que √© o mesmo objetivo do m√©todo dos m√≠nimos quadrados. Tomando derivadas e igualando a zero obtemos:
$$\hat{\beta}_{ML} = (X^TX)^{-1}X^TY$$
Para maximizar em rela√ß√£o a $\sigma^2$, derivamos o termo restante e igualamos a zero:
$$\frac{\partial}{\partial \sigma^2} \left[ -\frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{N} (y_i - x_i^T\hat{\beta}_{ML})^2 \right] = 0$$
O que nos leva a estimativa de m√°xima verossimilhan√ßa da vari√¢ncia:
$$\hat{\sigma}^2_{ML} = \frac{1}{N}\sum_{i=1}^{N} (y_i - x_i^T\hat{\beta}_{ML})^2$$
que √© tamb√©m a estimativa de m√≠nimos quadrados para vari√¢ncia do erro. $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Vamos considerar um exemplo de regress√£o linear simples com duas vari√°veis. Suponha que temos os seguintes dados:
>
> | $x_1$ | $x_2$ | $y$   |
> |-------|-------|-------|
> | 1     | 2     | 5     |
> | 2     | 3     | 8     |
> | 3     | 4     | 11    |
> | 4     | 5     | 14    |
> | 5     | 6     | 17    |
>
> Podemos representar esses dados na forma matricial:
>
> $$ X = \begin{bmatrix} 1 & 2 \\ 2 & 3 \\ 3 & 4 \\ 4 & 5 \\ 5 & 6 \end{bmatrix}, \quad Y = \begin{bmatrix} 5 \\ 8 \\ 11 \\ 14 \\ 17 \end{bmatrix} $$
>
> Primeiro, calculamos $X^TX$:
> $$ X^TX = \begin{bmatrix} 1 & 2 & 3 & 4 & 5 \\ 2 & 3 & 4 & 5 & 6 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 2 & 3 \\ 3 & 4 \\ 4 & 5 \\ 5 & 6 \end{bmatrix} = \begin{bmatrix} 55 & 70 \\ 70 & 90 \end{bmatrix} $$
>
> Em seguida, calculamos $(X^TX)^{-1}$:
> $$ (X^TX)^{-1} = \frac{1}{(55*90 - 70*70)} \begin{bmatrix} 90 & -70 \\ -70 & 55 \end{bmatrix} = \frac{1}{50} \begin{bmatrix} 90 & -70 \\ -70 & 55 \end{bmatrix} = \begin{bmatrix} 1.8 & -1.4 \\ -1.4 & 1.1 \end{bmatrix}$$
>
> Calculamos $X^TY$:
> $$ X^TY = \begin{bmatrix} 1 & 2 & 3 & 4 & 5 \\ 2 & 3 & 4 & 5 & 6 \end{bmatrix} \begin{bmatrix} 5 \\ 8 \\ 11 \\ 14 \\ 17 \end{bmatrix} = \begin{bmatrix} 195 \\ 254 \end{bmatrix} $$
>
> Finalmente, calculamos $\hat{\beta}_{ML}$:
> $$ \hat{\beta}_{ML} = (X^TX)^{-1}X^TY = \begin{bmatrix} 1.8 & -1.4 \\ -1.4 & 1.1 \end{bmatrix} \begin{bmatrix} 195 \\ 254 \end{bmatrix} = \begin{bmatrix} 0.2 \\ 2.2 \end{bmatrix} $$
>
> A estimativa de m√°xima verossimilhan√ßa para os par√¢metros do modelo √© $\hat{\beta}_{ML} = \begin{bmatrix} 0.2 \\ 2.2 \end{bmatrix}$, e corresponde √† solu√ß√£o de m√≠nimos quadrados.
> Usando estes par√¢metros, o modelo linear estimado √©: $y = 0.2x_1 + 2.2x_2$.

**Conceito 2: Bayesian Inference**
A **infer√™ncia Bayesiana** incorpora um conhecimento *a priori* sobre os par√¢metros do modelo por meio de uma distribui√ß√£o *a priori* $Pr(\theta)$. A combina√ß√£o dessa distribui√ß√£o com a verossimilhan√ßa $Pr(Z|\theta)$ leva √† distribui√ß√£o *a posteriori* $Pr(\theta|Z)$, que √© dada por:

$$Pr(\theta|Z) = \frac{Pr(Z|\theta)Pr(\theta)}{\int Pr(Z|\theta)Pr(\theta)d\theta}$$ [^8.3]
```mermaid
graph LR
    subgraph "Bayesian Inference Components"
        direction TB
        A["Posterior Distribution: Pr(Œ∏|Z)"]
        B["Likelihood: Pr(Z|Œ∏)"]
        C["Prior Distribution: Pr(Œ∏)"]
        D["Marginal Likelihood: ‚à´ Pr(Z|Œ∏)Pr(Œ∏)dŒ∏"]
        A --> B
        A --> C
        B & C --> D
        B & C --> A
    end
```
Esta abordagem permite expressar incerteza sobre os par√¢metros do modelo, n√£o apenas por meio de um estimador pontual, mas atrav√©s de uma distribui√ß√£o. Al√©m disso, a infer√™ncia Bayesiana permite derivar uma distribui√ß√£o preditiva, o que √© especialmente √∫til quando se quer estimar a probabilidade de novas observa√ß√µes:

$$Pr(z_{new}|Z) = \int Pr(z_{new}|\theta)Pr(\theta|Z)d\theta$$ [^8.3]

A infer√™ncia Bayesiana, em contraste com o *maximum likelihood*, n√£o se limita a encontrar um √∫nico conjunto de par√¢metros que melhor se ajustem aos dados; ela busca descrever a probabilidade de cada valor do par√¢metro com base em dados observados e conhecimentos pr√©vios.

> üí° **Exemplo Num√©rico:**
> Suponha que queremos estimar a probabilidade de um evento (por exemplo, a probabilidade de uma moeda dar cara). Seja $\theta$ a probabilidade de sucesso (cara), e suponha que temos 10 lan√ßamentos da moeda, e observamos 7 caras (sucessos).
> * Abordagem de M√°xima Verossimilhan√ßa:
>   A estimativa de m√°xima verossimilhan√ßa para $\theta$ seria simplesmente a propor√ß√£o de sucessos:
>   $$ \hat{\theta}_{ML} = \frac{7}{10} = 0.7 $$
>   Esta √© uma estimativa pontual.
> * Abordagem Bayesiana:
>   Vamos usar uma distribui√ß√£o *a priori* Beta para $\theta$, que √© uma escolha comum para probabilidades:
>   $$ Pr(\theta) = \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} $$
>   onde $B(\alpha, \beta)$ √© a fun√ß√£o Beta. Vamos escolher um prior n√£o informativo, com $\alpha = 1$ e $\beta = 1$ (equivalente a uma distribui√ß√£o uniforme entre 0 e 1). A verossimilhan√ßa, assumindo independ√™ncia dos lan√ßamentos, √©:
>   $$ Pr(Z|\theta) = \theta^7(1-\theta)^3 $$
>   A distribui√ß√£o *a posteriori* √© proporcional ao produto do prior e da verossimilhan√ßa:
>   $$ Pr(\theta|Z) \propto \theta^7(1-\theta)^3 \cdot \theta^{1-1}(1-\theta)^{1-1} = \theta^7(1-\theta)^3 $$
>   Essa distribui√ß√£o *a posteriori* √© uma Beta com par√¢metros $\alpha' = 7 + 1 = 8$ e $\beta' = 3 + 1 = 4$. Ou seja, $Pr(\theta|Z) = Beta(8, 4)$.
>   Diferentemente da estimativa pontual de ML, a abordagem Bayesiana nos fornece uma distribui√ß√£o sobre $\theta$, que podemos usar para calcular intervalos de confian√ßa ou outras estat√≠sticas. Por exemplo, a m√©dia da distribui√ß√£o *a posteriori* √©:
>    $$E[\theta | Z] = \frac{\alpha'}{\alpha' + \beta'} = \frac{8}{8+4} = \frac{8}{12} \approx 0.667$$
>    E a vari√¢ncia:
>    $$Var[\theta | Z] = \frac{\alpha'\beta'}{(\alpha' + \beta')^2(\alpha' + \beta' + 1)} = \frac{8*4}{(12)^2(13)} \approx 0.017$$
> A abordagem Bayesiana fornece uma vis√£o mais completa da incerteza sobre $\theta$, em vez de um √∫nico valor.

**Corol√°rio 1:**
Sob certas condi√ß√µes, como o uso de um prior n√£o-informativo, a infer√™ncia Bayesiana pode levar a resultados que se assemelham aos do *maximum likelihood*, especialmente quando a quantidade de dados observados √© grande. A aproxima√ß√£o posterior se torna mais concentrada em torno da estimativa ML.

*Prova*:
Um prior n√£o-informativo (tamb√©m chamado de prior de refer√™ncia ou prior de Jeffreys) √© um prior que tem um efeito m√≠nimo sobre a infer√™ncia. Formalmente, se o prior $Pr(\theta)$ √© constante em rela√ß√£o a $\theta$, ent√£o a posterior √© proporcional √† verossimilhan√ßa:
$$Pr(\theta|Z) \propto Pr(Z|\theta) Pr(\theta) \propto Pr(Z|\theta)$$
Quando o n√∫mero de observa√ß√µes N tende ao infinito, a verossimilhan√ßa $Pr(Z|\theta)$ se torna cada vez mais concentrada em torno da estimativa de m√°xima verossimilhan√ßa $\hat{\theta}_{ML}$. Como o prior √© constante, a posterior tamb√©m se concentrar√° em $\hat{\theta}_{ML}$, ou seja, para grandes quantidades de dados, a escolha do prior tem um impacto menor, e as estimativas Bayesianas e de m√°xima verossimilhan√ßa convergem [^8.4]. $\blacksquare$

**Conceito 3: Bootstrap**
O m√©todo do **Bootstrap** √© uma t√©cnica computacional que permite avaliar a incerteza de um estimador, simulando amostras de dados a partir dos dados observados [^8.2.1]. No *bootstrap* n√£o param√©trico, amostras s√£o retiradas com reposi√ß√£o dos dados originais. Para cada amostra *bootstrap*, o estimador de interesse √© calculado, criando uma distribui√ß√£o amostral. Essa distribui√ß√£o permite obter intervalos de confian√ßa e avaliar a variabilidade do estimador [^8.2.1]. O *bootstrap* param√©trico usa a estimativa de m√°xima verossimilhan√ßa para gerar novas amostras a partir do modelo.

```mermaid
graph TB
    subgraph "Bootstrap Process"
        direction TB
        A["Original Data: Z"]
        B["Resampling with replacement: Z*"]
        C["Estimator Calculation on Z*: Œ∏ÃÇ*"]
        D["Distribution of Estimators:  {Œ∏ÃÇ‚ÇÅ*, Œ∏ÃÇ‚ÇÇ*,..., Œ∏ÃÇ‚Çô*}"]
        A --> B
        B --> C
        C --> D
    end
```

O *bootstrap* √© uma ferramenta vers√°til e pode ser aplicado em diversas situa√ß√µes onde a deriva√ß√£o anal√≠tica da distribui√ß√£o amostral √© complexa. Em particular, permite inferir a incerteza em modelos com adapta√ß√£o, como modelos onde os n√≥s de *B-splines* s√£o escolhidos via valida√ß√£o cruzada [^8.2.3].

> ‚ö†Ô∏è **Nota Importante:** O m√©todo do *bootstrap* pode ser usado tanto para avaliar a incerteza de um estimador quanto para melhorar sua qualidade, como no caso do *bagging*.
> ‚ùó **Ponto de Aten√ß√£o:** Em problemas de classifica√ß√£o, a abordagem de *bootstrap* de amostragem com reposi√ß√£o do conjunto de dados de treinamento pode levar a modelos que generalizam menos do que um modelo treinado com os dados originais.
> ‚úîÔ∏è **Destaque:** A conex√£o entre *bootstrap*, *maximum likelihood* e m√©todos Bayesianos fica evidente quando se usa o *bootstrap* param√©trico com um prior n√£o informativo, conforme demonstrado em [^8.4].

> üí° **Exemplo Num√©rico:**
> Vamos usar um exemplo para ilustrar o *bootstrap* n√£o param√©trico. Suponha que temos um conjunto de dados com 5 observa√ß√µes: $Z = \{2, 4, 5, 7, 8\}$. Nosso estimador de interesse √© a m√©dia amostral.
> 1. **Amostragem com Reposi√ß√£o:** Criamos v√°rias amostras *bootstrap* retirando elementos de $Z$ com reposi√ß√£o. Por exemplo, algumas amostras poderiam ser:
>    - $Z_1^* = \{2, 2, 5, 7, 8\}$
>    - $Z_2^* = \{4, 4, 5, 5, 8\}$
>    - $Z_3^* = \{2, 7, 7, 8, 8\}$
>    - ... e assim por diante.
> 2. **C√°lculo do Estimador:** Para cada amostra *bootstrap*, calculamos a m√©dia amostral.
>    - $\hat{\mu}_1^* = \frac{2+2+5+7+8}{5} = 4.8$
>    - $\hat{\mu}_2^* = \frac{4+4+5+5+8}{5} = 5.2$
>    - $\hat{\mu}_3^* = \frac{2+7+7+8+8}{5} = 6.4$
> 3. **Distribui√ß√£o Amostral:** Ap√≥s gerar muitas amostras *bootstrap* (por exemplo, 1000) e calcular suas m√©dias, obtemos uma distribui√ß√£o amostral das m√©dias *bootstrap*.
> 4. **Intervalos de Confian√ßa:** Podemos usar a distribui√ß√£o das m√©dias *bootstrap* para calcular um intervalo de confian√ßa. Por exemplo, um intervalo de confian√ßa de 95% pode ser obtido a partir dos percentis 2.5% e 97.5% da distribui√ß√£o amostral.
> ```python
> import numpy as np
>
> data = np.array([2, 4, 5, 7, 8])
> n_bootstrap_samples = 1000
> bootstrap_means = []
>
> for _ in range(n_bootstrap_samples):
>     bootstrap_sample = np.random.choice(data, size=len(data), replace=True)
>     bootstrap_mean = np.mean(bootstrap_sample)
>     bootstrap_means.append(bootstrap_mean)
>
> lower_percentile = np.percentile(bootstrap_means, 2.5)
> upper_percentile = np.percentile(bootstrap_means, 97.5)
>
> print(f"Intervalo de confian√ßa de 95% (bootstrap): [{lower_percentile:.2f}, {upper_percentile:.2f}]")
> ```
> Este exemplo demonstra como o *bootstrap* permite quantificar a incerteza do estimador (neste caso, a m√©dia) sem precisar de suposi√ß√µes sobre a distribui√ß√£o subjacente dos dados.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
<imagem: Um diagrama de fluxo complexo que ilustra o processo de regress√£o de indicadores para classifica√ß√£o, come√ßando com a codifica√ß√£o das classes e terminando com a avalia√ß√£o do modelo, incluindo as diferentes etapas de estimativa de par√¢metros e decis√£o de classes.>

A regress√£o linear com uma matriz de indicadores pode ser aplicada √† classifica√ß√£o, utilizando uma representa√ß√£o bin√°ria das classes. Cada classe √© codificada como um vetor bin√°rio onde uma entrada √© 1 e as demais s√£o 0. Uma regress√£o linear √© ent√£o aplicada a cada uma dessas entradas. As classes para novas observa√ß√µes s√£o preditas selecionando a classe com a maior sa√≠da do modelo de regress√£o linear [^8.2.1].

No entanto, essa abordagem tem suas limita√ß√µes. As estimativas de regress√£o linear podem extrapolar para fora do intervalo [0,1] e n√£o garantir que as estimativas sejam probabilidades v√°lidas. Al√©m disso, as suposi√ß√µes de normalidade e homocedasticidade do modelo linear podem n√£o ser v√°lidas para problemas de classifica√ß√£o. Contudo, em muitas situa√ß√µes, essa abordagem fornece um limite de decis√£o linear semelhante ao que seria obtido com *Linear Discriminant Analysis* (LDA), especialmente quando as classes est√£o bem separadas [^8.2.1], [^8.3].

**Lemma 2:**
A regress√£o de indicadores aplicada a um problema de classifica√ß√£o com duas classes resulta em uma fronteira de decis√£o linear, onde o classificador atribui uma observa√ß√£o √† classe com o maior valor de resposta do modelo linear.

*Prova*:
Seja $y_i \in \{0, 1\}$ a classe de cada observa√ß√£o $i$, e $x_i$ seus atributos. Considere o modelo linear $y_i = x_i^T \beta + \epsilon_i$. Para duas classes, $\beta$ √© um vetor de pesos e $\epsilon_i$ o termo de erro. Ao aplicar a regress√£o de indicadores, a fun√ß√£o de decis√£o √© dada por $\hat{y}_i = x_i^T \hat{\beta}$, onde $\hat{\beta}$ √© a estimativa dos par√¢metros do modelo obtida por m√≠nimos quadrados. Para classificar uma nova observa√ß√£o $x$, √© atribu√≠da a classe 1 se $\hat{y} \geq 0.5$ e a classe 0 caso contr√°rio, criando uma fronteira de decis√£o linear $x^T \hat{\beta} = 0.5$. Isso demonstra que a regress√£o de indicadores define um hiperplano de decis√£o linear no espa√ßo de atributos. $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Considere um problema de classifica√ß√£o bin√°ria com duas caracter√≠sticas ($x_1$ e $x_2$) e duas classes (0 e 1). Temos os seguintes dados:
>
> | $x_1$ | $x_2$ | Classe ($y$) |
> |-------|-------|-------------|
> | 1     | 1     | 0           |
> | 1     | 2     | 0           |
> | 2     | 1     | 1           |
> | 2     | 2     | 1           |
>
> Vamos usar a regress√£o de indicadores para construir um classificador linear. Criamos uma matriz de desenho $X$ e um vetor de indicadores $Y$:
> $$ X = \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 2 & 1 \\ 2 & 2 \end{bmatrix}, \quad Y = \begin{bmatrix} 0 \\ 0 \\ 1 \\ 1 \end{bmatrix} $$
>
> Calculamos os coeficientes $\hat{\beta}$ utilizando a f√≥rmula $\hat{\beta} = (X^TX)^{-1}X^TY$.
> Primeiro, calculamos $X^TX$:
> $$ X^TX = \begin{bmatrix} 1 & 1 & 2 & 2 \\ 1 & 2 & 1 & 2 \end{bmatrix} \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 2 & 1 \\ 2 & 2 \end{bmatrix} = \begin{bmatrix} 10 & 8 \\ 8 & 10 \end{bmatrix} $$
>
> Em seguida, calculamos $(X^TX)^{-1}$:
> $$ (X^TX)^{-1} = \frac{1}{100 - 64} \begin{bmatrix} 10 & -8 \\ -8 & 10 \end{bmatrix} = \frac{1}{36} \begin{bmatrix} 10 & -8 \\ -8 & 10 \end{bmatrix} = \begin{bmatrix} \frac{10}{36} & -\frac{8}{36} \\ -\frac{8}{36} & \frac{10}{36} \end{bmatrix} $$
>
> Calculamos $X^TY$:
> $$ X^TY = \begin{bmatrix} 1 & 1 & 2 & 2 \\ 1 & 2 & 1 & 2 \end{bmatrix} \begin{bmatrix} 0 \\ 0 \\ 1 \\ 1 \end{bmatrix} = \begin{bmatrix} 4 \\ 3 \end{bmatrix} $$
>
> Finalmente, calculamos $\hat{\beta}$:
> $$ \hat{\beta} = (X^TX)^{-1}X^TY = \begin{bmatrix} \frac{10}{36} & -\frac{8}{36} \\ -\frac{8}{36} & \frac{10}{36} \end{bmatrix} \begin{bmatrix} 4 \\ 3 \end{bmatrix} = \begin{bmatrix} \frac{40-24}{36} \\ \frac{-32+30}{36} \end{bmatrix} = \begin{bmatrix} \frac{16}{36} \\ -\frac{2}{36} \end{bmatrix} = \begin{bmatrix} 0.44 \\ -0.06 \end{bmatrix} $$
>
> O modelo linear √© dado por $\hat{y} = 0.44x_1 - 0.06x_2$. Para classificar uma nova observa√ß√£o $x = (1.5, 1.5)$, calculamos $\hat{y} = 0.44(1.5) - 0.06(1.5) = 0.66 - 0.09 = 0.57$. Como $\hat{y} > 0.5$, a observa√ß√£o seria classificada como classe 1. A fronteira de decis√£o linear seria dada por $0.44x_1 - 0.06x_2 = 0.5$.

**Corol√°rio 2:**
Em situa√ß√µes com mais de duas classes, a regress√£o de indicadores resulta em m√∫ltiplas fun√ß√µes lineares, uma para cada classe. A classifica√ß√£o √© obtida atribuindo cada observa√ß√£o √† classe correspondente √† fun√ß√£o linear com a maior resposta.

*Prova*:
Considere um problema com $K$ classes. Para cada classe $k$, definimos um vetor indicador $y_i^k$ que √© 1 se a observa√ß√£o $i$ pertence √† classe $k$ e 0 caso contr√°rio. Aplicamos regress√£o linear para cada classe $k$: $y_i^k = x_i^T\beta_k + \epsilon_i^k$. O modelo linear para a classe $k$ √© ent√£o $\hat{y}^k=x^T\hat{\beta}_k$, onde $\hat{\beta}_k$ √© a estimativa por m√≠nimos quadrados para a classe $k$. A nova observa√ß√£o $x$ ser√° classificada na classe $k$ se $\hat{y}^k > \hat{y}^j$ para todo $j \neq k$. Este procedimento define $K$ hiperplanos de decis√£o no espa√ßo de atributos, que juntos determinam as fronteiras de decis√£o entre todas as classes. $\blacksquare$

A regress√£o linear para classifica√ß√£o √© um m√©todo pr√°tico, mas deve ser usado com cautela, especialmente quando as classes n√£o s√£o bem separadas ou quando se precisa de estimativas de probabilidade bem calibradas [^8.2.1].

> ‚ÄúEm alguns cen√°rios, conforme apontado em [^8.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1].‚Äù
> ‚ÄúNo entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^8.2.1], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear.‚Äù

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem: Uma representa√ß√£o gr√°fica detalhada que ilustra como a regulariza√ß√£o L1 e L2 afetam os coeficientes de modelos de classifica√ß√£o, mostrando o efeito da esparsidade e a redu√ß√£o da complexidade do modelo. O diagrama deve mostrar a rela√ß√£o com outras abordagens de classifica√ß√£o.>
Para lidar com problemas de alta dimensionalidade e evitar *overfitting* em modelos de classifica√ß√£o, t√©cnicas de regulariza√ß√£o s√£o frequentemente empregadas [^8.4.4], [^8.5]. A regulariza√ß√£o adiciona um termo de penalidade √† fun√ß√£o de custo, que for√ßa o modelo a encontrar solu√ß√µes mais simples e evitar pesos excessivos nos par√¢metros do modelo.

A regulariza√ß√£o $L1$ (Lasso) adiciona uma penalidade proporcional ao valor absoluto dos pesos:

$$J(\beta) = \text{Loss}(\beta) + \lambda \sum_{j=1}^p |\beta_j|$$

A regulariza√ß√£o $L2$ (Ridge) adiciona uma penalidade proporcional ao quadrado dos pesos:

$$J(\beta) = \text{Loss}(\beta) + \lambda \sum_{j=1}^p \beta_j^2$$
[^8.4.4]

```mermaid
graph LR
    subgraph "Regularization Methods"
        direction TB
        A["Cost Function: J(Œ≤)"]
        B["Loss Function: Loss(Œ≤)"]
        C["L1 Regularization: Œª‚àë|Œ≤‚±º|"]
        D["L2 Regularization: Œª‚àëŒ≤‚±º¬≤"]
        A --> B
        A --> C
        A --> D
    end
```

A regulariza√ß√£o $L1$ tende a produzir solu√ß√µes esparsas, onde muitos pesos s√£o exatamente zero, realizando sele√ß√£o de vari√°veis. A regulariza√ß√£o $L2$ tende a reduzir os pesos dos par√¢metros sem zer√°-los, o que leva a modelos mais est√°veis. A escolha entre $L1$ e $L2$ ou uma combina√ß√£o das duas (Elastic Net) depende das caracter√≠sticas do problema [^8.5].

> üí° **Exemplo Num√©rico:**
> Vamos considerar um problema de classifica√ß√£o bin√°ria com duas caracter√≠sticas ($x_1$, $x_2$) e um termo de vi√©s. Usaremos a regress√£o log√≠stica como a fun√ß√£o de perda (Loss).
>
> Suponha que temos os seguintes dados:
>
> | $x_1$ | $x_2$ | Classe ($y$) |
> |-------|-------|-------------|
> | 1     | 1     | 0           |
> | 1     | 2     | 0           |
> | 2     | 1     | 1           |
> | 2     | 2     | 1           |
>
> **Regress√£o Log√≠stica sem Regulariza√ß√£o:** A fun√ß√£o de perda (Loss) para regress√£o log√≠stica √© dada por entropia cruzada:
>
>  $$ Loss(\beta) = -\frac{1}{N}\sum_{i=1}^N \left[y_i\log(\sigma(x_i^T\beta)) + (1-y_i)\log(1-\sigma(x_i^T\beta)) \right] $$
>
>  onde $\sigma$ √© a fun√ß√£o sigmoide.
>
>
>  **Regulariza√ß√£o L1 (Lasso):**
>  A fun√ß√£o de custo com regulariza√ß√£o L1 √©:
>
> $$J(\beta) = Loss(\beta) + \lambda (|\beta_1| + |\beta_2|)$$
>
>
>  Vamos assumir que ap√≥s o processo de otimiza√ß√£o, obtivemos os seguintes par√¢metros sem regulariza√ß√£o:
>
>  $\beta = \begin{bmatrix} -3 \\ 3 \\ 1\end{bmatrix}$
>
> onde  $\beta_0$ √© o termo de vi√©s. Vamos aplicar regulariza√ß√£o L1 com $\lambda=0.5$:
>
> $$J(\beta) = Loss(\beta) + 0.5 * (|-3| + |3|) = Loss(\beta) + 3$$
>
> A regulariza√ß√£o L1 for√ßaria alguns coeficientes a serem zero. Ap√≥s a otimiza√ß√£o com L1, podemos encontrar um novo conjunto de par√¢metros, por exemplo:
>
> $\beta = \begin{bmatrix} -1
