## Model Inference and Averaging: A Deep Dive into Complete Data Log-Likelihood
<imagem: Mapa mental abrangente conectando bootstrap, maximum likelihood, m√©todos Bayesianos, EM algorithm, bagging e bumping, com √™nfase na complete data log-likelihood>

### Introdu√ß√£o

Este cap√≠tulo aborda m√©todos avan√ßados para infer√™ncia e modelagem estat√≠stica, com foco em t√©cnicas de *maximum likelihood*, abordagens Bayesianas, *bootstrap* e m√©todos de agrega√ß√£o de modelos. A √™nfase central √© a compreens√£o da *complete data log-likelihood* e seu papel na otimiza√ß√£o de modelos. A classifica√ß√£o e an√°lise discriminante s√£o fundamentais para o aprendizado de m√°quina, e diversos m√©todos estat√≠sticos foram propostos para lidar com esses desafios [^8.1]. T√©cnicas como a minimiza√ß√£o da soma de quadrados para regress√£o e a minimiza√ß√£o da *cross-entropy* para classifica√ß√£o, s√£o, na verdade, casos especiais do m√©todo de *maximum likelihood* [^8.1]. O objetivo deste cap√≠tulo √© fornecer uma explora√ß√£o detalhada e avan√ßada dessas t√©cnicas, indo al√©m das abordagens convencionais. Exploraremos o *bootstrap* como ferramenta para quantificar incertezas, o m√©todo Bayesiano como uma alternativa para infer√™ncia, e tamb√©m m√©todos de combina√ß√£o de modelos (*model averaging*) como *bagging* e *bumping*, todos eles interconectados pela ideia da *complete data log-likelihood*.

### Conceitos Fundamentais

**Conceito 1: Maximum Likelihood Estimation (MLE)**

O m√©todo de **Maximum Likelihood Estimation (MLE)** √© uma abordagem fundamental para a estima√ß√£o de par√¢metros em modelos estat√≠sticos. A ideia central √© encontrar os valores dos par√¢metros que tornam os dados observados mais prov√°veis, dado o modelo estat√≠stico proposto. Isso √© feito maximizando a *likelihood function* [^8.1]. Formalmente, dado um conjunto de dados $Z = \{z_1, z_2, \ldots, z_N\}$, onde cada $z_i$ √© uma observa√ß√£o, e um modelo estat√≠stico com par√¢metros $\theta$, a *likelihood function* √© definida como:
$$L(\theta; Z) = \prod_{i=1}^{N} g_{\theta}(z_i)$$.
Aqui, $g_\theta(z_i)$ √© a fun√ß√£o de densidade de probabilidade (PDF) ou a fun√ß√£o de massa de probabilidade (PMF) da observa√ß√£o $z_i$ dado o par√¢metro $\theta$ [^8.2.2]. Na pr√°tica, √© mais conveniente trabalhar com o logaritmo da *likelihood*, conhecido como *log-likelihood*:
$$l(\theta; Z) = \sum_{i=1}^{N} \log(g_{\theta}(z_i))$$.
O objetivo do MLE √© encontrar o valor de $\theta = \hat{\theta}$ que maximiza essa fun√ß√£o. Os m√©todos de classifica√ß√£o e regress√£o discutidos anteriormente podem ser formulados como problemas de MLE, onde a fun√ß√£o de perda √© derivada da *log-likelihood* [^8.1].
```mermaid
graph LR
    subgraph "Maximum Likelihood Estimation (MLE)"
        direction TB
        A["Observed Data: Z = {z‚ÇÅ, z‚ÇÇ,..., z‚Çô}"]
        B["Model with Parameters: Œ∏"]
        C["Likelihood Function: L(Œ∏; Z) = ‚àè g_Œ∏(z·µ¢)"]
        D["Log-Likelihood: l(Œ∏; Z) = Œ£ log(g_Œ∏(z·µ¢))"]
        E["MLE Goal: Find Œ∏ÃÇ that maximizes l(Œ∏; Z)"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```
> üí° **Exemplo Num√©rico:** Suponha que temos um conjunto de dados com 3 observa√ß√µes de uma distribui√ß√£o normal com m√©dia $\mu$ e desvio padr√£o $\sigma = 1$: $Z = \{2, 3, 4\}$. Queremos estimar o par√¢metro $\mu$ usando MLE. A PDF de uma distribui√ß√£o normal √© $g_{\mu}(z_i) = \frac{1}{\sqrt{2\pi}}e^{-\frac{(z_i - \mu)^2}{2}}$. A *log-likelihood* √©:
>
> $$l(\mu; Z) = \sum_{i=1}^{3} \log\left(\frac{1}{\sqrt{2\pi}}e^{-\frac{(z_i - \mu)^2}{2}}\right) = - \frac{3}{2} \log(2\pi) - \frac{1}{2}\sum_{i=1}^{3} (z_i - \mu)^2$$
>
> Para maximizar $l(\mu; Z)$, minimizamos a soma dos quadrados: $\sum_{i=1}^{3} (z_i - \mu)^2$.  Calculando a derivada em rela√ß√£o a $\mu$ e igualando a zero, obtemos:
>
> $$ \frac{d}{d\mu} \sum_{i=1}^{3} (z_i - \mu)^2 = -2 \sum_{i=1}^{3} (z_i - \mu) = 0$$
> $$\Rightarrow \hat{\mu} = \frac{2 + 3 + 4}{3} = 3 $$
> Portanto, a estimativa de m√°xima verossimilhan√ßa para $\mu$ √© a m√©dia amostral, 3.
>
> ```python
> import numpy as np
> from scipy.stats import norm
>
> data = np.array([2, 3, 4])
> mu_mle = np.mean(data)
> print(f"MLE estimate of mu: {mu_mle}")
>
> def log_likelihood(mu, data):
>     return np.sum(norm.logpdf(data, loc=mu, scale=1))
>
> # Evaluate log-likelihood for a range of mu
> mu_values = np.linspace(0, 6, 100)
> log_lik_values = [log_likelihood(mu, data) for mu in mu_values]
>
> import matplotlib.pyplot as plt
> plt.plot(mu_values, log_lik_values)
> plt.xlabel("mu")
> plt.ylabel("Log-Likelihood")
> plt.title("Log-Likelihood Function")
> plt.scatter(mu_mle, log_likelihood(mu_mle, data), color='red', label = "MLE")
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
>
> O gr√°fico mostra que a *log-likelihood* √© maximizada quando $\mu$ √© igual √† m√©dia amostral, 3. Isso demonstra o conceito de MLE em um contexto num√©rico.

**Lemma 1:** O m√©todo de m√≠nimos quadrados para regress√£o linear √© um caso especial do Maximum Likelihood Estimation (MLE) quando os erros s√£o Gaussianos.

**Prova:**
Assumindo que o modelo de regress√£o linear √© dado por $y_i = \mu(x_i) + \epsilon_i$, onde $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$. A *likelihood function* para cada observa√ß√£o √© dada por
$g_{\theta}(y_i | x_i) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(y_i - \mu(x_i))^2}{2\sigma^2}}$, onde $\theta$ engloba os par√¢metros do modelo linear e $\sigma^2$. A *log-likelihood function* √©
$$l(\theta; Z) = \sum_{i=1}^N \left[ -\frac{1}{2}\log(2\pi\sigma^2) - \frac{(y_i - \mu(x_i))^2}{2\sigma^2} \right]$$.
Maximizar esta fun√ß√£o em rela√ß√£o aos par√¢metros $\mu(x_i)$ √© equivalente a minimizar $\sum_{i=1}^N (y_i - \mu(x_i))^2$, que √© a soma dos quadrados dos res√≠duos, base do m√©todo de m√≠nimos quadrados. $\blacksquare$
```mermaid
graph LR
    subgraph "Equivalence of Least Squares and MLE (Gaussian Errors)"
        direction TB
        A["Linear Regression Model: y·µ¢ = Œº(x·µ¢) + Œµ·µ¢,  Œµ·µ¢ ~ N(0, œÉ¬≤)"]
        B["Likelihood Function: g_Œ∏(y·µ¢|x·µ¢) = (1/‚àö(2œÄœÉ¬≤)) * exp(-(y·µ¢ - Œº(x·µ¢))¬≤ / (2œÉ¬≤))"]
        C["Log-Likelihood: l(Œ∏; Z) = Œ£ [-¬Ωlog(2œÄœÉ¬≤) - (y·µ¢ - Œº(x·µ¢))¬≤ / (2œÉ¬≤)]"]
        D["Maximizing Log-Likelihood is equivalent to minimizing Œ£(y·µ¢ - Œº(x·µ¢))¬≤"]
        E["Least Squares: Minimize Œ£(y·µ¢ - Œº(x·µ¢))¬≤"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o linear simples $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$ com erros $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$. Temos os seguintes dados: $X = [1, 2, 3, 4, 5]$ e $Y = [2, 4, 5, 4, 5]$. Vamos usar MLE para estimar os par√¢metros $\beta_0$ e $\beta_1$, assumindo $\sigma^2$ conhecido (para simplificar).
>
> A fun√ß√£o a ser maximizada √© a *log-likelihood*, que √© equivalente a minimizar a soma dos erros quadrados. Usaremos `numpy` para realizar este c√°lculo:
> ```python
> import numpy as np
>
> X = np.array([1, 2, 3, 4, 5])
> Y = np.array([2, 4, 5, 4, 5])
>
> # Add a column of ones to X for the intercept term
> X_matrix = np.vstack((np.ones(len(X)), X)).T
>
> # Calculate the least squares solution
> beta_hat = np.linalg.inv(X_matrix.T @ X_matrix) @ X_matrix.T @ Y
> print(f"Estimated intercept (beta_0): {beta_hat[0]:.2f}")
> print(f"Estimated slope (beta_1): {beta_hat[1]:.2f}")
>
> # Verify the error sum of squares calculation
> predicted_y = X_matrix @ beta_hat
> residuals = Y - predicted_y
> sum_squared_residuals = np.sum(residuals**2)
> print(f"Sum of squared residuals: {sum_squared_residuals:.2f}")
> ```
> Os resultados s√£o: $\hat{\beta}_0 = 2.2$ e $\hat{\beta}_1 = 0.6$. O erro quadr√°tico √© 2.8.  Este exemplo demonstra que minimizar a soma dos quadrados dos res√≠duos √© equivalente a maximizar a *log-likelihood* quando os erros s√£o Gaussianos. Este √© o fundamento da equival√™ncia entre m√≠nimos quadrados e MLE neste contexto.

**Conceito 2: Linear Discriminant Analysis (LDA)**

A **Linear Discriminant Analysis (LDA)** √© um m√©todo de classifica√ß√£o linear que busca encontrar um subespa√ßo que maximize a separa√ß√£o entre classes e minimize a variabilidade dentro das classes [^8.1]. O LDA assume que as classes seguem uma distribui√ß√£o normal multivariada com a mesma matriz de covari√¢ncia [^8.1]. Dado um conjunto de dados com $K$ classes, o LDA projeta os dados em um espa√ßo de menor dimens√£o, onde as classes est√£o o mais separadas poss√≠vel. As fun√ß√µes discriminantes lineares s√£o derivadas com base nas m√©dias e covari√¢ncias amostrais de cada classe [^8.1]. Formalmente, para cada classe $k$, a fun√ß√£o discriminante √© dada por:
$$\delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log\pi_k$$
onde $x$ √© um vetor de entrada, $\mu_k$ √© o vetor m√©dio da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum, e $\pi_k$ √© a probabilidade *a priori* da classe $k$ [^8.1]. O LDA assume que as matrizes de covari√¢ncia de todas as classes s√£o iguais, simplificando a an√°lise.
```mermaid
graph LR
    subgraph "Linear Discriminant Analysis (LDA)"
        direction TB
        A["Data with K Classes"]
        B["Assumption: Classes follow multivariate normal with common covariance matrix Œ£"]
        C["LDA Goal: Project data to maximize class separation, minimize intra-class variability"]
        D["Discriminant Function: Œ¥‚Çñ(x) = x·µÄŒ£‚Åª¬πŒº‚Çñ - ¬ΩŒº‚Çñ·µÄŒ£‚Åª¬πŒº‚Çñ + log(œÄ‚Çñ)"]
        E["x: Input Vector, Œº‚Çñ: Mean vector of class k, Œ£: Common Covariance Matrix, œÄ‚Çñ: Prior probability of class k"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

**Corol√°rio 1:** O LDA pode ser visto como um m√©todo de proje√ß√£o linear que maximiza a raz√£o de vari√¢ncia entre classes para vari√¢ncia dentro das classes.

**Prova:** A fun√ß√£o discriminante linear do LDA pode ser reescrita como uma proje√ß√£o no subespa√ßo gerado pela matriz de covari√¢ncia conjunta. Essa proje√ß√£o √© projetada para maximizar a separa√ß√£o entre as m√©dias das classes e minimizar a variabilidade interna das classes. Os autovetores da matriz de covari√¢ncia conjunta representam as dire√ß√µes de m√°xima variabilidade, e a proje√ß√£o no espa√ßo de menor dimens√£o busca encontrar um espa√ßo que maximize a vari√¢ncia entre as classes em rela√ß√£o √† vari√¢ncia dentro das classes [^8.1]. $\blacksquare$

> üí° **Exemplo Num√©rico:** Imagine um problema de classifica√ß√£o bin√°ria com duas classes. Temos as seguintes amostras: Classe 1: $X_1 = [[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]]$; Classe 2: $X_2 = [[8, 1], [9, 3], [11, 1], [9.5, 2], [10, 4], [6, 0]]$.  Vamos calcular as m√©dias de cada classe, a matriz de covari√¢ncia comum e, em seguida, aplicar LDA.
>
> ```python
> import numpy as np
> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
>
> # Dataset
> X1 = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])
> X2 = np.array([[8, 1], [9, 3], [11, 1], [9.5, 2], [10, 4], [6, 0]])
>
> X = np.concatenate((X1, X2), axis=0)
> y = np.array([0]*len(X1) + [1]*len(X2)) # Class labels
>
> # Fit LDA model
> lda = LinearDiscriminantAnalysis()
> lda.fit(X, y)
>
> # Means of each class
> mean1 = np.mean(X1, axis=0)
> mean2 = np.mean(X2, axis=0)
> print(f"Mean of Class 1: {mean1}")
> print(f"Mean of Class 2: {mean2}")
>
> # Common covariance matrix
> cov = lda.covariance_
> print(f"Common Covariance Matrix:\n {cov}")
>
> # Print decision boundary coefficients
> print(f"Coefficients of LDA decision boundary: {lda.coef_}")
> print(f"Intercept of LDA decision boundary: {lda.intercept_}")
>
> # Use the discriminant function to classify a new point
> new_point = np.array([[7, 5]])
> predicted_class = lda.predict(new_point)
> print(f"Predicted class for {new_point}: {predicted_class}")
> ```
> Este c√≥digo calcula as m√©dias de cada classe, a matriz de covari√¢ncia comum, os coeficientes da fronteira de decis√£o e usa a fun√ß√£o discriminante para classificar um novo ponto. O resultado mostra como o LDA usa essas informa√ß√µes para classificar.

**Conceito 3: Logistic Regression**

A **Logistic Regression** √© um m√©todo para modelar a probabilidade de um evento bin√°rio [^8.1]. Ao contr√°rio do LDA, que assume uma distribui√ß√£o gaussiana, a regress√£o log√≠stica usa uma fun√ß√£o log√≠stica (sigmoide) para mapear uma combina√ß√£o linear das vari√°veis de entrada para um intervalo de probabilidade entre 0 e 1 [^8.1]. Formalmente, a probabilidade de pertencer √† classe 1, dado um vetor de entrada $x$ √© dada por:
$$P(Y=1|x) = \frac{1}{1 + e^{-(\beta_0 + \beta^T x)}}$$,
onde $\beta_0$ √© o intercepto e $\beta$ s√£o os coeficientes que precisam ser estimados [^8.1]. A estimativa dos par√¢metros ($\beta_0$, $\beta$) √© realizada por maximiza√ß√£o da *log-likelihood* [^8.1]. A fun√ß√£o *log-likelihood* para um modelo de regress√£o log√≠stica √© dada por:
$$l(\beta; Z) = \sum_{i=1}^{N} \left[ y_i \log(p_i) + (1-y_i) \log(1-p_i) \right]$$,
onde $p_i$ √© a probabilidade estimada pelo modelo para a observa√ß√£o $i$.
```mermaid
graph LR
    subgraph "Logistic Regression Model"
      direction TB
      A["Input Vector: x"]
      B["Linear Combination: Œ≤‚ÇÄ + Œ≤·µÄx"]
      C["Sigmoid Function: P(Y=1|x) = 1 / (1 + exp(-(Œ≤‚ÇÄ + Œ≤·µÄx)))"]
      D["Log-Likelihood: l(Œ≤;Z) = Œ£ [y·µ¢log(p·µ¢) + (1-y·µ¢)log(1-p·µ¢)]"]
      E["Parameter Estimation: Maximize l(Œ≤;Z)"]
      A --> B
      B --> C
      C --> D
      D --> E
   end
```

> üí° **Exemplo Num√©rico:** Vamos usar um exemplo simples de regress√£o log√≠stica com duas vari√°veis preditoras. Temos os seguintes dados: $X = [[2, 3], [4, 5], [6, 7], [8, 9], [1, 1], [9, 2], [7, 1], [3, 6]]$ e as classes $Y = [0, 0, 0, 0, 1, 1, 1, 1]$. Usaremos Python para treinar o modelo e obter os par√¢metros.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
>
> X = np.array([[2, 3], [4, 5], [6, 7], [8, 9], [1, 1], [9, 2], [7, 1], [3, 6]])
> Y = np.array([0, 0, 0, 0, 1, 1, 1, 1])
>
> # Train the logistic regression model
> logreg = LogisticRegression(solver='liblinear')
> logreg.fit(X, Y)
>
> # Get the parameters
> beta_0 = logreg.intercept_
> beta = logreg.coef_
> print(f"Intercept (beta_0): {beta_0}")
> print(f"Coefficients (beta): {beta}")
>
> # Make a prediction
> new_point = np.array([[5, 5]])
> predicted_probability = logreg.predict_proba(new_point)
> predicted_class = logreg.predict(new_point)
> print(f"Predicted Probability for {new_point}: {predicted_probability}")
> print(f"Predicted Class for {new_point}: {predicted_class}")
> ```
>
> O c√≥digo acima mostra como o modelo de regress√£o log√≠stica √© ajustado e como podemos obter as probabilidades estimadas e a classe predita para um novo ponto de dados. Os par√¢metros $\beta_0$ e $\beta$ definem a fronteira de decis√£o.

> ‚ö†Ô∏è **Nota Importante**: A regress√£o log√≠stica estima a probabilidade de um evento, enquanto o LDA busca um hiperplano para separa√ß√£o de classes. **Refer√™ncia ao t√≥pico [^8.1]**.

> ‚ùó **Ponto de Aten√ß√£o**: Tanto o LDA quanto a regress√£o log√≠stica s√£o m√©todos lineares, mas diferem em suas suposi√ß√µes e abordagem de otimiza√ß√£o. **Conforme indicado em [^8.1]**.

> ‚úîÔ∏è **Destaque**: A *log-likelihood* √© a fun√ß√£o objetivo para ambos os modelos de regress√£o log√≠stica e MLE em geral. **Baseado no t√≥pico [^8.2.2]**.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
```mermaid
flowchart TD
  subgraph "Linear Regression for Classification"
    A["Encode Classes (Indicator Matrix)"] --> B["Estimate Coefficients using Least Squares"]
    B --> C["Apply Decision Rule (e.g., assign to class with largest output)"]
    C --> D["Compare with Probabilistic Methods (e.g., Logistic Regression)"]
  end
```
**Explica√ß√£o:** Este diagrama representa o fluxo do processo de regress√£o de indicadores e como ele se relaciona √† classifica√ß√£o, **conforme descrito nos t√≥picos [^8.1] e [^8.2.2]**.

A regress√£o linear pode ser utilizada para classifica√ß√£o atrav√©s da regress√£o de uma matriz indicadora [^8.1]. Em um problema de classifica√ß√£o com K classes, √© criada uma matriz $Y$ de tamanho $N \times K$, onde cada linha representa uma observa√ß√£o, e as colunas indicam a qual classe cada observa√ß√£o pertence (1 para a classe correta, 0 para as outras classes). Um modelo de regress√£o linear √© ent√£o ajustado para cada coluna da matriz, fornecendo coeficientes que podem ser usados para fazer a predi√ß√£o de classe [^8.1]. Em outras palavras, o modelo busca uma aproxima√ß√£o linear para a fun√ß√£o indicadora de cada classe. Para uma nova observa√ß√£o, a classe √© atribu√≠da com base na maior sa√≠da da regress√£o. No entanto, essa abordagem possui limita√ß√µes. Primeiro, a sa√≠da do modelo de regress√£o n√£o √© garantida de estar entre 0 e 1, como seria esperado para probabilidades. Segundo, essa abordagem pode ser menos precisa em cen√°rios onde as classes n√£o s√£o bem separadas por hiperplanos lineares [^8.1].

**Lemma 2:** A regress√£o linear em uma matriz indicadora para classifica√ß√£o pode, sob certas condi√ß√µes de ortogonalidade, levar √† mesma fun√ß√£o discriminante linear do LDA para duas classes.

**Prova:** Seja $Y$ a matriz indicadora com duas classes ($N \times 2$). A regress√£o linear busca $\hat{\beta} = (H^TH)^{-1}H^Ty$, onde $H$ √© a matriz de entrada. Se as classes forem balanceadas e as caracter√≠sticas forem ortogonais, a proje√ß√£o de cada classe na sa√≠da da regress√£o linear ser√° equivalente √† proje√ß√£o realizada pelo LDA. A regra de decis√£o (atribuir √† classe com maior valor) leva ao mesmo hiperplano de decis√£o nas condi√ß√µes de normalidade e homocedasticidade de LDA. $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria. Temos $X = [[1, 2], [2, 3], [3, 4], [4, 5], [1, 1], [2, 2], [3, 1], [4, 2]]$, e as classes s√£o $Y = [0, 0, 0, 0, 1, 1, 1, 1]$. Para usar regress√£o linear, codificamos Y como uma matriz indicadora. Se temos duas classes, basta usar uma coluna para indicar a classe 1 (0 indica classe 0).
>
> ```python
> import numpy as np
> from sklearn.linear_model import LinearRegression
>
> X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [1, 1], [2, 2], [3, 1], [4, 2]])
> Y = np.array([0, 0, 0, 0, 1, 1, 1, 1])
>
> # Add a column of ones to X for the intercept term
> X_matrix = np.vstack((np.ones(X.shape[0]), X.T)).T
>
> # Fit linear regression
> model = LinearRegression()
> model.fit(X_matrix, Y)
>
> # Get parameters
> beta_0 = model.intercept_
> beta = model.coef_[1:] # Ignore the intercept coefficient
> print(f"Intercept (beta_0): {beta_0}")
> print(f"Coefficients (beta): {beta}")
>
> # Predict
> new_point = np.array([[3, 3]])
> new_point_matrix = np.concatenate(([1], new_point[0]))
> predicted_value = model.predict(new_point_matrix.reshape(1,-1))
> print(f"Predicted Value for {new_point}: {predicted_value}")
>
> # Decision rule: assign the class with largest output value
> predicted_class = 1 if predicted_value > 0.5 else 0
> print(f"Predicted Class for {new_point}: {predicted_class}")
> ```
>
> Este c√≥digo demonstra como podemos utilizar regress√£o linear para classifica√ß√£o, mostrando os par√¢metros ajustados e a decis√£o de classifica√ß√£o para um novo ponto. Note que, neste caso, o valor previsto n√£o √© uma probabilidade, mas um valor que √© usado para tomar a decis√£o.

**Corol√°rio 2:** Em problemas de classifica√ß√£o bin√°ria, a regress√£o de indicadores pode ser simplificada para uma √∫nica regress√£o com uma resposta bin√°ria, onde a resposta da regress√£o pode ser mapeada para uma probabilidade atrav√©s de uma fun√ß√£o log√≠stica.

As limita√ß√µes da regress√£o de indicadores incluem a possibilidade de extrapola√ß√µes fora do intervalo \[0,1], e uma modelagem menos eficiente de probabilidades quando comparada √† regress√£o log√≠stica. Em cen√°rios onde a fronteira de decis√£o linear √© suficiente, a regress√£o de indicadores pode ser uma alternativa simples, mas em muitos casos, a regress√£o log√≠stica fornece resultados mais robustos e probabilidades mais bem calibradas [^8.1].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem: Mapa mental que conecta regulariza√ß√£o L1 e L2 com LDA e Logistic Regression, mostrando como a penaliza√ß√£o afeta as fronteiras de decis√£o e a complexidade do modelo>
A sele√ß√£o de vari√°veis e regulariza√ß√£o s√£o t√©cnicas essenciais para lidar com problemas de alta dimensionalidade e evitar *overfitting* em modelos de classifica√ß√£o [^8.1]. A regulariza√ß√£o adiciona termos de penalidade √† fun√ß√£o de custo (e.g., *log-likelihood*), controlando a complexidade do modelo [^8.2.2]. As penalidades L1 e L2 s√£o comumente utilizadas:
*   **Penalidade L1 (Lasso):** Adiciona a soma dos valores absolutos dos coeficientes ($\sum_j |\beta_j|$) √† fun√ß√£o de custo, promovendo esparsidade (isto √©, alguns coeficientes iguais a zero). Isso auxilia na sele√ß√£o de vari√°veis, excluindo aquelas menos relevantes [^8.5].
*   **Penalidade L2 (Ridge):** Adiciona a soma dos quadrados dos coeficientes ($\sum_j \beta_j^2$) √† fun√ß√£o de custo, reduzindo o tamanho dos coeficientes, e tamb√©m a complexidade do modelo e evitando *overfitting* [^8.5].

Em modelos log√≠sticos, essas penalidades s√£o adicionadas √† *log-likelihood*:
$$l_{\text{regularizada}}(\beta; Z) = l(\beta; Z) - \lambda_1 \sum_{j=1}^p |\beta_j| - \lambda_2 \sum_{j=1}^p \beta_j^2$$.
Onde $\lambda_1$ e $\lambda_2$ s√£o par√¢metros de regulariza√ß√£o que controlam a intensidade da penalidade.
```mermaid
graph LR
    subgraph "Regularized Logistic Regression"
        direction TB
        A["Original Log-Likelihood: l(Œ≤; Z)"]
        B["L1 Penalty (Lasso): Œª‚ÇÅ Œ£ |Œ≤‚±º|"]
        C["L2 Penalty (Ridge): Œª‚ÇÇ Œ£ Œ≤‚±º¬≤"]
        D["Regularized Log-Likelihood: l_regularized(Œ≤; Z) = l(Œ≤; Z) - Œª‚ÇÅ Œ£ |Œ≤‚±º| - Œª‚ÇÇ Œ£ Œ≤‚±º¬≤"]
        E["Œª‚ÇÅ, Œª‚ÇÇ: Regularization Parameters"]
        A --> D
        B --> D
        C --> D
         D --> E
     end
```

**Lemma 3:** A penaliza√ß√£o L1 em classifica√ß√£o log√≠stica promove a esparsidade dos coeficientes, levando a modelos mais interpret√°veis.

**Prova:** A penaliza√ß√£o L1 introduz um termo n√£o diferenci√°vel na fun√ß√£o de custo. Quando a fun√ß√£o √© otimizada, os coeficientes menos relevantes s√£o for√ßados a zero, promovendo a sele√ß√£o de vari√°veis. A regulariza√ß√£o L1 busca solu√ß√µes em cantos dos hiperplanos definidos pelos par√¢metros, concentrando massa de probabilidade em par√¢metros iguais a zero. Isso √© demonstrado pela deriva√ß√£o das condi√ß√µes de otimalidade, onde os gradientes em rela√ß√£o a cada par√¢metro mostram que valores pequenos s√£o for√ßados a zero por causa do termo $| \beta_j |$ [^8.5]. $\blacksquare$

> üí° **Exemplo Num√©rico:** Vamos utilizar regress√£o log√≠stica com penalidade L1 (Lasso). Temos o seguinte conjunto de dados: $X = [[1, 2, 3, 4], [2, 3, 4, 5], [3, 4, 5, 6], [4, 5, 6, 7], [1, 1, 1, 1], [2, 2, 2, 2], [3, 1, 2, 1], [4, 2, 3, 1]]$ e as classes $Y = [0, 0, 0, 0, 1, 1, 1, 1]$. Usaremos Python com `sklearn` para ajustar o modelo com diferentes valores de $\lambda_1$.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> import matplotlib.pyplot as plt
>
> X = np.array([[1, 2, 3, 4], [2, 3, 4, 5], [3, 4, 5, 6], [4, 5, 6, 7], [1, 1, 1, 1], [2, 2, 2, 2], [3, 1, 2, 1], [4, 2, 3, 1]])
> Y = np.array([0, 0, 0, 0, 1, 1, 1, 1])
>
> lambda_values = [0.1, 1, 10]
>
> # Table to display the results
> print("| Lambda | Coefficients    |")
> print("|--------|-----------------|")
>
> for lambda_val in lambda_values:
>     logreg_l1 = LogisticRegression(penalty='l1', C=1/lambda_val, solver='liblinear', random_state=42)
>     logreg_l1.fit(X, Y)
>     coefficients = logreg_l1.coef_[0]
>     print(f"| {lambda_val}    | {coefficients} |")
>
>
> # Demonstrate regularization effect on coefficient values
> from sklearn.preprocessing import StandardScaler
> X = StandardScaler().fit_transform(X)
> lambda_values = np.logspace(-3, 3, 10)
> coef_values = []
> for lambda_val in lambda_values:
>     logreg_l1 = LogisticRegression(penalty='l1', C=1/lambda_val, solver='liblinear', random_state=42)
>     logreg_l1.fit(X, Y)
>     coef_values.append(logreg_l1.coef_[0])
> coef_values = np.array(coef_values)
>
> # Visualize the regularization path
> plt.figure(figsize=(10, 6))
> for i in range(X.shape[1]):
>     plt.plot(lambda_values, coef_values[:,i], label=f"Feature {i+1}")
>
> plt.xscale('log')
> plt.xlabel('Lambda')
> plt.ylabel('Coefficient Value')
> plt.title('L1 Regularization Path')
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
>  O c√≥digo demonstra como diferentes valores de $\lambda_1$ (inverso do par√¢metro `C` em `sklearn`) afetam os coeficientes do modelo. A tabela mostra que para valores maiores de $\lambda_1$, os coeficientes tendem a ser menores, e alguns deles s√£o for√ßados a zero. O gr√°fico mostra a varia√ß√£o dos coeficientes em fun√ß√£o de $\lambda$. A visualiza√ß√£o da regulariza√ß√£o mostra a import√¢ncia de $\lambda$ no controle da complexidade do modelo.

**Corol√°rio 3:** A regulariza√ß√£o L1 ajuda a reduzir a complexidade do modelo, tornando-o mais generaliz√°vel e interpret√°vel.

A regulariza√ß√£o L1 e L2 pode ser combinada usando o *Elastic Net*, permitindo aproveitar as vantagens de ambas as abordagens [^8.5].

> ‚ö†Ô∏è **Ponto Crucial**: A combina√ß√£o de L1 e L2 (Elastic Net) oferece um m√©todo flex√≠vel para regulariza√ß√£o. **conforme discutido em [^8.5]**.

### Separating Hyperplanes e Perceptrons
A ideia de **Separating Hyperplanes** est√° relacionada √† busca por um hiperplano que divida o espa√ßo de caracter√≠sticas em regi√µes distintas correspondentes a diferentes classes [^8.1]. Um **hiperplano √≥timo** maximiza a margem de separa√ß√£o entre as classes. Essa formula√ß√£o leva a um problema de otimiza√ß√£o quadr√°tica que pode ser resolvido atrav√©s da formula√ß√£o dual de Wolfe, utilizando combina√ß√µes lineares de pontos de suporte [^8.1].
```mermaid
graph LR
    subgraph "Separating Hyperplanes"
      direction TB
      A["Feature Space"]
      B["Goal: Find a hyperplane that divides feature space into distinct class regions"]
      C["Optimal Hyperplane: Maximizes margin between classes"]
      D["Quadratic Optimization Problem (Wolfe Duality)"]
       E["Solution: Linear combinations of support vectors"]
       A --> B
       B --> C
       C --> D
       D --> E
    end
```
O **Perceptron**, por sua vez, √© um algoritmo de aprendizado online que busca iterativamente encontrar um hiperplano que separa as classes [^8.1]. O algoritmo ajusta seus par√¢metros em resposta a classifica√ß√µes erradas e converge para uma solu√ß√£o se as classes forem linearmente separ√°veis.

### Pergunta Te√≥rica Avan√ßada: Como a escolha da covari√¢ncia em m√©todos de classifica√ß√£o lineares influencia a forma da fronteira de decis√£o e o custo computacional?
**Resposta:**

Em m√©todos lineares como o LDA, a escolha