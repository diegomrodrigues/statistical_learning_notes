Okay, here's the text with added Mermaid diagrams as requested, focusing on enhancing the mathematical and statistical concepts.

## Model Inference and Averaging with Complete Data

```mermaid
graph LR
    subgraph "Statistical Inference Methods"
    direction TB
        A["Maximum Likelihood"]
        B["Bayesian Inference"]
        C["Bootstrap"]
        D["Averaging Methods"]
        A --> D
        B --> D
        C --> D
    end
```

### Introdu√ß√£o

Neste cap√≠tulo, exploraremos m√©todos avan√ßados para infer√™ncia e modelagem estat√≠stica, focando na an√°lise de *complete data*, ou seja, conjuntos de dados onde n√£o h√° valores faltantes ou latentes. Nos cap√≠tulos anteriores, a aprendizagem de modelos foi frequentemente realizada atrav√©s da minimiza√ß√£o de uma soma de quadrados para regress√£o ou da entropia cruzada para classifica√ß√£o [^8.1]. Esses m√©todos, como veremos, s√£o inst√¢ncias da abordagem de *maximum likelihood*. O objetivo deste cap√≠tulo √© fornecer uma exposi√ß√£o detalhada das t√©cnicas de maximum likelihood, juntamente com a metodologia Bayesiana para infer√™ncia. Abordaremos tamb√©m o *bootstrap*, explorando sua rela√ß√£o com *maximum likelihood* e m√©todos Bayesianos, e apresentaremos algumas t√©cnicas relacionadas √† modelagem por m√©dia e melhoria, incluindo m√©todos de comit√™, *bagging*, *stacking* e *bumping* [^8.1].

### Conceitos Fundamentais

**Conceito 1: O Problema de Infer√™ncia Estat√≠stica com Dados Completos:**
O problema fundamental de infer√™ncia estat√≠stica √©, dada uma amostra de dados, determinar quais modelos melhor representam o processo gerador desses dados [^8.1]. Em um cen√°rio de *complete data*, este processo √© mais direto, pois n√£o precisamos lidar com a incerteza adicional de valores faltantes. Em ess√™ncia, buscamos inferir os par√¢metros de um modelo estat√≠stico que melhor se ajustam aos dados observados. Frequentemente, esta busca √© formulada como um problema de otimiza√ß√£o, onde procuramos os par√¢metros que maximizam uma fun√ß√£o de verossimilhan√ßa ou minimizam um erro de ajuste espec√≠fico. Este processo envolve um *trade-off* entre **vi√©s** e **vari√¢ncia**, onde modelos mais complexos se ajustam melhor aos dados de treino (menor vi√©s) mas podem n√£o generalizar bem para novos dados (alta vari√¢ncia). Um exemplo pr√°tico seria a regress√£o linear para modelar a rela√ß√£o entre duas vari√°veis, onde os coeficientes da regress√£o s√£o os par√¢metros que buscamos inferir [^8.1].

> üí° **Exemplo Num√©rico:** Imagine que temos um dataset com as seguintes observa√ß√µes de uma vari√°vel independente $x$ e uma vari√°vel dependente $y$:
>
>   | $x$ | $y$ |
>   |-----|-----|
>   | 1   | 2   |
>   | 2   | 3   |
>   | 3   | 5   |
>   | 4   | 6   |
>   | 5   | 8   |
>
>   Podemos usar regress√£o linear para modelar a rela√ß√£o entre $x$ e $y$, buscando os par√¢metros $\beta_0$ (intercepto) e $\beta_1$ (inclina√ß√£o) do modelo $y = \beta_0 + \beta_1x$. Atrav√©s do m√©todo dos m√≠nimos quadrados, que √© um caso de m√°xima verossimilhan√ßa sob a suposi√ß√£o de erros normais, estimamos esses par√¢metros. O objetivo √© encontrar os valores de $\beta_0$ e $\beta_1$ que minimizam a soma dos quadrados dos res√≠duos, ou seja, a diferen√ßa entre os valores observados de $y$ e os valores preditos pelo modelo.  Para esse exemplo, podemos calcular:
>
> ```python
> import numpy as np
> from sklearn.linear_model import LinearRegression
>
> x = np.array([[1], [2], [3], [4], [5]])
> y = np.array([2, 3, 5, 6, 8])
>
> model = LinearRegression()
> model.fit(x, y)
>
> beta_1 = model.coef_[0]
> beta_0 = model.intercept_
>
> print(f"Estimated beta_1 (slope): {beta_1:.2f}")
> print(f"Estimated beta_0 (intercept): {beta_0:.2f}")
> ```
>
>  O resultado do c√≥digo acima nos d√° $\beta_1 \approx 1.5$ e $\beta_0 \approx 0.5$. Isso significa que para cada aumento de uma unidade em $x$, esperamos que $y$ aumente em aproximadamente 1.5 unidades, e que quando $x$ √© 0, o valor esperado de $y$ √© 0.5. Este √© um exemplo de como a infer√™ncia estat√≠stica, atrav√©s da regress√£o linear, nos permite entender a rela√ß√£o entre vari√°veis. O objetivo √© escolher um modelo que balanceie bem o vi√©s e a vari√¢ncia. Um modelo que se ajusta perfeitamente aos dados de treinamento (alto vi√©s) pode n√£o generalizar para novos dados (alta vari√¢ncia).

```mermaid
graph LR
    subgraph "Bias-Variance Tradeoff"
        direction LR
        A["Model Complexity"]
        B["Bias"]
        C["Variance"]
        A --> B
        A --> C
        B --"Decreases with complexity"-->D["Good fit on training data"]
        C --"Increases with complexity"--> E["Poor generalization on new data"]
        D-->F["Trade-off is balanced to get best prediction"]
        E-->F

    end
```

**Lemma 1:** *A estimativa de m√≠nimos quadrados para regress√£o linear √© uma solu√ß√£o de m√°xima verossimilhan√ßa sob a suposi√ß√£o de que os erros do modelo seguem uma distribui√ß√£o normal com m√©dia zero*.

**Prova:**
Considere um modelo de regress√£o linear $y_i = \mathbf{x}_i^T\boldsymbol{\beta} + \epsilon_i$, onde $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$. A fun√ß√£o de verossimilhan√ßa √© dada por:
$$
L(\boldsymbol{\beta}, \sigma^2 | \mathbf{y}, \mathbf{X}) = \prod_{i=1}^{N} \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left( -\frac{(y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2}{2\sigma^2} \right)
$$
Tomando o logaritmo da verossimilhan√ßa:
$$
\ell(\boldsymbol{\beta}, \sigma^2 | \mathbf{y}, \mathbf{X}) = -\frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{N}(y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2
$$
Maximizar a verossimilhan√ßa √© equivalente a minimizar a soma dos quadrados dos erros, $\sum_{i=1}^{N}(y_i - \mathbf{x}_i^T\boldsymbol{\beta})^2$, resultando na solu√ß√£o de m√≠nimos quadrados $\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}$. Portanto, a estimativa de m√≠nimos quadrados √© tamb√©m a estimativa de m√°xima verossimilhan√ßa sob a suposi√ß√£o de erros Gaussianos. $\blacksquare$
```mermaid
graph LR
    subgraph "Maximum Likelihood Derivation"
        direction TB
        A["Likelihood Function: L(Œ≤, œÉ¬≤ | y, X)"]
        B["Log-Likelihood Function: ‚Ñì(Œ≤, œÉ¬≤ | y, X)"]
        C["Minimizing Sum of Squared Errors: ‚àë(y·µ¢ - x·µ¢·µÄŒ≤)¬≤"]
        D["Least Squares Estimator: Œ≤ÃÇ = (X·µÄX)‚Åª¬πX·µÄy"]
        A --> B
        B --> C
        C --> D
    end
```

**Conceito 2: Linear Discriminant Analysis (LDA):**
A LDA √© um m√©todo de classifica√ß√£o que busca encontrar uma combina√ß√£o linear de features que melhor separe as classes, ou seja, projeta os dados em um subespa√ßo onde a separa√ß√£o entre classes √© maximizada [^8.3]. Assume que os dados dentro de cada classe seguem uma distribui√ß√£o normal com a mesma matriz de covari√¢ncia, mas com m√©dias diferentes [^8.3]. A fronteira de decis√£o entre duas classes √© linear, e √© determinada pela diferen√ßa entre as m√©dias e pela matriz de covari√¢ncia comum das classes [^8.3.1], [^8.3.2], [^8.3.3]. A LDA √© √∫til para redu√ß√£o de dimensionalidade e classifica√ß√£o, oferecendo uma forma eficiente de lidar com problemas de classifica√ß√£o multi-classes, mesmo quando as features s√£o altamente correlacionadas.

> üí° **Exemplo Num√©rico:** Imagine um problema de classifica√ß√£o com duas classes (A e B) e duas features ($x_1$ e $x_2$). Temos as seguintes m√©dias e matriz de covari√¢ncia (considerando que as covari√¢ncias s√£o iguais entre as classes):
>
>  * M√©dia da Classe A: $\mu_A = [1, 2]$
>  * M√©dia da Classe B: $\mu_B = [3, 4]$
>  * Matriz de covari√¢ncia comum: $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
>
>  A LDA projetar√° os dados em uma linha que maximiza a separa√ß√£o entre as classes A e B, considerando as m√©dias e a matriz de covari√¢ncia comum.  A dire√ß√£o desta linha √© dada pelo autovetor correspondente ao maior autovalor da matriz $\Sigma^{-1}(\mu_B - \mu_A)(\mu_B - \mu_A)^T$. O resultado dessa proje√ß√£o linear ser√° uma nova representa√ß√£o dos dados em uma dimens√£o, com as classes o mais separadas poss√≠vel. Se tivermos um novo ponto, por exemplo, $x=[2,3]$, podemos projetar ele nesta dimens√£o e classificar com base na proje√ß√£o.
>
>  ```python
>  import numpy as np
>  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
>
>  X = np.array([[1, 2], [1.5, 2.5], [2, 1.8], [3, 4], [3.5, 4.5], [4, 3.8]])
>  y = np.array([0, 0, 0, 1, 1, 1])  # 0 for class A, 1 for class B
>
>  lda = LinearDiscriminantAnalysis()
>  lda.fit(X, y)
>  new_point = np.array([[2, 3]])
>  predicted_class = lda.predict(new_point)
>  print(f"Predicted class for [2, 3]: {predicted_class[0]}")
>  ```
>
>  Este c√≥digo mostra um exemplo simples de como a LDA pode ser usada para classifica√ß√£o. No exemplo acima, o ponto [2, 3] ser√° classificado de acordo com a proje√ß√£o obtida. A LDA √© √∫til quando h√° muitas features e deseja-se reduzir a dimensionalidade enquanto mant√©m a separa√ß√£o entre as classes.

```mermaid
graph LR
    subgraph "LDA Process"
        direction TB
    A["Data with multiple classes and features"]
    B["Calculate Class Means (Œº‚Çñ)"]
    C["Calculate Common Covariance Matrix (Œ£)"]
    D["Project data onto a line"]
    E["Maximize separation between classes using (Œº_B - Œº_A)"]
    F["Classify new data point"]
    A --> B
    A --> C
    B & C --> E
    E --> D
    D --> F
    end
```

**Corol√°rio 1:** *Sob a hip√≥tese de que as classes seguem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia, a fronteira de decis√£o da LDA corresponde a uma proje√ß√£o linear dos dados que maximiza a separabilidade das classes*.
Essa proje√ß√£o pode ser entendida como uma dire√ß√£o no espa√ßo de features onde a variabilidade entre as m√©dias das classes √© maximizada em rela√ß√£o √† variabilidade dentro das classes [^8.3.1].

**Conceito 3: Logistic Regression:**
A Regress√£o Log√≠stica √© um modelo de classifica√ß√£o probabil√≠stica que modela a probabilidade de um evento ocorrer utilizando uma fun√ß√£o log√≠stica. Em vez de modelar a vari√°vel resposta diretamente, ela modela o *log-odds* da probabilidade de uma classe [^8.4]. A probabilidade de um evento √© dada pela fun√ß√£o sigmoide aplicada a uma combina√ß√£o linear das features [^8.4.1]. Os par√¢metros do modelo s√£o estimados utilizando o m√©todo de *maximum likelihood*, que busca maximizar a verossimilhan√ßa dos dados observados [^8.4.2]. A Regress√£o Log√≠stica √© amplamente utilizada para problemas de classifica√ß√£o bin√°ria, embora possa ser estendida para problemas multiclasses utilizando abordagens como *one-vs-all* ou *softmax regression* [^8.4.3], [^8.4.4], [^8.4.5].

> üí° **Exemplo Num√©rico:**  Suponha que queremos modelar a probabilidade de um cliente comprar um produto com base em seu hist√≥rico de compras ($x$). Temos um conjunto de dados com clientes que compraram (y=1) e n√£o compraram (y=0). Os dados s√£o:
>
>   | $x$ (Hist√≥rico) | $y$ (Compra) |
>   |-----------------|--------------|
>   | 1               | 0            |
>   | 2               | 0            |
>   | 3               | 1            |
>   | 4               | 1            |
>   | 5               | 1            |
>
>  O modelo de regress√£o log√≠stica √© dado por: $P(y=1|x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x)}}$. Os par√¢metros $\beta_0$ e $\beta_1$ s√£o estimados por m√°xima verossimilhan√ßa. Ap√≥s o treinamento, digamos que obtivemos os seguintes coeficientes: $\beta_0 = -3$ e $\beta_1 = 1$. Para um novo cliente com hist√≥rico $x = 3.5$, a probabilidade de comprar o produto √©:
>
>  $P(y=1|x=3.5) = \frac{1}{1 + e^{-(-3 + 1 \times 3.5)}} = \frac{1}{1 + e^{-0.5}} \approx 0.62$.
>
>  Isso significa que, dado o hist√≥rico de 3.5, o cliente tem uma probabilidade de aproximadamente 62% de comprar o produto.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
>
> X = np.array([[1], [2], [3], [4], [5]])
> y = np.array([0, 0, 1, 1, 1])
>
> model = LogisticRegression()
> model.fit(X, y)
>
> beta_0 = model.intercept_[0]
> beta_1 = model.coef_[0][0]
>
> new_x = np.array([[3.5]])
> probability = model.predict_proba(new_x)[0][1]
>
> print(f"Estimated beta_0 (intercept): {beta_0:.2f}")
> print(f"Estimated beta_1 (slope): {beta_1:.2f}")
> print(f"Predicted probability for x=3.5: {probability:.2f}")
> ```
>
> O c√≥digo mostra o ajuste da regress√£o log√≠stica aos dados de exemplo e a previs√£o da probabilidade para um novo ponto.

```mermaid
graph LR
    subgraph "Logistic Regression Model"
        direction TB
        A["Input Features (x)"]
        B["Linear Combination: Œ≤‚ÇÄ + Œ≤‚ÇÅx"]
        C["Sigmoid Function: œÉ(z) = 1 / (1 + e‚Åª·∂ª)"]
        D["Predicted Probability: P(y=1|x)"]
        A --> B
        B --> C
        C --> D
    end
```

> ‚ö†Ô∏è **Nota Importante**: A Regress√£o Log√≠stica √© um modelo linear no espa√ßo do log-odds, o que implica que a fronteira de decis√£o no espa√ßo original das features √© linear.
> ‚ùó **Ponto de Aten√ß√£o**: Em problemas de classifica√ß√£o com classes n√£o balanceadas, a Regress√£o Log√≠stica pode precisar de t√©cnicas de amostragem ou pondera√ß√£o para evitar vi√©s em dire√ß√£o √† classe majorit√°ria.
> ‚úîÔ∏è **Destaque**: Tanto a LDA quanto a regress√£o log√≠stica podem ser consideradas modelos lineares com base em seus fundamentos. A LDA assume normalidade e covari√¢ncias iguais, enquanto a regress√£o log√≠stica se baseia em um modelo log√≠stico, ajustando os par√¢metros por meio da maximiza√ß√£o da verossimilhan√ßa.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction LR
        A["Encode Classes with Indicator Matrix"]
        B["Estimate Coefficients using Least Squares"]
        C["Apply Decision Rule"]
        D["Compare with probabilistic methods"]
        A --> B
        B --> C
        C --> D

    end
```

**Explica√ß√£o:** O diagrama acima ilustra o flow of using indicator matrices in Linear Regression for classification.

Uma abordagem para realizar classifica√ß√£o utilizando regress√£o linear √© empregar uma matriz de indicadores para representar as classes. Nessa abordagem, cada classe √© codificada como um vetor bin√°rio, onde um √∫nico elemento √© igual a 1 (indicando a classe correspondente) e todos os outros elementos s√£o iguais a 0. Em seguida, um modelo de regress√£o linear √© ajustado para prever a classe a partir das features. Ap√≥s o ajuste, a classe prevista √© determinada pela maior sa√≠da do modelo. Esta abordagem, apesar de intuitiva, tem suas limita√ß√µes, pois as sa√≠das da regress√£o linear n√£o s√£o necessariamente probabilidades v√°lidas e podem at√© extrapolar fora do intervalo [0,1] [^8.1], [^8.2]. Al√©m disso, a regress√£o linear n√£o considera as suposi√ß√µes de distribui√ß√£o dos dados, e pode ser sens√≠vel a outliers e problemas de multicolinearidade [^8.3].

> üí° **Exemplo Num√©rico:** Imagine um problema de classifica√ß√£o com tr√™s classes (A, B e C). Usando regress√£o de indicadores, criamos uma matriz de indicadores da seguinte forma:
>
>   * Classe A:  [1, 0, 0]
>   * Classe B:  [0, 1, 0]
>   * Classe C:  [0, 0, 1]
>
>   Para um dataset com duas features ($x_1$ e $x_2$) e tr√™s classes, cada amostra √© representada por $(x_1, x_2, y)$, onde $y$ √© o vetor indicador da classe. A regress√£o linear tentar√° prever os tr√™s valores do vetor indicador a partir das features. Suponha que ap√≥s ajustar o modelo, para uma nova amostra com features $x = [2, 3]$, o modelo preveja o seguinte vetor: $\hat{y} = [0.2, 0.7, 0.1]$.  Neste caso, a classe prevista seria a Classe B, pois corresponde ao maior valor previsto. No entanto, os valores previstos n√£o somam 1 e n√£o est√£o no intervalo [0, 1], mostrando as limita√ß√µes da regress√£o linear para classifica√ß√£o.

**Lemma 2:** *Em problemas de classifica√ß√£o bin√°ria, com classes representadas por valores 0 e 1, a regress√£o linear da matriz de indicadores pode levar a hiperplanos de decis√£o que s√£o equivalentes aos obtidos pela LDA em certas condi√ß√µes.*

**Prova:**
Considere um problema de classifica√ß√£o bin√°ria com classes 0 e 1. A regress√£o linear para a matriz de indicadores neste caso se torna uma regress√£o simples onde a sa√≠da √© a classe. A fun√ß√£o discriminante linear gerada pela regress√£o pode ser escrita como $\hat{y}(x) = \beta_0 + \beta^Tx$. Se assumirmos que a LDA tamb√©m tem uma fun√ß√£o discriminante linear da forma $\delta(x) = w_0 + w^Tx$, para que as proje√ß√µes da regress√£o e LDA sejam equivalentes em alguns casos, os vetores $\beta$ e $w$ devem ser proporcionales, e os limiares devem estar na mesma posi√ß√£o. Essa equival√™ncia ocorre quando as classes s√£o bem separadas e as amostras podem ser bem representadas por suas m√©dias.  $\blacksquare$

```mermaid
graph LR
    subgraph "Linear Decision Boundaries"
        direction LR
        A["Linear Regression with Indicator Matrix"] --> B["Decision Hyperplane: yÃÇ(x) = Œ≤‚ÇÄ + Œ≤·µÄx"]
        C["LDA"] --> D["Decision Hyperplane: Œ¥(x) = w‚ÇÄ + w·µÄx"]
        B --> E["Equivalence when Œ≤ and w are proportional"]
        D --> E
    end
```

**Corol√°rio 2:** *A equival√™ncia entre as proje√ß√µes nos hiperplanos de decis√£o gerados por regress√£o linear e discriminantes lineares, sob certas condi√ß√µes, simplifica a an√°lise do modelo e permite aplicar resultados te√≥ricos de um para o outro, facilitando a interpreta√ß√£o das decis√µes da classifica√ß√£o*. Isso √© particularmente √∫til para entender como as features influenciam as decis√µes de classifica√ß√£o, tanto pela regress√£o linear quanto pela LDA,  mostrando que, em algumas situa√ß√µes, os modelos se comportam de maneira similar, mas tamb√©m expondo as suas diferen√ßas [^8.3].

Em alguns cen√°rios, a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1]. No entanto, h√° situa√ß√µes em que a regress√£o de indicadores √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["Logistic Regression Model"]
        B["L1 Regularization (Lasso)"]
        C["L2 Regularization (Ridge)"]
        D["Elastic Net Regularization"]
        A --> B
        A --> C
        A --> D
        B --> E["Sparsity, Feature Selection"]
        C --> F["Stability, Reduced Complexity"]
        D --> G["Combination of L1 and L2"]
    end
```

**Explica√ß√£o:** The above diagram illustrates the application of L1, L2 and Elastic Net regularization on a logistic classification model.

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas importantes para melhorar o desempenho e a generaliza√ß√£o de modelos de classifica√ß√£o. A sele√ß√£o de vari√°veis visa identificar as features mais relevantes para o modelo, descartando as features irrelevantes ou redundantes. A regulariza√ß√£o, por outro lado, adiciona um termo de penaliza√ß√£o √† fun√ß√£o de custo do modelo, a fim de restringir a magnitude dos coeficientes e evitar o sobreajuste [^8.4.4], [^8.5]. Em particular, a Regress√£o Log√≠stica com penaliza√ß√µes L1 e L2 pode controlar a *sparsity* (n√∫mero de coeficientes zero) e a estabilidade do modelo. A penaliza√ß√£o L1 (Lasso) tende a gerar modelos com muitos coeficientes exatamente iguais a zero, realizando sele√ß√£o de vari√°veis, enquanto a penaliza√ß√£o L2 (Ridge) tende a reduzir a magnitude dos coeficientes sem zer√°-los, melhorando a estabilidade do modelo. Combinando penaliza√ß√µes L1 e L2, obt√©m-se a regulariza√ß√£o *Elastic Net* [^8.4.4], [^8.5], [^8.5.1], [^8.5.2].

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o log√≠stica com duas features ($x_1$ e $x_2$) e regulariza√ß√£o. A fun√ß√£o de custo regularizada com penaliza√ß√£o L1 √©:
>
> $J(\boldsymbol{\beta}) = -\frac{1}{N}\sum_{i=1}^N [y_i \log(\sigma(\mathbf{x}_i^T \boldsymbol{\beta})) + (1-y_i) \log(1-\sigma(\mathbf{x}_i^T \boldsymbol{\beta}))] + \lambda (|\beta_1| + |\beta_2|)$
>
> Onde $\lambda$ √© o par√¢metro de regulariza√ß√£o. Se $\lambda=0.1$, e ap√≥s o treinamento do modelo, obtivemos $\beta_1 = 0.8$ e $\beta_2 = -0.5$, aplicando a penaliza√ß√£o L1 na fun√ß√£o de custo, tendemos a reduzir $\beta_1$ e $\beta_2$. Se aumentarmos $\lambda$ para 1.0, a penalidade L1 se torna mais forte, e o modelo pode levar a um dos coeficientes, digamos $\beta_2$, para 0, resultando em um modelo com apenas a feature $x_1$.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.preprocessing import StandardScaler
> from sklearn.pipeline import Pipeline
>
> X = np.array([[1, 2], [1.5, 2.5], [2, 1.8], [3, 4], [3.5, 4.5], [4, 3.8]])
> y = np.array([0, 0, 0, 1, 1, 1])
>
> # L1 Regularization
> pipeline_l1 = Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression(penalty='l1', solver='liblinear', C=1.0))]) # C = 1/lambda
> pipeline_l1.fit(X, y)
> print(f"L1 Regularization Coefficients: {pipeline_l1['model'].coef_[0]}")
>
> # L2 Regularization
> pipeline_l2 = Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression(penalty='l2', C=1.0))])
> pipeline_l2.fit(X, y)
> print(f"L2 Regularization Coefficients: {pipeline_l2['model'].coef_[0]}")
>
> # Elastic Net
> pipeline_en = Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, C=1.0))]) # l1_ratio controls the mix of L1 and L2
> pipeline_en.fit(X, y)
> print(f"Elastic Net Coefficients: {pipeline_en['model'].coef_[0]}")
> ```
>
>  O c√≥digo ilustra como as penaliza√ß√µes L1, L2 e Elastic Net afetam os coeficientes do modelo. Podemos ver como L1 pode levar alguns coeficientes a zero, realizando a sele√ß√£o de vari√°veis.

**Lemma 3:** *A penaliza√ß√£o L1 na regress√£o log√≠stica leva a coeficientes esparsos devido √† natureza da fun√ß√£o de penalidade, que imp√µe um custo adicional proporcional √† soma dos valores absolutos dos coeficientes.*

**Prova:**
A fun√ß√£o de custo regularizada para regress√£o log√≠stica com penaliza√ß√£o L1 √© dada por:
$$
J(\boldsymbol{\beta}) = -\frac{1}{N}\sum_{i=1}^N [y_i \log(\sigma(\mathbf{x}_i^T \boldsymbol{\beta})) + (1-y_i) \log(1-\sigma(\mathbf{x}_i^T \boldsymbol{\beta}))] + \lambda \sum_{j=1}^p |\beta_j|
$$
onde $\sigma$ √© a fun√ß√£o log√≠stica, $\lambda$ √© o par√¢metro de regulariza√ß√£o, e $\sum_{j=1}^p |\beta_j|$ √© a penaliza√ß√£o L1. A derivada do termo de penaliza√ß√£o $\lambda \sum_{j=1}^p |\beta_j|$ em rela√ß√£o a $\beta_j$ √© $\lambda \cdot \text{sign}(\beta_j)$, que √© constante para $\beta_j > 0$ e $\beta_j < 0$, e uma subderivada em $\beta_j = 0$. Esse comportamento da penalidade L1 leva a solu√ß√µes com muitos $\beta_j$ exatamente iguais a zero, induzindo *sparsity*. A otimiza√ß√£o de $J(\boldsymbol{\beta})$ leva a coeficientes esparsos. $\blacksquare$

```mermaid
graph LR
    subgraph "L1 Regularization and Sparsity"
        direction TB
        A["Cost Function with L1 Penalty: J(Œ≤)"]
        B["L1 Penalty Term: Œª‚àë|Œ≤‚±º|"]
        C["Derivative of Penalty: Œª¬∑sign(Œ≤‚±º)"]
        D["Sparse Coefficients (many Œ≤‚±º = 0)"]
        A --> B
        B --> C
        C --> D
    end
```

**Corol√°rio 3:** *A esparsidade induzida pela penaliza√ß√£o L1 resulta em modelos mais interpret√°veis e com melhor capacidade de generaliza√ß√£o, uma vez que reduz a complexidade do modelo e foca apenas nas features mais relevantes*. Isso √© particularmente √∫til em problemas com grande n√∫mero de features, onde a identifica√ß√£o das features mais importantes √© crucial [^8.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: L1 e L2 podem ser combinadas (Elastic Net) para aproveitar vantagens de ambos os tipos de regulariza√ß√£o, controlando *sparsity* e estabilidade simultaneamente.

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Separating Hyperplanes"
        direction TB
        A["Input Data"]
        B["LDA"]
        C["Logistic Regression"]
        D["Optimal Separating Hyperplane"]
        E["Maximizing Margin"]
        F["Support Vectors"]
        A --> B
        A --> C
        A --> D
        D --> E
        E --> F
    end
```

**Explica√ß√£o:** The diagram illustrates different techniques to obtain separating hyperplanes, such as LDA, logistic regression and maximum margin approaches.

A ideia de maximizar a margem de separa√ß√£o entre as classes leva ao conceito de hiperplanos √≥timos para classifica√ß√£o. Um hiperplano √© um subespa√ßo linear de dimens√£o *p-1* em um espa√ßo de *p* dimens√µes, que pode ser usado para separar os dados em diferentes classes [^8.5.2]. Um hiperplano √≥timo √© aquele que maximiza a dist√¢ncia m√≠nima entre o hiperplano e os pontos de dados mais pr√≥ximos de cada classe, tamb√©m conhecidos como *support vectors*. A formula√ß√£o do problema de otimiza√ß√£o para encontrar um hiperplano √≥timo envolve encontrar os coeficientes do hiperplano e um par√¢metro de *bias* que minimizem a classifica√ß√£o err√¥nea e maximizem a margem. As solu√ß√µes para este problema surgem a partir de combina√ß√µes lineares dos pontos de suporte, que s√£o os pontos que est√£o mais pr√≥ximos do hiperplano de decis√£o. A ideia de separar as classes utilizando hiperplanos est√° intimamente ligada a modelos como *Support Vector Machines (SVMs)*, onde o objetivo principal √© encontrar este hiperplano que maximiza a margem de separa√ß√£o.

> üí° **Exemplo Num√©rico:** Imagine que temos duas classes, representadas por pontos em um espa√ßo 2D:
> * Classe 1: (1, 1), (2, 1), (1, 2)
> * Classe 2: (3, 3), (4, 3), (3, 4)
>
> O objetivo do *Separating Hyperplane* √© encontrar uma linha (hiperplano em 2D) que separe as duas classes com a maior margem poss√≠vel. Podemos usar o SVM para achar o hiperplano. O SVM encontra os pontos de suporte (os pontos mais pr√≥ximos do hiperplano) e ajusta o hiperplano para maximizar a dist√¢ncia entre ele e os pontos de suporte. Os pontos de suporte s√£o os pontos que definem a margem do hiperplano.
>
> ```python
> import numpy as np
> from sklearn.svm import SVC
>
> X = np.array([[1, 1], [2, 1], [1, 2], [3, 3], [4, 3], [3, 4]])
> y = np.array([0, 0, 0, 1, 1, 1]) # 0 for class 1, 1 for class 2
>
> svm_model = SVC(kernel='linear')
> svm_model.fit(X, y)
>
> w = svm_model.coef_[0]
> b = svm_model.intercept_[0]
>
> print(f"Hiperplane coefficients (w): {w}")
> print(f"Hiperplane intercept (b): {b}")
> print(f"Support vectors: {svm_model.support_vectors_}")
>
> ```
> O c√≥digo mostra como ajustar o SVM a esses pontos e determinar o hiperplano e os pontos de suporte.  Este hiperplano divide o espa√ßo em duas regi√µes, cada uma correspondente a uma classe. A margem do hiperplano √© a dist√¢ncia entre ele e os pontos de suporte.
>

O *Perceptron* de Rosenblatt √© um algoritmo de aprendizado que busca encontrar um hiperplano que separa os dados em diferentes classes. O algoritmo ajusta iterativamente os pesos do hiperplano com base nos erros de classifica√ß√£o das amostras, at√© que todas as amostras sejam classificadas corretamente (em situa√ß√µes onde a separa√ß√£o √© linear) [^8.5.1]. A converg√™ncia do Perceptron √© garantida sob condi√ß√µes espec√≠ficas, como a linear separabilidade dos dados. O Perceptron √© um dos primeiros algoritmos de aprendizado de m√°quina, e sua simplicidade e efici√™ncia o tornam uma ferramenta importante para entender os fundamentos do aprendizado de modelos lineares.

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**

A *Linear Discriminant Analysis (LDA)* e a regra de decis√£o Bayesiana compartilham uma base comum, especialmente quando se considera dados com distribui√ß√µes Gaussianas e covari√¢ncias iguais. Ambas se baseiam em um modelo probabil√≠stico, mas suas formula√ß√µes e objetivos s√£o distintos. A LDA √© uma abordagem discriminativa que busca um subespa√ßo onde as classes s√£o separadas, enquanto a regra de decis√£o Bayesiana √© uma abordagem generativa que busca estimar a probabilidade posterior das classes. Quando as classes seguem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia, a fronteira de decis√£o Bayesiana se torna uma fronteira linear, o que a torna similar √† LDA [^8.3].

A LDA formula o problema da classifica√ß√£o atrav√©s da busca por uma proje√ß√£o linear dos dados que maximize a separa√ß√£o entre classes, usando conceitos como matrizes de covari√¢ncia e m√©dias das classes. O objetivo √© projetar os dados em um espa√ßo unidimensional onde as classes s√£o mais distintas. A regra de decis√£o Bayesiana, por outro lado, busca classificar um ponto de dados atribuindo-o √† classe que tem a maior probabilidade posterior, calculada atrav√©s do Teorema de Bayes. Sob a hip√≥tese de distribui√ß√µes Gaussianas com covari√¢ncias iguais, a regra de decis√£o Bayesiana pode ser expressa como uma fun√ß√£o discriminante linear, semelhante ao resultado do LDA [^8.3], [^8.3.3]. Em ambos os m√©todos, o limite de decis√£o √© determinado pelas diferen√ßas entre as m√©dias das classes e pela matriz de covari√¢ncia comum.

**Lemma 4:** *Quando as classes seguem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia, a fun√ß√£o discriminante linear do LDA √© proporcional √† fun√ß√£o discriminante Bayesiana, resultando em decis√µes de classifica√ß√£o equivalentes*.

**Prova:**
A fun√ß√£o discriminante linear do LDA pode ser expressa como: $\delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log(\pi_k)$, onde $\mu_k$ √© a m√©dia da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum, e $\pi_k$ √© a probabilidade *a priori* da classe $k$. J√° a regra de decis√£o Bayesiana para classes Gaussianas com covari√¢ncias iguais