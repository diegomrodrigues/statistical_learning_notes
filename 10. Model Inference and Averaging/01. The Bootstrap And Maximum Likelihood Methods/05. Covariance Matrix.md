## Model Inference and Averaging with a Focus on Covariance Matrices

```mermaid
graph LR
    subgraph "Statistical Modeling & Inference"
        direction TB
        A["Maximum Likelihood Estimation"]
        B["Bayesian Inference"]
        C["Bootstrap Methods"]
        D["Model Averaging Techniques"]
         A --> D
         B --> D
        C --> D
        style D fill:#ccf,stroke:#333,stroke-width:2px
    end
    subgraph "Key Component: Covariance Matrix"
        direction TB
        E["Covariance Matrix Role"]
        E --> A
        E --> B
        E --> C
         E --> D
        style E fill:#fcc,stroke:#333,stroke-width:2px
    end
```

### Introdu√ß√£o

Este cap√≠tulo explora m√©todos avan√ßados de **infer√™ncia e modelagem estat√≠stica**, com um foco particular em como a **matriz de covari√¢ncia** (covariance matrix) afeta a constru√ß√£o e interpreta√ß√£o dos modelos. Em grande parte deste texto, a modelagem tem sido realizada minimizando a soma dos quadrados para regress√£o ou a entropia cruzada para classifica√ß√£o [^8.1]. Ambas as abordagens s√£o, na verdade, inst√¢ncias do m√©todo de **m√°xima verossimilhan√ßa** (maximum likelihood). Aqui, examinamos a teoria por tr√°s da m√°xima verossimilhan√ßa, bem como m√©todos bayesianos de infer√™ncia. O **bootstrap**, introduzido no Cap√≠tulo 7, √© discutido nesse contexto, e sua rela√ß√£o com a m√°xima verossimilhan√ßa e o m√©todo bayesiano √© explicada [^8.1]. Al√©m disso, apresentamos t√©cnicas para a m√©dia e melhoria de modelos, incluindo m√©todos de comit√™, *bagging*, *stacking* e *bumping* [^8.1]. A **matriz de covari√¢ncia** surge como um elemento fundamental para modelagem e infer√™ncia em muitos desses m√©todos, influenciando desde a constru√ß√£o de estimativas at√© a avalia√ß√£o da incerteza e a combina√ß√£o de modelos.

### Conceitos Fundamentais

Vamos analisar os conceitos fundamentais para construir uma base s√≥lida para o nosso estudo aprofundado dos modelos estat√≠sticos e sua rela√ß√£o com a matriz de covari√¢ncia:

**Conceito 1:** O **problema de classifica√ß√£o** e a abordagem de modelos lineares. O problema de classifica√ß√£o busca atribuir r√≥tulos de classe a dados de entrada, um processo no qual m√©todos lineares oferecem uma abordagem direta. No entanto, a adequa√ß√£o desses modelos √© moldada por um equil√≠brio entre vi√©s e vari√¢ncia. Modelos com poucos par√¢metros (modelos lineares simples) tendem a ter alto vi√©s, ou seja, uma incapacidade de capturar a verdadeira rela√ß√£o entre as vari√°veis. Por outro lado, modelos com muitos par√¢metros (como fun√ß√µes polinomiais de alta ordem) tendem a ter alta vari√¢ncia, sendo muito sens√≠veis a varia√ß√µes no conjunto de dados de treinamento. A matriz de covari√¢ncia, em modelos lineares, afeta diretamente a forma da fronteira de decis√£o e a incerteza das estimativas. [^8.1], [^8.2]

```mermaid
graph LR
    subgraph "Linear Model Trade-off"
        direction TB
        A["Low Complexity Model"] --> B["High Bias"]
        A --> C["Low Variance"]
        D["High Complexity Model"] --> E["Low Bias"]
        D --> F["High Variance"]
        B & C --> G["Trade-off Decision"]
        E & F --> G
        style G fill:#ccf,stroke:#333,stroke-width:2px
    end
    subgraph "Covariance Matrix Influence"
        direction TB
        H["Covariance Matrix"] --> I["Decision Boundary Shape"]
        H --> J["Parameter Uncertainty"]
    end
```

**Lemma 1:** Suponha um modelo linear $y = X\beta + \epsilon$, onde $\epsilon \sim N(0, \sigma^2I)$.  A matriz de covari√¢ncia dos par√¢metros estimados $\hat{\beta}$, obtidos por m√≠nimos quadrados, √© dada por $Var(\hat{\beta}) = (X^TX)^{-1}\sigma^2$. A matriz $(X^TX)^{-1}$ √© fundamental para a an√°lise de sensibilidade dos par√¢metros e, portanto, influencia diretamente a precis√£o da fun√ß√£o discriminante linear.

*Prova:* A estimativa de m√≠nimos quadrados √© $\hat{\beta} = (X^TX)^{-1}X^Ty$. Substituindo $y = X\beta + \epsilon$, temos $\hat{\beta} = (X^TX)^{-1}X^T(X\beta + \epsilon) = \beta + (X^TX)^{-1}X^T\epsilon$. Assim, $Var(\hat{\beta}) = Var(\beta + (X^TX)^{-1}X^T\epsilon) = Var((X^TX)^{-1}X^T\epsilon) = (X^TX)^{-1}X^TVar(\epsilon)X(X^TX)^{-1} = (X^TX)^{-1}X^T\sigma^2IX(X^TX)^{-1} = \sigma^2(X^TX)^{-1}X^TX(X^TX)^{-1} = \sigma^2(X^TX)^{-1}$. $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere um modelo linear com duas vari√°veis preditoras (X1 e X2) e 5 observa√ß√µes. Suponha que, ap√≥s os c√°lculos, tenhamos:
>
>  $X = \begin{bmatrix} 1 & 2 \\ 1 & 3 \\ 1 & 4 \\ 1 & 5 \\ 1 & 6 \end{bmatrix}$, $X^T = \begin{bmatrix} 1 & 1 & 1 & 1 & 1 \\ 2 & 3 & 4 & 5 & 6 \end{bmatrix}$
>
>  Calculando $X^TX$:
>
>  $X^TX = \begin{bmatrix} 1 & 1 & 1 & 1 & 1 \\ 2 & 3 & 4 & 5 & 6 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 1 & 3 \\ 1 & 4 \\ 1 & 5 \\ 1 & 6 \end{bmatrix} = \begin{bmatrix} 5 & 20 \\ 20 & 90 \end{bmatrix}$
>
>  Calculando $(X^TX)^{-1}$:
>
>  $(X^TX)^{-1} = \frac{1}{(5)(90) - (20)(20)} \begin{bmatrix} 90 & -20 \\ -20 & 5 \end{bmatrix} = \frac{1}{50} \begin{bmatrix} 90 & -20 \\ -20 & 5 \end{bmatrix} = \begin{bmatrix} 1.8 & -0.4 \\ -0.4 & 0.1 \end{bmatrix}$
>
>  Se $\sigma^2 = 1$, ent√£o $Var(\hat{\beta}) = (X^TX)^{-1}\sigma^2 = \begin{bmatrix} 1.8 & -0.4 \\ -0.4 & 0.1 \end{bmatrix}$.
>
>  A matriz de covari√¢ncia mostra que a vari√¢ncia de $\hat{\beta}_1$ √© 1.8, a vari√¢ncia de $\hat{\beta}_2$ √© 0.1, e a covari√¢ncia entre elas √© -0.4. Uma alta vari√¢ncia em $\hat{\beta}_1$ indica maior incerteza na estimativa desse par√¢metro, enquanto a covari√¢ncia negativa sugere que se um par√¢metro aumenta, o outro tende a diminuir. Isso ilustra como a matriz $(X^TX)^{-1}$ influencia a variabilidade e a rela√ß√£o entre os par√¢metros estimados.
>
> ```python
> import numpy as np
>
> X = np.array([[1, 2], [1, 3], [1, 4], [1, 5], [1, 6]])
> XT = X.T
> XT_X = XT @ X
> XT_X_inv = np.linalg.inv(XT_X)
>
> print("X^T * X:\n", XT_X)
> print("\n(X^T * X)^-1:\n", XT_X_inv)
>
> sigma2 = 1
> var_beta = XT_X_inv * sigma2
> print("\nVar(beta):\n", var_beta)
> ```

**Conceito 2:** **Linear Discriminant Analysis (LDA)**. A LDA √© um m√©todo de classifica√ß√£o que busca projetar dados em um espa√ßo de menor dimens√£o de forma a maximizar a separa√ß√£o entre classes. A LDA assume normalidade dos dados em cada classe, com covari√¢ncias iguais entre as classes. A fronteira de decis√£o, neste caso, √© linear e determinada pela matriz de covari√¢ncia comum. As suposi√ß√µes de normalidade e igualdade de covari√¢ncias t√™m um impacto significativo no desempenho do LDA. [^8.3], [^8.3.1], [^8.3.2], [^8.3.3]

```mermaid
graph LR
    subgraph "Linear Discriminant Analysis (LDA)"
        direction TB
        A["Data with Normal Distribution"]
        B["Equal Class Covariances"]
        C["Dimensionality Reduction"]
        D["Maximize Class Separation"]
        E["Linear Decision Boundary"]
        A & B --> C
        C --> D
        D --> E
          style E fill:#ccf,stroke:#333,stroke-width:2px
    end
```

**Corol√°rio 1:** A fun√ß√£o discriminante linear na LDA pode ser expressa como $\delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log \pi_k$, onde $\Sigma$ √© a matriz de covari√¢ncia comum, $\mu_k$ √© a m√©dia da classe k e $\pi_k$ √© a probabilidade a priori da classe k. O termo $x^T\Sigma^{-1}\mu_k$ representa a proje√ß√£o do ponto de entrada $x$ na dire√ß√£o da m√©dia da classe k, considerando a covari√¢ncia dos dados. O termo $\Sigma^{-1}$ √© crucial pois permite o ajuste da proje√ß√£o para a escala e correla√ß√£o entre as vari√°veis. [^8.3.1]

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com duas classes. A matriz de covari√¢ncia comum √© $\Sigma = \begin{bmatrix} 2 & 0.5 \\ 0.5 & 1 \end{bmatrix}$. As m√©dias das classes s√£o $\mu_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$ e $\mu_2 = \begin{bmatrix} 3 \\ 2 \end{bmatrix}$, e as probabilidades a priori s√£o $\pi_1 = 0.4$ e $\pi_2 = 0.6$. Para classificar um novo ponto $x = \begin{bmatrix} 2 \\ 1.5 \end{bmatrix}$, precisamos calcular as fun√ß√µes discriminantes $\delta_1(x)$ e $\delta_2(x)$.
>
> Primeiro, calculamos a inversa da matriz de covari√¢ncia:
>
> $\Sigma^{-1} = \frac{1}{(2)(1) - (0.5)(0.5)} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 2 \end{bmatrix} = \frac{1}{1.75} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 2 \end{bmatrix} = \begin{bmatrix} 0.57 & -0.29 \\ -0.29 & 1.14 \end{bmatrix}$
>
> Agora, calculamos os termos para $\delta_1(x)$:
>
> $x^T\Sigma^{-1}\mu_1 = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 0.57 & -0.29 \\ -0.29 & 1.14 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 0.28 \\ 0.85 \end{bmatrix} = 1.83$
>
> $\mu_1^T\Sigma^{-1}\mu_1 = \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 0.57 & -0.29 \\ -0.29 & 1.14 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} = \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 0.28 \\ 0.85 \end{bmatrix} = 1.13$
>
> $\delta_1(x) = 1.83 - \frac{1}{2}(1.13) + \log(0.4) \approx 1.83 - 0.565 - 0.916 = 0.349$
>
> Calculando os termos para $\delta_2(x)$:
>
> $x^T\Sigma^{-1}\mu_2 = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 0.57 & -0.29 \\ -0.29 & 1.14 \end{bmatrix} \begin{bmatrix} 3 \\ 2 \end{bmatrix} = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 1.13 \\ 1.71 \end{bmatrix} = 4.82$
>
> $\mu_2^T\Sigma^{-1}\mu_2 = \begin{bmatrix} 3 & 2 \end{bmatrix} \begin{bmatrix} 0.57 & -0.29 \\ -0.29 & 1.14 \end{bmatrix} \begin{bmatrix} 3 \\ 2 \end{bmatrix} = \begin{bmatrix} 3 & 2 \end{bmatrix} \begin{bmatrix} 1.13 \\ 1.71 \end{bmatrix} = 6.81$
>
> $\delta_2(x) = 4.82 - \frac{1}{2}(6.81) + \log(0.6) \approx 4.82 - 3.405 - 0.511 = 0.904$
>
> Como $\delta_2(x) > \delta_1(x)$, o ponto $x$ √© classificado como pertencente √† classe 2. Este exemplo demonstra como a matriz de covari√¢ncia $\Sigma$ e seu inverso influenciam o c√°lculo das fun√ß√µes discriminantes e a tomada de decis√£o. A matriz inversa $\Sigma^{-1}$ ajusta a proje√ß√£o de $x$ levando em conta a escala e correla√ß√£o das vari√°veis, determinando o alinhamento e a forma da fronteira de decis√£o linear.
>
> ```python
> import numpy as np
>
> # Matriz de covari√¢ncia comum
> sigma = np.array([[2, 0.5], [0.5, 1]])
> sigma_inv = np.linalg.inv(sigma)
>
> # M√©dias das classes
> mu1 = np.array([1, 1])
> mu2 = np.array([3, 2])
>
> # Probabilidades a priori
> pi1 = 0.4
> pi2 = 0.6
>
> # Ponto a ser classificado
> x = np.array([2, 1.5])
>
> # Fun√ß√£o discriminante para classe 1
> delta1 = x.T @ sigma_inv @ mu1 - 0.5 * mu1.T @ sigma_inv @ mu1 + np.log(pi1)
>
> # Fun√ß√£o discriminante para classe 2
> delta2 = x.T @ sigma_inv @ mu2 - 0.5 * mu2.T @ sigma_inv @ mu2 + np.log(pi2)
>
> print(f"delta_1(x) = {delta1:.3f}")
> print(f"delta_2(x) = {delta2:.3f}")
>
> if delta1 > delta2:
>   print("Classificado como classe 1")
> else:
>   print("Classificado como classe 2")
> ```

```mermaid
graph LR
    subgraph "LDA Discriminant Function"
    direction TB
        A["Œ¥_k(x) = x^TŒ£‚Åª¬πŒº_k - 1/2Œº_k^TŒ£‚Åª¬πŒº_k + log(œÄ_k)"]
        B["x^TŒ£‚Åª¬πŒº_k : Project x onto class mean with covariance"]
        C["1/2Œº_k^TŒ£‚Åª¬πŒº_k : Mean term with covariance"]
        D["log(œÄ_k) : Prior probability of class k"]
        A --> B
        A --> C
         A --> D
    end
     subgraph "Key Component: Œ£‚Åª¬π"
        direction TB
      E["Œ£‚Åª¬π : Inverse of the common covariance matrix"]
        E --> B
        E --> C
        style E fill:#fcc,stroke:#333,stroke-width:2px
    end
```

**Conceito 3:** **Logistic Regression**. A regress√£o log√≠stica √© outro m√©todo de classifica√ß√£o amplamente utilizado, que modela a probabilidade de um evento ocorrer usando a fun√ß√£o *logit* (log-odds). A regress√£o log√≠stica √© um modelo linear na escala *logit*, e seus par√¢metros s√£o estimados via maximiza√ß√£o da verossimilhan√ßa. Embora tamb√©m seja um classificador linear, a regress√£o log√≠stica n√£o assume necessariamente covari√¢ncias iguais entre as classes, e suas estimativas s√£o obtidas por um processo iterativo. A matriz de covari√¢ncia dos preditores, no entanto, desempenha um papel crucial na regulariza√ß√£o e na avalia√ß√£o da qualidade das estimativas. [^8.4], [^8.4.1], [^8.4.2], [^8.4.3], [^8.4.4], [^8.4.5]

> ‚ö†Ô∏è **Nota Importante**: A escolha entre LDA e regress√£o log√≠stica depende das suposi√ß√µes feitas sobre os dados e do objetivo da an√°lise. Se a igualdade de covari√¢ncias e a normalidade s√£o plaus√≠veis, a LDA pode ser uma escolha mais direta. Se essas suposi√ß√µes s√£o question√°veis, a regress√£o log√≠stica oferece mais flexibilidade. **Refer√™ncia ao t√≥pico [^8.4.1]**.

> ‚ùó **Ponto de Aten√ß√£o**: Dados n√£o-balanceados podem afetar o desempenho da regress√£o log√≠stica, levando √† estima√ß√£o de probabilidades enviesadas. T√©cnicas de reamostragem ou pondera√ß√£o de classes podem ser necess√°rias. **Conforme indicado em [^8.4.2]**.

> ‚úîÔ∏è **Destaque**: Embora os m√©todos sejam diferentes, tanto LDA como regress√£o log√≠stica compartilham o objetivo de encontrar uma separa√ß√£o linear entre as classes, e a matriz de covari√¢ncia influencia a geometria das decis√µes. **Baseado no t√≥pico [^8.5]**.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Relationship between Regression and Classification"
        direction LR
        A["Indicator Regression"] --> B["LDA (under equal covariance)"]
        A --> C["Logistic Regression (stable probabilities)"]
        B --> D["Linear Separation"]
        C --> D
         C --> E["Avoids extrapolation outside [0,1]"]
    end
    subgraph "Masking Problem"
        direction TB
        F["Class Covariance"] --> G["Masks relevant information"]
         G --> B
         style F fill:#fcc,stroke:#333,stroke-width:2px
     end
```

A regress√£o linear, quando aplicada a matrizes de indicadores para problemas de classifica√ß√£o, se apresenta como uma alternativa interessante, com suas pr√≥prias vantagens e limita√ß√µes. Em vez de modelar diretamente as classes, a regress√£o linear modela vari√°veis *dummy* associadas a cada classe, o que √© uma abordagem direta e computacionalmente eficiente [^8.2].

Para um problema de classifica√ß√£o com *K* classes, criamos *K* vari√°veis indicadoras, onde $y_{ik} = 1$ se a observa√ß√£o *i* pertence √† classe *k* e $0$ caso contr√°rio.  Aplicamos ent√£o a regress√£o linear a cada uma dessas vari√°veis, gerando um conjunto de fun√ß√µes lineares, onde cada fun√ß√£o estimada pode ser expressa como $\hat{f_k(x)} = x^T\hat{\beta_k}$. A classifica√ß√£o √© realizada pela atribui√ß√£o de um ponto √† classe com o maior valor da fun√ß√£o estimada, ou seja, classe *k* tal que $k = \text{argmax}_k \hat{f_k(x)}$.

A estima√ß√£o dos par√¢metros $\hat{\beta_k}$ geralmente √© feita atrav√©s de m√≠nimos quadrados, que busca minimizar a soma dos erros quadrados entre os valores observados e os valores preditos, levando √† estimativa $\hat{\beta} = (X^TX)^{-1}X^Ty$.

**Lemma 2:** Sob a suposi√ß√£o de que as classes podem ser separadas linearmente, o hiperplano de decis√£o resultante da regress√£o linear de indicadores √© equivalente ao hiperplano de decis√£o gerado por discriminantes lineares, quando as classes t√™m covari√¢ncias iguais.

*Prova:* Em condi√ß√µes de separabilidade linear, os coeficientes da regress√£o linear podem ser representados como uma combina√ß√£o linear das m√©dias e da matriz de covari√¢ncia das classes. A fun√ß√£o discriminante da LDA, quando aplicada a dados com covari√¢ncias iguais, possui a mesma forma que os hiperplanos de decis√£o gerados pela regress√£o de indicadores. $\blacksquare$

**Corol√°rio 2:** A proje√ß√£o de um ponto de entrada no hiperplano de decis√£o gerado pela regress√£o linear de indicadores √© equivalente a uma proje√ß√£o em um subespa√ßo definido pela LDA, sob certas condi√ß√µes. Isso oferece uma interpreta√ß√£o geom√©trica para os resultados da regress√£o linear e demonstra a conex√£o entre essas duas abordagens. [^8.3]

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com tr√™s classes e um conjunto de dados com 5 observa√ß√µes e 2 features. A matriz de indicadores $Y$ √© uma matriz 5x3, onde cada coluna representa uma classe:
>
> $Y = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 0 \\ 0 & 1 & 0 \end{bmatrix}$
>
> A matriz de features $X$ √©:
>
> $X = \begin{bmatrix} 1 & 2 \\ 2 & 3 \\ 3 & 4 \\ 4 & 5 \\ 5 & 6 \end{bmatrix}$
>
> Adicionamos uma coluna de 1s para o intercepto:
>
> $X = \begin{bmatrix} 1 & 1 & 2 \\ 1 & 2 & 3 \\ 1 & 3 & 4 \\ 1 & 4 & 5 \\ 1 & 5 & 6 \end{bmatrix}$
>
> Para cada classe $k$, calculamos $\hat{\beta_k} = (X^TX)^{-1}X^Ty_k$. Para a primeira classe, $y_1 = \begin{bmatrix} 1 \\ 0 \\ 0 \\ 1 \\ 0 \end{bmatrix}$.
>
> Calculando $X^TX$:
>
> $X^TX = \begin{bmatrix} 5 & 15 & 20 \\ 15 & 55 & 70 \\ 20 & 70 & 90 \end{bmatrix}$
>
> Calculando $(X^TX)^{-1}$ (usando um software ou calculadora):
>
> $(X^TX)^{-1} \approx \begin{bmatrix} 2.917 & -0.5 & -0.083 \\ -0.5 & 0.333 & 0 \\ -0.083 & 0 & 0.017 \end{bmatrix}$
>
> Calculando $X^Ty_1$:
>
> $X^Ty_1 = \begin{bmatrix} 1 & 1 & 1 & 1 & 1 \\ 1 & 2 & 3 & 4 & 5 \\ 2 & 3 & 4 & 5 & 6 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \\ 0 \\ 1 \\ 0 \end{bmatrix} = \begin{bmatrix} 2 \\ 5 \\ 7 \end{bmatrix}$
>
> Agora calculamos $\hat{\beta_1}$:
>
> $\hat{\beta_1} = (X^TX)^{-1}X^Ty_1 \approx \begin{bmatrix} 2.917 & -0.5 & -0.083 \\ -0.5 & 0.333 & 0 \\ -0.083 & 0 & 0.017 \end{bmatrix} \begin{bmatrix} 2 \\ 5 \\ 7 \end{bmatrix} \approx \begin{bmatrix} 2.15 \\ 0.66 \\ 0 \end{bmatrix}$
>
> Similarmente, calcular√≠amos $\hat{\beta_2}$ e $\hat{\beta_3}$ para as outras classes. Para classificar um novo ponto, $x_{new} = \begin{bmatrix} 1 \\ 4 \\ 5 \end{bmatrix}$, calcular√≠amos $\hat{f_k(x_{new})} = x_{new}^T\hat{\beta_k}$ para cada classe e escolher√≠amos a classe com o maior valor. Isso ilustra como a regress√£o de indicadores, por meio dos coeficientes estimados $\hat{\beta_k}$, fornece fun√ß√µes lineares para classificar novas amostras. A escolha da classe √© feita comparando os valores das fun√ß√µes discriminantes. Embora a regress√£o linear n√£o forne√ßa diretamente probabilidades, ela permite uma separa√ß√£o linear eficiente, especialmente quando as classes s√£o bem separadas.
> ```python
> import numpy as np
>
> # Matriz de indicadores (Y)
> Y = np.array([[1, 0, 0],
>               [0, 1, 0],
>               [0, 0, 1],
>               [1, 0, 0],
>               [0, 1, 0]])
>
> # Matriz de features (X) com intercepto
> X = np.array([[1, 2],
>               [2, 3],
>               [3, 4],
>               [4, 5],
>               [5, 6]])
> X = np.insert(X, 0, 1, axis=1)
>
> # Calculo de X^T * X
> XT_X = X.T @ X
>
> # Inversa de (X^T * X)
> XT_X_inv = np.linalg.inv(XT_X)
>
> # Y para a primeira classe
> y1 = Y[:, 0]
>
> # Calcula X^T * y1
> XT_y1 = X.T @ y1
>
> # Calcula os coeficientes para a classe 1
> beta1 = XT_X_inv @ XT_y1
>
> print("Coeficientes para classe 1:")
> print(beta1)
>
> # Novo ponto para classificar
> x_new = np.array([1, 4, 5])
>
> # Calcula f(x_new) para a classe 1
> f_x_new_class1 = x_new.T @ beta1
>
> print(f"\nf(x_new) para a classe 1: {f_x_new_class1}")
>
> # O mesmo processo pode ser repetido para outras classes
> ```

Entretanto, a regress√£o de indicadores pode levar a resultados indesej√°veis, como valores preditos fora do intervalo $[0, 1]$, j√° que a regress√£o linear n√£o √© projetada para fornecer probabilidades. Al√©m disso, o "masking problem" ocorre quando as covari√¢ncias entre classes podem obscurecer as rela√ß√µes de interesse, especialmente quando as classes s√£o sobrepostas [^8.3].  A regress√£o log√≠stica, como abordado em [^8.4], pode, em muitos casos, fornecer estimativas de probabilidade mais est√°veis e evitar extrapola√ß√µes impr√≥prias. Em certos contextos, no entanto, a regress√£o de indicadores se mostra uma alternativa vi√°vel, especialmente quando o objetivo prim√°rio √© a separa√ß√£o linear das classes, conforme discutido em [^8.2].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Variable Selection & Regularization"
        direction TB
        A["Input Data"] --> B["Variable Selection (L1/L2)"]
        B --> C["Logistic Regression with Regularization"]
        C --> E["Final Model"]
         E --> F["Model Evaluation"]
         F --> B
          subgraph "Sparsity Decision"
              direction LR
               B --> D1["L1 (Lasso)"]
               B --> D2["L2 (Ridge)"]
          end
          style E fill:#ccf,stroke:#333,stroke-width:2px
        style F fill:#fcc,stroke:#333,stroke-width:2px
    end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas importantes no aprendizado de m√°quina que ajudam a construir modelos mais robustos e interpret√°veis, reduzindo o sobreajuste e melhorando a generaliza√ß√£o. Em modelos de classifica√ß√£o, isso se torna particularmente relevante devido √† necessidade de lidar com conjuntos de dados complexos e com um grande n√∫mero de *features* (preditores). As penalidades L1 e L2 s√£o comumente usadas nesse contexto.

A penalidade L1 (Lasso) adiciona um termo √† fun√ß√£o de custo que √© proporcional √† soma dos valores absolutos dos coeficientes, ou seja, $||\beta||_1 = \sum_{j=1}^p |\beta_j|$. A penalidade L2 (Ridge) adiciona um termo proporcional √† soma dos quadrados dos coeficientes, dado por $||\beta||_2^2 = \sum_{j=1}^p \beta_j^2$. A penalidade L1 tende a gerar solu√ß√µes esparsas, ou seja, muitas das estimativas $\beta_j$ ser√£o exatamente zero, o que realiza uma sele√ß√£o de vari√°veis. A penalidade L2, por sua vez, tende a encolher os coeficientes em dire√ß√£o a zero, mas raramente os torna exatamente zero, o que aumenta a estabilidade da estimativa e reduz a vari√¢ncia.

Em regress√£o log√≠stica, a fun√ß√£o de custo a ser minimizada combina a log-verossimilhan√ßa com os termos de penaliza√ß√£o L1 ou L2.  Para penalidade L1, a fun√ß√£o de custo √© dada por:
$$
- \frac{1}{N} \sum_{i=1}^N  [ y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda ||\beta||_1
$$
onde $\lambda$ √© um par√¢metro que controla a for√ßa da regulariza√ß√£o. A penalidade L2 possui uma formula√ß√£o semelhante, mas utilizando $||\beta||_2^2$ em vez de $||\beta||_1$ [^8.4.4].

```mermaid
graph LR
    subgraph "L1 Regularization Cost Function"
      direction TB
      A["Cost(Œ≤) = -1/N Œ£ [y_i log(p(x_i)) + (1-y_i)log(1-p(x_i))] + Œª ||Œ≤||‚ÇÅ"]
      B["Data Loss Term:  -1/N Œ£ [y_i log(p(x_i)) + (1-y_i)log(1-p(x_i))]"]
      C["L1 Penalty Term:  Œª ||Œ≤||‚ÇÅ = Œª Œ£ |Œ≤_j|"]
      A --> B
      A --> C
      style C fill:#fcc,stroke:#333,stroke-width:2px
  end
```
```mermaid
graph LR
     subgraph "L2 Regularization Cost Function"
      direction TB
      A["Cost(Œ≤) = -1/N Œ£ [y_i log(p(x_i)) + (1-y_i)log(1-p(x_i))] + Œª ||Œ≤||‚ÇÇ¬≤"]
       B["Data Loss Term:  -1/N Œ£ [y_i log(p(x_i)) + (1-y_i)log(1-p(x_i))]"]
       C["L2 Penalty Term:  Œª ||Œ≤||‚ÇÇ¬≤ = Œª Œ£ Œ≤_j¬≤"]
        A --> B
        A --> C
      style C fill:#fcc,stroke:#333,stroke-width:2px
    end
```

**Lemma 3:** A penaliza√ß√£o L1, ao minimizar a fun√ß√£o de custo, leva a coeficientes esparsos devido ao formato da penalidade, que possui "quinas" no ponto zero. A minimiza√ß√£o frequentemente resulta em coeficientes exatamente zero, realizando uma sele√ß√£o de vari√°veis. [^8.4.4]

*Prova:* A penalidade L1 n√£o √© diferenci√°vel em $\beta_j = 0$. Ao derivar a fun√ß√£o de custo com rela√ß√£o a $\beta_j$, temos uma fun√ß√£o descont√≠nua, que igual a zero n√£o leva necessariamente ao cancelamento de $\beta_j$. Os termos associados a $\beta_j = 0$ ser√£o removidos do modelo devido √† forma da penalidade.  $\blacksquare$

**Corol√°rio 3:**  A propriedade da penalidade L1 de gerar coeficientes esparsos possui implica√ß√µes diretas para a interpretabilidade de modelos de classifica√ß√£o, j√° que remove vari√°veis irrelevantes do modelo, simplificando a an√°lise e destacando apenas as vari√°veis mais importantes. [^8.4.5]

> üí° **Exemplo Num√©rico:** Suponha que temos um problema de classifica√ß√£o bin√°ria com uma matriz de features $X$ (100 amostras, 5 features) e um vetor de classe $y$ (0 ou 1). Vamos aplicar a regress√£o log√≠stica com regulariza√ß√£o L1 (Lasso) e L2 (Ridge) e observar os coeficientes resultantes. Usaremos o scikit-learn para este exemplo:
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.preprocessing import StandardScaler
>
> # Gerando dados aleat√≥rios
> np.random.seed(42)
> X = np.random.rand(100, 5)
> y = np.random.randint(0, 2, 100)
>
> # Normalizando os dados
> scaler = StandardScaler()
> X_scaled = scaler.fit_transform(X)
>
> # Regulariza√ß√£o L1 (Lasso)
> lasso_model = LogisticRegression(penalty='l1', solver='liblinear', C=0.1)
> lasso_model.fit(X_scaled, y)
> lasso_coef = lasso_model.coef_
>
> # Regulariza√ß√£o L2 (Ridge)
> ridge_model = LogisticRegression(penalty='l2', C=0.1)
> ridge_model.fit(X_scaled, y)
> ridge_coef = ridge_model.coef_
>
> print("Coeficientes Lasso:", lasso_coef)
> print("Coeficientes Ridge:", ridge_coef)
> ```
>
> Ao executar este c√≥digo, observaremos que a regulariza√ß√£o L1 (Lasso) resulta em coeficientes que s√£o exatamente zero para algumas das features, indicando que essas features foram removidas do modelo (sele√ß√£o de vari√°veis). A