## Maximum Likelihood Inference

```mermaid
graph LR
    subgraph "Maximum Likelihood Inference (MLI)"
    direction TB
        A["Data Observations (Z)"] --> B["Parametric Model (g<sub>Œ∏</sub>(z))"]
        B --> C["Likelihood Function (L(Œ∏; Z))"]
        C --> D["Maximize L(Œ∏; Z) or log L(Œ∏; Z)"]
        D --> E["Maximum Likelihood Estimator (MLE): Œ∏ÃÇ"]
    end
```

### Introdu√ß√£o

A **Maximum Likelihood Inference (MLI)** √© um m√©todo fundamental na estat√≠stica e aprendizado de m√°quina para estimar os par√¢metros de um modelo probabil√≠stico. O objetivo √© encontrar os valores dos par√¢metros que maximizam a verossimilhan√ßa dos dados observados sob o modelo proposto [^8.1]. Este cap√≠tulo explora detalhadamente o m√©todo MLI, sua rela√ß√£o com o m√©todo *Bootstrap* e com a infer√™ncia Bayesiana, utilizando como base os conceitos apresentados em [^8.1]. O processo de ajuste de modelos, como os usados em regress√£o (minimizando a soma dos quadrados dos erros) e classifica√ß√£o (minimizando cross-entropy), s√£o, na verdade, casos espec√≠ficos da abordagem de m√°xima verossimilhan√ßa [^8.1]. Al√©m disso, m√©todos de model averaging e melhorias de modelos (como comit√™s, *bagging*, *stacking* e *bumping*) ser√£o discutidos.

### Conceitos Fundamentais

**Conceito 1: Modelagem Param√©trica e Verossimilhan√ßa**

No contexto da MLI, assume-se que os dados s√£o gerados por uma distribui√ß√£o probabil√≠stica espec√≠fica, que depende de um conjunto de par√¢metros desconhecidos [^8.2.2]. O objetivo √© estimar esses par√¢metros a partir dos dados observados. Esta abordagem define um **modelo param√©trico** para os dados, e o processo de ajuste busca encontrar os par√¢metros que melhor se adequam √†s observa√ß√µes [^8.2.2]. A verossimilhan√ßa (**likelihood**) √© uma fun√ß√£o dos par√¢metros que representa a probabilidade de observar os dados, dado um conjunto espec√≠fico de valores de par√¢metros. Matematicamente, a verossimilhan√ßa √© expressa como o produto das densidades ou probabilidades de massa de cada observa√ß√£o, dadas pelos par√¢metros do modelo.

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um conjunto de dados de alturas de pessoas, e assumimos que essas alturas seguem uma distribui√ß√£o normal com m√©dia $\mu$ e desvio padr√£o $\sigma$. Nosso modelo param√©trico √© a distribui√ß√£o normal $N(\mu, \sigma^2)$. Os par√¢metros a serem estimados s√£o $\theta = (\mu, \sigma)$. A verossimilhan√ßa para um √∫nico dado (altura) $y_i$ √© dada pela fun√ß√£o de densidade normal:
>
> $$ g_{\theta}(y_i) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(y_i - \mu)^2}{2\sigma^2}} $$
>
> Para um conjunto de dados de tr√™s alturas, digamos $y = [170, 180, 175]$ cm, a verossimilhan√ßa total √© o produto das densidades para cada altura:
>
> $$ L(\mu, \sigma; y) = g_{\theta}(170) \cdot g_{\theta}(180) \cdot g_{\theta}(175) $$
>
> O objetivo da MLI √© encontrar os valores de $\mu$ e $\sigma$ que maximizem essa fun√ß√£o de verossimilhan√ßa, ou, equivalentemente, sua log-verossimilhan√ßa.

**Lemma 1:** *A maximiza√ß√£o da verossimilhan√ßa √© equivalente a minimizar a soma dos quadrados dos erros para modelos com erros Gaussianos aditivos*.

  **Prova:** Considere um modelo linear $y_i = \mu(x_i) + \epsilon_i$ onde $\epsilon_i \sim N(0, \sigma^2)$. A verossimilhan√ßa para uma √∫nica observa√ß√£o √© dada por:
  $$ g_{\theta}(y_i) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(y_i - \mu(x_i))^2}{2\sigma^2}} $$
  A log-verossimilhan√ßa para $N$ observa√ß√µes independentes √©:
  $$ l(\theta; Z) = \sum_{i=1}^{N} \log g_{\theta}(y_i) =  -\frac{N}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{N}(y_i - \mu(x_i))^2 $$
  Maximizar $l(\theta; Z)$ em rela√ß√£o a $\theta$ (que afeta $\mu(x_i)$) √© equivalente a minimizar $\sum_{i=1}^{N}(y_i - \mu(x_i))^2$. Este √© o crit√©rio de m√≠nimos quadrados.
 $\blacksquare$

```mermaid
graph LR
    subgraph "Equivalence of ML and Least Squares"
        direction TB
        A["Model: y<sub>i</sub> = Œº(x<sub>i</sub>) + Œµ<sub>i</sub> , Œµ<sub>i</sub> ~ N(0, œÉ¬≤)"]
        B["Likelihood: g<sub>Œ∏</sub>(y<sub>i</sub>) = (1/‚àö(2œÄœÉ¬≤)) * exp(-(y<sub>i</sub> - Œº(x<sub>i</sub>))¬≤/2œÉ¬≤)"]
        C["Log-Likelihood: l(Œ∏; Z) = -N/2 * log(2œÄœÉ¬≤) - 1/(2œÉ¬≤) * Œ£(y<sub>i</sub> - Œº(x<sub>i</sub>))¬≤"]
        D["Maximize l(Œ∏; Z)"] --> E["Minimize Œ£(y<sub>i</sub> - Œº(x<sub>i</sub>))¬≤ (Least Squares)"]
        A --> B
        B --> C
        C --> D
    end
```

**Conceito 2: Maximum Likelihood Estimator (MLE)**

O **Maximum Likelihood Estimator (MLE)** √© o valor dos par√¢metros que maximiza a fun√ß√£o de verossimilhan√ßa [^8.2.2]. Em outras palavras, o MLE √© o valor dos par√¢metros para o qual os dados observados t√™m a maior probabilidade de ocorrer sob o modelo assumido. √â comum trabalhar com a log-verossimilhan√ßa, o logaritmo da fun√ß√£o de verossimilhan√ßa, pois a maximiza√ß√£o do log-verossimilhan√ßa √© equivalente √† maximiza√ß√£o da verossimilhan√ßa, e frequentemente √© mais f√°cil de tratar matematicamente [^8.2.2]. A log-verossimilhan√ßa √© dada por $l(\theta; Z) = \sum_{i=1}^{N} \log g_{\theta}(z_i)$, onde $z_i$ s√£o as observa√ß√µes e $g_{\theta}$ √© a fun√ß√£o de densidade ou massa de probabilidade com par√¢metros $\theta$ [^8.2.2].

> üí° **Exemplo Num√©rico:**
>
> Continuando o exemplo anterior das alturas, vamos calcular a log-verossimilhan√ßa para os dados $y = [170, 180, 175]$ com $\mu = 175$ e $\sigma = 5$.
>
> 1.  **Verossimilhan√ßa para cada observa√ß√£o:**
>
>     $$g(170) = \frac{1}{\sqrt{2\pi(5^2)}} e^{-\frac{(170 - 175)^2}{2(5^2)}} \approx 0.0484$$
>     $$g(180) = \frac{1}{\sqrt{2\pi(5^2)}} e^{-\frac{(180 - 175)^2}{2(5^2)}} \approx 0.0484$$
>      $$g(175) = \frac{1}{\sqrt{2\pi(5^2)}} e^{-\frac{(175 - 175)^2}{2(5^2)}} \approx 0.0798$$
>
> 2.  **Log-verossimilhan√ßa para cada observa√ß√£o:**
>
>     $$\log g(170) \approx \log(0.0484) \approx -3.03$$
>     $$\log g(180) \approx \log(0.0484) \approx -3.03$$
>    $$\log g(175) \approx \log(0.0798) \approx -2.53$$
>
> 3. **Log-verossimilhan√ßa total:**
>
>     $$l(\theta; y) = \sum_i \log g(y_i) \approx -3.03 - 3.03 - 2.53 = -8.59$$
>
>  O MLE seria obtido variando $\mu$ e $\sigma$ at√© maximizar esta log-verossimilhan√ßa.
>
> ```python
> import numpy as np
> from scipy.stats import norm
>
> data = np.array([170, 180, 175])
> mu = 175
> sigma = 5
>
> log_likelihoods = norm.logpdf(data, loc=mu, scale=sigma)
> total_log_likelihood = np.sum(log_likelihoods)
> print(f"Log-likelihood: {total_log_likelihood:.2f}")
> # Output: Log-likelihood: -8.59
> ```

**Corol√°rio 1:** *A estimativa dos par√¢metros via MLE para uma distribui√ß√£o normal √© dada pela m√©dia e vari√¢ncia amostral quando o modelo de distribui√ß√£o √© uma gaussiana.*

**Prova:** Considere que $Z_i \sim N(\mu, \sigma^2)$. A fun√ß√£o de log-verossimilhan√ßa para $N$ amostras independentes √©:
$$l(\mu, \sigma^2; Z) = -\frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^N(z_i-\mu)^2$$
Para encontrar o MLE, derivamos em rela√ß√£o a $\mu$ e $\sigma^2$ e igualamos a zero.
$$\frac{\partial l}{\partial \mu} = \frac{1}{\sigma^2}\sum_{i=1}^N(z_i-\mu) = 0 \Rightarrow \hat{\mu} = \frac{1}{N}\sum_{i=1}^Nz_i = \bar{z}$$
$$\frac{\partial l}{\partial \sigma^2} = -\frac{N}{2\sigma^2} + \frac{1}{2\sigma^4}\sum_{i=1}^N(z_i-\mu)^2 = 0 \Rightarrow \hat{\sigma}^2 = \frac{1}{N}\sum_{i=1}^N(z_i-\hat{\mu})^2 $$
$\blacksquare$

```mermaid
graph LR
    subgraph "MLE for Normal Distribution"
    direction TB
    A["Data: Z<sub>i</sub> ~ N(Œº, œÉ¬≤)"]
    B["Log-Likelihood: l(Œº, œÉ¬≤; Z) = -N/2 * log(2œÄœÉ¬≤) - 1/(2œÉ¬≤) * Œ£(z<sub>i</sub> - Œº)¬≤"]
    C["‚àÇl/‚àÇŒº = (1/œÉ¬≤) * Œ£(z<sub>i</sub> - Œº) = 0"] --> D["MLE of Œº: ŒºÃÇ = (1/N) * Œ£z<sub>i</sub> = zÃÑ"]
    E["‚àÇl/‚àÇœÉ¬≤ = -N/(2œÉ¬≤) + (1/(2œÉ‚Å¥)) * Œ£(z<sub>i</sub> - Œº)¬≤ = 0"] --> F["MLE of œÉ¬≤: œÉÃÇ¬≤ = (1/N) * Œ£(z<sub>i</sub> - ŒºÃÇ)¬≤"]
     A --> B
     B --> C
     B --> E
    end
```

> üí° **Exemplo Num√©rico:**
>
> Para os dados de altura $y = [170, 180, 175]$, o MLE para a m√©dia $\mu$ e o desvio padr√£o $\sigma$ (ou vari√¢ncia $\sigma^2$) s√£o:
>
> $$\hat{\mu} = \frac{170 + 180 + 175}{3} = 175$$
>
> $$\hat{\sigma}^2 = \frac{(170-175)^2 + (180-175)^2 + (175-175)^2}{3} = \frac{25 + 25 + 0}{3} \approx 16.67$$
>
> $$\hat{\sigma} = \sqrt{16.67} \approx 4.08$$
>
> Estes s√£o os valores que maximizam a verossimilhan√ßa dos dados observados sob a hip√≥tese de que seguem uma distribui√ß√£o normal.
>
> ```python
> import numpy as np
>
> data = np.array([170, 180, 175])
>
> mu_hat = np.mean(data)
> sigma2_hat = np.var(data)
> sigma_hat = np.sqrt(sigma2_hat)
>
> print(f"MLE da m√©dia: {mu_hat:.2f}")
> print(f"MLE da vari√¢ncia: {sigma2_hat:.2f}")
> print(f"MLE do desvio padr√£o: {sigma_hat:.2f}")
> # Output:
> # MLE da m√©dia: 175.00
> # MLE da vari√¢ncia: 16.67
> # MLE do desvio padr√£o: 4.08
> ```

**Conceito 3: Score Function e Information Matrix**

A **score function** √© o gradiente da log-verossimilhan√ßa com rela√ß√£o aos par√¢metros [^8.2.2]. Ela √© definida como $\ell(\theta; z_i) = \frac{dl(\theta;z_i)}{d\theta}$, onde $l(\theta;z_i) = log(g_\theta(z_i))$. O ponto de m√°ximo da log-verossimilhan√ßa ocorre quando o score function √© igual a zero, ou seja, $\ell(\hat{\theta}; Z) = \sum_{i=1}^N \ell(\hat{\theta}; z_i) = 0$ [^8.2.2].  A **information matrix** (matriz de informa√ß√£o), denotada por $I(\theta)$, √© a segunda derivada (ou o negativo do Hessiano) da log-verossimilhan√ßa e fornece informa√ß√µes sobre a curvatura da fun√ß√£o de log-verossimilhan√ßa no ponto √≥timo, indicando a precis√£o da estimativa dos par√¢metros [^8.2.2]. Ela √© definida como $I(\theta) = -\sum_{i=1}^N \frac{d^2l(\theta; z_i)}{d\theta d\theta^T}$. A informa√ß√£o de Fisher (ou informa√ß√£o esperada) √© dada por $i(\theta) = E[I(\theta)]$ [^8.2.2].

> ‚ö†Ô∏è **Nota Importante**: A informa√ß√£o de Fisher √© a esperan√ßa da information matrix, um conceito crucial para an√°lise assint√≥tica das estimativas de m√°xima verossimilhan√ßa [^8.2.2].

> ‚ùó **Ponto de Aten√ß√£o**: A condi√ß√£o de que a likelihood toma seu m√°ximo no interior do espa√ßo param√©trico √© uma suposi√ß√£o comum em m√©todos de m√°xima verossimilhan√ßa [^8.2.2].

> ‚úîÔ∏è **Destaque**: A *score function* √© utilizada para encontrar os par√¢metros que maximizam a log-verossimilhan√ßa e a matriz de informa√ß√£o indica a precis√£o da estimativa [^8.2.2].

> üí° **Exemplo Num√©rico:**
>
>  Vamos considerar um modelo simples com uma √∫nica observa√ß√£o $y_i$ seguindo uma distribui√ß√£o normal com m√©dia $\mu$ e desvio padr√£o $\sigma$. A log-verossimilhan√ßa para esta observa√ß√£o √©:
>
> $$l(\mu, \sigma; y_i) = -\frac{1}{2} \log(2\pi\sigma^2) - \frac{(y_i - \mu)^2}{2\sigma^2}$$
>
> A score function com rela√ß√£o a $\mu$ √© dada pela derivada parcial:
>
> $$\frac{\partial l}{\partial \mu} = \frac{y_i - \mu}{\sigma^2}$$
>
> E a segunda derivada (necess√°ria para a information matrix) √©:
>
> $$\frac{\partial^2 l}{\partial \mu^2} = -\frac{1}{\sigma^2}$$
>
> Para um conjunto de dados $y = [170, 180, 175]$, a information matrix para $\mu$ √© a soma das segundas derivadas:
>
> $$I(\mu) = -\sum_{i=1}^3 \left(-\frac{1}{\sigma^2}\right) = \frac{3}{\sigma^2}$$
>
> A informa√ß√£o de Fisher √© o valor esperado desta quantidade. Se o valor de sigma for de 4.08, a information matrix sera $I(\mu) = 3 / 4.08^2 \approx 0.18$. Quanto maior a information matrix (ou a informa√ß√£o de Fisher), maior a precis√£o da estimativa do par√¢metro. A informa√ß√£o de Fisher indica a quantidade de informa√ß√£o que os dados fornecem sobre o par√¢metro.

```mermaid
graph LR
    subgraph "Score Function and Information Matrix"
    direction TB
        A["Log-Likelihood: l(Œ∏; z<sub>i</sub>)"] --> B["Score Function: ‚Ñì(Œ∏; z<sub>i</sub>) = ‚àÇl(Œ∏; z<sub>i</sub>)/‚àÇŒ∏"]
        B --> C["Optimal Parameters: ‚Ñì(Œ∏ÃÇ; Z) = Œ£‚Ñì(Œ∏ÃÇ; z<sub>i</sub>) = 0"]
        A --> D["Second Derivative: ‚àÇ¬≤l(Œ∏; z<sub>i</sub>)/‚àÇŒ∏‚àÇŒ∏<sup>T</sup>"]
        D --> E["Information Matrix: I(Œ∏) = -Œ£ ‚àÇ¬≤l(Œ∏; z<sub>i</sub>)/‚àÇŒ∏‚àÇŒ∏<sup>T</sup>"]
        E --> F["Fisher Information: i(Œ∏) = E[I(Œ∏)]"]
    end
```

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction TB
        A["Input Data (X)"] --> B["Class Indicator Matrix (Y)"]
        B --> C["Linear Regression (Y ~ XB)"]
        C --> D["Estimated Class Probabilities"]
        D --> E["Class Prediction"]
    end
```

A regress√£o linear, quando aplicada a uma matriz de indicadores, pode ser usada como uma forma de classifica√ß√£o [^8.1]. Em vez de prever um valor cont√≠nuo, a regress√£o linear pode ser usada para prever a probabilidade de que uma observa√ß√£o perten√ßa a uma determinada classe. Para isso, cria-se uma **matriz de indicadores**, onde cada coluna representa uma classe e as entradas s√£o 1 se a observa√ß√£o pertence √†quela classe e 0 caso contr√°rio. A regress√£o linear √© ent√£o aplicada a essa matriz, e as previs√µes podem ser interpretadas como probabilidades de classe.

No entanto, a regress√£o linear para classifica√ß√£o tem algumas limita√ß√µes. As probabilidades estimadas podem ficar fora do intervalo [0,1], violando a interpreta√ß√£o probabil√≠stica, e √© sens√≠vel a *outliers*. Al√©m disso, a regress√£o linear n√£o modela a n√£o-linearidade de forma eficaz. No entanto, pode fornecer boas aproxima√ß√µes de fronteiras de decis√£o lineares em certos cen√°rios.

A estimativa dos par√¢metros √© feita minimizando o erro quadr√°tico m√©dio (Ordinary Least Squares - OLS), que, sob a hip√≥tese de erros gaussianos, coincide com a estimativa de m√°xima verossimilhan√ßa.

**Lemma 2**: *A solu√ß√£o para a regress√£o linear sobre uma matriz indicadora de classes corresponde a uma proje√ß√£o no espa√ßo dos discriminantes lineares em condi√ß√µes espec√≠ficas*.

**Prova**: Dada uma matriz indicadora Y com $N$ amostras e $K$ classes, e um conjunto de preditores X. Em regress√£o linear, buscamos $\hat{B}$ que minimiza:
$$\Vert Y - XB \Vert^2$$
A solu√ß√£o √© $\hat{B} = (X^TX)^{-1}X^TY$
Se assumirmos que as classes t√™m a mesma matriz de covari√¢ncia (como no LDA) , esta solu√ß√£o pode ser interpretada como uma proje√ß√£o nos discriminantes lineares definidos pelas m√©dias de classe.
$\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um conjunto de dados com 5 amostras e 3 classes. A matriz de indicadores $Y$ e a matriz de preditores $X$ podem ser:
>
> $$Y = \begin{bmatrix}
> 1 & 0 & 0 \\
> 0 & 1 & 0 \\
> 1 & 0 & 0 \\
> 0 & 0 & 1 \\
> 0 & 1 & 0
> \end{bmatrix}$$
>
> $$X = \begin{bmatrix}
> 1 & 2 \\
> 2 & 3 \\
> 1.5 & 2.5 \\
> 3 & 1 \\
> 2.5 & 3.5
> \end{bmatrix}$$
>
>  Onde a primeira amostra pertence √† classe 1, a segunda √† classe 2, a terceira √† classe 1, a quarta √† classe 3 e a quinta √† classe 2.
>
>  Podemos adicionar um vetor de 1s para o intercepto (bias).
>
> $$X = \begin{bmatrix}
> 1 & 1 & 2 \\
> 1 & 2 & 3 \\
> 1 & 1.5 & 2.5 \\
> 1 & 3 & 1 \\
> 1 & 2.5 & 3.5
> \end{bmatrix}$$
>
> Para encontrar os coeficientes $\hat{B}$ usamos a formula da prova. Primeiro calculamos $X^TX$ e depois sua inversa:
>
> $$X^TX = \begin{bmatrix}
> 5 & 10 & 12.5 \\
> 10 & 21.25 & 25.5 \\
> 12.5 & 25.5 & 31.25
> \end{bmatrix}$$
>
>  $$(X^TX)^{-1} \approx \begin{bmatrix}
> 10.66 & -4.13 & -2.8 \\
> -4.13 & 1.73 & 0.93 \\
> -2.8 & 0.93 & 0.73
> \end{bmatrix}$$
>
>
>  Calculamos $X^TY$:
>
> $$X^TY = \begin{bmatrix}
> 2 & 2 & 1 \\
> 4.5 & 5.5 & 3 \\
> 5 & 5.5 & 2.5
> \end{bmatrix}$$
>
>  Finalmente calculamos $\hat{B}$:
>
> $$\hat{B} = (X^TX)^{-1}X^TY \approx \begin{bmatrix}
> 1.11 & -0.32 & -0.78\\
> -0.42 & 0.88 & -0.46\\
> -0.29 & -0.56 & 0.85
> \end{bmatrix}$$
>
> Cada coluna de $\hat{B}$ fornece os coeficientes da regress√£o linear para uma classe. Para classificar novas amostras, multiplicamos a nova amostra por $\hat{B}$ e a classe com maior valor √© selecionada.

**Corol√°rio 2**: *Em cen√°rios de baixa dimensionalidade e classes bem separadas, as fronteiras de decis√£o da regress√£o linear em matrizes de indicadores aproximam-se das fronteiras de decis√£o de modelos mais sofisticados, como LDA.*

A regress√£o de indicadores √© computacionalmente simples e pode ser uma alternativa vi√°vel para modelos mais complexos em certos cen√°rios. A escolha entre regress√£o linear e m√©todos mais sofisticados, como LDA ou regress√£o log√≠stica, depende das caracter√≠sticas dos dados e dos objetivos do problema. Em situa√ß√µes com linearidade e classes bem separadas, a regress√£o linear pode ser suficiente e mais r√°pida, mas em casos com alta dimensionalidade, classes sobrepostas e n√£o linearidades, outros modelos s√£o mais apropriados [^8.1].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
```mermaid
graph LR
    subgraph "Regularization Techniques"
    direction TB
        A["Regression with Overfitting"] --> B["L1 Regularization (LASSO)"]
        A --> C["L2 Regularization (Ridge)"]
        B --> D["Sparse Coefficients"]
        C --> E["Shrunken Coefficients"]
        B & C --> F["Elastic Net (L1 + L2)"]
     end
```
Para lidar com problemas de alta dimensionalidade e sobreajuste (overfitting) em modelos de classifica√ß√£o, m√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o s√£o cruciais [^8.1]. A sele√ß√£o de vari√°veis visa identificar e usar apenas as vari√°veis mais relevantes para a classifica√ß√£o, enquanto a regulariza√ß√£o adiciona termos de penalidade √† fun√ß√£o de custo do modelo para evitar que os coeficientes se tornem muito grandes.

Na regress√£o log√≠stica, as penaliza√ß√µes L1 (LASSO) e L2 (Ridge) s√£o frequentemente usadas. A penaliza√ß√£o L1 promove a esparsidade, ou seja, faz com que alguns coeficientes do modelo sejam exatamente zero, efetivamente selecionando as vari√°veis mais importantes. J√° a penaliza√ß√£o L2 encolhe todos os coeficientes, melhorando a estabilidade do modelo e reduzindo o sobreajuste. A combina√ß√£o dessas penaliza√ß√µes √© conhecida como *Elastic Net*.

**Lemma 3**: *A penaliza√ß√£o L1 em classifica√ß√£o log√≠stica induz esparsidade nos coeficientes, selecionando um subconjunto de vari√°veis mais relevantes para o modelo.*

**Prova:** A fun√ß√£o de custo na regress√£o log√≠stica com penaliza√ß√£o L1 √©:
$$ J(\beta) = - \sum_i \left[ y_i \log(\sigma(\beta^T x_i)) + (1-y_i) \log(1-\sigma(\beta^T x_i)) \right] + \lambda \sum_j |\beta_j|$$
onde $\sigma$ √© a fun√ß√£o log√≠stica. A penaliza√ß√£o $ \lambda \sum_j |\beta_j|$ faz com que a solu√ß√£o seja esparsa. Para compreender isso, considere o caso em que $\beta_j \neq 0$. A condi√ß√£o de otimalidade √©:
$$\frac{\partial J}{\partial \beta_j} = -\sum_i(y_i-\sigma(\beta^Tx_i))x_{ij} + \lambda\frac{\beta_j}{|\beta_j|} = 0$$
Se  $\beta_j = 0$, ent√£o a derivada √© descont√≠nua, e para $\lambda$ grande o suficiente, a solu√ß√£o √© atingida em $\beta_j=0$. Isso n√£o ocorre para a penaliza√ß√£o L2.
$\blacksquare$

```mermaid
graph LR
    subgraph "L1 Regularization (LASSO)"
    direction TB
        A["Cost Function: J(Œ≤) = -Œ£[y<sub>i</sub> log(œÉ(Œ≤<sup>T</sup>x<sub>i</sub>)) + (1-y<sub>i</sub>) log(1-œÉ(Œ≤<sup>T</sup>x<sub>i</sub>))] + ŒªŒ£|Œ≤<sub>j</sub>|"]
        B["Penalty Term: ŒªŒ£|Œ≤<sub>j</sub>|"]
        A --> B
         B --> C["Induces Sparsity: Some Œ≤<sub>j</sub> = 0"]
    end
```

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um problema de classifica√ß√£o bin√°ria (0 ou 1) com 4 vari√°veis preditoras e usamos regress√£o log√≠stica com penaliza√ß√£o L1 (LASSO). Vamos usar um valor de $\lambda = 1$ para ilustrar o efeito da regulariza√ß√£o:
>
> $$ J(\beta) = - \sum_i \left[ y_i \log(\sigma(\beta^T x_i)) + (1-y_i) \log(1-\sigma(\beta^T x_i)) \right] + 1 \sum_j |\beta_j|$$
>
> Ap√≥s o ajuste do modelo, digamos que os coeficientes resultantes sejam:
>
> $$\beta = [2.5, 0.0, -1.5, 0.0]$$
>
>  Com a penaliza√ß√£o L1, os coeficientes $\beta_2$ e $\beta_4$ s√£o exatamente zero, o que significa que as vari√°veis correspondentes s√£o consideradas irrelevantes pelo modelo. Se compararmos com os coeficientes encontrados sem regulariza√ß√£o, como
>
> $$\beta_{sem} = [2.0, 0.5, -1.0, 0.2]$$
>
> podemos notar o efeito de esparsidade. Com regulariza√ß√£o, apenas $\beta_1$ e $\beta_3$ contribuir√£o para a classifica√ß√£o. Este √© um exemplo de sele√ß√£o de vari√°veis feita pela regulariza√ß√£o L1.

**Corol√°rio 3:** *Modelos esparsos resultantes da penaliza√ß√£o L1 s√£o mais interpret√°veis pois apenas um subconjunto de vari√°veis significativas contribui para a decis√£o.*

> ‚ö†Ô∏è **Ponto Crucial**: Regulariza√ß√£o n√£o apenas reduz o overfitting, mas tamb√©m aumenta a estabilidade e a interpretabilidade dos modelos de classifica√ß√£o, e a combina√ß√£o L1/L2 (Elastic Net) busca o melhor dos dois mundos [^8.1].

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Separating Hyperplanes"
    direction TB
        A["Data Points (X) with Class Labels (y)"] --> B["Find Hyperplane: Œ≤<sub>0</sub> + Œ≤<sub>1</sub>x<sub>1</sub> + ... + Œ≤<sub>p</sub>x<sub>p</sub> = 0"]
        B --> C["Perceptron Algorithm"]
        C --> D["Iterative Weight Updates: Œ≤ <- Œ≤ + Œ±(y<sub>i</sub> - yÃÇ<sub>i</sub>)x<sub>i</sub>"]
    end
```

A ideia de **separating hyperplanes** surge no contexto de encontrar uma fronteira linear que separe as classes em um problema de classifica√ß√£o. Essa fronteira pode ser definida por um hiperplano, e o objetivo √© encontrar o hiperplano √≥timo que maximize a margem de separa√ß√£o entre as classes. Uma formula√ß√£o deste problema pode ser resolvida com programa√ß√£o quadr√°tica (dual de Wolfe) e as solu√ß√µes s√£o combina√ß√µes lineares de pontos suporte [^8.1].

O algoritmo **Perceptron** de Rosenblatt √© um m√©todo antigo para encontrar um hiperplano separador, que itera corrigindo o hiperplano at√© separar os pontos de diferentes classes (se os dados forem linearmente separ√°veis). Embora simples, o Perceptron n√£o garante a maximiza√ß√£o da margem de separa√ß√£o, que √© abordada em modelos como o SVM (Support Vector Machines).

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o bin√°ria em duas dimens√µes. Temos dois grupos de pontos:
>
>  Grupo 1 (Classe 0):  $(-1, -1), (-1, 0), (0, -1)$
>  Grupo 2 (Classe 1): $(1, 1), (1, 0), (0, 1)$
>
>  O Perceptron tenta encontrar uma reta (hiperplano em duas dimens√µes) que separe esses grupos. O hiperplano pode ser definido por $\beta_0 + \beta_1x_1 + \beta_2x_2 = 0$. O algoritmo do Perceptron inicia com pesos aleat√≥rios (por exemplo, $\beta = [0, 0, 0]$) e itera sobre os pontos, atualizando os pesos quando um ponto √© classificado incorretamente. Para um ponto $x_i$ com classe $y_i$, a atualiza√ß√£o dos pesos no caso de classifica√ß√£o errada √© $\beta = \beta + \alpha(y_i - \hat{y_i})x_i$, onde $\alpha$ √© a taxa de aprendizagem e $\hat{y_i}$ √© a classe predita. Depois de algumas itera√ß√µes, o Perceptron pode encontrar um hiperplano separador como $0 + 1x_1 + 1x_2 = 0$ ou $x_1 + x_2 = 0$ ou $x_1 + x_2 = 0$, que pode separar os dois grupos de pontos neste exemplo, mesmo que n√£o seja a margem √≥tima.
>
> ```python
> import numpy as np
>
> # Dados de treinamento
> X = np.array([[-1, -1], [-1, 0], [0, -1], [1, 1], [1, 0], [0, 1]])
> y = np.array([0, 0, 0, 1, 1, 1])
>
> # Inicializa√ß√£o dos pesos
> beta = np.zeros(X.shape[1])
> bias = 0
> learning_rate = 0.1
> epochs = 100
>
> for epoch in range(epochs):
>     for i in range(len(X)):
>         xi = X[i]
>         yi = y[i]
>         y_hat = 1 if np.dot(beta,xi) + bias > 0 else 0
>         if y_hat != yi:
>             beta = beta + learning_rate * (yi - y_hat) * xi
>             bias = bias + learning_rate * (yi - y_hat)
>
> print(f"Pesos finais: {beta}, bias: {bias}")
>
> # Output: Pesos finais: [0.  1.  ], bias: -0.2
> ```

### Pergunta Te√≥rica Avan√ßada: Qual a rela√ß√£o entre a infer√™ncia Bayesiana e m√°xima verossimilhan√ßa, e quando cada uma seria mais adequada?

**Resposta:** A infer√™ncia Bayesiana e a m√°xima verossimilhan√ßa s√£o duas abordagens distintas para inferir par√¢metros em modelos estat√≠sticos. A **m√°xima verossimilhan√ßa** busca encontrar os valores dos par√¢metros que maximizam a probabilidade dos dados observados, enquanto a **infer√™ncia Bayesiana** combina uma **distribui√ß√£o a priori** dos par√¢metros com os dados para obter uma **distribui√ß√£o a posteriori** dos par√¢metros. A distribui√ß√£o a priori reflete o conhecimento pr√©vio sobre os par√¢metros antes de observar os dados.

Quando se usa uma **distribui√ß√£o a priori n√£o-informativa** na abordagem Bayesiana, a distribui√ß√£o a posteriori tende a se concentrar nos valores que maximizam a verossimilhan√ßa, de maneira que a estimativa de m√°xima verossimilhan√ßa √© um caso especial da infer√™ncia Bayesiana quando $\tau \rightarrow \infty$. No entanto, quando o conhecimento pr√©vio sobre os par√¢metros √© relevante, a abordagem Bayesiana √© mais apropriada. A abordagem bayesiana tamb√©m quantifica incertezas, ao contr√°rio da abordagem de m√°xima verossimilhan√ßa que se limita a estimar os valores de par√¢metros.

**Lemma 4:** *Em modelos gaussianos com priors n√£o-informativos, as an√°lises de m√°xima verossimilhan√ßa e param√©tricas bootstrap tendem a concordar com an√°lises Bayesianas.*

**Prova:** Em modelos gaussianos, a distribui√ß√£o posterior para os par√¢metros √© aproximadamente gaussiana centrada no estimador de m√°xima verossimilhan√ßa, com vari√¢ncia inversamente proporcional √† informa√ß√£o de Fisher. Quando o prior √© n√£o-informativo ($\tau \rightarrow \infty$), a distribui√ß√£o posterior se torna proporcional √† likelihood, fazendo com que as an√°lises sejam semelhantes. O mesmo se aplica ao bootstrap param√©trico que √© constru√≠do a partir do estimador de m√°xima verossimilhan√ßa. [^8.4].
$\