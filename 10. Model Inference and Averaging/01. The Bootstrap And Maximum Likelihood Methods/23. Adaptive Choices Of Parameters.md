Okay, here's the revised text with the requested Mermaid diagrams:

## Adaptive Choices of Parameters in Statistical Learning

```mermaid
graph LR
    subgraph "Model Adaptation Framework"
        A["Adaptive Choices of Parameters"]
        B["Maximum Likelihood"]
        C["Bayesian Methods"]
        D["Bootstrap"]
        E["Bagging"]
        F["Stacking"]
        A --> B
        A --> C
        A --> D
        A --> E
        A --> F
    end
```

### Introdu√ß√£o

A adapta√ß√£o de par√¢metros √© um aspecto crucial no desenvolvimento de modelos estat√≠sticos robustos e eficazes. Em diversas situa√ß√µes, a escolha de par√¢metros fixos pode limitar a capacidade do modelo de se ajustar adequadamente aos dados, levando a resultados sub√≥timos. Modelos de aprendizado estat√≠stico, muitas vezes, necessitam de abordagens que permitam a adapta√ß√£o desses par√¢metros durante o processo de treinamento, visando alcan√ßar maior precis√£o e generaliza√ß√£o. Este cap√≠tulo aborda t√©cnicas de infer√™ncia e melhoria de modelos que se relacionam com a escolha adaptativa de par√¢metros, incluindo Maximum Likelihood, m√©todos Bayesianos, Bootstrap, Bagging e Stacking. A discuss√£o √© baseada no texto fornecido, explorando suas nuances te√≥ricas e pr√°ticas [^8.1].

### Conceitos Fundamentais

**Conceito 1:** O **problema de adapta√ß√£o de par√¢metros** surge quando a complexidade dos dados exige que os modelos ajustem seus par√¢metros dinamicamente. Abordagens tradicionais de *fitting* envolvem a minimiza√ß√£o de uma fun√ß√£o de custo, como soma de quadrados para regress√£o ou *cross-entropy* para classifica√ß√£o, que, na verdade, s√£o inst√¢ncias da abordagem de **Maximum Likelihood** [^8.1]. Contudo, esses m√©todos podem se tornar r√≠gidos quando aplicados a dados complexos.
A adapta√ß√£o busca permitir que o modelo se adapte de acordo com o que √© aprendido, mitigando o *bias* e controlando a *variance*.

**Lemma 1:** Para modelos lineares, a adapta√ß√£o de par√¢metros pode ser vista como uma forma de balancear o *trade-off* entre *bias* e *variance*. Um modelo com poucos par√¢metros (menos complexo) pode sofrer de *high bias*, enquanto um com muitos par√¢metros pode sofrer de *high variance*. A escolha adaptativa de par√¢metros permite encontrar um ponto √≥timo nesse balan√ßo [^8.1]. Formalmente, seja um modelo linear com par√¢metros $\theta$, o *bias* pode ser expresso como a diferen√ßa entre a m√©dia das predi√ß√µes e o valor verdadeiro, enquanto a *variance* representa a variabilidade das predi√ß√µes em diferentes amostras de treinamento. O objetivo √© minimizar ambas as quantidades, o que pode ser alcan√ßado por meio de t√©cnicas adaptativas que ajustam a complexidade do modelo de acordo com os dados.
$$ \text{Bias}(\theta) = \mathbb{E}_{\mathcal{D}}[\hat{f}_{\theta}(x)] - f(x) $$
$$ \text{Variance}(\theta) = \mathbb{E}_{\mathcal{D}}[(\hat{f}_{\theta}(x) - \mathbb{E}_{\mathcal{D}}[\hat{f}_{\theta}(x)])^2] $$
Onde $\hat{f}_{\theta}(x)$ √© a predi√ß√£o do modelo com par√¢metros $\theta$,  $\mathcal{D}$ √© o conjunto de dados de treino, e $f(x)$ √© o valor real.

> üí° **Exemplo Num√©rico:** Suponha que temos um conjunto de dados com uma rela√ß√£o quadr√°tica entre a vari√°vel independente *x* e a vari√°vel dependente *y*. Se tentarmos ajustar um modelo linear simples ($y = \beta_0 + \beta_1x$), teremos um *high bias*, pois o modelo n√£o √© capaz de capturar a curvatura da rela√ß√£o. Por outro lado, se usarmos um modelo polinomial de alta ordem ($y = \beta_0 + \beta_1x + \beta_2x^2 + \beta_3x^3 + ...$)  com muitos par√¢metros, podemos obter um *high variance*, pois o modelo se ajustaria muito bem aos dados de treinamento, mas teria um desempenho ruim com dados novos (overfitting).
>
> Considere um pequeno conjunto de dados:
> ```python
> import numpy as np
> from sklearn.linear_model import LinearRegression
> from sklearn.preprocessing import PolynomialFeatures
> from sklearn.metrics import mean_squared_error
>
> # Dados de exemplo
> x = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)
> y = np.array([2, 6, 7, 9, 15])
>
> # Modelo Linear
> linear_model = LinearRegression()
> linear_model.fit(x, y)
> y_pred_linear = linear_model.predict(x)
> mse_linear = mean_squared_error(y, y_pred_linear)
> print(f"MSE Linear: {mse_linear:.2f}")
>
> # Modelo Polinomial (Grau 3)
> poly = PolynomialFeatures(degree=3)
> x_poly = poly.fit_transform(x)
> poly_model = LinearRegression()
> poly_model.fit(x_poly, y)
> y_pred_poly = poly_model.predict(x_poly)
> mse_poly = mean_squared_error(y, y_pred_poly)
> print(f"MSE Polinomial: {mse_poly:.2f}")
> ```
>
>  Neste exemplo, o modelo linear ter√° um MSE maior devido ao *bias*, enquanto o modelo polinomial de grau 3 ter√° um MSE menor (ou at√© 0 se usarmos um polin√¥mio de grau 4). No entanto, em um cen√°rio com ru√≠do, o modelo polinomial de grau 3 poderia sofrer mais com *variance* em um novo conjunto de dados.
>
>
> ```mermaid
>  graph LR
>      A["Data"] --> B["Linear Model"];
>      A --> C["Polynomial Model"];
>      B --> D["High Bias"];
>      C --> E["High Variance"];
> ```
>
>  A escolha adaptativa de par√¢metros, atrav√©s de m√©todos como valida√ß√£o cruzada, nos ajudaria a encontrar o ponto √≥timo entre complexidade do modelo e generaliza√ß√£o.

**Conceito 2:** A **Linear Discriminant Analysis (LDA)** e suas varia√ß√µes, embora n√£o exploradas no texto, s√£o exemplos de modelos lineares que requerem a escolha dos par√¢metros de forma adaptativa.  A LDA busca encontrar a melhor proje√ß√£o linear dos dados que maximize a separa√ß√£o entre as classes. A escolha dos par√¢metros nessa proje√ß√£o √© crucial para a efici√™ncia do m√©todo [^8.1, 8.2]. A LDA assume que as classes seguem distribui√ß√µes gaussianas com a mesma matriz de covari√¢ncia. Para problemas onde essa hip√≥tese n√£o se sustenta, s√£o usadas abordagens que adaptam essa matriz [^8.1].
A constru√ß√£o da fronteira de decis√£o da LDA envolve a estimativa de m√©dias de classe e da matriz de covari√¢ncia.

**Corol√°rio 1:**  A adapta√ß√£o de par√¢metros, como vista em regulariza√ß√£o ou em m√©todos de *shrinkage*, pode ser usada em LDA para lidar com problemas de alta dimensionalidade,  onde o n√∫mero de par√¢metros a ser estimado (especialmente na matriz de covari√¢ncia) √© alto em compara√ß√£o com o tamanho da amostra. M√©todos como *Regularized Discriminant Analysis (RDA)* utilizam par√¢metros de regulariza√ß√£o para evitar o *overfitting*, adaptando a complexidade do modelo ao tamanho dos dados [^8.1].
$$ \text{Cov}(\hat{\mu}_k, \hat{\mu}_{k'}) = \frac{1}{n_k}\Sigma \delta_{k,k'} $$
Aqui $\hat{\mu}_k$ √© a m√©dia amostral da classe k, $n_k$ √© o n√∫mero de observa√ß√µes dessa classe, e $\Sigma$ √© a matriz de covari√¢ncia.

> üí° **Exemplo Num√©rico:**  Imagine que temos um problema de classifica√ß√£o com duas classes (A e B) e 10 vari√°veis preditoras.  A matriz de covari√¢ncia $\Sigma$ seria uma matriz 10x10.  Se tivermos poucos dados (digamos, menos de 100 amostras), a estimativa dessa matriz pode ser inst√°vel, resultando em *overfitting*.  RDA pode ser usado aqui. RDA introduz um par√¢metro de regulariza√ß√£o que 'encolhe' a matriz de covari√¢ncia em dire√ß√£o a uma matriz diagonal, ou seja, imp√µe a suposi√ß√£o de que as vari√°veis preditoras sejam menos correlacionadas entre si. Isso leva a uma estimativa mais robusta da matriz de covari√¢ncia e, consequentemente, a um melhor modelo de classifica√ß√£o.
>
> Vamos supor para simplificar que as m√©dias de cada classe s√£o $\mu_A = [1, 2, \ldots, 10]$ e $\mu_B = [2, 3, \ldots, 11]$. Usando dados sint√©ticos, podemos simular este cen√°rio:
>
> ```python
> import numpy as np
> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import accuracy_score
>
> # Gerar dados sint√©ticos
> np.random.seed(42)
> n_samples = 80
> n_features = 10
>
> # M√©dias das classes
> mu_A = np.arange(1, n_features + 1)
> mu_B = np.arange(2, n_features + 2)
>
> # Matriz de covari√¢ncia
> cov = np.eye(n_features)
>
> # Gerar amostras para classe A e B
> X_A = np.random.multivariate_normal(mu_A, cov, n_samples // 2)
> X_B = np.random.multivariate_normal(mu_B, cov, n_samples // 2)
>
> X = np.vstack((X_A, X_B))
> y = np.array([0] * (n_samples // 2) + [1] * (n_samples // 2))
>
> # Dividir dados
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # LDA
> lda = LinearDiscriminantAnalysis()
> lda.fit(X_train, y_train)
> y_pred_lda = lda.predict(X_test)
> acc_lda = accuracy_score(y_test, y_pred_lda)
>
> print(f"Acur√°cia LDA: {acc_lda:.2f}")
>
> # Sem regulariza√ß√£o RDA se reduz a LDA
>
> # Simular um problema com mais vari√°veis do que amostras (RDA com regulariza√ß√£o)
> # N√£o vamos mostrar o c√≥digo da RDA diretamente, apenas para demonstrar o problema
> n_samples_small = 30
> X_A_small = np.random.multivariate_normal(mu_A, cov, n_samples_small // 2)
> X_B_small = np.random.multivariate_normal(mu_B, cov, n_samples_small // 2)
> X_small = np.vstack((X_A_small, X_B_small))
> y_small = np.array([0] * (n_samples_small // 2) + [1] * (n_samples_small // 2))
> X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(X_small, y_small, test_size=0.3, random_state=42)
>
> lda_small = LinearDiscriminantAnalysis()
> lda_small.fit(X_train_small, y_train_small)
> y_pred_lda_small = lda_small.predict(X_test_small)
> acc_lda_small = accuracy_score(y_test_small, y_pred_lda_small)
> print(f"Acur√°cia LDA com poucas amostras: {acc_lda_small:.2f}")
>
> ```
>
>  O exemplo mostra que, com um n√∫mero menor de amostras, podemos ter uma redu√ß√£o na acur√°cia. A regulariza√ß√£o em RDA ajustaria a matriz de covari√¢ncia para melhorar a performance nessas condi√ß√µes, demonstrando como a adapta√ß√£o de par√¢metros √© necess√°ria para lidar com diferentes conjuntos de dados.

**Conceito 3:** A **Logistic Regression**, similarmente √† LDA,  √© um modelo que adapta seus par√¢metros (pesos) para melhor separar as classes [^8.1]. Na regress√£o log√≠stica, os par√¢metros s√£o ajustados maximizando a verossimilhan√ßa dos dados, de forma que a probabilidade predita de um caso pertencer a uma classe corresponda √† classe real.  O modelo busca os pesos que melhor ajustam uma *sigmoid function* aos dados, aprendendo a fronteira de decis√£o entre as classes.
> ‚ö†Ô∏è **Nota Importante**: O processo de maximiza√ß√£o da verossimilhan√ßa na regress√£o log√≠stica envolve a otimiza√ß√£o de uma fun√ß√£o n√£o-linear, que usualmente √© feita utilizando m√©todos iterativos [^8.1, 8.2].
> ‚ùó **Ponto de Aten√ß√£o**: Em problemas com classes desbalanceadas, a regress√£o log√≠stica pode ser usada com ajustes para mitigar o vi√©s em dire√ß√£o √† classe majorit√°ria [^8.1, 8.2].
> ‚úîÔ∏è **Destaque**:  Tanto LDA quanto regress√£o log√≠stica buscam por fronteiras de decis√£o lineares; contudo, a LDA busca maximizar a separabilidade das classes sob certas suposi√ß√µes, enquanto a regress√£o log√≠stica busca ajustar as probabilidades de classe aos dados [^8.1, 8.2].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
flowchart TD
    subgraph "Indicator Regression for Classification"
    A["Encode Classes into Indicator Matrix"]
    B["Estimate Coefficients via Least Squares"]
    C["Apply Decision Rule based on Indicators"]
    D["Compare with Probabilistic Methods"]
    A --> B
    B --> C
    C --> D
  end
```

**Explica√ß√£o:** Este diagrama representa o fluxo do processo de regress√£o de indicadores e como ele se relaciona √† classifica√ß√£o [^8.1, 8.2].

A regress√£o linear em matriz de indicadores pode ser usada na classifica√ß√£o, onde cada coluna da matriz representa uma classe, e os valores indicam a pertin√™ncia de cada observa√ß√£o a cada classe. Os coeficientes da regress√£o s√£o estimados minimizando a soma dos quadrados dos erros, buscando ajustar uma fun√ß√£o linear aos dados codificados [^8.1, 8.2].

Essa abordagem √© uma forma de adapta√ß√£o de par√¢metros,  onde os coeficientes se ajustam para refletir a rela√ß√£o entre os preditores e as classes. Contudo, a regress√£o linear para classifica√ß√£o pode sofrer de algumas limita√ß√µes. A minimiza√ß√£o dos quadrados pode resultar em estimativas que n√£o necessariamente se traduzem em boas probabilidades para as classes, e a sensibilidade a outliers e a quebra de pressupostos de normalidade dos erros podem afetar a qualidade dos resultados [^8.1].

**Lemma 2:** A regress√£o linear em uma matriz de indicadores pode ser equivalentemente vista como a procura por uma proje√ß√£o linear dos dados que maximize a separa√ß√£o entre as classes. Em outras palavras, os coeficientes obtidos pela regress√£o linear formam um conjunto de hiperplanos de decis√£o. Matematicamente, se $Y$ for a matriz de indicadores e $X$ a matriz de *design*, os coeficientes $\beta$ que minimizam a soma dos quadrados dos erros  $|Y-X\beta|^2$ podem ser usados para construir as fronteiras de decis√£o, que s√£o lineares no espa√ßo de $X$. Essa conex√£o entre proje√ß√µes lineares e a abordagem por m√≠nimos quadrados ressalta como os par√¢metros s√£o adaptados em modelos lineares de classifica√ß√£o [^8.1, 8.2].
$$ \beta = (X^TX)^{-1}X^TY $$
onde $\beta$ s√£o os coeficientes, $X$ √© a matriz de *design*, e $Y$ √© a matriz de indicadores.

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com tr√™s classes. Cada amostra √© descrita por duas vari√°veis preditoras $x_1$ e $x_2$. A matriz de indicadores $Y$ ser√° uma matriz com tr√™s colunas (uma para cada classe) e cada linha representar√° uma amostra. O valor na coluna correspondente √† classe correta ser√° 1, e 0 nas outras colunas.
>
> Vamos criar dados sint√©ticos para ilustrar este processo:
> ```python
> import numpy as np
> from sklearn.linear_model import LinearRegression
> from sklearn.preprocessing import OneHotEncoder
>
> # Dados sint√©ticos
> X = np.array([[1, 2], [2, 3], [3, 2], [5, 8], [6, 9], [7, 8], [1, 8], [2, 9], [3, 8]])
> y = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2]) # 3 Classes
>
> # Codificar as classes usando OneHotEncoder
> encoder = OneHotEncoder(sparse_output=False)
> Y = encoder.fit_transform(y.reshape(-1, 1))
>
> # Regress√£o Linear
> model = LinearRegression()
> model.fit(X, Y)
>
> # Previs√µes
> Y_pred = model.predict(X)
> print("Matriz de Indicadores Y:")
> print(Y)
> print("Matriz Y Predita:")
> print(Y_pred)
>
> # Obter a classe predita para cada amostra (classe com maior valor predito)
> y_pred_class = np.argmax(Y_pred, axis=1)
> print("Classes Preditas:")
> print(y_pred_class)
>
> # Visualizar os coeficientes
> print("Coeficientes:")
> print(model.coef_)
> print("Interceptos:")
> print(model.intercept_)
> ```
>
> O c√≥digo acima mostra como a regress√£o linear pode ser usada para classifica√ß√£o. O `OneHotEncoder` transforma as classes em um formato adequado para a regress√£o. Os coeficientes obtidos representam os pesos das vari√°veis preditoras para cada classe, e a predi√ß√£o √© feita atribuindo cada amostra √† classe com o maior valor predito. A matriz de coeficientes `model.coef_` e os interceptos `model.intercept_` representam os hiperplanos de decis√£o que separam as classes no espa√ßo de caracter√≠sticas.  Note que as predi√ß√µes `Y_pred` n√£o s√£o probabilidades, mas podem ser usadas para classificar as amostras.

**Corol√°rio 2:** O Lemma 2 implica que, em certos cen√°rios onde a separabilidade linear √© suficiente, a regress√£o linear pode ser uma ferramenta v√°lida para a classifica√ß√£o. Em situa√ß√µes mais complexas, a regress√£o linear pode n√£o ser capaz de capturar todas as nuances da rela√ß√£o entre preditores e classes, requerendo m√©todos mais sofisticados como os explorados posteriormente neste cap√≠tulo. Entretanto, a equival√™ncia demonstra uma das primeiras abordagens para adapta√ß√£o de par√¢metros a problemas de classifica√ß√£o [^8.1, 8.2].

A regress√£o log√≠stica, por sua vez, busca estimar probabilidades diretamente, ao contr√°rio da regress√£o de indicadores, que pode extrapolar valores fora do intervalo [0, 1] [^8.1]. A escolha entre esses m√©todos depende da natureza do problema e da necessidade de estimar probabilidades confi√°veis ou apenas construir uma fronteira de decis√£o adequada.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
```mermaid
graph LR
    subgraph "Regularization Techniques in Classification"
        A["L1 Regularization (Lasso)"]
        B["L2 Regularization (Ridge)"]
        C["Elastic Net"]
        D["Logistic Regression"]
        E["LDA and Other Models"]
        A --> D
        A --> E
        B --> D
        B --> E
        C --> D
        C --> E
        style A fill:#f9f,stroke:#333,stroke-width:2px
        style B fill:#ccf,stroke:#333,stroke-width:2px
        style C fill:#9f9,stroke:#333,stroke-width:2px
    end
```
Na classifica√ß√£o, a sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o cruciais para evitar o *overfitting* e melhorar a generaliza√ß√£o do modelo. A regulariza√ß√£o imp√µe restri√ß√µes aos par√¢metros do modelo, reduzindo sua complexidade e evitando que ele se ajuste excessivamente aos ru√≠dos nos dados de treinamento. A penaliza√ß√£o L1 (Lasso) promove *sparsity* nos par√¢metros, o que significa que alguns coeficientes s√£o levados a zero, realizando, simultaneamente, sele√ß√£o de vari√°veis e ajuste do modelo [^8.1, 8.4.4, 8.5]. A penaliza√ß√£o L2 (Ridge), por sua vez, reduz a magnitude dos par√¢metros, o que estabiliza o modelo e ajuda a lidar com multicolinearidade.

Em modelos log√≠sticos, a fun√ß√£o de custo √© modificada para incluir os termos de penaliza√ß√£o,  que s√£o adicionados √† fun√ß√£o de *log-likelihood*. A penaliza√ß√£o L1 √© especialmente √∫til quando se espera que apenas um subconjunto de vari√°veis seja relevante para a classifica√ß√£o,  enquanto a L2 √© mais apropriada quando todas as vari√°veis podem contribuir para a classifica√ß√£o, mas nenhuma deve ter um peso excessivo.  A combina√ß√£o das duas penaliza√ß√µes no *Elastic Net*  permite aproveitar as vantagens de ambas as abordagens [^8.1, 8.4.4, 8.5, 8.5.1, 8.5.2].

**Lemma 3:** A penaliza√ß√£o L1 na classifica√ß√£o log√≠stica resulta em um modelo com coeficientes esparsos devido √† natureza do termo de penalidade. A norma L1 for√ßa os coeficientes de caracter√≠sticas n√£o relevantes para zero,  o que √© √∫til em problemas com muitas vari√°veis e poucos exemplos, ou quando se deseja selecionar as caracter√≠sticas mais importantes.
Matematicamente, a fun√ß√£o de custo em uma regress√£o log√≠stica com penaliza√ß√£o L1 √© dada por:
$$J(\beta) = - \frac{1}{N} \sum_{i=1}^{N} [y_i \log(p_i) + (1-y_i) \log(1-p_i)] + \lambda \sum_{j=1}^{p} |\beta_j|$$
Onde $p_i$ √© a probabilidade estimada da classe para o exemplo $i$, $\beta_j$ √© o j-√©simo coeficiente, e $\lambda$ √© o par√¢metro de regulariza√ß√£o que controla a intensidade da penalidade L1.  A derivada do termo da penalidade com respeito a $\beta_j$ √© $\lambda \cdot \text{sign}(\beta_j)$ (onde $\text{sign}(\cdot)$ √© a fun√ß√£o sinal), que for√ßa os coeficientes a zero.

**Prova do Lemma 3:**
A derivada do termo de penaliza√ß√£o com respeito a $\beta_j$ √© $\lambda \cdot \text{sign}(\beta_j)$. Em otimiza√ß√£o, a solu√ß√£o para um problema com penaliza√ß√£o L1 envolve frequentemente um *soft-thresholding*  dos coeficientes. Isso faz com que os coeficientes menores em magnitude sejam exatamente zerados, e os maiores s√£o reduzidos em uma quantia proporcional a $\lambda$, levando a um modelo esparso. $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com 5 vari√°veis preditoras, onde apenas 2 vari√°veis s√£o realmente relevantes para a classifica√ß√£o. Se usarmos regress√£o log√≠stica sem regulariza√ß√£o, todos os coeficientes podem ter valores diferentes de zero. No entanto, com a penaliza√ß√£o L1 (Lasso), o modelo tentar√° zerar os coeficientes das 3 vari√°veis irrelevantes.
>
> Vamos simular este cen√°rio usando dados sint√©ticos:
>
> ```python
> import numpy as np
> import pandas as pd
> from sklearn.linear_model import LogisticRegression
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import accuracy_score
> from sklearn.preprocessing import StandardScaler
>
> # Dados sint√©ticos
> np.random.seed(42)
> n_samples = 100
> n_features = 5
>
> # Criar uma matriz de features com 5 vari√°veis
> X = np.random.rand(n_samples, n_features)
>
> # Criar um vetor de resposta com base em apenas duas features
> beta_true = np.array([2, -3, 0, 0, 0])
> y_probs = 1 / (1 + np.exp(-(X @ beta_true + 0.5)))
> y = np.random.binomial(1, y_probs)
>
>
> # Dividir os dados
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Padronizar os dados
> scaler = StandardScaler()
> X_train_scaled = scaler.fit_transform(X_train)
> X_test_scaled = scaler.transform(X_test)
>
> # Regress√£o log√≠stica sem regulariza√ß√£o
> model_no_reg = LogisticRegression(penalty=None)
> model_no_reg.fit(X_train_scaled, y_train)
> y_pred_no_reg = model_no_reg.predict(X_test_scaled)
> acc_no_reg = accuracy_score(y_test, y_pred_no_reg)
>
> # Regress√£o log√≠stica com regulariza√ß√£o L1
> model_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=0.5)
> model_l1.fit(X_train_scaled, y_train)
> y_pred_l1 = model_l1.predict(X_test_scaled)
> acc_l1 = accuracy_score(y_test, y_pred_l1)
>
>
> print(f"Acur√°cia sem regulariza√ß√£o: {acc_no_reg:.2f}")
> print(f"Acur√°cia com L1 regulariza√ß√£o: {acc_l1:.2f}")
>
> # Imprimir os coeficientes
> print("Coeficientes sem regulariza√ß√£o:")
> print(model_no_reg.coef_)
> print("Coeficientes com regulariza√ß√£o L1:")
> print(model_l1.coef_)
>
> # Tabela comparativa
> results = pd.DataFrame({'Method': ['No Regularization', 'L1 Regularization'],
>                       'Accuracy': [acc_no_reg, acc_l1],
>                       'Coefficients': [model_no_reg.coef_, model_l1.coef_] })
> print("\nComparative Table:")
> print(results)
> ```
>
> O resultado mostrar√° que os coeficientes das vari√°veis irrelevantes s√£o pr√≥ximos de zero no modelo com regulariza√ß√£o L1, enquanto no modelo sem regulariza√ß√£o todos os coeficientes ter√£o valores diferentes de zero, demonstrando o efeito da penaliza√ß√£o L1 na sele√ß√£o de vari√°veis.  A tabela permite a f√°cil compara√ß√£o entre as duas abordagens.

**Corol√°rio 3:** A esparsidade induzida pela penaliza√ß√£o L1 n√£o s√≥ melhora a generaliza√ß√£o, mas tamb√©m a interpretabilidade do modelo.  Ao selecionar apenas as vari√°veis mais relevantes, o modelo se torna mais simples e mais f√°cil de entender, focando nas caracter√≠sticas mais importantes para a tarefa de classifica√ß√£o. Al√©m disso, ao usar um m√©todo como o *Elastic Net*, pode-se combinar a sele√ß√£o de vari√°veis com a estabilidade fornecida pela penaliza√ß√£o L2 [^8.1, 8.4.4, 8.5].

> ‚ö†Ô∏è **Ponto Crucial**:  As penalidades L1 e L2 s√£o par√¢metros de regulariza√ß√£o que precisam ser ajustados por meio de m√©todos como valida√ß√£o cruzada.  A escolha da penalidade e o seu respectivo par√¢metro dependem da complexidade do problema e do *trade-off* desejado entre vi√©s e vari√¢ncia [^8.1, 8.4.4, 8.5].

### Separating Hyperplanes e Perceptrons
The concept of **separating hyperplanes** in classification is fundamental for building linear models that aim to divide the feature space into regions corresponding to different classes. Maximizing the margin between these classes leads to the formulation of optimal hyperplanes, which seek to ensure the best possible generalization. The optimization problem associated with constructing these hyperplanes can be solved using methods like the Wolfe dual formulation, where the solution is expressed as a linear combination of support vectors [^8.1, 8.5.2].

The **Rosenblatt Perceptron** is a classic algorithm for adjusting hyperplanes in linearly separable classification problems. The Perceptron updates its weights iteratively until it converges to a hyperplane that separates the classes. Convergence is guaranteed if the classes are linearly separable, and the algorithm works based on iterations that aim to minimize the classification error, adaptively adjusting the weights at each iteration [^8.1, 8.5.1].

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**

A LDA e a Regra de Decis√£o Bayesiana s√£o ambas baseadas na suposi√ß√£o de que os dados seguem uma distribui√ß√£o Gaussiana,  mas elas diferem na forma como calculam a probabilidade de um ponto pertencer a uma classe. A LDA deriva a fun√ß√£o discriminante linear ao maximizar a separa√ß√£o entre as classes, assumindo que as classes t√™m a mesma matriz de covari√¢ncia. Por outro lado, a Regra de Decis√£o Bayesiana calcula a probabilidade *a posteriori* de um ponto pertencer a uma classe usando as densidades Gaussianas e as probabilidades *a priori* das classes.
Sob a premissa de igualdade das matrizes de covari√¢ncia, a fronteira de decis√£o da LDA e da regra de decis√£o Bayesiana se tornam equivalentes,  pois ambas as abordagens levam a uma fronteira de decis√£o linear [^8.1, 8.3].

```mermaid
graph LR
    subgraph "Comparison of LDA and Bayesian Decision Rule"
        A["LDA: Maximizes Class Separation"]
        B["Bayesian Rule: Computes Posterior Probabilities"]
        C["Assumption: Gaussian Distributions"]
        D["Assumption: Equal Covariance Matrices"]
        E["Result: Equivalent Linear Decision Boundary"]
        A --> C
        B --> C
        C --> D
        D --> E
    end
```

**Lemma 4:** A equival√™ncia entre LDA e a regra de decis√£o Bayesiana com covari√¢ncias iguais decorre da forma da fun√ß√£o discriminante. Na LDA, a fun√ß√£o discriminante linear √© obtida ao projetar os dados em uma dire√ß√£o que maximize a separa√ß√£o entre as classes, assumindo covari√¢ncias iguais. Na regra de decis√£o Bayesiana, com covari√¢ncias iguais, a forma da fun√ß√£o *log-odds* leva a um discriminante linear, que √© id√™ntico √†quele da LDA.  Isso pode ser demonstrado formalmente mostrando que as equa√ß√µes da fronteira de decis√£o nos dois m√©todos s√£o equivalentes sob essas hip√≥teses.
$$ \text{LDA: } \delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log \pi_k $$
$$ \text{Bayes: } \log \frac{P(G=k|X=x)}{P(G=l|X=x)} = x^T \Sigma^{-1} (\mu_k - \mu_l) - \frac{1}{2} (\mu_k^T \Sigma^{-1} \mu_k - \mu_l^T \Sigma^{-1} \mu_l) + \log \frac{\pi_k}{\pi_l} $$

**Corol√°rio 4:** Ao relaxar a hip√≥tese de covari√¢ncias iguais, surge o *Quadratic Discriminant Analysis* (QDA),  onde as fronteiras de decis√£o passam a ser quadr√°ticas. A regra de decis√£o Bayesiana com covari√¢ncias diferentes para cada classe tamb√©m leva a fronteiras de decis√£o quadr√°ticas, e isso difere substancialmente do LDA, que assume linearidade da fronteira. A LDA, com a simplifica√ß√£o das covari√¢ncias iguais,  visa maior generaliza√ß√£o, enquanto a QDA tem maior flexibilidade, mas √© mais suscet√≠vel a *overfitting* [^8.1, 8.3].

> ‚ö†Ô∏è **Ponto Crucial**: A escolha de covari√¢ncias iguais ou n√£o iguais tem um impacto grande no tipo de fronteira de decis√£o,  com a igualdade resultando em fronteiras lineares e a desigualdade em fronteiras quadr√°ticas. Essa escolha tamb√©m tem influ√™ncia sobre a complexidade do modelo e sua capacidade de generaliza√ß√£o. [^8.1, 8.3, 8.3.1].

### Conclus√£o

A adapta√ß√£o de par√¢metros √© um tema central em aprendizado estat√≠stico,  e as abordagens discutidas neste cap√≠tulo fornecem ferramentas para lidar com essa complexidade. Desde o ajuste de modelos lineares at√© abordagens Bayesianas e m√©todos como *Bagging* e *Stacking*, cada t√©cnica oferece maneiras diferentes de ajustar modelos aos dados, balanceando o *trade-off* entre *bias* e *variance* e melhorando a capacidade de generaliza√ß√£o.
<!-- END DOCUMENT -->
### Footnotes
[^8.1]: "For most of this book, the fitting (learning) of models has been achieved by minimizing a sum of squares for regression, or by minimizing cross-entropy for classification. In fact, both of these minimizations are instances of the maximum likelihood approach to fitting. In this chapter we provide a general exposition of the maximum likelihood approach, as well as the Bayesian method for inference. The bootstrap, introduced in Chapter 7, is discussed in this context, and its relation to maximum likelihood and Bayes is described. Finally, we present some related techniques for model averaging and improvement, including committee methods, bagging, stacking and bumping." *(Trecho de Model Inference and Averaging)*
[^8.2]: "Denote the training data by Z = {z1, z2,..., zn}, with zi = (xi, yi), i = 1,2,..., N. Here xi is a one-dimensional input, and yi the outcome, either continuous or categorical." *(Trecho de Model Inference and Averaging)*
[^8.3]: "Suppose we decide to fit a cubic spline to the data, with three knots placed at the quartiles of the X values. This is a seven-dimensional linear space of functions, and can be represented, for example, by a linear expansion of B-spline basis functions (see Section 5.9.2):" *(Trecho de Model Inference and Averaging)*
[^8.4.4]: "In general, the parametric bootstrap agrees not with least squares but with maximum likelihood, which we now review." *(Trecho de Model Inference and Averaging)*
[^8.5]: "The bootstrap method described above, in which we sample with replacement from the training data, is called the nonparametric bootstrap. This really means that the method is "model-free," since it uses the raw data, not a specific parametric model, to generate new datasets. Consider a variation of the bootstrap, called the parametric bootstrap, in which we simulate new responses by adding Gaussian noise to the predicted values:" *(Trecho de Model Inference and Averaging)*
[^8.5.1]:  "In essence the bootstrap is a computer implementation of nonparametric or parametric maximum likelihood." *(Trecho de Model Inference and Averaging)*
[^8.5.2]: "The advantage of the bootstrap over the maximum likelihood formula is that it allows us to compute maximum likelihood estimates of standard errors and other quantities in settings where no formulas are available." *(Trecho de Model Inference and Averaging)*
