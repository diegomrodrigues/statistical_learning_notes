## Model Inference and Averaging: A Deep Dive into Parametric Models

<imagem: Mapa mental abrangente que conecta os m√©todos de infer√™ncia e model averaging, incluindo bootstrap, maximum likelihood, m√©todos bayesianos e t√©cnicas de combina√ß√£o de modelos como bagging e stacking, com foco em modelos param√©tricos>

### Introdu√ß√£o

Este cap√≠tulo explora m√©todos de infer√™ncia e model averaging, com foco em **modelos param√©tricos**, que s√£o modelos cujas distribui√ß√µes s√£o governadas por um n√∫mero finito de par√¢metros [^8.1]. A modelagem estat√≠stica, tanto para regress√£o quanto para classifica√ß√£o, muitas vezes envolve a otimiza√ß√£o de um crit√©rio de ajuste como a soma dos quadrados ou a entropia cruzada. De fato, essas minimiza√ß√µes s√£o inst√¢ncias do m√©todo de **m√°xima verossimilhan√ßa**. Este cap√≠tulo fornece uma exposi√ß√£o geral da abordagem de m√°xima verossimilhan√ßa e m√©todos Bayesianos, discutindo a rela√ß√£o entre o bootstrap, introduzido no Cap√≠tulo 7, m√°xima verossimilhan√ßa e abordagens Bayesianas [^8.1]. Finalmente, t√©cnicas de model averaging e melhoramento do modelo como committee methods, bagging, stacking e bumping s√£o apresentadas [^8.1].

### Conceitos Fundamentais

**Conceito 1: M√°xima Verossimilhan√ßa**

A abordagem de **m√°xima verossimilhan√ßa** busca encontrar os valores dos par√¢metros de um modelo que maximizam a probabilidade dos dados observados. Formalmente, dado um conjunto de dados $Z = \{z_1, z_2, \ldots, z_N\}$, onde cada $z_i$ √© uma observa√ß√£o, e um modelo param√©trico $g_\theta(z)$ que descreve a probabilidade dos dados, o objetivo √© encontrar o valor $\hat{\theta}$ que maximiza a fun√ß√£o de verossimilhan√ßa [^8.2.2]:

$$
L(\theta; Z) = \prod_{i=1}^N g_\theta(z_i)
$$

Em vez de maximizar diretamente a verossimilhan√ßa, muitas vezes maximizamos a **log-verossimilhan√ßa**, que √© dada por:

$$
l(\theta; Z) = \sum_{i=1}^N \log g_\theta(z_i)
$$

Isso simplifica a otimiza√ß√£o e n√£o altera o resultado [^8.2.2]. A m√°xima verossimilhan√ßa √© um conceito central na infer√™ncia estat√≠stica, fornecendo uma base para estimar par√¢metros em uma ampla variedade de modelos.

```mermaid
graph LR
    subgraph "Maximum Likelihood Estimation"
        direction TB
        A["Data: Z = {z_1, z_2, ..., z_N}"]
        B["Parametric Model: g_Œ∏(z)"]
        C["Likelihood Function: L(Œ∏; Z) = Œ† g_Œ∏(z_i)"]
        D["Log-Likelihood Function: l(Œ∏; Z) = Œ£ log g_Œ∏(z_i)"]
        E["Maximize l(Œ∏; Z) to find Œ∏ÃÇ"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

> üí° **Exemplo Num√©rico:** Considere um modelo param√©trico simples onde cada observa√ß√£o $z_i$ segue uma distribui√ß√£o normal com m√©dia $\mu$ e desvio padr√£o $\sigma$, ou seja, $g_\theta(z_i) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(z_i - \mu)^2}{2\sigma^2}}$, onde $\theta = (\mu, \sigma)$. Suponha que temos um conjunto de dados $Z = \{2, 4, 6, 8, 10\}$. Para encontrar a estimativa de m√°xima verossimilhan√ßa dos par√¢metros, primeiro calculamos a log-verossimilhan√ßa:
>
> $$
> l(\mu, \sigma; Z) = \sum_{i=1}^N \log \left( \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(z_i - \mu)^2}{2\sigma^2}} \right) = - \frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^N (z_i - \mu)^2
> $$
>
>  Para maximizar essa fun√ß√£o, derivamos parcialmente em rela√ß√£o a $\mu$ e $\sigma$ e igualamos a zero.  As derivadas s√£o:
>
> $$
> \frac{\partial l}{\partial \mu} = \frac{1}{\sigma^2} \sum_{i=1}^N (z_i - \mu)
> $$
> $$
> \frac{\partial l}{\partial \sigma} = -\frac{N}{\sigma} + \frac{1}{\sigma^3} \sum_{i=1}^N (z_i - \mu)^2
> $$
>
> Igualando a zero e resolvendo, obtemos as estimativas de m√°xima verossimilhan√ßa:
>
> $$
> \hat{\mu} = \frac{1}{N} \sum_{i=1}^N z_i
> $$
> $$
> \hat{\sigma}^2 = \frac{1}{N} \sum_{i=1}^N (z_i - \hat{\mu})^2
> $$
>
> Para o conjunto de dados dado $Z$, temos:
>
> $$
> \hat{\mu} = \frac{2+4+6+8+10}{5} = 6
> $$
> $$
> \hat{\sigma}^2 = \frac{(2-6)^2 + (4-6)^2 + (6-6)^2 + (8-6)^2 + (10-6)^2}{5} = \frac{16+4+0+4+16}{5} = 8
> $$
>
> Assim, as estimativas de m√°xima verossimilhan√ßa para $\mu$ e $\sigma$ s√£o $\hat{\mu} = 6$ e $\hat{\sigma} = \sqrt{8} \approx 2.83$.  Isso significa que o modelo gaussiano que melhor se ajusta aos dados, no sentido de m√°xima verossimilhan√ßa, √© uma gaussiana com m√©dia 6 e desvio padr√£o $\sqrt{8}$.

**Lemma 1:** _Sob certas condi√ß√µes de regularidade, os estimadores de m√°xima verossimilhan√ßa s√£o assintoticamente consistentes e eficientes. Isso significa que, conforme o tamanho da amostra aumenta, eles convergem para os verdadeiros valores dos par√¢metros e alcan√ßam a menor vari√¢ncia poss√≠vel._ [^8.2.2]

*Prova (esbo√ßo):* As condi√ß√µes de regularidade incluem a suavidade da fun√ß√£o de log-verossimilhan√ßa e a exist√™ncia de derivadas de primeira e segunda ordem. Sob essas condi√ß√µes, a distribui√ß√£o do estimador $\hat{\theta}$ se aproxima de uma distribui√ß√£o normal com m√©dia no verdadeiro valor do par√¢metro $\theta_0$ e vari√¢ncia dada pela inversa da informa√ß√£o de Fisher, ou seja, $\hat{\theta} \to \mathcal{N}(\theta_0, I^{-1}(\theta_0))$. $\blacksquare$

**Conceito 2: Bootstrap**

O m√©todo **bootstrap** fornece uma forma computacional de avaliar a incerteza, atrav√©s da reamostragem dos dados de treinamento. No contexto de um modelo param√©trico, temos o **parametric bootstrap**, onde, em vez de reamostrar os dados originais, simulamos novos conjuntos de dados com base no modelo estimado. Por exemplo, dada uma estimativa $\hat{\theta}$ de um modelo param√©trico, podemos gerar dados bootstrap, $z_i^* \sim g_{\hat{\theta}}(z)$, para $i = 1, 2, \ldots, N$, onde $g_{\hat{\theta}}(z)$ √© a distribui√ß√£o estimada do modelo [^8.2.1].  Reajustando o modelo para cada conjunto de dados bootstrap, podemos criar uma distribui√ß√£o emp√≠rica das estimativas dos par√¢metros e/ou previs√µes, nos permitindo inferir incertezas e gerar intervalos de confian√ßa.

```mermaid
graph LR
    subgraph "Parametric Bootstrap"
        direction TB
        A["Estimate parameters: Œ∏ÃÇ"]
        B["Simulate bootstrap data: z·µ¢* ~ g_Œ∏ÃÇ(z)"]
        C["Re-fit model to each bootstrap sample: Œ∏ÃÇ*"]
        D["Generate empirical distribution of Œ∏ÃÇ*"]
        E["Infer uncertainties and create confidence intervals"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

> üí° **Exemplo Num√©rico:** Usando o exemplo anterior, com $\hat{\mu} = 6$ e $\hat{\sigma} = \sqrt{8}$, podemos aplicar o bootstrap param√©trico para estimar a incerteza em $\hat{\mu}$.
>
> 1.  **Gera√ß√£o de amostras bootstrap:** Simulamos $B=1000$ amostras de tamanho $N=5$ de uma distribui√ß√£o normal com $\mu = 6$ e $\sigma = \sqrt{8}$.
>
>    ```python
>    import numpy as np
>    import matplotlib.pyplot as plt
>    from scipy.stats import norm
>
>    np.random.seed(42)
>    mu_hat = 6
>    sigma_hat = np.sqrt(8)
>    B = 1000
>    N = 5
>    bootstrap_means = []
>    for _ in range(B):
>        bootstrap_sample = np.random.normal(loc=mu_hat, scale=sigma_hat, size=N)
>        bootstrap_mean = np.mean(bootstrap_sample)
>        bootstrap_means.append(bootstrap_mean)
>
>    plt.hist(bootstrap_means, bins=30, density=True, alpha=0.7, color='skyblue')
>    plt.xlabel('Bootstrap Mean Estimates')
>    plt.ylabel('Density')
>    plt.title('Histogram of Bootstrap Mean Estimates')
>    plt.show()
>    ```
>
> 2.  **C√°lculo da distribui√ß√£o dos par√¢metros:** Calculamos a m√©dia e o desvio padr√£o das m√©dias bootstrap.
>
>    ```python
>    mean_of_bootstrap_means = np.mean(bootstrap_means)
>    std_of_bootstrap_means = np.std(bootstrap_means)
>    print(f"Mean of bootstrap means: {mean_of_bootstrap_means:.2f}")
>    print(f"Std. Dev. of bootstrap means: {std_of_bootstrap_means:.2f}")
>    ```
>
>    ```text
>    Mean of bootstrap means: 6.00
>    Std. Dev. of bootstrap means: 1.22
>    ```
>
> 3.  **Constru√ß√£o do intervalo de confian√ßa:** Usando o desvio padr√£o das m√©dias bootstrap, um intervalo de confian√ßa de 95% pode ser constru√≠do aproximadamente como $\hat{\mu} \pm 1.96 \cdot std(\hat{\mu}_{boot})$.
>
>    ```python
>    confidence_interval = (mean_of_bootstrap_means - 1.96 * std_of_bootstrap_means,
>                         mean_of_bootstrap_means + 1.96 * std_of_bootstrap_means)
>    print(f"95% Confidence Interval: {confidence_interval}")
>    ```
>
>    ```text
>    95% Confidence Interval: (3.605, 8.394)
>    ```
>
> O histograma mostra a distribui√ß√£o das m√©dias das amostras bootstrap, enquanto o intervalo de confian√ßa fornece uma estimativa da incerteza associada √† nossa estimativa do par√¢metro $\mu$.

**Corol√°rio 1:** _O bootstrap param√©trico, sob a suposi√ß√£o de que o modelo param√©trico est√° correto, fornece aproxima√ß√µes para os intervalos de confian√ßa dos par√¢metros que s√£o consistentes com a distribui√ß√£o assint√≥tica dos estimadores de m√°xima verossimilhan√ßa._ [^8.2.1]

*Prova (esbo√ßo):* Em casos onde os erros do modelo s√£o Gaussianos, o bootstrap param√©trico leva aos mesmos intervalos de confian√ßa que o m√©todo de m√≠nimos quadrados. Em geral, quando os erros n√£o s√£o Gaussianos, o bootstrap concorda com m√°xima verossimilhan√ßa, usando a fun√ß√£o de probabilidade dos dados gerados parametricamente  [^8.2.2]. $\blacksquare$

**Conceito 3: Infer√™ncia Bayesiana**

A **infer√™ncia Bayesiana** incorpora cren√ßas pr√©vias sobre os par√¢metros do modelo, utilizando uma distribui√ß√£o *a priori*, $Pr(\theta)$, que reflete nossas expectativas antes de observar os dados. Dados os dados observados $Z$, a distribui√ß√£o *a posteriori*, $Pr(\theta | Z)$, combina a informa√ß√£o dos dados com a informa√ß√£o a priori, usando a regra de Bayes [^8.3]:

$$
Pr(\theta|Z) = \frac{Pr(Z|\theta) \cdot Pr(\theta)}{\int Pr(Z|\theta) \cdot Pr(\theta) \, d\theta}
$$

onde $Pr(Z|\theta)$ √© a verossimilhan√ßa dos dados dados os par√¢metros e o denominador √© um termo de normaliza√ß√£o. A infer√™ncia Bayesiana fornece uma distribui√ß√£o completa para os par√¢metros, ao inv√©s de apenas um √∫nico valor estimado, e permite modelar incertezas de forma mais completa.

```mermaid
graph LR
    subgraph "Bayesian Inference"
        direction TB
        A["Prior Distribution: Pr(Œ∏)"]
        B["Likelihood: Pr(Z|Œ∏)"]
        C["Posterior Distribution: Pr(Œ∏|Z) = Pr(Z|Œ∏)Pr(Œ∏) / ‚à´Pr(Z|Œ∏)Pr(Œ∏)dŒ∏"]
        A --> C
        B --> C
    end
```

> üí° **Exemplo Num√©rico:** Usando o exemplo do modelo gaussiano, suponha que temos uma *prior* para $\mu$ que √© tamb√©m uma normal com m√©dia 5 e desvio padr√£o 2, ou seja, $Pr(\mu) = \mathcal{N}(5, 2^2)$. A verossimilhan√ßa √© dada por $Pr(Z|\mu) \propto \exp\left(-\frac{1}{2\sigma^2}\sum_i (z_i - \mu)^2\right)$.
>
> A distribui√ß√£o *a posteriori* $Pr(\mu|Z)$ √© proporcional ao produto da *prior* e da verossimilhan√ßa:
>
> $$
> Pr(\mu|Z) \propto Pr(Z|\mu) Pr(\mu) \propto \exp\left(-\frac{1}{2\sigma^2}\sum_i (z_i - \mu)^2 - \frac{1}{2 \cdot 2^2} (\mu - 5)^2\right)
> $$
>
> Simplificando a express√£o, obtemos que a *posteriori* de $\mu$ √© tamb√©m uma distribui√ß√£o normal. O valor esperado e a vari√¢ncia s√£o dados por (demonstra√ß√£o omitida para brevidade):
> $$
>  \mu_{posterior} = \frac{ \frac{1}{\sigma^2}\sum_{i=1}^{N}z_i + \frac{1}{2^2} 5 }{\frac{N}{\sigma^2} + \frac{1}{2^2}}
> $$
> $$
> \sigma^2_{posterior} = \frac{1}{\frac{N}{\sigma^2} + \frac{1}{2^2}}
> $$
>
> Usando os dados $Z = \{2, 4, 6, 8, 10\}$, $\hat{\mu}_{ML} = 6$, $\hat{\sigma}^2=8$,  e nossa *prior* $\mathcal{N}(5, 2^2)$, teremos:
>
> $$
>  \mu_{posterior} = \frac{ \frac{1}{8} (2+4+6+8+10) + \frac{1}{4} 5 }{\frac{5}{8} + \frac{1}{4}} =  \frac{ \frac{30}{8} + \frac{5}{4} }{\frac{7}{8}} =  \frac{ \frac{40}{8} }{\frac{7}{8}} = \frac{40}{7} \approx 5.714
> $$
>
> $$
> \sigma^2_{posterior} = \frac{1}{\frac{5}{8} + \frac{1}{4}} = \frac{1}{\frac{7}{8}} = \frac{8}{7} \approx 1.143
> $$
>
> Assim, a distribui√ß√£o *a posteriori* para $\mu$ √© aproximadamente $\mathcal{N}(5.714, \sqrt{1.143}^2)$, que representa nosso conhecimento atualizado sobre $\mu$ ap√≥s observar os dados e considerar nossas cren√ßas iniciais. Note que a m√©dia *a posteriori* est√° entre a *prior* e a estimativa de m√°xima verossimilhan√ßa.

> ‚ö†Ô∏è **Nota Importante:** A infer√™ncia Bayesiana difere da abordagem "frequentista" tradicional pela inclus√£o de uma distribui√ß√£o a priori, que reflete a incerteza pr√©-existente antes da an√°lise dos dados, e pela express√£o da incerteza ap√≥s a an√°lise dos dados na forma de uma distribui√ß√£o a posteriori [^8.3].

> ‚ùó **Ponto de Aten√ß√£o:** Em contraste com a abordagem de m√°xima verossimilhan√ßa, que usa $Pr(z_{new}|\hat{\theta})$ para fazer previs√µes, a infer√™ncia Bayesiana utiliza a distribui√ß√£o preditiva $Pr(z_{new}|Z) = \int Pr(z_{new}|\theta) Pr(\theta|Z) \, d\theta$, que contabiliza a incerteza na estimativa dos par√¢metros [^8.3].

> ‚úîÔ∏è **Destaque:** Em casos onde as priors s√£o n√£o-informativas (constantes), a distribui√ß√£o a posteriori √© proporcional √† verossimilhan√ßa, e as an√°lises Bayesianas e de m√°xima verossimilhan√ßa tendem a concordar, especialmente quando temos grandes conjuntos de dados [^8.4].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
<imagem: Diagrama mostrando um fluxo de dados para regress√£o de indicadores, desde a codifica√ß√£o das classes at√© a compara√ß√£o com m√©todos probabil√≠sticos. Uma seta liga 'Codificar Classes' a 'Estimar Coeficientes via LS', depois para 'Aplicar Regra de Decis√£o' e finalmente para 'Comparar com M√©todos Probabil√≠sticos'.>

A regress√£o linear aplicada a uma matriz de indicadores pode ser utilizada em problemas de classifica√ß√£o, onde cada classe √© representada por uma coluna bin√°ria indicando a pertin√™ncia de cada observa√ß√£o √†quela classe. Formalmente, para um problema de classifica√ß√£o com $K$ classes, criamos uma matriz de indicadores $Y$, onde $Y_{ij} = 1$ se a $i$-√©sima observa√ß√£o pertence √† $j$-√©sima classe e $Y_{ij} = 0$ caso contr√°rio [^4.2]. Podemos ent√£o aplicar a regress√£o linear a esta matriz de indicadores:

$$
\hat{Y} = X(X^T X)^{-1} X^T Y
$$

onde $X$ √© a matriz de *design*, contendo as vari√°veis preditoras. A predi√ß√£o para uma nova observa√ß√£o $x$ seria:

$$
\hat{y}(x) = x^T (X^T X)^{-1} X^T Y
$$

A classe predita √© aquela com o maior valor correspondente em $\hat{y}(x)$. Embora a regress√£o de indicadores possa ser usada para classifica√ß√£o, ela apresenta limita√ß√µes. Primeiro, as previs√µes n√£o est√£o restritas ao intervalo [0,1], o que pode gerar estimativas de probabilidade fora do intervalo l√≥gico. Segundo, a regress√£o de indicadores n√£o leva em considera√ß√£o a estrutura das probabilidades das classes, sendo mais focada em estimar as fronteiras de decis√£o.

```mermaid
graph LR
    subgraph "Indicator Regression for Classification"
        direction TB
        A["Indicator Matrix Y"]
        B["Design Matrix X"]
        C["Estimate YÃÇ using Linear Regression: YÃÇ = X(X·µÄX)‚Åª¬πX·µÄY"]
        D["Predict for new observation x: yÃÇ(x) = x·µÄ(X·µÄX)‚Åª¬πX·µÄY"]
        E["Assign class based on max value in yÃÇ(x)"]
        A --> C
        B --> C
        C --> D
        D --> E
    end
```

> üí° **Exemplo Num√©rico:** Suponha que temos um conjunto de dados com 3 observa√ß√µes e 2 classes, com duas vari√°veis preditoras, $x_1$ e $x_2$. A matriz de design $X$ e a matriz de indicadores $Y$ s√£o:
>
> $$
> X = \begin{bmatrix} 1 & 1 & 2 \\ 1 & 2 & 1 \\ 1 & 3 & 3 \end{bmatrix} , \quad Y = \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix}
> $$
>
> Para calcular $\hat{Y}$, primeiro calculamos $(X^T X)^{-1}$:
>
> $$
> X^T X = \begin{bmatrix} 1 & 1 & 1 \\ 1 & 2 & 3 \\ 2 & 1 & 3 \end{bmatrix} \begin{bmatrix} 1 & 1 & 2 \\ 1 & 2 & 1 \\ 1 & 3 & 3 \end{bmatrix} = \begin{bmatrix} 3 & 6 & 6 \\ 6 & 14 & 13 \\ 6 & 13 & 14 \end{bmatrix}
> $$
>
> Usando numpy para calcular a inversa:
>
> ```python
> import numpy as np
>
> X = np.array([[1, 1, 2], [1, 2, 1], [1, 3, 3]])
> Y = np.array([[1, 0], [0, 1], [1, 0]])
>
> XtX = X.T @ X
> XtX_inv = np.linalg.inv(XtX)
>
> print("Inverse of X^T X:\n", XtX_inv)
> ```
> ```text
> Inverse of X^T X:
> [[ 1.66666667  -0.33333333  -0.33333333]
> [-0.33333333   0.73333333  -0.36666667]
> [-0.33333333  -0.36666667   0.73333333]]
> ```
>
> Agora, podemos calcular $\hat{Y}$:
>
> $$
> \hat{Y} = X (X^T X)^{-1} X^T Y
> $$
>
> ```python
> Y_hat = X @ XtX_inv @ X.T @ Y
> print("\nPredicted Y:\n", Y_hat)
> ```
> ```text
> Predicted Y:
> [[ 0.66666667  0.33333333]
> [ 0.          1.        ]
> [ 0.66666667  0.33333333]]
> ```
> Para uma nova observa√ß√£o $x_{new} = [1, 2, 2]$, a previs√£o seria:
> $$
> \hat{y}(x_{new}) = x_{new}^T(X^TX)^{-1}X^T Y
> $$
> ```python
> x_new = np.array([1,2,2])
> y_hat_new = x_new @ XtX_inv @ X.T @ Y
> print(f"\nPredicted y for new observation {x_new}: {y_hat_new}")
> ```
> ```text
> Predicted y for new observation [1 2 2]: [0.33333333 0.66666667]
> ```
>  O maior valor √© 0.666 na segunda coluna, ent√£o a classe predita √© a segunda classe.

**Lemma 2:** _Em certos casos, as fronteiras de decis√£o derivadas da regress√£o linear de indicadores s√£o equivalentes √†s obtidas com discriminantes lineares, especialmente quando as covari√¢ncias s√£o iguais entre as classes._

*Prova (esbo√ßo):* Quando as classes s√£o separ√°veis por um hiperplano, e o objetivo √© apenas estimar a fronteira de decis√£o, a regress√£o linear de indicadores pode gerar resultados similares ao LDA, quando as covari√¢ncias das classes s√£o similares e podemos ignorar estimativas de probabilidade. $\blacksquare$

**Corol√°rio 2:** _Em situa√ß√µes onde a separa√ß√£o das classes por hiperplanos √© o objetivo prim√°rio, a regress√£o de indicadores pode ser uma ferramenta mais eficiente computacionalmente e, muitas vezes, fornece resultados similares aos do LDA, quando as classes t√™m covari√¢ncias iguais ou similares._

"A regress√£o log√≠stica, conforme apontado em [^4.4], pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1]. No entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^4.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear."

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem: Mapa mental complexo mostrando como a regulariza√ß√£o conecta modelos de classifica√ß√£o como LDA, regress√£o log√≠stica e hiperplanos, indicando penalidades L1 e L2 como m√©todos para lidar com sparsity e estabilidade>

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o cruciais em modelos de classifica√ß√£o, especialmente quando se trabalha com conjuntos de dados de alta dimensionalidade. Em modelos lineares, como regress√£o log√≠stica, a **regulariza√ß√£o** √© um m√©todo chave para evitar overfitting e melhorar a capacidade de generaliza√ß√£o [^4.4.4]. A regulariza√ß√£o adiciona um termo de penalidade √† fun√ß√£o de custo, que pune coeficientes grandes, induzindo modelos mais simples e evitando *overfitting*.

A **penaliza√ß√£o L1** (Lasso), adiciona uma penalidade proporcional √† soma dos valores absolutos dos coeficientes:

$$
\text{Penalidade L1} = \lambda \sum_{j=1}^p |\beta_j|
$$

onde $\lambda$ √© o par√¢metro de regulariza√ß√£o e $\beta_j$ s√£o os coeficientes do modelo. A penaliza√ß√£o L1 tende a gerar coeficientes esparsos, ou seja, alguns coeficientes s√£o exatamente zero, realizando a sele√ß√£o de vari√°veis automaticamente. J√° a **penaliza√ß√£o L2** (Ridge) adiciona uma penalidade proporcional √† soma dos quadrados dos coeficientes:

$$
\text{Penalidade L2} = \lambda \sum_{j=1}^p \beta_j^2
$$

A penaliza√ß√£o L2 tamb√©m reduz a magnitude dos coeficientes, mas sem necessariamente zer√°-los. Ela promove a estabilidade do modelo e evita que os coeficientes assumam valores muito grandes [^4.4.4], [^4.5].

```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["Cost Function without Regularization: J(Œ≤)"]
        B["L1 Regularization (Lasso): Penalty = ŒªŒ£|Œ≤‚±º|"]
        C["L2 Regularization (Ridge): Penalty = ŒªŒ£Œ≤‚±º¬≤"]
        D["Cost Function with L1: J(Œ≤) + ŒªŒ£|Œ≤‚±º|"]
        E["Cost Function with L2: J(Œ≤) + ŒªŒ£Œ≤‚±º¬≤"]
        A --> B
        A --> C
        B --> D
        C --> E

    end
```

> üí° **Exemplo Num√©rico:** Suponha que estamos ajustando um modelo de regress√£o log√≠stica para classifica√ß√£o bin√°ria e temos os seguintes coeficientes obtidos com m√°xima verossimilhan√ßa: $\beta = [2, -3, 1, 0.5, -2.5]$.  Vamos aplicar a regulariza√ß√£o L1 e L2 com diferentes valores de $\lambda$.
>
> **Penaliza√ß√£o L1 (Lasso):**
>
>  A fun√ß√£o de custo com regulariza√ß√£o L1 √©:
>
> $$
>  J(\beta) = \text{Log-Loss} + \lambda \sum_{j=1}^p |\beta_j|
> $$
>
> Vamos usar $\lambda=0.5$ e $\lambda=1$:
>
> -   $\lambda = 0.5$: Otimizando a fun√ß√£o de custo com a penaliza√ß√£o L1, poder√≠amos obter (para simplifica√ß√£o, assumimos que a otimiza√ß√£o leva aos seguintes valores) $\beta_{L1, \lambda=0.5} = [1.5, -2.5, 0.5, 0, -2]$ (alguns coeficientes reduziram em magnitude e um foi zerado).
> -   $\lambda = 1$:  Otimizando a fun√ß√£o de custo com a penaliza√ß√£o L1, poder√≠amos obter $\beta_{L1, \lambda=1} = [1, -2, 0, 0, -1]$ (mais coeficientes zerados).
>
> **Penaliza√ß√£o L2 (Ridge):**
>
> A fun√ß√£o de custo com regulariza√ß√£o L2 √©:
>
> $$
> J(\beta) = \text{Log-Loss} + \lambda \sum_{j=1}^p \beta_j^2
> $$
>
> Vamos usar $\lambda=0.5$ e $\lambda=1$:
>
> -   $\lambda = 0.5$:  Otimizando a fun√ß√£o de custo com a penaliza√ß√£o L2, poder√≠amos obter $\beta_{L2, \lambda=0.5} = [1.8, -2.7, 0.8, 0.4, -2.2]$ (todos os coeficientes s√£o reduzidos em magnitude, mas n√£o zerados).
> -   $\lambda = 1$: Otimizando a fun√ß√£o de custo com a penaliza√ß√£o L2, poder√≠amos obter $\beta_{L2, \lambda=1} = [1.6, -2.4, 0.6, 0.3, -1.9]$ (redu√ß√£o ainda maior na magnitude dos coeficientes).
>
> Comparando os resultados em uma tabela:
>
> | M√©todo                 | $\lambda$ | $\beta_1$ | $\beta_2$ | $\beta_3$ | $\beta_4$ | $\beta_5$ | Sparsity |
> |------------------------|-----------|-----------|-----------|-----------|-----------|-----------|----------|
> | Original                |  -        | 2        | -3        | 1        | 0.5        | -2.5        | False  |
> | L1 (Lasso)             | 0.5        | 1.5       | -2.5        | 0.5        | 0       | -2        | True     |
> | L1 (Lasso)             | 1        | 1       | -2        | 0        | 0       | -1      | True     |
> | L2 (Ridge)            | 0.5        | 1.8       | -2.7        | 0.8        | 0.4       | -2.2        | False     |
> | L2 (Ridge)             | 1        | 1.6       | -2.4        | 0.6        | 0.3       | -1.9       | False     |
>
> Podemos observar que a regulariza√ß√£o L1 promoveu a esparsidade dos coeficientes, zerando alguns deles, enquanto a L2 reduziu a magnitude, mas n√£o zerou os coeficientes.

**Lemma 3:** _A penaliza√ß√£o L1 em classifica√ß√£o log√≠stica conduz a coeficientes esparsos, levando √† sele√ß√£o de vari√°veis. Este comportamento √© uma consequ√™ncia da natureza n√£o diferenci√°vel do termo L1 na origem._ [^4.4.4]

*Prova (esbo√ßo):* Na otimiza√ß√£o com regulariza√ß√£o L1, a solu√ß√£o muitas vezes se encontra nas "quinas" do espa√ßo de par√¢metros, onde alguns coeficientes s√£o exatamente zero. Isso acontece porque a penalidade L1 induz um vi√©s em dire√ß√£o a solu√ß√µes esparsas, que reduzem o n√∫mero de vari√°veis relevantes. $\blacksquare$

**Corol√°rio 3:** _A esparsidade induzida pela penaliza√ß√£o L1 simplifica a interpreta√ß√£o do modelo, facilitando a identifica√ß√£o das vari√°veis mais importantes para a classifica√ß√£o, o que √© crucial para muitos problemas pr√°ticos._ [^4.4.5]

> ‚ö†Ô∏è **Ponto Crucial**: As penaliza√ß√µes L1 e L2 podem ser combinadas na chamada regulariza√ß√£o Elastic Net, que oferece vantagens de ambas as penaliza√ß√µes, controlando simultaneamente a sparsity e a estabilidade dos coeficientes [^4.5].

### Separating Hyperplanes e Perceptrons
A ideia de maximizar a margem de separa√ß√£o entre classes conduz ao conceito de hiperplanos √≥timos. Dado um conjunto de dados linearmente separ√°vel, o objetivo √© encontrar o hiperplano que maximiza a dist√¢ncia m√≠nima entre o hiperplano e os pontos de cada classe. Isso √© equivalente a resolver um problema de otimiza√ß√£o quadr√°tica, que pode ser formulado no espa√ßo primal ou dual. A formula√ß√£o dual, via o dual de Wolfe, nos permite trabalhar com combina√ß√µes lineares dos pontos de suporte e encontrar uma solu√ß√£o mais eficiente computacionalmente [^4.5.2].

O **Perceptron** de Rosenblatt √© um algoritmo cl√°ssico para encontrar hiperplanos separadores, especialmente para dados linearmente separ√°veis. O perceptron √© um algoritmo iterativo que ajusta os pesos do hiperplano de decis√£o a cada classifica√ß√£o errada, at√© que todos os pontos do conjunto de treinamento sejam corretamente classificados. Sob condi√ß√µes de linear separability, o perceptron tem converg√™ncia garantida, e o limite encontrado √© um hiperplano que separa as classes. No entanto, a solu√ß√£o do perceptron n√£o √© necessariamente a que maximiza a margem [^4.5.1].

```mermaid
graph LR
    subgraph "Perceptron Algorithm"
        direction TB
        A["Initialize Weights: w"]
        B["For each data point x·µ¢"]
        C["Calculate Output: w·µÄx·µ¢"]
        D["Check Classification"]
        E["If misclassified: Update w = w + Œ∑x·µ¢"]
        F["Repeat until all points correctly classified"]
        A --> B
        B --> C
        C --> D
        D -- "Misclassified" --> E
        D -- "Correctly classified" --> B
        E --> B
        B --> F
    end
```

> üí° **Exemplo Num√©rico:** Considere um conjunto de dados bidimensional com duas classes, classe 1: {(1,1), (2,2)} e classe 2: {(3,1), (3,3)}. O objetivo do Perceptron √© encontrar um hiperplano (neste caso, uma linha) que separe as duas classes.
>
> 1.  **Inicializa√ß√£o:** Come√ßamos com um vetor de pesos aleat√≥rio, por exemplo, $w = [0.5, -0.5, 0.1]$ (inclu√≠mos o termo de bias).
>
> 2.  **Itera√ß√µes:** O Perceptron itera sobre os dados, ajustando os pesos quando h√° classifica√ß√µes incorretas.
>
>     -   Para o ponto (1,1) (classe 1): a sa√≠da √© $0.5*1 -0.5*1 +0.1 = 0.1$. Como √© maior que zero, √© classificado corretamente.
>     -   Para o ponto (2,2) (classe 1): a sa√≠da √© $0.5*2 -0.5*2 +0.1 = 0.