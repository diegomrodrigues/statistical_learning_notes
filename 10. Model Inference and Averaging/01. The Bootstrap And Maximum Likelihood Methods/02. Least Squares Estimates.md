## Least Squares Estimates of Parameters in Statistical Modeling

```mermaid
flowchart TB
    subgraph "Least Squares (LS) in Statistical Modeling"
        A["Input Data (Observed Values)"]
        B["Model (Predicted Values)"]
        C["Difference (Observed - Predicted)"]
        D["Square of Differences"]
        E["Sum of Squared Differences (Objective Function)"]
        F["Minimize Sum of Squared Differences"]
        A --> C
        B --> C
        C --> D
        D --> E
        E --> F
        F --> G["Parameter Estimates"]
    end
```

<imagem: Mapa mental complexo que conecta os m√©todos de m√≠nimos quadrados com regress√£o linear, an√°lise discriminante linear e regress√£o log√≠stica, mostrando a rela√ß√£o entre as diferentes abordagens de classifica√ß√£o e as respectivas fun√ß√µes de custo, otimiza√ß√£o e regulariza√ß√£o>

### Introdu√ß√£o

A estimativa de par√¢metros por **m√≠nimos quadrados (Least Squares - LS)** √© uma t√©cnica fundamental em modelagem estat√≠stica, usada tanto em problemas de regress√£o quanto em classifica√ß√£o [^8.1]. O m√©todo busca ajustar um modelo aos dados, minimizando a soma dos quadrados das diferen√ßas entre os valores observados e os valores preditos pelo modelo. Este cap√≠tulo explorar√° a aplica√ß√£o e as nuances dos m√≠nimos quadrados no contexto da classifica√ß√£o, com foco em m√©todos lineares, como a regress√£o linear de matrizes indicadoras, an√°lise discriminante linear (LDA) e regress√£o log√≠stica. Os m√©todos de regulariza√ß√£o tamb√©m ser√£o abordados no intuito de melhorar a estabilidade e generaliza√ß√£o dos modelos.

### Conceitos Fundamentais

**Conceito 1: O Problema de Classifica√ß√£o e M√©todos Lineares**

O problema de classifica√ß√£o busca atribuir uma observa√ß√£o a uma das v√°rias classes predefinidas. M√©todos lineares, como a regress√£o linear, podem ser adaptados para tarefas de classifica√ß√£o atrav√©s da cria√ß√£o de **fun√ß√µes discriminantes lineares**. No contexto de um classificador bin√°rio, um **hiperplano** separa as classes, minimizando um custo baseado nas classifica√ß√µes incorretas. Em modelos lineares, o ajuste √© determinado pelos coeficientes que ponderam as vari√°veis, de forma a criar o hiperplano que melhor separa as classes [^4.1].

O uso de modelos lineares em classifica√ß√£o envolve o trade-off entre vi√©s e vari√¢ncia. Modelos lineares possuem um alto vi√©s devido √† sua simplicidade, mas tendem a ter baixa vari√¢ncia, sendo mais est√°veis e menos propensos a overfitting, o que pode ser vantajoso em alguns cen√°rios com poucos dados. No entanto, se a rela√ß√£o entre as vari√°veis e as classes for n√£o linear, esses modelos podem levar a predi√ß√µes deficientes [^4.2].

**Lemma 1:** *Fun√ß√µes discriminantes lineares podem ser decompostas em uma soma ponderada das vari√°veis preditoras, com cada peso representando a import√¢ncia de cada vari√°vel na decis√£o de classe*. Formalmente, dada uma fun√ß√£o discriminante $g(x) = w^T x + b$, onde $x$ √© o vetor de vari√°veis preditoras, $w$ √© o vetor de pesos e $b$ √© o termo independente (bias), ent√£o a decomposi√ß√£o representa como cada vari√°vel contribui para a decis√£o final [^4.3].

$$g(x) = \sum_{i=1}^{p} w_i x_i + b$$

Aqui, $p$ √© o n√∫mero de vari√°veis preditoras. Esta formula√ß√£o mostra que a decis√£o √© uma combina√ß√£o linear das entradas ponderadas pelos seus respectivos coeficientes.

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com duas vari√°veis preditoras, $x_1$ (idade) e $x_2$ (renda), para classificar se um cliente comprar√° um produto (classe 1) ou n√£o (classe 0). Suponha que a fun√ß√£o discriminante linear seja $g(x) = 0.02x_1 + 0.001x_2 - 5$. Para um cliente com idade 30 e renda 5000, ter√≠amos $g(x) = 0.02 * 30 + 0.001 * 5000 - 5 = 0.6 + 5 - 5 = 0.6$.  Se o limiar de decis√£o fosse 0, o cliente seria classificado como classe 1, indicando uma probabilidade maior de compra com base nesse modelo linear simples. O peso $w_1 = 0.02$ indica que a idade contribui positivamente para a decis√£o, enquanto $w_2 = 0.001$ indica que a renda tamb√©m contribui positivamente, mas com menor intensidade.

**Conceito 2: Linear Discriminant Analysis (LDA)**

A LDA √© um m√©todo cl√°ssico de classifica√ß√£o que busca projetar os dados em um espa√ßo de menor dimens√£o de forma a maximizar a separa√ß√£o entre classes [^4.3]. A LDA assume que os dados s√£o gerados por uma distribui√ß√£o normal multivariada e que as classes t√™m covari√¢ncias iguais. A **fun√ß√£o discriminante linear** da LDA √© constru√≠da a partir das m√©dias e da covari√¢ncia das classes. A LDA procura o subespa√ßo linear que melhor separa as m√©dias das classes, considerando a vari√¢ncia dentro das classes.

```mermaid
graph LR
    subgraph "Linear Discriminant Analysis (LDA)"
    A["Input Data (x)"] --> B["Class Means (Œº‚ÇÅ, Œº‚ÇÇ, ...)"]
    A --> C["Covariance Matrix (Œ£)"]
    B & C --> D["LDA Discriminant Function: x·µÄŒ£‚Åª¬π(Œº‚ÇÅ - Œº‚ÇÇ) - 1/2(Œº‚ÇÅ + Œº‚ÇÇ)·µÄŒ£‚Åª¬π(Œº‚ÇÅ - Œº‚ÇÇ) = 0"]
    D --> E["Projected Data (Lower Dimension)"]
    E --> F["Maximized Class Separation"]
    end
```

A fronteira de decis√£o entre duas classes na LDA √© dada por:
$$x^T \Sigma^{-1}(\mu_1 - \mu_2) - \frac{1}{2}(\mu_1 + \mu_2)^T\Sigma^{-1}(\mu_1 - \mu_2) = 0$$

Onde $\mu_1$ e $\mu_2$ s√£o os vetores de m√©dias das classes, e $\Sigma$ √© a matriz de covari√¢ncia comum [^4.3.1]. A LDA projeta os dados em uma dire√ß√£o que maximiza a raz√£o entre a vari√¢ncia interclasses e a vari√¢ncia intraclases.

**Corol√°rio 1:** *A fun√ß√£o discriminante linear da LDA define um hiperplano que separa as classes, projetando os dados em uma dire√ß√£o que maximize a separa√ß√£o entre as m√©dias das classes, enquanto minimiza a variabilidade dentro das classes, assumindo covari√¢ncias iguais*. Matematicamente, esta fun√ß√£o pode ser vista como uma proje√ß√£o dos dados em uma dire√ß√£o definida pelo autovetor correspondente ao maior autovalor da matriz de dispers√£o entre classes, ponderado pela matriz de dispers√£o dentro das classes, conforme discutido em [^4.3.1].

> üí° **Exemplo Num√©rico:** Suponha duas classes de flores, classe 1 com m√©dia $\mu_1 = [2, 3]$ e classe 2 com m√©dia $\mu_2 = [4, 5]$, e uma matriz de covari√¢ncia comum $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$. O vetor de diferen√ßa das m√©dias √© $\mu_1 - \mu_2 = [-2, -2]$. A inversa da matriz de covari√¢ncia √© $\Sigma^{-1} = \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix}$. A dire√ß√£o do hiperplano (normal) √© dada por $\Sigma^{-1}(\mu_1 - \mu_2) = \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \begin{bmatrix} -2 \\ -2 \end{bmatrix} = \begin{bmatrix} -1.34 \\ -1.34\end{bmatrix}$. Este vetor define a orienta√ß√£o do hiperplano que melhor separa as classes no espa√ßo de caracter√≠sticas, considerando a vari√¢ncia comum dentro das classes. A constante do hiperplano √© calculada como $- \frac{1}{2}(\mu_1 + \mu_2)^T\Sigma^{-1}(\mu_1 - \mu_2) =  - \frac{1}{2}([6, 8])\begin{bmatrix} -1.34 \\ -1.34\end{bmatrix} = 10.72$. A fun√ß√£o discriminante linear √© ent√£o $g(x) = [-1.34, -1.34]^T x + 10.72$, e a decis√£o da classe √© feita comparando $g(x)$ com 0.

**Conceito 3: Regress√£o Log√≠stica**

A Regress√£o Log√≠stica √© um m√©todo de classifica√ß√£o que modela a probabilidade de uma observa√ß√£o pertencer a uma determinada classe usando a **fun√ß√£o log√≠stica** (ou sigmoid) para transformar uma combina√ß√£o linear das vari√°veis preditoras em uma probabilidade entre 0 e 1 [^4.4]. Ao contr√°rio da regress√£o linear, que assume uma rela√ß√£o linear entre as vari√°veis e o resultado, a regress√£o log√≠stica modela o **log-odds** (ou logit) da probabilidade como uma combina√ß√£o linear das vari√°veis preditoras.

```mermaid
graph LR
    subgraph "Logistic Regression"
        A["Input Features (x)"]
        B["Linear Combination: w·µÄx + b"]
        C["Logistic Function (Sigmoid): 1 / (1 + exp(-(w·µÄx + b)))"]
        D["Probability of Class Membership (p(x))"]
        A --> B
        B --> C
        C --> D
    end
```

A fun√ß√£o log√≠stica √© dada por:

$$p(x) = \frac{1}{1 + e^{-(w^T x + b)}}$$

Onde $p(x)$ √© a probabilidade de uma observa√ß√£o pertencer a uma das classes. Os par√¢metros $w$ e $b$ s√£o estimados atrav√©s da **maximiza√ß√£o da verossimilhan√ßa (maximum likelihood estimation)**, que busca encontrar os valores que melhor ajustam as probabilidades aos dados observados [^4.4.1].

> ‚ö†Ô∏è **Nota Importante**: A regress√£o log√≠stica modela a probabilidade de pertencimento √† classe, sendo mais adequada para problemas de classifica√ß√£o probabil√≠stica, especialmente quando as classes s√£o desbalanceadas. **Refer√™ncia ao t√≥pico [^4.4.1]**.

> ‚ùó **Ponto de Aten√ß√£o**: Em casos de classes n√£o-balanceadas, a regress√£o log√≠stica tende a ser mais robusta que a regress√£o linear de matrizes indicadoras, uma vez que esta pode sofrer influ√™ncia da distribui√ß√£o desigual das classes. **Conforme indicado em [^4.4.2]**.

> ‚úîÔ∏è **Destaque**: Em certos casos, as estimativas de par√¢metros da LDA e da regress√£o log√≠stica podem ser relacionadas, especialmente quando as suposi√ß√µes da LDA s√£o satisfeitas. **Baseado no t√≥pico [^4.5]**.

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o log√≠stica com uma √∫nica vari√°vel preditora, $x$ (horas de estudo), e um par√¢metro $w = 0.5$ e bias $b = -3$. Se um aluno estuda por 6 horas, a probabilidade de ele ser aprovado √©: $p(x) = \frac{1}{1 + e^{-(0.5*6 - 3)}} = \frac{1}{1 + e^0} = \frac{1}{1 + 1} = 0.5$. Se outro aluno estuda 8 horas, $p(x) = \frac{1}{1 + e^{-(0.5*8 - 3)}} = \frac{1}{1 + e^{-1}} \approx 0.731$. Isso mostra como a fun√ß√£o log√≠stica transforma a combina√ß√£o linear das vari√°veis em uma probabilidade, nesse caso, a chance de um aluno ser aprovado. Um aumento de horas de estudo aumenta a probabilidade de aprova√ß√£o de forma n√£o linear.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
flowchart TB
    subgraph "Indicator Matrix Regression"
      A["Input Data (X)"]
      B["Indicator Matrix (Y)"]
      C["Compute: Œ≤ÃÇ = (X·µÄX)‚Åª¬πX·µÄY"]
      D["Estimated Coefficients (Œ≤ÃÇ)"]
      E["Prediction: x·µÄŒ≤ÃÇ"]
      F["Assign to Class with Highest Prediction"]
      A --> B
      A & B --> C
      C --> D
      D & A --> E
      E --> F
    end
```

<imagem: Diagrama de fluxo detalhado que descreve o processo da regress√£o de indicadores, incluindo a codifica√ß√£o de classes, a estimativa de coeficientes via m√≠nimos quadrados, a aplica√ß√£o da regra de decis√£o e a compara√ß√£o com m√©todos probabil√≠sticos>

**Explica√ß√£o:** Este diagrama representa o fluxo do processo de regress√£o de indicadores e como ele se relaciona √† classifica√ß√£o, **conforme descrito nos t√≥picos [^4.2]**.

A regress√£o linear, usualmente aplicada em problemas de regress√£o, pode ser adaptada para classifica√ß√£o atrav√©s do uso de uma **matriz de indicadores** (ou matriz dummy). Nesta abordagem, cada classe √© representada por uma coluna na matriz, onde cada linha corresponde a uma observa√ß√£o. O valor 1 indica que a observa√ß√£o pertence √†quela classe e 0 caso contr√°rio [^4.2]. Ao realizar a regress√£o linear com esta matriz, estamos, essencialmente, ajustando um modelo que prediz a probabilidade de uma observa√ß√£o pertencer a cada classe.

A estimativa dos coeficientes $\beta$ √© feita usando o m√©todo dos m√≠nimos quadrados, que busca minimizar a soma dos erros quadrados:
$$ \hat{\beta} = (X^T X)^{-1} X^T Y $$
Onde $X$ √© a matriz de vari√°veis preditoras (incluindo a coluna de "1" para o bias), e $Y$ √© a matriz de indicadores de classe.

Em problemas com mais de duas classes, a matriz de indicadores $Y$ possui m√∫ltiplas colunas, uma para cada classe. A regress√£o linear estima um vetor de coeficientes $\beta_k$ para cada classe $k$. A classe predita para uma observa√ß√£o √© determinada pela classe com maior valor estimado, i.e., $\text{argmax}_k (x^T \beta_k)$. No entanto, essa abordagem pode levar a estimativas de probabilidade fora do intervalo [0, 1].

A regress√£o linear em matrizes indicadoras pode ser vista como uma **aproxima√ß√£o da fun√ß√£o discriminante**. O modelo busca um hiperplano que separa as diferentes classes no espa√ßo de caracter√≠sticas. Apesar de ser uma abordagem simples e direta, a regress√£o linear para classifica√ß√£o pode apresentar limita√ß√µes, como dificuldade em lidar com classes n√£o linearmente separ√°veis e sensibilidade a outliers. Al√©m disso, ela n√£o possui uma interpreta√ß√£o probabil√≠stica direta como a regress√£o log√≠stica [^4.2].

> üí° **Exemplo Num√©rico:** Considere um dataset com 3 amostras e duas classes. Seja $X = \begin{bmatrix} 1 & 2 \\ 1 & 3 \\ 1 & 4 \end{bmatrix}$ a matriz de design (primeira coluna √© para o intercepto), e $Y = \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix}$ a matriz de indicadores de classe (classe 1 na primeira coluna, classe 2 na segunda). Primeiro, calculamos $X^TX = \begin{bmatrix} 3 & 9 \\ 9 & 29 \end{bmatrix}$. A inversa √© $(X^TX)^{-1} = \begin{bmatrix} 29/6 & -9/6 \\ -9/6 & 3/6 \end{bmatrix}$. Ent√£o, $X^TY = \begin{bmatrix} 2 & 1 \\ 9 & 3\end{bmatrix}$. Finalmente, $\hat{\beta} = (X^TX)^{-1}X^TY = \begin{bmatrix} 29/6 & -9/6 \\ -9/6 & 3/6 \end{bmatrix} \begin{bmatrix} 2 & 1 \\ 9 & 3\end{bmatrix} = \begin{bmatrix} -1.83 & 0.33 \\ 0.5 & 0 \end{bmatrix}$. Este $\hat{\beta}$ cont√©m os coeficientes para ambas as classes. A previs√£o para uma nova observa√ß√£o $x_{new} = [1, 2]$ ser√° $x_{new}^T \hat{\beta} = [1, 2] \begin{bmatrix} -1.83 & 0.33 \\ 0.5 & 0 \end{bmatrix} = [-0.83, 0.33]$. Como o primeiro valor (-0.83) √© menor que o segundo (0.33), classificamos a amostra como classe 2.

**Lemma 2:** *Sob certas condi√ß√µes de linearidade e normalidade dos dados, as proje√ß√µes nos hiperplanos de decis√£o gerados por regress√£o linear em matrizes indicadoras s√£o equivalentes √†s proje√ß√µes geradas por discriminantes lineares*. Formalmente, sob a suposi√ß√£o de que as classes s√£o linearmente separ√°veis, o vetor normal ao hiperplano de decis√£o da regress√£o de indicadores √© proporcional ao vetor normal ao hiperplano da LDA. A diferen√ßa est√° em como os pesos s√£o estimados, o que pode levar a diferentes fronteiras de decis√£o [^4.2].

**Corol√°rio 2:** *A equival√™ncia entre as proje√ß√µes nos hiperplanos de decis√£o da regress√£o linear e da LDA, sob certas suposi√ß√µes, permite simplificar a an√°lise do modelo, demonstrando que ambas as t√©cnicas buscam separa√ß√£o linear das classes*. No entanto, a regress√£o linear n√£o incorpora a informa√ß√£o da variabilidade dentro das classes na estima√ß√£o dos coeficientes, como a LDA faz, o que pode afetar a qualidade da separa√ß√£o em alguns casos, conforme indicado em [^4.3].

"Em alguns cen√°rios, conforme apontado em [^4.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1]."

"No entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^4.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear."

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Techniques"
    A["Initial Model (Parameters: Œ≤)"]
    B["L1 Regularization:  Œª||Œ≤||‚ÇÅ"]
    C["L2 Regularization: Œª||Œ≤||‚ÇÇ¬≤"]
    D["Elastic Net: Œª(Œ±||Œ≤||‚ÇÅ + (1-Œ±)||Œ≤||‚ÇÇ¬≤)"]
    E["Regularized Model Parameters"]
     A --> B
     A --> C
     A --> D
     B --> E
     C --> E
     D --> E
    end
```

<imagem: Mapa mental conectando os m√©todos de sele√ß√£o de vari√°veis (L1, L2, Elastic Net) com a regulariza√ß√£o em modelos lineares, detalhando suas implica√ß√µes em modelos LDA, Logistic Regression e Separating Hyperplanes>

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas cruciais para melhorar a generaliza√ß√£o e interpretabilidade de modelos de classifica√ß√£o, especialmente em casos de alta dimensionalidade, ou seja, quando o n√∫mero de vari√°veis preditoras √© grande [^4.5].

A regulariza√ß√£o adiciona um termo de penaliza√ß√£o √† fun√ß√£o de custo, que penaliza coeficientes grandes, evitando overfitting. As penaliza√ß√µes L1 e L2 s√£o as mais comuns. A **penaliza√ß√£o L1 (Lasso)** √© dada por $||\beta||_1 = \sum_{j=1}^p |\beta_j|$, onde $p$ √© o n√∫mero de par√¢metros. A penaliza√ß√£o L1 promove a esparsidade, ou seja, for√ßa alguns coeficientes a serem exatamente zero, selecionando assim as vari√°veis mais importantes [^4.4.4]. A **penaliza√ß√£o L2 (Ridge)** √© dada por $||\beta||_2^2 = \sum_{j=1}^p \beta_j^2$, e encolhe os coeficientes, mas geralmente n√£o os torna exatamente zero [^4.5.1]. A combina√ß√£o de ambas as penaliza√ß√µes, chamada de **Elastic Net**, usa uma combina√ß√£o linear das penalidades L1 e L2 para aproveitar as vantagens de ambas as abordagens [^4.5].

Em modelos log√≠sticos, a fun√ß√£o de custo regularizada √© dada por:

$$ J(\beta) = - \frac{1}{N}\sum_{i=1}^N [y_i \log(p(x_i)) + (1 - y_i) \log(1 - p(x_i))] + \lambda (\alpha ||\beta||_1 + (1-\alpha) ||\beta||_2^2) $$

Onde $\lambda$ controla a intensidade da regulariza√ß√£o, e $\alpha$ √© um hiperpar√¢metro que pondera as penalidades L1 e L2, com valores entre 0 e 1 [^4.4.4].

> üí° **Exemplo Num√©rico:** Em um modelo de regress√£o log√≠stica com duas vari√°veis preditoras, suponha que ap√≥s a otimiza√ß√£o sem regulariza√ß√£o, obtivemos $\beta = [2, -3]$. Aplicando L1 regulariza√ß√£o com $\lambda = 0.5$, a fun√ß√£o custo √© modificada. Se, ap√≥s otimizar a fun√ß√£o de custo regularizada, obtivermos um novo $\beta_{L1} = [1.5, -0.5]$, note como os coeficientes foram reduzidos, e a penaliza√ß√£o L1 pode for√ßar um deles a zero com um valor de $\lambda$ maior. Com a regulariza√ß√£o L2 (Ridge), e com o mesmo $\lambda = 0.5$,  podemos obter $\beta_{L2} = [1.8, -2.7]$, que encolhe os coeficientes, mas n√£o a zero. J√° no Elastic Net, com $\lambda = 0.5$ e $\alpha = 0.5$, combinando ambas as penaliza√ß√µes, poder√≠amos ter um resultado $\beta_{EN} = [1.6, -1.2]$. A escolha de $\lambda$ e $\alpha$ impacta diretamente o qu√£o esparsos e generaliz√°veis ser√£o os modelos.

**Lemma 3:** *A penaliza√ß√£o L1 em modelos de classifica√ß√£o log√≠stica tende a gerar solu√ß√µes esparsas, devido √† natureza do termo de penaliza√ß√£o, que for√ßa alguns coeficientes a se tornarem exatamente zero*. Formalmente, a n√£o diferenciabilidade do termo $||\beta||_1$ em $\beta = 0$ leva a solu√ß√µes em que um subconjunto de coeficientes √© nulo, promovendo a sele√ß√£o de vari√°veis [^4.4.4].

**Prova do Lemma 3:** A fun√ß√£o objetivo da regress√£o log√≠stica com penaliza√ß√£o L1 √© convexa. Para um coeficiente $\beta_j$, a derivada do termo de regulariza√ß√£o em rela√ß√£o a $\beta_j$ √© $\lambda \text{sign}(\beta_j)$. A solu√ß√£o √≥tima √© encontrada quando a derivada da fun√ß√£o de custo total em rela√ß√£o a $\beta_j$ √© zero. A penaliza√ß√£o L1 leva a que muitos coeficientes $\beta_j$ sejam exatamente zero em busca da otimiza√ß√£o, resultando em um modelo esparso. O ponto √≥timo de $\beta_j$ ser√° zero se a derivada da fun√ß√£o de custo (sem o termo de regulariza√ß√£o) cair dentro de um certo intervalo $[-\lambda, \lambda]$. $\blacksquare$

**Corol√°rio 3:** *A esparsidade induzida pela penaliza√ß√£o L1 n√£o s√≥ melhora a generaliza√ß√£o ao reduzir a vari√¢ncia, mas tamb√©m aumenta a interpretabilidade do modelo classificat√≥rio, pois seleciona as vari√°veis mais relevantes para a predi√ß√£o*. A remo√ß√£o de vari√°veis n√£o relevantes reduz a complexidade do modelo e facilita a compreens√£o dos fatores que influenciam a decis√£o de classe [^4.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: L1 e L2 podem ser combinadas (Elastic Net) para aproveitar vantagens de ambos os tipos de regulariza√ß√£o, controlando esparsidade e estabilidade do modelo, **conforme discutido em [^4.5]**.

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Separating Hyperplanes"
        A["Feature Space"]
        B["Data Points (Classes 1 & 2)"]
        C["Separating Hyperplane (w·µÄx + b = 0)"]
        D["Margin of Separation"]
        E["Support Vectors (Closest Data Points)"]
        B --> C
        C --> D
        D --> E
        A --> B
    end
```

O conceito de **hiperplanos separadores** √© fundamental em classifica√ß√£o linear. Um hiperplano separa as classes no espa√ßo de caracter√≠sticas, definindo um limite de decis√£o entre elas. Hiperplanos √≥timos s√£o aqueles que maximizam a **margem de separa√ß√£o**, ou seja, a dist√¢ncia entre o hiperplano e os pontos mais pr√≥ximos de cada classe, chamados de **vetores de suporte** [^4.5.2].

O problema de encontrar o hiperplano √≥timo √© um problema de otimiza√ß√£o que pode ser formulado usando programa√ß√£o quadr√°tica. A solu√ß√£o do problema de otimiza√ß√£o resulta em um hiperplano definido por combina√ß√µes lineares dos vetores de suporte [^4.5.2].

O **Perceptron de Rosenblatt** √© um algoritmo de aprendizagem para classifica√ß√£o linear. Ele aprende a fun√ß√£o discriminante linear atrav√©s de ajustes iterativos nos pesos, com base na classifica√ß√£o incorreta dos exemplos de treinamento [^4.5.1]. Em cada itera√ß√£o, o Perceptron ajusta os pesos, movendo o hiperplano de decis√£o em dire√ß√£o √† classifica√ß√£o correta. Sob a condi√ß√£o de separabilidade linear dos dados, o algoritmo do Perceptron converge para uma solu√ß√£o que separa as classes.

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**

A **Regra de Decis√£o Bayesiana** busca classificar uma observa√ß√£o na classe que maximiza a probabilidade *a posteriori*, i.e., a probabilidade da classe dado a observa√ß√£o. Sob a suposi√ß√£o de que os dados s√£o gerados por distribui√ß√µes gaussianas, essa regra leva a fun√ß√µes discriminantes quadr√°ticas, dado que a densidade gaussiana √© quadr√°tica no expoente. Quando as covari√¢ncias das classes s√£o iguais, o termo quadr√°tico cancela, e a fronteira de decis√£o passa a ser linear [^4.3].

A LDA, por sua vez, busca projetar os dados em um espa√ßo de menor dimens√£o de forma a maximizar a separa√ß√£o entre as m√©dias das classes, considerando a vari√¢ncia intraclases. Sob a suposi√ß√£o de distribui√ß√µes gaussianas com covari√¢ncias iguais, o resultado da LDA √© equivalente √† regra de decis√£o Bayesiana, com a mesma fun√ß√£o discriminante linear, j√° que, ambas, buscam a dire√ß√£o que melhor separa as classes sob essas condi√ß√µes [^4.3].

**Lemma 4:** *Sob a hip√≥tese de que os dados s√£o provenientes de distribui√ß√µes Gaussianas com covari√¢ncias iguais, a fun√ß√£o discriminante linear da LDA √© proporcional √† fun√ß√£o discriminante linear derivada da regra de decis√£o Bayesiana*. Formalmente, ambas as fun√ß√µes levam ao mesmo hiperplano separador, diferindo apenas em uma constante multiplicativa que n√£o afeta a decis√£o de classe [^4.3], [^4.3.3].

**Corol√°rio 4:** *Ao relaxar a hip√≥tese de covari√¢ncias iguais, a regra de decis√£o Bayesiana leva a fronteiras quadr√°ticas entre as classes (Quadratic Discriminant Analysis - QDA)*. A diferen√ßa entre LDA e QDA √© que, enquanto a LDA imp√µe a restri√ß√£o de covari√¢ncias iguais entre classes, a QDA assume que cada classe possui sua pr√≥pria matriz de covari√¢ncia, o que a torna mais flex√≠vel para dados com padr√µes de variabilidade diferentes entre classes, **conforme em [^4.3]**.

```mermaid
graph LR
    subgraph "LDA vs. QDA"
    A["Bayesian Decision Rule"]
    B["Gaussian Distributions"]
    C["Equal Covariances"]
    D["LDA (Linear Decision Boundary)"]
    E["Unequal Covariances"]
    F["QDA (Quadratic Decision Boundary)"]
    A --> B
    B --> C
    C --> D
    B --> E
    E --> F
    end
```

> ‚ö†Ô∏è **Ponto Crucial**: A ado√ß√£o ou n√£o de covari√¢ncias iguais impacta fortemente o tipo de fronteira de decis√£o (linear vs. quadr√°tica), e as escolhas devem ser tomadas com base no conhecimento sobre os dados, **conforme discutido em [^4.3.1]**.

### Conclus√£o

Este cap√≠tulo explorou os fundamentos e aplica√ß√µes da estimativa por m√≠nimos quadrados no contexto da classifica√ß√£o linear. Os m√©todos de regress√£o de matrizes indicadoras, LDA, regress√£o log√≠stica e hiperplanos separadores foram discutidos em detalhes, incluindo suas vantagens, limita√ß√µes e as formas como a regulariza√ß√£o pode ser aplicada para melhorar a estabilidade e capacidade de generaliza√ß√£o dos modelos. Atrav√©s de conceitos matem√°ticos e lemmas, estabelecemos a liga√ß√£o entre os diferentes m√©todos, elucidando as suposi√ß√µes e aproxima√ß√µes necess√°rias para cada abordagem.

<!-- END DOCUMENT -->

### Footnotes

[^8.1]: "For most of this book, the fitting (learning) of models has been achieved by minimizing a sum of squares for regression, or by minimizing cross-entropy for classification. In fact, both of these minimizations are instances of the maximum likelihood approach to fitting." *(Trecho de <Model Inference and Averaging>)*
[^4.1]: "In this chapter we provide a general exposition of the maximum likeli-
hood approach, as well as the Bayesian method for inference. The boot-
strap, introduced in Chapter 7, is discussed in this context, and its relation
to maximum likelihood and Bayes is described. Finally, we present some
related techniques for model averaging and improvement, including com-
mittee methods, bagging, stacking and bumping." *(Trecho de <Model Inference and Averaging>)*
[^4.2]: "Here xi is a one-dimensional input, and y‚ÇÅ the outcome, either continuous or categorical." *(Trecho de <Model Inference and Averaging>)*
[^4.3]: "Suppose we decide to fit a cubic spline to the data, with three knots placed at the quartiles of the X values. This is a seven-dimensional linear space of functions, and can be represented, for example, by a linear expansion of B-spline basis functions (see Section 5.9.2):" *(Trecho de <Model Inference and Averaging>)*
[^4.3.1]: "Here the h;(x), j = 1, 2, ..., 7 are the seven functions shown in the right panel of Figure 8.1. We can think of Œº(x) as representing the conditional mean E(Y|X = x)." *(Trecho de <Model Inference and Averaging>)*
[^4.3.2]: "Let H be the N√ó7 matrix with ijth element hj(xi). The usual estimate
of Œ≤, obtained by minimizing the squared error over the training set, is
given by" *(Trecho de <Model Inference and Averaging>)*
[^4.3.3]: "The corresponding fit (x) = ‚àë=1 Œ≤jhj (x) is shown in the top left panel
of Figure 8.2." *(Trecho de <Model Inference and Averaging>)*
[^4.4]: "In the top right panel of Figure 8.2 we have plotted √ª(x) ¬±1.96.se[(x)]. Since 1.96 is the 97.5% point of the standard normal distribution, these represent approximate 100-2 √ó 2.5% = 95% pointwise confidence bands for Œº(x)." *(Trecho de <Model Inference and Averaging>)*
[^4.4.1]: "Here is how we could apply the bootstrap in this example. We draw B datasets each of size N = 50 with replacement from our training data, the sampling unit being the pair zi = (xi, Yi)." *(Trecho de <Model Inference and Averaging>)*
[^4.4.2]: "To each bootstrap dataset Z* we fit a cubic spline √ª*(x); the fits from ten such samples are shown in the bottom left panel of Figure 8.2." *(Trecho de <Model Inference and Averaging>)*
[^4.4.3]: "Using B = 200 bootstrap samples, we can form a 95% pointwise confidence band from the percentiles at each x: we find the 2.5% √ó 200 = fifth largest and smallest values at each x." *(Trecho de <Model Inference and Averaging>)*
[^4.4.4]: "These are plotted in the bottom right panel of Figure 8.2. The bands look similar to those in the top right, being a little wider at the endpoints." *(Trecho de <Model Inference and Averaging>)*
[^4.4.5]: "There is actually a close connection between the least squares estimates (8.2) and (8.3), the bootstrap, and maximum likelihood. Suppose we further assume that the model errors are Gaussian," *(Trecho de <Model Inference and Averaging>)*
[^4.5]: "The bootstrap method described above, in which we sample with replacement from the training data, is called the nonparametric bootstrap." *(Trecho de <Model Inference and Averaging>)*
[^4.5.1]: "This really means that the method is "model-free," since it uses the raw data, not a specific parametric model, to generate new datasets." *(Trecho de <Model Inference and Averaging>)*
[^4.5.2]: "Consider a variation of the bootstrap, called the parametric bootstrap, in which we simulate new responses by adding Gaussian noise to the predicted values:" *(Trecho de <Model Inference and Averaging>)*
