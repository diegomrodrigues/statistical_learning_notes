## Bootstrap para Avalia√ß√£o de Incerteza

```mermaid
graph LR
    A["Original Data"] --> B("Resampling (with replacement)");
    B --> C("Bootstrap Samples");
    C --> D("Model Fitting on Each Sample");
    D --> E("Distribution of Estimates");
    E --> F("Confidence Intervals & Variability Assessment");
```

### Introdu√ß√£o

Este cap√≠tulo aborda o uso do **bootstrap** como uma ferramenta computacional para quantificar a incerteza em modelos estat√≠sticos e de machine learning. O bootstrap, introduzido no Cap√≠tulo 7 e discutido no contexto de *maximum likelihood* [^8.1], oferece uma abordagem direta para estimar a variabilidade de estimativas e previs√µes, sem a necessidade de suposi√ß√µes param√©tricas fortes. Ao longo deste cap√≠tulo, exploraremos sua conex√£o com a infer√™ncia *maximum likelihood* e o m√©todo Bayesiano, al√©m de discutir t√©cnicas relacionadas para model averaging e melhorias de modelos como committee methods, bagging, stacking e bumping.

### Conceitos Fundamentais

**Conceito 1: O Problema da Incerteza em Modelos**

O ajuste de modelos, seja por meio da minimiza√ß√£o de *sum of squares* em regress√£o ou da minimiza√ß√£o de *cross-entropy* em classifica√ß√£o [^8.1], frequentemente leva a estimativas pontuais dos par√¢metros. No entanto, essas estimativas n√£o capturam a incerteza associada ao processo de ajuste. A **incerteza** surge da variabilidade dos dados de treinamento, da escolha do modelo e da otimiza√ß√£o utilizada. A compreens√£o e quantifica√ß√£o dessa incerteza s√£o cruciais para a tomada de decis√µes informadas e para a avalia√ß√£o da robustez das conclus√µes obtidas. M√©todos lineares s√£o especialmente importantes nesse contexto, j√° que sua estrutura simples permite an√°lises mais claras de vi√©s e vari√¢ncia, conforme discutido em [^8.1].
```mermaid
graph LR
    subgraph "Sources of Uncertainty"
        A["Training Data Variability"]
        B["Model Choice"]
        C["Optimization Method"]
        A --> D["Model Parameter Uncertainty"]
        B --> D
        C --> D
    end
```
> üí° **Exemplo Num√©rico:** Considere um conjunto de dados de treinamento com 10 pontos onde queremos ajustar uma regress√£o linear simples. Os dados s√£o: `X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)` e `y = np.array([2, 3, 5, 6, 8, 9, 10, 12, 13, 15])`. Ao ajustar uma regress√£o linear usando m√≠nimos quadrados, obtemos uma estimativa para o coeficiente angular, $\hat{\beta_1}$, e para o intercepto, $\hat{\beta_0}$. No entanto, se tiv√©ssemos um conjunto de dados de treinamento ligeiramente diferente (devido √† amostragem aleat√≥ria dos dados), os valores de $\hat{\beta_1}$ e $\hat{\beta_0}$ tamb√©m seriam diferentes. O bootstrap nos permite quantificar essa variabilidade.
```python
import numpy as np
from sklearn.linear_model import LinearRegression

X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)
y = np.array([2, 3, 5, 6, 8, 9, 10, 12, 13, 15])

model = LinearRegression()
model.fit(X, y)

beta_0 = model.intercept_
beta_1 = model.coef_[0]

print(f"Estimativa de beta_0: {beta_0:.2f}")
print(f"Estimativa de beta_1: {beta_1:.2f}")
```
Ao rodar o c√≥digo, obtemos $\hat{\beta_0} \approx 0.67$ e $\hat{\beta_1} \approx 1.44$. O bootstrap nos permite gerar novas amostras a partir do conjunto original e recalcular esses coeficientes, obtendo uma distribui√ß√£o de poss√≠veis valores para $\hat{\beta_0}$ e $\hat{\beta_1}$.

**Lemma 1: Invari√¢ncia da Estimativa de M√≠nimos Quadrados Sob Permuta√ß√µes**
Dada uma matriz de dados *H*, um vetor de respostas *y*, e a estimativa de m√≠nimos quadrados de $\beta$ como $\hat{\beta} = (H^T H)^{-1} H^T y$ [^8.2], prove que a estimativa de $\beta$ √© invariante sob permuta√ß√µes das linhas de *H* e *y* simultaneamente.

**Prova:**
Seja *P* uma matriz de permuta√ß√£o. Uma permuta√ß√£o das linhas de *H* e *y* pode ser escrita como *H' = PH* e *y' = Py*. A nova estimativa de m√≠nimos quadrados √© dada por:
$$ \hat{\beta}' = (H'^T H')^{-1} H'^T y' $$
$$ \hat{\beta}' = ((PH)^T PH)^{-1} (PH)^T Py $$
$$ \hat{\beta}' = (H^T P^T PH)^{-1} H^T P^T Py $$
Como *P* √© uma matriz de permuta√ß√£o, $P^T P = I$, onde *I* √© a matriz identidade. Portanto,
$$ \hat{\beta}' = (H^T H)^{-1} H^T y = \hat{\beta} $$
Isso demonstra que a estimativa de m√≠nimos quadrados √© invariante sob permuta√ß√µes das linhas de *H* e *y* simultaneamente. $\blacksquare$
```mermaid
graph LR
    subgraph "Proof of Invariance"
        direction TB
        A["Original Estimate: Œ≤ÃÇ = (H·µÄH)‚Åª¬πH·µÄy"]
        B["Permuted Data: H' = PH, y' = Py"]
        C["New Estimate: Œ≤ÃÇ' = (H'·µÄH')‚Åª¬πH'·µÄy'"]
        D["Substitute: Œ≤ÃÇ' = ((PH)·µÄPH)‚Åª¬π(PH)·µÄPy"]
        E["Simplify: Œ≤ÃÇ' = (H·µÄP·µÄPH)‚Åª¬πH·µÄP·µÄPy"]
        F["P·µÄP = I: Œ≤ÃÇ' = (H·µÄH)‚Åª¬πH·µÄy"]
        G["Result: Œ≤ÃÇ' = Œ≤ÃÇ"]
        A --> B
        B --> C
        C --> D
        D --> E
        E --> F
        F --> G
    end
```

**Conceito 2: Linear Discriminant Analysis (LDA) e suas Suposi√ß√µes**

A **Linear Discriminant Analysis (LDA)** [^4.3] √© um m√©todo de classifica√ß√£o que assume que as classes s√£o geradas a partir de distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia. Esta suposi√ß√£o simplifica o problema e leva a uma fronteira de decis√£o linear. No entanto, a viola√ß√£o dessas suposi√ß√µes pode levar a resultados sub√≥timos. A LDA busca a dire√ß√£o que melhor separa as m√©dias das classes, ao mesmo tempo em que minimiza a variabilidade dentro de cada classe [^4.3.1], [^4.3.2], [^4.3.3]. O bootstrap pode ser usado para avaliar a incerteza na posi√ß√£o da fronteira de decis√£o e na classifica√ß√£o de novos dados.
```mermaid
graph LR
    subgraph "LDA Assumptions and Process"
        A["Data from Gaussian Distributions"]
        B["Equal Covariance Matrices"]
        C["Maximize Between-Class Variance"]
        D["Minimize Within-Class Variance"]
        A & B --> E["Linear Decision Boundary"]
        C & D --> E
    end
```

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com duas classes, onde cada classe √© representada por pontos 2D. Suponha que a classe 1 tenha m√©dia $\mu_1 = [2, 2]$ e a classe 2 tenha m√©dia $\mu_2 = [5, 5]$, e ambas compartilham uma matriz de covari√¢ncia $\Sigma = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$. A LDA busca o vetor que melhor separa essas duas m√©dias, enquanto considera a variabilidade dos pontos em cada classe. Se gerarmos amostras bootstrap desses dados, podemos ver como a posi√ß√£o da fronteira de decis√£o varia, demonstrando a incerteza do modelo.
```python
import numpy as np
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
import matplotlib.pyplot as plt

# Gerando dados sint√©ticos
np.random.seed(42)
mean1 = np.array([2, 2])
mean2 = np.array([5, 5])
cov = np.array([[1, 0], [0, 1]])
X1 = np.random.multivariate_normal(mean1, cov, 50)
X2 = np.random.multivariate_normal(mean2, cov, 50)
X = np.vstack((X1, X2))
y = np.array([0] * 50 + [1] * 50)

lda = LinearDiscriminantAnalysis()
lda.fit(X, y)

# Visualizando a fronteira de decis√£o
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))
Z = lda.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

plt.contourf(xx, yy, Z, alpha=0.3)
plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k')
plt.title('Fronteira de Decis√£o LDA')
plt.show()
```
Este c√≥digo gera um gr√°fico com a fronteira de decis√£o linear da LDA, com os dados originais.  Ao aplicar o bootstrap, podemos amostrar diferentes conjuntos de dados a partir de X e y, recalcular a fronteira de decis√£o e observar sua variabilidade.

**Corol√°rio 1: A Rela√ß√£o entre a Fun√ß√£o Discriminante Linear e a Proje√ß√£o em Subespa√ßos de Menor Dimens√£o**
Com base nas propriedades da LDA, em [^4.3.1], um corol√°rio √© que, a fun√ß√£o discriminante linear pode ser interpretada como uma proje√ß√£o dos dados em um subespa√ßo de menor dimens√£o que maximiza a separabilidade entre as classes.

**Prova:**
O objetivo da LDA √© encontrar uma transforma√ß√£o linear que projete os dados originais para um espa√ßo de menor dimens√£o, de modo que as classes estejam bem separadas nesse novo espa√ßo. Formalmente, a LDA busca uma matriz de proje√ß√£o *W* que maximize a raz√£o de dispers√£o entre as classes, $S_B$, e a dispers√£o dentro das classes, $S_W$:
$$ J(W) = \frac{W^T S_B W}{W^T S_W W} $$
Onde $S_B$ e $S_W$ s√£o dadas por:
$$ S_B = \sum_{i=1}^{k} n_i(\mu_i - \mu)(\mu_i - \mu)^T $$
$$ S_W = \sum_{i=1}^{k} \sum_{x_j \in D_i} (x_j - \mu_i)(x_j - \mu_i)^T $$
Onde *k* √© o n√∫mero de classes, $n_i$ √© o n√∫mero de amostras na classe *i*, $\mu_i$ √© a m√©dia da classe *i*, $\mu$ √© a m√©dia global, e $D_i$ √© o conjunto de dados na classe *i*. A matriz *W* otimizada representa uma proje√ß√£o linear que resulta em uma fun√ß√£o discriminante linear que maximiza a separabilidade das classes.  $\blacksquare$
```mermaid
graph LR
    subgraph "LDA Projection"
        direction TB
        A["Objective: Maximize J(W) = (W·µÄS_B W) / (W·µÄS_W W)"]
        B["Between-Class Scatter: S_B = Œ£ n·µ¢(Œº·µ¢ - Œº)(Œº·µ¢ - Œº)·µÄ"]
        C["Within-Class Scatter: S_W = Œ£ Œ£ (x‚±º - Œº·µ¢)(x‚±º - Œº·µ¢)·µÄ"]
         A --> B
        A --> C
        B --> D["Optimal Projection Matrix: W"]
        C --> D
    end
```

**Conceito 3: Logistic Regression e a Maximiza√ß√£o da Verossimilhan√ßa**

A **Logistic Regression** [^4.4] √© um modelo estat√≠stico para classifica√ß√£o que estima a probabilidade de um evento bin√°rio (ou multi-classe) ocorrer. Ao contr√°rio da LDA, a Logistic Regression n√£o faz suposi√ß√µes sobre a distribui√ß√£o das classes. Ela modela a probabilidade do evento utilizando a fun√ß√£o log√≠stica, que mapeia qualquer n√∫mero real para o intervalo (0, 1). A Logistic Regression estima os par√¢metros do modelo atrav√©s da **maximiza√ß√£o da verossimilhan√ßa** [^4.4.1], ou seja, encontrar os par√¢metros que tornam os dados observados mais prov√°veis [^4.4.2]. O bootstrap pode ser usado para avaliar a incerteza nos par√¢metros do modelo e nas previs√µes da probabilidade. A escolha entre LDA e Logistic Regression pode depender da natureza dos dados e das suposi√ß√µes que podem ser feitas [^4.4.5].
```mermaid
graph LR
    subgraph "Logistic Regression"
        A["No Assumptions about Class Distributions"]
        B["Models Probability using Sigmoid"]
        C["Parameter Estimation via Maximum Likelihood"]
         A --> D["Estimates parameters Œ≤"]
        B --> D
        C --> D
    end
```
> ‚ö†Ô∏è **Nota Importante**: √â crucial entender que a Logistic Regression modela a *probabilidade condicional* de uma classe dado os preditores, enquanto a LDA modela as *densidades* das classes.

> ‚ùó **Ponto de Aten√ß√£o**: Em situa√ß√µes com classes n√£o balanceadas, pode ser necess√°rio aplicar t√©cnicas como *re-sampling* ou *pondera√ß√£o* das classes durante o ajuste dos modelos, tanto em LDA quanto em Logistic Regression.

> ‚úîÔ∏è **Destaque**: Apesar de suas diferen√ßas, as estimativas dos par√¢metros em LDA e Logistic Regression podem apresentar correla√ß√µes significativas, especialmente quando as suposi√ß√µes da LDA s√£o aproximadamente v√°lidas.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    A["Linear Regression"] --> B["Indicator Matrix Regression"];
    B --> C["Binary Classification"];
    B --> D["Multi-Class Classification"];
    C --> E["Linear Decision Boundaries"];
    D --> F["Linear Decision Boundaries"];
```
**Explica√ß√£o:** Este mapa mental ilustra como a regress√£o linear, quando usada para regredir uma matriz de indicadores, pode ser usada para resolver problemas de classifica√ß√£o bin√°ria e multi-classe.

A **regress√£o linear** pode ser aplicada a problemas de classifica√ß√£o codificando as classes como vari√°veis indicadoras. Em problemas de classifica√ß√£o bin√°ria, as classes podem ser codificadas como 0 e 1. Em problemas multi-classe, uma matriz de indicadores pode ser usada, onde cada coluna representa uma classe e cada linha indica qual classe pertence a determinada observa√ß√£o. Ao ajustar um modelo de regress√£o linear nesta matriz, podemos obter uma estimativa dos coeficientes que podem ser usados para determinar a classe de cada observa√ß√£o. No entanto, √© fundamental notar que a regress√£o linear n√£o imp√µe que as previs√µes de classe estejam no intervalo [0, 1], levando a poss√≠veis extrapola√ß√µes problem√°ticas.

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com dados `X = np.array([[1], [2], [3], [4], [5]])` e as classes correspondentes `y = np.array([0, 0, 1, 1, 1])`. Podemos usar uma regress√£o linear para modelar as classes como vari√°veis indicadoras. Ao ajustar o modelo, obtemos um vetor de coeficientes $\hat{\beta}$. A previs√£o de classe para um novo ponto *x* √© feita comparando o valor $x\hat{\beta}$ com um limiar (por exemplo, 0.5). O bootstrap pode ser usado para avaliar como a estimativa de $\hat{\beta}$ varia com diferentes amostras de treinamento, afetando a posi√ß√£o da fronteira de decis√£o.
```python
import numpy as np
from sklearn.linear_model import LinearRegression

X = np.array([[1], [2], [3], [4], [5]])
y = np.array([0, 0, 1, 1, 1])

model = LinearRegression()
model.fit(X, y)

beta_0 = model.intercept_
beta_1 = model.coef_[0]

print(f"Estimativa de beta_0: {beta_0:.2f}")
print(f"Estimativa de beta_1: {beta_1:.2f}")
```
O c√≥digo acima ajusta uma regress√£o linear aos dados. A ideia √© que, usando amostras bootstrap dos dados, as estimativas de  $\hat{\beta_0}$ e $\hat{\beta_1}$ variam, o que indica a incerteza no modelo.

**Lemma 2: Equival√™ncia entre Proje√ß√µes de Regress√£o e Discriminantes Lineares**
Sob certas condi√ß√µes, as proje√ß√µes geradas pela regress√£o linear de indicadores e as obtidas por discriminantes lineares (como na LDA) podem ser equivalentes, especialmente quando o foco principal √© a fronteira de decis√£o linear.

**Prova:**
A regress√£o linear sobre uma matriz de indicadores para um problema de *K* classes com *N* observa√ß√µes pode ser expressa como:
$$ Y = X\beta + \epsilon $$
onde *Y* √© uma matriz *N x K* de indicadores, *X* √© a matriz de preditores de dimens√£o *N x p*, $\beta$ √© a matriz de coeficientes *p x K*, e $\epsilon$ representa os erros. A estimativa de m√≠nimos quadrados para $\beta$ √©:
$$ \hat{\beta} = (X^T X)^{-1} X^T Y $$
Em LDA, a fun√ß√£o discriminante linear para uma classe *k* √© definida como:
$$ \delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k $$
onde $\Sigma$ √© a matriz de covari√¢ncia comum e $\mu_k$ √© a m√©dia da classe *k*. As proje√ß√µes de ambos os m√©todos visam encontrar uma transforma√ß√£o que separe as classes. Em condi√ß√µes espec√≠ficas, como quando as classes s√£o aproximadamente balanceadas e linearmente separ√°veis, as dire√ß√µes das proje√ß√µes podem se alinhar, e os hiperplanos de decis√£o ser√£o similares, conforme mencionado em [^4.3]. A prova formal da equival√™ncia envolve an√°lise detalhada das condi√ß√µes e das formas funcionais dos dois m√©todos. $\blacksquare$
```mermaid
graph LR
    subgraph "Equivalence Proof"
        direction TB
        A["Linear Regression: Y = XŒ≤ + Œµ"]
        B["LS Estimate: Œ≤ÃÇ = (X·µÄX)‚Åª¬πX·µÄY"]
        C["LDA Discriminant: Œ¥‚Çñ(x) = x·µÄŒ£‚Åª¬πŒº‚Çñ - 1/2Œº‚Çñ·µÄŒ£‚Åª¬πŒº‚Çñ"]
        D["Similar Projections under Specific Conditions"]
        A --> B
        B --> D
        C --> D
    end
```

**Corol√°rio 2: Simplifica√ß√£o da An√°lise em Condi√ß√µes Espec√≠ficas**
Quando as classes s√£o bem separadas, o uso da regress√£o de indicadores, conforme indicado em [^4.3], pode fornecer resultados semelhantes aos da LDA e pode simplificar a an√°lise, especialmente em casos onde o foco √© apenas na fronteira de decis√£o linear.

Apesar da sua simplicidade, a regress√£o linear em matrizes de indicadores possui algumas limita√ß√µes. Uma delas √© que a regress√£o linear n√£o garante que as previs√µes estejam dentro do intervalo [0, 1], o que pode dificultar a interpreta√ß√£o das previs√µes como probabilidades. Al√©m disso, quando h√° muitas classes, a regress√£o linear pode levar a estimativas de par√¢metros inst√°veis, especialmente se as classes n√£o forem bem separadas [^4.2].

> ‚ÄúEm alguns cen√°rios, conforme apontado em [^4.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1].‚Äù

> ‚ÄúNo entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^4.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear.‚Äù

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    A["Logistic Regression"] --> B["L1 Regularization (Lasso)"];
    A --> C["L2 Regularization (Ridge)"];
    B --> D["Sparsity (Variable Selection)"];
    C --> E["Stability"];
    B --> F["Interpretability"];
     C --> G["Reduced Overfitting"];
```
**Explica√ß√£o:** Este mapa mental descreve como a regulariza√ß√£o L1 e L2 na regress√£o log√≠stica impacta na sele√ß√£o de vari√°veis e na estabilidade do modelo.

A **sele√ß√£o de vari√°veis** e a **regulariza√ß√£o** s√£o t√©cnicas importantes para melhorar a performance e a interpretabilidade de modelos classificat√≥rios, particularmente em situa√ß√µes com um grande n√∫mero de preditores. A regulariza√ß√£o imp√µe penalidades aos par√¢metros do modelo durante o processo de otimiza√ß√£o, evitando o *overfitting* e levando a modelos mais robustos e generaliz√°veis. A **penaliza√ß√£o L1 (Lasso)** [^4.4.4], adiciona um termo proporcional √† soma dos valores absolutos dos coeficientes, promovendo a esparsidade do modelo, ou seja, alguns coeficientes s√£o for√ßados a zero, levando √† sele√ß√£o de vari√°veis mais relevantes. A **penaliza√ß√£o L2 (Ridge)**, por outro lado, adiciona um termo proporcional √† soma dos quadrados dos coeficientes, reduzindo a magnitude dos coeficientes e melhorando a estabilidade das estimativas [^4.5].

> üí° **Exemplo Num√©rico:**  Suponha que temos um problema de classifica√ß√£o com 10 preditores e queremos aplicar regress√£o log√≠stica. Com regulariza√ß√£o L1 (Lasso), alguns coeficientes ser√£o exatamente zero, indicando que essas vari√°veis n√£o s√£o importantes para o modelo. Por exemplo, o modelo sem regulariza√ß√£o poderia ter coeficientes $\beta = [0.5, -0.2, 0.7, 0.1, -0.9, 0.3, -0.4, 0.8, 0.2, -0.1]$. Ap√≥s a regulariza√ß√£o L1, poder√≠amos ter $\beta_{L1} = [0.7, 0, 0.9, 0, -1.2, 0, -0.6, 1.1, 0, 0]$, mostrando que as vari√°veis 2, 4, 6, 9 e 10 foram exclu√≠das do modelo. O bootstrap pode ser usado para avaliar a variabilidade dos coeficientes ap√≥s a regulariza√ß√£o, indicando quais vari√°veis s√£o consistentemente selecionadas.

```python
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Gerando dados sint√©ticos
np.random.seed(42)
X = np.random.rand(100, 10)
y = np.random.randint(0, 2, 100)

# Dividindo em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalizando os dados
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Ajustando regress√£o log√≠stica sem regulariza√ß√£o
model_no_reg = LogisticRegression(penalty=None, solver='lbfgs', max_iter=1000)
model_no_reg.fit(X_train_scaled, y_train)
coef_no_reg = model_no_reg.coef_[0]
print("Coeficientes sem regulariza√ß√£o:", coef_no_reg)

# Ajustando regress√£o log√≠stica com regulariza√ß√£o L1 (Lasso)
model_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=0.5, max_iter=1000)
model_l1.fit(X_train_scaled, y_train)
coef_l1 = model_l1.coef_[0]
print("Coeficientes com regulariza√ß√£o L1:", coef_l1)

# Ajustando regress√£o log√≠stica com regulariza√ß√£o L2 (Ridge)
model_l2 = LogisticRegression(penalty='l2', solver='lbfgs', C=0.5, max_iter=1000)
model_l2.fit(X_train_scaled, y_train)
coef_l2 = model_l2.coef_[0]
print("Coeficientes com regulariza√ß√£o L2:", coef_l2)
```

O c√≥digo acima mostra um exemplo de como a regulariza√ß√£o afeta os coeficientes de um modelo de regress√£o log√≠stica. O bootstrap pode ser aplicado para observar como esses coeficientes variam com diferentes amostras de treinamento.

**Lemma 3: A Penaliza√ß√£o L1 e a Esparsidade em Classifica√ß√£o Log√≠stica**
A penaliza√ß√£o L1 na classifica√ß√£o log√≠stica leva a coeficientes esparsos, o que significa que muitas vari√°veis irrelevantes ser√£o exclu√≠das do modelo.

**Prova:**
O problema de otimiza√ß√£o na regress√£o log√≠stica com penaliza√ß√£o L1 √© dado por:
$$ \min_{\beta} -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(p_i) + (1-y_i)\log(1-p_i)] + \lambda \sum_{j=1}^{p} |\beta_j| $$
onde $y_i$ √© a resposta, $p_i$ √© a probabilidade predita, $\beta_j$ s√£o os coeficientes do modelo, *p* √© o n√∫mero de preditores e $\lambda$ √© o par√¢metro de regulariza√ß√£o. A penalidade L1, $\lambda \sum_{j=1}^{p} |\beta_j|$, n√£o √© diferenci√°vel em $\beta_j = 0$, o que causa uma solu√ß√£o esparsa.  A otimiza√ß√£o por subgradiente, utilizada neste caso, tende a for√ßar alguns coeficientes para zero, resultando na sele√ß√£o de apenas as vari√°veis mais relevantes para o modelo. A intui√ß√£o matem√°tica √© que a penalidade L1 adiciona um termo com contornos em formato de losango, que tendem a interceptar os contornos de fun√ß√£o de custo em v√©rtices, onde muitos coeficientes ser√£o iguais a zero. $\blacksquare$
```mermaid
graph LR
    subgraph "L1 Regularization"
         direction TB
        A["Objective Function with L1 Penalty"]
        B["Penalty Term: ŒªŒ£|Œ≤‚±º|"]
        C["Non-differentiable at Œ≤‚±º = 0"]
        D["Sparse Solutions (Some Œ≤‚±º = 0)"]
         A --> B
        B --> C
        C --> D

    end
```

**Corol√°rio 3: Implica√ß√µes da Esparsidade para Interpretabilidade**
A esparsidade resultante da penaliza√ß√£o L1 melhora a interpretabilidade dos modelos classificat√≥rios, pois apenas as vari√°veis mais relevantes permanecem no modelo, facilitando a compreens√£o de quais preditores t√™m o maior impacto na resposta [^4.4.5].
```mermaid
graph LR
    subgraph "Sparsity and Interpretability"
        A["L1 Regularization"] --> B["Sparsity"]
        B --> C["Variable Selection"]
        C --> D["Improved Interpretability"]
    end
```

> ‚ö†Ô∏è **Ponto Crucial**: As penalidades L1 e L2 podem ser combinadas na forma de **Elastic Net** para aproveitar as vantagens de ambos os tipos de regulariza√ß√£o, proporcionando esparsidade e estabilidade ao mesmo tempo.

### Separating Hyperplanes e Perceptrons

Os **separating hyperplanes** representam uma abordagem para classifica√ß√£o que busca encontrar o hiperplano que melhor separa as classes. Essa ideia √© diretamente relacionada √† maximiza√ß√£o da margem de separa√ß√£o entre as classes, levando ao conceito de hiperplanos √≥timos [^4.5.2]. O problema de otimiza√ß√£o para encontrar esses hiperplanos pode ser resolvido usando a dualidade de Wolfe [^4.5.2], onde a solu√ß√£o resulta em combina√ß√µes lineares dos pontos de suporte, que s√£o os pontos mais pr√≥ximos da fronteira de decis√£o. O Perceptron de Rosenblatt [^4.5.1] √© um algoritmo iterativo que busca encontrar um hiperplano de separa√ß√£o de maneira iterativa. A converg√™ncia do Perceptron √© garantida sob condi√ß√µes espec√≠ficas, principalmente quando os dados s√£o linearmente separ√°veis.
```mermaid
graph LR
    subgraph "Separating Hyperplanes"
         direction TB
        A["Find Optimal Hyperplane"]
        B["Maximize Separation Margin"]
        C["Wolfe Duality for Optimization"]
        D["Solution as Linear Combination of Support Vectors"]
         A --> B
        B --> C
        C --> D

    end
```
```mermaid
graph LR
    subgraph "Perceptron Algorithm"
         direction TB
        A["Iterative Search for Separating Hyperplane"]
         B["Guaranteed Convergence if Data is Linearly Separable"]
        A --> B
    end
```

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?
**Resposta:**
A LDA e a regra de decis√£o Bayesiana s√£o abordagens para classifica√ß√£o que podem levar a resultados semelhantes sob certas condi√ß√µes, especialmente quando as classes seguem distribui√ß√µes Gaussianas com covari√¢ncias iguais. A regra de decis√£o Bayesiana, baseada nas probabilidades posteriores, minimiza a probabilidade de erro de classifica√ß√£o, conforme em [^4.3]. A LDA, por outro lado, busca um subespa√ßo que maximize a separa√ß√£o entre as m√©dias das classes.

**Lemma 4: Equival√™ncia Formal entre LDA e Decis√£o Bayesiana sob Suposi√ß√µes**
Sob a suposi√ß√£o de distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia, o limite de decis√£o encontrado pela LDA √© formalmente equivalente ao encontrado pela regra de decis√£o Bayesiana, conforme em [^4.3] e [^4.3.3].

**Prova:**
Suponha que tenhamos *k* classes, com cada classe *i* seguindo uma distribui√ß√£o normal multivariada:
$$ p(x|C_i) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}} \exp \left(-\frac{1}{2}(x-\mu_i)^T\Sigma^{-1}(x-\mu_i) \right) $$
onde $\mu_i$ √© a m√©dia da classe *i* e $\Sigma$ √© a matriz de covari√¢ncia comum a todas as classes.  Pela regra de decis√£o Bayesiana, classificamos um ponto *x* na classe *j* se
$$ P(C_j|x) = \frac{p(x|C_j)P(C_j)}{\sum_{i=1}^k p(x|C_i)P(C_i)} >  P(C_l|x) \quad \forall l \neq j $$
Para distribui√ß√µes Gaussianas com covari√¢ncias iguais, o log das probabilidades posteriores pode ser simplificado, e o classificador Bayesiano atribuir√° x √† classe *j* se:
$$ \delta_j(x) = \log P(C_j) + x^T\Sigma^{-1}\mu_j - \frac{1}{2}\mu_j^T\Sigma^{-1}\mu_j $$
for m√°ximo.  A fun√ß√£o discriminante linear encontrada pela LDA pode ser expressa de forma similar.
$$ \delta_j^{LDA}(x) = x^T \Sigma^{-1} \mu_j  +  b_j $$
onde $b_j$ √© um termo constante que depende de $\mu_j$ e $\Sigma$. A igualdade das formas funcionais, sob as suposi√ß√µes indicadas, demonstra a equival√™ncia entre as decis√µes de classifica√ß√£o. $\blacksquare$
```mermaid
graph LR
    subgraph "Equivalence of LDA and Bayesian Decision"
         direction TB
        A["Gaussian Class Distributions: p(x|C·µ¢)"]
        B["Bayesian Decision Rule: max P(C‚±º|x)"]
        C["Simplified Bayesian Discriminant: Œ¥‚±º(x)"]
        D["LDA Discriminant: Œ¥‚±º(x)"]
        E["Equivalent Decision Boundaries"]
         A --> B
        B --> C
        C --> E
        D --> E
    end
```

**Corol√°rio 4: Fronteiras Quadr√°ticas com Covari√¢ncias Desiguais**
Se relaxarmos a suposi√ß√£o de covari√¢ncias iguais, como em [^4.3], as fronteiras de decis√£o resultantes ser√£o quadr√°ticas (QDA), em vez de lineares, e a equival√™ncia formal com a LDA n√£o se mant√©m.

> ‚ö†Ô∏è **Ponto Crucial**: A suposi√ß√£o de covari√¢ncias iguais em LDA √© uma simplifica√ß√£o importante que leva a fronteiras de decis√£o lineares. A escolha entre modelos lineares (LDA) e quadr√°ticos (QDA) depende da validade dessa suposi√ß√£o e da natureza dos dados, conforme discutido em [^4.3.1].

### Conclus√£o

O bootstrap emerge como uma ferramenta essencial para a an√°lise de incerteza em modelos estat√≠sticos e de machine learning. Atrav√©s de m√©todos de re-amostragem, √© poss√≠vel obter estimativas mais robustas da variabilidade de modelos, tanto param√©tricos quanto n√£o-param√©tricos. As conex√µes do bootstrap com o *maximum likelihood* e infer√™ncia Bayesiana permitem uma compreens√£o mais profunda dos modelos e uma melhor tomada de decis√µes, utilizando t√©cnicas de regulariza√ß√£o, sele√ß√£o de vari√°veis, e outras abordagens como *separating hyperplanes*, *Perceptrons*, *bagging*, *stacking* e *bumping*. A escolha do m√©todo mais adequado depende do problema e dos objetivos de cada an√°lise. O bootstrap, em todas as suas formas, continua a ser uma ferramenta indispens√°vel no arsenal do estat√≠stico e do cientista de dados moderno.

<!-- END DOCUMENT -->

### Footnotes

[^8.1]: "For most of this book, the fitting (learning) of models has been achieved by minimizing a sum of squares for regression, or by minimizing cross-entropy for classification. In fact, both of these minimizations are instances of the maximum likelihood approach to fitting. In this chapter we provide a general exposition of the maximum likelihood approach, as well as the Bayesian method for inference. The bootstrap, introduced in Chapter 7, is discussed in this context, and its relation to maximum likelihood and Bayes is described. Finally, we present some related techniques for model averaging and improvement, including committee methods, bagging, stacking and bumping." *(Trecho de <Model Inference and Averaging>)*
[^8.2]: "Denote the training data by Z = {z1, z2,...,zN}, with zi = (xi, yi), i = 1,2,..., N. Here xi is a one-dimensional input, and yi the outcome, either continuous or categorical. As an example, consider the N = 50 data points shown in the left panel of Figure 8.1. Suppose we decide to fit a cubic spline to the data, with three knots placed at the quartiles of the X values. This is a seven-dimensional linear space of functions, and can be represented, for example, by a linear expansion of B-spline basis functions (see Section 5.9.2):  Œº(x) = ‚àëj=17 Œ≤jhj(x). Here the hj(x), j = 1, 2, ..., 7 are the seven functions shown in the right panel of
