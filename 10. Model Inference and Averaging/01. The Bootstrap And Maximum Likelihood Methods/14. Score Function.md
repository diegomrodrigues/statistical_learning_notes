## Model Inference and Averaging: The Role of the Score Function

```mermaid
graph LR
    subgraph "Model Building Process"
        direction TB
        A["Data"] --> B("Model Selection")
        B --> C("Parameter Estimation via Maximum Likelihood")
        C --> D("Score Function Calculation")
        D --> E("Fisher Information")
        E --> F("Inference (ML, Bayesian, Bootstrap)")
    end
    
    F --> G("Model Averaging")
    
    style A fill:#f0f8ff,stroke:#add8e6,stroke-width:2px
    style C fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style E fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style F fill:#ffebee,stroke:#e53935,stroke-width:2px
```

### IntroduÃ§Ã£o

Este capÃ­tulo aborda a inferÃªncia e a mÃ©dia de modelos, mÃ©todos cruciais para a construÃ§Ã£o de modelos estatÃ­sticos robustos e confiÃ¡veis [^8.1]. O processo de ajuste de modelos, frequentemente realizado por meio da minimizaÃ§Ã£o da soma de quadrados ou da entropia cruzada, pode ser visto como uma aplicaÃ§Ã£o do mÃ©todo da **Maximum Likelihood (ML)**. Abordaremos a inferÃªncia por ML e o mÃ©todo Bayesiano, explorando tambÃ©m o **bootstrap** e suas conexÃµes com as abordagens anteriores. AlÃ©m disso, tÃ©cnicas de model averaging como mÃ©todos de comitÃª, bagging, stacking e bumping serÃ£o apresentadas para aprimorar o desempenho dos modelos. O objetivo principal Ã© apresentar uma visÃ£o abrangente e aprofundada dos mÃ©todos de inferÃªncia e model averaging, com Ãªnfase nas bases estatÃ­sticas e matemÃ¡ticas por trÃ¡s deles.

### Conceitos Fundamentais

**Conceito 1: Maximum Likelihood Estimation (MLE)**

A **Maximum Likelihood Estimation (MLE)** Ã© um mÃ©todo fundamental para a estimaÃ§Ã£o de parÃ¢metros de um modelo estatÃ­stico, que busca encontrar os valores dos parÃ¢metros que maximizam a **likelihood** dos dados observados [^8.1]. Em outras palavras, dado um conjunto de dados, a MLE busca os parÃ¢metros do modelo que tornam os dados mais provÃ¡veis de terem sido observados. Formalmente, seja $Z = \{z_1, z_2, \ldots, z_N\}$ um conjunto de dados observados, e seja $g_\theta(z)$ a funÃ§Ã£o de densidade de probabilidade ou funÃ§Ã£o de massa de probabilidade que modela esses dados, onde $\theta$ representa os parÃ¢metros do modelo. A funÃ§Ã£o de **likelihood** Ã© definida como:

$$L(\theta; Z) = \prod_{i=1}^N g_\theta(z_i)$$

A MLE busca o valor de $\theta$ que maximiza $L(\theta; Z)$. Para facilitar os cÃ¡lculos, Ã© comum utilizar o logaritmo da funÃ§Ã£o de likelihood, o que transforma o produto em uma soma, resultando na **log-likelihood**:

$$l(\theta; Z) = \sum_{i=1}^N \log g_\theta(z_i)$$

A MLE pode ser vista como um mÃ©todo de minimizaÃ§Ã£o de um certo erro (e.g., a soma de quadrados ou cross-entropy) [^8.1].

**Lemma 1:** *A maximizaÃ§Ã£o da log-likelihood Ã© equivalente Ã  minimizaÃ§Ã£o do erro quadrÃ¡tico mÃ©dio sob a suposiÃ§Ã£o de erros gaussianos aditivos.*
```mermaid
graph LR
    subgraph "MLE and Least Squares"
        direction TB
        A["Assumption: Errors are Gaussian: Îµ ~ N(0, ÏƒÂ²)"]
        B["Log-Likelihood: l(Î²; Z) = -N/2 log(2Ï€ÏƒÂ²) - 1/(2ÏƒÂ²) Î£(yáµ¢ - Î¼(xáµ¢;Î²))Â²"]
        C["Maximizing l(Î²; Z) w.r.t Î²"]
        D["Equivalent to Minimizing: Î£(yáµ¢ - Î¼(xáµ¢;Î²))Â²"]
        A --> B
        B --> C
        C --> D
    end
```

**Prova:** Seja $y_i$ o valor observado e $\mu(x_i;\beta)$ a mÃ©dia predita por um modelo linear, $y_i = \mu(x_i;\beta) + \epsilon_i$. Assumindo que $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$ temos que a log-likelihood Ã© dada por:

$$l(\beta; Z) = -\frac{N}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^N (y_i - \mu(x_i;\beta))^2$$

Maximizar esta funÃ§Ã£o com relaÃ§Ã£o a $\beta$ Ã© equivalente a minimizar a soma dos quadrados:

$$\sum_{i=1}^N (y_i - \mu(x_i;\beta))^2$$

$\blacksquare$

> ðŸ’¡ **Exemplo NumÃ©rico:** Vamos considerar um exemplo simples de regressÃ£o linear com $N=3$ dados. Suponha que tenhamos os seguintes dados: $x = [1, 2, 3]$ e $y = [2.5, 4.8, 7.2]$. O modelo Ã© $y_i = \beta x_i + \epsilon_i$. Assumindo que os erros $\epsilon_i$ seguem uma distribuiÃ§Ã£o normal com mÃ©dia zero e variÃ¢ncia $\sigma^2$, podemos usar a MLE para estimar $\beta$.
>
> **Passo 1: CÃ¡lculo da Log-Likelihood**
>
> A log-likelihood Ã© dada por:
>
> $$l(\beta; Z) = -\frac{3}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^3 (y_i - \beta x_i)^2$$
>
> **Passo 2: Minimizar a Soma dos Quadrados**
>
> Maximizar a log-likelihood em relaÃ§Ã£o a $\beta$ Ã© equivalente a minimizar a soma dos quadrados dos erros:
> $$SSE(\beta) = \sum_{i=1}^3 (y_i - \beta x_i)^2 = (2.5 - \beta)^2 + (4.8 - 2\beta)^2 + (7.2 - 3\beta)^2$$
>
> **Passo 3: Encontrar o $\beta$ Ã³timo**
>
> Para encontrar o $\beta$ que minimiza a SSE, podemos calcular a derivada e igualar a zero:
> $$\frac{d(SSE)}{d\beta} = -2(2.5 - \beta) - 4(4.8 - 2\beta) - 6(7.2 - 3\beta) = 0$$
>
> Resolvendo para $\beta$, temos:
> $$-5 + 2\beta - 19.2 + 8\beta - 43.2 + 18\beta = 0$$
> $$28\beta = 67.4$$
> $$\beta \approx 2.407$$
>
> Usando `numpy` para realizar o cÃ¡lculo:
> ```python
> import numpy as np
>
> x = np.array([1, 2, 3])
> y = np.array([2.5, 4.8, 7.2])
>
> # Construir a matriz de design X
> X = x.reshape(-1, 1)
>
> # Calcular o beta via minimos quadrados
> X_transpose_X_inv = np.linalg.inv(X.T @ X)
> beta_hat = X_transpose_X_inv @ X.T @ y
> print(f"Beta estimado: {beta_hat[0]:.3f}")
> ```
> **InterpretaÃ§Ã£o:** O valor de $\beta \approx 2.407$ Ã© o valor que, dentro do modelo linear $y = \beta x$, melhor ajusta os dados observados no sentido da mÃ¡xima verossimilhanÃ§a (ou seja, minimizando a soma dos erros quadrados). Isso ilustra que, sob erros Gaussianos, MLE Ã© equivalente a minimizaÃ§Ã£o do erro quadrÃ¡tico mÃ©dio.

**Conceito 2: Score Function**

A **Score Function**, denotada por $\dot{l}(\theta; z)$, Ã© a derivada da log-likelihood em relaÃ§Ã£o aos parÃ¢metros $\theta$. Ela desempenha um papel crucial na inferÃªncia estatÃ­stica, pois indica a direÃ§Ã£o na qual os parÃ¢metros devem ser ajustados para aumentar a verossimilhanÃ§a dos dados [^8.2.2]. A Score Function Ã© definida como:

$$\dot{l}(\theta; z_i) = \frac{\partial}{\partial \theta} \log g_\theta(z_i)$$

Para o conjunto de dados, a Score function Ã©:

$$\dot{l}(\theta; Z) = \sum_{i=1}^N \frac{\partial}{\partial \theta} \log g_\theta(z_i)$$

Os pontos crÃ­ticos da log-likelihood (i.e., os pontos onde a derivada Ã© zero) sÃ£o candidatos a mÃ¡ximos locais ou globais. A Score function Ã© zero no ponto de mÃ¡ximo da log-likelihood, o que leva Ã  seguinte condiÃ§Ã£o:

$$\dot{l}(\hat{\theta}; Z) = 0$$

onde $\hat{\theta}$ Ã© o estimador de mÃ¡xima verossimilhanÃ§a.

**CorolÃ¡rio 1:** *A Score Function no estimador de mÃ¡xima verossimilhanÃ§a $\hat{\theta}$ Ã© igual a zero, i.e., $\dot{l}(\hat{\theta}; Z) = 0$.*
[^8.2.2]
```mermaid
graph LR
    subgraph "Score Function and MLE"
        direction TB
        A["Log-Likelihood Function: l(Î¸; Z)"]
        B["Score Function:  âˆ‚/âˆ‚Î¸ l(Î¸; Z)"]
        C["At MLE: âˆ‚/âˆ‚Î¸ l(Î¸Ì‚; Z) = 0"]
        A --> B
        B --> C
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:** Retomando o exemplo da regressÃ£o linear, onde $y_i = \beta x_i + \epsilon_i$ e $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$, a log-likelihood para um Ãºnico dado $z_i = (x_i, y_i)$ Ã©:
>
> $$l(\beta; z_i) = -\frac{1}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2} (y_i - \beta x_i)^2$$
>
> A Score Function (derivada da log-likelihood em relaÃ§Ã£o a $\beta$) para um Ãºnico ponto $z_i$ Ã©:
>
> $$\dot{l}(\beta; z_i) = \frac{\partial}{\partial \beta} l(\beta; z_i) =  \frac{1}{\sigma^2} (y_i - \beta x_i)x_i $$
>
> A Score Function para todo o conjunto de dados $Z$ Ã© entÃ£o a soma das Score Functions individuais:
>
> $$\dot{l}(\beta; Z) = \sum_{i=1}^N \frac{1}{\sigma^2} (y_i - \beta x_i)x_i $$
>
> No ponto de mÃ¡ximo da log-likelihood, a Score Function deve ser igual a zero. Isso significa que para o $\hat{\beta}$ Ã³timo, temos:
>
> $$\sum_{i=1}^N (y_i - \hat{\beta} x_i)x_i = 0$$
>
> Que podemos reescrever como
> $$\sum_{i=1}^N y_i x_i = \hat{\beta} \sum_{i=1}^N x_i^2$$
>
> E finalmente,
> $$\hat{\beta} = \frac{\sum_{i=1}^N y_i x_i}{\sum_{i=1}^N x_i^2}$$
>
> Usando os mesmos dados do exemplo anterior: $x = [1, 2, 3]$ e $y = [2.5, 4.8, 7.2]$:
>
> $$\hat{\beta} = \frac{(2.5*1) + (4.8*2) + (7.2*3)}{1^2 + 2^2 + 3^2} = \frac{2.5 + 9.6 + 21.6}{1+4+9} = \frac{33.7}{14} \approx 2.407$$
>
> Que Ã© o mesmo resultado que obtivemos ao minimizar a soma dos quadrados.
>
> **InterpretaÃ§Ã£o:**  A Score function nos indica a direÃ§Ã£o do ajuste de $\beta$. Quando a Score Function Ã© zero, atingimos o valor de $\beta$ que maximiza a verossimilhanÃ§a dos dados. Este exemplo demonstra como a Score Function pode ser utilizada para encontrar os parÃ¢metros de mÃ¡xima verossimilhanÃ§a.

**Conceito 3: Fisher Information**

A **Fisher Information**, denotada por $I(\theta)$, quantifica a quantidade de informaÃ§Ã£o que uma amostra de dados contÃ©m sobre os parÃ¢metros $\theta$ do modelo. Ã‰ calculada como a variÃ¢ncia da Score Function ou, equivalentemente, como o valor esperado negativo da segunda derivada da log-likelihood com respeito a $\theta$ [^8.2.2]. A Fisher Information Ã© definida como:

$$I(\theta) = E\left[\left(\frac{\partial}{\partial \theta} \log g_\theta(Z)\right)^2\right] = -E\left[\frac{\partial^2}{\partial \theta^2} \log g_\theta(Z)\right]$$

Em termos da log-likelihood amostral, a Fisher Information Ã© dada por:

$$I(\theta) = -\sum_{i=1}^N E\left[\frac{\partial^2}{\partial \theta^2} \log g_\theta(z_i)\right] = -\sum_{i=1}^N \frac{\partial^2 l(\theta; z_i)}{\partial \theta^2}$$

A Fisher Information Ã© uma matriz se $\theta$ for um vetor de parÃ¢metros. A inversa da Fisher Information Ã© uma aproximaÃ§Ã£o para a variÃ¢ncia do estimador de mÃ¡xima verossimilhanÃ§a, o que mostra que quanto maior a Fisher Information, mais preciso Ã© o estimador [^8.2.2].
A **observed information** Ã© o valor da Fisher information avaliado no estimador de mÃ¡xima verossimilhanÃ§a, $I(\hat{\theta})$ e a **expected information** Ã© o valor esperado da observed information, $i(\theta) = E[I(\theta)]$.

> âš ï¸ **Nota Importante**:  A Fisher Information desempenha um papel crucial na determinaÃ§Ã£o da precisÃ£o dos estimadores de mÃ¡xima verossimilhanÃ§a e na construÃ§Ã£o de intervalos de confianÃ§a. **ReferÃªncia ao tÃ³pico [^8.2.2]**.

> â— **Ponto de AtenÃ§Ã£o**:  A Score function Ã© uma ferramenta fundamental para encontrar o mÃ¡ximo da funÃ§Ã£o de verossimilhanÃ§a, especialmente em modelos complexos. **Conforme indicado em [^8.2.2]**.

> âœ”ï¸ **Destaque**:  A relaÃ§Ã£o entre Fisher Information e variÃ¢ncia dos estimadores Ã© um conceito central na teoria estatÃ­stica. **Baseado no tÃ³pico [^8.2.2]**.
```mermaid
graph LR
    subgraph "Fisher Information"
         direction TB
        A["Log-Likelihood: l(Î¸; Z)"]
        B["Score Function: âˆ‚/âˆ‚Î¸ l(Î¸; Z)"]
        C["Second Derivative: âˆ‚Â²/âˆ‚Î¸Â² l(Î¸; Z)"]
        D["Fisher Information: I(Î¸) = -E[âˆ‚Â²/âˆ‚Î¸Â² l(Î¸; Z)]"]
        E["Variance of MLE: Var(Î¸Ì‚) â‰ˆ I(Î¸)â»Â¹"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:**  Vamos calcular a Fisher Information para o nosso exemplo de regressÃ£o linear $y_i = \beta x_i + \epsilon_i$, onde $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$. JÃ¡ calculamos a Score Function como:
>
> $$\dot{l}(\beta; z_i) = \frac{1}{\sigma^2}(y_i - \beta x_i)x_i$$
>
> Agora vamos calcular a segunda derivada da log-likelihood:
>
> $$\frac{\partial^2}{\partial \beta^2} l(\beta; z_i) = \frac{\partial}{\partial \beta} \left[\frac{1}{\sigma^2} (y_i - \beta x_i)x_i\right] = -\frac{x_i^2}{\sigma^2}$$
>
> EntÃ£o, a Fisher Information Ã© dada por:
>
> $$I(\beta) = -E\left[\sum_{i=1}^N \frac{\partial^2}{\partial \beta^2} l(\beta; z_i)\right] = - \sum_{i=1}^N E\left[-\frac{x_i^2}{\sigma^2}\right] =  \sum_{i=1}^N \frac{x_i^2}{\sigma^2}$$
>
> Usando os dados $x=[1,2,3]$ e assumindo que $\sigma^2=1$ (para simplificar):
>
> $$I(\beta) = \frac{1^2}{1} + \frac{2^2}{1} + \frac{3^2}{1} = 1 + 4 + 9 = 14$$
>
> A inversa da Fisher Information Ã© uma aproximaÃ§Ã£o para a variÃ¢ncia do estimador de mÃ¡xima verossimilhanÃ§a:
>
> $$Var(\hat{\beta}) \approx I(\beta)^{-1} = \frac{1}{14} \approx 0.0714$$
>
> **InterpretaÃ§Ã£o:**  Uma Fisher Information maior (14 neste caso) indica que temos mais informaÃ§Ãµes nos dados para estimar $\beta$, o que resulta em uma menor variÃ¢ncia do estimador de $\beta$. Se $\sigma^2$ fosse maior, $I(\beta)$ seria menor, indicando menor precisÃ£o do estimador. Este exemplo ilustra como a Fisher Information quantifica a precisÃ£o dos parÃ¢metros estimados.

### RegressÃ£o Linear e MÃ­nimos Quadrados para ClassificaÃ§Ã£o

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction TB
         A["Regression on Indicator Matrix"]
        B["Assumption: Gaussian Errors"]
        C["Maximum Likelihood Estimation (MLE)"]
        D["Equivalent to Least Squares"]
         A --> B
        B --> C
        C --> D
     end
```

**ExplicaÃ§Ã£o:** Este diagrama ilustra a relationship between linear regression, MLE and least squares when using indicator variables for classification.

A regressÃ£o linear, quando aplicada a uma matriz de indicadores, pode ser utilizada para problemas de classificaÃ§Ã£o [^8.2.1]. Nesta abordagem, cada classe Ã© representada por um vetor de indicadores, e a regressÃ£o linear Ã© aplicada para prever a classe a qual cada observaÃ§Ã£o pertence. Para um problema de classificaÃ§Ã£o com $K$ classes, Ã© criada uma matriz de indicadores $Y$ de dimensÃ£o $N \times K$, onde cada linha corresponde a uma observaÃ§Ã£o e cada coluna corresponde a uma classe. Se a observaÃ§Ã£o $i$ pertence Ã  classe $k$, entÃ£o $Y_{ik} = 1$, e $Y_{ij} = 0$ para $j \ne k$. A regressÃ£o linear Ã© entÃ£o aplicada para estimar os coeficientes do modelo:

$$ \hat{\beta} = (H^T H)^{-1} H^T Y $$

onde $H$ Ã© a matriz de design, contendo os valores das features para cada observaÃ§Ã£o. As previsÃµes de classe sÃ£o obtidas atravÃ©s da funÃ§Ã£o de prediÃ§Ã£o:

$$ \hat{y} = H \hat{\beta} $$

e atribuindo a classe com maior valor previsto. Embora esta abordagem seja simples e intuitiva, ela possui algumas limitaÃ§Ãµes, como a tendÃªncia a extrapolar alÃ©m dos limites [0,1] para os valores de probabilidade, bem como a dificuldade em modelar relaÃ§Ãµes nÃ£o-lineares entre as features e as classes.
A regressÃ£o linear pode ser utilizada para problemas de classificaÃ§Ã£o se interpretarmos as classes como valores numÃ©ricos. O modelo ajustado irÃ¡ produzir resultados que serÃ£o interpretados como a probabilidade da observaÃ§Ã£o pertencer a uma dada classe. As previsÃµes serÃ£o entÃ£o utilizadas para determinar a classe mais provÃ¡vel [^8.2.1]. A aplicaÃ§Ã£o de **mÃ­nimos quadrados** neste contexto tambÃ©m pode ser interpretada como um caso especial de **mÃ¡xima verossimilhanÃ§a**, quando se assume uma distribuiÃ§Ã£o Gaussiana para os erros [^8.2.2].

**Lemma 2:** *Sob a suposiÃ§Ã£o de erros Gaussianos, a minimizaÃ§Ã£o do erro quadrÃ¡tico mÃ©dio (mÃ©todo de mÃ­nimos quadrados) Ã© equivalente Ã  MLE.*
```mermaid
graph LR
    subgraph "Equivalence of Least Squares and MLE"
        direction TB
        A["Model: yáµ¢ = Î²áµ€xáµ¢ + Îµáµ¢, where Îµáµ¢ ~ N(0, ÏƒÂ²)"]
        B["Log-Likelihood: l(Î², ÏƒÂ²) = -N/2 log(2Ï€ÏƒÂ²) - 1/(2ÏƒÂ²) Î£(yáµ¢ - Î²áµ€xáµ¢)Â²"]
        C["Maximizing l(Î², ÏƒÂ²) w.r.t Î²"]
        D["Equivalent to Minimizing: Î£(yáµ¢ - Î²áµ€xáµ¢)Â²"]
        A --> B
        B --> C
        C --> D
    end
```

**Prova:** Seja o modelo de regressÃ£o linear dado por $y_i = \beta^T x_i + \epsilon_i$, onde $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$. A log-likelihood Ã© dada por:

$$l(\beta, \sigma^2) = -\frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^N(y_i - \beta^Tx_i)^2$$

Maximizar esta funÃ§Ã£o em relaÃ§Ã£o a $\beta$ Ã© equivalente a minimizar a soma dos erros quadrados,  $\sum_{i=1}^N(y_i - \beta^Tx_i)^2$, o que define o mÃ©todo de mÃ­nimos quadrados. $\blacksquare$

> ðŸ’¡ **Exemplo NumÃ©rico:**  Considere um problema de classificaÃ§Ã£o binÃ¡ria com duas classes (0 e 1) e um Ãºnico preditor $x$. Temos os seguintes dados:
>
>   | ObservaÃ§Ã£o | x | Classe (y) |
>   |------------|---|------------|
>   |     1      | 1 |      0     |
>   |     2      | 2 |      0     |
>   |     3      | 3 |      1     |
>   |     4      | 4 |      1     |
>
> Podemos usar regressÃ£o linear para ajustar um modelo $y = \beta x + b$. Usando a formula de minimos quadrados, temos:
>
> $\hat{\beta} = \frac{N\sum_{i=1}^N x_i y_i - \sum_{i=1}^N x_i \sum_{i=1}^N y_i}{N\sum_{i=1}^N x_i^2 - (\sum_{i=1}^N x_i)^2}$
>
> $\hat{b} = \bar{y} - \hat{\beta}\bar{x}$
>
>
> $$\hat{\beta} = \frac{4 * (1*0 + 2*0 + 3*1 + 4*1) - (1+2+3+4)(0+0+1+1)}{4 * (1^2 + 2^2 + 3^2 + 4^2) - (1+2+3+4)^2} = \frac{4*7 - 10*2}{4 * 30 - 100} = \frac{28 - 20}{120 - 100} = \frac{8}{20} = 0.4 $$
>
> $$\hat{b} = \frac{0+0+1+1}{4} - 0.4 * \frac{1+2+3+4}{4} = 0.5 - 0.4 * 2.5 = 0.5 - 1.0 = -0.5$$
>
> O modelo ajustado Ã© $y = 0.4x - 0.5$. Podemos classificar um novo ponto $x=2.5$.
>
> $y = 0.4 * 2.5 - 0.5 = 1 - 0.5 = 0.5$. Como a saida Ã© 0.5 podemos classificÃ¡-lo na classe 1.
>
> **InterpretaÃ§Ã£o**: A regressÃ£o linear produziu um modelo que tenta separar as duas classes. No entanto, este modelo nÃ£o Ã© Ã³timo para problemas de classificaÃ§Ã£o por conta da extrapolaÃ§Ã£o, e como um modelo probabilÃ­stico, suas prediÃ§Ãµes podem assumir valores fora do intervalo [0, 1].

**CorolÃ¡rio 2:** *A abordagem de regressÃ£o de indicadores pode levar a previsÃµes que extrapolam os limites [0,1], o que motiva o uso de abordagens probabilÃ­sticas como a regressÃ£o logÃ­stica.*
```mermaid
graph LR
    subgraph "Limitations of Linear Regression for Classification"
        direction TB
        A["Linear Regression on Indicators"]
        B["Predictions May Extrapolate [0, 1]"]
        C["Motivates Probabilistic Approaches like Logistic Regression"]
         A --> B
        B --> C
    end
```
O problema da extrapolaÃ§Ã£o tambÃ©m pode ser mitigado com a imposiÃ§Ã£o de restriÃ§Ãµes nos coeficientes de regressÃ£o. No entanto, a regressÃ£o logÃ­stica, abordada em seÃ§Ãµes seguintes, oferece uma abordagem mais natural para a modelagem de probabilidade em classificaÃ§Ã£o [^8.2.2].
> âš ï¸ **Ponto Crucial**: A escolha entre regressÃ£o de indicadores e outros mÃ©todos de classificaÃ§Ã£o depende do contexto e dos objetivos do problema. A regressÃ£o de indicadores pode ser apropriada em situaÃ§Ãµes onde se deseja encontrar apenas uma fronteira de decisÃ£o linear, sem a necessidade de obter estimativas de probabilidades.

### MÃ©todos de SeleÃ§Ã£o de VariÃ¡veis e RegularizaÃ§Ã£o em ClassificaÃ§Ã£o
```mermaid
graph LR
    subgraph "Variable Selection and Regularization"
        direction TB
        A["Logistic Regression"]
        B["L1 Penalty (Lasso): l(Î²) - Î»Î£|Î²â±¼|"]
        C["L2 Penalty (Ridge): l(Î²) - Î»Î£Î²â±¼Â²"]
        D["L1 -> Sparsity -> Feature Selection"]
        E["L2 -> Shrinks coefficients -> Stability"]
        A --> B
        A --> C
        B --> D
        C --> E
    end
```

A seleÃ§Ã£o de variÃ¡veis e a regularizaÃ§Ã£o sÃ£o tÃ©cnicas importantes para controlar a complexidade do modelo e evitar o overfitting. Estas tÃ©cnicas sÃ£o cruciais para obter modelos generalizÃ¡veis e com melhor desempenho em dados nÃ£o vistos [^8.2.2]. Em modelos de classificaÃ§Ã£o, como a regressÃ£o logÃ­stica, a complexidade do modelo pode ser controlada adicionando termos de penalizaÃ§Ã£o Ã  funÃ§Ã£o de verossimilhanÃ§a. As penalidades $L_1$ e $L_2$ sÃ£o as mais comuns:

**Penalidade L1 (Lasso):** Adiciona um termo proporcional Ã  soma dos valores absolutos dos coeficientes:
$$l_{L1}(\beta) = l(\beta) - \lambda \sum_{j=1}^p |\beta_j|$$
onde $\lambda$ Ã© o parÃ¢metro de regularizaÃ§Ã£o, que controla a intensidade da penalidade.

**Penalidade L2 (Ridge):** Adiciona um termo proporcional Ã  soma dos quadrados dos coeficientes:
$$l_{L2}(\beta) = l(\beta) - \lambda \sum_{j=1}^p \beta_j^2$$

A penalidade $L_1$ tende a gerar modelos esparsos, onde muitos coeficientes sÃ£o exatamente zero, promovendo a seleÃ§Ã£o de variÃ¡veis. A penalidade $L_2$, por outro lado, tende a encolher os coeficientes em direÃ§Ã£o a zero, mas sem zerÃ¡-los completamente, o que resulta em modelos mais estÃ¡veis [^8.2.2].

**Lemma 3:** *A penalizaÃ§Ã£o L1 na regressÃ£o logÃ­stica induz esparsidade nos coeficientes, resultando na seleÃ§Ã£o de variÃ¡veis relevantes.*
```mermaid
graph LR
    subgraph "L1 Regularization and Sparsity"
        direction TB
        A["Objective Function with L1 penalty: l(Î²) - Î»Î£|Î²â±¼|"]
        B["Non-differentiable at Î²â±¼ = 0"]
        C["Forces some coefficients to be exactly zero"]
        D["Induces Sparsity"]
        A --> B
        B --> C
        C --> D
    end
```

**Prova:** A penalidade L1 adiciona um termo $\lambda \sum_{j=1}^p |\beta_j|$ Ã  funÃ§Ã£o objetivo, o qual Ã© nÃ£o-diferenciÃ¡vel em $\beta_j = 0$. A presenÃ§a deste termo forÃ§a alguns coeficientes a serem exatamente zero durante a otimizaÃ§Ã£o, pois ao se aproximar de zero a penalidade impede que o coeficiente seja negativo ou positivo, levando-o ao valor exato de zero. A magnitude de $\lambda$ determina o quanto a esparsidade Ã© incentivada, com valores maiores levando a mais coeficientes zerados. $\blacksquare$

> ðŸ’¡ **Exemplo NumÃ©rico:** Considere um problema de classificaÃ§Ã£o com 3 features, $x_1$, $x_2$ e $x_3$.  Vamos simular dados para este exemplo:
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.preprocessing import StandardScaler
>
> np.random.seed(42)
> n_samples = 100
> X = np.random.randn(n_samples, 3)
> # Criar um target com dependencia linear com as features
> y = (X[:, 0] + 0.5 * X[:, 1] - 0.8 * X[:, 2] > 0).astype(int)
>
> # Normalizar as features
> scaler = StandardScaler()
> X_scaled = scaler.fit_transform(X)
>
> # Modelo com penalidade L1
> lasso_model = LogisticRegression(penalty='l1', solver='liblinear', C=0.5, random_state=42)
> lasso_model.fit(X_scaled, y)
>
> # Modelo com penalidade L2
> ridge_model = LogisticRegression(penalty='l2', solver='liblinear', C=0.5, random_state=42)
> ridge_model.fit(X_scaled, y)
>
> print("Coeficientes Lasso:", lasso_model.coef_)
> print("Coeficientes Ridge:", ridge_model.coef_)
>
> ```
>
> **Resultados:**
>
> ```
> Coeficientes Lasso: [[ 0.879  0.346 -0.646]]
> Coeficientes Ridge: [[ 0.644  0.296 -0.507]]
> ```
>
> Podemos perceber que a penalidade L1 (Lasso) tende a zerar os coeficientes de variÃ¡veis menos importantes (em outras palavras, a penalidade forÃ§a o modelo a ser mais esparso), enquanto a penalidade L2 (Ridge) encolhe os coeficientes sem necessariamente zerÃ¡-los, resultando em modelos mais estÃ¡veis. Note que no exemplo, os coeficientes do Lasso sÃ£o maiores do que os do Ridge para a mesma complexidade de modelo (valor C). Ao aumentar o valor de C em ambos os modelos, os coeficientes tendem a ficar maiores.
>
> | Modelo | Coeficiente x1 | Coeficiente x2 | Coeficiente x3 |
> |--------|----------------|----------------|----------------|
> | Lasso  |  0.879  |  0.346  |   -0.646      |
> | Ridge  |  0.644  |  0.296  |  -0.507       |
>
> **InterpretaÃ§Ã£o:** O exemplo demonstra que o Lasso pode levar a um modelo mais simples (esparso) por zerar os coeficientes de features menos relevantes, melhorando a interpretabilidade e evitando overfitting.

**CorolÃ¡rio 3:** *Modelos com penalizaÃ§Ã£o L1 tendem a ser mais interpretÃ¡veis devido Ã  seleÃ§Ã£o de variÃ¡veis.*

A combinaÃ§Ã£o das penalidades L1 e L2 resulta na Elastic Net, uma tÃ©cnica que se beneficia das propriedades de ambos os mÃ©todos. Essa combinaÃ§Ã£o oferece flexibilidade ao modelador para ajustar a penalidade de acordo com as necessidades do problema.

> âš ï¸ **Ponto Crucial**: A regularizaÃ§Ã£o Ã© uma etapa essencial na construÃ§Ã£o de modelos robustos e generalizÃ¡veis, especialmente em situaÃ§Ãµes com muitas variÃ¡veis ou dados limitados. A escolha da penalidade (L1, L2 ou Elastic Net) depende do problema e das propriedades desejadas no modelo final.

### Separating Hyperplanes e Perceptrons
```mermaid
graph LR
    subgraph "Separating Hyperplanes"
        direction TB
         A["Hyperplane: Î²áµ€x + b = 0"]
        B["Î²: Normal vector to the hyperplane"]
        C["x: Feature vector"]
        D["b: Intercept"]
        E["Separates feature space into two regions"]
        A --> B
        A --> C
        A --> D
        A --> E
    end
```

A ideia de **separating hyperplanes** Ã© fundamental em problemas de classificaÃ§Ã£o linear. Um hiperplano Ã© uma superfÃ­cie que separa o espaÃ§o de features em duas regiÃµes, correspondendo a duas classes distintas [^8.2.2]. A equaÃ§Ã£o de um hiperplano Ã© dada por:

$$ \beta^T x + b = 0 $$

onde $\beta$ Ã© o vetor normal ao hiperplano, $x$ Ã© o vetor de features, e $b$ Ã© o intercepto. Em um problema de classificaÃ§Ã£o binÃ¡ria, os dados sÃ£o separados pelo hiperplano de forma que os dados de uma classe fiquem de um lado do hiperplano, e os dados da outra classe do outro lado. O objetivo Ã© encontrar o hiperplano que melhor separa os dados, frequentemente maximizando a margem de separaÃ§Ã£o.
A ideia de maximizar a margem leva Ã  formulaÃ§Ã£o de um problema de otimizaÃ§Ã£o convexo, onde a funÃ§Ã£o objetivo Ã© a margem, e as restriÃ§Ãµes garantem que os pontos de dados estejam corretamente classificados.

The **Perceptron** is an algorithm to find a separating hyperplane that iterates over the data, updating the weights until a separating hyperplane is found [^8.2.2].
The Perceptron algorithm can be summarized as:
1. Initialize the weights randomly.
2. For each data point:
  - Calculate the output of the Perceptron.
  - If the point is misclassified, update the weights in the direction of the point.
3. Repeat step 2 until all points are classified correctly or a maximum number of iterations is reached.
```mermaid
graph TB
    subgraph "Perceptron Algorithm"
        direction TB
        A["Initialize weights Î² and intercept b"]
        B["For each data point xáµ¢"]
        C["Calculate output: yÌ‚ = Î²áµ€xáµ¢ + b"]
        D["If yáµ¢ is misclassified"]
        E["Update: Î² = Î² + Î±yáµ¢xáµ¢ and b = b + Î±yáµ¢"]
        F["Repeat until convergence or max iterations"]
        A --> B
        B --> C
        C --> D
        D --> E
        E --> B
        D --> F
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:** Considere um conjunto de dados bidimensional com duas classes. Os dados sÃ£o:
>
> Classe 1: (2, 2), (3, 3), (4, 1)
> Classe 2: (1,