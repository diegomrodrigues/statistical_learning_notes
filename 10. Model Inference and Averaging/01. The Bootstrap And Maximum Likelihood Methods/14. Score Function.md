## Model Inference and Averaging: The Role of the Score Function

```mermaid
graph LR
    subgraph "Model Building Process"
        direction TB
        A["Data"] --> B("Model Selection")
        B --> C("Parameter Estimation via Maximum Likelihood")
        C --> D("Score Function Calculation")
        D --> E("Fisher Information")
        E --> F("Inference (ML, Bayesian, Bootstrap)")
    end
    
    F --> G("Model Averaging")
    
    style A fill:#f0f8ff,stroke:#add8e6,stroke-width:2px
    style C fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style E fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style F fill:#ffebee,stroke:#e53935,stroke-width:2px
```

### Introdu√ß√£o

Este cap√≠tulo aborda a infer√™ncia e a m√©dia de modelos, m√©todos cruciais para a constru√ß√£o de modelos estat√≠sticos robustos e confi√°veis [^8.1]. O processo de ajuste de modelos, frequentemente realizado por meio da minimiza√ß√£o da soma de quadrados ou da entropia cruzada, pode ser visto como uma aplica√ß√£o do m√©todo da **Maximum Likelihood (ML)**. Abordaremos a infer√™ncia por ML e o m√©todo Bayesiano, explorando tamb√©m o **bootstrap** e suas conex√µes com as abordagens anteriores. Al√©m disso, t√©cnicas de model averaging como m√©todos de comit√™, bagging, stacking e bumping ser√£o apresentadas para aprimorar o desempenho dos modelos. O objetivo principal √© apresentar uma vis√£o abrangente e aprofundada dos m√©todos de infer√™ncia e model averaging, com √™nfase nas bases estat√≠sticas e matem√°ticas por tr√°s deles.

### Conceitos Fundamentais

**Conceito 1: Maximum Likelihood Estimation (MLE)**

A **Maximum Likelihood Estimation (MLE)** √© um m√©todo fundamental para a estima√ß√£o de par√¢metros de um modelo estat√≠stico, que busca encontrar os valores dos par√¢metros que maximizam a **likelihood** dos dados observados [^8.1]. Em outras palavras, dado um conjunto de dados, a MLE busca os par√¢metros do modelo que tornam os dados mais prov√°veis de terem sido observados. Formalmente, seja $Z = \{z_1, z_2, \ldots, z_N\}$ um conjunto de dados observados, e seja $g_\theta(z)$ a fun√ß√£o de densidade de probabilidade ou fun√ß√£o de massa de probabilidade que modela esses dados, onde $\theta$ representa os par√¢metros do modelo. A fun√ß√£o de **likelihood** √© definida como:

$$L(\theta; Z) = \prod_{i=1}^N g_\theta(z_i)$$

A MLE busca o valor de $\theta$ que maximiza $L(\theta; Z)$. Para facilitar os c√°lculos, √© comum utilizar o logaritmo da fun√ß√£o de likelihood, o que transforma o produto em uma soma, resultando na **log-likelihood**:

$$l(\theta; Z) = \sum_{i=1}^N \log g_\theta(z_i)$$

A MLE pode ser vista como um m√©todo de minimiza√ß√£o de um certo erro (e.g., a soma de quadrados ou cross-entropy) [^8.1].

**Lemma 1:** *A maximiza√ß√£o da log-likelihood √© equivalente √† minimiza√ß√£o do erro quadr√°tico m√©dio sob a suposi√ß√£o de erros gaussianos aditivos.*
```mermaid
graph LR
    subgraph "MLE and Least Squares"
        direction TB
        A["Assumption: Errors are Gaussian: Œµ ~ N(0, œÉ¬≤)"]
        B["Log-Likelihood: l(Œ≤; Z) = -N/2 log(2œÄœÉ¬≤) - 1/(2œÉ¬≤) Œ£(y·µ¢ - Œº(x·µ¢;Œ≤))¬≤"]
        C["Maximizing l(Œ≤; Z) w.r.t Œ≤"]
        D["Equivalent to Minimizing: Œ£(y·µ¢ - Œº(x·µ¢;Œ≤))¬≤"]
        A --> B
        B --> C
        C --> D
    end
```

**Prova:** Seja $y_i$ o valor observado e $\mu(x_i;\beta)$ a m√©dia predita por um modelo linear, $y_i = \mu(x_i;\beta) + \epsilon_i$. Assumindo que $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$ temos que a log-likelihood √© dada por:

$$l(\beta; Z) = -\frac{N}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^N (y_i - \mu(x_i;\beta))^2$$

Maximizar esta fun√ß√£o com rela√ß√£o a $\beta$ √© equivalente a minimizar a soma dos quadrados:

$$\sum_{i=1}^N (y_i - \mu(x_i;\beta))^2$$

$\blacksquare$

> üí° **Exemplo Num√©rico:** Vamos considerar um exemplo simples de regress√£o linear com $N=3$ dados. Suponha que tenhamos os seguintes dados: $x = [1, 2, 3]$ e $y = [2.5, 4.8, 7.2]$. O modelo √© $y_i = \beta x_i + \epsilon_i$. Assumindo que os erros $\epsilon_i$ seguem uma distribui√ß√£o normal com m√©dia zero e vari√¢ncia $\sigma^2$, podemos usar a MLE para estimar $\beta$.
>
> **Passo 1: C√°lculo da Log-Likelihood**
>
> A log-likelihood √© dada por:
>
> $$l(\beta; Z) = -\frac{3}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^3 (y_i - \beta x_i)^2$$
>
> **Passo 2: Minimizar a Soma dos Quadrados**
>
> Maximizar a log-likelihood em rela√ß√£o a $\beta$ √© equivalente a minimizar a soma dos quadrados dos erros:
> $$SSE(\beta) = \sum_{i=1}^3 (y_i - \beta x_i)^2 = (2.5 - \beta)^2 + (4.8 - 2\beta)^2 + (7.2 - 3\beta)^2$$
>
> **Passo 3: Encontrar o $\beta$ √≥timo**
>
> Para encontrar o $\beta$ que minimiza a SSE, podemos calcular a derivada e igualar a zero:
> $$\frac{d(SSE)}{d\beta} = -2(2.5 - \beta) - 4(4.8 - 2\beta) - 6(7.2 - 3\beta) = 0$$
>
> Resolvendo para $\beta$, temos:
> $$-5 + 2\beta - 19.2 + 8\beta - 43.2 + 18\beta = 0$$
> $$28\beta = 67.4$$
> $$\beta \approx 2.407$$
>
> Usando `numpy` para realizar o c√°lculo:
> ```python
> import numpy as np
>
> x = np.array([1, 2, 3])
> y = np.array([2.5, 4.8, 7.2])
>
> # Construir a matriz de design X
> X = x.reshape(-1, 1)
>
> # Calcular o beta via minimos quadrados
> X_transpose_X_inv = np.linalg.inv(X.T @ X)
> beta_hat = X_transpose_X_inv @ X.T @ y
> print(f"Beta estimado: {beta_hat[0]:.3f}")
> ```
> **Interpreta√ß√£o:** O valor de $\beta \approx 2.407$ √© o valor que, dentro do modelo linear $y = \beta x$, melhor ajusta os dados observados no sentido da m√°xima verossimilhan√ßa (ou seja, minimizando a soma dos erros quadrados). Isso ilustra que, sob erros Gaussianos, MLE √© equivalente a minimiza√ß√£o do erro quadr√°tico m√©dio.

**Conceito 2: Score Function**

A **Score Function**, denotada por $\dot{l}(\theta; z)$, √© a derivada da log-likelihood em rela√ß√£o aos par√¢metros $\theta$. Ela desempenha um papel crucial na infer√™ncia estat√≠stica, pois indica a dire√ß√£o na qual os par√¢metros devem ser ajustados para aumentar a verossimilhan√ßa dos dados [^8.2.2]. A Score Function √© definida como:

$$\dot{l}(\theta; z_i) = \frac{\partial}{\partial \theta} \log g_\theta(z_i)$$

Para o conjunto de dados, a Score function √©:

$$\dot{l}(\theta; Z) = \sum_{i=1}^N \frac{\partial}{\partial \theta} \log g_\theta(z_i)$$

Os pontos cr√≠ticos da log-likelihood (i.e., os pontos onde a derivada √© zero) s√£o candidatos a m√°ximos locais ou globais. A Score function √© zero no ponto de m√°ximo da log-likelihood, o que leva √† seguinte condi√ß√£o:

$$\dot{l}(\hat{\theta}; Z) = 0$$

onde $\hat{\theta}$ √© o estimador de m√°xima verossimilhan√ßa.

**Corol√°rio 1:** *A Score Function no estimador de m√°xima verossimilhan√ßa $\hat{\theta}$ √© igual a zero, i.e., $\dot{l}(\hat{\theta}; Z) = 0$.*
[^8.2.2]
```mermaid
graph LR
    subgraph "Score Function and MLE"
        direction TB
        A["Log-Likelihood Function: l(Œ∏; Z)"]
        B["Score Function:  ‚àÇ/‚àÇŒ∏ l(Œ∏; Z)"]
        C["At MLE: ‚àÇ/‚àÇŒ∏ l(Œ∏ÃÇ; Z) = 0"]
        A --> B
        B --> C
    end
```

> üí° **Exemplo Num√©rico:** Retomando o exemplo da regress√£o linear, onde $y_i = \beta x_i + \epsilon_i$ e $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$, a log-likelihood para um √∫nico dado $z_i = (x_i, y_i)$ √©:
>
> $$l(\beta; z_i) = -\frac{1}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2} (y_i - \beta x_i)^2$$
>
> A Score Function (derivada da log-likelihood em rela√ß√£o a $\beta$) para um √∫nico ponto $z_i$ √©:
>
> $$\dot{l}(\beta; z_i) = \frac{\partial}{\partial \beta} l(\beta; z_i) =  \frac{1}{\sigma^2} (y_i - \beta x_i)x_i $$
>
> A Score Function para todo o conjunto de dados $Z$ √© ent√£o a soma das Score Functions individuais:
>
> $$\dot{l}(\beta; Z) = \sum_{i=1}^N \frac{1}{\sigma^2} (y_i - \beta x_i)x_i $$
>
> No ponto de m√°ximo da log-likelihood, a Score Function deve ser igual a zero. Isso significa que para o $\hat{\beta}$ √≥timo, temos:
>
> $$\sum_{i=1}^N (y_i - \hat{\beta} x_i)x_i = 0$$
>
> Que podemos reescrever como
> $$\sum_{i=1}^N y_i x_i = \hat{\beta} \sum_{i=1}^N x_i^2$$
>
> E finalmente,
> $$\hat{\beta} = \frac{\sum_{i=1}^N y_i x_i}{\sum_{i=1}^N x_i^2}$$
>
> Usando os mesmos dados do exemplo anterior: $x = [1, 2, 3]$ e $y = [2.5, 4.8, 7.2]$:
>
> $$\hat{\beta} = \frac{(2.5*1) + (4.8*2) + (7.2*3)}{1^2 + 2^2 + 3^2} = \frac{2.5 + 9.6 + 21.6}{1+4+9} = \frac{33.7}{14} \approx 2.407$$
>
> Que √© o mesmo resultado que obtivemos ao minimizar a soma dos quadrados.
>
> **Interpreta√ß√£o:**  A Score function nos indica a dire√ß√£o do ajuste de $\beta$. Quando a Score Function √© zero, atingimos o valor de $\beta$ que maximiza a verossimilhan√ßa dos dados. Este exemplo demonstra como a Score Function pode ser utilizada para encontrar os par√¢metros de m√°xima verossimilhan√ßa.

**Conceito 3: Fisher Information**

A **Fisher Information**, denotada por $I(\theta)$, quantifica a quantidade de informa√ß√£o que uma amostra de dados cont√©m sobre os par√¢metros $\theta$ do modelo. √â calculada como a vari√¢ncia da Score Function ou, equivalentemente, como o valor esperado negativo da segunda derivada da log-likelihood com respeito a $\theta$ [^8.2.2]. A Fisher Information √© definida como:

$$I(\theta) = E\left[\left(\frac{\partial}{\partial \theta} \log g_\theta(Z)\right)^2\right] = -E\left[\frac{\partial^2}{\partial \theta^2} \log g_\theta(Z)\right]$$

Em termos da log-likelihood amostral, a Fisher Information √© dada por:

$$I(\theta) = -\sum_{i=1}^N E\left[\frac{\partial^2}{\partial \theta^2} \log g_\theta(z_i)\right] = -\sum_{i=1}^N \frac{\partial^2 l(\theta; z_i)}{\partial \theta^2}$$

A Fisher Information √© uma matriz se $\theta$ for um vetor de par√¢metros. A inversa da Fisher Information √© uma aproxima√ß√£o para a vari√¢ncia do estimador de m√°xima verossimilhan√ßa, o que mostra que quanto maior a Fisher Information, mais preciso √© o estimador [^8.2.2].
A **observed information** √© o valor da Fisher information avaliado no estimador de m√°xima verossimilhan√ßa, $I(\hat{\theta})$ e a **expected information** √© o valor esperado da observed information, $i(\theta) = E[I(\theta)]$.

> ‚ö†Ô∏è **Nota Importante**:  A Fisher Information desempenha um papel crucial na determina√ß√£o da precis√£o dos estimadores de m√°xima verossimilhan√ßa e na constru√ß√£o de intervalos de confian√ßa. **Refer√™ncia ao t√≥pico [^8.2.2]**.

> ‚ùó **Ponto de Aten√ß√£o**:  A Score function √© uma ferramenta fundamental para encontrar o m√°ximo da fun√ß√£o de verossimilhan√ßa, especialmente em modelos complexos. **Conforme indicado em [^8.2.2]**.

> ‚úîÔ∏è **Destaque**:  A rela√ß√£o entre Fisher Information e vari√¢ncia dos estimadores √© um conceito central na teoria estat√≠stica. **Baseado no t√≥pico [^8.2.2]**.
```mermaid
graph LR
    subgraph "Fisher Information"
         direction TB
        A["Log-Likelihood: l(Œ∏; Z)"]
        B["Score Function: ‚àÇ/‚àÇŒ∏ l(Œ∏; Z)"]
        C["Second Derivative: ‚àÇ¬≤/‚àÇŒ∏¬≤ l(Œ∏; Z)"]
        D["Fisher Information: I(Œ∏) = -E[‚àÇ¬≤/‚àÇŒ∏¬≤ l(Œ∏; Z)]"]
        E["Variance of MLE: Var(Œ∏ÃÇ) ‚âà I(Œ∏)‚Åª¬π"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

> üí° **Exemplo Num√©rico:**  Vamos calcular a Fisher Information para o nosso exemplo de regress√£o linear $y_i = \beta x_i + \epsilon_i$, onde $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$. J√° calculamos a Score Function como:
>
> $$\dot{l}(\beta; z_i) = \frac{1}{\sigma^2}(y_i - \beta x_i)x_i$$
>
> Agora vamos calcular a segunda derivada da log-likelihood:
>
> $$\frac{\partial^2}{\partial \beta^2} l(\beta; z_i) = \frac{\partial}{\partial \beta} \left[\frac{1}{\sigma^2} (y_i - \beta x_i)x_i\right] = -\frac{x_i^2}{\sigma^2}$$
>
> Ent√£o, a Fisher Information √© dada por:
>
> $$I(\beta) = -E\left[\sum_{i=1}^N \frac{\partial^2}{\partial \beta^2} l(\beta; z_i)\right] = - \sum_{i=1}^N E\left[-\frac{x_i^2}{\sigma^2}\right] =  \sum_{i=1}^N \frac{x_i^2}{\sigma^2}$$
>
> Usando os dados $x=[1,2,3]$ e assumindo que $\sigma^2=1$ (para simplificar):
>
> $$I(\beta) = \frac{1^2}{1} + \frac{2^2}{1} + \frac{3^2}{1} = 1 + 4 + 9 = 14$$
>
> A inversa da Fisher Information √© uma aproxima√ß√£o para a vari√¢ncia do estimador de m√°xima verossimilhan√ßa:
>
> $$Var(\hat{\beta}) \approx I(\beta)^{-1} = \frac{1}{14} \approx 0.0714$$
>
> **Interpreta√ß√£o:**  Uma Fisher Information maior (14 neste caso) indica que temos mais informa√ß√µes nos dados para estimar $\beta$, o que resulta em uma menor vari√¢ncia do estimador de $\beta$. Se $\sigma^2$ fosse maior, $I(\beta)$ seria menor, indicando menor precis√£o do estimador. Este exemplo ilustra como a Fisher Information quantifica a precis√£o dos par√¢metros estimados.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction TB
         A["Regression on Indicator Matrix"]
        B["Assumption: Gaussian Errors"]
        C["Maximum Likelihood Estimation (MLE)"]
        D["Equivalent to Least Squares"]
         A --> B
        B --> C
        C --> D
     end
```

**Explica√ß√£o:** Este diagrama ilustra a relationship between linear regression, MLE and least squares when using indicator variables for classification.

A regress√£o linear, quando aplicada a uma matriz de indicadores, pode ser utilizada para problemas de classifica√ß√£o [^8.2.1]. Nesta abordagem, cada classe √© representada por um vetor de indicadores, e a regress√£o linear √© aplicada para prever a classe a qual cada observa√ß√£o pertence. Para um problema de classifica√ß√£o com $K$ classes, √© criada uma matriz de indicadores $Y$ de dimens√£o $N \times K$, onde cada linha corresponde a uma observa√ß√£o e cada coluna corresponde a uma classe. Se a observa√ß√£o $i$ pertence √† classe $k$, ent√£o $Y_{ik} = 1$, e $Y_{ij} = 0$ para $j \ne k$. A regress√£o linear √© ent√£o aplicada para estimar os coeficientes do modelo:

$$ \hat{\beta} = (H^T H)^{-1} H^T Y $$

onde $H$ √© a matriz de design, contendo os valores das features para cada observa√ß√£o. As previs√µes de classe s√£o obtidas atrav√©s da fun√ß√£o de predi√ß√£o:

$$ \hat{y} = H \hat{\beta} $$

e atribuindo a classe com maior valor previsto. Embora esta abordagem seja simples e intuitiva, ela possui algumas limita√ß√µes, como a tend√™ncia a extrapolar al√©m dos limites [0,1] para os valores de probabilidade, bem como a dificuldade em modelar rela√ß√µes n√£o-lineares entre as features e as classes.
A regress√£o linear pode ser utilizada para problemas de classifica√ß√£o se interpretarmos as classes como valores num√©ricos. O modelo ajustado ir√° produzir resultados que ser√£o interpretados como a probabilidade da observa√ß√£o pertencer a uma dada classe. As previs√µes ser√£o ent√£o utilizadas para determinar a classe mais prov√°vel [^8.2.1]. A aplica√ß√£o de **m√≠nimos quadrados** neste contexto tamb√©m pode ser interpretada como um caso especial de **m√°xima verossimilhan√ßa**, quando se assume uma distribui√ß√£o Gaussiana para os erros [^8.2.2].

**Lemma 2:** *Sob a suposi√ß√£o de erros Gaussianos, a minimiza√ß√£o do erro quadr√°tico m√©dio (m√©todo de m√≠nimos quadrados) √© equivalente √† MLE.*
```mermaid
graph LR
    subgraph "Equivalence of Least Squares and MLE"
        direction TB
        A["Model: y·µ¢ = Œ≤·µÄx·µ¢ + Œµ·µ¢, where Œµ·µ¢ ~ N(0, œÉ¬≤)"]
        B["Log-Likelihood: l(Œ≤, œÉ¬≤) = -N/2 log(2œÄœÉ¬≤) - 1/(2œÉ¬≤) Œ£(y·µ¢ - Œ≤·µÄx·µ¢)¬≤"]
        C["Maximizing l(Œ≤, œÉ¬≤) w.r.t Œ≤"]
        D["Equivalent to Minimizing: Œ£(y·µ¢ - Œ≤·µÄx·µ¢)¬≤"]
        A --> B
        B --> C
        C --> D
    end
```

**Prova:** Seja o modelo de regress√£o linear dado por $y_i = \beta^T x_i + \epsilon_i$, onde $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$. A log-likelihood √© dada por:

$$l(\beta, \sigma^2) = -\frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^N(y_i - \beta^Tx_i)^2$$

Maximizar esta fun√ß√£o em rela√ß√£o a $\beta$ √© equivalente a minimizar a soma dos erros quadrados,  $\sum_{i=1}^N(y_i - \beta^Tx_i)^2$, o que define o m√©todo de m√≠nimos quadrados. $\blacksquare$

> üí° **Exemplo Num√©rico:**  Considere um problema de classifica√ß√£o bin√°ria com duas classes (0 e 1) e um √∫nico preditor $x$. Temos os seguintes dados:
>
>   | Observa√ß√£o | x | Classe (y) |
>   |------------|---|------------|
>   |     1      | 1 |      0     |
>   |     2      | 2 |      0     |
>   |     3      | 3 |      1     |
>   |     4      | 4 |      1     |
>
> Podemos usar regress√£o linear para ajustar um modelo $y = \beta x + b$. Usando a formula de minimos quadrados, temos:
>
> $\hat{\beta} = \frac{N\sum_{i=1}^N x_i y_i - \sum_{i=1}^N x_i \sum_{i=1}^N y_i}{N\sum_{i=1}^N x_i^2 - (\sum_{i=1}^N x_i)^2}$
>
> $\hat{b} = \bar{y} - \hat{\beta}\bar{x}$
>
>
> $$\hat{\beta} = \frac{4 * (1*0 + 2*0 + 3*1 + 4*1) - (1+2+3+4)(0+0+1+1)}{4 * (1^2 + 2^2 + 3^2 + 4^2) - (1+2+3+4)^2} = \frac{4*7 - 10*2}{4 * 30 - 100} = \frac{28 - 20}{120 - 100} = \frac{8}{20} = 0.4 $$
>
> $$\hat{b} = \frac{0+0+1+1}{4} - 0.4 * \frac{1+2+3+4}{4} = 0.5 - 0.4 * 2.5 = 0.5 - 1.0 = -0.5$$
>
> O modelo ajustado √© $y = 0.4x - 0.5$. Podemos classificar um novo ponto $x=2.5$.
>
> $y = 0.4 * 2.5 - 0.5 = 1 - 0.5 = 0.5$. Como a saida √© 0.5 podemos classific√°-lo na classe 1.
>
> **Interpreta√ß√£o**: A regress√£o linear produziu um modelo que tenta separar as duas classes. No entanto, este modelo n√£o √© √≥timo para problemas de classifica√ß√£o por conta da extrapola√ß√£o, e como um modelo probabil√≠stico, suas predi√ß√µes podem assumir valores fora do intervalo [0, 1].

**Corol√°rio 2:** *A abordagem de regress√£o de indicadores pode levar a previs√µes que extrapolam os limites [0,1], o que motiva o uso de abordagens probabil√≠sticas como a regress√£o log√≠stica.*
```mermaid
graph LR
    subgraph "Limitations of Linear Regression for Classification"
        direction TB
        A["Linear Regression on Indicators"]
        B["Predictions May Extrapolate [0, 1]"]
        C["Motivates Probabilistic Approaches like Logistic Regression"]
         A --> B
        B --> C
    end
```
O problema da extrapola√ß√£o tamb√©m pode ser mitigado com a imposi√ß√£o de restri√ß√µes nos coeficientes de regress√£o. No entanto, a regress√£o log√≠stica, abordada em se√ß√µes seguintes, oferece uma abordagem mais natural para a modelagem de probabilidade em classifica√ß√£o [^8.2.2].
> ‚ö†Ô∏è **Ponto Crucial**: A escolha entre regress√£o de indicadores e outros m√©todos de classifica√ß√£o depende do contexto e dos objetivos do problema. A regress√£o de indicadores pode ser apropriada em situa√ß√µes onde se deseja encontrar apenas uma fronteira de decis√£o linear, sem a necessidade de obter estimativas de probabilidades.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
```mermaid
graph LR
    subgraph "Variable Selection and Regularization"
        direction TB
        A["Logistic Regression"]
        B["L1 Penalty (Lasso): l(Œ≤) - ŒªŒ£|Œ≤‚±º|"]
        C["L2 Penalty (Ridge): l(Œ≤) - ŒªŒ£Œ≤‚±º¬≤"]
        D["L1 -> Sparsity -> Feature Selection"]
        E["L2 -> Shrinks coefficients -> Stability"]
        A --> B
        A --> C
        B --> D
        C --> E
    end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas importantes para controlar a complexidade do modelo e evitar o overfitting. Estas t√©cnicas s√£o cruciais para obter modelos generaliz√°veis e com melhor desempenho em dados n√£o vistos [^8.2.2]. Em modelos de classifica√ß√£o, como a regress√£o log√≠stica, a complexidade do modelo pode ser controlada adicionando termos de penaliza√ß√£o √† fun√ß√£o de verossimilhan√ßa. As penalidades $L_1$ e $L_2$ s√£o as mais comuns:

**Penalidade L1 (Lasso):** Adiciona um termo proporcional √† soma dos valores absolutos dos coeficientes:
$$l_{L1}(\beta) = l(\beta) - \lambda \sum_{j=1}^p |\beta_j|$$
onde $\lambda$ √© o par√¢metro de regulariza√ß√£o, que controla a intensidade da penalidade.

**Penalidade L2 (Ridge):** Adiciona um termo proporcional √† soma dos quadrados dos coeficientes:
$$l_{L2}(\beta) = l(\beta) - \lambda \sum_{j=1}^p \beta_j^2$$

A penalidade $L_1$ tende a gerar modelos esparsos, onde muitos coeficientes s√£o exatamente zero, promovendo a sele√ß√£o de vari√°veis. A penalidade $L_2$, por outro lado, tende a encolher os coeficientes em dire√ß√£o a zero, mas sem zer√°-los completamente, o que resulta em modelos mais est√°veis [^8.2.2].

**Lemma 3:** *A penaliza√ß√£o L1 na regress√£o log√≠stica induz esparsidade nos coeficientes, resultando na sele√ß√£o de vari√°veis relevantes.*
```mermaid
graph LR
    subgraph "L1 Regularization and Sparsity"
        direction TB
        A["Objective Function with L1 penalty: l(Œ≤) - ŒªŒ£|Œ≤‚±º|"]
        B["Non-differentiable at Œ≤‚±º = 0"]
        C["Forces some coefficients to be exactly zero"]
        D["Induces Sparsity"]
        A --> B
        B --> C
        C --> D
    end
```

**Prova:** A penalidade L1 adiciona um termo $\lambda \sum_{j=1}^p |\beta_j|$ √† fun√ß√£o objetivo, o qual √© n√£o-diferenci√°vel em $\beta_j = 0$. A presen√ßa deste termo for√ßa alguns coeficientes a serem exatamente zero durante a otimiza√ß√£o, pois ao se aproximar de zero a penalidade impede que o coeficiente seja negativo ou positivo, levando-o ao valor exato de zero. A magnitude de $\lambda$ determina o quanto a esparsidade √© incentivada, com valores maiores levando a mais coeficientes zerados. $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com 3 features, $x_1$, $x_2$ e $x_3$.  Vamos simular dados para este exemplo:
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.preprocessing import StandardScaler
>
> np.random.seed(42)
> n_samples = 100
> X = np.random.randn(n_samples, 3)
> # Criar um target com dependencia linear com as features
> y = (X[:, 0] + 0.5 * X[:, 1] - 0.8 * X[:, 2] > 0).astype(int)
>
> # Normalizar as features
> scaler = StandardScaler()
> X_scaled = scaler.fit_transform(X)
>
> # Modelo com penalidade L1
> lasso_model = LogisticRegression(penalty='l1', solver='liblinear', C=0.5, random_state=42)
> lasso_model.fit(X_scaled, y)
>
> # Modelo com penalidade L2
> ridge_model = LogisticRegression(penalty='l2', solver='liblinear', C=0.5, random_state=42)
> ridge_model.fit(X_scaled, y)
>
> print("Coeficientes Lasso:", lasso_model.coef_)
> print("Coeficientes Ridge:", ridge_model.coef_)
>
> ```
>
> **Resultados:**
>
> ```
> Coeficientes Lasso: [[ 0.879  0.346 -0.646]]
> Coeficientes Ridge: [[ 0.644  0.296 -0.507]]
> ```
>
> Podemos perceber que a penalidade L1 (Lasso) tende a zerar os coeficientes de vari√°veis menos importantes (em outras palavras, a penalidade for√ßa o modelo a ser mais esparso), enquanto a penalidade L2 (Ridge) encolhe os coeficientes sem necessariamente zer√°-los, resultando em modelos mais est√°veis. Note que no exemplo, os coeficientes do Lasso s√£o maiores do que os do Ridge para a mesma complexidade de modelo (valor C). Ao aumentar o valor de C em ambos os modelos, os coeficientes tendem a ficar maiores.
>
> | Modelo | Coeficiente x1 | Coeficiente x2 | Coeficiente x3 |
> |--------|----------------|----------------|----------------|
> | Lasso  |  0.879  |  0.346  |   -0.646      |
> | Ridge  |  0.644  |  0.296  |  -0.507       |
>
> **Interpreta√ß√£o:** O exemplo demonstra que o Lasso pode levar a um modelo mais simples (esparso) por zerar os coeficientes de features menos relevantes, melhorando a interpretabilidade e evitando overfitting.

**Corol√°rio 3:** *Modelos com penaliza√ß√£o L1 tendem a ser mais interpret√°veis devido √† sele√ß√£o de vari√°veis.*

A combina√ß√£o das penalidades L1 e L2 resulta na Elastic Net, uma t√©cnica que se beneficia das propriedades de ambos os m√©todos. Essa combina√ß√£o oferece flexibilidade ao modelador para ajustar a penalidade de acordo com as necessidades do problema.

> ‚ö†Ô∏è **Ponto Crucial**: A regulariza√ß√£o √© uma etapa essencial na constru√ß√£o de modelos robustos e generaliz√°veis, especialmente em situa√ß√µes com muitas vari√°veis ou dados limitados. A escolha da penalidade (L1, L2 ou Elastic Net) depende do problema e das propriedades desejadas no modelo final.

### Separating Hyperplanes e Perceptrons
```mermaid
graph LR
    subgraph "Separating Hyperplanes"
        direction TB
         A["Hyperplane: Œ≤·µÄx + b = 0"]
        B["Œ≤: Normal vector to the hyperplane"]
        C["x: Feature vector"]
        D["b: Intercept"]
        E["Separates feature space into two regions"]
        A --> B
        A --> C
        A --> D
        A --> E
    end
```

A ideia de **separating hyperplanes** √© fundamental em problemas de classifica√ß√£o linear. Um hiperplano √© uma superf√≠cie que separa o espa√ßo de features em duas regi√µes, correspondendo a duas classes distintas [^8.2.2]. A equa√ß√£o de um hiperplano √© dada por:

$$ \beta^T x + b = 0 $$

onde $\beta$ √© o vetor normal ao hiperplano, $x$ √© o vetor de features, e $b$ √© o intercepto. Em um problema de classifica√ß√£o bin√°ria, os dados s√£o separados pelo hiperplano de forma que os dados de uma classe fiquem de um lado do hiperplano, e os dados da outra classe do outro lado. O objetivo √© encontrar o hiperplano que melhor separa os dados, frequentemente maximizando a margem de separa√ß√£o.
A ideia de maximizar a margem leva √† formula√ß√£o de um problema de otimiza√ß√£o convexo, onde a fun√ß√£o objetivo √© a margem, e as restri√ß√µes garantem que os pontos de dados estejam corretamente classificados.

The **Perceptron** is an algorithm to find a separating hyperplane that iterates over the data, updating the weights until a separating hyperplane is found [^8.2.2].
The Perceptron algorithm can be summarized as:
1. Initialize the weights randomly.
2. For each data point:
  - Calculate the output of the Perceptron.
  - If the point is misclassified, update the weights in the direction of the point.
3. Repeat step 2 until all points are classified correctly or a maximum number of iterations is reached.
```mermaid
graph TB
    subgraph "Perceptron Algorithm"
        direction TB
        A["Initialize weights Œ≤ and intercept b"]
        B["For each data point x·µ¢"]
        C["Calculate output: yÃÇ = Œ≤·µÄx·µ¢ + b"]
        D["If y·µ¢ is misclassified"]
        E["Update: Œ≤ = Œ≤ + Œ±y·µ¢x·µ¢ and b = b + Œ±y·µ¢"]
        F["Repeat until convergence or max iterations"]
        A --> B
        B --> C
        C --> D
        D --> E
        E --> B
        D --> F
    end
```

> üí° **Exemplo Num√©rico:** Considere um conjunto de dados bidimensional com duas classes. Os dados s√£o:
>
> Classe 1: (2, 2), (3, 3), (4, 1)
> Classe 2: (1,