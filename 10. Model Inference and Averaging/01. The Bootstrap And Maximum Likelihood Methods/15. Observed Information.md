## Model Inference and Averaging: Focusing on Observed Information

```mermaid
graph TD
    subgraph "Inference Methods"
      direction TB
      A["Maximum Likelihood (ML)"]
      B["Bayesian Inference"]
      C["Bootstrap Methods"]
    end
    subgraph "Model Improvement"
      direction TB
      D["Bagging"]
      E["Stacking"]
      F["Bumping"]
    end
    G["Observed Information"] --> H["Standard Errors"]
    G --> I["Fisher Information"]
    G --> J["Chi-Squared Approximation"]
    G --> K["MCMC"]
    A --> G
    B --> G
    C --> G
    G --> L["Uncertainty Evaluation"]
    L --> A
    L --> B
    L --> C
    D --> L
    E --> L
    F --> L
```

### Introdu√ß√£o
Este cap√≠tulo aborda a infer√™ncia de modelos, um pilar essencial no aprendizado estat√≠stico, explorando m√©todos para ajustar modelos aos dados e avaliar a incerteza das estimativas. A infer√™ncia envolve a otimiza√ß√£o de modelos atrav√©s da minimiza√ß√£o de erros (como a soma dos quadrados ou a cross-entropia), que s√£o inst√¢ncias da abordagem de **Maximum Likelihood**. Al√©m disso, m√©todos bayesianos e t√©cnicas de *bootstrap* ser√£o explorados como formas de avaliar e aprimorar os modelos, destacando a import√¢ncia de quantificar a incerteza associada √†s estimativas. Este cap√≠tulo ir√° se aprofundar em conceitos como **Observed Information** e sua rela√ß√£o com a precis√£o das estimativas.

### Conceitos Fundamentais
O entendimento dos conceitos fundamentais √© crucial para o dom√≠nio da infer√™ncia estat√≠stica e aprendizado de m√°quina.

**Conceito 1: Maximum Likelihood (ML) e sua rela√ß√£o com a otimiza√ß√£o**
A abordagem de **Maximum Likelihood** busca encontrar os par√¢metros de um modelo que melhor se ajustam aos dados observados. A minimiza√ß√£o de fun√ß√µes de erro como a soma dos quadrados (para regress√£o) ou a cross-entropia (para classifica√ß√£o) s√£o, na verdade, maneiras de otimizar a fun√ß√£o de verossimilhan√ßa (likelihood), ou seja, encontrar os par√¢metros que maximizam a probabilidade dos dados observados dado o modelo. Em ess√™ncia, o m√©todo ML busca ajustar um modelo aos dados de tal forma que esses dados se tornem "mais prov√°veis" sob o modelo proposto.

**Lemma 1:** *A minimiza√ß√£o da soma dos quadrados para modelos lineares de regress√£o √© equivalente √† maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa sob a suposi√ß√£o de erros Gaussianos com vari√¢ncia constante.*

**Prova:** Seja o modelo $y_i = h(x_i)^T \beta + \epsilon_i$, onde $\epsilon_i \sim N(0, \sigma^2)$. A verossimilhan√ßa para $N$ observa√ß√µes independentes √©:
$$ L(\beta, \sigma^2) = \prod_{i=1}^N \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_i - h(x_i)^T \beta)^2}{2\sigma^2}\right) $$
O log-verossimilhan√ßa √© dado por:
$$ l(\beta, \sigma^2) = -\frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^N (y_i - h(x_i)^T \beta)^2 $$
Maximizar $l(\beta, \sigma^2)$ em rela√ß√£o a $\beta$ √© equivalente a minimizar $\sum_{i=1}^N (y_i - h(x_i)^T \beta)^2$ que √© a soma dos quadrados. $\blacksquare$

```mermaid
graph LR
    subgraph "Maximum Likelihood Derivation"
      direction TB
      A["Model: y·µ¢ = h(x·µ¢)·µÄŒ≤ + Œµ·µ¢, Œµ·µ¢ ~ N(0, œÉ¬≤)"]
      B["Likelihood: L(Œ≤, œÉ¬≤) = ‚àè·µ¢ (1/‚àö(2œÄœÉ¬≤)) exp(-(y·µ¢ - h(x·µ¢)·µÄŒ≤)¬≤/(2œÉ¬≤))"]
      C["Log-Likelihood: l(Œ≤, œÉ¬≤) = -N/2 log(2œÄœÉ¬≤) - 1/(2œÉ¬≤) ‚àë·µ¢ (y·µ¢ - h(x·µ¢)·µÄŒ≤)¬≤"]
      D["Maximizing l(Œ≤, œÉ¬≤)  with respect to Œ≤"]
      E["Equivalent to Minimizing ‚àë·µ¢ (y·µ¢ - h(x·µ¢)·µÄŒ≤)¬≤ (Sum of Squares)"]
      A --> B
      B --> C
      C --> D
      D --> E
    end
```

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o linear simples com uma √∫nica vari√°vel preditora, onde $h(x_i) = x_i$. Suponha que temos os seguintes dados: $X = [1, 2, 3, 4, 5]$ e $Y = [2, 4, 5, 4, 5]$.  O objetivo √© encontrar os par√¢metros $\beta = [\beta_0, \beta_1]$ que minimizem a soma dos quadrados dos erros. Usando a f√≥rmula de m√≠nimos quadrados $\hat{\beta} = (X^TX)^{-1}X^Ty$, onde $X$ agora inclui uma coluna de 1s para o intercepto, podemos calcular:

```python
import numpy as np
from sklearn.linear_model import LinearRegression

X = np.array([[1, 1], [1, 2], [1, 3], [1, 4], [1, 5]])
y = np.array([2, 4, 5, 4, 5])

# Usando scikit-learn para calcular os par√¢metros
model = LinearRegression(fit_intercept=False)
model.fit(X, y)
beta_sklearn = model.coef_

print(f"Estimated coefficients (sklearn): {beta_sklearn}")

# Calculando manualmente para fins did√°ticos
XTX_inv = np.linalg.inv(X.T @ X)
beta_manual = XTX_inv @ X.T @ y
print(f"Estimated coefficients (manual): {beta_manual}")
```
>
> A sa√≠da deste c√≥digo mostrar√° que $\beta_0$ (o intercepto) e $\beta_1$ (o coeficiente da vari√°vel preditora) que minimizam a soma dos quadrados dos erros, o que tamb√©m corresponde √† maximiza√ß√£o da likelihood sob a suposi√ß√£o de erros gaussianos.  Os valores estimados, em torno de $\beta_0 = 2.2$ e $\beta_1 = 0.6$ indicam que, para cada unidade de aumento em $x$, esperamos um aumento de 0.6 em $y$, com um ponto de partida em $y = 2.2$ quando $x = 0$.

**Conceito 2: Bootstrap e sua conex√£o com a incerteza**
O **Bootstrap** √© uma t√©cnica computacional para avaliar a incerteza de uma estimativa. Em vez de assumir distribui√ß√µes te√≥ricas sobre os par√¢metros, o bootstrap gera amostras replicadas dos dados originais, permitindo a avalia√ß√£o da variabilidade e a constru√ß√£o de intervalos de confian√ßa diretamente a partir dos dados. Existem duas formas principais do Bootstrap: *n√£o-param√©trico* onde amostras s√£o geradas por reamostragem com reposi√ß√£o dos dados originais e o *param√©trico* onde amostras s√£o geradas a partir de um modelo assumido, utilizando os par√¢metros estimados pelo modelo.

**Corol√°rio 1:** *A distribui√ß√£o das estimativas do bootstrap √© uma aproxima√ß√£o da distribui√ß√£o amostral dos estimadores, e seus quantis podem ser usados para construir intervalos de confian√ßa.*

**Prova:** O bootstrap assume que a distribui√ß√£o amostral observada √© uma boa aproxima√ß√£o da distribui√ß√£o populacional. Ao gerar amostras replicadas a partir da amostra original, podemos estimar a variabilidade das estimativas sem precisar de distribui√ß√µes anal√≠ticas. Os quantis da distribui√ß√£o das estimativas bootstrap ($b^*$) aproximam os quantis da distribui√ß√£o real de um estimador ($b$), permitindo a constru√ß√£o de intervalos de confian√ßa.  $\blacksquare$

```mermaid
graph LR
    subgraph "Bootstrap Process"
      direction TB
      A["Original Data"]
      B["Resampling with Replacement"]
      C["Bootstrap Samples"]
      D["Estimating Parameters on each Sample"]
      E["Distribution of Bootstrap Estimates (b*)"]
      F["Confidence Intervals from Quantiles of b*"]
      A --> B
      B --> C
      C --> D
      D --> E
      E --> F
    end
```

> üí° **Exemplo Num√©rico:**  Vamos usar o mesmo conjunto de dados $X = [1, 2, 3, 4, 5]$ e $Y = [2, 4, 5, 4, 5]$ do exemplo anterior. Para o bootstrap n√£o param√©trico, vamos criar 100 amostras bootstrap por reamostragem com reposi√ß√£o e calcular a m√©dia e o desvio padr√£o dos coeficientes.

```python
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression

X = np.array([[1, 1], [1, 2], [1, 3], [1, 4], [1, 5]])
y = np.array([2, 4, 5, 4, 5])
n_bootstrap = 100
coefs_bootstrap = []

for _ in range(n_bootstrap):
    indices = np.random.choice(len(y), size=len(y), replace=True)
    X_sample = X[indices]
    y_sample = y[indices]
    model = LinearRegression(fit_intercept=False)
    model.fit(X_sample, y_sample)
    coefs_bootstrap.append(model.coef_)

coefs_bootstrap = np.array(coefs_bootstrap)

df_coefs = pd.DataFrame(coefs_bootstrap, columns=["beta_0", "beta_1"])

print("Bootstrap Mean Coefficients:\n", df_coefs.mean())
print("Bootstrap Standard Error Coefficients:\n", df_coefs.std())

```
> Este c√≥digo gera 100 amostras de bootstrap e calcula os coeficientes para cada uma. As m√©dias dos coeficientes bootstrap s√£o estimativas dos coeficientes, e os desvios padr√µes s√£o estimativas dos erros padr√£o. Estes erros podem ser usados para criar intervalos de confian√ßa para os par√¢metros.

**Conceito 3: Lineariza√ß√£o da vari√¢ncia e o conceito de Observed Information**

A vari√¢ncia de uma estimativa pode ser aproximada usando a **Observed Information**. Em particular, o erro padr√£o de uma predi√ß√£o, em modelos lineares, pode ser calculado atrav√©s de uma lineariza√ß√£o da vari√¢ncia, como mostra a f√≥rmula (8.4). Seja  $se[\mu(x)] = \sqrt{h(x)^T (H^TH)^{-1} h(x) \hat{\sigma}^2}$, temos um exemplo de como a **Observed Information** √© utilizada para quantificar a incerteza em rela√ß√£o ao valor de $\mu(x)$, onde $H$ representa a matriz de design, $h(x)$ o vetor das fun√ß√µes de base para o ponto $x$ e $\hat{\sigma}^2$ a estimativa da vari√¢ncia do erro.

**Aprofundamento do Conceito 3: Observed Information**
A **Observed Information** $I(\theta)$  √© uma matriz Hessiana negativa da fun√ß√£o log-verossimilhan√ßa avaliada no estimador de m√°xima verossimilhan√ßa $\hat{\theta}$. Formalmente,
$$
I(\theta) = - \sum_{i=1}^{N} \frac{\partial^2 l(\theta; z_i)}{\partial \theta \partial \theta^T}
$$
onde $l(\theta; z_i) = \log g_{\theta}(z_i)$ √© o log-verossimilhan√ßa para a observa√ß√£o $z_i$, $N$ √© o n√∫mero de observa√ß√µes e $g_{\theta}(z_i)$ √© a fun√ß√£o de densidade ou massa de probabilidade do modelo.  Esta matriz captura a curvatura da fun√ß√£o de verossimilhan√ßa em torno do ponto de m√°ximo e fornece uma medida da quantidade de informa√ß√£o que os dados carregam sobre os par√¢metros.
Quando $I(\theta)$ √© avaliada em $\theta = \hat{\theta}$, ela √© denominada **Observed Information**. Al√©m disso, a **Fisher Information** √© definida como a esperan√ßa da **Observed Information**, ou seja, $i(\theta) = E[I(\theta)]$.

> ‚ö†Ô∏è **Nota Importante**: A Observed Information √© crucial para derivar a vari√¢ncia assint√≥tica dos estimadores de m√°xima verossimilhan√ßa, que √© inversamente proporcional √† quantidade de informa√ß√£o.

> ‚ùó **Ponto de Aten√ß√£o**: A **Observed Information** √© uma propriedade espec√≠fica dos dados observados, enquanto a **Fisher Information** √© uma expectativa sobre todos os poss√≠veis conjuntos de dados.

> ‚úîÔ∏è **Destaque**: A matriz de **Observed Information** desempenha um papel crucial na avalia√ß√£o da precis√£o das estimativas em v√°rios contextos estat√≠sticos, conforme demonstrado nas deriva√ß√µes do erro padr√£o em (8.4).

```mermaid
graph LR
    subgraph "Observed Information"
      direction TB
      A["Log-likelihood function: l(Œ∏; z·µ¢) = log gŒ∏(z·µ¢)"]
      B["Observed Information: I(Œ∏) = -‚àë·µ¢ ‚àÇ¬≤l(Œ∏; z·µ¢) / ‚àÇŒ∏‚àÇŒ∏·µÄ"]
      C["Observed Information evaluated at MLE: I(Œ∏ÃÇ)"]
      D["Fisher Information: i(Œ∏) = E[I(Œ∏)]"]
      E["Asymptotic Variance of MLE is inversely proportional to I(Œ∏ÃÇ)"]
       A --> B
       B --> C
       B --> D
       C --> E
    end
```

> üí° **Exemplo Num√©rico:**  Vamos usar o modelo de regress√£o linear simples anterior, onde $X = [[1, 1], [1, 2], [1, 3], [1, 4], [1, 5]]$ e $y = [2, 4, 5, 4, 5]$.  A matriz de design √© $H = X$.  Calculamos $\hat{\beta}$ como antes e o erro padr√£o de uma predi√ß√£o $y$ para um novo ponto $x = [1, 3.5]$ (com um intercepto) √© calculado como  $se[\mu(x)] = \sqrt{h(x)^T (H^TH)^{-1} h(x) \hat{\sigma}^2}$.

```python
import numpy as np
from sklearn.linear_model import LinearRegression
from scipy import stats

X = np.array([[1, 1], [1, 2], [1, 3], [1, 4], [1, 5]])
y = np.array([2, 4, 5, 4, 5])

model = LinearRegression(fit_intercept=False)
model.fit(X, y)
beta_hat = model.coef_

y_hat = X @ beta_hat
residuals = y - y_hat

n = len(y)
p = X.shape[1]
sigma_hat_squared = (residuals @ residuals) / (n-p)

x_new = np.array([1, 3.5]) # Novo ponto x com um intercepto
H = X

var_mu_x = x_new.T @ np.linalg.inv(H.T @ H) @ x_new * sigma_hat_squared

se_mu_x = np.sqrt(var_mu_x)

print(f"Estimated coefficients: {beta_hat}")
print(f"Estimated Variance of the Error: {sigma_hat_squared}")
print(f"Standard error of prediction for x = {x_new}: {se_mu_x}")
```
> Aqui, o erro padr√£o da predi√ß√£o, que √© derivado usando a observed information (via $(H^TH)^{-1}$), quantifica a incerteza associada √† previs√£o em $x = 3.5$. Quanto menor o erro padr√£o, mais precisa a predi√ß√£o neste ponto.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
A regress√£o linear pode ser adaptada para problemas de classifica√ß√£o atrav√©s da codifica√ß√£o das classes por meio de matrizes de indicadores. Essa abordagem, embora direta, possui algumas limita√ß√µes em rela√ß√£o a outros m√©todos mais espec√≠ficos, como LDA e Regress√£o Log√≠stica.
A regress√£o linear busca ajustar uma reta, ou um hiperplano, que minimize a soma dos quadrados das diferen√ßas entre os valores observados e os valores preditos. No contexto de classifica√ß√£o, o valor predito pelo modelo linear √©, ent√£o, associado a uma classe espec√≠fica.

```mermaid
graph LR
    A["Encode Classes with Indicator Matrices"] --> B["Fit Linear Model via Least Squares"]
    B --> C["Classify Based on Threshold"]
    C --> D["Evaluate Performance and Limitations"]
```

**Explica√ß√£o:** Este diagrama representa os passos principais da regress√£o de indicadores para classifica√ß√£o.

A regress√£o de indicadores √© um m√©todo simples para modelar classifica√ß√µes, onde cada classe √© codificada usando um vetor indicador. Por exemplo, em um problema de classifica√ß√£o bin√°ria, uma classe pode ser codificada como 1 e a outra como 0. No entanto, a aplica√ß√£o direta de m√≠nimos quadrados neste contexto pode levar a problemas como extrapola√ß√µes fora do intervalo [0,1] quando usado para estimar probabilidades, uma vez que os valores preditos da regress√£o linear n√£o s√£o necessariamente limitados a este intervalo.

**Lemma 2**: *Em certos casos, a proje√ß√£o de um dado em um hiperplano de decis√£o por regress√£o linear pode ser equivalente √† proje√ß√£o obtida por Linear Discriminant Analysis (LDA), mas com diferentes interpreta√ß√µes sobre a proje√ß√£o*.

**Prova:** Em condi√ß√µes ideais, onde as classes s√£o bem separadas e suas covari√¢ncias s√£o aproximadamente iguais, a regress√£o linear pode gerar hiperplanos de decis√£o similares aos da LDA, pois ambas as abordagens usam uma combina√ß√£o linear de features. No entanto, a interpreta√ß√£o dos pesos e o objetivo da proje√ß√£o s√£o diferentes. LDA tem por objetivo encontrar um subespa√ßo que maximize a separa√ß√£o entre as classes, enquanto regress√£o linear minimiza a soma dos erros quadrados da proje√ß√£o linear.   $\blacksquare$

**Corol√°rio 2:** *Sob certas condi√ß√µes, as proje√ß√µes obtidas via regress√£o linear para classes podem ser linearmente separ√°veis, simplificando a an√°lise e a visualiza√ß√£o da decis√£o de classifica√ß√£o*.

A regress√£o de indicadores possui algumas limita√ß√µes, incluindo o ‚Äúmasking problem‚Äù onde vari√°veis relevantes podem ser ocultadas pela influ√™ncia de outras vari√°veis. Al√©m disso, o m√©todo n√£o √© otimizado para a tarefa de classifica√ß√£o, o que pode levar a resultados sub√≥timos quando comparado a abordagens mais especializadas, como LDA e Regress√£o Log√≠stica.

> üí° **Exemplo Num√©rico:** Para ilustrar a regress√£o linear para classifica√ß√£o, suponha que temos um conjunto de dados com duas classes (0 e 1) e uma vari√°vel preditora. Os dados s√£o: $X = [1, 2, 3, 4, 5, 6, 7, 8]$ e $Y = [0, 0, 0, 1, 1, 1, 1, 1]$.  Vamos transformar esses dados em um problema de regress√£o linear, ajustando uma reta aos pontos.

```python
import numpy as np
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

X = np.array([[1], [2], [3], [4], [5], [6], [7], [8]])
y = np.array([0, 0, 0, 1, 1, 1, 1, 1])

model = LinearRegression()
model.fit(X, y)
y_pred = model.predict(X)

plt.figure(figsize=(8, 6))
plt.scatter(X, y, color='blue', label='Dados Observados')
plt.plot(X, y_pred, color='red', label='Regress√£o Linear')

threshold = 0.5
y_class = (y_pred > threshold).astype(int) # Classifica√ß√£o com base no threshold
plt.scatter(X, y_class, color='green', label='Classes Preditas', marker='x')
plt.axhline(y=threshold, color='gray', linestyle='--', label='Limiar de Classifica√ß√£o (0.5)')
plt.xlabel('Vari√°vel Preditora (X)')
plt.ylabel('Classe (Y)')
plt.title('Regress√£o Linear para Classifica√ß√£o')
plt.legend()
plt.show()
print(f"Predicted Classes: {y_class}")
```
>  Este c√≥digo mostra como a regress√£o linear ajusta uma linha aos dados e como podemos usar um limiar (threshold) para converter a previs√£o linear em classes.  Perceba que algumas predi√ß√µes podem estar fora do intervalo [0,1].  O gr√°fico e o output das classes mostram que a regress√£o linear pode ser usada para classificar, apesar de suas limita√ß√µes.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
Em problemas de classifica√ß√£o, a sele√ß√£o de vari√°veis e a regulariza√ß√£o desempenham um papel fundamental para evitar overfitting, reduzir a complexidade do modelo e aumentar sua interpretabilidade. Esses m√©todos s√£o especialmente importantes quando h√° um grande n√∫mero de features, o que pode levar a modelos inst√°veis e com baixo poder de generaliza√ß√£o. A regulariza√ß√£o √© uma t√©cnica que adiciona um termo de penalidade √† fun√ß√£o de custo para reduzir a magnitude dos coeficientes. As penalidades L1 e L2 s√£o as mais comuns.
> ‚ö†Ô∏è **Ponto Crucial**: A escolha entre L1 e L2, ou uma combina√ß√£o de ambas (Elastic Net), depende da estrutura dos dados e do objetivo do modelo. L1 induz esparsidade (sele√ß√£o de vari√°veis) enquanto L2 reduz a magnitude dos coeficientes.

A penaliza√ß√£o L1, tamb√©m conhecida como Lasso, adiciona um termo proporcional ao valor absoluto dos coeficientes √† fun√ß√£o de custo: $\lambda \sum_j |\beta_j|$. Essa penaliza√ß√£o tem a propriedade de for√ßar alguns coeficientes a serem exatamente zero, promovendo a sele√ß√£o de vari√°veis e resultando em modelos mais esparsos. Por outro lado, a penaliza√ß√£o L2, ou Ridge, adiciona um termo proporcional ao quadrado dos coeficientes: $\lambda \sum_j \beta_j^2$. L2 reduz a magnitude dos coeficientes de forma uniforme, levando a modelos mais est√°veis e com menor vari√¢ncia.

```mermaid
graph LR
    A["Classification Model"] --> B["L1 Regularization (Lasso): Œª‚àë|Œ≤‚±º|"]
    A --> C["L2 Regularization (Ridge): Œª‚àëŒ≤‚±º¬≤"]
    A --> D["Elastic Net (L1 + L2): Œª‚ÇÅ‚àë|Œ≤‚±º| + Œª‚ÇÇ‚àëŒ≤‚±º¬≤"]
    B --> E["Variable Selection, Sparsity"]
    C --> F["Stability, Variance Reduction"]
    D --> G["Combined Selection and Stability"]
```
**Explica√ß√£o:** O diagrama acima ilustra como as diferentes t√©cnicas de regulariza√ß√£o se encaixam em um modelo de classifica√ß√£o, com foco nos efeitos de cada uma nas caracter√≠sticas do modelo.

**Lemma 3:** *A penaliza√ß√£o L1 em classifica√ß√£o log√≠stica leva a coeficientes esparsos*.
**Prova:** A fun√ß√£o de custo para regress√£o log√≠stica com penaliza√ß√£o L1 √© dada por:
$$ J(\beta) = -\sum_{i=1}^N \left(y_i \log(p_i) + (1-y_i) \log(1-p_i)\right) + \lambda \sum_{j=1}^p |\beta_j| $$
onde $p_i = \frac{1}{1+e^{-h(x_i)^T\beta}}$. O termo de penaliza√ß√£o L1  $\lambda \sum_j |\beta_j|$ adiciona uma penalidade que favorece solu√ß√µes com coeficientes iguais a zero, o que induz esparsidade na solu√ß√£o. A otimiza√ß√£o deste problema com t√©cnicas como subgradient descent promove que muitos coeficientes $\beta_j$ tendam a ser iguais a zero, selecionando assim as vari√°veis mais relevantes. $\blacksquare$

**Corol√°rio 3:** *Modelos classificat√≥rios com regulariza√ß√£o L1 s√£o mais f√°ceis de interpretar pois as features com coeficientes iguais a zero s√£o consideradas irrelevantes*.

A regulariza√ß√£o, em conjunto com a sele√ß√£o de vari√°veis, proporciona modelos mais robustos, interpret√°veis e com melhor poder preditivo. A combina√ß√£o de penalidades L1 e L2 (Elastic Net) permite aproveitar as vantagens de ambos os m√©todos, controlando tanto a esparsidade quanto a estabilidade do modelo.

> üí° **Exemplo Num√©rico:**  Vamos gerar dados simulados com 10 vari√°veis, onde apenas 3 s√£o realmente relevantes para classificar um problema bin√°rio. Vamos usar regress√£o log√≠stica com regulariza√ß√£o L1 (Lasso) e L2 (Ridge) e comparar o resultado.

```python
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
import pandas as pd

# Generate synthetic data
np.random.seed(42)
n_samples = 200
n_features = 10
X = np.random.randn(n_samples, n_features)
# Only features 1, 3 and 6 are informative
true_coef = np.array([0.8, 0, 1.2, 0, 0, -0.6, 0, 0, 0, 0])
y_prob = 1 / (1 + np.exp(-(X @ true_coef)))
y = np.random.binomial(1, y_prob)


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


# L1 Regularization (Lasso)
lasso_model = LogisticRegression(penalty='l1', solver='liblinear', C=0.5, random_state=42)
lasso_model.fit(X_train_scaled, y_train)
y_pred_lasso = lasso_model.predict(X_test_scaled)

# L2 Regularization (Ridge)
ridge_model = LogisticRegression(penalty='l2', C=0.5, random_state=42)
ridge_model.fit(X_train_scaled, y_train)
y_pred_ridge = ridge_model.predict(X_test_scaled)


# Resultados
accuracy_lasso = accuracy_score(y_test, y_pred_lasso)
accuracy_ridge = accuracy_score(y_test, y_pred_ridge)
coef_lasso = lasso_model.coef_.flatten()
coef_ridge = ridge_model.coef_.flatten()
results_df = pd.DataFrame({
    "Feature": range(1,n_features+1),
    "True Coefs": true_coef,
    "Lasso Coefs": coef_lasso,
    "Ridge Coefs": coef_ridge
})
print(results_df)
print(f"Lasso Accuracy: {accuracy_lasso:.4f}")
print(f"Ridge Accuracy: {accuracy_ridge:.4f}")
```
>  Este exemplo demonstra como a penaliza√ß√£o L1 (Lasso) zera alguns coeficientes, efetuando a sele√ß√£o de vari√°veis, enquanto a penaliza√ß√£o L2 (Ridge) reduz a magnitude de todos os coeficientes. No exemplo, a acur√°cia √© semelhante entre os dois modelos, mas os coeficientes mostram a diferen√ßa na abordagem de regulariza√ß√£o. Observe que apenas os coeficientes 1, 3 e 6 s√£o diferentes de zero no Lasso, o que reflete a estrutura dos dados, onde apenas essas vari√°veis s√£o relevantes.

### Separating Hyperplanes e Perceptrons
A ideia de **Separating Hyperplanes** surge da necessidade de encontrar uma fronteira de decis√£o √≥tima que maximize a margem de separa√ß√£o entre as classes. Essa abordagem √© fundamental em classificadores lineares e leva ao conceito de hiperplanos √≥timos, que s√£o definidos por combina√ß√µes lineares das features de entrada. Os pontos mais pr√≥ximos do hiperplano de decis√£o s√£o conhecidos como *pontos de suporte*, e s√£o essenciais para a defini√ß√£o do hiperplano. Formalmente, um hiperplano separador em um espa√ßo $p$-dimensional pode ser definido como:
$$ h(x) = w^Tx + b = 0 $$
onde $w$ √© o vetor de pesos e $b$ √© o bias. A classifica√ß√£o de um ponto $x$ √© dada por $sign(w^Tx + b)$. A otimiza√ß√£o deste hiperplano de separa√ß√£o envolve a maximiza√ß√£o da margem, que √© a dist√¢ncia entre o hiperplano e os pontos de suporte mais pr√≥ximos.

```mermaid
graph LR
    A["Input Data"] --> B["Define Hyperplane: h(x) = w·µÄx + b = 0"]
    B --> C["Calculate Separation Margin"]
    C --> D["Optimize Hyperplane to Maximize Margin"]
    D --> E["Classification based on Hyperplane sign(w·µÄx + b)"]
```
**Explica√ß√£o:** Este diagrama representa o processo de defini√ß√£o de hiperplanos separadores para classifica√ß√£o, mostrando a rela√ß√£o entre os dados e a constru√ß√£o da fronteira de decis√£o.

O **Perceptron de Rosenblatt** √© um algoritmo de aprendizado que ajusta iterativamente os pesos de um hiperplano de decis√£o. O perceptron √© um classificador linear e seu processo de otimiza√ß√£o baseia-se em atualizar os pesos sempre que um erro de classifica√ß√£o √© encontrado. Embora o Perceptron n√£o maximize a margem como em **Separating Hyperplanes** otimizados, ele √© um algoritmo fundamental para entender a base dos classificadores lineares e pode convergir para uma solu√ß√£o (se os dados forem linearmente separ√°veis).

**Teorema 1**: *Se um conjunto de dados √© linearmente separ√°vel, o algoritmo do perceptron ir√° convergir para uma solu√ß√£o que separa os dados corretamente*.
**Prova:** A prova desse teorema envolve demonstrar que, a cada itera√ß√£o, o algoritmo reduz o n√∫mero de erros de classifica√ß√£o ou mant√©m o mesmo n√∫mero, mas o vetor de pesos se aproxima de um vetor √≥timo. A converg√™ncia √© garantida se os dados forem linearmente separ√°veis.  $\blacksquare$
A formula√ß√£o do problema de **Separating Hyperplanes** frequentemente envolve a solu√ß√£o do *dual de Wolfe* que permite uma solu√ß√£o eficiente via combina√ß√£o linear de pontos de suporte, o que √© fundamental para algoritmos como Support Vector Machines (SVM).

> üí° **Exemplo Num√©rico:** Vamos criar um exemplo simples com dados linearmente separ√°veis para demonstrar o funcionamento do Perceptron. Consideremos duas classes com dados bidimensionais.

```python
import numpy as np
import matplotlib.pyplot as plt

# Dados linearmente separ√°veis
X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 1], [1, 1], [10, 10]])
y = np.array([0, 0, 1, 1, 0, 1, 0, 1]) # Classes: 0 e 1

def perceptron(X, y, learning_rate=0.01, n_iterations=100):
    n_samples, n_features = X.shape
    w = np.zeros(n_features)
    b = 0

    for _ in range(n_iterations):
        for i in range(n_samples):
            y_pred = np.sign(np.dot(X[i], w) + b)
            if y_pred != y[i]:
                w = w + learning_rate * (y[i] - y_pred) * X[i]
                b = b + learning_rate * (y[i] - y_pred)
    return w, b

w, b = perceptron(X, y)

# Plotagem
plt.figure(figsize=(8, 6))
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolors='k')
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))

Z = np.sign(np.dot(np.c_[xx.ravel(), yy.ravel()], w) + b).reshape(xx.shape)
plt.contourf(xx, yy, Z, cmap='RdBu', alpha=0.5)

plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('Perceptron Decision Boundary')
plt.show()

print(f"Perceptron Weights: {w}")
print(f"Perceptron Bias: {b}")

```
> Este c√≥digo demonstra como o Perceptron aprende os pesos do hiperplano (linha, neste caso 2D) que separa as duas classes. Os pesos e o bias, juntamente com a visualiza√ß√£o do hiperplano, mostram como o Perceptron divide os dados linearmente separ√°veis.

### Pergunta Te√≥rica Avan√ßada: Quais as rela√ß√µes entre o *parametric bootstrap* e a infer√™ncia de m√°xima verossimilhan√ßa (Maximum Likelihood Inference)?
**Resposta:**
O *parametric bootstrap* √© uma t√©cnica para gerar amostras replicadas de dados, utilizando um modelo param√©trico, com par√¢metros estimados via m√°xima verossimilhan√ßa.  Em geral, o *parametric bootstrap* converge para os resultados da infer√™ncia por m√°xima verossimilhan√ßa quando o tamanho da amostra se aproxima do infinito. A conex√£o entre os dois m√©todos pode ser ilustrada no contexto de modelos com erros gaussianos.
No *parametric bootstrap*, novos dados s√£o gerados usando um modelo, por exemplo, $y_i^* = h(x_i)^T \hat{\beta} + \epsilon_i^* $, onde $\epsilon_i^* \sim N(0, \hat{\sigma}^2)$, sendo $\hat{\beta}$ e $\hat{\sigma}^2$ as estimativas de m√°xima verossimilhan√ßa dos par√¢metros do modelo. Repetindo esse processo v√°rias vezes, obt√©m-se um conjunto de estimativas bootstrap para os par√¢metros $\beta$. Por sua vez, as estimativas obtidas pela infer√™ncia de m√°xima verossimilhan√ßa s√£o dadas por $\hat{\beta} = (H^TH)^{-1}H^Ty$ e sua vari√¢ncia estimada por $Var(\hat{\beta}) = (H^TH)^{-1}\hat{\sigma}^2$. Como a distribui√ß√£o amostral de $\hat{\beta}$ √© assintoticamente normal (sob condi√ß√µes de regularidade) e o bootstrap param√©trico gera amostras com base na mesma distribui√ß√£o e par√¢metros estimados por m√°xima verossimilhan√ßa, ambos tendem a concordar conforme o tamanho da amostra cresce.

```mermaid
graph LR
    subgraph "Parametric Bootstrap vs MLE"
      direction TB
      A["MLE: Estimate Parameters (Œ∏ÃÇ) from data"]
      B["Parametric Bootstrap: Generate samples based on model using Œ∏ÃÇ"]
      C["Parametric Bootstrap: y·µ¢* = h(x·µ¢)·µÄŒ≤ÃÇ + Œµ·µ¢*, Œµ·µ¢* ~ N(0, œÉÃÇ¬≤)"]
      D["MLE: Asymptotic Variance Var(Œ∏ÃÇ) is related to Fisher Information"]
      E["Bootstrap: Distribution of Œ∏ÃÇ* converges to MLE Distribution as sample size increases"]
      A --> B
      B --> C
      A --> D
      C --> E
    end
```

**Lemma 4**: *Sob certas condi√ß√µes, as vari√¢ncias dos estimadores por bootstrap param√©trico e por infer√™ncia de m√°xima verossimilhan√ßa se igualam quando o n√∫mero de amostras bootstrap tende ao infinito*.

**Prova:** A distribui√ß√£o de um estimador de m√°xima verossimilhan√ßa $\hat{\theta}$ √© assintoticamente normal