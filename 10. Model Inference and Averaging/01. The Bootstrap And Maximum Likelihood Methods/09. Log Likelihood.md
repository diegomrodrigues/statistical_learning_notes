## Model Inference and Averaging: A Deep Dive into Maximum Likelihood and Beyond

```mermaid
graph LR
    subgraph "Model Inference Techniques"
        A["Maximum Likelihood (ML)"]
        B["Bootstrap"]
        C["Bayesian Inference"]
    end
    subgraph "Model Improvement Techniques"
        D["Bagging"]
        E["Stacking"]
        F["Bumping"]
    end
    A --> B
    A --> C
    A --> D
    A --> E
    A --> F
    B --> D
    C --> E
    D --> F
    E --> F
```

### Introdu√ß√£o
Neste cap√≠tulo, exploraremos o conceito de **Log Likelihood**, um alicerce para a infer√™ncia estat√≠stica e a aprendizagem de modelos [^8.1]. A adapta√ß√£o de modelos, seja por meio da minimiza√ß√£o da soma de quadrados para regress√£o ou da minimiza√ß√£o da entropia cruzada para classifica√ß√£o, pode ser vista, em √∫ltima an√°lise, como casos da abordagem de **Maximum Likelihood (ML)** [^8.1].  A infer√™ncia estat√≠stica, tanto na perspectiva frequentista quanto na Bayesiana, busca, a partir dos dados observados, inferir os par√¢metros de um modelo, e o Log Likelihood √© a fun√ß√£o central para esse objetivo. Exploraremos os m√©todos de ML e Bayes, a t√©cnica de **Bootstrap** para avalia√ß√£o da incerteza e t√©cnicas de aprimoramento de modelos como **Bagging, Stacking e Bumping**.

### Conceitos Fundamentais
#### Conceito 1:  Maximum Likelihood
A **Maximum Likelihood Inference (MLI)** √© uma metodologia para estimar os par√¢metros de um modelo estat√≠stico, maximizando a fun√ß√£o de verossimilhan√ßa (likelihood). A fun√ß√£o de verossimilhan√ßa, denotada por $L(\theta; Z)$, quantifica a probabilidade dos dados observados $Z$ dado um conjunto de par√¢metros $\theta$. Matematicamente, a ideia √© encontrar os valores de $\theta$ que tornam os dados observados mais prov√°veis sob o modelo especificado [^8.2.2].
$$
L(\theta; Z) = \prod_{i=1}^{N} g_\theta(z_i),
$$
onde $g_\theta(z_i)$ representa a fun√ß√£o de densidade ou massa de probabilidade da observa√ß√£o $z_i$ dado o par√¢metro $\theta$. Para fins pr√°ticos, o **log-likelihood**, $l(\theta; Z)$, √© usualmente utilizado por ser mais f√°cil de manipular. Ele √© definido como o logaritmo da fun√ß√£o de verossimilhan√ßa:
$$
l(\theta; Z) = \sum_{i=1}^{N} \log g_\theta(z_i).
$$
O estimador de m√°xima verossimilhan√ßa, $\hat{\theta}_{ML}$, √© aquele que maximiza $l(\theta; Z)$:
$$
\hat{\theta}_{ML} = \underset{\theta}{\text{argmax}} \, l(\theta; Z).
$$
A abordagem de ML √© fundamental para muitos modelos estat√≠sticos, porque ela fornece um crit√©rio objetivo para ajustar os modelos aos dados.

```mermaid
graph LR
  subgraph "Maximum Likelihood Inference (MLI)"
    direction TB
    A["Likelihood Function: L(Œ∏; Z) = Œ† g(z·µ¢;Œ∏)"]
    B["Log-Likelihood Function: l(Œ∏; Z) = Œ£ log(g(z·µ¢;Œ∏))"]
    C["ML Estimator: Œ∏ÃÇ‚Çò‚Çó = argmax‚Çô l(Œ∏; Z)"]
    A --> B
    B --> C
  end
```

> üí° **Exemplo Num√©rico:** Suponha que temos um conjunto de dados de 5 lan√ßamentos de uma moeda, onde observamos 3 caras (C) e 2 coroas (K). Assumimos que a probabilidade de obter cara √© $\theta$. A fun√ß√£o de verossimilhan√ßa √© $L(\theta; Z) = \theta^3(1-\theta)^2$. Para calcular o log-likelihood, temos $l(\theta; Z) = 3\log(\theta) + 2\log(1-\theta)$. Para encontrar $\hat{\theta}_{ML}$, derivamos $l(\theta; Z)$ com rela√ß√£o a $\theta$ e igualamos a zero:
>
> $\frac{dl}{d\theta} = \frac{3}{\theta} - \frac{2}{1-\theta} = 0$
>
> Resolvendo para $\theta$, temos:
>
> $3(1-\theta) = 2\theta$
>
> $3 - 3\theta = 2\theta$
>
> $3 = 5\theta$
>
> $\hat{\theta}_{ML} = \frac{3}{5} = 0.6$
>
> Isso significa que, segundo a m√°xima verossimilhan√ßa, a estimativa da probabilidade de sair cara √© 0.6.

**Lemma 1:** *Sob certas condi√ß√µes de regularidade*, o estimador de m√°xima verossimilhan√ßa √© consistente, assintoticamente normal e assintoticamente eficiente.
*Prova:* A prova desse resultado envolve uma expans√£o de Taylor da fun√ß√£o de log-verossimilhan√ßa em torno do verdadeiro valor do par√¢metro e a aplica√ß√£o do teorema central do limite. As condi√ß√µes de regularidade garantem a exist√™ncia e unicidade do m√°ximo, bem como a validade das expans√µes de Taylor e dos argumentos assint√≥ticos [^8.2.2]. $\blacksquare$

#### Conceito 2:  Bootstrap
O m√©todo de **Bootstrap** √© uma t√©cnica de reamostragem que permite estimar a distribui√ß√£o amostral de um estimador estat√≠stico atrav√©s da gera√ß√£o de m√∫ltiplos conjuntos de dados a partir da amostra original [^8.2.1]. Ao contr√°rio dos m√©todos que se baseiam em premissas te√≥ricas, o bootstrap utiliza a amostra observada como uma "popula√ß√£o" substituta e simula novos conjuntos de dados a partir dela. Existem duas variantes principais: o *bootstrap n√£o param√©trico*, onde os dados s√£o amostrados com reposi√ß√£o da amostra original, e o *bootstrap param√©trico*, onde as amostras s√£o geradas a partir de um modelo param√©trico, cujos par√¢metros s√£o estimados a partir da amostra original [^8.2.1]. O Bootstrap √© √∫til para estimar intervalos de confian√ßa e erros padr√£o, especialmente em situa√ß√µes onde as suposi√ß√µes te√≥ricas n√£o s√£o v√°lidas. No contexto da fun√ß√£o de Log Likelihood, o bootstrap permite avaliar a incerteza associada aos par√¢metros estimados atrav√©s da constru√ß√£o de amostras bootstrap e estima√ß√£o da distribui√ß√£o da fun√ß√£o de Log Likelihood [^8.2.1].

```mermaid
graph LR
    subgraph "Bootstrap Method"
        direction TB
        A["Original Sample: Z"]
        subgraph "Non-parametric Bootstrap"
            B["Resample Z with replacement -> Z*"]
        end
        subgraph "Parametric Bootstrap"
            C["Estimate parameters from Z -> Œ∏ÃÇ"]
            D["Sample from model with Œ∏ÃÇ -> Z*"]
        end
        E["Estimate statistic on each Z*"]
        A --> B
        A --> C
        C --> D
        B --> E
        D --> E
    end
```

> üí° **Exemplo Num√©rico:** Considere o mesmo exemplo da moeda com 5 lan√ßamentos (3 caras e 2 coroas). Para realizar um bootstrap n√£o param√©trico, reamostramos com reposi√ß√£o essa amostra original v√°rias vezes (e.g., 1000 vezes), cada vez criando uma nova amostra de tamanho 5. Para cada amostra bootstrap, recalculamos o estimador $\hat{\theta}_{ML}$ (a propor√ß√£o de caras). A distribui√ß√£o dos 1000 valores de $\hat{\theta}_{ML}$ ser√° nossa estimativa da distribui√ß√£o amostral do estimador. Por exemplo, se uma amostra bootstrap fosse [C, C, K, K, C], $\hat{\theta}_{ML}$ seria 3/5 = 0.6. Se outra fosse [C, K, K, K, K], seria 1/5 = 0.2. Ap√≥s as 1000 amostras, poder√≠amos calcular o erro padr√£o e o intervalo de confian√ßa de $\hat{\theta}_{ML}$.

**Corol√°rio 1:** A distribui√ß√£o do estimador de m√°xima verossimilhan√ßa pode ser aproximada pela distribui√ß√£o amostral obtida atrav√©s de bootstrap.
*Prova:* Atrav√©s do processo de reamostragem do bootstrap, onde cada amostra bootstrap √© utilizada para recalcular o estimador, geramos uma distribui√ß√£o emp√≠rica do estimador. Essa distribui√ß√£o emp√≠rica √© utilizada para aproximar a distribui√ß√£o amostral do estimador original, e pode ser usada para construir intervalos de confian√ßa ou avaliar outras propriedades estat√≠sticas [^8.2.1]. $\blacksquare$

#### Conceito 3: Bayesian Inference
Na infer√™ncia bayesiana, os par√¢metros do modelo, $\theta$, s√£o tratados como vari√°veis aleat√≥rias. A infer√™ncia √© feita n√£o apenas com base nos dados observados, mas tamb√©m em um conhecimento a priori (prior), que √© incorporado atrav√©s da distribui√ß√£o $Pr(\theta)$ [^8.3]. O principal objetivo da infer√™ncia Bayesiana √© calcular a distribui√ß√£o a posteriori, $Pr(\theta|Z)$, que √© dada por:

$$
Pr(\theta|Z) = \frac{Pr(Z|\theta)Pr(\theta)}{\int Pr(Z|\theta)Pr(\theta) d\theta},
$$
onde $Pr(Z|\theta)$ √© a fun√ß√£o de verossimilhan√ßa, $Pr(\theta)$ √© a distribui√ß√£o *a priori*, e o denominador √© uma constante de normaliza√ß√£o. A distribui√ß√£o a posteriori representa nosso conhecimento sobre os par√¢metros ap√≥s observarmos os dados, e ela √© usada para infer√™ncia e predi√ß√£o [^8.3]. Na pr√°tica, pode ser dif√≠cil realizar a integral no denominador, ent√£o m√©todos de amostragem, como **Markov Chain Monte Carlo (MCMC)** s√£o utilizados para obter amostras da distribui√ß√£o a posteriori [^8.6].

```mermaid
graph LR
    subgraph "Bayesian Inference"
        direction TB
        A["Prior Distribution: Pr(Œ∏)"]
        B["Likelihood Function: Pr(Z|Œ∏)"]
        C["Posterior Distribution: Pr(Œ∏|Z) = Pr(Z|Œ∏)Pr(Œ∏) / ‚à´Pr(Z|Œ∏)Pr(Œ∏)dŒ∏"]
        A --> C
        B --> C
       
        subgraph "MCMC Sampling"
          D["Markov Chain Monte Carlo (MCMC)"]
           C --> D
        end
    end
```

> üí° **Exemplo Num√©rico:** Voltando ao exemplo da moeda, podemos definir uma *prior* para $\theta$, por exemplo, uma distribui√ß√£o Beta com par√¢metros $\alpha = 2$ e $\beta = 2$. A *prior* $Pr(\theta)$ √© proporcional a $\theta^{\alpha-1}(1-\theta)^{\beta-1}$, que neste caso √© $\theta(1-\theta)$. A verossimilhan√ßa $Pr(Z|\theta)$ √© proporcional a $\theta^3(1-\theta)^2$. A *posterior* √© proporcional ao produto da *prior* e da verossimilhan√ßa: $Pr(\theta|Z) \propto \theta(1-\theta)\theta^3(1-\theta)^2 = \theta^4(1-\theta)^3$. Essa *posterior* tamb√©m √© uma Beta, com par√¢metros $\alpha_{novo}=2+3=5$ e $\beta_{novo} = 2+2=4$.  A m√©dia da *posterior*, que pode ser usada como estimativa Bayesiana para $\theta$, √© $\frac{\alpha_{novo}}{\alpha_{novo} + \beta_{novo}} = \frac{5}{5+4} = \frac{5}{9} \approx 0.556$. O ML nos deu 0.6, o Bayes 0.556. A diferen√ßa √© devido √† *prior*.

> ‚ö†Ô∏è **Nota Importante**: A infer√™ncia Bayesiana usa uma distribui√ß√£o *a priori* para incorporar o conhecimento pr√©vio sobre os par√¢metros, ao contr√°rio do ML, que n√£o usa nenhuma informa√ß√£o pr√©via. **Refer√™ncia ao t√≥pico [^8.3]**.

> ‚ùó **Ponto de Aten√ß√£o**: A escolha de uma distribui√ß√£o *a priori* n√£o informativa leva, em muitos casos, a resultados semelhantes aos obtidos pelo ML, conforme discutido em [^8.4].

> ‚úîÔ∏è **Destaque**: M√©todos como o MCMC (Gibbs Sampler) podem ser utilizados para amostrar da distribui√ß√£o a posteriori em modelos Bayesianos complexos, conforme indicado em [^8.6].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
```mermaid
flowchart TD
  subgraph "Regression for Classification"
    A["Indicator Matrix Y"]
    B["Predictor Matrix H"]
    C["Linear Model: Y = HŒ≤ + E"]
    D["Least Squares Estimator: Œ≤ÃÇ = (H·µÄH)‚Åª¬πH·µÄY"]
    A --> C
    B --> C
    C --> D
  end
```
**Explica√ß√£o:** Este diagrama representa a use of the least squares approach to estimate parameters in linear regression applied to classification by using a indicator matrix.

Na regress√£o linear, o objetivo √© encontrar uma rela√ß√£o linear entre vari√°veis preditoras e uma vari√°vel resposta. Quando se trata de classifica√ß√£o, podemos aplicar a regress√£o linear a uma matriz de indicadores, onde cada coluna representa uma classe diferente e os valores indicam a pertin√™ncia de cada observa√ß√£o a essa classe [^8.2]. Para um problema de $K$ classes, criamos uma matriz indicadora $Y$ de dimens√£o $N \times K$, onde $N$ √© o n√∫mero de observa√ß√µes. Se a observa√ß√£o $i$ pertence √† classe $k$, ent√£o $Y_{ik}=1$ e 0 caso contr√°rio. Podemos modelar a rela√ß√£o entre as vari√°veis preditoras e as classes atrav√©s da seguinte equa√ß√£o linear:

$$
Y = H\beta + E,
$$
onde $H$ √© a matriz de vari√°veis preditoras (incluindo uma coluna para o intercepto), $\beta$ √© a matriz de coeficientes e $E$ √© a matriz de erros. Para estimar $\beta$, minimizamos a soma dos erros quadr√°ticos, obtendo:

$$
\hat{\beta} = (H^TH)^{-1}H^TY
$$
Este estimador nos permite mapear as vari√°veis preditoras para os escores de cada classe, com a classe predita sendo aquela que apresenta o maior escore. No entanto, esta abordagem pode ter limita√ß√µes, como extrapola√ß√µes fora do intervalo [0,1] e dificuldade em lidar com classes desbalanceadas [^8.2].

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com 3 classes (A, B, C) e 4 observa√ß√µes. As vari√°veis preditoras s√£o $H = \begin{bmatrix} 1 & 2 \\ 1 & 3 \\ 1 & 4 \\ 1 & 5 \end{bmatrix}$ (incluindo o intercepto). A matriz de indicadores $Y$ √©:
>
> $Y = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 0 \end{bmatrix}$,
>
> onde a primeira observa√ß√£o √© da classe A, a segunda da classe B, a terceira da classe C e a quarta da classe A. O estimador $\hat{\beta}$ √© calculado como:
>
> $\hat{\beta} = (H^TH)^{-1}H^TY$. Primeiro, calculamos $H^TH = \begin{bmatrix} 4 & 14 \\ 14 & 54 \end{bmatrix}$, e $(H^TH)^{-1} \approx \begin{bmatrix} 13.5 & -3.5 \\ -3.5 & 1 \end{bmatrix}$.  Depois calculamos $H^TY = \begin{bmatrix} 2 & 1 & 1 \\ 14 & 3 & 4 \end{bmatrix}$. Finalmente:
>
> $\hat{\beta} \approx  \begin{bmatrix} 13.5 & -3.5 \\ -3.5 & 1 \end{bmatrix} \begin{bmatrix} 2 & 1 & 1 \\ 14 & 3 & 4 \end{bmatrix} = \begin{bmatrix} -22 & 3 & -0.5 \\ 7 & -0.5 & 0.5 \end{bmatrix}$
>
> Essa matriz $\hat{\beta}$ cont√©m os pesos para cada classe. Para classificar uma nova observa√ß√£o, multiplicamos sua matriz de atributos pelo $\hat{\beta}$ e a classe predita √© a de maior valor.

**Lemma 2:** Sob certas suposi√ß√µes de normalidade dos erros, o estimador de m√≠nimos quadrados, $\hat{\beta}$, √© o estimador de m√°xima verossimilhan√ßa.
*Prova:* Se os erros na regress√£o linear s√£o normalmente distribu√≠dos com m√©dia zero e vari√¢ncia constante, ent√£o a fun√ß√£o de log-verossimilhan√ßa √© proporcional √† soma dos erros quadr√°ticos. Portanto, minimizar a soma dos erros quadr√°ticos √© equivalente a maximizar a log-verossimilhan√ßa [^8.2]. $\blacksquare$

**Corol√°rio 2:** O erro padr√£o da predi√ß√£o pode ser calculado utilizando a matriz de covari√¢ncia do estimador de m√≠nimos quadrados:
$$
Var(\hat{\beta}) = (H^TH)^{-1}\sigma^2,
$$
onde $\sigma^2$ √© a vari√¢ncia dos erros [^8.2].

√â importante mencionar que, embora a regress√£o linear possa ser usada para classifica√ß√£o, m√©todos como a regress√£o log√≠stica s√£o geralmente mais adequados, por modelarem diretamente as probabilidades de classe [^8.2.2]. Contudo, a regress√£o linear √© simples e pode ser eficaz em algumas situa√ß√µes, especialmente quando o foco principal √© obter uma fronteira de decis√£o linear entre classes.

"√â fundamental notar que a regress√£o linear em matriz de indicadores pode levar a problemas de masking se houver grande sobreposi√ß√£o entre classes ou quando o n√∫mero de classes √© elevado, e por isso, t√©cnicas de regulariza√ß√£o e sele√ß√£o de vari√°veis s√£o importantes, como indicado em [^8.3]"

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
```mermaid
graph LR
    subgraph "Regularization in Logistic Regression"
        direction TB
        A["Log-Likelihood: l(Œ≤)"]
        B["L1 Regularization:  l‚ÇÅ(Œ≤) = l(Œ≤) - ŒªŒ£|Œ≤‚±º|"]
        C["L2 Regularization: l‚ÇÇ(Œ≤) = l(Œ≤) - ŒªŒ£Œ≤‚±º¬≤"]
        A --> B
        A --> C
    end
```
**Explanation:** This diagram shows the log-likelihood function and two regularizations (L1 and L2), detailing the mathematical terms of each one

Em problemas de classifica√ß√£o, a complexidade dos modelos pode levar a overfitting. Para contornar esse problema, podemos utilizar t√©cnicas de sele√ß√£o de vari√°veis e regulariza√ß√£o [^8.5]. A regulariza√ß√£o introduz uma penalidade na fun√ß√£o de custo, geralmente relacionada √† magnitude dos coeficientes, visando tornar o modelo mais simples e est√°vel.

Na regress√£o log√≠stica, a fun√ß√£o de verossimilhan√ßa √© dada por:

$$
l(\beta) = \sum_{i=1}^N y_i \log(\sigma(H_i \beta)) + (1-y_i) \log(1-\sigma(H_i \beta))
$$

onde $\sigma(x) = \frac{1}{1+e^{-x}}$ √© a fun√ß√£o sigmoide, $H_i$ √© a linha $i$ da matriz de vari√°veis preditoras e $y_i$ √© o r√≥tulo de classe da observa√ß√£o $i$. A regulariza√ß√£o L1 (Lasso) adiciona uma penalidade proporcional √† soma dos valores absolutos dos coeficientes:

$$
l_1(\beta) = l(\beta) - \lambda \sum_{j=1}^p |\beta_j|,
$$

enquanto a regulariza√ß√£o L2 (Ridge) adiciona uma penalidade proporcional √† soma dos quadrados dos coeficientes:

$$
l_2(\beta) = l(\beta) - \lambda \sum_{j=1}^p \beta_j^2,
$$
onde $\lambda$ √© um hiperpar√¢metro que controla a for√ßa da regulariza√ß√£o [^8.5]. A regulariza√ß√£o L1 tende a zerar os coeficientes de vari√°veis menos importantes, promovendo a esparsidade, enquanto a regulariza√ß√£o L2 reduz a magnitude dos coeficientes, o que melhora a estabilidade do modelo.

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o log√≠stica com 3 vari√°veis preditoras, onde o vetor de coeficientes inicial √© $\beta = [2, -1, 3]$. Se aplicarmos regulariza√ß√£o L1 com $\lambda=0.5$, a penalidade seria $0.5 * (|2| + |-1| + |3|) = 0.5 * (2+1+3) = 3$.  Se usarmos L2, a penalidade seria $0.5 * (2^2 + (-1)^2 + 3^2) = 0.5 * (4+1+9) = 7$. A otimiza√ß√£o do modelo busca um vetor $\beta$ que minimize a fun√ß√£o de log-verossimilhan√ßa penalizada por esses valores. Se $\lambda$ for grande, a penalidade ter√° um peso grande na fun√ß√£o de custo, fazendo os coeficientes se tornarem menores. No caso do L1 alguns podem se tornar zero.

**Lemma 3:** A regulariza√ß√£o L1 na regress√£o log√≠stica leva a um modelo esparso, i.e., com muitos coeficientes iguais a zero.
*Prova:* A penalidade L1 induz solu√ß√µes esparsas porque o ponto de n√£o diferenciabilidade em $\beta_j=0$ leva o otimizador a definir alguns coeficientes como exatamente zero [^8.5]. Para que o valor da fun√ß√£o de custo diminua, alguns coeficientes tendem a ser exatamente iguais a zero. $\blacksquare$

**Corol√°rio 3:** A combina√ß√£o das regulariza√ß√µes L1 e L2 (Elastic Net) pode ser utilizada para obter um equil√≠brio entre esparsidade e estabilidade do modelo [^8.5].

> ‚ö†Ô∏è **Ponto Crucial**: A escolha do hiperpar√¢metro $\lambda$ √© crucial na regulariza√ß√£o e pode ser feita por meio de valida√ß√£o cruzada, conforme discutido em [^8.5].
### Separating Hyperplanes e Perceptrons
O conceito de **Separating Hyperplanes** (Hiperplanos Separadores) busca encontrar um hiperplano que separa as classes de dados, no caso da classifica√ß√£o bin√°ria, com a maior margem poss√≠vel. O hiperplano √© definido por um vetor normal $w$ e um intercepto $b$, e a decis√£o de classe √© dada pelo sinal da fun√ß√£o discriminante: $f(x) = w^Tx + b$ [^8.5.2].

O **Perceptron** √© um algoritmo de aprendizado que ajusta iterativamente os par√¢metros $w$ e $b$ para classificar corretamente os dados. Ele inicia com par√¢metros aleat√≥rios e itera sobre os dados, ajustando os par√¢metros quando uma classifica√ß√£o incorreta √© encontrada. No caso de dados linearmente separ√°veis, o Perceptron converge para um hiperplano separador [^8.5.1]. No entanto, se os dados n√£o s√£o linearmente separ√°veis, o Perceptron n√£o converge e pode oscilar [^8.5.1].

```mermaid
graph LR
    subgraph "Perceptron Learning"
        direction TB
        A["Initialize weights w and bias b"]
        B["For each training instance x·µ¢:"]
        C["Compute f(x·µ¢) = w·µÄx·µ¢ + b"]
        D["If f(x·µ¢) misclassifies x·µ¢:"]
        E["Update w = w + Œ∑x·µ¢ and b = b + Œ∑"]
        F["Repeat until convergence or maximum iterations"]
         A --> B
        B --> C
        C --> D
        D --> E
         E --> F
    end
```

> üí° **Exemplo Num√©rico:** Imagine um problema de classifica√ß√£o bin√°ria com dois atributos $(x_1, x_2)$. Temos os pontos da classe 1: (1, 1), (2, 2), (2,1) e da classe 2: (4, 4), (5, 5), (4, 5). O Perceptron busca um vetor $w$ e um bias $b$ tal que $w^Tx + b > 0$ para classe 1 e $w^Tx + b < 0$ para classe 2. Inicializamos $w = [0.1, -0.2]$ e $b=0$. Iteramos sobre os pontos. O ponto (1,1) √© classe 1 e $w^Tx+b = 0.1*1 -0.2*1 + 0 = -0.1 < 0$. A classifica√ß√£o est√° errada. Atualizamos $w = w + \eta*x = [0.1, -0.2] + 1*[1, 1] = [1.1, 0.8]$ (assumindo uma taxa de aprendizado $\eta = 1$) e $b=b+\eta=1$. O Perceptron itera sobre os pontos, atualizando $w$ e $b$ at√© que todos os pontos estejam corretamente classificados.

#### Pergunta Te√≥rica Avan√ßada: Qual a rela√ß√£o entre os separating hyperplanes e a fun√ß√£o de log-likelihood na regress√£o log√≠stica?
**Resposta:**
Os separating hyperplanes s√£o uma abordagem geom√©trica para a classifica√ß√£o, enquanto a regress√£o log√≠stica modela as probabilidades de classe diretamente utilizando a fun√ß√£o de log-likelihood.  No entanto, eles est√£o relacionados: a fronteira de decis√£o obtida pela regress√£o log√≠stica, quando linear, corresponde a um separating hyperplane. Na regress√£o log√≠stica, a fun√ß√£o de log-likelihood penaliza solu√ß√µes que n√£o separam bem as classes, enquanto os m√©todos de separating hyperplanes procuram diretamente o hiperplano que maximiza a margem de separa√ß√£o, que indiretamente afeta a verossimilhan√ßa. Ambas as abordagens buscam, de maneiras distintas, solu√ß√µes que levam √† melhor classifica√ß√£o.

**Lemma 4:** Em dados linearmente separ√°veis, o Perceptron encontra um separating hyperplane.
*Prova:* O Perceptron ajusta iterativamente os pesos e bias at√© que todos os pontos sejam corretamente classificados. Em um problema linearmente separ√°vel, existe um hiperplano que separa os pontos das diferentes classes; o Perceptron convergir√° para esse hiperplano ou um hiperplano similar [^8.5.1]. $\blacksquare$

**Corol√°rio 4:** A margem de um separating hyperplane pode ser maximizada por um processo de otimiza√ß√£o, que leva a uma melhor generaliza√ß√£o.
*Prova:* O problema de encontrar o hiperplano que maximiza a margem de separa√ß√£o pode ser formulado como um problema de otimiza√ß√£o quadr√°tica que √© resolvido pelos m√©todos de SVM (Support Vector Machines) [^8.5.2].

> ‚ö†Ô∏è **Ponto Crucial**: A exist√™ncia de um separating hyperplane depende da separabilidade linear dos dados. M√©todos de kernel podem ser usados para lidar com dados n√£o-linearmente separ√°veis [^8.5.2].

### Pergunta Te√≥rica Avan√ßada (Exemplo): Quais as diferen√ßas fundamentais entre o Bootstrap param√©trico e o Bootstrap n√£o-param√©trico no contexto de estimar a incerteza da fun√ß√£o Log Likelihood?
**Resposta:**

O *Bootstrap param√©trico* assume um modelo param√©trico para os dados, estimando os par√¢metros por m√°xima verossimilhan√ßa a partir da amostra original. Amostras bootstrap s√£o geradas a partir desse modelo com os par√¢metros estimados, conforme a equa√ß√£o (8.6) [^8.2.1]. A incerteza √© estimada atrav√©s da distribui√ß√£o dos resultados do modelo.

O *Bootstrap n√£o param√©trico*, por sua vez, n√£o faz nenhuma suposi√ß√£o param√©trica sobre os dados. Ele gera amostras bootstrap por reamostragem com reposi√ß√£o da amostra original. A incerteza √© estimada a partir da varia√ß√£o dos resultados do modelo nas diferentes amostras.

A principal diferen√ßa reside em como as amostras s√£o geradas: o bootstrap param√©trico utiliza um modelo e os seus par√¢metros estimados para gerar dados, enquanto o bootstrap n√£o param√©trico gera os dados diretamente da distribui√ß√£o emp√≠rica dos dados.

No contexto da fun√ß√£o de Log Likelihood, o bootstrap param√©trico usa a forma funcional da log-likelihood induzida pelo modelo param√©trico e estima a incerteza dos par√¢metros que a maximizam. J√° o bootstrap n√£o param√©trico utiliza uma amostra emp√≠rica do log-likelihood induzida pelas amostras bootstrap e calcula a variabilidade dos resultados. O bootstrap param√©trico pode ser mais preciso quando o modelo √© bem especificado, enquanto o bootstrap n√£o param√©trico √© mais robusto em rela√ß√£o a erros na especifica√ß√£o do modelo.

### Conclus√£o
Neste cap√≠tulo, exploramos a fun√ß√£o de **Log Likelihood** e sua relev√¢ncia fundamental para a infer√™ncia estat√≠stica e o aprendizado de modelos. Discutimos como a fun√ß√£o de Log Likelihood √© usada no **Maximum Likelihood Inference (MLI)**, exploramos o **Bootstrap** para estimar a incerteza e a infer√™ncia Bayesiana para integrar informa√ß√µes pr√©vias. Tamb√©m cobrimos t√©cnicas de aprimoramento de modelos como o **Bagging, Stacking e Bumping**, que utilizam a reamostragem e a combina√ß√£o de modelos para melhorar a performance. Este estudo profundo fornece um alicerce s√≥lido para lidar com modelos estat√≠sticos complexos e extrair informa√ß√µes valiosas de dados.

<!-- END DOCUMENT -->
[^8.1]: "For most of this book, the fitting (learning) of models has been achieved by minimizing a sum of squares for regression, or by minimizing cross-entropy for classification. In fact, both of these minimizations are instances of the maximum likelihood approach to fitting." *(Trecho de Model Inference and Averaging)*
[^8.2]: "In this chapter we provide a general exposition of the maximum likelihood approach, as well as the Bayesian method for inference. The bootstrap, introduced in Chapter 7, is discussed in this context, and its relation to maximum likelihood and Bayes is described. Finally, we present some related techniques for model averaging and improvement, including committee methods, bagging, stacking and bumping." *(Trecho de Model Inference and Averaging)*
[^8.2.1]: "The bootstrap method provides a direct computational way of assessing uncertainty, by sampling from the training data. Here we illustrate the bootstrap in a simple one-dimensional smoothing problem, and show its connection to maximum likelihood." *(Trecho de Model Inference and Averaging)*
[^8.2.2]: "It turns out that the parametric bootstrap agrees with least squares in the previous example because the model (8.5) has additive Gaussian errors. In general, the parametric bootstrap agrees not with least squares but with maximum likelihood, which we now review." *(Trecho de Model Inference and Averaging)*
[^8.3]: "In the Bayesian approach to inference, we specify a sampling model Pr(Z|0) (density or probability mass function) for our data given the parameters, and a prior distribution for the parameters Pr(0) reflecting our knowledge about 0 before we see the data. We then compute the posterior distribution." *(Trecho de Model Inference and Averaging)*
[^8.4]: "The distribution (8.25) with —Ç ‚Üí ‚àû is called a noninformative prior for 0. In Gaussian models, maximum likelihood and parametric bootstrap analyses tend to agree with Bayesian analyses that use a noninformative prior for the free parameters. These tend to agree, because with a constant prior, the posterior distribution is proportional to the likelihood." *(Trecho de Model Inference and Averaging)*
[^8.5]: "Methods of Selection of Variables and Regularization in Classification..."
[^8.5.1]: "Descreva em texto corrido como a ideia de maximizar a margem de separa√ß√£o leva ao conceito de hiperplanos √≥timos" *(Trecho de Model Inference and Averaging)*
[^8.5.2]: "Descreva em texto corrido como a ideia de maximizar a margem de separa√ß√£o leva ao conceito de hiperplanos √≥timos" *(Trecho de Model Inference and Averaging)*
[^8.6]: "Having defined a Bayesian model, one would like to draw samples from the resulting posterior distribution, in order to make inferences about the parameters. Except for simple models, this is often a difficult computational problem. In this section we discuss the Markov chain Monte Carlo (MCMC) approach to posterior sampling." *(Trecho de Model Inference and Averaging)*
