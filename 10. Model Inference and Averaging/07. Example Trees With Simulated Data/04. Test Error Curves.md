## Test Error Curves: Model Inference and Averaging
```mermaid
flowchart LR
    subgraph "Model Averaging and Improvement"
        A["Maximum Likelihood"] --> B["Bayesian Approaches"]
        B --> C["Bootstrap Analysis"]
        C --> D["Bagging"]
        D --> E["Stacking"]
        E --> F["Bumping"]
        F --> G["MCMC"]
    end
```

### Introdu√ß√£o
O presente cap√≠tulo explora t√©cnicas avan√ßadas de **infer√™ncia e modelagem**, com foco especial em m√©todos de **model averaging** e **melhoria de modelos**, que visam, em √∫ltima inst√¢ncia, a redu√ß√£o do **test error**. Abordamos desde os fundamentos do **maximum likelihood** e abordagens Bayesianas [^8.1], passando pela an√°lise do **bootstrap** [^8.2], at√© as estrat√©gias de **bagging**, **stacking**, **bumping** [^8.7, ^8.8, ^8.9] e **MCMC** [^8.6]. Cada uma dessas t√©cnicas √© crucial para entender e mitigar os erros que surgem ao aplicar modelos estat√≠sticos e de machine learning em dados reais. A busca pela redu√ß√£o do **test error** √© um objetivo central em muitos problemas pr√°ticos, e as ferramentas que apresentamos neste cap√≠tulo oferecem abordagens sofisticadas para atingir esse objetivo.

### Conceitos Fundamentais
**Conceito 1:** *Classifica√ß√£o e Erro de Teste*: O problema de **classifica√ß√£o** busca alocar inst√¢ncias a categorias predefinidas. A qualidade de um classificador √© avaliada pelo seu desempenho em dados n√£o vistos (conjunto de teste), quantificado pelo **test error**. M√©todos lineares, embora simples, podem ser eficazes em certos contextos, mas seu uso implica em um *trade-off* entre **vi√©s** e **vari√¢ncia**. Modelos mais complexos podem reduzir o vi√©s, mas tamb√©m podem ter alta vari√¢ncia e superajustar os dados de treinamento, levando a um alto **test error**. [^8.1]
**Lemma 1:** Dada uma fun√ß√£o de classifica√ß√£o linear $f(x) = w^Tx + b$, a decomposi√ß√£o do erro quadr√°tico m√©dio em vi√©s e vari√¢ncia pode ser expressa como
$$E[(y - f(x))^2] = (E[f(x)] - E[y])^2 + E[(f(x)-E[f(x)])^2]$$ onde o primeiro termo representa o quadrado do vi√©s e o segundo termo representa a vari√¢ncia. Essa decomposi√ß√£o revela o compromisso inerente a um modelo linear. O vi√©s representa a capacidade do modelo de se ajustar aos dados, enquanto a vari√¢ncia representa a sensibilidade do modelo a pequenas varia√ß√µes nos dados de treinamento. Ajustar mais par√¢metros na fun√ß√£o de classifica√ß√£o linear aumenta a complexidade, reduzindo o vi√©s mas tamb√©m aumentando a vari√¢ncia.
$\blacksquare$

```mermaid
graph TD
    subgraph "MSE Decomposition"
        direction TB
        A["MSE: E[(y - f(x))¬≤]"]
        B["Bias¬≤: (E[f(x)] - E[y])¬≤"]
        C["Variance: E[(f(x) - E[f(x)])¬≤]"]
        A --> B
        A --> C
    end
```

> üí° **Exemplo Num√©rico:**
> Vamos considerar um cen√°rio simplificado onde temos um modelo linear $f(x) = 0.5x + 1$ e os valores reais de $y$ para alguns pontos. Suponha que a verdadeira rela√ß√£o seja $y = 0.8x + 1.5$.
> 
> Dados:
> *  $x = [1, 2, 3]$
> *  $y_{true} = [2.3, 3.1, 3.9]$ (calculado como $0.8x + 1.5$)
> *  $f(x) = [1.5, 2.0, 2.5]$ (calculado como $0.5x + 1$)
>
> C√°lculos:
> 1.  **Vi√©s:** Calculamos o vi√©s como a diferen√ßa entre a m√©dia das previs√µes e a m√©dia dos valores reais:
>     *   $E[f(x)] = (1.5 + 2.0 + 2.5)/3 = 2.0$
>     *   $E[y] = (2.3 + 3.1 + 3.9) / 3 = 3.1$
>     *   $\text{Vi√©s}^2 = (2.0 - 3.1)^2 = 1.21$
> 2.  **Vari√¢ncia:** Calculamos a vari√¢ncia das previs√µes:
>     *   $Var(f(x)) =  ((1.5 - 2.0)^2 + (2.0 - 2.0)^2 + (2.5 - 2.0)^2)/3 =  (0.25 + 0 + 0.25)/3 = 0.167$
> 3.  **Erro Total (MSE):**
>     *  $\text{Erro Total} = ((1.5-2.3)^2 + (2.0 - 3.1)^2 + (2.5 - 3.9)^2)/3 = (0.64 + 1.21 + 1.96)/3 = 1.27$
>
> Decomposi√ß√£o do Erro:
> *   $\text{Vi√©s}^2 = 1.21$
> *   $\text{Vari√¢ncia} = 0.167$
> *   Note que $\text{Vi√©s}^2 + \text{Vari√¢ncia} \approx 1.21 + 0.167 = 1.377$.  O MSE (1.27) n√£o √© exatamente a soma do vi√©s ao quadrado e da vari√¢ncia devido a um termo de covari√¢ncia que n√£o √© zero neste exemplo (veja a deriva√ß√£o do erro quadr√°tico m√©dio em livros de estat√≠stica). Este exemplo mostra como o vi√©s, a vari√¢ncia e o erro total se relacionam. Um modelo mais complexo poderia reduzir o vi√©s, mas aumentaria a vari√¢ncia.
>
> **Interpreta√ß√£o**: Este exemplo num√©rico ilustra o trade-off entre vi√©s e vari√¢ncia. O modelo linear simples tem um vi√©s elevado pois est√° longe da rela√ß√£o verdadeira, e uma vari√¢ncia baixa por ser uma linha reta. Um modelo mais complexo (e.g. uma fun√ß√£o polinomial) poderia se ajustar melhor aos dados de treinamento e reduzir o vi√©s, mas isso pode levar a um aumento da vari√¢ncia e potencialmente um *overfitting* se generalizar mal para novos dados.

**Conceito 2:** *Linear Discriminant Analysis (LDA)*: LDA √© um m√©todo de classifica√ß√£o que assume que as classes seguem uma distribui√ß√£o normal com covari√¢ncias iguais. LDA busca projetar os dados em um subespa√ßo que maximiza a separa√ß√£o entre as classes. A fronteira de decis√£o em LDA √© linear e obtida pela maximiza√ß√£o da raz√£o entre a vari√¢ncia interclasses e a vari√¢ncia intraclasses. [^8.2] A suposi√ß√£o de normalidade e covari√¢ncias iguais, embora simplificadora, pode n√£o ser adequada em muitos cen√°rios do mundo real.
**Corol√°rio 1:** Em um problema de classifica√ß√£o com duas classes, a fun√ß√£o discriminante linear obtida pelo LDA pode ser expressa como
$$f(x) = (\mu_1 - \mu_2)^T \Sigma^{-1} x - \frac{1}{2} (\mu_1^T \Sigma^{-1} \mu_1 - \mu_2^T \Sigma^{-1} \mu_2),$$
onde $\mu_1$ e $\mu_2$ s√£o as m√©dias das classes e $\Sigma$ √© a covari√¢ncia comum. A escolha da proje√ß√£o linear de x no espa√ßo discriminante ($\Sigma^{-1}x$) e a diferen√ßa de dist√¢ncia para as m√©dias das classes ($\mu_1$ e $\mu_2$) levam √† constru√ß√£o de uma fronteira de decis√£o √≥tima. Esse corol√°rio destaca a import√¢ncia de um pr√©-processamento dos dados, visto que dados n√£o normalizados e com distribui√ß√µes diferentes em cada classe podem invalidar o pressuposto central do LDA. [^8.2]

```mermaid
graph LR
 subgraph "LDA Discriminant Function"
    direction LR
    A["f(x)"] --> B["(Œº‚ÇÅ - Œº‚ÇÇ)^T Œ£‚Åª¬π x"]
    A --> C["- 1/2 (Œº‚ÇÅ^T Œ£‚Åª¬π Œº‚ÇÅ - Œº‚ÇÇ^T Œ£‚Åª¬π Œº‚ÇÇ)"]
  end
```

> üí° **Exemplo Num√©rico:**
>
> Consideremos um problema de classifica√ß√£o com duas classes (0 e 1) em duas dimens√µes (x1 e x2). Suponha que temos os seguintes dados:
>
> *   **Classe 0:**
>     *   $n_0 = 100$ pontos
>     *   $\mu_0 = [1, 1]$
> *   **Classe 1:**
>     *   $n_1 = 100$ pontos
>     *   $\mu_1 = [3, 3]$
>
>  Vamos supor que a matriz de covari√¢ncia para ambas as classes seja $\Sigma = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$.
>
> 1.  **Calcular a Diferen√ßa das M√©dias:**
>      $\mu_1 - \mu_0 = [3 - 1, 3 - 1] = [2, 2]$
>
> 2.  **Calcular a Inversa da Matriz de Covari√¢ncia:**
>      $\Sigma^{-1} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$ (como √© a matriz identidade, sua inversa √© ela mesma).
>
> 3. **Calculando o termo $(\mu_1 - \mu_2)^T \Sigma^{-1}$:**
>      $[2, 2] \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} = [2, 2]$
>
> 4. **Calculando o termo $\frac{1}{2} (\mu_1^T \Sigma^{-1} \mu_1 - \mu_2^T \Sigma^{-1} \mu_2)$:**
>      * $\mu_1^T \Sigma^{-1} \mu_1 = [3, 3] \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} [3,3]^T = [3,3][3,3]^T = 3*3 + 3*3 = 18$
>      * $\mu_0^T \Sigma^{-1} \mu_0 = [1, 1] \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} [1,1]^T = [1,1][1,1]^T = 1*1 + 1*1 = 2$
>      * $\frac{1}{2}(18 - 2) = 8$
> 5.  **Fun√ß√£o Discriminante LDA:**
>     $f(x) = [2, 2] \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} - 8 = 2x_1 + 2x_2 - 8$
>
> 6.  **Fronteira de Decis√£o:** Para classificar uma nova inst√¢ncia, calculamos $f(x)$ e comparamos com 0.
>     *   Se $f(x) > 0$, classificamos como Classe 1.
>     *   Se $f(x) < 0$, classificamos como Classe 0.
>    * Se $f(x) = 0$, a inst√¢ncia est√° exatamente sobre a fronteira de decis√£o linear.
>   A fronteira de decis√£o linear √© $2x_1 + 2x_2 - 8 = 0$, que simplifica para $x_1 + x_2 = 4$.
>
> **Interpreta√ß√£o**: A fun√ß√£o discriminante $f(x) = 2x_1 + 2x_2 - 8$ gera uma fronteira de decis√£o linear que separa as duas classes. Se os dados fossem distribu√≠dos de forma diferente, ou se as covari√¢ncias fossem distintas, o resultado seria diferente.
>
> ```python
> import numpy as np
> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
>
> # Dados de exemplo
> X = np.array([[1, 1], [1, 2], [2, 1], [2, 2], [3, 3], [3, 4], [4, 3], [4, 4]])
> y = np.array([0, 0, 0, 0, 1, 1, 1, 1])
>
> # Treinando o modelo LDA
> lda = LinearDiscriminantAnalysis()
> lda.fit(X, y)
>
> # Coeficientes da fronteira de decis√£o
> print(f"Coeficientes: {lda.coef_}")
> print(f"Intercept: {lda.intercept_}")
>
> # Previs√£o para um novo ponto
> new_point = np.array([[2.5, 2.5]])
> prediction = lda.predict(new_point)
> print(f"Predi√ß√£o para [2.5, 2.5]: Classe {prediction[0]}")
> ```

**Conceito 3:** *Logistic Regression*: Logistic Regression modela a probabilidade de uma inst√¢ncia pertencer a uma classe por meio de uma fun√ß√£o sigmoide aplicada a uma combina√ß√£o linear das vari√°veis. O aprendizado dos par√¢metros na Logistic Regression √© feito por meio da maximiza√ß√£o da verossimilhan√ßa (maximum likelihood). A escolha da fun√ß√£o logit √© crucial para estabelecer uma rela√ß√£o entre a combina√ß√£o linear e a probabilidade. Ao contr√°rio do LDA, Logistic Regression n√£o assume que as classes s√£o Gaussianas, o que o torna um m√©todo mais flex√≠vel para muitos problemas reais. [^8.3]
> ‚ö†Ô∏è **Nota Importante**: A fun√ß√£o de custo da Logistic Regression √© baseada na entropia cruzada (cross-entropy) e penaliza erros mais severamente quando a probabilidade prevista difere muito da probabilidade real. [^8.3]
> ‚ùó **Ponto de Aten√ß√£o**: Em problemas com classes n√£o balanceadas, a Logistic Regression pode ser suscet√≠vel ao problema de vi√©s e necessitar de t√©cnicas adicionais como reamostragem ou pondera√ß√£o de classes para um modelo mais balanceado. [^8.3]
> ‚úîÔ∏è **Destaque**: Tanto LDA quanto Logistic Regression, em problemas com duas classes, podem levar a resultados similares em termos da fronteira de decis√£o linear, mas a forma como cada m√©todo estima e interpreta os par√¢metros √© distinta. [^8.5]
> üí° **Exemplo Num√©rico:**
>
> Suponha que temos dados de treinamento com duas classes (0 e 1) e uma √∫nica caracter√≠stica (x). A fun√ß√£o log√≠stica (sigmoide) √© dada por $p(y=1|x) = \frac{1}{1+e^{-(\beta_0 + \beta_1x)}}$. O modelo tem como objetivo estimar os par√¢metros $\beta_0$ e $\beta_1$.
>
> Dados de Treinamento:
>
> | x    | y |
> | ---- | - |
> | -1   | 0 |
> | 0    | 0 |
> | 1    | 1 |
> | 2    | 1 |
>
> O processo de estima√ß√£o dos par√¢metros $\beta_0$ e $\beta_1$ envolve a maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa ou, equivalentemente, a minimiza√ß√£o da fun√ß√£o de custo de entropia cruzada.
>
> Para fins de ilustra√ß√£o, vamos supor que, ap√≥s o treinamento, encontramos os seguintes par√¢metros:
>
> *   $\beta_0 = -1$
> *   $\beta_1 = 1$
>
> Ent√£o, a probabilidade prevista de $y=1$ dado $x$ √©:
>
>   $p(y=1|x) = \frac{1}{1+e^{-(-1 + 1x)}}$
>
> Para um novo ponto $x = 0.5$, a probabilidade prevista de $y=1$ seria:
>   $p(y=1|x=0.5) = \frac{1}{1+e^{-(-1 + 1(0.5))}} =  \frac{1}{1+e^{0.5}} \approx \frac{1}{1+1.6487} \approx 0.377$
>
> Para classificar essa inst√¢ncia, comparamos a probabilidade com um limiar (por exemplo, 0.5):
>
>   Como $0.377 < 0.5$, a inst√¢ncia seria classificada como 0.
>
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
>
> # Dados de exemplo
> X = np.array([[-1], [0], [1], [2]])
> y = np.array([0, 0, 1, 1])
>
> # Treinando o modelo de regress√£o log√≠stica
> log_reg = LogisticRegression()
> log_reg.fit(X, y)
>
> # Par√¢metros aprendidos
> print(f"Intercept: {log_reg.intercept_}")
> print(f"Coeficiente: {log_reg.coef_}")
>
> # Previs√£o de probabilidade para um novo ponto
> new_point = np.array([[0.5]])
> probability = log_reg.predict_proba(new_point)[0, 1]
> print(f"Probabilidade para x=0.5: {probability}")
>
> # Predi√ß√£o da classe para um novo ponto
> prediction = log_reg.predict(new_point)[0]
> print(f"Predi√ß√£o para x=0.5: Classe {prediction}")
>
> ```
>
> **Interpreta√ß√£o:** A regress√£o log√≠stica modela a probabilidade de uma inst√¢ncia pertencer a uma classe. Os par√¢metros $\beta_0$ e $\beta_1$ s√£o obtidos maximizando a verossimilhan√ßa dos dados de treinamento.
>

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
```mermaid
flowchart LR
    subgraph "Indicator Regression"
        A["Encode Classes into Indicator Matrix"] --> B["Estimate Coefficients (B) via Least Squares"]
        B --> C["Apply Decision Rule:  argmax(x^T * B)"]
    end
```
A regress√£o linear em matrizes indicadoras pode ser aplicada para problemas de classifica√ß√£o atrav√©s da codifica√ß√£o das classes em vari√°veis bin√°rias e ajuste dos coeficientes por m√≠nimos quadrados (least squares). Essa abordagem √© uma extens√£o direta da regress√£o linear para problemas multivariados, onde cada classe √© representada por um vetor indicador. A regra de decis√£o √© dada pela atribui√ß√£o de uma nova inst√¢ncia √† classe com o maior valor previsto. No entanto, esse m√©todo tem limita√ß√µes, como a possibilidade de gerar previs√µes fora do intervalo [0, 1] para as probabilidades, o que pode ser problem√°tico em termos de interpreta√ß√£o. Al√©m disso, a regress√£o de indicadores pode n√£o levar a resultados √≥timos em problemas onde as classes n√£o s√£o linearmente separ√°veis. [^8.2] A compara√ß√£o com outros m√©todos, como LDA e Logistic Regression, revela que a regress√£o de indicadores √©, muitas vezes, uma abordagem mais simples com maior vi√©s em rela√ß√£o a modelos mais flex√≠veis.

**Lemma 2:** Seja $Y$ uma matriz indicadora $N \times K$ com $K$ classes, e $X$ a matriz de preditores $N \times p$. A regress√£o linear em matriz de indicadores encontra os coeficientes $B$ atrav√©s de
$$B = (X^TX)^{-1}X^TY$$.
A fun√ß√£o discriminante linear √© dada por $f(x) = x^TB$. As proje√ß√µes das inst√¢ncias nas diferentes classes levam √† regra de decis√£o de escolher a classe $k$ para a qual $f_k(x)$ √© m√°xima. A matriz de covari√¢ncia de $B$ √© dada por $(X^TX)^{-1}\sigma^2$, onde $\sigma^2$ √© a vari√¢ncia dos erros.
$\blacksquare$

```mermaid
graph LR
    subgraph "Indicator Regression Formula"
        direction LR
        A["B"] --> B["(X^T X)^-1"]
        B --> C["X^T Y"]
        C
    end
```

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um problema de classifica√ß√£o com 3 classes (A, B, C) e 2 preditores ($x_1$, $x_2$). Usaremos uma matriz indicadora para codificar as classes.
>
>  Dados:
>  ```
>  X = [[1, 1], [1, 2], [2, 1], [2, 2], [3, 3], [3, 4], [4, 3], [4, 4]]
>  Y = [[1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1]]
>  ```
>  Onde a primeira coluna em Y representa a classe A, a segunda a classe B e a terceira a classe C. Por exemplo, a primeira inst√¢ncia pertence √† classe A.
>
> 1.  **Montar as matrizes X e Y:**
>
>     $X = \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 2 & 1 \\ 2 & 2 \\ 3 & 3 \\ 3 & 4 \\ 4 & 3 \\ 4 & 4 \end{bmatrix}$,  $Y = \begin{bmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \end{bmatrix}$
>
> 2.  **Calcular $X^TX$:**
>
>     $X^TX = \begin{bmatrix} 1 & 1 & 2 & 2 & 3 & 3 & 4 & 4 \\ 1 & 2 & 1 & 2 & 3 & 4 & 3 & 4 \end{bmatrix} \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 2 & 1 \\ 2 & 2 \\ 3 & 3 \\ 3 & 4 \\ 4 & 3 \\ 4 & 4 \end{bmatrix} = \begin{bmatrix} 60 & 59 \\ 59 & 60 \end{bmatrix}$
>
> 3.  **Calcular a inversa de $(X^TX)^{-1}$:**
>
>     $(X^TX)^{-1} = \frac{1}{60*60 - 59*59} \begin{bmatrix} 60 & -59 \\ -59 & 60 \end{bmatrix} = \frac{1}{119} \begin{bmatrix} 60 & -59 \\ -59 & 60 \end{bmatrix} \approx \begin{bmatrix} 0.504 & -0.496 \\ -0.496 & 0.504 \end{bmatrix}$
>
> 4.  **Calcular $X^TY$:**
>     $X^TY = \begin{bmatrix} 1 & 1 & 2 & 2 & 3 & 3 & 4 & 4 \\ 1 & 2 & 1 & 2 & 3 & 4 & 3 & 4 \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \end{bmatrix} = \begin{bmatrix} 2 & 4 & 14 \\ 3 & 3 & 14 \end{bmatrix}$
>
>
> 5.  **Calcular os coeficientes $B = (X^TX)^{-1}X^TY$:**
>     $B = \begin{bmatrix} 0.504 & -0.496 \\ -0.496 & 0.504 \end{bmatrix} \begin{bmatrix} 2 & 4 & 14 \\ 3 & 3 & 14 \end{bmatrix} = \begin{bmatrix} -0.48 & 0.52 & 0.08 \\ 0.52 & -0.48 & 0.08 \end{bmatrix} $
> 6.  **Fun√ß√£o Discriminante:** Para uma nova inst√¢ncia $x = [2.5, 2.5]$, calculamos $f(x) = x^TB$:
>
>  $f(x) = \begin{bmatrix} 2.5 & 2.5 \end{bmatrix} \begin{bmatrix} -0.48 & 0.52 & 0.08 \\ 0.52 & -0.48 & 0.08 \end{bmatrix} = \begin{bmatrix} 0.1 & 0.1 & 0.4 \end{bmatrix} $
>
> 7.  **Regra de Decis√£o:**  A classe com o maior valor √© a classe C.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LinearRegression
>
> # Dados de exemplo
> X = np.array([[1, 1], [1, 2], [2, 1], [2, 2], [3, 3], [3, 4], [4, 3], [4, 4]])
> Y = np.array([[1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1]])
>
> # Treinando o modelo de regress√£o linear
> lin_reg = LinearRegression()
> lin_reg.fit(X, Y)
>
> # Coeficientes aprendidos
> print(f"Coeficientes:\n {lin_reg.coef_}")
>
> # Previs√£o para um novo ponto
> new_point = np.array([[2.5, 2.5]])
> prediction = lin_reg.predict(new_point)
> print(f"Previs√£o para [2.5, 2.5]: {prediction}")
>
> # Escolhendo a classe com maior valor
> predicted_class = np.argmax(prediction)
> print(f"Classe predita: {predicted_class}")
>
> ```
>
> **Interpreta√ß√£o:** A regress√£o de indicadores usa os coeficientes $B$ para calcular um valor para cada classe, atribuindo a nova inst√¢ncia √† classe com o maior valor. As limita√ß√µes s√£o que as previs√µes podem ficar fora do intervalo $[0, 1]$, e os resultados podem n√£o ser ideais para conjuntos de dados complexos.

**Corol√°rio 2:** A proje√ß√£o das inst√¢ncias no hiperplano gerado pela regress√£o de indicadores √© matematicamente equivalente √† proje√ß√£o no espa√ßo discriminante gerado pelo LDA, quando a matriz de covari√¢ncia √© a mesma para todas as classes, mas o LDA assume explicitamente distribui√ß√µes Gaussianas. A equival√™ncia entre as abordagens simplifica a an√°lise do modelo, destacando que a diferen√ßa entre os modelos est√° na formula√ß√£o dos pressupostos e na otimiza√ß√£o dos par√¢metros.
‚ÄúEm alguns cen√°rios, conforme apontado em [^8.3], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1].‚Äù
‚ÄúNo entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^8.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear.‚Äù

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
```mermaid
graph LR
 subgraph "Regularization Methods"
    direction TB
    A["Cost Function"] --> B["L1 Regularization (Lasso)"]
    A --> C["L2 Regularization (Ridge)"]
    A --> D["Elastic Net (L1 + L2)"]
    B --> E["Promotes Sparsity"]
    C --> F["Reduces Coefficient Magnitude"]
    D --> G["Combines Sparsity and Coefficient Reduction"]
 end
```
M√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o desempenham um papel crucial no aprimoramento dos modelos de classifica√ß√£o. Regulariza√ß√£o L1 (Lasso) e L2 (Ridge) s√£o t√©cnicas importantes que adicionam termos de penalidade √† fun√ß√£o de custo, que combinam a verossimilhan√ßa e um termo de penalidade, levando a modelos mais est√°veis e menos sujeitos a overfitting. A penaliza√ß√£o L1 promove a esparsidade, selecionando um subconjunto de vari√°veis importantes, enquanto a penaliza√ß√£o L2 reduz a magnitude dos coeficientes, tornando o modelo menos sens√≠vel a pequenas varia√ß√µes nos dados. A escolha entre L1 e L2 depende da estrutura dos dados e dos objetivos do modelo; L1 √© mais indicada para problemas com um grande n√∫mero de vari√°veis potencialmente irrelevantes, enquanto L2 √© √∫til para estabilizar os coeficientes e melhorar a generaliza√ß√£o do modelo. A combina√ß√£o de L1 e L2 (Elastic Net) pode combinar as vantagens de ambas as abordagens. [^8.4.4, ^8.5, ^8.5.1, ^8.5.2]
**Lemma 3:** Em classifica√ß√£o log√≠stica, adicionar uma penalidade L1 √† fun√ß√£o de custo resulta em um problema de otimiza√ß√£o que promove a esparsidade dos coeficientes, ou seja, muitos coeficientes ser√£o exatamente iguais a zero. A fun√ß√£o de custo penalizada em um cen√°rio de regress√£o log√≠stica com penaliza√ß√£o L1 √© dada por:
$$J(\beta) = -\sum_{i=1}^{N} [y_i \log(p_i) + (1-y_i) \log(1-p_i)] + \lambda \sum_{j=1}^{p} |\beta_j|,$$
onde $p_i$ √© a probabilidade prevista para a inst√¢ncia $i$, $\beta_j$ s√£o os coeficientes e $\lambda$ √© um par√¢metro de regulariza√ß√£o. A norma L1 penaliza a soma dos valores absolutos dos coeficientes e promove uma solu√ß√£o esparsa.
$\blacksquare$

```mermaid
graph LR
    subgraph "L1 Regularized Logistic Cost Function"
    direction LR
    A["J(Œ≤)"] --> B["- Œ£ [y·µ¢ log(p·µ¢) + (1-y·µ¢)log(1-p·µ¢)]"]
    A --> C["+ Œª Œ£ |Œ≤‚±º|"]
    end
```

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar uma regress√£o log√≠stica com 3 preditores ($x_1, x_2, x_3$) e aplicar a regulariza√ß√£o L1 (Lasso). Os dados s√£o simulados.
>
> 1.  **Simula√ß√£o dos Dados:**
>
> ```python
> import numpy as np
> import pandas as pd
> from sklearn.linear_model import LogisticRegression
> from sklearn.model_selection import train_test_split
> from sklearn.preprocessing import StandardScaler
>
> np.random.seed(42)
> n_samples = 100
>
> # Simulando dados com alguns preditores pouco informativos
> X = np.random.rand(n_samples, 3)
> y = (2*X[:, 0] + 1*X[:, 1] + 0.1 * X[:, 2] > 1.5).astype(int)
>
> # Adicionando ru√≠do aos dados
> y = y + np.random.normal(0, 0.2, size=n_samples)
> y = np.clip(y,0,1).astype(int)
>
> # Dividindo os dados em treino e teste
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Normalizando os dados
> scaler = StandardScaler()
> X_train_scaled = scaler.fit_transform(X_train)
> X_test_scaled = scaler.transform(X_test)
> ```
>
> 2.  **Treinar Regress√£o Log√≠stica sem Regulariza√ß√£o:**
> ```python
> # Treinando sem regulariza√ß√£o
> log_reg_no_reg = LogisticRegression(penalty=None)
> log_reg_no_reg.fit(X_train_scaled, y_train)
> print("Coefficients without L1: ", log_reg_no_reg.coef_)
> ```
>
> 3. **Treinar Regress√£o Log√≠stica com Regulariza√ß√£o L1 (Lasso):**
> ```python
> # Treinando com regulariza√ß√£o L1 (Lasso)
> log_reg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=0.5)
> log_reg_l1.fit(X_train_scaled, y_train)
> print("Coefficients with L1: ", log_reg_l1.coef_)
>
> # Treinando com regulariza√ß√£o L1 (Lasso) com um lambda menor
> log_reg_l1_strong = LogisticRegression(penalty='l1', solver='liblinear', C=0.1)
> log_reg_l1_strong.fit(X_train_scaled, y_train)
> print("Coefficients with stronger L1: ", log_reg_l1_strong.coef_)
> ```
> 4. **Interpreta√ß√£o:**
>  * Sem regulariza√ß√£o, todos os coeficientes t√™m valores diferentes de zero, refletindo uma abordagem que usa todos os preditores.
>  * Com regulariza√ß√£o L1, o coeficiente associado a $x_3$ foi zerado com um $\lambda$ inicial (C=0.5), demonstrando a esparsidade da penaliza√ß√£o L1. Quando aumentamos o $\lambda$ (reduzindo o C para 0.1), os coeficientes de x2 e x3 foram zerados, indicando que o modelo s√≥ considera x1 para a classifica√ß√£o. O par√¢metro C (inverso de lambda) controla a for√ßa da regulariza√ß√£o. Quanto menor o C, maior a regulariza√ß√£o.
>
> ```mermaid
>  flowchart TD
>      A["Simulated Data"] --> B["Without Regularization"]
>      A --> C["With L1 Regularization"]
>      B --> D["All Coefficients != 0"]
>      C --> E["Some Coefficients = 0"]
> ```
>
> **Interpreta√ß√£o**:  O exemplo num√©rico ilustra que a penalidade L1 leva √† esparsidade dos coeficientes. Um valor maior para $\lambda$ (ou menor para $C$) leva mais coeficientes a zero. Assim, a regulariza√ß√£o L1 realiza uma sele√ß√£o de vari√°veis, identificando os preditores mais importantes para a classifica√ß√£o.

**Prova do Lemma 3:** A prova do lemma envolve conceitos de ot