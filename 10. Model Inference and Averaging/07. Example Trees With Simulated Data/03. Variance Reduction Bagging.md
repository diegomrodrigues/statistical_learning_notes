Okay, here's the enhanced text with all mathematical expressions formatted using LaTeX notation:

## Variance Reduction in Bagging

```mermaid
graph LR
    A["Original Data"] --> B("Bootstrap Sampling")
    B --> C("Multiple Datasets")
    C --> D("Train Model on Each Dataset")
    D --> E("Aggregate Predictions")
    E --> F("Final Prediction (Reduced Variance)")
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style F fill:#ccf,stroke:#333,stroke-width:2px
```

### Introdu√ß√£o

O presente cap√≠tulo explora o conceito de **bagging** (Bootstrap Aggregating), uma t√©cnica poderosa no arsenal do aprendizado de m√°quina para reduzir a vari√¢ncia de estimativas e previs√µes [^8.1], [^8.7]. O bagging √© uma metodologia que se baseia na cria√ß√£o de m√∫ltiplas amostras de dados atrav√©s do **bootstrap**, e no treinamento de um modelo em cada uma dessas amostras. Em seguida, as previs√µes desses modelos s√£o agregadas para produzir uma estimativa final. Esta t√©cnica √© especialmente √∫til para modelos inst√°veis, como **√°rvores de decis√£o**, onde pequenas mudan√ßas nos dados de treinamento podem levar a grandes varia√ß√µes nas previs√µes. O objetivo principal do bagging √© criar um modelo mais robusto, com menor variabilidade, e consequentemente com maior capacidade de generaliza√ß√£o.

### Conceitos Fundamentais

**Conceito 1:** O **Bootstrap** √© uma t√©cnica de reamostragem que envolve a amostragem com reposi√ß√£o a partir dos dados de treinamento originais [^8.2]. Essa amostragem gera um n√∫mero *B* de novos datasets, cada um com o mesmo tamanho que o dataset original, mas com algumas observa√ß√µes repetidas e outras omitidas. O bootstrap √© fundamental para o bagging, pois fornece a base para criar as m√∫ltiplas vers√µes do modelo.

**Lemma 1:** Dado um conjunto de dados $Z = \{z_1, z_2, \ldots, z_N\}$, onde $z_i = (x_i, y_i)$, a probabilidade de uma observa√ß√£o $z_i$ n√£o ser selecionada em uma amostra bootstrap de tamanho *N* √© $(1 - \frac{1}{N})^N$. Quando $N \rightarrow \infty$, esta probabilidade converge para $e^{-1} \approx 0.368$ [^8.2.1].
$$\lim_{N\to\infty} (1 - \frac{1}{N})^N = e^{-1} \approx 0.368$$
Isso implica que cerca de 63.2% das observa√ß√µes originais estar√£o em cada amostra bootstrap, enquanto o restante n√£o. Este resultado justifica por que amostras bootstrap s√£o ‚Äúsuficientemente‚Äù diferentes para induzir diversidade nos modelos. $\blacksquare$

> üí° **Exemplo Num√©rico:**  Imagine que temos um dataset com 100 observa√ß√µes (N=100). Ao criar uma amostra bootstrap, cada observa√ß√£o tem uma probabilidade de 1/100 de ser selecionada a cada sorteio. Ap√≥s 100 sorteios, algumas observa√ß√µes ser√£o selecionadas mais de uma vez, enquanto outras n√£o ser√£o selecionadas. A probabilidade de uma observa√ß√£o *n√£o* ser selecionada √© aproximadamente $e^{-1} \approx 0.368$, o que significa que cerca de 37 das 100 observa√ß√µes originais n√£o estar√£o em uma dada amostra bootstrap. Por outro lado, aproximadamente 63 observa√ß√µes do dataset original estar√£o presentes na amostra bootstrap, algumas repetidas. Este processo gera diversidade entre as amostras bootstrap, o que √© crucial para o bagging.
>
>  ```python
>  import numpy as np
>
>  def bootstrap_sample(data):
>    n = len(data)
>    indices = np.random.choice(n, size=n, replace=True)
>    return data[indices]
>
>  # Criando um conjunto de dados de exemplo
>  data = np.arange(100)
>
>  # Gerando uma amostra bootstrap
>  sample = bootstrap_sample(data)
>
>  # Verificando a ocorr√™ncia de cada elemento
>  unique, counts = np.unique(sample, return_counts=True)
>  print("Unique elements in bootstrap sample:", unique)
>  print("Counts of each unique element:", counts)
>
>  # Estimativa do percentual de elementos n√£o selecionados
>  original_not_selected = 0
>  for i in range(100):
>      if i not in unique:
>          original_not_selected += 1
>  print(f"Elements from the original set not in the bootstrap set: {original_not_selected}")
>  print(f"Proportion not selected: {original_not_selected/100:.3f}")
>  ```

**Conceito 2:** O **Bagging**, ou Bootstrap Aggregating, consiste em treinar um modelo em cada uma das amostras bootstrap geradas e, em seguida, agregar as previs√µes [^8.7]. Para problemas de regress√£o, essa agrega√ß√£o √© geralmente a m√©dia das previs√µes dos modelos individuais. Para problemas de classifica√ß√£o, a agrega√ß√£o pode ser por meio de vota√ß√£o majorit√°ria, ou seja, a classe mais predita pelos modelos √© a classe final.
$$f_{bag}(x) = \frac{1}{B}\sum_{b=1}^{B} f_b^*(x)$$
onde $f_b^*(x)$ √© a previs√£o do modelo treinado na amostra bootstrap *b*, e *B* √© o n√∫mero total de amostras bootstrap.

```mermaid
graph LR
    subgraph "Bagging Aggregation"
        direction TB
        A["Individual Model Predictions: f_1*(x), ..., f_B*(x)"]
        B["Aggregation Method (Mean or Voting)"]
        C["Bagged Prediction: f_bag(x)"]
        A --> B
        B --> C
    end
```

> üí° **Exemplo Num√©rico (Regress√£o):** Suponha que temos um problema de regress√£o, onde queremos prever o pre√ßo de uma casa com base em suas caracter√≠sticas. Usamos o bagging com B=3 √°rvores de decis√£o. Cada √°rvore √© treinada em uma amostra bootstrap diferente do conjunto de dados original. Para uma nova casa com caracter√≠sticas x, as tr√™s √°rvores retornam as seguintes previs√µes de pre√ßo (em milhares de d√≥lares):
>
> *   √Årvore 1: f‚ÇÅ\*(x) = 350
> *   √Årvore 2: f‚ÇÇ\*(x) = 370
> *   √Årvore 3: f‚ÇÉ\*(x) = 360
>
> A previs√£o agregada pelo bagging seria:
>
> $$f_{bag}(x) = \frac{350 + 370 + 360}{3} = \frac{1080}{3} = 360$$
>
> Assim, a previs√£o final do bagging √© de 360 mil d√≥lares.
>
> üí° **Exemplo Num√©rico (Classifica√ß√£o):** Em um problema de classifica√ß√£o, queremos classificar emails como spam ou n√£o-spam. Usamos bagging com B=5 √°rvores de decis√£o. Para um determinado email, cada √°rvore faz a seguinte classifica√ß√£o:
>
>  * √Årvore 1: spam
>  * √Årvore 2: n√£o-spam
>  * √Årvore 3: spam
>  * √Årvore 4: n√£o-spam
>  * √Årvore 5: spam
>
> A classe predita pelo bagging seria "spam", pois √© a classe majorit√°ria (3 de 5 √°rvores classificaram como spam).

**Corol√°rio 1:** Se o modelo base √© inst√°vel, ou seja, sofre grandes altera√ß√µes nas previs√µes quando pequenas altera√ß√µes nos dados de treinamento s√£o feitas, o bagging pode reduzir a vari√¢ncia da estimativa final [^8.7]. Isso ocorre porque o bagging agrega as previs√µes de muitos modelos inst√°veis, e essa agrega√ß√£o tende a ser mais est√°vel.

**Conceito 3:** Em problemas de classifica√ß√£o, al√©m da vota√ß√£o majorit√°ria, o bagging pode ser implementado agregando as *probabilidades* estimadas para cada classe por cada modelo [^8.7]. Essa abordagem geralmente leva a melhores estimativas das probabilidades de classe e tamb√©m pode reduzir a vari√¢ncia.

> üí° **Exemplo Num√©rico (Classifica√ß√£o com Probabilidades):**  No mesmo problema de classifica√ß√£o de spam, em vez de usar vota√ß√£o majorit√°ria, cada √°rvore estima a probabilidade de um email ser spam. As probabilidades retornadas pelas 5 √°rvores para um email s√£o:
>
> * √Årvore 1: P(spam) = 0.9
> * √Årvore 2: P(spam) = 0.3
> * √Årvore 3: P(spam) = 0.8
> * √Årvore 4: P(spam) = 0.4
> * √Årvore 5: P(spam) = 0.7
>
> A probabilidade agregada pelo bagging seria:
> $$P_{bag}(spam) = \frac{0.9 + 0.3 + 0.8 + 0.4 + 0.7}{5} = 0.62$$
>
> A previs√£o final seria classificar o email como "spam", j√° que a probabilidade agregada √© maior que 0.5. Al√©m disso, temos uma estimativa da probabilidade do email ser spam, o que √© mais informativo do que apenas a classifica√ß√£o.
> ```python
> import numpy as np
>
> # Probabilidades de spam de cada modelo
> probs = np.array([0.9, 0.3, 0.8, 0.4, 0.7])
>
> # Calcula a m√©dia
> avg_prob = np.mean(probs)
>
> print(f"Probabilidade m√©dia de spam: {avg_prob:.2f}")
>
> # Classifica com base no threshold de 0.5
> if avg_prob > 0.5:
>    print("Classificado como spam")
> else:
>    print("Classificado como n√£o-spam")
> ```

> ‚ö†Ô∏è **Nota Importante**:  O bagging √© uma t√©cnica de redu√ß√£o de vari√¢ncia que n√£o altera significativamente o vi√©s do modelo [^8.7]. A t√©cnica funciona melhor quando os modelos base s√£o inst√°veis e com pouca tend√™ncia.
> ‚ùó **Ponto de Aten√ß√£o**: O bagging, em alguns casos, pode n√£o funcionar bem se os modelos base forem muito fortes ou est√°veis. Nesses casos, as previs√µes dos modelos individuais ser√£o muito similares e a agrega√ß√£o n√£o trar√° muitos ganhos.
> ‚úîÔ∏è **Destaque**: O bagging funciona bem em conjunto com √°rvores de decis√£o. A combina√ß√£o de instabilidade das √°rvores com o poder de redu√ß√£o de vari√¢ncia do bagging leva a bons resultados.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Bagging with Linear Regression"
        direction TB
        A["Bootstrap Samples"] --> B["Train Linear Regression on each sample"]
        B --> C["Predictions from each model f_b*(x)"]
        C --> D["Aggregate Predictions (Mean)"]
        D --> E["Bagged Prediction f_bag(x)"]
    end
```

O bagging pode ser aplicado a modelos de regress√£o linear de uma maneira espec√≠fica e com certas limita√ß√µes [^8.7]. Ao aplic√°-lo, para cada amostra bootstrap, treina-se um modelo linear, obtendo um conjunto de coeficientes. A agrega√ß√£o das previs√µes se d√° calculando a m√©dia das predi√ß√µes obtidas em cada um dos modelos treinados. Entretanto, como a regress√£o linear √© um m√©todo geralmente est√°vel, o bagging ter√° pouco efeito quando aplicado diretamente [^8.7]. Em outras palavras, as predi√ß√µes de regress√µes lineares em diferentes amostras bootstrap ser√£o muito similares e, ao agregar, n√£o haver√° redu√ß√£o na vari√¢ncia.

**Lemma 2:** Seja $f(x)$ uma fun√ß√£o de regress√£o linear e $f_b^*(x)$ a fun√ß√£o de regress√£o linear estimada na amostra bootstrap *b*. Se os par√¢metros do modelo linear forem estimados por Ordinary Least Squares (OLS), sob a suposi√ß√£o de que os erros s√£o independentes e identicamente distribu√≠dos, ent√£o:
$$\lim_{B\to\infty} \frac{1}{B} \sum_{b=1}^B f_b^*(x) = f(x)$$
Isso significa que, no limite quando o n√∫mero de amostras bootstrap tende ao infinito, a agrega√ß√£o das previs√µes dos modelos lineares coincide com a previs√£o do modelo linear treinado no dataset original. $\blacksquare$

> üí° **Exemplo Num√©rico:** Consideremos uma regress√£o linear simples, onde $y = \beta_0 + \beta_1x + \epsilon$. Vamos supor que, no dataset original, tenhamos $\beta_0 = 2$ e $\beta_1 = 3$. Ap√≥s aplicar o bootstrap, obtemos 3 amostras e treinamos 3 modelos lineares, resultando nos seguintes par√¢metros:
>
> *   Modelo 1: $\beta_0^* = 2.1, \beta_1^*= 2.9$
> *   Modelo 2: $\beta_0^* = 1.9, \beta_1^*= 3.1$
> *   Modelo 3: $\beta_0^* = 2.0, \beta_1^*= 3.0$
>
> Para um valor de entrada x=5, as previs√µes dos tr√™s modelos s√£o:
>
> *   $f_1^*(5) = 2.1 + 2.9 * 5 = 16.6$
> *   $f_2^*(5) = 1.9 + 3.1 * 5 = 17.4$
> *   $f_3^*(5) = 2.0 + 3.0 * 5 = 17.0$
>
> A previs√£o agregada pelo bagging √©:
>
> $$f_{bag}(5) = \frac{16.6 + 17.4 + 17.0}{3} = 17$$
>
> Observe que a previs√£o agregada est√° muito pr√≥xima da previs√£o que seria obtida usando os par√¢metros originais ($\beta_0 = 2$ e $\beta_1 = 3$) no mesmo ponto x=5, que √© $2 + 3 * 5 = 17$. Isto ilustra o fato de que o bagging tem pouco efeito em modelos lineares, pois as estimativas s√£o muito parecidas nas amostras bootstrap.

**Corol√°rio 2:** Como consequ√™ncia do Lemma 2, o bagging aplicado a uma regress√£o linear, onde as predi√ß√µes s√£o agregadas utilizando a m√©dia, n√£o apresenta ganho na vari√¢ncia, pois o m√©todo √© est√°vel e as predi√ß√µes das m√∫ltiplas inst√¢ncias se aproximam da predi√ß√£o no dataset original. [^8.7].

√â crucial entender que a regress√£o linear √©, por natureza, um modelo est√°vel. Sua estimativa n√£o √© drasticamente alterada por pequenas perturba√ß√µes nos dados de treinamento, como aquelas geradas pelo bootstrap. Assim, a agrega√ß√£o por bagging pouco afeta a predi√ß√£o. Por outro lado, modelos altamente n√£o-lineares e inst√°veis, como as √°rvores de decis√£o, se beneficiam grandemente do bagging.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization with Bagging"
        direction TB
        A["Bootstrap Sample"] --> B["Feature Selection/Regularization (Lasso)"]
        B --> C["Trained Model with sparse coefficients"]
        C --> D["Aggregate Model Coefficients"]
        D --> E["Final Regularized Model (Reduced Variance)"]
    end
```

O bagging pode ser combinado com m√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o para melhorar ainda mais o desempenho do modelo, especialmente em cen√°rios com alta dimensionalidade e com a presen√ßa de *outliers* [^8.7]. Ao aplicar bagging, podemos incluir dentro do *pipeline* de treinamento de cada modelo uma etapa de sele√ß√£o de vari√°veis, como por exemplo *feature selection* atrav√©s de *Lasso*, ou de regulariza√ß√£o, como *Ridge Regression*, para aumentar ainda mais a estabilidade dos modelos individuais. A estabilidade dos modelos individuais garante que, ao serem agregados pelo bagging, a vari√¢ncia seja reduzida.

**Lemma 3:** Suponha que em cada amostra bootstrap, apliquemos a regress√£o log√≠stica com regulariza√ß√£o L1 (*Lasso*). Seja $\hat{\beta_b}$ o vetor de par√¢metros estimados na amostra *b*. O uso da regulariza√ß√£o L1 tende a gerar vetores $\hat{\beta_b}$ com muitos componentes iguais a zero, ou seja, modelos esparsos, e com alta diversidade. Ap√≥s o bagging, com $B$ amostras bootstraps, a agrega√ß√£o dos $\hat{\beta_b}$ gera uma estimativa final com baixa vari√¢ncia e capaz de realizar sele√ß√£o de vari√°veis.
$$\hat{\beta} = \frac{1}{B} \sum_{b=1}^{B} \hat{\beta_b}$$

**Prova do Lemma 3:** A regulariza√ß√£o L1 induz esparsidade ao adicionar uma penalidade proporcional √† soma dos valores absolutos dos coeficientes, isto √©, $\|\beta\|_1$, √† fun√ß√£o de custo da regress√£o log√≠stica. O efeito da penalidade √© o de encolher coeficientes com pouco efeito preditivo para 0, gerando um modelo com alta diversidade, o que beneficia a agrega√ß√£o pelo bagging. $\blacksquare$

> üí° **Exemplo Num√©rico (Lasso com Bagging):** Imagine um problema de classifica√ß√£o com muitas vari√°veis (alta dimensionalidade). Usamos regress√£o log√≠stica com regulariza√ß√£o L1 (Lasso) em combina√ß√£o com bagging. Suponha que, ap√≥s o treinamento em tr√™s amostras bootstrap, obtemos os seguintes vetores de coeficientes (ap√≥s regulariza√ß√£o):
>
> *   $\hat{\beta_1} = [0.5, 0, 0.2, 0, -0.1, 0]$
> *   $\hat{\beta_2} = [0.6, 0, 0, 0.1, -0.2, 0]$
> *   $\hat{\beta_3} = [0.5, 0, 0.1, 0, -0.1, 0.1]$
>
> Observe que muitos coeficientes s√£o zero (esparsidade). Ao agregar esses coeficientes usando bagging (m√©dia), obtemos:
>
> $$\hat{\beta} = \frac{1}{3} [ (0.5+0.6+0.5), (0+0+0), (0.2+0+0.1), (0+0.1+0), (-0.1-0.2-0.1), (0+0+0.1)]$$
> $$\hat{\beta} = [0.53, 0, 0.1, 0.03, -0.13, 0.03]$$
>
> O vetor final tem coeficientes menores, mas ainda mant√©m as vari√°veis mais importantes. O bagging, neste caso, reduz a vari√¢ncia da estimativa dos coeficientes.
>
> ```python
> import numpy as np
>
> # Coeficientes dos modelos Lasso nas amostras bootstrap
> beta1 = np.array([0.5, 0, 0.2, 0, -0.1, 0])
> beta2 = np.array([0.6, 0, 0, 0.1, -0.2, 0])
> beta3 = np.array([0.5, 0, 0.1, 0, -0.1, 0.1])
>
> # Agregando os coeficientes
> beta_bagged = np.mean([beta1, beta2, beta3], axis=0)
>
> print(f"Coeficientes agregados: {beta_bagged}")
> ```

**Corol√°rio 3:** A combina√ß√£o de m√©todos de sele√ß√£o de vari√°veis como *Lasso* com o *bagging* leva a modelos que s√£o simultaneamente robustos (baixa vari√¢ncia) e mais interpret√°veis (esparsos), al√©m de apresentar grande capacidade preditiva [^8.7]. Isso √© especialmente √∫til em problemas com alta dimensionalidade, onde a sele√ß√£o de vari√°veis pode melhorar a capacidade preditiva e a interpretabilidade do modelo.

> ‚ö†Ô∏è **Ponto Crucial**: A escolha da t√©cnica de regulariza√ß√£o (L1, L2, ou Elastic Net) no contexto do bagging deve ser feita com base nas caracter√≠sticas do problema. A penaliza√ß√£o L1 √© mais adequada para a sele√ß√£o de vari√°veis, enquanto a penaliza√ß√£o L2 √© melhor para reduzir os pesos.
>
### Separating Hyperplanes e Perceptrons
O bagging n√£o √© diretamente aplic√°vel a modelos como *separating hyperplanes* e *perceptrons* da mesma maneira que √© para √°rvores de decis√£o e regress√µes. A quest√£o central √© que esses modelos t√™m baixa vari√¢ncia, pois a solu√ß√£o √≥tima √© usualmente √∫nica [^8.7]. Em geral, o bagging aplicado a modelos est√°veis como *separating hyperplanes* e *perceptrons* ter√° pouco ou nenhum efeito, pois a estabilidade intr√≠nseca desses m√©todos leva a pouca diversidade entre os modelos individuais.

### Pergunta Te√≥rica Avan√ßada: Qual o efeito de aumentar o n√∫mero de amostras bootstrap em bagging, tanto em termos de vari√¢ncia quanto de vi√©s?
**Resposta:**
O efeito de aumentar o n√∫mero de amostras bootstrap, *B*, em bagging, √© principalmente sobre a vari√¢ncia [^8.7]. O vi√©s, por outro lado, √© afetado de forma menos significativa. Como visto, a estimativa do bagging √© dada por:
$$f_{bag}(x) = \frac{1}{B}\sum_{b=1}^{B} f_b^*(x)$$
onde $f_b^*(x)$ √© a previs√£o do modelo treinado em cada uma das $B$ amostras bootstrap. Em teoria, quando $B \rightarrow \infty$, a vari√¢ncia da estimativa *bagged* tende a zero (a converg√™ncia √© para a m√©dia populacional) [^8.7], assumindo que os modelos treinados nas amostras bootstrap sejam independentes (o que n√£o √© o caso, mas a correla√ß√£o √© pequena, na pr√°tica).
$$Var[f_{bag}(x)] = Var[\frac{1}{B}\sum_{b=1}^{B} f_b^*(x)] = \frac{1}{B^2} \sum_{b=1}^B Var[f_b^*(x)] \approx \frac{Var[f^*(x)]}{B}$$
Em termos de vi√©s, o bagging n√£o altera significativamente o vi√©s dos modelos individuais. Como cada $f_b^*(x)$ √© uma estimativa do modelo base, e o bagging faz uma m√©dia dessas estimativas, o vi√©s final da estimativa bagged ser√°, aproximadamente, o mesmo da estimativa do modelo base.
$$Bias[f_{bag}(x)] = E[f_{bag}(x) - f(x)] = E[\frac{1}{B}\sum_{b=1}^B f_b^*(x) - f(x)] = \frac{1}{B}\sum_{b=1}^B E[f_b^*(x) - f(x)] \approx E[f^*(x) - f(x)]$$
Portanto, aumentar *B* reduz a vari√¢ncia, mas n√£o afeta muito o vi√©s. Isso √© fundamental porque a redu√ß√£o da vari√¢ncia tende a levar a uma maior capacidade de generaliza√ß√£o do modelo.

```mermaid
graph LR
    subgraph "Impact of B on Variance and Bias"
        direction TB
        A["Variance: Var(f_bag(x)) ‚âà Var(f*(x))/B"]
        B["Bias: Bias(f_bag(x)) ‚âà Bias(f*(x))"]
        C["Increasing B --> Decreased Variance"]
        D["Increasing B --> Minimal Bias Change"]
        A --> C
        B --> D
    end
```

> üí° **Exemplo Num√©rico:** Vamos simular um exemplo com √°rvores de decis√£o. Consideremos que a vari√¢ncia da previs√£o de uma √°rvore de decis√£o individual seja  $Var[f^*(x)] = 1.5$. Se usarmos bagging com B=10 √°rvores, a vari√¢ncia da previs√£o agregada ser√° aproximadamente:
>
> $$Var[f_{bag}(x)] \approx \frac{1.5}{10} = 0.15$$
>
> Se aumentarmos para B=100 √°rvores:
>
>  $$Var[f_{bag}(x)] \approx \frac{1.5}{100} = 0.015$$
>
> Isso demonstra como o aumento do n√∫mero de amostras bootstrap reduz a vari√¢ncia da estimativa do bagging. O vi√©s, por outro lado, permanece aproximadamente o mesmo, j√° que a m√©dia dos modelos individuais tende a ter o mesmo vi√©s do modelo individual.

### Conclus√£o

O bagging √© uma t√©cnica eficaz para reduzir a vari√¢ncia de modelos inst√°veis, como √°rvores de decis√£o, e pode ser combinado com m√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o para obter modelos ainda mais robustos e precisos [^8.7]. Embora o bagging n√£o altere significativamente o vi√©s do modelo, a redu√ß√£o da vari√¢ncia leva a uma maior capacidade de generaliza√ß√£o, e o conceito de agrega√ß√£o de previs√µes pode ser estendido para modelos mais complexos com *boosting* e *stacking*.

### Footnotes

[^8.1]: "In this chapter we provide a general exposition of the maximum likelihood approach, as well as the Bayesian method for inference." *(Trecho de "Model Inference and Averaging")*
[^8.2]: "The bootstrap method provides a direct computational way of assessing uncertainty, by sampling from the training data." *(Trecho de "Model Inference and Averaging")*
[^8.2.1]:  "Suppose we divide to fit a cubic spline to the data, with three knots placed at the quartiles of the X values." *(Trecho de "Model Inference and Averaging")*
[^8.7]: "Earlier we introduced the bootstrap as a way of assessing the accuracy of a parameter estimate or a prediction. Here we show how to use the bootstrap to improve the estimate or prediction itself." *(Trecho de "Model Inference and Averaging")*

<!-- END DOCUMENT -->
