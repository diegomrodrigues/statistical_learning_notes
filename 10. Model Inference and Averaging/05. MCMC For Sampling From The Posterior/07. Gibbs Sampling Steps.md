## Gibbs Sampling: A Deep Dive into Bayesian Computation
```mermaid
graph TD
    subgraph "Gibbs Sampling Process"
    direction TB
        A["Start: Initial Parameters"]
        B["Sample Î¸_1 | Î¸_{-1}, Z"]
        C["Sample Î¸_2 | Î¸_1, Î¸_{-2}, Z"]
        D["Sample ... Î¸_k | Î¸_{-k}, Z"]
        E["Iterate Samples (Markov Chain)"]
        F["Converged Samples: Approximation of P(Î¸|Z)"]
        A --> B
        B --> C
        C --> D
        D --> E
        E --> F
    end
```

### IntroduÃ§Ã£o
O **Gibbs Sampling**, um mÃ©todo de **Markov Chain Monte Carlo (MCMC)**, surge como uma ferramenta poderosa e versÃ¡til no contexto da inferÃªncia Bayesiana [^8.6]. Diferente de mÃ©todos de otimizaÃ§Ã£o que buscam um Ãºnico ponto de mÃ¡ximo (como o EM Algorithm), o Gibbs Sampling visa gerar amostras da distribuiÃ§Ã£o posterior, permitindo uma anÃ¡lise mais completa da incerteza associada aos parÃ¢metros do modelo. Este capÃ­tulo explorarÃ¡ em detalhes o mecanismo do Gibbs Sampling, suas conexÃµes com outros mÃ©todos computacionais, e sua relevÃ¢ncia na obtenÃ§Ã£o de inferÃªncias Bayesianas robustas e confiÃ¡veis. O Gibbs Sampling se destaca por sua relativa simplicidade de implementaÃ§Ã£o e por sua aplicabilidade a uma vasta gama de problemas, onde a obtenÃ§Ã£o direta da distribuiÃ§Ã£o posterior Ã© impraticÃ¡vel ou impossÃ­vel.

### Conceitos Fundamentais
**Conceito 1:** *O problema da amostragem conjunta*. Em muitos problemas Bayesianos, estamos interessados em obter amostras da distribuiÃ§Ã£o conjunta posterior, $Pr(\theta|Z)$, onde $\theta$ representa os parÃ¢metros do modelo e $Z$ os dados observados [^8.6]. Contudo, a obtenÃ§Ã£o direta dessas amostras Ã© muitas vezes complexa, pois a distribuiÃ§Ã£o conjunta pode nÃ£o ter uma forma analÃ­tica conhecida ou ser de alta dimensionalidade.

**Lemma 1:** *DecomposiÃ§Ã£o da distribuiÃ§Ã£o conjunta em distribuiÃ§Ãµes condicionais*. O Gibbs Sampling explora a ideia de que, se Ã© difÃ­cil amostrar da distribuiÃ§Ã£o conjunta diretamente, Ã© possÃ­vel, em muitos casos, amostrar de distribuiÃ§Ãµes condicionais, $Pr(\theta_k|\theta_{-k}, Z)$, onde $\theta_k$ Ã© um componente do vetor de parÃ¢metros $\theta$ e $\theta_{-k}$ representa todos os outros componentes [^8.6].

**DemonstraÃ§Ã£o:** A distribuiÃ§Ã£o conjunta $Pr(\theta|Z)$ pode ser escrita como o produto de distribuiÃ§Ãµes condicionais. Para um vetor de parÃ¢metros $\theta$ com $K$ componentes $\theta_1, \ldots, \theta_K$, podemos escrever:
$$ Pr(\theta | Z) = Pr(\theta_1 | \theta_2, \ldots, \theta_K, Z) \cdot Pr(\theta_2 | \theta_3, \ldots, \theta_K, Z) \cdot \ldots \cdot Pr(\theta_K | Z) $$
A amostragem dessas distribuiÃ§Ãµes condicionais, em vez da conjunta, Ã© o cerne do Gibbs Sampling. $\blacksquare$

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Suponha que temos dois parÃ¢metros, $\theta_1$ e $\theta_2$, e queremos amostrar da distribuiÃ§Ã£o conjunta $Pr(\theta_1, \theta_2 | Z)$.  Em vez de amostrar diretamente dessa distribuiÃ§Ã£o, podemos amostrar alternadamente das condicionais:  $Pr(\theta_1 | \theta_2, Z)$ e $Pr(\theta_2 | \theta_1, Z)$. Se, por exemplo,  $Pr(\theta_1 | \theta_2, Z)$ Ã© uma distribuiÃ§Ã£o normal com mÃ©dia $\mu = 0.8\theta_2$ e desvio padrÃ£o $\sigma = 0.5$, e $Pr(\theta_2 | \theta_1, Z)$ Ã© uma distribuiÃ§Ã£o gama com parÃ¢metros de forma $k = 2$ e escala $\lambda = 1/\theta_1$, podemos gerar uma cadeia de amostras da seguinte forma:
>
> 1.  Inicializamos com um valor arbitrÃ¡rio, por exemplo, $\theta_1^{(0)} = 1$ e $\theta_2^{(0)} = 0.5$.
> 2.  **IteraÃ§Ã£o 1:**
>     *   Amostramos $\theta_1^{(1)}$ de  $Pr(\theta_1 | \theta_2^{(0)}, Z) \sim \mathcal{N}(0.8 \cdot 0.5, 0.5^2)$, obtendo, digamos, $\theta_1^{(1)} = 0.6$.
>     *   Amostramos $\theta_2^{(1)}$ de  $Pr(\theta_2 | \theta_1^{(1)}, Z) \sim \text{Gamma}(2, 1/0.6)$, obtendo, digamos, $\theta_2^{(1)} = 0.8$.
> 3.  **IteraÃ§Ã£o 2:**
>    *   Amostramos $\theta_1^{(2)}$ de  $Pr(\theta_1 | \theta_2^{(1)}, Z) \sim \mathcal{N}(0.8 \cdot 0.8, 0.5^2)$, obtendo, digamos, $\theta_1^{(2)} = 0.9$.
>    *   Amostramos $\theta_2^{(2)}$ de  $Pr(\theta_2 | \theta_1^{(2)}, Z) \sim \text{Gamma}(2, 1/0.9)$, obtendo, digamos, $\theta_2^{(2)} = 0.7$.
>
>  Continuamos este processo iterativamente. Cada amostra $(\theta_1^{(t)}, \theta_2^{(t)})$ constitui um passo na cadeia de Markov. ApÃ³s um nÃºmero suficiente de iteraÃ§Ãµes, as amostras convergem para a distribuiÃ§Ã£o conjunta alvo $Pr(\theta_1, \theta_2 | Z)$.

```mermaid
graph TD
    subgraph "Joint to Conditional Sampling"
        direction TB
        A["Joint Distribution: P(Î¸|Z)"]
        B["Conditional Distribution 1: P(Î¸_1 | Î¸_2, ..., Î¸_K, Z)"]
        C["Conditional Distribution 2: P(Î¸_2 | Î¸_3, ..., Î¸_K, Z)"]
        D["Conditional Distribution K: P(Î¸_K | Z)"]
        A --> B
        A --> C
        A --> D
        B --> E["Iterative Sampling"]
        C --> E
        D --> E
         E --> F["Markov Chain Convergence"]
    end
```

**Conceito 2:** *Amostragem Iterativa e Cadeias de Markov*. O Gibbs Sampling Ã© um processo iterativo [^8.6]. Em cada iteraÃ§Ã£o $t$, amostramos cada componente $\theta_k$ de seu posterior condicional, usando os valores mais recentes dos outros componentes ($\theta_{-k}$) obtidos nas iteraÃ§Ãµes anteriores. Desta forma, gera-se uma sequÃªncia de amostras $(\theta^{(1)}, \theta^{(2)}, \ldots)$, que formam uma Cadeia de Markov.

**CorolÃ¡rio 1:** *ConvergÃªncia para a distribuiÃ§Ã£o alvo*. Sob condiÃ§Ãµes de regularidade, a cadeia de Markov gerada pelo Gibbs Sampling converge para uma distribuiÃ§Ã£o estacionÃ¡ria que Ã© igual Ã  distribuiÃ§Ã£o posterior $Pr(\theta|Z)$. Isso significa que, apÃ³s um nÃºmero suficiente de iteraÃ§Ãµes, as amostras geradas se tornam amostras da distribuiÃ§Ã£o posterior, e podemos usÃ¡-las para fazer inferÃªncias sobre os parÃ¢metros do modelo.

**Conceito 3:** *RelaÃ§Ã£o com o EM Algorithm*. O Gibbs Sampling tem uma conexÃ£o interessante com o EM Algorithm [^8.6]. No EM Algorithm, o passo de Expectation (E) calcula a esperanÃ§a da log-verossimilhanÃ§a completa (com dados latentes), e o passo de MaximizaÃ§Ã£o (M) maximiza essa esperanÃ§a em relaÃ§Ã£o aos parÃ¢metros do modelo. No Gibbs Sampling, em vez de maximizar, amostramos dos condicionais posteriores, que tambÃ©m consideram os dados latentes como variÃ¡veis a serem amostradas.

```mermaid
graph LR
    subgraph "EM Algorithm vs. Gibbs Sampling"
        direction LR
        A["EM Algorithm: Expectation Step"] --> B["Compute Expected Log-Likelihood"]
        B --> C["EM Algorithm: Maximization Step"]
        C --> D["Maximize Parameters"]
        E["Gibbs Sampling"] --> F["Sample from Conditionals P(Î¸_k|Î¸_{-k},Z)"]
        A --> G["Latent Variables Considered"]
        F --> G
        D --> H["Point Estimate"]
        F --> I["Posterior Samples"]
         G --> J["Iterative process"]
         J --> H
         J --> I
    end
```

### RegressÃ£o Linear e MÃ­nimos Quadrados para ClassificaÃ§Ã£o
```mermaid
graph TB
    subgraph "Gibbs Sampling for Linear Regression"
        direction TB
        A["Data: (X, y)"]
        B["Prior for Î²: P(Î²)"]
        C["Prior for ÏƒÂ²: P(ÏƒÂ²)"]
        D["Conditional Posterior: P(Î² | y, X, ÏƒÂ²)"]
        E["Conditional Posterior: P(ÏƒÂ² | y, X, Î²)"]
        F["Sample Î² from P(Î² | y, X, ÏƒÂ²)"]
        G["Sample ÏƒÂ² from P(ÏƒÂ² | y, X, Î²)"]
        H["Iterate Samples"]
        I["Posterior samples of Î², ÏƒÂ²"]
        A --> D
        A --> E
        B --> D
        C --> E
        D --> F
        E --> G
        F --> H
        G --> H
         H --> I
    end
```

O Gibbs Sampling pode ser aplicado a diversos modelos Bayesianos, incluindo a regressÃ£o linear. Suponha que tenhamos um modelo de regressÃ£o linear, $y = X\beta + \epsilon$, com $\epsilon \sim \mathcal{N}(0, \sigma^2)$. No contexto Bayesiano, definimos *priors* para os parÃ¢metros $\beta$ e $\sigma^2$. Com isso, o objetivo Ã© amostrar da distribuiÃ§Ã£o posterior $Pr(\beta, \sigma^2|y, X)$.

O processo do Gibbs Sampling para este modelo envolve os seguintes passos:

1.  **InicializaÃ§Ã£o:** ComeÃ§amos com valores iniciais para $\beta$ e $\sigma^2$.
2.  **Amostragem de $\beta$:** Dado os dados $y, X$ e o valor atual de $\sigma^2$, amostramos de sua distribuiÃ§Ã£o condicional posterior. Sob priors normais conjugados para $\beta$, a distribuiÃ§Ã£o condicional posterior de $\beta$ Ã© tambÃ©m normal, de modo que a amostragem Ã© fÃ¡cil:
    $$ Pr(\beta|y, X, \sigma^2) \sim \mathcal{N}(m, V) $$
     onde $m$ e $V$ sÃ£o parÃ¢metros que dependem dos *priors* e dos dados [^8.6].
3.  **Amostragem de $\sigma^2$:** Dado os dados e o valor atual de $\beta$, amostramos de sua distribuiÃ§Ã£o condicional posterior. Sob um prior conjugado inverso-gama para $\sigma^2$, sua distribuiÃ§Ã£o condicional posterior tambÃ©m Ã© inverso-gama, facilitando a amostragem:
    $$ Pr(\sigma^2|y, X, \beta) \sim \text{Inv-Gamma}(a,b) $$
     onde $a$ e $b$ sÃ£o parÃ¢metros que dependem dos *priors* e dos dados [^8.6].
4.  **IteraÃ§Ã£o:** Repetimos os passos 2 e 3 por um nÃºmero suficiente de iteraÃ§Ãµes, atÃ© que a cadeia de Markov tenha convergido para a distribuiÃ§Ã£o estacionÃ¡ria.

**Lemma 2:** *ConjugaÃ§Ã£o em modelos lineares*. O uso de *priors conjugados* (normal para $\beta$ e inverso-gama para $\sigma^2$) simplifica enormemente o processo de amostragem no Gibbs Sampling, pois garantem que as distribuiÃ§Ãµes condicionais posteriores sejam da mesma famÃ­lia do *prior*. Isso facilita a obtenÃ§Ã£o das amostras.

**CorolÃ¡rio 2:** *InferÃªncia Bayesiana*. ApÃ³s a convergÃªncia, as amostras geradas pelo Gibbs Sampling podem ser usadas para fazer inferÃªncias Bayesianas sobre os parÃ¢metros do modelo, como calcular mÃ©dias posteriores, intervalos de confianÃ§a, e fazer prediÃ§Ãµes.

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Considere um modelo de regressÃ£o linear com um preditor, onde $y = X\beta + \epsilon$, e $\epsilon \sim \mathcal{N}(0, \sigma^2)$. Suponha que tenhamos os seguintes dados:
> ```python
> import numpy as np
> import scipy.stats as st
>
> X = np.array([[1], [2], [3], [4], [5]])
> y = np.array([2, 4, 5, 4, 5])
> ```
>
> Assumimos *priors* conjugados:
> *   $\beta \sim \mathcal{N}(0, 10)$ (prior normal com mÃ©dia 0 e variÃ¢ncia 10)
> *   $\sigma^2 \sim \text{Inv-Gamma}(2, 2)$ (prior inverso-gama com parÃ¢metros $a=2$ e $b=2$)
>
>  A distribuiÃ§Ã£o condicional posterior para $\beta$ Ã© $\mathcal{N}(m, V)$, onde
>
>  $V = (X^T X / \sigma^2 + 1/10)^{-1}$ e $m = V(X^T y / \sigma^2)$
>
>  A distribuiÃ§Ã£o condicional posterior para $\sigma^2$ Ã©  $\text{Inv-Gamma}(a', b')$, onde:
>
>   $a' = a + n/2$, com $n$ sendo o nÃºmero de amostras.
>
>   $b' = b + 0.5 \sum_i (y_i - X_i\beta)^2$
>
>  Inicializamos o Gibbs Sampling com $\beta^{(0)} = 0.5$ e $\sigma^{2(0)} = 1$.
>
>  **IteraÃ§Ã£o 1:**
>  1. Amostrando $\beta^{(1)}$:
>   * Calculamos $V = ((X.T @ X) / \sigma^{2(0)} + 1/10)^{-1} = ((55)/1 + 0.1)^{-1} = 0.018$
>   * Calculamos $m = V(X.T @ y / \sigma^{2(0)}) =  0.018 * 47 / 1 = 0.846$.
>    *   Amostramos $\beta^{(1)}$ de  $\mathcal{N}(0.846, 0.018)$, obtendo, digamos, $\beta^{(1)} = 0.9$.
> 2. Amostrando $\sigma^{2(1)}$:
>    *   Calculamos $a' = 2 + 5/2 = 4.5$.
>    *   Calculamos $b' = 2 + 0.5 * \sum_i (y_i - X_i\beta^{(1)})^2 = 2 + 0.5 * ( (2-0.9)^2 + (4-1.8)^2 + (5-2.7)^2 + (4-3.6)^2 + (5-4.5)^2) = 2 + 0.5 * 6.24 = 5.12$
>    *  Amostramos $\sigma^{2(1)}$ de  $\text{Inv-Gamma}(4.5, 5.12)$, obtendo, digamos, $\sigma^{2(1)} = 1.2$.
>
> Repetimos o processo para vÃ¡rias iteraÃ§Ãµes. As amostras obtidas de $\beta$ e $\sigma^2$ sÃ£o usadas para calcular suas mÃ©dias posteriores e intervalos de confianÃ§a.
>
> ```python
> def gibbs_sampling_linear_regression(X, y, iterations=1000, initial_beta=0.5, initial_sigma2=1, prior_beta_mean=0, prior_beta_var=10, prior_sigma2_a=2, prior_sigma2_b=2):
>    n = len(y)
>    beta_samples = np.zeros(iterations)
>    sigma2_samples = np.zeros(iterations)
>
>    beta_current = initial_beta
>    sigma2_current = initial_sigma2
>
>    for i in range(iterations):
>        # Amostra beta
>        V = np.linalg.inv((X.T @ X) / sigma2_current + 1/prior_beta_var)
>        m = V @ (X.T @ y / sigma2_current)
>        beta_current = np.random.normal(m, np.sqrt(V))
>
>        # Amostra sigma2
>        a_prime = prior_sigma2_a + n/2
>        b_prime = prior_sigma2_b + 0.5 * np.sum((y - X @ beta_current)**2)
>        sigma2_current = 1/np.random.gamma(a_prime, 1/b_prime)
>
>        beta_samples[i] = beta_current
>        sigma2_samples[i] = sigma2_current
>    return beta_samples, sigma2_samples
>
> beta_samples, sigma2_samples = gibbs_sampling_linear_regression(X, y)
>
> print(f"Posterior mean of beta: {np.mean(beta_samples)}")
> print(f"Posterior mean of sigma^2: {np.mean(sigma2_samples)}")
> ```

### MÃ©todos de SeleÃ§Ã£o de VariÃ¡veis e RegularizaÃ§Ã£o em ClassificaÃ§Ã£o
```mermaid
graph TB
    subgraph "Variable Selection with Spike-and-Slab Prior"
        direction TB
        A["Data: (X, y)"]
        B["Prior for Î²_k: P(Î²_k | Î³_k)"]
        C["Prior for Î³_k: P(Î³_k)"]
        D["Prior for ÏƒÂ²: P(ÏƒÂ²)"]
         E["Conditional Posterior: P(Î³_k | Î², ÏƒÂ², X, y)"]
        F["Conditional Posterior: P(Î² | Î³, ÏƒÂ², X, y)"]
        G["Conditional Posterior: P(ÏƒÂ² | Î², Î³, X, y)"]
        H["Sample Î³_k"]
        I["Sample Î²"]
        J["Sample ÏƒÂ²"]
        K["Iterate Samples"]
        L["Posterior samples of Î², ÏƒÂ², Î³"]
        A --> E
        A --> F
        A --> G
        B --> F
        C --> E
        D --> G
        E --> H
        F --> I
        G --> J
        H --> K
        I --> K
        J --> K
         K --> L
    end
```

O Gibbs Sampling pode ser adaptado para lidar com a seleÃ§Ã£o de variÃ¡veis no contexto de modelos Bayesianos. Isso Ã© feito usando tÃ©cnicas de *spike-and-slab prior*, onde um indicador binÃ¡rio determina se uma variÃ¡vel estÃ¡ ou nÃ£o incluÃ­da no modelo.

1.  **Modelo base:** Considere um modelo linear, $y = X\beta + \epsilon$, com $\epsilon \sim \mathcal{N}(0, \sigma^2)$.
2.  **Prior spike-and-slab:** Para cada componente $\beta_k$ do vetor de parÃ¢metros $\beta$, introduzimos um indicador binÃ¡rio $\gamma_k$, tal que:

    -   Se $\gamma_k = 1$, entÃ£o $\beta_k \sim \mathcal{N}(0, \tau^2)$ (o "slab"), onde $\tau^2$ Ã© uma variÃ¢ncia.
    -   Se $\gamma_k = 0$, entÃ£o $\beta_k = 0$ (o "spike").
    -   Adotamos um *prior* para $\gamma_k$, por exemplo, $Pr(\gamma_k = 1) = \pi$.
3.  **Gibbs sampling:** O algoritmo agora envolve a amostragem iterativa de:
    -   Os indicadores de inclusÃ£o $\gamma_k$, condicional a $\beta$ e $\sigma^2$.
    -   Os coeficientes $\beta_k$, condicional aos indicadores $\gamma$ e $\sigma^2$ .
    -   A variÃ¢ncia $\sigma^2$, condicional a $\beta$ e aos dados.

**Lemma 3:** *DistribuiÃ§Ã£o condicional para $\gamma_k$*. A distribuiÃ§Ã£o condicional para $\gamma_k$ Ã© de Bernoulli, com parÃ¢metro que depende de $\beta_k$, dos dados e do *prior* [^8.6]. A amostragem de $\gamma_k$ decide se a variÃ¡vel estÃ¡ incluÃ­da ou nÃ£o no modelo na iteraÃ§Ã£o atual.

**Prova do Lemma 3:** A probabilidade condicional de inclusÃ£o $\gamma_k$, dado os dados e os demais parÃ¢metros, Ã© dada por:
$$Pr(\gamma_k=1| \beta, \sigma^2, X, y) = \frac{Pr(y|X,\beta, \sigma^2, \gamma_k=1)Pr(\beta_k|\gamma_k=1)Pr(\gamma_k=1)}{Pr(y|X,\beta, \sigma^2,\gamma_k=1)Pr(\beta_k|\gamma_k=1)Pr(\gamma_k=1) + Pr(y|X,\beta, \sigma^2,\gamma_k=0)Pr(\beta_k|\gamma_k=0)Pr(\gamma_k=0)}$$
Os termos de verossimilhanÃ§a $Pr(y|X,\beta, \sigma^2, \gamma_k)$, as *priors* de $\beta_k$ (normal ou zero), e as *priors* de $\gamma_k$ (Bernoulli) permitem calcular essa probabilidade. $\blacksquare$

**CorolÃ¡rio 3:** *InferÃªncia sobre a seleÃ§Ã£o de variÃ¡veis*. As amostras geradas pelos indicadores $\gamma_k$ podem ser utilizadas para avaliar a probabilidade posterior de cada variÃ¡vel estar incluÃ­da no modelo. VariÃ¡veis com alta probabilidade posterior tÃªm maior probabilidade de estarem de fato relacionadas Ã  resposta.

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Suponha que temos um modelo com dois preditores, $X_1$ e $X_2$, e queremos usar o *spike-and-slab prior* para selecionar variÃ¡veis.
>  Definimos que $y = X_1\beta_1 + X_2\beta_2 + \epsilon$, com $\epsilon \sim \mathcal{N}(0, \sigma^2)$.
>  Introduzimos os indicadores $\gamma_1$ e $\gamma_2$ para $X_1$ e $X_2$, respectivamente.
>  Vamos usar um prior $Pr(\gamma_k = 1) = 0.5$.
>  Assumimos que $\tau^2 = 1$.
>  Usando os mesmos dados anteriores e adicionando uma coluna para $X_2$:
> ```python
> import numpy as np
> import scipy.stats as st
>
> X = np.array([[1, 2], [2, 1], [3, 3], [4, 2], [5, 4]])
> y = np.array([2, 4, 5, 4, 5])
> ```
>
>  Inicializamos o Gibbs Sampling com $\beta^{(0)} = [0.5, 0.5]$, $\sigma^{2(0)} = 1$ e $\gamma^{(0)} = [1,1]$.
>
>  **IteraÃ§Ã£o 1:**
>  1.  Amostrando $\gamma_1^{(1)}$ e $\gamma_2^{(1)}$:
>    *  Para $\gamma_1$, calculamos a probabilidade de $\gamma_1 = 1$ usando os valores atuais de $\beta_1$, $\sigma^2$ e os dados, e amostramos de uma distribuiÃ§Ã£o de Bernoulli. Suponha que amostramos $\gamma_1^{(1)} = 1$.
>    *   Fazemos o mesmo para $\gamma_2$, calculando a probabilidade de $\gamma_2 = 1$, e amostramos de uma distribuiÃ§Ã£o de Bernoulli. Suponha que amostramos $\gamma_2^{(1)} = 0$.
> 2. Amostrando $\beta^{(1)}$:
>    * Se $\gamma_1 = 1$, amostramos $\beta_1$ de sua condicional posterior (normal), usando os dados e $\sigma^2$. Se $\gamma_1=0$, entÃ£o $\beta_1=0$. Suponha que amostramos $\beta_1^{(1)} = 0.8$.
>   * Se $\gamma_2 = 1$, amostramos $\beta_2$ de sua condicional posterior (normal), usando os dados e $\sigma^2$. Se $\gamma_2=0$, entÃ£o $\beta_2=0$. Suponha que amostramos $\beta_2^{(1)} = 0$.
>
> 3. Amostrando $\sigma^{2(1)}$:
>    * Amostramos $\sigma^{2(1)}$ de sua condicional posterior (inversa-gama), usando os dados e $\beta$. Suponha que amostramos $\sigma^{2(1)} = 1.1$.
>
> ApÃ³s vÃ¡rias iteraÃ§Ãµes, as amostras de $\gamma_1$ e $\gamma_2$ sÃ£o usadas para calcular as probabilidades posteriores de cada variÃ¡vel ser incluÃ­da no modelo.
> ```python
> def gibbs_sampling_variable_selection(X, y, iterations=1000, prior_gamma_prob=0.5, tau2=1, initial_beta=None, initial_sigma2=1, prior_sigma2_a=2, prior_sigma2_b=2):
>    n, p = X.shape
>    beta_samples = np.zeros((iterations, p))
>    sigma2_samples = np.zeros(iterations)
>    gamma_samples = np.zeros((iterations, p))
>
>    if initial_beta is None:
>        initial_beta = np.zeros(p)
>
>    beta_current = initial_beta
>    sigma2_current = initial_sigma2
>    gamma_current = np.ones(p)
>
>    for i in range(iterations):
>        # Amostra gammas
>        for k in range(p):
>           X_k = X[:, k].reshape(-1, 1) # Transforma a coluna k de X em uma matriz coluna
>           if gamma_current[k] == 1:
>              likelihood_gamma1 = st.norm.pdf(y, X @ beta_current, np.sqrt(sigma2_current))
>           else:
>              likelihood_gamma1 = 1 # Likelihood is 1 if gamma_k = 0
>
>           likelihood_gamma0 = st.norm.pdf(y, X @ (beta_current * (1 - np.eye(p)[k])), np.sqrt(sigma2_current)) # Define beta_k as 0 if gamma_k=0
>
>           numerator = np.prod(likelihood_gamma1) * prior_gamma_prob
>           denominator = numerator + np.prod(likelihood_gamma0) * (1 - prior_gamma_prob)
>           prob_gamma1 = numerator / denominator
>           gamma_current[k] = np.random.binomial(1, prob_gamma1)
>
>        # Amostra beta
>        for k in range(p):
>            if gamma_current[k] == 1:
>              X_k = X[:, k].reshape(-1, 1)
>              V = np.linalg.inv(X_k.T @ X_k / sigma2_current + 1/tau2)
>              m = V @ (X_k.T @ (y - X @ (beta_current * (1 - np.eye(p)[k] )) )/ sigma2_current)
>              beta_current[k] = np.random.normal(m, np.sqrt(V))
>            else:
>                beta_current[k] = 0
>
>
>        # Amostra sigma2
>        a_prime = prior_sigma2_a + n/2
>        b_prime = prior_sigma2_b + 0.5 * np.sum((y - X @ beta_current)**2)
>        sigma2_current = 1/np.random.gamma(a_prime, 1/b_prime)
>
>        beta_samples[i] = beta_current
>        sigma2_samples[i] = sigma2_current
>        gamma_samples[i] = gamma_current
>    return beta_samples, sigma2_samples, gamma_samples
>
> beta_samples, sigma2_samples, gamma_samples = gibbs_sampling_variable_selection(X,y)
>
>
> print(f"Posterior mean of beta: {np.mean(beta_samples, axis=0)}")
> print(f"Posterior mean of sigma^2: {np.mean(sigma2_samples)}")
> print(f"Posterior probability of variable 1 inclusion: {np.mean(gamma_samples[:, 0])}")
> print(f"Posterior probability of variable 2 inclusion: {np.mean(gamma_samples[:, 1])}")
> ```

> âš ï¸ **Ponto Crucial**: O uso do *spike-and-slab prior* permite realizar a seleÃ§Ã£o de variÃ¡veis diretamente no processo de inferÃªncia Bayesiana, sem a necessidade de testes de hipÃ³tese ou outros critÃ©rios de seleÃ§Ã£o.

### Separating Hyperplanes e Perceptrons
```mermaid
graph TB
    subgraph "Gibbs Sampling for Separating Hyperplanes"
        direction TB
         A["Data: (X, y)"]
        B["Prior for w: P(w)"]
        C["Prior for b: P(b)"]
        D["Latent variables z_i ~ N(w^T x_i + b, 1)"]
        E["Conditional Posterior: P(w | z, X, b)"]
        F["Conditional Posterior: P(b | z, X, w)"]
         G["Sample z_i"]
        H["Sample w"]
        I["Sample b"]
        J["Iterate Samples"]
        K["Posterior samples of w, b"]
        A --> D
        B --> E
        C --> F
        D --> E
        D --> F
        E --> H
        F --> I
        G --> J
        H --> J
        I --> J
         J --> K
    end
```

O Gibbs Sampling pode ser aplicado no contexto de *separating hyperplanes* para encontrar um hiperplano Ã³timo em modelos classificatÃ³rios lineares, em contextos onde o modelo Ã© visto como uma distribuiÃ§Ã£o de probabilidade sobre as classes, ao invÃ©s de apenas uma funÃ§Ã£o discriminante.

1.  **Modelo:** Considere um modelo com hiperplanos definidos por $w^T x + b = 0$, onde $w$ Ã© o vetor de pesos, $x$ Ã© o vetor de *features* e $b$ Ã© o *bias*.
2.  **FormulaÃ§Ã£o probabilÃ­stica:** Definimos a probabilidade de um ponto $x_i$ pertencer Ã  classe 1 ou 0, com uma funÃ§Ã£o sigmoide ou similar.
3.  **IntroduÃ§Ã£o de variÃ¡veis latentes:** Para a aplicaÃ§Ã£o do Gibbs Sampling, podemos introduzir variÃ¡veis latentes $z_i$, que indicam a probabilidade condicional de cada ponto $x_i$ pertencer a uma dada classe dado os parÃ¢metros.
4.  **Processo iterativo:** Em cada iteraÃ§Ã£o do Gibbs Sampling, amostramos:
    -   Os parÃ¢metros $w$, dado as classes, os pontos e o *bias*, a partir de suas distribuiÃ§Ãµes condicionais posteriores (normal ou similar)
    -   O *bias* $b$, dado as classes, os pontos e os pesos
    -   As variÃ¡veis latentes $z_i$, dado os parÃ¢metros do hiperplano

**Teorema 1:** *ConvergÃªncia do Gibbs Sampling para o problema do *separating hyperplane*.* Sob certas condiÃ§Ãµes de regularidade (e com um *prior* razoÃ¡vel para $w$ e $b$), a sequÃªncia de amostras geradas pelo Gibbs Sampling converge para a distribuiÃ§Ã£o posterior do hiperplano, condicionada aos dados.

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Suponha que temos um problema de classificaÃ§Ã£o binÃ¡ria com dois *features*, onde as classes sÃ£o separadas por um hiperplano. Queremos amostrar a distribuiÃ§Ã£o posterior dos parÃ¢metros do hiperplano usando Gibbs Sampling.
>  Os dados de entrada $X$ e os rÃ³tulos $y$ podem ser representados como:
> ```python
> import numpy as np
> import scipy.stats as st
>
> X = np.array([[1, 2], [2, 1], [3, 3], [4, 2], [5, 4], [1, 1], [2, 2], [3, 1], [4, 3], [5, 2]])
> y = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])
> ```
>
> O hiperplano Ã© definido por $w^T x + b = 0$. Usamos uma funÃ§Ã£o sigmoide para calcular a probabilidade de um ponto pertencer Ã  classe 1:
>  $P(y_i=1|x_i, w, b) = \frac{1}{1+exp(-(w^T x_i + b))}$.
>  Introduzimos as variÃ¡veis latentes $z_i$, onde $z_i \sim \mathcal{N}(w^T x_i + b, 1)$ para simular a funÃ§Ã£o sigmoide.
>  Definimos *priors* para os parÃ¢metros: $w \sim \mathcal{N}(0, \Sigma)$ e $b \sim \mathcal{N}(0, 1)$, onde $\Sigma$ Ã© a matriz de covariÃ¢ncia.
>  Inicializamos $w^{(0)} = [0.5, 0.5]$ e $b^{(0)} = 0.1$ e $z_i^{(0)}$ com valores arbitrÃ¡rios.
>
> **IteraÃ§Ã£o 1:**
> 1.  Amostrando $z_i$:
>      * Para cada ponto $x_i$, amostramos $z_i$ de sua distribuiÃ§Ã£o condicional $z_i \sim \mathcal{N}(w^T x_i + b, 1)$. Suponha que amostramos $z^{(1)} = [1, 0.5, 1.2, 1.5, 1.1, -0.8, -0.4, -0.7, -0.2, -0.9]$.
> 2. Amostrando $w$:
>    *  Amostramos $w$ de sua distribuiÃ§Ã£o condicional, que Ã© uma distribuiÃ§Ã£o normal com parÃ¢metros dependentes de $z$, $b$ e $X$. Suponha que amostramos $w^{(1)} = [0.8, -0.6]$.
> 3.  Amostrando $b$:
>    * Amostramos $b$ de sua distribuiÃ§Ã£o condicional, que tambÃ©m Ã© uma normal com parÃ¢metros dependentes de $z$ e $X$ e $w$. Suponha que amostramos $b^{(1)} = -0.2$.
>
> Este processo Ã© repetido por vÃ¡rias iteraÃ§Ãµes, e as amostras obtidas para $w$ e $b$ sÃ£o usadas para fazer inferÃªncia sobre o hiperplano separador.
>
> ```python
> import numpy as np
> import scipy.stats as st
>
> def gibbs_sampling_separating_hyperplane(X, y, iterations=1000, prior_w_