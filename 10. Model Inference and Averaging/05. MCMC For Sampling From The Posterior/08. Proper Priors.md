## Model Inference and Averaging with Proper Priors

```mermaid
graph LR
    A["Maximum Likelihood"] --> B{"Minimizing Loss Function"};
    B --> C["Regression (Sum of Squares)"];
    B --> D["Classification (Cross-Entropy)"];
    A --> E["Bayesian Methods"];
    A --> F["Bootstrap"];
    E --> G{"Proper Priors"};
    F --> H{"Model Averaging"};
    G --> I["Impact on Bayesian Inference"];
    I --> J{"Improved Model Performance"};
    H --> J;
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style E fill:#ccf,stroke:#333,stroke-width:2px
```

### Introdu√ß√£o

O processo de ajuste de modelos, conforme abordado em [^8.1], geralmente envolve a minimiza√ß√£o de alguma fun√ß√£o de perda, seja ela uma soma de quadrados para regress√£o ou cross-entropia para classifica√ß√£o. Estas abordagens s√£o inst√¢ncias da metodologia de **Maximum Likelihood (ML)**. Este cap√≠tulo explora uma exposi√ß√£o mais geral da ML, introduz o m√©todo Bayesiano para infer√™ncia, e discute a t√©cnica do *bootstrap* [^8.1]. Al√©m disso, abordamos como essas t√©cnicas se relacionam e como elas podem ser usadas para realizar a m√©dia de modelos e melhorias. Um aspecto crucial √© a considera√ß√£o de *proper priors*, que ser√£o exploradas em detalhe neste cap√≠tulo, impactando notavelmente a infer√™ncia Bayesiana.

### Conceitos Fundamentais

**Conceito 1: Maximum Likelihood (ML)**
O m√©todo de **Maximum Likelihood** busca estimar os par√¢metros de um modelo atrav√©s da maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa (likelihood), que representa a probabilidade dos dados observados dado os par√¢metros do modelo [^8.1]. Esta abordagem, embora eficaz, assume que os dados observados s√£o a √∫nica fonte de informa√ß√£o sobre os par√¢metros, ignorando qualquer conhecimento pr√©vio que possamos ter sobre eles.

**Lemma 1:** Para um modelo com erros Gaussianos, a minimiza√ß√£o da soma dos erros quadrados √© equivalente √† maximiza√ß√£o da verossimilhan√ßa.
*Prova:*
Suponha que os erros $\epsilon_i$ s√£o independentes e identicamente distribu√≠dos com uma distribui√ß√£o normal com m√©dia zero e vari√¢ncia $\sigma^2$, ou seja, $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$. Dado um modelo linear $Y_i = \mu(x_i) + \epsilon_i$, a fun√ß√£o de verossimilhan√ßa para os par√¢metros $\beta$ e $\sigma^2$ pode ser escrita como:
$$L(\beta, \sigma^2 | Y) = \prod_{i=1}^N \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(Y_i - \mu(x_i))^2}{2\sigma^2}\right)$$
Tomando o logaritmo, temos o log-likelihood:
$$\ell(\beta, \sigma^2 | Y) = -\frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^N (Y_i - \mu(x_i))^2$$
Maximizar o log-likelihood em rela√ß√£o a $\beta$ √© equivalente a minimizar a soma dos quadrados dos erros $\sum_{i=1}^N (Y_i - \mu(x_i))^2$.  $\blacksquare$

```mermaid
graph LR
    subgraph "Maximum Likelihood and Gaussian Errors"
        direction TB
        A["Likelihood Function: L(Œ≤, œÉ¬≤|Y)"]
        B["Log-Likelihood: ‚Ñì(Œ≤, œÉ¬≤|Y)"]
        C["Sum of Squared Errors: ‚àë(Y·µ¢ - Œº(x·µ¢))¬≤"]
        A --> B
        B --> C
        style A fill:#ccf,stroke:#333,stroke-width:2px
    end
```

> üí° **Exemplo Num√©rico:** Considere um modelo linear simples $Y_i = \beta_0 + \beta_1 x_i + \epsilon_i$ com tr√™s observa√ß√µes: $(x_1, Y_1) = (1, 3)$, $(x_2, Y_2) = (2, 5)$, e $(x_3, Y_3) = (3, 7)$.  Assumindo $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$, o objetivo √© encontrar $\beta_0$ e $\beta_1$ que maximizem a verossimilhan√ßa (ou equivalentemente, minimizem a soma dos quadrados dos erros).  Usando a abordagem de m√≠nimos quadrados, podemos encontrar $\hat{\beta}_0 = 1$ e $\hat{\beta}_1 = 2$.  O log-likelihood para estes par√¢metros (e um $\sigma^2$ estimado) seria avaliado e maximizado. Note que a minimiza√ß√£o da soma dos quadrados dos erros $\sum_{i=1}^3 (Y_i - (\beta_0 + \beta_1 x_i))^2$ leva aos mesmos valores de $\beta_0$ e $\beta_1$.

**Conceito 2: Linear Discriminant Analysis (LDA) e Gaussianidade**
O LDA, frequentemente usado para classifica√ß√£o, assume que as classes seguem distribui√ß√µes Gaussianas com covari√¢ncias iguais. Essa suposi√ß√£o simplifica o problema, permitindo a cria√ß√£o de fronteiras lineares de decis√£o [^8.3]. Contudo, na pr√°tica, nem sempre essa premissa se mant√©m, e modelos como *Logistic Regression*, podem ser mais flex√≠veis e apresentar melhor desempenho [^8.4]. A conex√£o com a ML reside no fato de que as estimativas de par√¢metros no LDA podem ser derivadas atrav√©s da maximiza√ß√£o da verossimilhan√ßa sob as suposi√ß√µes gaussianas.

```mermaid
graph LR
    subgraph "LDA and Gaussian Assumptions"
    direction TB
        A["LDA Assumptions"]
        B["Classes follow Gaussian Distributions"]
        C["Equal Covariance Matrices"]
        A --> B
        A --> C
    end
```

**Corol√°rio 1:** Quando as suposi√ß√µes de gaussianidade do LDA n√£o se sustentam, √© prefer√≠vel utilizar abordagens como *Logistic Regression* que n√£o dependem estritamente dessas premissas. A *Logistic Regression* tamb√©m maximiza a verossimilhan√ßa, mas sob uma fun√ß√£o log√≠stica.

> üí° **Exemplo Num√©rico:** Suponha que temos duas classes de dados em duas dimens√µes, uma com m√©dia $\mu_1 = [1, 1]$ e outra com m√©dia $\mu_2 = [3, 3]$. Se as covari√¢ncias das classes s√£o aproximadamente iguais, o LDA funcionaria bem. No entanto, se uma classe tem alta vari√¢ncia em uma dire√ß√£o e a outra em outra dire√ß√£o, o LDA pode ter um desempenho ruim devido √† suposi√ß√£o de covari√¢ncias iguais, e a regress√£o log√≠stica ou outras abordagens se tornariam mais apropriadas.

**Conceito 3: Logistic Regression e Prior N√£o-Informativo**
A *Logistic Regression*, ao contr√°rio do LDA, n√£o assume distribui√ß√µes Gaussianas para os preditores. Ela modela a probabilidade de uma classe atrav√©s de uma fun√ß√£o log√≠stica, conectando essa probabilidade a uma combina√ß√£o linear dos preditores. A *Logistic Regression* tamb√©m envolve a maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa. Em uma abordagem *frequentist*, um *prior* n√£o-informativo √© frequentemente utilizado (como o constante). Na pr√°tica, no contexto *frequentist*, o *prior* √© geralmente ignorado, o que pode levar a problemas em situa√ß√µes de dados escassos ou quando h√° forte *colinearidade*.

> ‚ö†Ô∏è **Nota Importante**: O uso de um prior n√£o-informativo, embora comum, n√£o √© sem suas limita√ß√µes, especialmente quando a quantidade de dados √© limitada ou quando h√° multicolinearidade entre as vari√°veis preditoras. **Refer√™ncia ao t√≥pico [^8.1]**.

> üí° **Exemplo Num√©rico:** Imagine que voc√™ esteja modelando a probabilidade de um cliente comprar um produto com base em duas vari√°veis: idade ($x_1$) e renda ($x_2$). Usando regress√£o log√≠stica, modelamos a probabilidade como $P(Y=1|x_1, x_2) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2)}}$.  A abordagem de ML estimaria $\beta_0$, $\beta_1$ e $\beta_2$ maximizando a verossimilhan√ßa dos dados observados. Um *prior* n√£o informativo seria impl√≠cito, sem influenciar a solu√ß√£o. No entanto, se houvesse colinearidade entre idade e renda (por exemplo, pessoas mais velhas geralmente terem renda maior), a estimativa ML pode se tornar inst√°vel.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    A["Input Data (x, y)"] --> B["Indicator Matrix Encoding"];
    B --> C["Linear Regression"];
    C --> D["Coefficient Estimation (Œ≤)"];
    D --> E["Prediction and Classification"];
```
**Explica√ß√£o:** Diagrama que ilustra o processo de regress√£o linear com matriz de indicadores para classifica√ß√£o.

A regress√£o linear pode ser aplicada para classifica√ß√£o usando matrizes de indicadores, onde cada classe √© representada por uma coluna. A ideia √© ajustar um modelo linear para prever a probabilidade de uma observa√ß√£o pertencer a uma dada classe. A matriz de indicadores √© criada de modo que as colunas sejam vari√°veis *dummy* (0 ou 1), indicando a classe a que cada amostra pertence [^8.2]. Entretanto, essa abordagem pode ter limita√ß√µes, especialmente quando h√° muitas classes ou se estas n√£o s√£o linearmente separ√°veis.

**Lemma 2:** Em um cen√°rio de classifica√ß√£o bin√°ria com classes linearmente separ√°veis, a regress√£o linear com matriz de indicadores pode gerar hiperplanos de decis√£o equivalentes aos obtidos por outras abordagens como LDA sob condi√ß√µes espec√≠ficas.
*Prova:* Em um problema de classifica√ß√£o bin√°ria com duas classes distintas, a regress√£o linear com matrizes de indicadores busca estimar um modelo linear da forma $Y = X\beta + \epsilon$, onde $Y$ √© um vetor de indicadores (0 ou 1) para cada classe, e $X$ √© a matriz de preditores. Sob condi√ß√µes de linear separabilidade, os par√¢metros $\beta$ estimados por m√≠nimos quadrados formam um hiperplano que separa as duas classes com erro m√≠nimo. Esse hiperplano √© equivalente aos hiperplanos gerados por LDA quando a vari√¢ncia dentro das classes √© aproximadamente a mesma. $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere um conjunto de dados de classifica√ß√£o bin√°ria com duas caracter√≠sticas: $x_1$ e $x_2$.  Para a classe 0, temos os pontos (1, 1), (2, 1), e para a classe 1, temos os pontos (2, 2), (3, 2). Criamos uma matriz de indicadores *Y*, onde os valores para a classe 0 s√£o 0, e para a classe 1 s√£o 1. Usamos uma regress√£o linear para ajustar um modelo $Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2$. A estimativa dos coeficientes $\beta$ por m√≠nimos quadrados levar√° a um hiperplano que tenta separar as duas classes. Em dados linearmente separ√°veis, este hiperplano pode ser similar ao gerado pelo LDA.

**Corol√°rio 2:** Embora a regress√£o linear com matriz de indicadores seja uma abordagem simples para classifica√ß√£o, ela pode sofrer em cen√°rios com mais de duas classes ou quando a separabilidade linear n√£o √© garantida, necessitando de abordagens mais robustas e flex√≠veis.

> ‚ùó **Ponto de Aten√ß√£o**: A regress√£o linear com matriz de indicadores, embora simples, pode levar a extrapola√ß√µes problem√°ticas em cen√°rios de classifica√ß√£o. **Conforme indicado em [^8.2]**. √â crucial avaliar os resultados com cautela, especialmente em problemas com classes n√£o-balanceadas ou dados de treinamento limitados.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Techniques in Logistic Regression"
        direction TB
        A["Logistic Regression Cost Function"]
        B["L1 Regularization (Lasso): Œª‚àë|Œ≤·µ¢|"]
        C["L2 Regularization (Ridge): Œª‚àëŒ≤·µ¢¬≤"]
        D["Elastic Net: Combination of L1 and L2"]
        A --> B
        A --> C
        A --> D
    end
```
A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas essenciais para lidar com problemas de overfitting, especialmente quando temos muitas vari√°veis preditoras [^8.5]. Na classifica√ß√£o, isso √© particularmente relevante para aumentar a estabilidade e a interpretabilidade dos modelos. T√©cnicas como a regulariza√ß√£o L1 (Lasso) e L2 (Ridge) s√£o comumente usadas para esse fim, adicionando termos de penaliza√ß√£o √† fun√ß√£o de custo que √© otimizada durante o treinamento. A regulariza√ß√£o L1 tende a produzir modelos esparsos, ou seja, com muitos coeficientes iguais a zero, enquanto a L2 reduz a magnitude dos coeficientes, contribuindo para um modelo mais est√°vel.

**Lemma 3:** A penaliza√ß√£o L1 na classifica√ß√£o log√≠stica leva a coeficientes esparsos devido ao formato da norma L1 e sua rela√ß√£o com as derivadas da fun√ß√£o de custo.
*Prova:*
Na regress√£o log√≠stica, a fun√ß√£o de custo √© a log-verossimilhan√ßa negativa, que √© uma fun√ß√£o convexa dos par√¢metros $\beta$. A regulariza√ß√£o L1 adiciona um termo de penaliza√ß√£o proporcional √† soma dos valores absolutos dos coeficientes:
$$ J(\beta) = -\ell(\beta) + \lambda \sum_{j=1}^p |\beta_j| $$
onde $\lambda$ √© o par√¢metro de regulariza√ß√£o. Ao tentar minimizar $J(\beta)$, o termo de penaliza√ß√£o L1 favorece solu√ß√µes com coeficientes $\beta_j$ iguais a zero, resultando em um modelo mais esparso. Isso ocorre porque a derivada da norma L1 √© constante (exceto no ponto zero), o que promove solu√ß√µes nos eixos, resultando em muitos par√¢metros com valores iguais a zero. $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com 5 vari√°veis preditoras, e uma vari√°vel alvo bin√°ria. Ao ajustar uma regress√£o log√≠stica sem regulariza√ß√£o, todos os 5 coeficientes s√£o estimados, podendo ocorrer overfitting. Com regulariza√ß√£o L1 (Lasso), a fun√ß√£o de custo se torna $J(\beta) = -\ell(\beta) + \lambda (|\beta_1| + |\beta_2| + |\beta_3| + |\beta_4| + |\beta_5|)$. Se $\lambda$ for suficientemente grande, alguns dos coeficientes $\beta_j$ ser√£o for√ßados a ser exatamente zero, simplificando o modelo e, consequentemente, selecionando as vari√°veis mais relevantes para a classifica√ß√£o. Por exemplo, se os coeficientes resultantes fossem $\beta = [2, 0, 1.5, 0, 0]$, apenas $x_1$ e $x_3$ seriam considerados preditores relevantes.

**Corol√°rio 3:** Modelos com regulariza√ß√£o L1 n√£o apenas evitam overfitting, mas tamb√©m oferecem maior interpretabilidade por selecionar apenas as vari√°veis mais relevantes para a classifica√ß√£o, o que facilita a identifica√ß√£o dos preditores mais importantes para o resultado.

> ‚úîÔ∏è **Destaque**: Regulariza√ß√£o n√£o apenas melhora a generaliza√ß√£o do modelo, mas tamb√©m simplifica a interpreta√ß√£o dos resultados, permitindo a identifica√ß√£o das vari√°veis mais importantes para a classifica√ß√£o. **Baseado no t√≥pico [^8.5]**.

### Separating Hyperplanes e Perceptrons
```mermaid
graph LR
    subgraph "Separating Hyperplanes and Perceptrons"
        direction TB
        A["Separating Hyperplane"] --> B["Maximum Margin (SVM)"]
        A --> C["Perceptron Algorithm"]
        B --> D["Wolfe Dual Problem (Optimization)"]
        C --> E["Iterative Parameter Adjustment"]
    end
```
Os **separating hyperplanes** s√£o fundamentais em modelos de classifica√ß√£o linear, onde o objetivo √© encontrar um hiperplano que separe as classes de dados. A ideia de maximizar a margem entre as classes leva a formula√ß√µes de otimiza√ß√£o como o problema de **Support Vector Machine (SVM)**. O problema dual de Wolfe, como referenciado em [^8.5.2], √© uma ferramenta importante para resolver esses problemas de otimiza√ß√£o, permitindo expressar o problema original como uma fun√ß√£o de seus multiplicadores de Lagrange.

O **Perceptron** de Rosenblatt [^8.5.1] √© um algoritmo que busca iterativamente encontrar um hiperplano de separa√ß√£o. Esse algoritmo converge quando os dados s√£o linearmente separ√°veis, mas pode n√£o convergir em outros casos. A ideia principal √© usar os dados de treinamento para ajustar um modelo linear de forma iterativa.

> üí° **Exemplo Num√©rico:** Imagine dois grupos de pontos 2D, o primeiro grupo (classe 0) como (1,2), (1.5, 1.8), (1.2, 1.5) e o segundo grupo (classe 1) (3,4), (3.5, 3.8), (3.2, 4.2). Um hiperplano (neste caso uma linha) separador pode ser definido como $\beta_0 + \beta_1 x_1 + \beta_2 x_2 = 0$. O perceptron iterativamente ajustaria os coeficientes $\beta_0, \beta_1, \beta_2$ para encontrar um hiperplano que separa esses pontos. Se, por exemplo, inicialmente $\beta$ fosse [0, 1, -1], a linha $x_2 = x_1$ n√£o separaria os pontos corretamente, e o perceptron ajustaria os coeficientes iterativamente.  Se ap√≥s algumas itera√ß√µes, o algoritmo converge para, por exemplo, $\beta = [-6, 2, 1]$, ter√≠amos o hiperplano  $2x_1 + x_2 = 6$, o qual separaria as duas classes.

### Pergunta Te√≥rica Avan√ßada: Qual o impacto do uso de priors informativos em m√©todos bayesianos de classifica√ß√£o?
**Resposta:**
O uso de *priors* informativos em m√©todos Bayesianos de classifica√ß√£o altera a forma como os par√¢metros do modelo s√£o estimados. Ao contr√°rio de *priors* n√£o-informativos, que d√£o igual peso a todas as possibilidades, um *prior* informativo direciona a busca da solu√ß√£o para √°reas do espa√ßo de par√¢metros que s√£o consideradas mais prov√°veis com base em conhecimento pr√©vio [^8.3].

**Lemma 4:** Um *prior* informativo pode aumentar a precis√£o das estimativas de par√¢metros, especialmente quando o tamanho da amostra √© pequeno. No entanto, se o *prior* for mal especificado, ele pode levar a estimativas enviesadas, mesmo com grandes amostras.
*Prova:*
Em uma abordagem Bayesiana, a distribui√ß√£o *posterior* dos par√¢metros $\theta$ dado os dados $Z$ √© proporcional √† verossimilhan√ßa multiplicada pelo *prior*:
$$ p(\theta|Z) \propto p(Z|\theta)p(\theta) $$
Se o *prior* $p(\theta)$ estiver concentrado em regi√µes do espa√ßo de par√¢metros que s√£o consistentes com o verdadeiro valor de $\theta$, ele ajudar√° a obter estimativas mais precisas e com menor vari√¢ncia na *posterior*. No entanto, se $p(\theta)$ atribuir alta probabilidade a valores de $\theta$ que s√£o muito diferentes do verdadeiro valor, o resultado final ser√° uma estimativa enviesada. $\blacksquare$

```mermaid
graph LR
    subgraph "Bayesian Inference with Informative Priors"
    direction TB
        A["Posterior Distribution p(Œ∏|Z)"]
        B["Likelihood p(Z|Œ∏)"]
        C["Prior Distribution p(Œ∏)"]
        A --> B
        A --> C
        style A fill:#ccf,stroke:#333,stroke-width:2px
    end
```

> üí° **Exemplo Num√©rico:** Em uma regress√£o log√≠stica bayesiana para prever a probabilidade de um evento, podemos usar um *prior* informativo para o coeficiente de uma vari√°vel preditora. Se soubermos que uma vari√°vel deve ter um efeito positivo sobre a probabilidade do evento com base em estudos anteriores, podemos escolher um *prior* Gaussiano com m√©dia positiva para o coeficiente. Se o *prior* for corretamente especificado, a distribui√ß√£o *posterior* dos par√¢metros ter√° menor vari√¢ncia e estar√° centrada em um valor mais preciso. Por outro lado, se o *prior* for mal especificado, com uma m√©dia negativa quando o efeito √© na verdade positivo, a *posterior* resultante pode levar a estimativas de par√¢metros enviesadas.

**Corol√°rio 4:** √â crucial que a especifica√ß√£o de *priors* informativos seja feita com cuidado e com base em conhecimento pr√©vio bem fundamentado, para evitar a introdu√ß√£o de vieses indesejados nas estimativas dos par√¢metros e na previs√£o do modelo.

> ‚ö†Ô∏è **Ponto Crucial**: A escolha do *prior* pode ter um impacto substancial nos resultados em problemas Bayesianos. *Priors* informativos podem melhorar a precis√£o das estimativas quando bem especificados, mas podem levar a vieses quando mal definidos. **Conforme discutido em [^8.3]**.

### Conclus√£o

Neste cap√≠tulo, exploramos diversas t√©cnicas para infer√™ncia e modelagem, incluindo **Maximum Likelihood**, *bootstrap*, abordagens Bayesianas com o uso de *proper priors* e *model averaging*. Cada t√©cnica oferece uma perspectiva √∫nica sobre a an√°lise de dados e a constru√ß√£o de modelos, com suas pr√≥prias vantagens e limita√ß√µes. A escolha da t√©cnica mais apropriada depende do problema em quest√£o e dos objetivos da an√°lise. A discuss√£o sobre *proper priors* destaca a import√¢ncia de incorporar conhecimento pr√©vio na modelagem, particularmente em abordagens Bayesianas. Nas pr√≥ximas se√ß√µes, iremos aprofundar em outros temas cruciais relacionados ao modelamento e infer√™ncia estat√≠stica.

### Footnotes

[^8.1]: "For most of this book, the fitting (learning) of models has been achieved by minimizing a sum of squares for regression, or by minimizing cross-entropy for classification. In fact, both of these minimizations are instances of the maximum likelihood approach to fitting." *(Trecho de <8.1 Introduction>)*
[^8.2]: "Denote the training data by Z = {z1,z2,...,zN}, with zi = (xi, yi), i = 1,2,..., N. Here xi is a one-dimensional input, and y·µ¢ the outcome, either continuous or categorical." *(Trecho de <8.2 The Bootstrap and Maximum Likelihood Methods>)*
[^8.3]: "Suppose we decide to fit a cubic spline to the data, with three knots placed at the quartiles of the X values. This is a seven-dimensional lin- ear space of functions, and can be represented, for example, by a linear expansion of B-spline basis functions (see Section 5.9.2):" *(Trecho de <8.2 The Bootstrap and Maximum Likelihood Methods>)*
[^8.4]: "In the top right panel of Figure 8.2 we have plotted √ª(x) ¬±1.96.se[√ª(x)]. Since 1.96 is the 97.5% point of the standard normal distribution, these represent approximate 100 ‚àí 2 √ó 2.5% = 95% pointwise confidence bands for Œº(x)." *(Trecho de <8.2 The Bootstrap and Maximum Likelihood Methods>)*
[^8.5]: "It turns out that the parametric bootstrap agrees with least squares in the previous example because the model (8.5) has additive Gaussian errors. In general, the parametric bootstrap agrees not with least squares but with maximum likelihood, which we now review." *(Trecho de <8.2 The Bootstrap and Maximum Likelihood Methods>)*
