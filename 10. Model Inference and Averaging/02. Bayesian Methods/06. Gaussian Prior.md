## Gaussian Priors em Modelos de Infer√™ncia e M√©dia

```mermaid
graph LR
    subgraph "Inference and Averaging"
        direction TB
        A["Maximum Likelihood"]
        B["Bayesian Methods"]
        C["Gaussian Priors"]
        D["Bootstrap"]
        E["Model Averaging"]
        F["Committee Methods"]
         G["Bagging"]
        H["Stacking"]
        I["Bumping"]
        A --> B
        B --> C
        A --> D
        A & B --> E
        E --> F
        E --> G
        E --> H
         E --> I
    end
```

### Introdu√ß√£o

Este cap√≠tulo aborda a infer√™ncia de modelos e t√©cnicas de averaging, com √™nfase na abordagem de **Maximum Likelihood** e em m√©todos Bayesianos, incluindo o uso de **Gaussian priors**. A motiva√ß√£o principal √© encontrar formas eficazes de ajustar modelos a dados, quantificar incertezas e combinar modelos para obter previs√µes mais robustas. Inicialmente, modelos s√£o ajustados minimizando a soma dos quadrados (para regress√£o) ou a cross-entropy (para classifica√ß√£o), que s√£o, essencialmente, inst√¢ncias da abordagem de maximum likelihood [^8.1]. No entanto, este cap√≠tulo explora formalmente o m√©todo de maximum likelihood e o m√©todo Bayesiano para infer√™ncia. O *bootstrap*, apresentado anteriormente, ser√° discutido neste contexto, juntamente com sua rela√ß√£o com maximum likelihood e Bayes. Finalmente, ser√£o apresentadas t√©cnicas para model averaging e aprimoramento, incluindo m√©todos de comit√™, bagging, stacking e bumping [^8.1].

### Conceitos Fundamentais
**Conceito 1: Maximum Likelihood e Modelos Param√©tricos**

O m√©todo de **maximum likelihood** busca encontrar os par√¢metros de um modelo que melhor explicam os dados observados, maximizando a fun√ß√£o de verossimilhan√ßa (likelihood) [^8.2.2]. Dado um conjunto de dados $Z = \{z_1, z_2, \ldots, z_N\}$ e um modelo param√©trico $g_{\theta}(z)$ que descreve a probabilidade de observar um dado ponto $z$, onde $\theta$ representa os par√¢metros do modelo, a fun√ß√£o de verossimilhan√ßa √© dada por [^8.2.2]:
$$
L(\theta; Z) = \prod_{i=1}^{N} g_{\theta}(z_i)
$$
O objetivo √© encontrar o valor de $\theta$ que maximize esta fun√ß√£o de verossimilhan√ßa. Usualmente, √© mais conveniente trabalhar com o log-likelihood, denotado por $l(\theta; Z)$, que √© a soma dos log-likelihoods componentes [^8.2.2]:
```mermaid
graph LR
    subgraph "Log-Likelihood Derivation"
        direction TB
        A["Likelihood Function: L(Œ∏; Z) = Œ† g_Œ∏(z_i)"]
        B["Log-Likelihood Function: l(Œ∏; Z) = Œ£ log(g_Œ∏(z_i))"]
        A --> B
        C["Objective: Maximize l(Œ∏; Z) with respect to Œ∏"]
        B --> C
    end
```
$$
l(\theta; Z) = \sum_{i=1}^{N} \log g_{\theta}(z_i)
$$
O estimador de maximum likelihood $\hat{\theta}$ √© o valor de $\theta$ que maximiza $l(\theta; Z)$. Em geral, n√£o existe uma solu√ß√£o anal√≠tica para esse problema e √© preciso recorrer a m√©todos num√©ricos.

> üí° **Exemplo Num√©rico:** Considere um modelo simples onde $g_\theta(z_i)$ √© uma distribui√ß√£o normal com m√©dia $\mu$ e desvio padr√£o $\sigma$, ou seja,  $z_i \sim \mathcal{N}(\mu, \sigma^2)$. Temos um dataset com tr√™s pontos $Z = \{2, 4, 6\}$. A fun√ß√£o de verossimilhan√ßa para um √∫nico ponto √© $g_{\theta}(z_i) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(z_i-\mu)^2}{2\sigma^2}}$. Para maximizar a verossimilhan√ßa, buscamos os par√¢metros $\hat{\mu}$ e $\hat{\sigma}$ que maximizam:
>
> $L(\mu, \sigma; Z) = \prod_{i=1}^3 \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(z_i-\mu)^2}{2\sigma^2}}$
>
> O log-likelihood √©:
>
> $l(\mu, \sigma; Z) = \sum_{i=1}^3 \left[ -\frac{1}{2} \log(2\pi\sigma^2) - \frac{(z_i - \mu)^2}{2\sigma^2} \right]$
>
> Para encontrar os estimadores de maximum likelihood, derivamos $l(\mu, \sigma; Z)$ em rela√ß√£o a $\mu$ e $\sigma$ e igualamos a zero. No caso da m√©dia $\mu$, o estimador √© $\hat{\mu} = \frac{2+4+6}{3} = 4$. Para o desvio padr√£o $\sigma$, $\hat{\sigma}$ √© o desvio padr√£o amostral dos dados.
>
> Este exemplo ilustra como o m√©todo de maximum likelihood estima par√¢metros que melhor explicam os dados, neste caso, a m√©dia e o desvio padr√£o de uma distribui√ß√£o normal.

**Lemma 1:** A fun√ß√£o de verossimilhan√ßa para erros Gaussianos aditivos em um modelo de regress√£o √© equivalente √† minimiza√ß√£o da soma dos quadrados.

**Prova:**  Suponha um modelo de regress√£o $y_i = \mu(x_i) + \epsilon_i$ onde $\epsilon_i \sim N(0, \sigma^2)$. A densidade de probabilidade de $y_i$ dado $x_i$ √© $g_{\theta}(y_i) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(y_i - \mu(x_i))^2}{2\sigma^2}}$. O log-likelihood √© ent√£o [^8.2.2]:

```mermaid
graph LR
    subgraph "Lemma 1: Log-Likelihood and SSE"
        direction TB
        A["Regression Model: y_i = Œº(x_i) + Œµ_i"]
        B["Error Distribution: Œµ_i ~ N(0, œÉ¬≤)"]
        C["Log-Likelihood: l(Œ∏; Z) = Œ£ [-1/2 log(2œÄœÉ¬≤) - (y_i - Œº(x_i))¬≤ / 2œÉ¬≤]"]
        D["Equivalent to Minimizing: SSE = Œ£ (y_i - Œº(x_i))¬≤"]
        A --> B
        B --> C
         C --> D
    end
```
$$l(\theta; Z) = \sum_{i=1}^{N} \left[ -\frac{1}{2} \log(2\pi\sigma^2) - \frac{(y_i - \mu(x_i))^2}{2\sigma^2} \right] $$

Maximizar $l(\theta; Z)$ em rela√ß√£o a $\mu(x_i)$ √© equivalente a minimizar $\sum_{i=1}^{N} (y_i - \mu(x_i))^2$, que √© a soma dos quadrados dos erros. $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o linear simples: $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$, com $\epsilon_i \sim N(0, \sigma^2)$. Temos os dados:
>
> | $x_i$ | $y_i$ |
> |-------|-------|
> | 1     | 3     |
> | 2     | 5     |
> | 3     | 6     |
>
> Usando a prova do Lema 1, o log-likelihood √©:
>
> $l(\beta_0, \beta_1, \sigma^2; Z) = \sum_{i=1}^3 \left[ -\frac{1}{2} \log(2\pi\sigma^2) - \frac{(y_i - (\beta_0 + \beta_1 x_i))^2}{2\sigma^2} \right]$
>
> Maximizar esse log-likelihood √© equivalente a minimizar a soma dos quadrados dos erros:
>
> $\text{SSE} = \sum_{i=1}^3 (y_i - (\beta_0 + \beta_1 x_i))^2 = (3 - (\beta_0 + \beta_1))^2 + (5 - (\beta_0 + 2\beta_1))^2 + (6 - (\beta_0 + 3\beta_1))^2$
>
> A solu√ß√£o de m√≠nimos quadrados para este problema √© $\hat{\beta}_0 = 2.33$ e $\hat{\beta}_1 = 1.17$. Isso demonstra como o m√©todo de maximum likelihood se relaciona √† minimiza√ß√£o da soma dos quadrados para modelos de regress√£o linear com erros Gaussianos.

**Conceito 2: Linear Splines e B-splines**
O uso de **B-splines** como fun√ß√µes de base para representar $\mu(x)$ √© uma t√©cnica poderosa em modelagem n√£o linear. Uma fun√ß√£o spline c√∫bica com tr√™s n√≥s pode ser definida como uma combina√ß√£o linear de sete fun√ß√µes base $h_j(x)$, como [^8.2]:
```mermaid
graph LR
    subgraph "B-Spline Representation"
       direction TB
        A["Model: Œº(x) = Œ£ Œ≤_j h_j(x)"]
        B["h_j(x): B-spline basis functions"]
        C["Œ≤_j: Coefficients to be estimated"]
        A --> B
        A --> C
    end
```
$$
\mu(x) = \sum_{j=1}^{7} \beta_j h_j(x)
$$
Onde $h_j(x)$ s√£o as fun√ß√µes B-spline e $\beta_j$ s√£o os coeficientes a serem estimados. A matriz $H$, com elementos $h_j(x_i)$, e o vetor $y$ das observa√ß√µes, permitem estimar $\beta$ atrav√©s de m√≠nimos quadrados [^8.2]:
```mermaid
graph LR
    subgraph "Estimating Coefficients"
        direction TB
        A["Data Matrix H (elements h_j(x_i))"]
        B["Observation Vector y"]
        C["Coefficient Estimator: Œ≤ÃÇ = (H·µÄH)‚Åª¬πH·µÄy"]
        D["Variance of Coefficients: Var(Œ≤ÃÇ) = (H·µÄH)‚Åª¬πœÉÃÇ¬≤"]
        A & B --> C
         C --> D
    end
```
$$
\hat{\beta} = (H^TH)^{-1}H^Ty
$$
A vari√¢ncia dos coeficientes √© estimada por [^8.2]:
$$
Var(\hat{\beta}) = (H^TH)^{-1}\hat{\sigma}^2
$$
onde $\hat{\sigma}^2$ √© a vari√¢ncia dos erros.

> üí° **Exemplo Num√©rico:**  Vamos considerar um exemplo simplificado com apenas 3 fun√ß√µes B-spline, ou seja, $h_1(x)$, $h_2(x)$ e $h_3(x)$. Temos os seguintes valores para $x_i$ e os respectivos valores das B-splines:
>
> | $x_i$ | $h_1(x_i)$ | $h_2(x_i)$ | $h_3(x_i)$ | $y_i$ |
> |-------|------------|------------|------------|-------|
> | 1     | 0.5        | 0.3        | 0.2        | 2.5   |
> | 2     | 0.2        | 0.6        | 0.2        | 4.1   |
> | 3     | 0.1        | 0.3        | 0.6        | 6.0   |
>
> A matriz $H$ e o vetor $y$ s√£o:
>
> $$ H = \begin{bmatrix} 0.5 & 0.3 & 0.2 \\ 0.2 & 0.6 & 0.2 \\ 0.1 & 0.3 & 0.6 \end{bmatrix} \quad y = \begin{bmatrix} 2.5 \\ 4.1 \\ 6.0 \end{bmatrix} $$
>
> Para calcular $\hat{\beta}$, seguimos os seguintes passos:
>
> 1.  Calcular $H^T$:
>
>     $$ H^T = \begin{bmatrix} 0.5 & 0.2 & 0.1 \\ 0.3 & 0.6 & 0.3 \\ 0.2 & 0.2 & 0.6 \end{bmatrix} $$
>
> 2.  Calcular $H^TH$:
>
>     $$ H^TH = \begin{bmatrix} 0.5 & 0.2 & 0.1 \\ 0.3 & 0.6 & 0.3 \\ 0.2 & 0.2 & 0.6 \end{bmatrix}  \begin{bmatrix} 0.5 & 0.3 & 0.2 \\ 0.2 & 0.6 & 0.2 \\ 0.1 & 0.3 & 0.6 \end{bmatrix} = \begin{bmatrix} 0.3 & 0.3 & 0.2 \\ 0.3 & 0.54 & 0.36 \\ 0.2 & 0.36 & 0.44 \end{bmatrix} $$
>
> 3.  Calcular $(H^TH)^{-1}$. Usando o numpy:
> ```python
> import numpy as np
> H = np.array([[0.5, 0.3, 0.2], [0.2, 0.6, 0.2], [0.1, 0.3, 0.6]])
> HT = H.T
> HTH = HT @ H
> inv_HTH = np.linalg.inv(HTH)
> print(inv_HTH)
> ```
>
>     Obtemos:
>
> $$ (H^TH)^{-1} = \begin{bmatrix} 5.57 & -2.86 & -0.71 \\ -2.86 & 5.71 & -1.43 \\ -0.71 & -1.43 & 3.57 \end{bmatrix} $$
>
> 4. Calcular $H^Ty$:
>
>  $$ H^Ty = \begin{bmatrix} 0.5 & 0.2 & 0.1 \\ 0.3 & 0.6 & 0.3 \\ 0.2 & 0.2 & 0.6 \end{bmatrix} \begin{bmatrix} 2.5 \\ 4.1 \\ 6.0 \end{bmatrix} = \begin{bmatrix} 2.07 \\ 4.71 \\ 5.42 \end{bmatrix} $$
>
> 5.  Finalmente, calcular $\hat{\beta} = (H^TH)^{-1}H^Ty$:
>
> $$ \hat{\beta} =  \begin{bmatrix} 5.57 & -2.86 & -0.71 \\ -2.86 & 5.71 & -1.43 \\ -0.71 & -1.43 & 3.57 \end{bmatrix} \begin{bmatrix} 2.07 \\ 4.71 \\ 5.42 \end{bmatrix} = \begin{bmatrix} 1.08 \\ 1.15 \\ 5.00 \end{bmatrix} $$
>
> Portanto, $\hat{\beta} \approx [1.08, 1.15, 5.00]^T$. Este exemplo demonstra como calcular os coeficientes para splines usando m√≠nimos quadrados.

**Corol√°rio 1:** O estimador de m√≠nimos quadrados para o ajuste de splines com erros gaussianos aditivos coincide com o estimador de maximum likelihood.
**Prova:** Conforme provado no Lemma 1, quando os erros s√£o gaussianos, o estimador que maximiza o log-likelihood √© o mesmo que minimiza a soma dos erros quadr√°ticos. No caso das splines, o estimador de m√≠nimos quadrados para $\beta$ √© $\hat{\beta} = (H^TH)^{-1}H^Ty$, o que coincide com o estimador obtido por maximum likelihood, conforme explicitado em [^8.2]. $\blacksquare$

**Conceito 3: Gaussian Priors e Infer√™ncia Bayesiana**
Na abordagem Bayesiana, al√©m de um modelo para os dados, especificamos uma distribui√ß√£o *a priori* para os par√¢metros, $Pr(\theta)$, refletindo o conhecimento pr√©vio sobre $\theta$ antes de observar os dados [^8.3]. A distribui√ß√£o *a posteriori* √© calculada utilizando o teorema de Bayes:
```mermaid
graph LR
    subgraph "Bayesian Inference"
        direction TB
        A["Prior Distribution: Pr(Œ∏)"]
        B["Likelihood: Pr(Z|Œ∏)"]
        C["Posterior Distribution: Pr(Œ∏|Z) =  Pr(Z|Œ∏)Pr(Œ∏) / ‚à´Pr(Z|Œ∏)Pr(Œ∏)dŒ∏"]
         A & B --> C
        D["Bayesian Inference: Update belief based on data"]
        C --> D
    end
```
$$
Pr(\theta|Z) = \frac{Pr(Z|\theta)Pr(\theta)}{\int Pr(Z|\theta)Pr(\theta) \, d\theta}
$$
No contexto de regress√£o, um **Gaussian prior** para os coeficientes $\beta$ em um modelo de regress√£o √© dado por:
```mermaid
graph LR
    subgraph "Gaussian Prior"
       direction TB
        A["Coefficients: Œ≤"]
        B["Gaussian Prior: Œ≤ ~ N(0, œÑŒ£)"]
        C["Prior Variance: œÑ"]
        D["Prior Covariance Matrix: Œ£"]
       B --> C
       B --> D
       A --> B
    end
```
$$
\beta \sim N(0, \tau\Sigma)
$$
onde $\tau$ √© a vari√¢ncia *a priori* e $\Sigma$ √© a matriz de correla√ß√£o *a priori*. O uso de Gaussian priors implica que a distribui√ß√£o *a priori* de $\mu(x)$ tamb√©m √© Gaussiana [^8.3]. Esta abordagem permite modelar a incerteza dos par√¢metros e das previs√µes.

> ‚ö†Ô∏è **Nota Importante**: A escolha da matriz de covari√¢ncia $\Sigma$ √© crucial.  Uma escolha comum √© $\Sigma = I$, que assume que os coeficientes s√£o independentes a priori. **Refer√™ncia ao t√≥pico [^8.3]**.

> ‚ùó **Ponto de Aten√ß√£o**: Gaussian priors imp√µem um certo n√≠vel de suavidade √† solu√ß√£o, como visto na Figura 8.4, onde um $\tau$ menor resulta em curvas mais suaves. **Conforme indicado em [^8.3]**.

> üí° **Exemplo Num√©rico:**  Suponha que temos um modelo de regress√£o linear $y = X\beta + \epsilon$ e queremos usar um prior Gaussiano para os coeficientes $\beta$.  Assumimos $\beta \sim N(0, \tau I)$, onde $\tau$ controla a vari√¢ncia do prior. Se usarmos um $\tau$ pequeno (por exemplo, $\tau = 0.1$),  estamos indicando que acreditamos que os coeficientes $\beta$ devem ser pequenos. Se $\tau$ for grande (por exemplo, $\tau = 10$), estamos menos restritivos sobre os valores de $\beta$.
>
>  Vamos visualizar o efeito de $\tau$ utilizando dados simulados:
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import Ridge
>
> # Dados simulados
> np.random.seed(0)
> X = np.sort(5 * np.random.rand(50, 1), axis=0)
> y = np.sin(X).ravel() + 0.1 * np.random.randn(50)
>
> # Valores de alpha (inverso de tau)
> alphas = [10, 1, 0.1, 0.01]
>
> plt.figure(figsize=(10,6))
> for i, alpha in enumerate(alphas):
>     ridge = Ridge(alpha=alpha)
>     ridge.fit(X, y)
>     y_pred = ridge.predict(X)
>     plt.plot(X, y_pred, label=f'alpha={alpha}')
>
> plt.scatter(X, y, color='black', s=10, label='Dados')
> plt.legend()
> plt.title("Efeito do Regulariza√ß√£o L2 (Ridge) com diferentes valores de alpha")
> plt.xlabel('x')
> plt.ylabel('y')
> plt.show()
> ```
>
> No exemplo acima, o alpha do Ridge regression √© o inverso de tau. Vemos que com alpha grande (tau pequeno), a linha fica mais suave e pr√≥xima de zero. Isso demonstra como a escolha do valor de $\tau$ (ou alpha) afeta a complexidade do modelo e sua tend√™ncia a overfit ou underfit os dados.

> ‚úîÔ∏è **Destaque**:  Para $\tau \to \infty$, a distribui√ß√£o posterior coincide com a distribui√ß√£o do bootstrap, indicando uma rela√ß√£o entre Bayesian methods com priors n√£o informativos e o bootstrap. **Baseado no t√≥pico [^8.4]**.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction TB
        A["Input Data: Features (X) and Class Labels (Y)"]
        B["Encoding: Y encoded as Indicator Matrix"]
        C["Linear Regression: Fit Model Y = XŒ≤ + Œµ"]
        D["Decision Boundary: Linear hyperplanes defined by Œ≤"]
        E["Limitations: Predictions may not be within [0, 1]"]
        F["Masking Problem: Class correlation issues"]
        A --> B
        B --> C
        C --> D
        D --> E
        D --> F
    end
```

A regress√£o linear, ajustada por m√≠nimos quadrados, pode ser aplicada a problemas de classifica√ß√£o atrav√©s da codifica√ß√£o das classes como vari√°veis indicadoras. Se tivermos $K$ classes, cada observa√ß√£o √© associada a um vetor de indicadores de classe, onde cada elemento corresponde a uma classe. Um dos elementos ser√° igual a 1, indicando a classe a que a observa√ß√£o pertence, e os demais ser√£o iguais a 0. Ao aplicar a regress√£o linear na matriz de indicadores, obtemos coeficientes que, implicitamente, definem as fronteiras de decis√£o linear [^8.1].

No entanto, essa abordagem possui limita√ß√µes. Por exemplo, para problemas com mais de duas classes, a regress√£o linear ajustada diretamente √† matriz de indicadores pode levar a predi√ß√µes fora do intervalo [0, 1] quando projetada. A estima√ß√£o dos par√¢metros pode sofrer com o *masking problem*, onde a influ√™ncia de algumas classes pode obscurecer a influ√™ncia de outras, especialmente se houver alta correla√ß√£o entre as classes [^8.1].

Al√©m disso, a regress√£o de indicadores n√£o leva em conta a natureza categ√≥rica da vari√°vel de resposta.  Embora a regress√£o linear minimize a soma dos quadrados, isso pode n√£o ser o objetivo mais adequado para a classifica√ß√£o [^8.1].
Para mitigar estas limita√ß√µes, t√©cnicas de regulariza√ß√£o ou abordagens probabil√≠sticas como a regress√£o log√≠stica podem ser mais apropriadas.

> üí° **Exemplo Num√©rico:** Suponha que temos um problema de classifica√ß√£o com 3 classes (A, B e C) e temos duas caracter√≠sticas (x1, x2) para cada observa√ß√£o. Vamos codificar as classes usando vari√°veis indicadoras.
>
> |   x1  |   x2  | Class |  Y_A  |  Y_B  | Y_C   |
> |-------|-------|-------|-------|-------|-------|
> |   1   |   2   |  A    |   1   |   0   |   0   |
> |   2   |   1   |  A    |   1   |   0   |   0   |
> |   2   |   3   |  B    |   0   |   1   |   0   |
> |   3   |   2   |  B    |   0   |   1   |   0   |
> |   3   |   4   |  C    |   0   |   0   |   1   |
> |   4   |   3   |  C    |   0   |   0   |   1   |
>
> Aplicamos a regress√£o linear separadamente para cada coluna indicadora (Y_A, Y_B e Y_C) usando as colunas x1 e x2 como preditores. Para a classe A, o modelo seria $Y_A = \beta_{0A} + \beta_{1A}x_1 + \beta_{2A}x_2 + \epsilon_A$. Da mesma forma para as classes B e C. Ap√≥s o ajuste, obtemos coeficientes para cada classe.
>
> Para prever a classe de um novo ponto (x1=2.5, x2=2.5),  calculamos os valores preditos para $Y_A$, $Y_B$ e $Y_C$ usando os coeficientes obtidos. Por exemplo:
>
> - $\hat{Y}_A = \hat{\beta}_{0A} + \hat{\beta}_{1A} \cdot 2.5 + \hat{\beta}_{2A} \cdot 2.5$
> - $\hat{Y}_B = \hat{\beta}_{0B} + \hat{\beta}_{1B} \cdot 2.5 + \hat{\beta}_{2B} \cdot 2.5$
> - $\hat{Y}_C = \hat{\beta}_{0C} + \hat{\beta}_{1C} \cdot 2.5 + \hat{\beta}_{2C} \cdot 2.5$
>
> A classe predita seria aquela com o maior valor previsto ($\hat{Y}$). Uma limita√ß√£o desta abordagem √© que as predi√ß√µes $\hat{Y}$ podem ser valores fora do intervalo [0, 1], o que n√£o √© ideal para probabilidades de classe.

**Lemma 2:** A regress√£o linear para classifica√ß√£o com matriz de indicadores, quando ajustada via m√≠nimos quadrados, produz solu√ß√µes com um componente que corresponde a proje√ß√µes em hiperplanos, similares aos que podem ser obtidos por an√°lises discriminantes lineares em condi√ß√µes espec√≠ficas.

**Prova:**
Seja $Y$ a matriz de indicadores, onde $Y_{ij} = 1$ se a observa√ß√£o $i$ pertence √† classe $j$ e 0 caso contr√°rio. O modelo de regress√£o linear para a classe $j$ √© $Y_j = X\beta_j + \epsilon_j$, onde $X$ √© a matriz de features e $\beta_j$ s√£o os coeficientes associados √† classe $j$. A solu√ß√£o de m√≠nimos quadrados √© dada por $\hat{\beta_j} = (X^TX)^{-1}X^TY_j$. A predi√ß√£o para uma nova observa√ß√£o $x$ √© $\hat{y_j} = x^T\hat{\beta_j}$. A classe predita ser√° a classe $k$ que maximizar $\hat{y_k} = x^T\hat{\beta_k}$. Essa opera√ß√£o corresponde a uma proje√ß√£o em hiperplanos definidos pelos coeficientes $\hat{\beta_k}$. Em certas condi√ß√µes, como as da LDA, estes hiperplanos ser√£o equivalentes aos da an√°lise discriminante linear. $\blacksquare$

**Corol√°rio 2:** Sob certas condi√ß√µes de distribui√ß√£o dos dados e de classes balanceadas, a regress√£o de indicadores pode gerar resultados compar√°veis √† an√°lise discriminante linear em termos de fronteiras de decis√£o, mas com riscos de predi√ß√µes fora do intervalo \[0,1] e sem levar em conta a natureza categ√≥rica da vari√°vel de resposta.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["Log-Likelihood"]
        B["L1 Penalty (Lasso): - Œª Œ£|Œ≤_j|"]
         C["L2 Penalty (Ridge): - Œª Œ£Œ≤_j¬≤"]
        D["Elastic Net: - Œª‚ÇÅ Œ£|Œ≤_j| - Œª‚ÇÇ Œ£Œ≤_j¬≤"]
        A --> B
        A --> C
        A --> D
    end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas importantes para melhorar a generaliza√ß√£o e a interpretabilidade de modelos classificat√≥rios. Em modelos lineares como a regress√£o log√≠stica, a regulariza√ß√£o adiciona termos de penalidade √† fun√ß√£o de verossimilhan√ßa. Penaliza√ß√µes $L_1$ e $L_2$ s√£o comuns.  A penaliza√ß√£o $L_1$  (Lasso) adiciona um termo proporcional √† norma $L_1$ dos coeficientes [^8.4]:
$$
l(\theta; Z) - \lambda \sum_{j=1}^{p} |\beta_j|
$$
Essa penaliza√ß√£o leva a solu√ß√µes esparsas, isto √©, alguns coeficientes ser√£o exatamente zero. J√° a penaliza√ß√£o $L_2$ (Ridge) adiciona um termo proporcional ao quadrado da norma $L_2$ dos coeficientes:
$$
l(\theta; Z) - \lambda \sum_{j=1}^{p} \beta_j^2
$$
A penaliza√ß√£o $L_2$ n√£o leva a solu√ß√µes esparsas, mas reduz a magnitude dos coeficientes, melhorando a estabilidade do modelo e reduzindo o risco de overfitting. O *Elastic Net* combina as penaliza√ß√µes $L_1$ e $L_2$ [^8.4]:
```mermaid
graph LR
    subgraph "Elastic Net Penalty"
        direction TB
         A["Elastic Net Penalty: - Œª‚ÇÅ Œ£|Œ≤_j| - Œª‚ÇÇ Œ£Œ≤_j¬≤"]
         B["L1 Component: - Œª‚ÇÅ Œ£|Œ≤_j| (sparsity)"]
        C["L2 Component: - Œª‚ÇÇ Œ£Œ≤_j¬≤ (stability)"]
        A --> B
        A --> C
    end
```
$$
l(\theta; Z) - \lambda_1 \sum_{j=1}^{p} |\beta_j| - \lambda_2 \sum_{j=1}^{p} \beta_j^2
$$
A escolha apropriada dos hiperpar√¢metros $\lambda$, $\lambda_1$ e $\lambda_2$ √© geralmente realizada por valida√ß√£o cruzada.

> üí° **Exemplo Num√©rico:** Vamos considerar um problema de classifica√ß√£o bin√°ria usando regress√£o log√≠stica com penaliza√ß√£o $L_1$ e $L_2$. Os dados consistem em 5 features (x1 at√© x5) e um label bin√°rio (0 ou 1). Vamos usar um conjunto de dados simulado:
>
> ```python
> import numpy as np
> import pandas as pd
> from sklearn.linear_model import LogisticRegression
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import accuracy_score
>
> # Cria dados simulados
> np.random.seed(42)
> X = np.random.rand(100, 5)
> y = np.random.randint(0, 2, 100)
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Regress√£o Log√≠stica sem regulariza√ß√£o
> logreg_none = LogisticRegression(penalty=None, solver='liblinear')
> logreg_none.fit(X_train, y_train)
> y_pred_none = logreg_none.predict(X_test)
> acc_none = accuracy_score(y_test, y_pred_none)
>
> # Regress√£o Log√≠stica com L1 (Lasso)
> logreg_l1 = LogisticRegression(penalty='l1', C=0.1, solver='liblinear')
> logreg_l1.fit(X_train, y_train)
> y_pred_l1 = logreg_l1.predict(X_test)
> acc_l1 = accuracy_score(y_test, y_pred_l1)
>
> # Regress√£o Log√≠stica com L2 (Ridge)
> logreg_l2 = LogisticRegression(penalty='l2', C=0.1, solver='liblinear')
> logreg_l2.fit(X_train, y_train)
> y_pred_l2 = logreg_l2.predict(X_test)
> acc_l2 = accuracy_score(y_test, y_pred_l2)
>
> # Imprimir resultados
> print(f"Acur√°cia sem regulariza√ß√£o: {acc_none:.2f}")
> print(f"Acur√°cia com L1 (Lasso): {acc_l1:.2f}")
> print(f"Acur√°cia com L2 (Ridge): {acc_l2:.2f}")
>
> # Ver os coeficientes
> print("\nCoeficientes sem regulariza√ß√£o:", logreg_none.coef_)
> print("Coeficientes com L1 (Lasso):", logreg_l1.coef_)
> print("Coeficientes com L2 (Ridge):", logreg_l2.coef_)
>
> ```
>
> Neste exemplo, C √© o inverso de lambda. Podemos ver que a regulariza√ß√£o L1 (Lasso) leva a alguns coeficientes exatamente zero, enquanto a regulariza√ß√£o L2 (Ridge) reduz a magnitude de todos os coeficientes. Al√©m disso, vemos que as acur√°cias podem variar dependendo do m√©todo. Este exemplo ilustra como as penalidades afetam os coeficientes e a performance do modelo.
>

**Lemma 3:** A penaliza√ß√£o $L_1$ em classifica√ß√£o log√≠stica induz a esparsidade na solu√ß√£o, tendendo a fazer com que alguns coeficientes sejam exatamente zero.

**Prova:** A penaliza√ß√£o $L_1$ adiciona um termo $-\lambda \sum_{j=1}^{p} |\beta_j|$ ao log-likelihood.  A otimiza√ß√£o desta fun√ß√£o envolve um trade-off entre o ajuste aos dados e a penaliza√ß√£o dos coeficientes. A fun√ß√£o $|x|$ n√£o √© diferenci√°vel em $x = 0$, o que for√ßa muitos coeficientes a serem exatamente zero para minimizar o termo de penaliza√ß√£o, desde que $\lambda$ seja suficientemente grande. Isto resulta em uma solu√ß√£o esparsa. $\blacksquare$

**Corol√°rio 3:** Solu√ß√µes esparsas promovidas pela regulariza√ß√£o $L_1$ facilitam a interpretabilidade dos modelos classificat√≥rios, pois identificam as features mais importantes para a predi√ß√£o. A regulariza√ß√£o $L_2$, embora n√£o promova a esparsidade, tamb√©m melhora a estabilidade do modelo e reduz a vari√¢ncia das estimativas dos coeficientes.

> ‚ö†Ô∏è **Ponto Crucial**:  O Elastic Net combina os benef√≠cios de ambas as penaliza√ß√µes, permitindo um balanceamento entre esparsidade e estabilidade. **Conforme discutido em [^8.4]**.

### Separating Hyperplanes e Perceptrons
A ideia central de **Separating Hyperplanes** √© encontrar um hiperplano que maximize a margem de separa√ß√£o entre as classes em um problema de classifica√ß√£o.  O *Perceptron*, um algoritmo cl√°ssico para modelos lineares, busca iterativamente um hiperplano que separa as classes corretamente, utilizando uma fun√ß√£o discriminante linear [^8.5].
```mermaid
graph LR
    sub