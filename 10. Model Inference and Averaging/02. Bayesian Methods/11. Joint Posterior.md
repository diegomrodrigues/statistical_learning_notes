## Infer√™ncia e Amostragem da Distribui√ß√£o Conjunta Posterior

```mermaid
graph LR
    subgraph "Bayesian Inference Framework"
        direction TB
        A["Prior: P(Œ∏)"] --> B["Likelihood: P(Z|Œ∏)"]
        B --> C["Posterior: P(Œ∏|Z) ‚àù P(Z|Œ∏)P(Œ∏)"]
        C --> D["Inference & Sampling"]
    end
```

### Introdu√ß√£o

Neste cap√≠tulo, exploramos t√©cnicas para a **infer√™ncia e amostragem da distribui√ß√£o conjunta posterior**, um conceito central na infer√™ncia Bayesiana. A infer√™ncia Bayesiana difere da abordagem frequentista por incorporar um *prior* que reflete o conhecimento pr√©vio sobre os par√¢metros, permitindo atualizar este conhecimento ap√≥s observar os dados [^8.1]. A distribui√ß√£o posterior, por sua vez, expressa a incerteza remanescente ap√≥s a observa√ß√£o dos dados, atrav√©s de uma distribui√ß√£o de probabilidade. Este cap√≠tulo aprofunda as t√©cnicas de **maximum likelihood**, **bootstrap**, **m√©todos Bayesianos**, e os m√©todos de *model averaging* e *stacking* [^8.1]. Apresentamos uma discuss√£o avan√ßada sobre o uso de m√©todos *Markov chain Monte Carlo* (MCMC), incluindo *Gibbs Sampling*, e suas conex√µes com o algoritmo *Expectation-Maximization* (EM). As t√©cnicas abordadas s√£o essenciais para problemas de infer√™ncia e an√°lise de dados, onde a incerteza nos par√¢metros √© uma considera√ß√£o crucial.

### Conceitos Fundamentais

**Conceito 1: Maximum Likelihood**

O m√©todo de **Maximum Likelihood** busca encontrar os valores dos par√¢metros que maximizam a probabilidade dos dados observados, dada uma determinada distribui√ß√£o [^8.1]. Matematicamente, dado um conjunto de dados $Z = \{z_1, z_2, \ldots, z_N\}$, e uma distribui√ß√£o de probabilidade com par√¢metros $\theta$, a fun√ß√£o de verossimilhan√ßa √© dada por:

$$
L(\theta; Z) = \prod_{i=1}^N g_\theta(z_i),
$$

onde $g_\theta(z_i)$ √© a densidade de probabilidade ou massa de probabilidade para a observa√ß√£o $z_i$ sob o modelo com par√¢metros $\theta$. Para facilitar a otimiza√ß√£o, frequentemente maximizamos o logaritmo da verossimilhan√ßa, que √© dado por:

$$
l(\theta; Z) = \sum_{i=1}^N \log g_\theta(z_i).
$$

O estimador de maximum likelihood, $\hat{\theta}$, √© o valor de $\theta$ que maximiza $l(\theta; Z)$. Este m√©todo, embora amplamente utilizado, n√£o considera nenhum *prior* sobre os par√¢metros e √©, portanto, puramente baseado nos dados [^8.1].

> üí° **Exemplo Num√©rico:** Suponha que temos um conjunto de dados de 5 lan√ßamentos de uma moeda, onde observamos 3 caras (1) e 2 coroas (0). O modelo para a probabilidade de cara √© um modelo de Bernoulli com par√¢metro $\theta$, ent√£o $g_\theta(z_i) = \theta^{z_i}(1-\theta)^{1-z_i}$. A fun√ß√£o de verossimilhan√ßa √© $L(\theta; Z) = \theta^3(1-\theta)^2$. O log-likelihood √© $l(\theta; Z) = 3\log(\theta) + 2\log(1-\theta)$. Para encontrar o estimador de m√°xima verossimilhan√ßa, derivamos $l(\theta; Z)$ em rela√ß√£o a $\theta$ e igualamos a zero: $\frac{3}{\theta} - \frac{2}{1-\theta} = 0$. Resolvendo para $\theta$, obtemos $\hat{\theta} = 3/5 = 0.6$. Este √© o valor de $\theta$ que maximiza a probabilidade de observar os dados que temos.

```mermaid
graph LR
    subgraph "Maximum Likelihood Estimation"
        direction TB
        A["Data: Z = {z1, z2, ..., zN}"] --> B["Likelihood Function: L(Œ∏; Z) = ‚àè gŒ∏(zi)"]
        B --> C["Log-Likelihood: l(Œ∏; Z) = Œ£ log gŒ∏(zi)"]
        C --> D["Maximize l(Œ∏; Z) to find Œ∏ÃÇ"]
    end
```

**Lemma 1:** O estimador de m√≠nimos quadrados para regress√£o linear √© um caso especial do estimador de m√°xima verossimilhan√ßa quando os erros s√£o gaussianos.

*Prova:* Para um modelo de regress√£o linear com erros gaussianos, $y_i = h(x_i)^T\beta + \epsilon_i$, onde $\epsilon_i \sim N(0, \sigma^2)$, a fun√ß√£o de log-verossimilhan√ßa √© dada por:

$$
l(\beta, \sigma^2) = -\frac{N}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^N (y_i - h(x_i)^T\beta)^2
$$

Maximizando essa fun√ß√£o em rela√ß√£o a $\beta$, obtemos o estimador de m√≠nimos quadrados $\hat{\beta} = (H^TH)^{-1}H^Ty$, que coincide com o estimador de m√°xima verossimilhan√ßa. $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o linear simples $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$ com $\epsilon_i \sim N(0, \sigma^2)$. Suponha que temos os seguintes dados: $X = [1, 2, 3, 4, 5]$ e $Y = [2, 4, 5, 4, 5]$. Podemos construir a matriz $H$ com uma coluna de 1's e a coluna de $X$, tal que
>
> $H = \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 1 & 3 \\ 1 & 4 \\ 1 & 5 \end{bmatrix}$
>
> Usando a f√≥rmula do estimador de m√≠nimos quadrados, $\hat{\beta} = (H^TH)^{-1}H^Ty$, podemos calcular:
>
> $H^TH = \begin{bmatrix} 5 & 15 \\ 15 & 55 \end{bmatrix}$
>
> $(H^TH)^{-1} = \begin{bmatrix} 0.55 & -0.15 \\ -0.15 & 0.05 \end{bmatrix}$
>
> $H^Ty = \begin{bmatrix} 20 \\ 74 \end{bmatrix}$
>
> $\hat{\beta} = \begin{bmatrix} 0.9 \\ 0.7 \end{bmatrix}$.
>
> Este resultado coincide com a solu√ß√£o de m√°xima verossimilhan√ßa para este problema quando os erros s√£o gaussianos, como demonstrado no Lemma 1.

```mermaid
graph LR
    subgraph "OLS as Maximum Likelihood"
        direction TB
        A["Linear Regression Model: yi = h(xi)TŒ≤ + Œµi, Œµi ~ N(0, œÉ¬≤)"] --> B["Log-Likelihood: l(Œ≤, œÉ¬≤)"]
        B --> C["Maximize l(Œ≤, œÉ¬≤) w.r.t Œ≤"]
        C --> D["Result: Œ≤ÃÇ = (HTH)-1HTy"]
        D --> E["Equivalence with Least Squares"]
    end
```

**Conceito 2: Linear Discriminant Analysis (LDA) e sua rela√ß√£o com Maximum Likelihood.**

O Linear Discriminant Analysis (LDA) pode ser visto como uma aplica√ß√£o de Maximum Likelihood para problemas de classifica√ß√£o. No LDA, assumimos que as classes t√™m distribui√ß√µes gaussianas com a mesma matriz de covari√¢ncia, mas m√©dias diferentes. O objetivo √© encontrar uma transforma√ß√£o linear que maximize a separa√ß√£o entre as classes e minimize a vari√¢ncia dentro de cada classe [^8.1]. Formalmente,  dado que $g_k(x) = N(\mu_k, \Sigma)$ representa a densidade Gaussiana da classe $k$, o LDA estima as m√©dias de classe  $\mu_k$ e a matriz de covari√¢ncia comum $\Sigma$ por maximum likelihood. A fronteira de decis√£o linear √© definida com base nas estimativas de maximum likelihood e √© uma aproxima√ß√£o da fronteira de decis√£o Bayesiana ideal sob as suposi√ß√µes de normalidade e covari√¢ncias iguais.

**Corol√°rio 1:** A fronteira de decis√£o do LDA √© linear e √© definida pelos pontos onde a probabilidade posterior das classes s√£o iguais.

*Prova:* A fronteira de decis√£o entre duas classes k e l √© dada por $P(G=k|X=x)=P(G=l|X=x)$. Utilizando o teorema de Bayes, $P(G=k|X=x) = \frac{P(X=x|G=k)P(G=k)}{P(X=x)}$. Assumindo prior de classes iguais $P(G=k) = P(G=l)$  e as densidades gaussianas $P(X=x|G=k) = N(x;\mu_k, \Sigma)$, a fronteira de decis√£o torna-se $N(x;\mu_k, \Sigma)=N(x;\mu_l, \Sigma)$, que leva a uma equa√ß√£o linear em $x$ sob as mesmas covari√¢ncias, determinando um hiperplano. $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere duas classes, uma com m√©dia $\mu_1 = [1, 1]$ e outra com m√©dia $\mu_2 = [3, 3]$, ambas com matriz de covari√¢ncia $\Sigma = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$. O LDA, ao assumir essas distribui√ß√µes gaussianas, estima as m√©dias e a covari√¢ncia por m√°xima verossimilhan√ßa. A fronteira de decis√£o ser√° um hiperplano, neste caso uma linha, que separa as duas classes. A fronteira de decis√£o, $x$, satisfaz:
>
> $(x - \mu_1)^T\Sigma^{-1}(x-\mu_1) = (x - \mu_2)^T\Sigma^{-1}(x-\mu_2)$.
>
> Resolvendo, chegamos a $2x_1 + 2x_2 = 16$, que √© uma linha. A fronteira √© uma reta com inclina√ß√£o -1 e intercepto 8, localizada no meio do caminho entre as m√©dias das duas classes, como esperado.

```mermaid
graph LR
    subgraph "LDA as Maximum Likelihood"
        direction TB
        A["Classes with Gaussian Distributions: N(Œºk, Œ£)"] --> B["Maximum Likelihood Estimation of Œºk and Œ£"]
        B --> C["Decision Boundary: P(G=k|X=x) = P(G=l|X=x)"]
        C --> D["Linear Decision Boundary (Hyperplane)"]
    end
```

**Conceito 3: Bootstrap**

O **Bootstrap** √© uma t√©cnica de reamostragem que permite estimar a incerteza de um estimador sem fazer suposi√ß√µes param√©tricas sobre a distribui√ß√£o dos dados [^8.2.1]. A ideia √© gerar m√∫ltiplas amostras a partir da amostra original, com reposi√ß√£o, e calcular o estimador para cada uma dessas amostras. A distribui√ß√£o dos estimadores assim obtidos √© usada para aproximar a distribui√ß√£o do estimador original. No contexto de regress√£o, por exemplo, dado um conjunto de dados $\{(x_i, y_i)\}_{i=1}^N$, geramos $B$ conjuntos de dados bootstrap $\{(x_i^*, y_i^*)\}_{i=1}^N$, onde cada par $(x_i^*, y_i^*)$ √© sorteado com reposi√ß√£o a partir dos pares originais. Ent√£o, calculamos o estimador de interesse para cada conjunto de dados bootstrap, por exemplo, $\hat{\beta}^{*b}$ para $b = 1, \ldots, B$ e estimamos a incerteza a partir da vari√¢ncia desses estimadores bootstrap. O m√©todo Bootstrap pode ser aplicado tanto para estimadores de par√¢metros como para predi√ß√µes do modelo.

> ‚ö†Ô∏è **Nota Importante**: O bootstrap pode ser param√©trico ou n√£o param√©trico. O bootstrap n√£o param√©trico reamostra os dados diretamente, enquanto o bootstrap param√©trico simula novos dados a partir de um modelo ajustado aos dados originais, [^8.2.1].

> ‚ùó **Ponto de Aten√ß√£o**: O bootstrap √© √∫til quando n√£o temos f√≥rmulas anal√≠ticas para a incerteza de um estimador, mas pode ser computacionalmente intensivo [^8.2.1].

> ‚úîÔ∏è **Destaque**: A distribui√ß√£o emp√≠rica dos estimadores bootstrap aproxima a distribui√ß√£o amostral do estimador original [^8.2.1].

> üí° **Exemplo Num√©rico:**  Considere o mesmo conjunto de dados de regress√£o linear do exemplo anterior: $X = [1, 2, 3, 4, 5]$ e $Y = [2, 4, 5, 4, 5]$. Para aplicar o bootstrap, geramos, por exemplo, 5 amostras bootstrap com reposi√ß√£o. Uma poss√≠vel reamostragem poderia ser: $X^* = [2, 1, 4, 4, 3]$ e $Y^* = [4, 2, 4, 4, 5]$. Calculamos o estimador de m√≠nimos quadrados $\hat{\beta}^*$ para cada amostra bootstrap, resultando em $\hat{\beta}^{*1}$, $\hat{\beta}^{*2}$, ..., $\hat{\beta}^{*5}$. A partir da distribui√ß√£o desses $\hat{\beta}^*$, podemos estimar a incerteza dos par√¢metros do modelo original.

```mermaid
graph LR
    subgraph "Bootstrap Resampling"
        direction TB
        A["Original Data: {(xi, yi)}"] --> B["Resample with Replacement: {(xi*, yi*)}"]
        B --> C["Compute Estimator: Œ≤ÃÇ* for each sample"]
        C --> D["Approximate Sampling Distribution of Œ≤ÃÇ"]
    end
```

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
flowchart TD
    A["Classes as Indicator Variables"] --> B["Fit a Linear Model via Least Squares"]
    B --> C["Predict Classes for New Data"]
    C --> D["Decision Rule: Assign class with largest estimate"]
    D --> E["Classification Result"]
```

A **regress√£o linear** pode ser aplicada para problemas de classifica√ß√£o atrav√©s da codifica√ß√£o das classes como vari√°veis indicadoras [^8.2]. Em um problema de $K$ classes, criamos $K$ vari√°veis indicadoras, onde a $k$-√©sima vari√°vel √© 1 se a observa√ß√£o pertence √† classe $k$ e 0 caso contr√°rio. O modelo linear √© ent√£o ajustado para prever cada uma dessas vari√°veis indicadoras. Para classificar uma nova observa√ß√£o, atribu√≠mos a ela a classe cuja vari√°vel indicadora tenha a maior previs√£o.

O uso de regress√£o linear para classifica√ß√£o, apesar de sua simplicidade, apresenta algumas limita√ß√µes:
*  A regress√£o linear n√£o restringe as previs√µes a estarem entre 0 e 1, o que pode levar a resultados sem interpreta√ß√£o probabil√≠stica.
* A regress√£o linear assume que a rela√ß√£o entre as vari√°veis preditoras e as vari√°veis indicadoras √© linear, o que pode n√£o ser v√°lido em muitos casos pr√°ticos.
* A regress√£o linear n√£o garante que as previs√µes das vari√°veis indicadoras somem 1 para uma determinada observa√ß√£o, o que √© esperado em um problema de classifica√ß√£o probabil√≠stica.
* **Lemma 2:** O estimador de m√≠nimos quadrados em regress√£o linear para classifica√ß√£o pode ser derivado diretamente da matriz de indicadores.

*Prova:* Seja $Y$ a matriz de indicadores de tamanho $N \times K$ onde cada coluna representa uma classe e $X$ a matriz de preditoras $N \times p$. A solu√ß√£o de m√≠nimos quadrados para prever $Y$ a partir de $X$ √© dada por $\hat{B} = (X^TX)^{-1}X^TY$. Este $\hat{B}$ fornece os coeficientes lineares para cada classe. Para classificar uma nova amostra $x^*$, multiplicamos o vetor $x^*$ por $\hat{B}$ e alocamos a classe com o maior valor. $\blacksquare$

*   **Corol√°rio 2:** A regress√£o linear com vari√°veis indicadoras produz um classificador linear, que define fronteiras de decis√£o lineares.

*Prova:* As fun√ß√µes discriminantes obtidas pela regress√£o linear s√£o lineares na entrada $x$ devido ao modelo ser linear nos par√¢metros. As fronteiras de decis√£o s√£o dadas pelas igualdades entre as fun√ß√µes discriminantes. Consequentemente, $x^T \hat{\beta}_k = x^T \hat{\beta}_l$ define uma rela√ß√£o linear em $x$, representando uma fronteira de decis√£o linear. $\blacksquare$

> üí° **Exemplo Num√©rico:** Para um problema de classifica√ß√£o com duas classes (0 e 1) e uma √∫nica vari√°vel preditora $x$, suponha que temos os seguintes dados:
>
>  $X = [1, 2, 3, 4, 5]$ e $Y = [0, 0, 1, 1, 1]$. Criamos a matriz indicadora $Y$ que, neste caso, √© igual ao pr√≥prio vetor $Y$ (a classe 0 √© representada por 0 e a classe 1 por 1). Usando a regress√£o linear, ajustamos um modelo $\hat{y_i} = \hat{\beta}_0 + \hat{\beta}_1 x_i$. Aplicando a f√≥rmula de m√≠nimos quadrados, podemos encontrar os coeficientes $\hat{\beta}_0$ e $\hat{\beta}_1$. A fronteira de decis√£o ser√° um ponto onde $\hat{y} = 0.5$, separando as duas classes. Para este exemplo em particular, $\hat{\beta_0} \approx -0.7$ e $\hat{\beta_1} \approx 0.3$.  A fronteira de decis√£o √© definida por $-0.7 + 0.3x = 0.5$, que resulta em $x = 4$. Para classificar um novo ponto, dizemos que se $x < 4$ a classe √© 0, sen√£o √© 1.
>

Em alguns casos, a regress√£o linear para classifica√ß√£o pode gerar boas aproxima√ß√µes para a fronteira de decis√£o, especialmente quando as classes s√£o bem separ√°veis linearmente, como apresentado no cap√≠tulo, quando discute as liga√ß√µes entre o m√©todo e o LDA [^8.1]. No entanto,  a regress√£o linear de uma matriz indicadora pode levar a extrapola√ß√µes fora do intervalo [0, 1]. A **regress√£o log√≠stica** corrige esses problemas ao modelar diretamente as probabilidades das classes usando a fun√ß√£o log√≠stica, que por sua vez se enquadra em um modelo de maximum likelihood com distribui√ß√£o Bernoulli [^8.1], como apresentado na discuss√£o de **Maximum Likelihood** no cap√≠tulo.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["Regularization"] --> B["L1 (Lasso)"]
        A --> C["L2 (Ridge)"]
        B --> D["Sparsity: Variable Selection"]
        C --> E["Overfitting Reduction"]
        D --> F["Improved Interpretability"]
        E --> G["Enhanced Generalization"]
    end
```

A **sele√ß√£o de vari√°veis** e a **regulariza√ß√£o** s√£o t√©cnicas cruciais para lidar com modelos de classifica√ß√£o complexos, especialmente quando temos um n√∫mero elevado de vari√°veis preditoras [^8.1]. A regulariza√ß√£o adiciona uma penalidade √† fun√ß√£o de custo do modelo, com o objetivo de evitar *overfitting* e melhorar a capacidade de generaliza√ß√£o. As penaliza√ß√µes L1 e L2 s√£o as mais comuns:
*  A penaliza√ß√£o L1 (Lasso) adiciona ao custo a soma dos valores absolutos dos coeficientes. Esta penaliza√ß√£o tende a gerar modelos *esparsos*, ou seja, com muitos coeficientes iguais a zero, o que efetivamente realiza a sele√ß√£o de vari√°veis, identificando as mais importantes [^8.1]. A fun√ß√£o de custo com penaliza√ß√£o L1 √© dada por:

$$
\text{Custo} = -l(\beta) + \lambda \sum_{j=1}^p |\beta_j|
$$
Onde $l(\beta)$ √© a log-verossimilhan√ßa e $\lambda$ √© o par√¢metro de regulariza√ß√£o.

*   A penaliza√ß√£o L2 (Ridge) adiciona ao custo a soma dos quadrados dos coeficientes. Esta penaliza√ß√£o tende a reduzir a magnitude dos coeficientes, o que tamb√©m evita o *overfitting* e estabiliza o modelo [^8.1]. A fun√ß√£o de custo com penaliza√ß√£o L2 √© dada por:
$$
\text{Custo} = -l(\beta) + \lambda \sum_{j=1}^p \beta_j^2
$$
Onde $l(\beta)$ √© a log-verossimilhan√ßa e $\lambda$ √© o par√¢metro de regulariza√ß√£o.

*   A combina√ß√£o das penaliza√ß√µes L1 e L2 √© conhecida como Elastic Net, e visa combinar os benef√≠cios de ambos os m√©todos [^8.1].
    O Elastic Net oferece um controle mais flex√≠vel sobre a esparsidade e a estabilidade dos modelos.

**Lemma 3:** A penaliza√ß√£o L1 em regress√£o log√≠stica promove a esparsidade dos coeficientes.

*Prova:* A penaliza√ß√£o L1, ao adicionar o termo $\lambda \sum_{j=1}^p |\beta_j|$ na fun√ß√£o de custo, introduz uma solu√ß√£o n√£o diferenci√°vel para os coeficientes quando o valor de um deles √© igual a zero. Essa n√£o diferenciabilidade leva a uma "quebra" na trajet√≥ria de otimiza√ß√£o, empurrando os coeficientes para zero, a medida que o $\lambda$ aumenta, especialmente para aqueles menos importantes. Isso √© conhecido como a propriedade de *sparsity* da norma L1. A otimiza√ß√£o, nesse caso,  requer algoritmos espec√≠ficos que lidam com essa caracter√≠stica [^8.4.4]. $\blacksquare$

* **Corol√°rio 3:** Modelos com penaliza√ß√£o L1 s√£o mais interpret√°veis do que os modelos sem penaliza√ß√£o ou com L2, devido ao menor n√∫mero de vari√°veis relevantes no modelo.

*Prova:* A esparsidade dos coeficientes em modelos com penaliza√ß√£o L1 reduz a complexidade do modelo, facilitando a identifica√ß√£o das vari√°veis mais importantes para a predi√ß√£o. Isso torna o modelo mais f√°cil de interpretar e entender, uma vez que as vari√°veis preditoras com peso nulo s√£o explicitamente ignoradas no modelo [^8.4.5].$\blacksquare$

> üí° **Exemplo Num√©rico:** Considere um problema de regress√£o log√≠stica com duas vari√°veis preditoras ($x_1$ e $x_2$) e as seguintes estimativas dos coeficientes por maximum likelihood: $\hat{\beta_0} = 0.1$, $\hat{\beta_1} = 0.8$ e $\hat{\beta_2} = -0.3$. Aplicando a regulariza√ß√£o L1, o custo a ser minimizado √© $-l(\beta) + \lambda(|\beta_1| + |\beta_2|)$. Se usarmos $\lambda = 0.5$, a regulariza√ß√£o L1 pode for√ßar $\beta_2$ para zero, resultando em um modelo mais esparso e, portanto, mais interpret√°vel. Por exemplo, podemos obter novas estimativas $\hat{\beta_1}=0.6$ e $\hat{\beta_2}=0$. Isso sugere que apenas a vari√°vel $x_1$ √© relevante para o modelo. A regulariza√ß√£o L2, por sua vez,  iria reduzir a magnitude de ambos os coeficientes mas n√£o os for√ßaria a zero.

```mermaid
graph LR
    subgraph "L1 Regularization (Lasso)"
        direction TB
        A["Cost Function: -l(Œ≤) + ŒªŒ£|Œ≤j|"] --> B["Sparsity"]
         B --> C["Variable Selection"]
        C --> D["Interpretability"]
    end
```

### Separating Hyperplanes e Perceptrons

A ideia de **separating hyperplanes** (hiperplanos separadores) surge no contexto de problemas de classifica√ß√£o linear, onde o objetivo √© encontrar uma superf√≠cie linear que separe as diferentes classes de forma √≥tima.  A busca pelo hiperplano √≥timo leva ao conceito de **m√°xima margem**, que √© a dist√¢ncia m√°xima entre o hiperplano e os pontos mais pr√≥ximos de cada classe [^8.5.2]. O problema de encontrar o hiperplano com m√°xima margem √© formulado como um problema de otimiza√ß√£o convexa, que pode ser resolvido usando o m√©todo do **dual de Wolfe**. A solu√ß√£o do problema dual envolve apenas os produtos internos dos vetores de dados, e a solu√ß√£o final √© escrita como uma combina√ß√£o linear dos pontos de suporte (os pontos de dados mais pr√≥ximos do hiperplano) [^8.5.2].

O **Perceptron de Rosenblatt** √© um algoritmo para encontrar um hiperplano separador, que √© ajustado iterativamente com base nos erros de classifica√ß√£o [^8.5.1]. O Perceptron inicializa com um hiperplano aleat√≥rio e, em cada itera√ß√£o, ajusta os pesos do hiperplano na dire√ß√£o de classificar corretamente um exemplo mal classificado. O Perceptron tem uma garantia de converg√™ncia para dados linearmente separ√°veis, o que significa que, em um n√∫mero finito de itera√ß√µes, o algoritmo encontra um hiperplano que separa perfeitamente as classes. No entanto, o Perceptron n√£o tem garantia de converg√™ncia quando os dados n√£o s√£o linearmente separ√°veis, [^8.5.1].

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com dois pontos da classe 1: $x_1 = [1, 2]$ e $x_2 = [2, 3]$ e dois pontos da classe -1: $x_3 = [3, 1]$ e $x_4 = [4, 2]$. O perceptron come√ßa com um hiperplano aleat√≥rio, que corresponde a uma linha $w_0 + w_1x_1 + w_2x_2 = 0$. Se inicializarmos os pesos com $w = [0, 0, 0]$, e tomarmos um exemplo errado, como $x_1$, atualizamos o peso com $w \leftarrow w + \eta x_1 y_1$, onde $\eta$ √© a taxa de aprendizado e $y_1=1$. Se escolhermos $\eta=0.1$, a pr√≥xima itera√ß√£o, com $w = [0, 0.1, 0.2]$, deve levar o algoritmo a convergir para um hiperplano que separa as duas classes linearmente ap√≥s algumas itera√ß√µes.

```mermaid
graph LR
    subgraph "Perceptron Algorithm"
        direction TB
        A["Initialize Hyperplane (w)"] --> B["For Misclassified Example (xi)"]
        B --> C["Update Weights: w ‚Üê w + Œ∑xiyi"]
        C --> D["Iterate until Convergence"]
    end
```

### Pergunta Te√≥rica Avan√ßada: Qual a rela√ß√£o entre o bootstrap param√©trico e o estimador de m√°xima verossimilhan√ßa em modelos gaussianos?

**Resposta:**
Em modelos gaussianos com erros aditivos, o bootstrap param√©trico concorda com a solu√ß√£o de m√≠nimos quadrados, que coincide com a solu√ß√£o de m√°xima verossimilhan√ßa. No bootstrap param√©trico, novas respostas s√£o simuladas adicionando ru√≠do gaussiano aos valores preditos, usando a vari√¢ncia estimada a partir dos dados originais. A distribui√ß√£o dos par√¢metros obtida por esse processo coincide, no limite de um grande n√∫mero de amostras bootstrap, com a distribui√ß√£o normal assint√≥tica dos estimadores de m√°xima verossimilhan√ßa [^8.2.2].

*   **Lemma 4:** Em modelos gaussianos com erros aditivos, o bootstrap param√©trico converge para o estimador de m√°xima verossimilhan√ßa √† medida que o n√∫mero de amostras bootstrap tende ao infinito.

*Prova:* Considere o modelo gaussiano $Y = \mu(X) + \epsilon$, onde $\epsilon \sim N(0, \sigma^2)$. No bootstrap param√©trico, simulamos novas respostas $Y^*_i = \hat{\mu}(x_i) + \epsilon^*_i$, com $\epsilon^*_i \sim N(0,\hat{\sigma}^2)$. As estimativas dos par√¢metros $\beta^*$ obtidas por essa reamostragem ter√° a mesma vari√¢ncia assint√≥tica dos estimadores de m√°xima verossimilhan√ßa $\hat{\beta}$ obtidos diretamente, devido a propriedade de consist√™ncia de ambos os estimadores, o que leva a distribui√ß√£o assint√≥tica coincidir no limite de amostras [^8.2.2]. $\blacksquare$

* **Corol√°rio 4:** A vari√¢ncia das estimativas dos par√¢metros obtidas por bootstrap param√©trico em modelos gaussianos √© igual √† vari√¢ncia assint√≥tica dos estimadores de m√°xima verossimilhan√ßa.

*Prova:* Como as m√©dias das distribui√ß√µes convergem para o mesmo valor (estimador de m√°xima verossimilhan√ßa), as vari√¢ncias tamb√©m convergem para a vari√¢ncia assint√≥tica do estimador de m√°xima verossimilhan√ßa, dado que a distribui√ß√£o √© normal no limite [^8.2.2]. $\blacksquare$

> ‚ö†Ô∏è **Ponto Crucial**: O bootstrap param√©trico n√£o s√≥ estima a incerteza associada aos par√¢metros (como o bootstrap n√£o param√©trico), mas tamb√©m replica o comportamento do modelo ajustado com o m√©todo de maximum likelihood, mostrando a conex√£o entre os dois m√©todos para o caso Gaussiano [^8.2.2].

> üí° **Exemplo Num√©rico:**  Considerando novamente o exemplo de regress√£o linear com $X = [1, 2, 3, 4, 5]$ e $Y = [2, 4, 5, 4, 5]$, obtemos os estimadores por m√≠nimos quadrados $\hat{\beta}_0 \approx 0.9$ e $\hat{\beta}_1 \approx 0.7$ e  $\hat{\sigma}^2 \approx 0.3$. O bootstrap param√©trico geraria amostras de $Y^*$ usando o modelo $\hat{y_i} = 0.9 + 0.7x_i + \epsilon_i$, onde $\epsilon_i \sim N(0, 0.3)$. Para cada nova amostra $Y^*$, calculamos novos coeficientes $\hat{\beta_0}^*$ e $\hat{\beta_1}^*$. A vari√¢ncia dessas estimativas converge, no limite de um n√∫mero grande de amostras, para a vari√¢ncia assint√≥tica do estimador de m√°xima verossimilhan√ßa, ilustrando a conex√£o entre o bootstrap param√©trico e o estimador de m√°xima verossimilhan√ßa no caso gaussiano.

```mermaid
graph LR
    subgraph "Parametric Bootstrap vs Maximum Likelihood"
        direction TB
        A["Gaussian Model: Y = Œº(X) + Œµ, Œµ ~ N(0, œÉ¬≤)"] --> B["Parametric Bootstrap: Y*i = ŒºÃÇ(xi) + Œµ*i, Œµ*i ~ N(0, œÉÃÇ¬≤)"]
        B --> C["Distribution of Œ≤ÃÇ* converges to MLE distribution"]
        C --> D["Variance of Œ≤ÃÇ* matches asymptotic variance of MLE"]
    end
```

### Conclus√£o

Neste cap√≠tulo, exploramos uma variedade de t√©cnicas para a **infer√™ncia e amostragem da distribui√ß√£o conjunta posterior**, incluindo *maximum likelihood*, *bootstrap*, m√©todos Bayesianos, modelos de *model averaging* e *stacking*, e m√©todos MCMC com foco em *Gibbs Sampling*. Demonstramos como esses m√©todos podem ser aplicados para problemas de classifica√ß√£o e regress√£o, enfatizando a import√¢ncia da modelagem da incerteza e o papel do *prior* na infer√™ncia Bayesiana. Cada m√©todo apresentou nuances e aplica√ß√µes espec√≠ficas, que foram discutidas com o devido rigor.

<!-- END DOCUMENT -->
### Footnotes
[^8.1]: "In this chapter we provide a general exposition of the maximum likelihood approach, as well as the Bayesian method for inference. The bootstrap, introduced in Chapter 7, is discussed in this context, and its relation to maximum likelihood and Bayes is described. Finally, we present some related techniques for model averaging and improvement, including committee methods, bagging, stacking and bumping."
[^8.2.1]: "The bootstrap method provides a direct computational way of assessing uncertainty, by sampling from the training data. Here we illustrate the bootstrap in a simple one-dimensional smoothing problem, and show its connection to maximum likelihood."
[^8.2.2]: "It turns out that the parametric bootstrap agrees with least squares in the previous example because the model (8.5) has additive Gaussian errors. In general, the parametric bootstrap agrees not with least squares but with maximum likelihood, which we now review."
[^8.4.4]: "The dependence of the log-likelihood l(Œ∏; Z) on the data Z only through the maximum likelihood estimate Œ∏. Hence we can write the log-likelihood as l(Œ∏; ÀÜŒ∏)."
[^8.4.5]: "Properties (2) and (3) essentially only hold for the Gaussian distribution. However, they also hold approximately for the multinomial distribution, leading to a correspondence between the nonparametric bootstrap and Bayes inference, which we outline next."
[^8.5.1]: "The algorithm also makes it clear that a full maximization in the M step is not necessary: we need only to find a value Œ∏(i+1) so that Q(Œ∏', Œ∏(i)) increases as a function of the first argument, that is, Q(Œ∏(i+1),Œ∏(i)) > Q(Œ∏(i),Œ∏(i))."
[^8.5.2]: "Finally, since F(Œ∏', P) and the observed data log-likelihood agree when P(Zm) = Pr(Zm|Z, Œ∏'), maximization of the former accomplishes maxi- mization of the latter. Figure 8.7 shows a schematic view of this process."
