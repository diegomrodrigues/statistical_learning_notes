## Model Inference and Averaging: A Deep Dive into Prior Variance

<imagem: Mapa mental abrangente conectando os conceitos de bootstrap, maximum likelihood, m√©todos Bayesianos e model averaging, com √™nfase na varia√ß√£o da prior variance e suas implica√ß√µes.>

### Introdu√ß√£o
Neste cap√≠tulo, exploramos m√©todos de infer√™ncia e averaging de modelos, com foco nas abordagens de **Maximum Likelihood**, **Bootstrap** e **Bayesiana**.  Os m√©todos de fitting de modelos, que anteriormente foram alcan√ßados pela minimiza√ß√£o de soma de quadrados para regress√£o ou cross-entropy para classifica√ß√£o, s√£o, na verdade, inst√¢ncias da abordagem de **maximum likelihood** [^8.1]. Este cap√≠tulo fornece uma exposi√ß√£o geral desta abordagem, bem como do m√©todo Bayesiano para infer√™ncia, e discute o bootstrap em rela√ß√£o ao maximum likelihood e ao Bayes [^8.1]. Al√©m disso, t√©cnicas relacionadas ao model averaging e model improvement, como m√©todos de comit√™, bagging, stacking e bumping, s√£o apresentadas [^8.1]. O foco deste cap√≠tulo est√° na infer√™ncia e averaging de modelos, utilizando prior variance como vari√°vel chave em abordagens bayesianas.

### Conceitos Fundamentais

**Conceito 1: Maximum Likelihood e sua generaliza√ß√£o**

O **Maximum Likelihood Estimation (MLE)** busca encontrar os par√¢metros de um modelo que maximizam a verossimilhan√ßa (likelihood) dos dados observados [^8.1]. Em termos mais formais, dado um conjunto de dados $Z = \{z_1, z_2, \ldots, z_N\}$ e um modelo param√©trico definido por $g_\theta(z)$, onde $\theta$ representa os par√¢metros do modelo, a fun√ß√£o de verossimilhan√ßa √© dada por:

$$L(\theta; Z) = \prod_{i=1}^{N} g_\theta(z_i)$$
```mermaid
graph LR
    subgraph "Maximum Likelihood Estimation"
        direction TB
        A["Data Set: Z = {z1, z2, ..., zN}"]
        B["Parametric Model: g<sub>Œ∏</sub>(z)"]
        C["Likelihood Function: L(Œ∏; Z) = ‚àè<sub>i=1</sub><sup>N</sup> g<sub>Œ∏</sub>(z<sub>i</sub>)"]
        A --> B
        B --> C
    end
```

O objetivo do MLE √© encontrar o valor de $\theta$ que maximiza $L(\theta; Z)$. Equivalentemente, muitas vezes √© mais conveniente maximizar o log-likelihood, dado por:

$$l(\theta; Z) = \sum_{i=1}^{N} \log g_\theta(z_i)$$

Este conceito √© fundamental para a modelagem estat√≠stica, servindo como base para v√°rios m√©todos de estima√ß√£o [^8.1]. Quando aplicamos a estima√ß√£o de m√°ximo de verossimilhan√ßa, estamos essencialmente escolhendo os par√¢metros que melhor explicam os dados que j√° foram observados, sem incorporarmos uma cren√ßa pr√©via sobre como esses par√¢metros podem se comportar.

> üí° **Exemplo Num√©rico:** Suponha que temos um conjunto de dados com 3 observa√ß√µes (N=3) onde cada $z_i$ representa o resultado de um experimento, e acreditamos que os dados seguem uma distribui√ß√£o normal com m√©dia $\mu$ e desvio padr√£o $\sigma$. O modelo param√©trico √© $g_{\theta}(z_i) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(z_i-\mu)^2}{2\sigma^2}}$, onde $\theta = (\mu, \sigma)$. Digamos que as observa√ß√µes s√£o $Z = \{2, 4, 6\}$. Para estimar os par√¢metros $\mu$ e $\sigma$ por MLE, calculamos o log-likelihood:
>
> $$l(\mu, \sigma; Z) = \sum_{i=1}^{3} \log \left( \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(z_i-\mu)^2}{2\sigma^2}} \right)$$
>
> $$l(\mu, \sigma; Z) = -\frac{3}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^3 (z_i - \mu)^2$$
>
> Para encontrar os par√¢metros $\mu$ e $\sigma$ que maximizam essa fun√ß√£o, podemos utilizar m√©todos num√©ricos. Nesse caso simples, o valor de $\mu$ que maximiza o log-likelihood √© a m√©dia amostral, $\mu = (2+4+6)/3 = 4$. E o valor de $\sigma$ que maximiza √© o desvio padr√£o amostral, que nesse caso seria $\sigma \approx \sqrt{8/3} \approx 1.63$. Portanto, a estimativa de m√°xima verossimilhan√ßa √© $\theta_{MLE} = (4, 1.63)$. Isso significa que, dentro dessa fam√≠lia de distribui√ß√µes normais, a que melhor explica os dados observados √© a normal com m√©dia 4 e desvio padr√£o 1.63.
>
> ```python
> import numpy as np
> from scipy.stats import norm
>
> data = np.array([2, 4, 6])
> mu_mle = np.mean(data)
> sigma_mle = np.std(data, ddof=1) # ddof=1 for sample std
>
> print(f"MLE for mu: {mu_mle:.2f}")
> print(f"MLE for sigma: {sigma_mle:.2f}")
> ```

**Lemma 1:** A estima√ß√£o de m√≠nimos quadrados, utilizada para ajustar modelos de regress√£o linear, √© um caso especial da abordagem de m√°xima verossimilhan√ßa sob a suposi√ß√£o de erros Gaussianos.
**Prova:** Assuma que os erros $\epsilon_i$ seguem uma distribui√ß√£o normal com m√©dia zero e vari√¢ncia $\sigma^2$. Logo, as observa√ß√µes $y_i$ seguem uma distribui√ß√£o normal com m√©dia $\mu(x_i) = \sum_{j=1}^7 \beta_j h_j(x_i)$ e vari√¢ncia $\sigma^2$. A fun√ß√£o de verossimilhan√ßa √© dada por:
$$ L(\beta, \sigma^2; y) = \prod_{i=1}^{N} \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left(-\frac{(y_i - \mu(x_i))^2}{2\sigma^2}\right) $$
Tomando o log-likelihood:
$$ l(\beta, \sigma^2; y) = -\frac{N}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^N (y_i - \mu(x_i))^2 $$
Maximizar $l(\beta, \sigma^2; y)$ em rela√ß√£o a $\beta$ equivale a minimizar $\sum_{i=1}^N (y_i - \mu(x_i))^2$, o que √© precisamente o objetivo da estima√ß√£o de m√≠nimos quadrados. $\blacksquare$
```mermaid
graph LR
    subgraph "Lemma 1: MLE and Least Squares"
        direction TB
        A["Error Assumption: Œµ<sub>i</sub> ~ N(0, œÉ¬≤)"]
        B["Observation Distribution: y<sub>i</sub> ~ N(Œº(x<sub>i</sub>), œÉ¬≤)"]
        C["Likelihood Function: L(Œ≤, œÉ¬≤; y) = ‚àè<sub>i=1</sub><sup>N</sup> (1/‚àö(2œÄœÉ¬≤)) * exp(-(y<sub>i</sub> - Œº(x<sub>i</sub>))¬≤ / (2œÉ¬≤))"]
        D["Log-Likelihood: l(Œ≤, œÉ¬≤; y) = -N/2 * log(2œÄœÉ¬≤) - 1/(2œÉ¬≤) * Œ£<sub>i=1</sub><sup>N</sup> (y<sub>i</sub> - Œº(x<sub>i</sub>))¬≤"]
        E["Minimizing Œ£<sub>i=1</sub><sup>N</sup> (y<sub>i</sub> - Œº(x<sub>i</sub>))¬≤  = Least Squares"]
        C --> D
        D --> E
    end
```
> üí° **Exemplo Num√©rico:** Imagine que estamos modelando a rela√ß√£o entre a √°rea de um apartamento (`x`, em metros quadrados) e seu pre√ßo (`y`, em milhares de reais). Temos um conjunto de dados com 5 apartamentos:
>
> | Apartamento | √Årea (x) | Pre√ßo (y) |
> |------------|----------|----------|
> | 1          | 50       | 300      |
> | 2          | 75       | 450      |
> | 3          | 60       | 380      |
> | 4          | 90       | 550      |
> | 5          | 70       | 420      |
>
> Assumimos um modelo linear $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$ onde $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$. O objetivo do MLE √© encontrar os valores de $\beta_0$ e $\beta_1$ que maximizam a verossimilhan√ßa dos dados. Como demonstrado no Lemma 1, isso √© equivalente a minimizar a soma dos quadrados dos res√≠duos. Resolvendo o problema de m√≠nimos quadrados, obtemos $\beta_0 \approx 52.38$ e $\beta_1 \approx 5.14$. Isso significa que, para cada metro quadrado adicional, o pre√ßo do apartamento aumenta em aproximadamente 5.14 mil reais, com um pre√ßo base de 52.38 mil reais. Este exemplo mostra como a minimiza√ß√£o de m√≠nimos quadrados, uma t√©cnica comum em regress√£o linear, surge naturalmente como um caso especial de MLE sob a suposi√ß√£o de erros Gaussianos.
>
>  ```python
> import numpy as np
> from sklearn.linear_model import LinearRegression
>
> X = np.array([[50], [75], [60], [90], [70]])
> y = np.array([300, 450, 380, 550, 420])
>
> model = LinearRegression()
> model.fit(X, y)
>
> beta_0 = model.intercept_
> beta_1 = model.coef_[0]
>
> print(f"Beta_0 (Intercept): {beta_0:.2f}")
> print(f"Beta_1 (Slope): {beta_1:.2f}")
> ```
>
> Usando os valores estimados de $\beta_0$ e $\beta_1$, podemos fazer previs√µes sobre o pre√ßo de um apartamento com uma dada √°rea. Por exemplo, um apartamento com 80 metros quadrados teria um pre√ßo estimado de aproximadamente $52.38 + 5.14 \times 80 \approx 463.58$ mil reais.

**Conceito 2: Linear Discriminant Analysis (LDA) e sua Rela√ß√£o com Regress√£o Linear**

O **Linear Discriminant Analysis (LDA)** √© uma t√©cnica de classifica√ß√£o que busca encontrar uma combina√ß√£o linear de vari√°veis que melhor separe as classes. Embora n√£o explicitamente abordado no contexto atual, √© relevante destacar a conex√£o entre LDA e regress√£o linear para compreens√£o completa da modelagem. LDA assume que as classes seguem distribui√ß√µes normais com covari√¢ncias iguais [^4.3].
A regress√£o linear, em combina√ß√£o com uma matriz indicadora de classes, tamb√©m pode ser utilizada para fins de classifica√ß√£o [^4.2]. Ambas as abordagens conduzem a fronteiras de decis√£o lineares, mas a LDA possui uma base probabil√≠stica mais robusta sob as suposi√ß√µes de normalidade. A regress√£o linear tenta ajustar um modelo que mapeia as entradas para um vetor de indicadores de classe, enquanto a LDA encontra uma proje√ß√£o linear que maximiza a separabilidade das classes [^4.2], [^4.3]. A regress√£o linear pode ser sens√≠vel a outliers, enquanto a LDA tende a ser mais robusta devido √† sua abordagem de otimiza√ß√£o baseada em dist√¢ncias.

**Corol√°rio 1:** Sob certas condi√ß√µes, a fronteira de decis√£o obtida por LDA pode ser derivada de um modelo de regress√£o linear em uma matriz indicadora, especialmente quando o objetivo principal √© encontrar uma separa√ß√£o linear [^4.2], [^4.3].
```mermaid
graph LR
    subgraph "LDA vs. Linear Regression for Classification"
        direction TB
         A["LDA: Assumes Normal Distribution with Equal Covariances"]
        B["Linear Regression: Uses Indicator Matrix for Classes"]
        C["Both Produce Linear Decision Boundaries"]
        D["LDA: Maximizes Class Separability"]
        E["Linear Regression: Maps Inputs to Class Indicators"]
        F["Linear Regression: Sensitive to Outliers"]
        G["LDA: More Robust"]
        A --> C
        B --> C
        C --> D
        C --> E
        E --> F
        D --> G
    end
```

**Conceito 3: Logistic Regression e a Fun√ß√£o Logit**

A **Logistic Regression** √© uma t√©cnica de classifica√ß√£o que modela a probabilidade de uma vari√°vel bin√°ria (ou categ√≥rica) como uma fun√ß√£o sigmoidal de uma combina√ß√£o linear de vari√°veis preditoras [^4.4]. A fun√ß√£o logit, dada por $logit(p) = \log(\frac{p}{1-p})$, transforma probabilidades no espa√ßo dos n√∫meros reais, permitindo a modelagem com um modelo linear:
$$ \log \left(\frac{p(x)}{1-p(x)}\right) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n $$
Onde $p(x)$ √© a probabilidade de uma observa√ß√£o pertencer a uma classe, dadas as vari√°veis preditoras $x_1, x_2, \ldots, x_n$, e $\beta_0, \beta_1, \beta_2, \ldots, \beta_n$ s√£o os par√¢metros do modelo. A estima√ß√£o dos par√¢metros √© geralmente realizada por meio da **maximization of likelihood** [^4.4.1]. Em contraste com a LDA, que assume normalidade das classes, a regress√£o log√≠stica n√£o requer essa suposi√ß√£o, e pode ser mais adequada em muitos casos. A regress√£o log√≠stica tamb√©m √© menos suscet√≠vel a outliers do que a regress√£o linear, pois modela probabilidades e n√£o valores diretamente. O ajuste do modelo √© baseado na maximiza√ß√£o da likelihood [^4.4.3], que por sua vez est√° ligada √† minimiza√ß√£o do erro, quando log-likelihood √© usado para otimizar uma classifica√ß√£o.
```mermaid
graph LR
    subgraph "Logistic Regression and Logit Function"
        direction TB
        A["Probability: p(x)"]
        B["Logit Function: logit(p) = log(p/(1-p))"]
        C["Linear Model: logit(p(x)) = Œ≤<sub>0</sub> + Œ≤<sub>1</sub>x<sub>1</sub> + ... + Œ≤<sub>n</sub>x<sub>n</sub>"]
        D["Parameter Estimation: Maximization of Likelihood"]
        A --> B
        B --> C
        C --> D
    end
```
> ‚ö†Ô∏è **Nota Importante**: A Regress√£o Log√≠stica modela diretamente a probabilidade de pertencer a uma classe, tornando-a adequada para problemas de classifica√ß√£o, enquanto a regress√£o linear modela valores cont√≠nuos, o que requer passos adicionais para ser utilizada em classifica√ß√£o [^4.4.1].

> ‚ùó **Ponto de Aten√ß√£o**: Em problemas de classifica√ß√£o com classes n√£o-balanceadas, √© crucial utilizar estrat√©gias de balanceamento ou ajustar os par√¢metros do modelo, pois a regress√£o log√≠stica pode ser enviesada em dire√ß√£o √† classe majorit√°ria [^4.4.2].

> ‚úîÔ∏è **Destaque**: As estimativas de par√¢metros em LDA e regress√£o log√≠stica podem estar relacionadas em cen√°rios espec√≠ficos, especialmente quando as classes podem ser linearmente separadas, mas o foco e a aplica√ß√£o de cada m√©todo s√£o diferentes [^4.5].
>
> üí° **Exemplo Num√©rico:** Vamos considerar um exemplo de previs√£o se um cliente vai comprar um produto (1) ou n√£o (0) baseado na sua idade. Suponha que temos os seguintes dados:
>
> | Cliente | Idade (x) | Compra (y) |
> |---------|-----------|------------|
> | 1       | 25        | 0          |
> | 2       | 30        | 0          |
> | 3       | 35        | 1          |
> | 4       | 40        | 1          |
> | 5       | 45        | 1          |
> | 6       | 28        | 0          |
> | 7       | 38        | 1          |
> | 8       | 32        | 0          |
>
> Queremos ajustar um modelo de regress√£o log√≠stica:
>
> $$\log\left(\frac{p(x)}{1-p(x)}\right) = \beta_0 + \beta_1 x$$
>
> Onde $p(x)$ √© a probabilidade de um cliente comprar o produto dado sua idade $x$. Usando a maximiza√ß√£o da verossimilhan√ßa, podemos encontrar os coeficientes do modelo: $\beta_0 \approx -6.0$ e $\beta_1 \approx 0.17$. Isso significa que a probabilidade de um cliente comprar o produto aumenta com a idade. Por exemplo, um cliente de 30 anos tem uma probabilidade estimada de compra de cerca de $p(30) = \frac{1}{1 + e^{-(-6.0 + 0.17 \times 30)}} \approx 0.23$, enquanto um cliente de 40 anos tem uma probabilidade de $p(40) \approx 0.77$. A fun√ß√£o sigmoidal garante que as probabilidades fiquem no intervalo de 0 a 1.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
>
> X = np.array([[25], [30], [35], [40], [45], [28], [38], [32]])
> y = np.array([0, 0, 1, 1, 1, 0, 1, 0])
>
> model = LogisticRegression()
> model.fit(X, y)
>
> beta_0 = model.intercept_[0]
> beta_1 = model.coef_[0][0]
>
> print(f"Beta_0 (Intercept): {beta_0:.2f}")
> print(f"Beta_1 (Slope): {beta_1:.2f}")
>
> # Example prediction
> x_new = np.array([[30], [40]])
> prob = model.predict_proba(x_new)[:, 1]
> print(f"Probability for age 30: {prob[0]:.2f}")
> print(f"Probability for age 40: {prob[1]:.2f}")
> ```

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

<imagem: Diagrama complexo mostrando um fluxo de dados que ilustra a regress√£o linear sendo utilizada para classifica√ß√£o. Come√ßa com a codifica√ß√£o das classes, segue com a estima√ß√£o dos coeficientes por m√≠nimos quadrados e finaliza com uma regra de decis√£o.  Inclui tamb√©m compara√ß√µes com abordagens probabil√≠sticas, mostrando os pr√≥s e contras de cada m√©todo.>

A regress√£o linear pode ser aplicada a problemas de classifica√ß√£o por meio da codifica√ß√£o das classes utilizando uma matriz indicadora, ou seja, criando um vetor $y$ onde cada elemento $y_i$ indica a qual classe a $i$-√©sima observa√ß√£o pertence [^4.2]. Em um cen√°rio de classifica√ß√£o bin√°ria, por exemplo, uma classe pode ser codificada como 0 e a outra como 1. A regress√£o linear tenta ent√£o ajustar um modelo linear que mapeia as vari√°veis preditoras para esses valores de classe. As previs√µes geradas pelo modelo s√£o ent√£o interpretadas como probabilidades ou podem ser usadas para gerar classifica√ß√µes.

Apesar da simplicidade, este m√©todo pode apresentar limita√ß√µes, especialmente quando a rela√ß√£o entre as vari√°veis preditoras e as classes n√£o √© linear ou quando as classes n√£o s√£o linearmente separ√°veis. Um problema surge quando a regress√£o linear gera previs√µes fora do intervalo [0, 1], dificultando sua interpreta√ß√£o como probabilidades.

**Lemma 2:** Em um problema de classifica√ß√£o bin√°ria, se as classes s√£o linearmente separ√°veis e as vari√¢ncias dentro das classes s√£o iguais, a regress√£o linear em uma matriz de indicadores e a an√°lise discriminante linear (LDA) produzir√£o a mesma fronteira de decis√£o.
**Prova:** Em um cen√°rio onde as classes s√£o linearmente separ√°veis, o ajuste da regress√£o linear visa encontrar um hiperplano que separa as classes. De forma semelhante, o LDA tenta encontrar uma proje√ß√£o linear que maximize a separa√ß√£o das classes, que resulta em um hiperplano de decis√£o. Quando as vari√¢ncias dentro das classes s√£o iguais e as classes s√£o linearmente separ√°veis, os hiperplanos obtidos por ambos os m√©todos ser√£o equivalentes. Esta equival√™ncia surge da otimiza√ß√£o que ambos os m√©todos realizam, mesmo com abordagens diferentes: LDA maximiza a separa√ß√£o entre as classes, e regress√£o linear minimiza os erros entre as previs√µes e os indicadores de classe. $\blacksquare$
```mermaid
graph LR
    subgraph "Lemma 2: Equivalence of Linear Regression and LDA"
        direction TB
        A["Linear Separability of Classes"]
        B["Equal Within-Class Variances"]
        C["Linear Regression: Finds Hyperplane"]
        D["LDA: Maximizes Class Separation (Hyperplane)"]
        E["Result: Same Decision Boundary"]
        A --> C
        A --> D
        B --> C
        B --> D
        C & D --> E
    end
```

**Corol√°rio 2:** A equival√™ncia mencionada no Lemma 2 implica que, em certos cen√°rios, a regress√£o linear pode ser vista como uma aproxima√ß√£o para LDA, com a vantagem de ser computacionalmente mais simples e de n√£o requerer as suposi√ß√µes de normalidade feitas pelo LDA [^4.3].
> üí° **Exemplo Num√©rico:** Suponha que temos um problema de classifica√ß√£o bin√°ria com duas classes (0 e 1) e uma √∫nica vari√°vel preditora (x). Os dados s√£o os seguintes:
>
> | Observa√ß√£o | x    | Classe (y) |
> |------------|------|------------|
> | 1          | 1    | 0          |
> | 2          | 2    | 0          |
> | 3          | 3    | 0          |
> | 4          | 4    | 1          |
> | 5          | 5    | 1          |
> | 6          | 6    | 1          |
>
> Aplicamos a regress√£o linear, codificando as classes como 0 e 1. Ajustamos o modelo: $y = \beta_0 + \beta_1 x$. A solu√ß√£o de m√≠nimos quadrados nos d√° $\beta_0 \approx -0.83$ e $\beta_1 \approx 0.33$. A fronteira de decis√£o (onde a regress√£o prev√™ 0.5) √© encontrada quando $-0.83 + 0.33x = 0.5$, que resulta em $x \approx 4$. Portanto, se a regress√£o linear prever um valor maior que 0.5, classificamos a observa√ß√£o como classe 1, caso contr√°rio, como classe 0.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LinearRegression
>
> X = np.array([[1], [2], [3], [4], [5], [6]])
> y = np.array([0, 0, 0, 1, 1, 1])
>
> model = LinearRegression()
> model.fit(X, y)
>
> beta_0 = model.intercept_
> beta_1 = model.coef_[0]
>
> print(f"Beta_0: {beta_0:.2f}")
> print(f"Beta_1: {beta_1:.2f}")
>
> # Decision boundary
> decision_boundary = (0.5 - beta_0) / beta_1
> print(f"Decision boundary (x): {decision_boundary:.2f}")
> ```
>
> Neste exemplo simples, a fronteira de decis√£o gerada pela regress√£o linear √© $x \approx 4$, que separa as classes. Embora funcional para este exemplo, a regress√£o linear n√£o garante previs√µes entre 0 e 1, o que limita sua interpretabilidade direta como probabilidades, como discutido no texto.

A regress√£o linear aplicada √† classifica√ß√£o pode levar a problemas de **extrapola√ß√£o**, onde as previs√µes podem assumir valores fora do intervalo [0,1], dificultando a interpreta√ß√£o dessas previs√µes como probabilidades [^4.4]. Embora a regress√£o linear possa fornecer uma fronteira de decis√£o linear, ela n√£o est√° diretamente calibrada para fornecer probabilidades confi√°veis. Nestes casos, a regress√£o log√≠stica, com sua fun√ß√£o sigmoidal, fornece probabilidades mais est√°veis e interpret√°veis [^4.4]. Por outro lado, em algumas situa√ß√µes a regress√£o linear na matriz de indicadores pode ser suficiente, e mesmo vantajosa, quando o objetivo principal √© a obten√ß√£o de uma fronteira de decis√£o linear [^4.2]. A escolha do m√©todo mais apropriado depende das caracter√≠sticas espec√≠ficas do problema em quest√£o, e ambos podem ser √∫teis.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem:  Diagrama em formato de mapa mental que conecta t√©cnicas de regulariza√ß√£o (L1 e L2) e sele√ß√£o de vari√°veis com os principais modelos de classifica√ß√£o (LDA, regress√£o log√≠stica). As conex√µes mostram como a regulariza√ß√£o e sele√ß√£o influenciam o ajuste, a interpretabilidade e a capacidade de generaliza√ß√£o de cada m√©todo.>

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas importantes para evitar overfitting e melhorar a capacidade de generaliza√ß√£o dos modelos de classifica√ß√£o [^4.5]. Estas t√©cnicas s√£o especialmente importantes quando o n√∫mero de vari√°veis preditoras √© alto em rela√ß√£o ao n√∫mero de observa√ß√µes.

A regulariza√ß√£o adiciona um termo de penalidade √† fun√ß√£o de custo, controlando a complexidade do modelo. As penalidades mais comuns s√£o L1 (Lasso) e L2 (Ridge). A penalidade L1, dada por $\lambda \sum_{j=1}^n |\beta_j|$, promove a esparsidade do modelo, levando alguns coeficientes a serem exatamente zero, realizando sele√ß√£o de vari√°veis. A penalidade L2, dada por $\lambda \sum_{j=1}^n \beta_j^2$, reduz a magnitude dos coeficientes, tornando o modelo mais est√°vel.

Em modelos log√≠sticos, a regulariza√ß√£o √© incorporada na fun√ß√£o de log-likelihood:

$$ l(\beta) - \lambda_1 \sum_{j=1}^n |\beta_j| - \lambda_2 \sum_{j=1}^n \beta_j^2 $$

onde $\lambda_1$ e $\lambda_2$ controlam a for√ßa das penalidades L1 e L2, respectivamente [^4.4.4]. Esta fun√ß√£o de custo combinada de log-likelihood e penalidades √© fundamental para controlar a complexidade do modelo, evitando o overfitting e melhorando a sua interpretabilidade.

**Lemma 3:** A penaliza√ß√£o L1 na regress√£o log√≠stica leva a coeficientes esparsos, pois o termo de penaliza√ß√£o for√ßa a que alguns dos coeficientes sejam exatamente zero.
**Prova:** O termo de penaliza√ß√£o L1, $\lambda \sum_{j=1}^n |\beta_j|$, adiciona um termo de penaliza√ß√£o na fun√ß√£o de custo, fazendo com que os coeficientes sejam exatamente zero para algumas das vari√°veis. Isso ocorre porque a penalidade L1 induz uma solu√ß√£o onde um n√∫mero de coeficientes $\beta_j$ √© igual a zero. O ponto onde a fun√ß√£o de custo penalizada √© minimizada tende a ocorrer em um "canto" da regi√£o admiss√≠vel, onde alguns $\beta_j$ s√£o zerados [^4.4.4]. Essa caracter√≠stica √© especialmente importante para a sele√ß√£o de vari√°veis, pois as vari√°veis com coeficientes zero podem ser consideradas irrelevantes.  A magnitude do par√¢metro de regulariza√ß√£o $\lambda$ controla o n√≠vel de esparsidade, com maiores valores de $\lambda$ resultando em modelos mais esparsos. $\blacksquare$
```mermaid
graph LR
    subgraph "Lemma 3: L1 Regularization and Sparsity"
        direction TB
        A["L1 Penalty Term: ŒªŒ£<sub>j=1</sub><sup>n</sup> |Œ≤<sub>j</sub>|"]
        B["Added to Log-Likelihood Cost Function"]
        C["Induces Sparse Solutions: Some Œ≤<sub>j</sub> = 0"]
        D["Minimization at 'Corner' of Admissible Region"]
        E["Variable Selection: Zeroed Coefficients"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

**Corol√°rio 3:** A esparsidade induzida pela penaliza√ß√£o L1 leva a modelos mais interpret√°veis, pois apenas as vari√°veis preditoras mais relevantes s√£o mantidas no modelo final. Os coeficientes n√£o-nulos indicam as vari√°veis que t√™m maior impacto na classifica√ß√£o.

> ‚ö†Ô∏è **Ponto Crucial**: A penaliza√ß√£o L1 e L2 podem ser combinadas utilizando o Elastic Net, que combina os efeitos de ambas, oferecendo flexibilidade e um controle mais preciso sobre a complexidade e esparsidade do modelo [^4.5].
>
> üí° **Exemplo Num√©rico:** Vamos usar um exemplo de classifica√ß√£o de texto para spam (1) ou n√£o spam (0). Temos 5 vari√°veis preditoras (x1 a x5), que representam a frequ√™ncia de algumas palavras chaves em um email. Os dados s√£o os seguintes:
>
> | Email | x1  | x2 | x3  | x4  | x5  | Spam (y) |
> |-------|-----|----|-----|-----|-----|----------|
> | 1     | 2   | 1  | 0   | 3   | 1   | 0        |
> | 2     | 0   | 4  | 2   | 1   | 0   | 1        |
> | 3     | 1   | 1  | 1   | 2   | 0   | 0        |
> | 4     | 3   | 0  | 4   | 0   | 2   | 1        |
> | 5     | 1   | 2  | 0   | 1   | 1   | 0        |
> | 6     | 2   | 3  | 1   | 2   | 0   | 1        |
>
> Aplicamos regress√£o log√≠stica com regulariza√ß√£o L1 (Lasso), e ajustamos o par√¢metro de regulariza√ß√£o $\lambda$ para 0.5. O modelo resultante pode ter alguns coeficientes $\beta_j$ iguais a zero, indicando que as vari√°veis correspondentes n√£o s√£o importantes para a classifica√ß√£o. Suponha que ap√≥s a regulariza√ß√£o, encontramos os seguintes coeficientes: $\beta_0 \approx -1.5$, $\beta_1 \approx 0.8$, $\beta_2 = 0$, $\beta_3 \approx 1.2$, $\beta_4 = 0$, $\beta_5 \approx -0.5$. Isso indica que as vari√°veis x2 e x4 foram eliminadas pelo Lasso, e as vari√°veis x1, x3 e x5 s√£o mais relevantes para a classifica√ß√£o de spam. O valor dos coeficientes indica a dire√ß√£o e a magnitude da rela√ß√£o entre a vari√°vel e a probabilidade de ser spam.
>
>  ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
>
> X = np.array([[2, 1, 0, 3, 1],
>               [0, 4, 2, 1, 0],
>               [1, 1, 1, 2, 0],
>               [3, 0, 4, 0, 2],
>               [1, 2, 0, 1, 1],
>               [2, 3, 1, 2, 0]])
> y = np.array([0, 1, 0, 1, 0, 1])
>
> model = LogisticRegression(penalty='l1', solver='liblinear', C=2) # C is inverse of lambda
> model.fit(X, y)
>
> beta_0 = model.intercept_[0]
> beta = model.coef_[0]
>
> print(f"Beta_0 (Intercept): {beta_0:.2f}")
> print(f"Beta coefficients: {beta}")
> ```
> Nesse exemplo, o uso de regulariza√ß√£o L1 leva √† sele√ß√£o de um subconjunto de vari√°veis relevantes (x1, x3, x5) para o modelo, melhorando a interpretabilidade e potencialmente prevenindo overfitting.

### Separating Hyperplanes e Perceptrons

O conceito de **Separating Hyperplanes** √© fundamental em modelos de classifica√ß√£o linear. A ideia central √© encontrar um hiperplano que maximize a margem de separa√ß√£o entre as classes [^4.5.2]. Matematicamente, o problema pode ser formulado como encontrar um vetor normal $w$ e um offset $b$ tal que:

$$ w^T x_i + b > 0 \text{ para } x_i \text{ da classe 1} $$
$$ w^T x_i + b < 0 \text{ para } x_i \text{ da classe 0} $$

A maximiza√ß√£o da margem √© um problema de otimiza√ß√£o que pode ser resolvido usando a dualidade de Wolfe [^4.5.2]. As solu√ß√µes deste problema s√£o expressas como combina√ß√µes lineares dos **pontos de suporte**, que s√£o as observa√ß√µes mais pr√≥ximas da fronteira de decis√£o.

O Perceptron de Rosenblatt √© um algoritmo que busca encontrar um hiperplano separador por meio de um processo iterativo [^4.5.1]. O algoritmo inicializa os pesos de um vetor $w$ aleatoriamente, e a cada itera√ß√£o, ele atualiza os pesos com base nas observa√ß√µes que foram classificadas incorretamente. Sob a condi√ß√£o de que as classes sejam linearmente separ√°veis, o Perceptron converge para um hiperplano de decis√£o.
```mermaid
graph LR
    subgraph "Separating Hyperplanes and Perceptron"
        direction TB
        A["Objective: Find Hyperplane Separating Classes"]
        B["Hyperplane Definition: w<sup>T</sup>x<sub>i</sub> + b > 0 for class 1 and w<sup>T</sup>x<sub>i</sub> + b < 0 for class 0"]
        C["Optimization: Maximize Margin"]
        D["Perceptron: Iterative Algorithm to find Hyperplane"]
        E["Perceptron: Updates weights based on misclassifications"]
        F["Perceptron: Converges to separating hyperplane if classes are linearly separable"]
        A --> B
        B --> C
        A --> D
        D --> E
        E --> F

    end
```
> üí° **Exemplo Num√©rico:** Imagine que temos um conjunto de dados bidimensional com duas classes, representadas por c√≠rculos e tri√¢ngulos:
>
> ```mermaid
> graph LR
>     A(2,2 - circle)-->|Class 0| D
>     B(1,3 - circle)-->|Class 0| D
>     C(3,1 - circle)-->|Class 0| D
>     E(5,4 - triangle)-->|Class 1| F
>     G(6,2 - triangle)-->|Class 1| F
>     H(7,3 - triangle)-->|Class 1| F
>     D[Class 0]
>     F[Class 1]
> ```
>
> Os pontos da classe 0 s√£o A(2,2), B(1,3), C(3,1), e os pontos da classe 1 s√£o E(5,4), G(6,2), H(7,3). O perceptron tentar√° encontrar um hiper