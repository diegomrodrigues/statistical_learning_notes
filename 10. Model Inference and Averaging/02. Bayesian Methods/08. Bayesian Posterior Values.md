## Bayesian Posterior Function Values

<imagem: Mapa mental conectando os conceitos de prior, likelihood, posterior e predictive distribution, destacando como a infer√™ncia Bayesiana combina essas informa√ß√µes para gerar conclus√µes. Uma imagem de um gr√°fico mostrando fun√ß√µes posteriores com diferentes graus de vari√¢ncia dependendo do prior usado.>

### Introdu√ß√£o
O cap√≠tulo aborda o tema de **Infer√™ncia e Modelagem Bayesiana**, com foco particular na constru√ß√£o de fun√ß√µes **posteriores** para an√°lise estat√≠stica e predi√ß√£o [^8.1]. A infer√™ncia Bayesiana √© uma metodologia que difere da abordagem cl√°ssica ou frequentista, pois incorpora uma **distribui√ß√£o a priori** para os par√¢metros do modelo, representando o conhecimento pr√©vio sobre esses par√¢metros. Ao combinar essa priori com a fun√ß√£o de verossimilhan√ßa (likelihood) dos dados observados, obt√©m-se a **distribui√ß√£o posterior**, que resume o conhecimento atualizado sobre os par√¢metros ap√≥s a observa√ß√£o dos dados. A fun√ß√£o posterior √© o cerne da an√°lise Bayesiana, pois ela nos permite fazer infer√™ncias, quantificar incertezas e fazer predi√ß√µes sobre novos dados, como abordado em [^8.1], [^8.3].

```mermaid
graph LR
    A["Par√¢metros (Œ∏)"]
    B["Distribui√ß√£o a Priori (Pr(Œ∏))"]
    C["Dados Observados (Z)"]
    D["Fun√ß√£o de Verossimilhan√ßa (Pr(Z|Œ∏))"]
    E["Distribui√ß√£o Posterior (Pr(Œ∏|Z))"]
    B --> E
    D --> E
    A --> B
    A --> D
    C --> D
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style E fill:#ccf,stroke:#333,stroke-width:2px
    linkStyle 0,1,2,3,4 stroke-width:2px;
```

### Conceitos Fundamentais
**Conceito 1: Distribui√ß√£o a Priori (Prior)**
Em Bayesian Inference, a **distribui√ß√£o a priori**, denotada por $Pr(\theta)$, √© usada para expressar cren√ßas sobre os par√¢metros do modelo ($\theta$) antes de observar os dados. Essa distribui√ß√£o reflete o conhecimento pr√©vio, a expertise do dom√≠nio ou mesmo uma aus√™ncia de informa√ß√£o inicial [^8.3]. A escolha da prior pode influenciar o resultado da an√°lise, e por isso, deve ser feita com cuidado e justificativa. Existem prioris n√£o-informativas (como a prior constante no contexto discutido [^8.4]) que minimizam a influ√™ncia da prior na posterior, mas tamb√©m existem prioris informativas que introduzem conhecimento pr√©vio na modelagem.

**Lemma 1:** *A prior n√£o-informativa para um par√¢metro escalar $\theta$ pode ser definida como uma distribui√ß√£o uniforme ou constante sobre um intervalo muito amplo. No limite, essa prior converge para uma constante, significando que todos os valores de $\theta$ s√£o igualmente prov√°veis a priori*. A constante n√£o afeta a infer√™ncia bayesiana, pois o termo de normaliza√ß√£o da posterior a cancela [^8.4].

> üí° **Exemplo Num√©rico:**  Suponha que estamos modelando a probabilidade de um evento ocorrer, e nosso par√¢metro $\theta$ √© essa probabilidade. Uma prior n√£o-informativa poderia ser uma distribui√ß√£o uniforme entre 0 e 1, que √© expressa como  $Pr(\theta) = 1$ para $0 \leq \theta \leq 1$ e $0$ caso contr√°rio. Isso significa que, antes de observar qualquer dado, consideramos que todos os valores de probabilidade entre 0 e 1 s√£o igualmente plaus√≠veis. A constante aqui √© 1, e ela se cancelar√° quando calcularmos a posterior.

**Conceito 2: Fun√ß√£o de Verossimilhan√ßa (Likelihood)**
A **fun√ß√£o de verossimilhan√ßa**, denotada por $Pr(Z|\theta)$, expressa a probabilidade dos dados observados (Z), dado um valor espec√≠fico dos par√¢metros ($\theta$). A verossimilhan√ßa √© fundamental para ligar o modelo aos dados, e sua forma √© determinada pela distribui√ß√£o estat√≠stica que modela o processo gerador dos dados [^8.2.2]. O objetivo da infer√™ncia √© encontrar os par√¢metros que tornam os dados observados mais prov√°veis. Uma verossimilhan√ßa gaussiana como discutida no contexto [^8.2.2] √© uma escolha comum para erros aditivos.

```mermaid
graph LR
    A["Par√¢metros (Œ∏)"]
    B["Dados Observados (Z)"]
    C["Distribui√ß√£o Estat√≠stica"]
    D["Fun√ß√£o de Verossimilhan√ßa (Pr(Z|Œ∏))"]
    A --> D
    B --> D
    C --> D
    style D fill:#fcc,stroke:#333,stroke-width:2px
    linkStyle 0,1,2 stroke-width:2px;
```

**Corol√°rio 1:** *No caso de erros Gaussianos, a maximiza√ß√£o da verossimilhan√ßa √© equivalente a minimizar a soma dos erros quadr√°ticos, como demonstrado no exemplo de suaviza√ß√£o de spline c√∫bico [^8.2.2], [^8.2.3]*.

> üí° **Exemplo Num√©rico:** Considere um problema de regress√£o linear com dados $(x_i, y_i)$, onde $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$, e $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$. A verossimilhan√ßa para um conjunto de dados Z √© dada por:
>
> $$Pr(Z|\beta_0, \beta_1, \sigma^2) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left( -\frac{(y_i - \beta_0 - \beta_1 x_i)^2}{2\sigma^2} \right).$$
>
> Maximizar essa verossimilhan√ßa com rela√ß√£o a $\beta_0$ e $\beta_1$ √© equivalente a minimizar a soma dos quadrados dos erros:
>
>  $$\text{minimize} \sum_{i=1}^{n} (y_i - \beta_0 - \beta_1 x_i)^2.$$

**Conceito 3: Distribui√ß√£o Posterior**
A **distribui√ß√£o posterior**, denotada por $Pr(\theta|Z)$, √© o resultado da combina√ß√£o da distribui√ß√£o a priori com a fun√ß√£o de verossimilhan√ßa, segundo a regra de Bayes [^8.3]. Ela representa a probabilidade dos par√¢metros ap√≥s considerar os dados observados. A forma da posterior resume o que foi aprendido a partir da combina√ß√£o da cren√ßa inicial e da evid√™ncia dos dados.
$$
Pr(\theta|Z) = \frac{Pr(Z|\theta) \cdot Pr(\theta)}{\int Pr(Z|\theta) \cdot Pr(\theta) \, d\theta}
$$
Onde o denominador √© o termo de normaliza√ß√£o e assegura que a posterior seja uma distribui√ß√£o de probabilidade.

> ‚ö†Ô∏è **Nota Importante:** A distribui√ß√£o posterior √© uma distribui√ß√£o probabil√≠stica, e n√£o um valor √∫nico para os par√¢metros. Isso √© fundamental na infer√™ncia Bayesiana, pois reflete a incerteza sobre o valor dos par√¢metros ap√≥s a observa√ß√£o dos dados [^8.3].

> üí° **Exemplo Num√©rico:**  Vamos supor que temos uma moeda e queremos estimar a probabilidade $\theta$ de obter cara. Nossa prior √© que a moeda √© justa, expressa como $\theta \sim \text{Beta}(1, 1)$, que √© uma prior uniforme entre 0 e 1. Agora, jogamos a moeda 10 vezes e obtivemos 7 caras (Z). A verossimilhan√ßa √© modelada por uma distribui√ß√£o binomial:  $Pr(Z|\theta) = \binom{10}{7} \theta^7 (1-\theta)^3$. A posterior, portanto, ser√° proporcional a $\theta^7 (1-\theta)^3 \cdot 1$, que √© uma distribui√ß√£o beta com par√¢metros 8 e 4. Assim,  $Pr(\theta|Z) \propto \text{Beta}(8,4)$. A distribui√ß√£o posterior representa a nossa cren√ßa atualizada sobre $\theta$, levando em conta os dados.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
<imagem: Diagrama mostrando a rela√ß√£o entre regress√£o linear, m√≠nimos quadrados e infer√™ncia Bayesiana, destacando como a regress√£o pode ser vista como um caso especial da abordagem Bayesiana com uma prior n√£o-informativa. Diagrama mostrando a influ√™ncia da prior na fun√ß√£o posterior e como diferentes valores de œÑ (vari√¢ncia da prior) afetam a suavidade da curva estimada.>
```mermaid
graph LR
    subgraph "Bayesian Linear Regression"
        direction TB
        A["Dados (Z)"]
        B["Fun√ß√£o de Verossimilhan√ßa (Pr(Z|Œ≤, œÉ¬≤))"]
        C["Prior para os Par√¢metros (Pr(Œ≤))"]
        D["Distribui√ß√£o Posterior (Pr(Œ≤|Z))"]
        E["Estimativa Bayesiana de Œ≤"]
        A --> B
        B --> D
        C --> D
        D --> E
    end
    subgraph "Classical Linear Regression"
        direction TB
        F["Dados (Z)"]
        G["Minimizar Soma dos Erros Quadr√°ticos"]
        H["Estimativa de M√≠nimos Quadrados de Œ≤"]
        F --> G
        G --> H
    end
     linkStyle 0,1,2,3,4,5,6 stroke-width:2px;
```
**Explica√ß√£o:** O diagrama ilustra como a regress√£o linear e m√≠nimos quadrados podem ser vistas como um caso particular da infer√™ncia Bayesiana quando usamos uma prior n√£o-informativa.
Em problemas de regress√£o linear, como o abordado no contexto [^8.2.1] com o ajuste de splines c√∫bicas, o m√©todo dos m√≠nimos quadrados √© amplamente utilizado para encontrar os par√¢metros $\beta$ que minimizam a soma dos erros quadr√°ticos. Na vis√£o Bayesiana, isso corresponde √† maximiza√ß√£o da verossimilhan√ßa, quando assumimos erros Gaussianos [^8.2.2].
No entanto, a infer√™ncia Bayesiana vai al√©m, introduzindo uma prior sobre os par√¢metros $\beta$. Como discutido no contexto, podemos definir uma prior Gaussiana centrada em zero com uma dada matriz de covari√¢ncia [^8.3]:
$$\beta \sim N(0, \tau\Sigma)$$
onde $\tau$ controla a for√ßa da prior e $\Sigma$ a estrutura de correla√ß√£o entre as componentes do vetor $\beta$. Esta prior representa nossa cren√ßa sobre os valores dos par√¢metros antes de observar os dados. A combina√ß√£o desta prior com a fun√ß√£o de verossimilhan√ßa (que tamb√©m √© Gaussiana no caso dos erros Gaussianos) resulta numa distribui√ß√£o posterior tamb√©m Gaussiana [^8.3]:
$$
    E(\beta|Z) = (H^T H + \frac{\sigma^2}{\tau} \Sigma^{-1})^{-1} H^T y
$$
e
$$
    cov(\beta|Z) = \sigma^2 (H^T H + \frac{\sigma^2}{\tau} \Sigma^{-1})^{-1}
$$
onde H √© a matriz de desenho e $\sigma^2$ √© a vari√¢ncia do erro.
A escolha do par√¢metro $\tau$ afeta a influ√™ncia da prior na posterior. Quando $\tau$ √© muito grande (prior n√£o-informativa), a posterior se aproxima da solu√ß√£o de m√≠nimos quadrados. Quando $\tau$ √© pequeno, a posterior √© mais influenciada pela prior, resultando em solu√ß√µes mais suaves, como ilustrado no contexto [^8.3].
Este exemplo demonstra como a infer√™ncia Bayesiana n√£o apenas estima os par√¢metros $\beta$, mas tamb√©m fornece uma distribui√ß√£o sobre eles, quantificando a incerteza associada √†s estimativas.
**Lemma 2:** *A distribui√ß√£o posterior obtida sob erros Gaussianos e prior Gaussiana para os par√¢metros tamb√©m √© Gaussiana. Os par√¢metros da posterior s√£o fun√ß√µes da m√©dia e covari√¢ncia a prior, e da m√©dia e covari√¢ncia da verossimilhan√ßa*. Isso implica que a infer√™ncia bayesiana neste caso tem uma solu√ß√£o anal√≠tica.
**Corol√°rio 2:** *No limite de uma prior n√£o-informativa ($\tau \rightarrow \infty$), a m√©dia da posterior para os par√¢metros beta corresponde √† solu√ß√£o de m√≠nimos quadrados, mostrando que a regress√£o linear √© um caso especial da an√°lise Bayesiana*.

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o linear com dois preditores e um intercepto:  $y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon$, onde $\epsilon \sim \mathcal{N}(0, \sigma^2)$.
> Suponha que temos os seguintes dados:
>
> ```python
> import numpy as np
>
> # Dados
> X = np.array([[1, 2, 3],
>               [1, 3, 4],
>               [1, 4, 2],
>               [1, 5, 5],
>               [1, 6, 3]])
> y = np.array([5, 6, 7, 8, 9])
> sigma2 = 1 # Vari√¢ncia do erro
> tau = 1 # Vari√¢ncia da prior
> Sigma = np.eye(3) # Matriz de covari√¢ncia da prior (identidade)
> ```
>
>  Aqui, a matriz de desenho H √© `X`, y √© o vetor de respostas, $\sigma^2 = 1$, $\tau = 1$ e $\Sigma$ √© a matriz identidade.
>  A m√©dia da posterior √© dada por:
>
> $\text{Step 1: } \text{Calculate } H^T H$:
> ```python
> HTH = X.T @ X
> print("H^T H:\n", HTH)
> ```
> $\text{Step 2: } \text{Calculate } \frac{\sigma^2}{\tau} \Sigma^{-1}$:
> ```python
> sigma2_tau_Sigma_inv = (sigma2 / tau) * np.linalg.inv(Sigma)
> print("(sigma^2/tau) * Sigma^-1:\n", sigma2_tau_Sigma_inv)
> ```
> $\text{Step 3: } \text{Calculate } (H^T H + \frac{\sigma^2}{\tau} \Sigma^{-1})^{-1}$:
> ```python
> inv_term = np.linalg.inv(HTH + sigma2_tau_Sigma_inv)
> print("(H^T H + (sigma^2/tau) * Sigma^-1)^-1:\n", inv_term)
> ```
> $\text{Step 4: } \text{Calculate } H^T y$:
> ```python
> HTy = X.T @ y
> print("H^T y:\n", HTy)
> ```
> $\text{Step 5: } \text{Calculate } E(\beta|Z)$:
> ```python
> E_beta = inv_term @ HTy
> print("E(beta|Z):\n", E_beta)
> ```
> O resultado √© $E(\beta|Z) \approx [3.44, 0.53, 0.65]$.  Se aumentarmos $\tau$ para 100 (prior n√£o-informativa), a m√©dia da posterior se aproxima da solu√ß√£o de m√≠nimos quadrados. A covari√¢ncia da posterior pode ser calculada de forma similar.
>
> Este exemplo mostra numericamente como a infer√™ncia Bayesiana combina a prior e os dados para estimar os par√¢metros e como $\tau$ influencia a estimativa.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem: Mapa mental que ilustra como a regulariza√ß√£o pode ser vista no contexto Bayesiano como uma forma de definir uma prior informativas sobre os coeficientes, reduzindo a complexidade do modelo e o overfitting. Diagrama mostrando o efeito de regulariza√ß√£o (L1 e L2) na fun√ß√£o posterior.>
```mermaid
graph LR
    subgraph "Regularization as Prior"
    direction TB
        A["Regularization Method"]
        B["Prior Distribution on Coefficients"]
        C["L1 Regularization (Lasso)"]
        D["Laplace Prior (Sparse)"]
        E["L2 Regularization (Ridge)"]
        F["Gaussian Prior (Small Values)"]
        A --> B
        A --> C
        A --> E
        C --> D
        E --> F
        B --> D
        B --> F
    end
    linkStyle 0,1,2,3,4,5,6 stroke-width:2px;
```
No contexto bayesiano, a regulariza√ß√£o pode ser interpretada como a aplica√ß√£o de prioris informativas sobre os coeficientes do modelo [^8.3], [^8.4]. A penaliza√ß√£o L1 (Lasso) imp√µe uma prior Laplaceana sobre os coeficientes, promovendo a esparsidade (isto √©, fazendo com que alguns coeficientes sejam exatamente zero) [^8.2.2], [^8.4]. A penaliza√ß√£o L2 (Ridge) imp√µe uma prior Gaussiana sobre os coeficientes, promovendo coeficientes menores em magnitude, mas geralmente n√£o exatamente zero [^8.2.2], [^8.4].

**Lemma 3:** *A prior Laplaceana sobre os coeficientes induz esparsidade na solu√ß√£o posterior, pois a densidade de probabilidade √© m√°xima em zero, como discutido no contexto, e promove solu√ß√µes com muitos coeficientes nulos*.
**Prova do Lemma 3:** A fun√ß√£o densidade da distribui√ß√£o Laplaceana √© dada por $p(\beta_j) = \frac{1}{2\lambda} e^{-|\beta_j|/\lambda}$. Quando maximizamos a posterior (ou minimizamos o negativo do logaritmo da posterior), o termo da prior corresponde a um termo de penaliza√ß√£o L1 na fun√ß√£o de custo a ser minimizada. Isso √©: $-\log p(\beta) \propto \sum_j |\beta_j|$. O termo de penaliza√ß√£o L1 for√ßa alguns coeficientes a serem nulos na solu√ß√£o √≥tima. $\blacksquare$

**Corol√°rio 3:** *A esparsidade resultante da regulariza√ß√£o L1 torna o modelo mais interpret√°vel, pois apenas um subconjunto dos par√¢metros tem influ√™ncia significativa na previs√£o*.

> üí° **Exemplo Num√©rico:**  Suponha que temos um problema de regress√£o com 10 preditores, e queremos selecionar um subconjunto deles. Usando o Lasso (regulariza√ß√£o L1), estamos implicitamente aplicando uma prior Laplaceana sobre os coeficientes. Por exemplo, com um valor de $\lambda$ adequado, o modelo pode for√ßar alguns coeficientes, digamos $\beta_3, \beta_5, \beta_7$ a serem exatamente zero, indicando que esses preditores n√£o s√£o importantes para o modelo. O gr√°fico da prior Laplaceana mostra uma "ponta" em zero, o que incentiva os coeficientes a serem exatamente zero. Em contraste, usando Ridge (L2), a prior Gaussiana n√£o leva os coeficientes a zero, mas a valores menores.
>
> Vamos simular dados e aplicar Lasso e Ridge:
>
> ```python
> import numpy as np
> from sklearn.linear_model import Lasso, Ridge
> from sklearn.preprocessing import StandardScaler
> import matplotlib.pyplot as plt
>
> # Simular dados
> np.random.seed(42)
> n_samples = 100
> n_features = 10
> X = np.random.randn(n_samples, n_features)
> true_beta = np.array([1.5, 0, 2, 0, -1, 0, 0.5, 0, -0.2, 0]) # Coeficientes verdadeiros (esparso)
> y = X @ true_beta + np.random.randn(n_samples)
>
> # Escalonar os dados
> scaler = StandardScaler()
> X_scaled = scaler.fit_transform(X)
>
> # Aplicar Lasso e Ridge
> alpha = 0.1  # Lambda (regulariza√ß√£o)
> lasso = Lasso(alpha=alpha)
> ridge = Ridge(alpha=alpha)
>
> lasso.fit(X_scaled, y)
> ridge.fit(X_scaled, y)
>
> # Coeficientes
> lasso_coef = lasso.coef_
> ridge_coef = ridge.coef_
>
> print("Lasso coefficients:", lasso_coef)
> print("Ridge coefficients:", ridge_coef)
>
> # Visualizar os resultados
> plt.figure(figsize=(10, 6))
> plt.bar(range(n_features), true_beta, color='gray', label='True Beta')
> plt.bar(range(n_features), lasso_coef, color='blue', label='Lasso')
> plt.bar(range(n_features), ridge_coef, color='red', alpha=0.7, label='Ridge')
> plt.xlabel("Features")
> plt.ylabel("Coefficient Value")
> plt.title("Comparison of Lasso and Ridge Coefficients")
> plt.legend()
> plt.show()
> ```
> A sa√≠da num√©rica e o gr√°fico mostram que o Lasso realmente for√ßa alguns coeficientes a zero, enquanto o Ridge os reduz.

A escolha entre L1 e L2, ou a combina√ß√£o delas como no Elastic Net, depende do problema e do objetivo da modelagem. Modelos com muitas vari√°veis e que precisam de interpretabilidade se beneficiam mais da L1, enquanto a L2 √© melhor para estabilizar modelos e lidar com multicolinearidade. Na vis√£o bayesiana, a escolha entre L1 e L2 corresponde a diferentes cren√ßas iniciais sobre os valores dos coeficientes [^8.3], [^8.4].

> ‚ùó **Ponto de Aten√ß√£o:** A regulariza√ß√£o no contexto Bayesiano corresponde a aplicar *prioris* informativas, ou seja, que expressam algum conhecimento pr√©vio sobre a distribui√ß√£o dos par√¢metros.

### Separating Hyperplanes e Perceptrons
A discuss√£o dos Separating Hyperplanes e Perceptrons, abordada em outras se√ß√µes, pode ser feita tamb√©m na perspectiva Bayesiana. Ao inv√©s de buscar um hiperplano √≥timo por meio de otimiza√ß√£o direta, podemos definir um modelo probabil√≠stico com uma prior sobre os par√¢metros do hiperplano, como discutido em [^8.3]. Por exemplo, para um SVM, podemos definir uma prior sobre os vetores de suporte e a margem de separa√ß√£o, e obter uma distribui√ß√£o posterior sobre os hiperplanos poss√≠veis [^8.4]. De forma similar, em Perceptrons, podemos definir distribui√ß√µes a priori sobre os pesos e biais, e obter distribui√ß√µes posteriores que representam a incerteza sobre os par√¢metros do modelo [^8.4].

### Pergunta Te√≥rica Avan√ßada (Exemplo): Como a escolha de uma prior influencia a distribui√ß√£o posterior, e em que situa√ß√µes a posterior converge para uma distribui√ß√£o com menor vari√¢ncia?
**Resposta:** A escolha da prior influencia significativamente a distribui√ß√£o posterior, especialmente quando o tamanho da amostra dos dados √© pequeno. Uma prior informativa (ou seja, que concentra sua massa de probabilidade em torno de certos valores dos par√¢metros) pode dominar a verossimilhan√ßa (ou seja, a evid√™ncia dos dados) e levar a uma posterior com m√©dia e vari√¢ncia pr√≥ximas da prior. Uma prior n√£o-informativa, por outro lado, permite que a verossimilhan√ßa tenha maior influ√™ncia na posterior, de forma que a posterior seja mais determinada pelos dados do que pela prior.
A converg√™ncia da posterior para uma distribui√ß√£o com menor vari√¢ncia ocorre quando a verossimilhan√ßa √© muito concentrada em torno de um valor dos par√¢metros, ou quando o tamanho da amostra de dados √© grande. Nestes casos, os dados dominam a prior e a posterior se torna mais precisa e concentrada. Matematicamente, essa converg√™ncia ocorre porque, quando o tamanho da amostra tende ao infinito, a influ√™ncia da prior se torna desprez√≠vel, e a posterior converge para uma distribui√ß√£o com m√©dia no estimador de m√°xima verossimilhan√ßa e vari√¢ncia igual √† inversa da informa√ß√£o de Fisher, como discutido no contexto [^8.2.2].

```mermaid
graph LR
    subgraph "Prior Influence on Posterior"
    direction TB
        A["Prior Distribution (Pr(Œ∏))"]
        B["Likelihood Function (Pr(Z|Œ∏))"]
        C["Posterior Distribution (Pr(Œ∏|Z))"]
        D["Small Sample Size"]
        E["Informative Prior"]
        F["Non-Informative Prior"]
        G["Large Sample Size"]
        H["Posterior influenced by Prior"]
        I["Posterior influenced by Likelihood"]
        J["Posterior converges to Likelihood Peak"]
        A --> C
        B --> C
        A --> D
        A --> F
        D --> E
        F --> I
         D --> G
        E --> H
        G --> J
    end
    linkStyle 0,1,2,3,4,5,6,7,8,9 stroke-width:2px;
```
**Lemma 4:** *No limite de um tamanho amostral tendendo ao infinito, a distribui√ß√£o posterior converge para uma distribui√ß√£o gaussiana com m√©dia igual ao estimador de m√°xima verossimilhan√ßa e vari√¢ncia igual √† inversa da informa√ß√£o de Fisher*. Isso demonstra a ass√≠ntotica de m√°xima verossimilhan√ßa e que os dados dominam a infer√™ncia.

**Corol√°rio 4:** *Sob uma prior n√£o-informativa e tamanho amostral grande, a infer√™ncia Bayesiana se aproxima da infer√™ncia frequentista, pois a posterior se concentra no estimador de m√°xima verossimilhan√ßa e a incerteza √© quantificada pela informa√ß√£o de Fisher*.

> üí° **Exemplo Num√©rico:** Considere um modelo simples de m√©dia com dados $Z = \{z_1, z_2, \ldots, z_n\}$, e assuma que $z_i \sim \mathcal{N}(\mu, \sigma^2)$.
>
> *   **Prior Informativa:** Seja $\mu \sim \mathcal{N}(\mu_0, \tau_0^2)$, com $\mu_0 = 5$ e $\tau_0^2 = 1$.  Isso indica que acreditamos que a m√©dia est√° pr√≥xima de 5, com uma vari√¢ncia de 1.
> *  **Prior N√£o-informativa:**  Pode ser representada por $\mu \sim \mathcal{N}(\mu_0, \tau_0^2)$, com $\tau_0^2 \rightarrow \infty$ (ou seja, a prior √© muito dispersa).
>
>  Vamos gerar dados com $\mu = 7$ e $\sigma^2 = 4$ e verificar a posterior com tamanhos de amostra crescentes:
>
>  ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from scipy.stats import norm
>
> np.random.seed(42)
> mu_true = 7
> sigma2 = 4
> mu0 = 5
> tau02 = 1
>
> sample_sizes = [10, 100, 1000]
>
> plt.figure(figsize=(12, 8))
> for i, n in enumerate(sample_sizes):
>     Z = np.random.normal(mu_true, np.sqrt(sigma2), n)
>     z_mean = np.mean(Z)
>     z_var = sigma2 / n
>
>     # Posterior com prior informativa
>     mu_posterior = (z_mean / z_var + mu0 / tau02) / (1/z_var + 1/tau02)
>     sigma2_posterior = 1 / (1/z_var + 1/tau02)
>     posterior_dist = norm(mu_posterior, np.sqrt(sigma2_posterior))
>
>     # Valores para plotar
>     x = np.linspace(mu_true - 5, mu_true + 5, 200)
>     posterior_pdf = posterior_dist.pdf(x)
>
>     # Plot
>     plt.subplot(1, 3, i + 1)
>     plt.plot(x, posterior_pdf, label=f'Posterior (n={n})', color='blue')
>     plt.title(f'Posterior for n={n}')
>     plt.xlabel('Œº')
>     plt.ylabel('Probability Density')
>     plt.legend()
>     plt.grid(True)
> plt.tight_layout()
> plt.show()
> ```
>
> Os gr√°ficos mostram como, com o aumento do tamanho amostral (n), a posterior converge para uma distribui√ß√£o mais concentrada em torno da m√©dia real $\mu = 7$. Inicialmente (n=10), a prior tem maior influ√™ncia, mas conforme n aumenta (n=1000), a verossimilhan√ßa domina, e a posterior torna-se mais estreita e centrada na m√©dia amostral, que se aproxima do valor verdadeiro. A vari√¢ncia da posterior diminui com o aumento do tamanho da amostra.

> ‚ö†Ô∏è **Ponto Crucial**: A escolha da prior √© fundamental na infer√™ncia Bayesiana, especialmente para amostras pequenas. A escolha correta da prior deve ser feita de forma a refletir o conhecimento pr√©vio sobre os par√¢metros, e deve ser justificada de acordo com a aplica√ß√£o espec√≠fica.

### Conclus√£o
A infer√™ncia Bayesiana oferece uma estrutura rica e flex√≠vel para modelagem estat√≠stica, atrav√©s da combina√ß√£o da distribui√ß√£o a priori, da verossimilhan√ßa e da obten√ß√£o da distribui√ß√£o posterior. Atrav√©s desta abordagem, √© poss√≠vel quantificar a incerteza associada aos par√¢metros e fazer predi√ß√µes sobre novos dados. Ao usar priors informativas, regulariza√ß√£o e t√©cnicas de modelagem Bayesiana, √© poss√≠vel obter modelos mais est√°veis, precisos e interpret√°veis. Modelos de *model averaging* e *bumping*, mencionados em [^8.8] e [^8.9] tamb√©m podem ser abordados do ponto de vista Bayesiano, pois s√£o aproxima√ß√µes da distribui√ß√£o posterior ou m√©todos de melhoria dos modelos sob a √≥tica Bayesiana.

### Footnotes
[^8.1]: "In this chapter we provide a general exposition of the maximum likelihood approach, as well as the Bayesian method for inference. The bootstrap, introduced in Chapter 7, is discussed in this context, and its relation to maximum likelihood and Bayes is described. Finally, we present some related techniques for model averaging and improvement, including committee methods, bagging, stacking and bumping." *(Trecho de Model Inference and Averaging)*
[^8.2.2]: "Maximum likelihood is based on the likelihood function, given by L(Œ∏; Z) = ‚àèN i=1 gŒ∏(zi), the probability of the observed data under the model gŒ∏." *(Trecho de Model Inference and Averaging)*
[^8.3]: "In the Bayesian approach to inference, we specify a sampling model Pr(Z|Œ∏) (density or probability mass function) for our data given the parameters, and a prior distribution for the parameters Pr(Œ∏) reflecting our knowledge about Œ∏ before we see the data. We then compute the posterior distribution Pr(Œ∏|Z) = Pr(Z|Œ∏)‚ãÖPr(Œ∏) / ‚à´Pr(Z|Œ∏)‚ãÖPr(Œ∏)dŒ∏'" *(Trecho de Model Inference and Averaging)*
[^8.4]: "The distribution (8.25) with œÑ ‚Üí ‚àû is called a noninformative prior for Œ∏. In Gaussian models, maximum likelihood and parametric bootstrap analyses tend to agree with Bayesian analyses that use a noninformative prior for the free parameters. These tend to agree, because with a constant prior, the posterior distribution is proportional to the likelihood." *(Trecho de Model Inference and Averaging)*
<!-- END DOCUMENT -->
