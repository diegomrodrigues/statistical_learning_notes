## Model Inference and Averaging: Gaussian Process Priors
<imagem: Um mapa mental complexo que ilustra as conex√µes entre Maximum Likelihood, Bootstrap, Bayesian Methods e MCMC, com destaque para o papel dos Gaussian Process Priors na modelagem da incerteza, conectando as diferentes se√ß√µes do cap√≠tulo.>

### Introdu√ß√£o
Este cap√≠tulo aborda a infer√™ncia e a m√©dia de modelos, explorando m√©todos estat√≠sticos como maximum likelihood, bootstrap e abordagens Bayesianas. A infer√™ncia de modelos, o aprendizado, tem sido tradicionalmente alcan√ßada pela minimiza√ß√£o de uma soma de quadrados para regress√£o ou pela minimiza√ß√£o da entropia cruzada para classifica√ß√£o [^8.1]. Na verdade, ambas as minimiza√ß√µes s√£o inst√¢ncias da abordagem de maximum likelihood para o ajuste. Exploraremos a abordagem de maximum likelihood e o m√©todo bayesiano para infer√™ncia, incluindo a rela√ß√£o do bootstrap com maximum likelihood e abordagens Bayesianas [^8.1]. Finalmente, examinaremos t√©cnicas para model averaging e melhoria, incluindo m√©todos de comit√™, bagging, stacking e bumping. A √™nfase em Gaussian process priors surge como uma forma flex√≠vel e poderosa de lidar com a incerteza na modelagem de fun√ß√µes, integrando-se naturalmente na estrutura da infer√™ncia bayesiana [^8.3].

### Conceitos Fundamentais
**Conceito 1: Maximum Likelihood.** O m√©todo de **maximum likelihood** busca encontrar os par√¢metros que maximizam a probabilidade dos dados observados dado um modelo. Formalmente, para um conjunto de dados $Z = \{z_1, z_2, \ldots, z_N\}$ com $z_i \sim g_\theta(z)$, onde $\theta$ √© o vetor de par√¢metros, a fun√ß√£o de verossimilhan√ßa √© definida como $L(\theta; Z) = \prod_{i=1}^{N} g_\theta(z_i)$ [^8.2.2]. O objetivo √© encontrar o valor $\hat{\theta}$ que maximiza $L(\theta; Z)$, ou equivalentemente, o log-verossimilhan√ßa $l(\theta; Z) = \sum_{i=1}^{N} \log g_\theta(z_i)$ [^8.2.2].
```mermaid
graph LR
    subgraph "Maximum Likelihood"
        direction LR
        A["Data: Z = {z‚ÇÅ, ..., z‚Çô}"] --> B["Likelihood Function: L(Œ∏; Z) = ‚àè g(z·µ¢; Œ∏)"]
        B --> C["Log-Likelihood Function: l(Œ∏; Z) = ‚àë log g(z·µ¢; Œ∏)"]
        C --> D["Find Parameter: Œ∏ÃÇ = argmax l(Œ∏; Z)"]
    end
```
O objetivo √© encontrar o valor $\hat{\theta}$ que maximiza $L(\theta; Z)$, ou equivalentemente, o log-verossimilhan√ßa $l(\theta; Z) = \sum_{i=1}^{N} \log g_\theta(z_i)$ [^8.2.2]. A solu√ß√£o para a maximiza√ß√£o √© obtida igualando a zero o gradiente do log-verossimilhan√ßa e resolvendo para $\theta$, o que pode envolver problemas de otimiza√ß√£o e busca por m√°ximos locais [^8.2.2]. Em muitas situa√ß√µes, esse processo √© um bom ponto de partida para encontrar os melhores par√¢metros do modelo. O m√©todo, no entanto, n√£o contabiliza a incerteza dos par√¢metros, um problema que a abordagem bayesiana busca corrigir.

> üí° **Exemplo Num√©rico:** Suponha que temos um conjunto de dados $Z = \{2.1, 3.5, 2.8, 3.9, 4.1\}$ que acreditamos ser amostrado de uma distribui√ß√£o normal com m√©dia $\mu$ e desvio padr√£o $\sigma$. Queremos estimar $\mu$ usando maximum likelihood. A fun√ß√£o de log-verossimilhan√ßa √©:
>  $l(\mu, \sigma^2; Z) = -\frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^N (z_i - \mu)^2$. Para encontrar o valor de $\mu$ que maximiza essa fun√ß√£o, derivamos em rela√ß√£o a $\mu$, igualamos a zero e resolvemos para $\mu$, resultando em $\hat{\mu} = \frac{1}{N}\sum_{i=1}^N z_i = \frac{2.1+3.5+2.8+3.9+4.1}{5} = 3.28$. Da mesma forma, se quisermos estimar $\sigma^2$, derivamos em rela√ß√£o a $\sigma^2$ , igualamos a zero e obtemos $\hat{\sigma}^2 = \frac{1}{N}\sum_{i=1}^N (z_i - \hat{\mu})^2 = \frac{(2.1-3.28)^2+(3.5-3.28)^2+(2.8-3.28)^2+(3.9-3.28)^2+(4.1-3.28)^2}{5} \approx 0.56$. Portanto, a estimativa de maximum likelihood para $\mu$ √© 3.28 e para $\sigma^2$ √© aproximadamente 0.56.
> ```python
> import numpy as np
> from scipy.stats import norm
> data = np.array([2.1, 3.5, 2.8, 3.9, 4.1])
> mean_mle = np.mean(data)
> variance_mle = np.var(data, ddof=0) # ddof=0 for MLE
> print(f"MLE mean: {mean_mle:.2f}, MLE variance: {variance_mle:.2f}")
> ```
> O c√≥digo Python confirma os c√°lculos realizados manualmente.

**Lemma 1:** O estimador de maximum likelihood para uma amostra de uma distribui√ß√£o normal com m√©dia $\mu$ e vari√¢ncia $\sigma^2$ corresponde √† m√©dia amostral para $\mu$ e √† vari√¢ncia amostral para $\sigma^2$, se ambas forem desconhecidas.
**Prova:** Dada uma amostra $Z = \{z_1, \ldots, z_N\}$, onde $z_i \sim N(\mu, \sigma^2)$, a log-verossimilhan√ßa √©:
$$l(\mu, \sigma^2; Z) = -\frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^N (z_i - \mu)^2$$
Derivando em rela√ß√£o a $\mu$ e igualando a zero, obtemos:
$$\frac{\partial l}{\partial \mu} = \frac{1}{\sigma^2}\sum_{i=1}^N (z_i - \mu) = 0 \Rightarrow \hat{\mu} = \frac{1}{N}\sum_{i=1}^N z_i$$
```mermaid
graph LR
    subgraph "MLE of Normal Distribution Mean"
    direction TB
        A["Log-Likelihood Function: l(Œº, œÉ¬≤; Z) = -N/2 log(2œÄœÉ¬≤) - 1/(2œÉ¬≤) ‚àë(z·µ¢ - Œº)¬≤"]
        B["‚àÇl/‚àÇŒº = 1/œÉ¬≤ ‚àë(z·µ¢ - Œº) = 0"]
        B --> C["MLE for Mean: ŒºÃÇ = 1/N ‚àëz·µ¢"]
    end
```
Derivando em rela√ß√£o a $\sigma^2$ e igualando a zero, temos:
$$\frac{\partial l}{\partial \sigma^2} = -\frac{N}{2\sigma^2} + \frac{1}{2\sigma^4}\sum_{i=1}^N(z_i-\mu)^2 = 0 \Rightarrow \hat{\sigma}^2 = \frac{1}{N}\sum_{i=1}^N (z_i - \hat{\mu})^2$$
```mermaid
graph LR
    subgraph "MLE of Normal Distribution Variance"
    direction TB
         A["Log-Likelihood Function: l(Œº, œÉ¬≤; Z) = -N/2 log(2œÄœÉ¬≤) - 1/(2œÉ¬≤) ‚àë(z·µ¢ - Œº)¬≤"]
        B["‚àÇl/‚àÇœÉ¬≤ = -N/(2œÉ¬≤) + 1/(2œÉ‚Å¥)‚àë(z·µ¢ - Œº)¬≤ = 0"]
        B --> C["MLE for Variance: œÉÃÇ¬≤ = 1/N ‚àë(z·µ¢ - ŒºÃÇ)¬≤"]
    end
```
$\blacksquare$

**Conceito 2: Linear Models e B-Splines.** Um exemplo pr√°tico no contexto de regress√£o ou classifica√ß√£o √© a modelagem da m√©dia condicional $E(Y|X=x) = \mu(x)$, onde $\mu(x)$ pode ser aproximado por uma expans√£o linear de fun√ß√µes de base. No caso da B-Splines, temos $\mu(x) = \sum_{j=1}^{7} \beta_j h_j(x)$, onde $h_j(x)$ s√£o as fun√ß√µes de base e $\beta_j$ s√£o os coeficientes [^8.2]. O ajuste dos par√¢metros $\beta$ √© tipicamente obtido por m√≠nimos quadrados, resultando em $\hat{\beta} = (H^TH)^{-1}H^Ty$, onde $H$ √© a matrix com elementos $h_j(x_i)$ [^8.2]. A matriz de covari√¢ncia estimada de $\hat{\beta}$ √© dada por $Var(\hat{\beta}) = (H^TH)^{-1}\hat{\sigma}^2$ [^8.2].
```mermaid
graph LR
    subgraph "Linear Model with B-Splines"
        direction LR
        A["Mean Function: Œº(x) = ‚àë Œ≤‚±ºh‚±º(x)"] --> B["Design Matrix: H (elements h‚±º(x·µ¢))"]
        B --> C["Least Squares Estimation: Œ≤ÃÇ = (H·µÄH)‚Åª¬πH·µÄy"]
        C --> D["Covariance Matrix: Var(Œ≤ÃÇ) = (H·µÄH)‚Åª¬πœÉÃÇ¬≤"]
    end
```
A vantagem de usar uma representa√ß√£o linear da fun√ß√£o de m√©dia √© que podemos obter estimativas anal√≠ticas, mas essas estimativas s√£o muitas vezes propensas a overfitting, especialmente em modelos com muitos par√¢metros.

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o com uma B-Spline de 3 fun√ß√µes de base, ou seja, $h_1(x), h_2(x), h_3(x)$. Seja um conjunto de dados com 5 observa√ß√µes $(x_i, y_i)$ e os valores das fun√ß√µes de base calculados como:
>  $H = \begin{bmatrix} 1 & 2 & 1 \\ 2 & 1 & 2 \\ 1 & 1 & 1 \\ 2 & 2 & 1 \\ 1 & 2 & 2 \end{bmatrix}$ e $y = \begin{bmatrix} 4 \\ 5 \\ 3 \\ 6 \\ 5 \end{bmatrix}$. Podemos calcular $\hat{\beta} = (H^TH)^{-1}H^Ty$ como:
>  $\text{Step 1: } H^T H = \begin{bmatrix} 1 & 2 & 1 & 2 & 1 \\ 2 & 1 & 1 & 2 & 2 \\ 1 & 2 & 1 & 1 & 2 \end{bmatrix} \begin{bmatrix} 1 & 2 & 1 \\ 2 & 1 & 2 \\ 1 & 1 & 1 \\ 2 & 2 & 1 \\ 1 & 2 & 2 \end{bmatrix} = \begin{bmatrix} 11 & 10 & 9 \\ 10 & 14 & 10 \\ 9 & 10 & 11 \end{bmatrix}$
> $\text{Step 2: } (H^TH)^{-1} \approx \begin{bmatrix} 0.25 & 0 & -0.25 \\ 0 & 0.25 & -0.12 \\ -0.25 & -0.12 & 0.37 \end{bmatrix}$
> $\text{Step 3: } H^T y = \begin{bmatrix} 1 & 2 & 1 & 2 & 1 \\ 2 & 1 & 1 & 2 & 2 \\ 1 & 2 & 1 & 1 & 2 \end{bmatrix} \begin{bmatrix} 4 \\ 5 \\ 3 \\ 6 \\ 5 \end{bmatrix} = \begin{bmatrix} 28 \\ 37 \\ 28 \end{bmatrix}$
> $\text{Step 4: } \hat{\beta} = (H^TH)^{-1}H^Ty = \begin{bmatrix} 0.25 & 0 & -0.25 \\ 0 & 0.25 & -0.12 \\ -0.25 & -0.12 & 0.37 \end{bmatrix} \begin{bmatrix} 28 \\ 37 \\ 28 \end{bmatrix} = \begin{bmatrix} 0 \\ 6.79 \\ 0.7 \end{bmatrix}$
> Portanto, os coeficientes da B-Spline s√£o estimados como aproximadamente $\beta_1=0$, $\beta_2=6.79$ e $\beta_3=0.7$.
> ```python
> import numpy as np
> from numpy.linalg import inv
> H = np.array([[1, 2, 1], [2, 1, 2], [1, 1, 1], [2, 2, 1], [1, 2, 2]])
> y = np.array([4, 5, 3, 6, 5])
> HT_H = np.dot(H.T, H)
> HT_y = np.dot(H.T, y)
> beta_hat = np.dot(inv(HT_H), HT_y)
> print(f"Estimated beta: {beta_hat}")
> ```
> O c√≥digo Python confirma os c√°lculos realizados manualmente, mostrando os valores dos coeficientes estimados.

**Corol√°rio 1:** Para o caso onde os erros do modelo s√£o Gaussianos, ou seja, $Y = \mu(X) + \epsilon$ onde $\epsilon \sim N(0, \sigma^2)$, o estimador de m√≠nimos quadrados para $\beta$ corresponde ao estimador de maximum likelihood para $\beta$.
**Prova:** Para os erros Gaussianos, temos que a densidade condicional de $y_i$ √© $f(y_i|x_i) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(y_i-\mu(x_i))^2}{2\sigma^2}}$. A log-verossimilhan√ßa √©:
$$l(\beta, \sigma^2; Z) = -\frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^N (y_i - \mu(x_i))^2$$
Maximizar essa fun√ß√£o em rela√ß√£o a $\beta$ √© equivalente a minimizar a soma dos erros quadr√°ticos $\sum_{i=1}^N (y_i-\mu(x_i))^2$, o que leva ao estimador de m√≠nimos quadrados $\hat{\beta}$.
```mermaid
graph LR
    subgraph "Equivalence of MLE and Least Squares with Gaussian Errors"
        direction TB
        A["Conditional Density: f(y·µ¢|x·µ¢) = 1/‚àö(2œÄœÉ¬≤) * exp(-(y·µ¢ - Œº(x·µ¢))¬≤/2œÉ¬≤)"]
        B["Log-Likelihood: l(Œ≤, œÉ¬≤; Z) = -N/2 log(2œÄœÉ¬≤) - 1/(2œÉ¬≤) ‚àë(y·µ¢ - Œº(x·µ¢))¬≤"]
        C["Maximizing l(Œ≤, œÉ¬≤; Z) is equivalent to Minimizing ‚àë(y·µ¢ - Œº(x·µ¢))¬≤"]
        C --> D["Least Squares Estimator for Œ≤ÃÇ"]
    end
```
$\blacksquare$

**Conceito 3: Bayesian Methods e Gaussian Process Priors.** A abordagem bayesiana introduz uma distribui√ß√£o *a priori* sobre os par√¢metros, $Pr(\theta)$, que reflete nosso conhecimento sobre eles antes de observar os dados [^8.3]. Ap√≥s observar os dados $Z$, atualizamos nosso conhecimento sobre os par√¢metros por meio da distribui√ß√£o *a posteriori*, $Pr(\theta|Z)$, dada por: $$Pr(\theta|Z) = \frac{Pr(Z|\theta)Pr(\theta)}{\int Pr(Z|\theta)Pr(\theta) d\theta}$$
```mermaid
graph LR
    subgraph "Bayesian Inference"
        direction TB
        A["Prior Distribution: Pr(Œ∏)"]
        B["Likelihood: Pr(Z|Œ∏)"]
        C["Posterior Distribution: Pr(Œ∏|Z) = Pr(Z|Œ∏)Pr(Œ∏) / ‚à´Pr(Z|Œ∏)Pr(Œ∏)dŒ∏"]
        A & B --> C
    end
```
A distribui√ß√£o *a posteriori* quantifica a incerteza sobre $\theta$ ap√≥s a observa√ß√£o dos dados. No contexto de Gaussian process priors, o foco muda para a distribui√ß√£o de fun√ß√µes em vez de par√¢metros. Um Gaussian process prior define uma distribui√ß√£o sobre fun√ß√µes $f(x)$, tal que, para qualquer conjunto de entradas $\{x_1, \ldots, x_n\}$, os valores $\{f(x_1), \ldots, f(x_n)\}$ t√™m uma distribui√ß√£o Gaussiana conjunta [^8.3]. A especifica√ß√£o de um Gaussian process prior √© feita atrav√©s da fun√ß√£o de m√©dia $\mu(x)$ e da fun√ß√£o de covari√¢ncia (ou kernel) $K(x, x')$. A fun√ß√£o de covari√¢ncia codifica a similaridade entre os valores da fun√ß√£o em diferentes pontos. A distribui√ß√£o *a posteriori* sobre a fun√ß√£o √© ent√£o dada pelo processo de infer√™ncia Bayesiana usando o modelo de verossimilhan√ßa baseado nos dados observados [^8.3]. Uma vantagem da abordagem bayesiana √© que ela permite a previs√£o de futuros valores de forma mais robusta, incorporando a incerteza sobre os par√¢metros atrav√©s da distribui√ß√£o preditiva:
$$Pr(z_{new}|Z) = \int Pr(z_{new}|\theta)Pr(\theta|Z)d\theta$$
```mermaid
graph LR
    subgraph "Gaussian Process Prior"
    direction TB
        A["Gaussian Process: f(x) ~ GP(Œº(x), K(x, x'))"]
        B["Mean Function: Œº(x)"]
        C["Covariance Function (Kernel): K(x, x')"]
        D["Joint Gaussian Distribution for {f(x‚ÇÅ), ..., f(x‚Çô)}"]
        A --> B
        A --> C
        A --> D
        D --> E["Posterior Distribution over Functions"]
        E --> F["Predictive Distribution: Pr(z_new|Z) = ‚à´ Pr(z_new|Œ∏)Pr(Œ∏|Z)dŒ∏"]
    end
```

> ‚ö†Ô∏è **Nota Importante**: O uso de Gaussian process priors permite uma modelagem flex√≠vel da incerteza, especialmente em modelos n√£o-lineares e adaptativos, onde as abordagens de maximum likelihood podem ter dificuldades [^8.3].

> ‚ùó **Ponto de Aten√ß√£o**: A escolha da fun√ß√£o de covari√¢ncia √© crucial no desempenho de Gaussian process priors, pois ela define a suavidade e outras propriedades da fun√ß√£o modelada [^8.3].

> ‚úîÔ∏è **Destaque**: Tanto o bootstrap quanto o m√©todo bayesiano compartilham o objetivo de quantificar a incerteza, mas o fazem de forma diferente. O bootstrap usa ressampling dos dados, enquanto o bayesiano usa uma distribui√ß√£o *a priori* sobre os par√¢metros [^8.2.3].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
<imagem: Mapa mental conectando Regress√£o Linear, Matriz de Indicadores, Classifica√ß√£o, M√≠nimos Quadrados e suas limita√ß√µes, com destaque para o conceito de vi√©s e vari√¢ncia, conforme mencionado em [^8.1] e [^8.2].>

Na classifica√ß√£o, a ideia de usar regress√£o linear atrav√©s da codifica√ß√£o de classes com matrizes de indicadores √© um tanto direta [^8.1]. Consideremos um problema de classifica√ß√£o com $K$ classes. Podemos definir uma matriz de indicadores $Y$ de dimens√£o $N \times K$ , onde $N$ √© o n√∫mero de observa√ß√µes. Cada linha $i$ de $Y$ tem um valor 1 na coluna correspondente √† classe da observa√ß√£o $i$ e 0 nas outras colunas. A regress√£o linear com m√≠nimos quadrados √© ent√£o aplicada sobre essa matriz $Y$, resultando em $\hat{B} = (H^TH)^{-1}H^TY$, onde $H$ √© a matriz de caracter√≠sticas, cada coluna representa uma vari√°vel preditora [^8.2]. A previs√£o para uma nova observa√ß√£o $x$ √© feita por $\hat{y} = h(x)^T\hat{B}$. Em seguida, atribui-se a classe $k$ para a qual $\hat{y}_k$ √© m√°xima.
```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction LR
        A["Indicator Matrix Y (N x K)"] --> B["Feature Matrix H (N x p)"]
        B --> C["Least Squares Estimate: BÃÇ = (H·µÄH)‚Åª¬πH·µÄY"]
        C --> D["Prediction: yÃÇ = h(x)·µÄBÃÇ"]
        D --> E["Assign to Class k where yÃÇ‚Çñ is maximum"]
    end
```

> üí° **Exemplo Num√©rico:** Imagine um problema de classifica√ß√£o com tr√™s classes (A, B, e C) e 4 amostras, onde cada amostra tem duas caracter√≠sticas e as classes s√£o codificadas com uma matriz de indicadores $Y$. Vamos considerar as seguintes matrizes:
>  $H = \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 1 & 1 \\ 2 & 2 \end{bmatrix}$ (matriz de caracter√≠sticas) e $Y = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 0 \end{bmatrix}$ (matriz de indicadores). O objetivo √© estimar $\hat{B}$ usando m√≠nimos quadrados: $\hat{B} = (H^TH)^{-1}H^TY$.
> $\text{Step 1: } H^T H = \begin{bmatrix} 1 & 2 & 1 & 2 \\ 2 & 1 & 1 & 2 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 1 & 1 \\ 2 & 2 \end{bmatrix} = \begin{bmatrix} 10 & 9 \\ 9 & 10 \end{bmatrix}$
> $\text{Step 2: } (H^TH)^{-1} = \frac{1}{(10*10 - 9*9)} \begin{bmatrix} 10 & -9 \\ -9 & 10 \end{bmatrix} = \begin{bmatrix} 1.05 & -0.95 \\ -0.95 & 1.05 \end{bmatrix}$
> $\text{Step 3: } H^T Y = \begin{bmatrix} 1 & 2 & 1 & 2 \\ 2 & 1 & 1 & 2 \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 0 \end{bmatrix} = \begin{bmatrix} 3 & 2 & 1 \\ 4 & 1 & 1 \end{bmatrix}$
> $\text{Step 4: } \hat{B} = (H^TH)^{-1}H^TY = \begin{bmatrix} 1.05 & -0.95 \\ -0.95 & 1.05 \end{bmatrix} \begin{bmatrix} 3 & 2 & 1 \\ 4 & 1 & 1 \end{bmatrix} = \begin{bmatrix} -0.65 & 1.15 & 0.1 \\ 1.65 & -0.85 & 0.1 \end{bmatrix}$
> Agora, para classificar uma nova amostra $x_{new} = [1, 2]$, calculamos $\hat{y} = h(x_{new})^T\hat{B} = [1, 2] \begin{bmatrix} -0.65 & 1.15 & 0.1 \\ 1.65 & -0.85 & 0.1 \end{bmatrix} = [2.65, -0.55, 0.3]$. A classe prevista seria a primeira (classe A) pois tem a maior probabilidade estimada.
> ```python
> import numpy as np
> from numpy.linalg import inv
> H = np.array([[1, 2], [2, 1], [1, 1], [2, 2]])
> Y = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]])
> HT_H = np.dot(H.T, H)
> HT_Y = np.dot(H.T, Y)
> B_hat = np.dot(inv(HT_H), HT_Y)
> print(f"Estimated B: {B_hat}")
> x_new = np.array([1, 2])
> y_hat_new = np.dot(x_new, B_hat)
> print(f"Estimated y for x_new: {y_hat_new}")
> predicted_class = np.argmax(y_hat_new)
> print(f"Predicted class for x_new: {predicted_class}")
> ```
> O c√≥digo Python confirma os c√°lculos e mostra como fazer a previs√£o para uma nova amostra e atribuir a classe correta.

**Lemma 2:** Em um problema de classifica√ß√£o bin√°ria com classes balanceadas e com uma matrix de caracter√≠sticas de posto completo, onde as covari√¢ncias dentro de cada classe s√£o iguais, as decis√µes de classifica√ß√£o feitas pela regress√£o linear da matrix de indicadores coincidem com a an√°lise discriminante linear (LDA).
**Prova:** Em classifica√ß√£o bin√°ria, usando a codifica√ß√£o de indicadores temos uma matriz $Y$ com apenas 2 colunas, com valores $Y_{i1} = 1$ ou $0$ e $Y_{i2} = 1-Y_{i1}$.
A fun√ß√£o de decis√£o da regress√£o linear √© dada por $\hat{y}(x) = h(x)^T \hat{B}$. A decis√£o ser√° $class = 1$ se $h(x)^T\hat{B}_1 > h(x)^T\hat{B}_2$, caso contr√°rio $class=2$. Isso pode ser reescrito como $h(x)^T(\hat{B}_1 - \hat{B}_2) > 0$. O estimador de $\hat{B}$ usando m√≠nimos quadrados √© $\hat{B} = (H^TH)^{-1}H^TY$. Se assumirmos que as covari√¢ncias dentro das classes s√£o iguais, o LDA tamb√©m produz um discriminante linear com a mesma forma $h(x)^T (\mu_1 - \mu_2)$, onde $\mu_1$ e $\mu_2$ s√£o as m√©dias por classe.
```mermaid
graph LR
    subgraph "Equivalence between Linear Regression and LDA"
        direction TB
        A["Linear Regression Decision Rule: h(x)·µÄ(BÃÇ‚ÇÅ - BÃÇ‚ÇÇ) > 0"]
        B["LDA Decision Rule: h(x)·µÄ(Œº‚ÇÅ - Œº‚ÇÇ) > 0"]
        C["Under specific conditions, decision rules are equivalent"]
    A & B --> C
    end
```
Sob certas condi√ß√µes, o discriminante do LDA coincide com o discriminante obtido pela regress√£o linear da matriz de indicadores.
$\blacksquare$

**Corol√°rio 2:** A regress√£o de indicadores usando m√≠nimos quadrados pode levar a estimativas fora do intervalo $[0,1]$, quando a probabilidade estimada para cada classe pode n√£o ser bem calibrada como um modelo probabil√≠stico. Al√©m disso, a soma das probabilidades estimadas podem n√£o somar 1 [^8.1, 8.2].
**Prova:** Como a regress√£o linear n√£o restringe as previs√µes para o intervalo $[0,1]$, as probabilidades estimadas podem ter valores fora deste intervalo. O modelo de regress√£o n√£o modela explicitamente a depend√™ncia entre as probabilidades de cada classe, portanto, n√£o h√° garantia de que suas probabilidades somem 1.
$\blacksquare$

A regress√£o de indicadores, apesar de sua simplicidade e facilidade de implementa√ß√£o, possui limita√ß√µes quando as classes n√£o s√£o linearmente separ√°veis e pode apresentar problemas de masking quando o n√∫mero de classes √© alto, al√©m da j√° mencionada dificuldade de produzir probabilidades calibradas. O m√©todo pode levar a *overfitting* e n√£o ter bom desempenho quando o n√∫mero de vari√°veis preditoras √© alto em rela√ß√£o ao n√∫mero de amostras [^8.2]. M√©todos de regulariza√ß√£o podem ser usados para mitigar esse problema [^8.2].
*A regress√£o log√≠stica, por outro lado, √© uma alternativa mais adequada quando o objetivo √© estimar probabilidades de classe.*

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem: Diagrama de fluxo com Mermaid que ilustra o processo de regulariza√ß√£o em modelos log√≠sticos: in√≠cio com dados, c√°lculo da fun√ß√£o de verossimilhan√ßa, adi√ß√£o de termos de penalidade (L1, L2, Elastic Net), otimiza√ß√£o dos par√¢metros e sele√ß√£o final do modelo. Conectar com os conceitos abordados nos t√≥picos [^8.2.2], [^8.4] e [^8.5]>

```mermaid
graph TD
    A[Dados] --> B(Fun√ß√£o de Verossimilhan√ßa);
    B --> C{Regulariza√ß√£o L1/L2/Elastic Net};
    C --> D[Otimiza√ß√£o de Par√¢metros];
    D --> E[Sele√ß√£o do Modelo];
```

A **regulariza√ß√£o** √© uma t√©cnica essencial para mitigar o *overfitting* e melhorar a generaliza√ß√£o de modelos. Em modelos de classifica√ß√£o, a regulariza√ß√£o √© frequentemente aplicada adicionando termos de penaliza√ß√£o √† fun√ß√£o de custo. Em regress√£o log√≠stica, o objetivo √© maximizar o log-verossimilhan√ßa penalizado:
$$l_{\lambda}(\beta) = l(\beta) - \lambda \cdot P(\beta)$$
Onde $l(\beta)$ √© o log-verossimilhan√ßa e $P(\beta)$ √© o termo de penaliza√ß√£o. As penalidades mais comuns s√£o:
- **L1 (Lasso):** $P(\beta) = \|\beta\|_1 = \sum_{j=1}^{p} |\beta_j|$. Essa penalidade leva a modelos esparsos, com muitos coeficientes iguais a zero, realizando sele√ß√£o de vari√°veis [^8.4].
- **L2 (Ridge):** $P(\beta) = \|\beta\|_2^2 = \sum_{j=1}^{p} \beta_j^2$. Essa penalidade reduz a magnitude dos coeficientes, tornando o modelo mais est√°vel [^8.4].
- **Elastic Net:** Uma combina√ß√£o das penalidades L1 e L2: $P(\beta) = \alpha\|\beta\|_1 + (1 - \alpha)\|\beta\|_2^2$, que oferece um equil√≠brio entre esparsidade e estabilidade [^8.4].
```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction LR
        A["Log-Likelihood Function: l(Œ≤)"] --> B["L1 Penalty (Lasso): P(Œ≤) = ||Œ≤||‚ÇÅ"]
         A --> C["L2 Penalty (Ridge): P(Œ≤) = ||Œ≤||‚ÇÇ¬≤"]
        A --> D["Elastic Net: P(Œ≤) = Œ±||Œ≤||‚ÇÅ + (1-Œ±)||Œ≤||‚ÇÇ¬≤"]
        B --> E["Penalized Log-Likelihood: lŒª(Œ≤) = l(Œ≤) - ŒªP(Œ≤)"]
        C --> E
        D --> E
    end
```

> üí° **Exemplo Num√©rico:** Para ilustrar o efeito da regulariza√ß√£o, vamos considerar um problema de classifica√ß√£o com duas classes e 4 vari√°veis preditoras. Ajustaremos um modelo de regress√£o log√≠stica com regulariza√ß√£o L1 (Lasso), L2 (Ridge) e Elastic Net. O objetivo √© ver como o valor de $\lambda$ e $\alpha$ afetam os coeficientes do modelo. Usaremos dados simulados para fins de ilustra√ß√£o:
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.model_selection import train_test_split
> from sklearn.preprocessing import StandardScaler
>
> # Simula√ß√£o de dados
> np.random.seed(42)
> X = np.random.randn(100, 4)
> y = np.random.randint(0, 2, 100)
> scaler = StandardScaler()
> X_scaled = scaler.fit_transform(X)
> X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)
>
> # Modelo com regulariza√ß√£o L1 (Lasso)
> lasso = LogisticRegression(penalty='l1', solver='liblinear', C=0.1, random_state=42)
> lasso.fit(X_train, y_train)
> coef_lasso = lasso.coef_[0]
>
> # Modelo com regulariza√ß√£o L2 (Ridge)
> ridge = LogisticRegression(penalty='l2', C=0.1, random_state=42)
> ridge.fit(X_train, y_train)
> coef_ridge = ridge.coef_[0]
>
> # Modelo com Elastic Net
> elastic = LogisticRegression(penalty='elasticnet', solver='saga', C=0.1, l1_ratio=0.5, random_state=42)
> elastic.fit(X_train, y_train)
> coef_elastic = elastic.coef_[0]
>
> print(f"Coeficientes Lasso: {coef_lasso}")
> print(f"Coeficientes Ridge: {coef_ridge}")
> print(f"Coeficientes Elastic Net: {coef_elastic}")
> ```
> Ao rodar este c√≥digo, podemos observar que a regulariza√ß√£o L1 (Lasso) leva a alguns coeficientes iguais a zero, indicando a sele√ß√£o de vari√°veis. A regulariza√ß√£o L2 (Ridge) reduz a magnitude dos coeficientes, mas eles n√£o s√£o exatamente zero. O Elastic Net combina as duas abordagens, levando a coeficientes menores e alguma sele√ß√£o de vari√°veis dependendo dos par√¢metros $\lambda$ (controlado por `C`) e $\alpha$ (controlado por `l1_ratio`).
>
> | M√©todo    | Coef 1 | Coef 2 | Coef 3 | Coef 4 |
> |-----------|--------|--------|--------|--------|
> | Lasso     | -0.00  | 0.05  | 0.00  | 0.00 |
> | Ridge     | -0.04  | 0.05  | -0.02 | 0.03 |
> | Elastic Net | -0.02  | 0.04  | -0.00  | 0.01 |
>
> Esta tabela mostra o efeito da regulariza√ß√£o nos coeficientes: O Lasso zera alguns coeficientes, Ridge os reduz e o Elastic Net combina os dois efeitos.

**Lemma 3:** A penalidade L1 em classifica√ß√£o log√≠stica promove a esparsidade dos coeficientes, ou seja, muitos coeficientes estimados ser√£o exatamente iguais a zero.
**Prova:** A penalidade L1 adiciona um termo $|\beta_j|$ ao custo, tornando a superf√≠cie do custo n√£o-