## Model Inference and Averaging: Focusing on Bootstrap Samples for Bumping

```mermaid
graph LR
    subgraph "Inference and Modeling Techniques"
    direction TB
        A["Maximum Likelihood Estimation"]
        B["Bayesian Inference"]
        C["Bootstrap Resampling"]
        D["Model Averaging"]
        E["Bumping"]
        A --> C
        B --> C
        C --> D
        C --> E
    end
```

### Introdu√ß√£o

Este cap√≠tulo explora a infer√™ncia e a m√©dia de modelos, focando em t√©cnicas estat√≠sticas e de aprendizado de m√°quina para aprimorar a precis√£o e a robustez das previs√µes. Ao longo do livro, a adapta√ß√£o de modelos tem sido realizada atrav√©s da minimiza√ß√£o de somas de quadrados para regress√£o ou da minimiza√ß√£o da entropia cruzada para classifica√ß√£o [^8.1]. Essas abordagens s√£o, na verdade, inst√¢ncias do m√©todo de m√°xima verossimilhan√ßa. Neste cap√≠tulo, aprofundaremos na exposi√ß√£o geral da abordagem de m√°xima verossimilhan√ßa e o m√©todo Bayesiano para infer√™ncia, com destaque para as t√©cnicas de amostragem de bootstrap e suas rela√ß√µes com m√°xima verossimilhan√ßa, modelos Bayesianos e t√©cnicas de _model averaging_. Exploraremos tamb√©m o _bumping_, uma t√©cnica para melhorar modelos que encontram m√≠nimos locais.

### Conceitos Fundamentais

#### Conceito 1: O Problema de Classifica√ß√£o e o Uso de M√©todos Lineares
O problema de classifica√ß√£o envolve atribuir r√≥tulos a dados com base em um conjunto de caracter√≠sticas. M√©todos lineares s√£o frequentemente utilizados para esse prop√≥sito devido √† sua simplicidade e efici√™ncia computacional [^8.1]. Esses m√©todos buscam estabelecer uma fronteira de decis√£o linear que separa as diferentes classes. Contudo, a escolha de um modelo linear pode introduzir vi√©s (bias) se a rela√ß√£o entre as caracter√≠sticas e as classes for n√£o-linear, e vari√¢ncia (variance) se o modelo for muito complexo para o tamanho da amostra. A complexidade do modelo √© controlada com regulariza√ß√£o e t√©cnicas de sele√ß√£o de vari√°veis, conforme discutido mais adiante.

**Lemma 1:** *Decomposi√ß√£o da Fun√ß√£o Discriminante Linear*. Em um problema de classifica√ß√£o linear com duas classes, a fun√ß√£o discriminante $f(x)$ pode ser expressa como $f(x) = w^T x + b$, onde $w$ √© o vetor de pesos e $b$ √© o termo de vi√©s. A fronteira de decis√£o √© definida por $f(x) = 0$. Se os dados s√£o linearmente separ√°veis, ent√£o existe uma solu√ß√£o que permite classificar todos os dados corretamente. Quando adicionamos regulariza√ß√£o, temos $$ f(x) = w^Tx + b + \lambda ||w||_p $$ onde $\lambda$ √© um par√¢metro de regulariza√ß√£o e $p$ pode ser $1$ ($L_1$ regulariza√ß√£o) ou $2$ ($L_2$ regulariza√ß√£o). A regulariza√ß√£o $L_1$ pode induzir esparsidade na solu√ß√£o, enquanto a $L_2$ pode tornar a solu√ß√£o mais est√°vel [^8.4]. $\blacksquare$

```mermaid
graph LR
    subgraph "Linear Discriminant Function"
        direction TB
        A["f(x) = w^T x + b"]
        B["L1 Regularization: f(x) = w^Tx + b + Œª||w||_1"]
        C["L2 Regularization: f(x) = w^Tx + b + Œª||w||_2"]
        A --> B
        A --> C
    end
```

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com duas classes, onde cada amostra tem duas caracter√≠sticas ($x_1$ e $x_2$). Suponha que ap√≥s treinamento sem regulariza√ß√£o, o modelo linear tenha o vetor de pesos $w = [2, -1]$ e vi√©s $b = 1$. A fun√ß√£o discriminante √© $f(x) = 2x_1 - x_2 + 1$. Uma nova amostra $x = [1, 3]$ √© classificada calculando $f(x) = 2(1) - 3 + 1 = 0$. Portanto, esta amostra est√° na fronteira de decis√£o. Agora, se adicionarmos regulariza√ß√£o $L_2$ com $\lambda=0.5$, a fun√ß√£o discriminante seria modificada. A otimiza√ß√£o com regulariza√ß√£o ajustaria os valores de $w$ e $b$ buscando um equil√≠brio entre minimizar o erro de classifica√ß√£o e evitar pesos muito grandes.

#### Conceito 2: Linear Discriminant Analysis (LDA)
O **Linear Discriminant Analysis (LDA)** √© uma t√©cnica para classifica√ß√£o que busca encontrar a melhor proje√ß√£o linear dos dados de forma a maximizar a separa√ß√£o entre as classes [^8.2]. O LDA assume que as classes t√™m distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia. A fronteira de decis√£o √© obtida atrav√©s da proje√ß√£o dos dados em um espa√ßo de menor dimens√£o, que maximiza a separa√ß√£o das m√©dias de classe e minimiza a vari√¢ncia dentro de cada classe. Essa abordagem √© especialmente √∫til quando as classes t√™m vari√¢ncias semelhantes e as amostras s√£o aproximadamente Gaussianas [^8.2]. A fun√ß√£o discriminante linear do LDA √© dada por $$ f(x) = x^T \Sigma^{-1} (\mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k) $$
onde $\mu_k$ √© a m√©dia da classe k e $\Sigma$ √© a matriz de covari√¢ncia conjunta das classes.

**Corol√°rio 1:** *Proje√ß√£o em Subespa√ßos*. A fun√ß√£o discriminante linear do LDA pode ser vista como uma proje√ß√£o dos dados em um subespa√ßo de menor dimens√£o que √© definido pelos autovetores da matriz de covari√¢ncia entre as classes. Essa proje√ß√£o maximiza a raz√£o entre a vari√¢ncia entre as classes e a vari√¢ncia dentro das classes [^8.2]. Formalmente, se $S_W$ √© a matriz de vari√¢ncia dentro das classes e $S_B$ √© a matriz de vari√¢ncia entre as classes, o LDA encontra a proje√ß√£o $W$ que maximiza $tr(W^T S_B W)/tr(W^T S_W W)$, onde $tr$ √© o tra√ßo da matriz. $\blacksquare$

```mermaid
graph LR
    subgraph "LDA Projection"
        direction TB
        A["Data Projection onto Subspace"]
        B["Maximize Between-Class Variance (S_B)"]
        C["Minimize Within-Class Variance (S_W)"]
         D["Maximize tr(W^T S_B W) / tr(W^T S_W W)"]
        A --> B
        A --> C
        B & C --> D
    end
```

> üí° **Exemplo Num√©rico:** Considere um conjunto de dados com duas classes e duas caracter√≠sticas. As m√©dias das classes s√£o $\mu_1 = [1, 2]$ e $\mu_2 = [3, 1]$. A matriz de covari√¢ncia conjunta √© $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$. Para aplicar o LDA, primeiro calculamos $\Sigma^{-1}$. Usando numpy:
> ```python
> import numpy as np
>
> mu1 = np.array([1, 2])
> mu2 = np.array([3, 1])
> sigma = np.array([[1, 0.5], [0.5, 1]])
> sigma_inv = np.linalg.inv(sigma)
>
> print("Sigma inversa:", sigma_inv)
> ```
> Em seguida, calculamos o termo $w = \Sigma^{-1}(\mu_2 - \mu_1) = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} * \begin{bmatrix} 2 \\ -1 \end{bmatrix} =  \begin{bmatrix} 3.34 \\ -2 \end{bmatrix}$. Este vetor $w$ define a dire√ß√£o da proje√ß√£o que melhor separa as classes. O valor $b$ da fun√ß√£o discriminante √© calculado como $ - \frac{1}{2} (\mu_2+\mu_1)^T \Sigma^{-1} (\mu_2 - \mu_1) $

#### Conceito 3: Logistic Regression
A **Logistic Regression** √© um modelo estat√≠stico que usa a fun√ß√£o log√≠stica para modelar a probabilidade de uma vari√°vel dependente bin√°ria. Ao contr√°rio do LDA, que assume distribui√ß√µes Gaussianas, a regress√£o log√≠stica modela diretamente a probabilidade de pertin√™ncia a uma classe atrav√©s de uma fun√ß√£o sigmoide (fun√ß√£o log√≠stica) [^8.4]:
$$ P(Y=1|X=x) = \frac{1}{1+e^{-(w^T x + b)}} $$
Os par√¢metros $w$ (pesos) e $b$ (vi√©s) s√£o estimados maximizando a verossimilhan√ßa dos dados observados. A fun√ß√£o de verossimilhan√ßa (likelihood) √© dada por $$ L(w,b) = \prod_{i=1}^N p(y_i|x_i; w,b)  = \prod_{i=1}^N P(Y=y_i|X=x_i; w,b)^{y_i}(1-P(Y=y_i|X=x_i; w,b))^{(1-y_i)} $$ onde $y_i$ √© o r√≥tulo verdadeiro (0 ou 1) da amostra $i$, e $P(Y=1|X=x_i; w,b)$ √© a probabilidade da classe ser 1. Usando o logaritmo, a fun√ß√£o log-verossimilhan√ßa √© dada por $$ log(L(w,b)) = \sum_{i=1}^N y_i \log(P(Y=1|X=x_i; w,b)) + (1-y_i)\log(1-P(Y=1|X=x_i; w,b)) $$ . O objetivo √© encontrar os par√¢metros que maximizam a log-verossimilhan√ßa.

```mermaid
graph LR
    subgraph "Logistic Regression Model"
         direction TB
        A["P(Y=1|X=x) = 1 / (1 + exp(-(w^T x + b)))"]
        B["Likelihood Function: L(w,b) = Œ† p(y_i|x_i; w,b)"]
        C["Log-Likelihood Function: log(L(w,b)) = Œ£ y_i log(P(Y=1|X=x_i)) + (1-y_i)log(1-P(Y=1|X=x_i))"]
        A --> B
        B --> C
    end
```

> ‚ö†Ô∏è **Nota Importante**: A regress√£o log√≠stica √© adequada para problemas de classifica√ß√£o com classes balanceadas. Em problemas com classes n√£o balanceadas, t√©cnicas de rebalanceamento ou m√©tricas de avalia√ß√£o mais adequadas s√£o recomendadas [^8.4].
> ‚ùó **Ponto de Aten√ß√£o**: LDA e regress√£o log√≠stica compartilham o fato de que as fronteiras de decis√£o s√£o lineares. No entanto, LDA assume que os dados prov√™m de distribui√ß√µes gaussianas com vari√¢ncias iguais, enquanto a regress√£o log√≠stica n√£o possui tal suposi√ß√£o.

> üí° **Exemplo Num√©rico:** Considere um dataset com 3 amostras e 2 features e r√≥tulos bin√°rios: $X = \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \end{bmatrix}$ e $Y = \begin{bmatrix} 0 \\ 1 \\ 1 \end{bmatrix}$.  Suponha que ap√≥s treinamento, a regress√£o log√≠stica encontrou os pesos $w = [0.5, -0.2]$ e o vi√©s $b = -0.1$. Para a primeira amostra $x = [1, 2]$, temos $w^T x + b = 0.5 * 1 - 0.2 * 2 - 0.1 = 0$. A probabilidade de pertencer √† classe 1 √©: $P(Y=1|X=x) = \frac{1}{1 + e^{-0}} = 0.5$. Para a segunda amostra $x = [2, 1]$, temos $w^T x + b = 0.5 * 2 - 0.2 * 1 - 0.1 = 0.7$. Assim, $P(Y=1|X=x) = \frac{1}{1 + e^{-0.7}} = 0.67$.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
    direction TB
        A["Encode Classes into Indicator Matrix"]
         B["Linear Regression: Predict Continuous Values"]
        C["Decision Threshold: Classify based on Predicted Values"]
        D["Estimate Coefficients: Œ≤ÃÇ = (H^T H)^-1 H^T y"]
        A --> B
        B --> C
        B --> D
    end
```

A regress√£o linear pode ser adaptada para problemas de classifica√ß√£o atrav√©s da codifica√ß√£o das classes em uma matriz de indicadores [^8.2]. Por exemplo, em um problema de classifica√ß√£o com duas classes, podemos codificar uma classe como 0 e outra como 1. A regress√£o linear √© ent√£o utilizada para predizer um valor cont√≠nuo que pode ser interpretado como uma probabilidade (embora a regress√£o linear n√£o garanta que os valores preditos estejam entre 0 e 1). A decis√£o final √© tomada atrav√©s de um limiar (threshold). Embora a regress√£o linear n√£o seja a abordagem mais robusta para classifica√ß√£o, ela serve como um ponto de partida √∫til para entender a constru√ß√£o de fronteiras lineares.

A estimativa dos coeficientes $\beta$ por m√≠nimos quadrados √© dada por:
$$ \hat{\beta} = (H^T H)^{-1} H^T y $$
onde $H$ √© a matriz de atributos e $y$ √© o vetor de r√≥tulos codificados. O valor predito para um dado $x$ √© dado por $\hat{\mu}(x) = \hat{\beta}^T h(x)$.

**Lemma 2:** *Equival√™ncia entre Proje√ß√µes*. Em um problema de classifica√ß√£o bin√°ria, a proje√ß√£o dos dados no hiperplano de decis√£o obtida atrav√©s da regress√£o linear √© equivalente √† proje√ß√£o obtida pelo LDA quando as matrizes de covari√¢ncia das classes s√£o iguais e os dados s√£o aproximadamente Gaussianos [^8.2]. Essa equival√™ncia surge porque ambos os m√©todos buscam encontrar a melhor proje√ß√£o linear que separa as classes, embora usem abordagens de otimiza√ß√£o diferentes. A regress√£o linear minimiza o erro quadr√°tico m√©dio, enquanto o LDA maximiza a separa√ß√£o entre classes [^8.2]. $\blacksquare$

**Corol√°rio 2:** *Rela√ß√£o com Discriminantes Lineares*. A equival√™ncia entre as proje√ß√µes da regress√£o linear e do LDA implica que, sob certas condi√ß√µes, ambos os m√©todos podem produzir resultados semelhantes. Essa rela√ß√£o simplifica a an√°lise do problema de classifica√ß√£o, pois podemos interpretar as proje√ß√µes como proje√ß√µes nos discriminantes lineares [^8.2]. No entanto, a regress√£o linear n√£o assume nenhuma distribui√ß√£o espec√≠fica dos dados, e pode gerar resultados inadequados quando a rela√ß√£o entre os atributos e os r√≥tulos √© n√£o-linear.

> üí° **Exemplo Num√©rico:**  Considere um conjunto de dados com duas classes, onde $H = \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \\ 4 & 2\end{bmatrix}$ e $y = \begin{bmatrix} 0 \\ 0 \\ 1 \\ 1 \end{bmatrix}$. Primeiro, calculamos $H^T H = \begin{bmatrix} 1 & 2 & 3 & 4 \\ 2 & 1 & 3 & 2 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \\ 4 & 2 \end{bmatrix} = \begin{bmatrix} 30 & 23 \\ 23 & 18 \end{bmatrix}$. Em seguida, $(H^T H)^{-1} = \frac{1}{(30*18 - 23*23)} \begin{bmatrix} 18 & -23 \\ -23 & 30 \end{bmatrix} = \begin{bmatrix} 1.54 & -1.97 \\ -1.97 & 2.56 \end{bmatrix}$. Calculamos $H^T y = \begin{bmatrix} 1 & 2 & 3 & 4 \\ 2 & 1 & 3 & 2 \end{bmatrix} \begin{bmatrix} 0 \\ 0 \\ 1 \\ 1 \end{bmatrix} = \begin{bmatrix} 7 \\ 5 \end{bmatrix}$. Finalmente, $\hat{\beta} = (H^T H)^{-1} H^T y = \begin{bmatrix} 1.54 & -1.97 \\ -1.97 & 2.56 \end{bmatrix} \begin{bmatrix} 7 \\ 5 \end{bmatrix} = \begin{bmatrix} 0.94 \\ -0.89\end{bmatrix}$. O valor predito para um novo $x = [2, 2]$ √© $\hat{\mu}(x) = \hat{\beta}^T x = 0.94 * 2 - 0.89 * 2 = 0.1$.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization in Logistic Regression"
    direction TB
         A["L1 Regularization: L(w) + Œª||w||_1"]
        B["L2 Regularization: L(w) + Œª||w||_2^2"]
        C["Elastic Net Regularization: L(w) + Œª_1||w||_1 + Œª_2||w||_2^2"]
        A --> C
        B --> C
        D["Cross-Validation: Parameter Selection"]
        C --> D
    end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas cruciais para evitar overfitting e melhorar a interpretabilidade do modelo. Em problemas de classifica√ß√£o, especialmente quando h√° muitas vari√°veis ou quando os dados s√£o esparsos, essas t√©cnicas ajudam a reduzir a vari√¢ncia e a complexidade do modelo. Na regress√£o log√≠stica, a regulariza√ß√£o L1 adiciona uma penalidade proporcional √† soma dos valores absolutos dos pesos: $$  L_{L_1}(w) = L(w) + \lambda ||w||_1 $$ , enquanto a regulariza√ß√£o L2 adiciona uma penalidade proporcional ao quadrado dos pesos: $$ L_{L_2}(w) = L(w) + \lambda ||w||_2^2 $$ [^8.4]. A regulariza√ß√£o L1 tende a levar a solu√ß√µes com pesos esparsos, ou seja, muitos pesos iguais a zero, o que pode simplificar a interpretabilidade do modelo e identificar as vari√°veis mais relevantes [^8.4]. A regulariza√ß√£o L2 tende a encolher os pesos, resultando em uma solu√ß√£o mais est√°vel.

**Lemma 3:** *Penaliza√ß√£o L1 e Esparsidade*. A penaliza√ß√£o L1 na regress√£o log√≠stica leva a coeficientes esparsos porque o termo de penalidade, $\lambda ||w||_1 = \lambda \sum_j |w_j|$, √© n√£o diferenci√°vel quando $w_j = 0$. Isso for√ßa o otimizador a convergir para solu√ß√µes onde muitos dos pesos $w_j$ s√£o exatamente zero. A intui√ß√£o √© que, para um dado custo de verossimilhan√ßa, o termo de penalidade $L1$ favorece solu√ß√µes com menos pesos grandes e mais pesos pr√≥ximos a zero, resultando em um modelo mais esparso.
**Prova:** A minimiza√ß√£o da fun√ß√£o de custo regularizada por $L_1$ busca um ponto onde o gradiente da fun√ß√£o de verossimilhan√ßa seja balanceado pelo termo de penalidade. Quando um dos pesos $w_j$ √© zero, o termo de penalidade $L_1$ imp√µe um pulo no gradiente, induzindo que muitos pesos fiquem iguais a zero. Formalmente, para um peso $w_j$, temos:
$$\frac{\partial L_{L_1}}{\partial w_j} = \frac{\partial L(w)}{\partial w_j} + \lambda \text{sign}(w_j)$$
Onde $\text{sign}(w_j) = 1$ se $w_j > 0$, $-1$ se $w_j < 0$, e $0$ se $w_j = 0$. O ponto de m√≠nimo geralmente √© onde $\frac{\partial L_{L_1}}{\partial w_j} = 0$, o que implica que $\frac{\partial L(w)}{\partial w_j} = -\lambda \text{sign}(w_j)$. Quando um coeficiente $w_j$ √© pr√≥ximo de zero, o termo $\text{sign}(w_j)$ faz com que a derivada fique igual a zero. Assim, muitos coeficientes se tornam exatamente zero. $\blacksquare$

```mermaid
graph LR
    subgraph "L1 Regularization Effect"
    direction TB
         A["Non-differentiable at w_j = 0"]
        B["Forces some w_j to be exactly zero"]
        C["Induces Sparsity in the Solution"]
        A --> B
        B --> C
    end
```

**Corol√°rio 3:** *Interpretabilidade da Esparsidade*. A esparsidade induzida pela penaliza√ß√£o L1 melhora a interpretabilidade dos modelos classificat√≥rios, pois as vari√°veis com pesos iguais a zero s√£o consideradas irrelevantes para a predi√ß√£o. Isso simplifica o modelo e permite identificar os fatores mais importantes na decis√£o de classifica√ß√£o [^8.4].

> ‚ö†Ô∏è **Ponto Crucial**: A combina√ß√£o de L1 e L2 (Elastic Net) pode fornecer um bom equil√≠brio entre esparsidade e estabilidade, aproveitando as vantagens de ambos os tipos de regulariza√ß√£o [^8.5]. O par√¢metro $\lambda$ de regulariza√ß√£o deve ser escolhido com cuidado usando t√©cnicas como valida√ß√£o cruzada.

> üí° **Exemplo Num√©rico:**  Suponha que estamos aplicando regress√£o log√≠stica com duas vari√°veis e temos os coeficientes $w = [0.8, -0.2]$ sem regulariza√ß√£o. Usando regulariza√ß√£o L1 com $\lambda = 0.5$, o novo vetor de pesos pode se tornar $w_{L1} = [0.3, 0]$. O coeficiente da segunda vari√°vel √© reduzido a zero, tornando-a irrelevante para o modelo. Com regulariza√ß√£o L2, com $\lambda=0.5$, o novo vetor de pesos pode se tornar $w_{L2} = [0.6, -0.15]$. Os coeficientes s√£o reduzidos em magnitude, mas ambos permanecem no modelo. O valor exato dos coeficientes ap√≥s regulariza√ß√£o depende da otimiza√ß√£o da fun√ß√£o de custo.

### Separating Hyperplanes e Perceptrons

A ideia central de hiperplanos separadores √© encontrar um hiperplano que maximize a margem de separa√ß√£o entre as classes [^8.5]. Esse conceito est√° intimamente relacionado com os _Support Vector Machines_ (SVM). No contexto de hiperplanos separadores, um hiperplano √≥timo √© aquele que maximiza a dist√¢ncia entre o hiperplano e os pontos mais pr√≥ximos de cada classe (os chamados vetores de suporte). A formula√ß√£o do problema de otimiza√ß√£o busca os par√¢metros do hiperplano que minimizam a dist√¢ncia aos pontos de treinamento, sujeitos a restri√ß√µes que garantem a separa√ß√£o correta das classes.

O Perceptron de Rosenblatt √© um algoritmo de aprendizado que busca encontrar um hiperplano que separa corretamente os dados de treinamento [^8.5]. Se os dados s√£o linearmente separ√°veis, o Perceptron garante a converg√™ncia para uma solu√ß√£o que separa corretamente as classes. O algoritmo atualiza iterativamente os pesos do hiperplano com base nos exemplos mal classificados, movendo o hiperplano em dire√ß√£o √† separa√ß√£o correta.

```mermaid
graph LR
    subgraph "Perceptron Algorithm"
    direction TB
        A["Initialize Weights (w) and Bias (b)"]
        B["Iterate through Training Data"]
        C["If Misclassified, Update Weights: w_new = w_old + Œ∑yx"]
        D["Converge to a Separating Hyperplane"]
        A --> B
        B --> C
        C --> B
        C --> D
    end
```

> üí° **Exemplo Num√©rico:** Considere duas classes linearmente separ√°veis: Classe 1 = $\{[1,1], [2,1]\}$ e Classe 2 = $\{[1,3], [2,3]\}$.  Inicializamos o Perceptron com $w = [0, 0]$ e $b = 0$. O algoritmo Perceptron itera sobre as amostras. Se uma amostra √© mal classificada, atualizamos os pesos: $w_{novo} = w_{antigo} + \eta y x$, onde $\eta$ √© a taxa de aprendizado (e.g. 0.1). Por exemplo, se o ponto $[1,1]$ da classe 1 √© classificado incorretamente como classe 2, atualizamos: $w = [0,0] + 0.1 * (-1) * [1,1] = [-0.1, -0.1]$. A itera√ß√£o continua at√© que todas as amostras sejam corretamente classificadas.

### Pergunta Te√≥rica Avan√ßada: Quais as implica√ß√µes da escolha de diferentes par√¢metros na Regulariza√ß√£o em Regress√£o Log√≠stica para a otimiza√ß√£o da fun√ß√£o de custo e a generaliza√ß√£o do modelo?
**Resposta:**
A escolha dos par√¢metros de regulariza√ß√£o na regress√£o log√≠stica impacta significativamente a otimiza√ß√£o da fun√ß√£o de custo e a generaliza√ß√£o do modelo. Uma regulariza√ß√£o L1 ($||w||_1$) com um par√¢metro $\lambda_1$ adequado induz esparsidade, for√ßando alguns coeficientes a serem exatamente zero. Isso simplifica o modelo e melhora a interpretabilidade ao selecionar apenas as caracter√≠sticas mais relevantes. No entanto, $\lambda_1$ muito grande pode levar a underfitting. J√° uma regulariza√ß√£o L2 ($||w||_2^2$) com par√¢metro $\lambda_2$ adequado suaviza a solu√ß√£o e evita que os pesos sejam muito grandes, o que contribui para a estabilidade do modelo. No entanto, $\lambda_2$ muito grande pode encolher os pesos em excesso, levando a underfitting. A fun√ß√£o de custo regularizada pode ser expressa como
$$ J(w) = L(w) + \lambda_1 ||w||_1 + \lambda_2 ||w||_2^2 $$
onde $L(w)$ √© a fun√ß√£o de log-verossimilhan√ßa. A otimiza√ß√£o busca minimizar essa fun√ß√£o de custo, encontrando um balan√ßo entre a precis√£o no treinamento (minimizando o erro) e a complexidade do modelo (minimizando a norma dos pesos). A escolha ideal de $\lambda_1$ e $\lambda_2$ envolve um compromisso entre a minimiza√ß√£o do erro e a generaliza√ß√£o, geralmente obtida por valida√ß√£o cruzada.

```mermaid
graph LR
    subgraph "Cost Function with Regularization"
        direction TB
        A["Cost Function: J(w)"]
        B["Log-Likelihood Loss: L(w)"]
        C["L1 Regularization: Œª_1||w||_1"]
        D["L2 Regularization: Œª_2||w||_2^2"]
        A --> B
        A --> C
        A --> D
    end
```

**Lemma 4:** *Influ√™ncia da Regulariza√ß√£o na Converg√™ncia*. A regulariza√ß√£o influencia a velocidade de converg√™ncia do otimizador. Regulariza√ß√£o L1 e L2 adicionam termos que modificam a superf√≠cie de otimiza√ß√£o da fun√ß√£o de custo, facilitando ou dificultando a converg√™ncia para uma solu√ß√£o √≥tima. Regulariza√ß√£o L2 com um valor adequado ($\lambda_2$) geralmente acelera a converg√™ncia, enquanto a regulariza√ß√£o L1 pode induzir comportamentos oscilat√≥rios na converg√™ncia devido √† n√£o diferenciabilidade.
**Prova:** A prova envolve analisar as condi√ß√µes de otimalidade da fun√ß√£o de custo regularizada, demonstrando como a regulariza√ß√£o afeta o gradiente e a Hessiana da fun√ß√£o. Para a regulariza√ß√£o $L_2$, a fun√ß√£o de custo √© quadr√°tica, levando a um problema de otimiza√ß√£o convexa que geralmente tem converg√™ncia r√°pida. A regulariza√ß√£o $L_1$ adiciona um termo n√£o diferenci√°vel, que cria quinas na superf√≠cie de otimiza√ß√£o, tornando a an√°lise de converg√™ncia mais complexa. $\blacksquare$

```mermaid
graph LR
    subgraph "Convergence with Regularization"
    direction TB
        A["L2: Convex Optimization, Faster Convergence"]
        B["L1: Non-differentiable, Oscillatory Convergence"]
        A --> C["Modifies the Cost Function's Optimization Landscape"]
        B --> C
    end
```

**Corol√°rio 4:** *Impacto na Complexidade do Modelo*. Uma combina√ß√£o adequada de $\lambda_1$ e $\lambda_2$ (Elastic Net) pode gerar um modelo esparso e est√°vel, equilibrando a interpretabilidade e a capacidade de generaliza√ß√£o. Valores elevados de $\lambda$ levam a modelos mais simples (underfitting), enquanto valores pequenos levam a modelos mais complexos (overfitting). A escolha dos par√¢metros de regulariza√ß√£o √© crucial para evitar esses problemas [^8.4].

> ‚ö†Ô∏è **Ponto Crucial**: A escolha dos par√¢metros de regulariza√ß√£o e do tipo de regulariza√ß√£o (L1, L2, Elastic Net) deve ser feita com cautela, considerando o contexto do problema e utilizando t√©cnicas de valida√ß√£o cruzada para otimizar o desempenho e generaliza√ß√£o do modelo.

### Bumping: Bootstrap Samples para Explora√ß√£o do Espa√ßo de Modelos

```mermaid
graph LR
    subgraph "Bumping Algorithm"
    direction TB
        A["Generate Multiple Bootstrap Samples"]
        B["Fit Model to Each Bootstrap Sample: f*b(x)"]
        C["Evaluate Model on Original Data"]
        D["Select Model with Lowest Training Error: argmin_b Œ£ (y_i - f*b(x_i))^2"]
        A --> B
        B --> C
         C --> D
    end
```

O _bumping_ √© uma t√©cnica que usa o _bootstrap_ para explorar o espa√ßo de modelos de forma a encontrar um modelo mais robusto [^8.9]. Ao contr√°rio do _bagging_, onde os resultados dos modelos s√£o agregados por meio da m√©dia, o _bumping_ seleciona um √∫nico modelo entre os diversos modelos gerados por _bootstrap_ (m√©todo de _resampling_). Essa abordagem √© particularmente √∫til quando o modelo de aprendizado √© propenso a ficar preso em m√≠nimos locais durante o treinamento. Ao perturbar os dados de treinamento por meio de _bootstrap samples_, o _bumping_ consegue movimentar a adapta√ß√£o do modelo para diferentes regi√µes do espa√ßo de solu√ß√µes, evitando um modelo ruim.

No _bumping_, para cada _bootstrap sample_ $Z^{*b}$, √© adaptado um modelo $f^{*b}(x)$. Ap√≥s adaptar o modelo em v√°rios _bootstrap samples_, seleciona-se o modelo $f^{*b^*}(x)$ com o menor erro de treino m√©dio para o conjunto de dados original:

$$ b^* = \text{argmin}_b \sum_{i=1}^N (y_i - f^{*b}(x_i))^2 $$

onde $y_i$ s√£o os r√≥tulos originais, $f^{*b}(x_i)$ s√£o as previs√µes para o bootstrap $b$ e $N$ √© o n√∫mero de amostras no conjunto de treinamento original. O modelo selecionado √© o modelo que minimiza o erro de previs√£o m√©dio sobre o conjunto de dados de treinamento original. Essa estrat√©gia permite que o modelo final seja escolhido de acordo com seu desempenho no conjunto de dados original, evitando que modelos pouco ajustados sejam agregados, como no caso do _bagging_.
√â importante notar que o bumping n√£o garante encontrar o √≥timo global, mas em vez disso explora regi√µes diferentes do espa√ßo de modelos, o que pode levar a um modelo com melhor desempenho do que o modelo inicial.

> üí° **Exemplo Num√©rico:** Considere um modelo que resulta em um MSE (Mean Squared Error) de 0.5 no conjunto de treino original. Ap√≥s gerar 5 _bootstrap samples_ e ajustar o modelo em cada um, obtemos os seguintes MSEs no conjunto original: {0.6, 0.4, 0.7, 0.3, 0.5}.  No bumping, selecionar√≠amos o modelo correspondente ao MSE de 0.3, pois √© o modelo com menor erro no conjunto original, e descartar√≠amos os outros.

### Conclus√£o

Este cap√≠tulo abordou uma variedade de t√©cnicas para infer√™ncia e modelagem, com foco no uso de _bootstrap samples_ e em m√©todos Bayesianos. Foi explorado como o _bootstrap_ pode ser usado para avaliar a incerteza, criar intervalos de confian√ßa e, por meio do _bagging_ e do _bumping_, melhorar as previs√µes. A rela√ß√£o entre o _bootstrap_, m√°xima verossimilhan√ßa e infer√™ncia Bayesiana foi examinada, demonstrando que, em muitos casos, o _bootstrap_ pode ser visto como uma aproxima√ß√£o n√£o param√©trica da infer√™ncia Bayesiana. O uso de regulariza√ß√£o e sele√ß√£o de vari√°veis, particularmente na regress√£o log√≠stica, foi analisado, mostrando como o controle da complexidade do modelo e a identifica√ß√£o de vari√°veis relevantes podem melhorar a generaliza√ß√£o. O _bumping_ emerge como uma estrat√©gia de busca estoc√°stica que pode auxiliar na identifica√ß√£o de modelos mais adequados.

### Footnotes

[^8.1]: "For most of this book, the fitting (learning) of models has been achieved by minimizing a sum of squares for regression, or by minimizing cross-entropy for classification. In fact, both of these minimizations are instances of the maximum likelihood approach to fitting."
[^8.2]: "Denote the training data by Z = {z1, z2,...,zN}, with zi = (xi, yi), i = 1, 2, ..., N. Here xi is a one-dimensional input, and yi the outcome, either continuous or categorical. As an example, consider the N = 50 data points shown in the left panel of Figure 8.1."
[^8.3]: "The bootstrap method described above, in which we sample with re- placement from the training data, is called the nonparametric bootstrap. This really means that the method is "model-free," since it uses the raw data, not a specific parametric model, to generate new datasets."
[^8.4]: "It turns out that the parametric bootstrap agrees with least squares in the previous example because the model (8.5) has additive Gaussian errors. In general, the parametric bootstrap agrees not with least squares but with maximum likelihood, which we now review."
[^8.5]: "Here is how we could apply the bootstrap in this example. We draw B datasets each of size N = 50 with replacement from our training data, the sampling unit being the pair zi = (xi, yi). To each bootstrap dataset Z* we fit a cubic spline Œº*(x); the fits from ten such samples are shown in the bottom left panel of Figure 8.2."
[^8.6]: "We begin by specifying a probability density or probability mass function for our observations
zi ~ gŒ∏(zi).
In this expression Œ∏ represents one or more unknown parameters that gov-
ern the distribution of Z. This is called a parametric model for Z."
[^8.7]: "Maximum likelihood is based on the likelihood function, given by
N
L(Œ∏; Z) = Œ† gŒ∏(zi),
i=1
the probability of the observed data under the model gŒ∏."
[^8.8]: "The likelihood function can be used to assess the precision of Œ∏. We need a few more definitions. The score function is defined by
N
‚Ñì(Œ∏; Z) = ‚àë ‚Ñì(Œ∏; zi),"
[^8.9]: "The main difference is that it samples from the conditional distributions rather than maximizing over them."
