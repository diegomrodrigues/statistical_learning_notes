## Model Inference and Averaging: Bumping for Tree Models

<imagem: Um diagrama complexo mostrando o processo de Bumping em modelos de √°rvore. O diagrama deve incluir a gera√ß√£o de amostras bootstrap, o ajuste de √°rvores em cada amostra, a avalia√ß√£o do erro no conjunto original de treinamento, e a sele√ß√£o do modelo com menor erro. As √°rvores devem ser representadas de forma hier√°rquica, com os n√≥s e divis√µes mostrando a variabilidade induzida pelo bootstrap. O diagrama deve enfatizar como o Bumping explora o espa√ßo de solu√ß√µes para encontrar uma √°rvore melhor.>

### Introdu√ß√£o

Este cap√≠tulo explora t√©cnicas avan√ßadas de infer√™ncia e combina√ß√£o de modelos, com foco em m√©todos que v√£o al√©m da simples minimiza√ß√£o de erros ou entropia cruzada [^8.1]. O conceito de **maximum likelihood**, j√° abordado em outras partes deste livro [^8.1], √© expandido e relacionado com m√©todos Bayesianos e o *bootstrap*. Al√©m disso, s√£o introduzidas t√©cnicas de *model averaging* e melhoria de modelos, como m√©todos de comit√™, *bagging*, *stacking* e *bumping* [^8.1]. Em particular, este cap√≠tulo se aprofundar√° no m√©todo de **bumping** aplicado a modelos de √°rvores, ilustrando como essa t√©cnica de busca estoc√°stica pode levar a modelos mais robustos e precisos. A aplica√ß√£o de bumping em modelos de √°rvore √© um exemplo not√°vel de como a perturba√ß√£o de dados pode ser usada para explorar o espa√ßo de modelos e encontrar solu√ß√µes mais adequadas, especialmente em cen√°rios onde m√©todos tradicionais podem ficar presos em m√≠nimos locais.

### Conceitos Fundamentais

**Conceito 1: Bootstrap e M√°xima Verossimilhan√ßa**
O m√©todo *bootstrap* √© uma t√©cnica computacional para avaliar a incerteza atrav√©s da amostragem da base de dados de treino [^8.2.1]. O *bootstrap* √© ilustrado em um problema de suaviza√ß√£o unidimensional, onde √© mostrada a sua liga√ß√£o com a **maximum likelihood** [^8.2.1]. Ao amostrar repetidamente com reposi√ß√£o do conjunto de dados original, o *bootstrap* permite estimar a variabilidade dos modelos e construir intervalos de confian√ßa. No contexto da *maximum likelihood*, o *bootstrap* √© usado como uma forma de simular a distribui√ß√£o dos estimadores de par√¢metros, particularmente quando as distribui√ß√µes te√≥ricas s√£o complexas ou desconhecidas [^8.2.2]. As estimativas de m√≠nimos quadrados e a matriz de covari√¢ncia dos par√¢metros podem ser derivadas utilizando a suposi√ß√£o de erros Gaussianos nos dados [^8.2].

> üí° **Exemplo Num√©rico:** Considere um conjunto de dados unidimensional com 10 pontos, `X = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]` e `y = [2, 4, 5, 4, 5, 7, 9, 10, 12, 13]`.  Para aplicar o bootstrap, vamos criar 3 amostras bootstrap. Uma poss√≠vel itera√ß√£o poderia gerar os seguintes √≠ndices para cada amostra: `sample_1_indices = [2, 5, 1, 8, 3, 2, 9, 4, 7, 5]`, `sample_2_indices = [6, 9, 1, 4, 3, 7, 2, 8, 5, 10]` e `sample_3_indices = [1, 3, 6, 8, 2, 9, 4, 7, 5, 10]`. Com esses √≠ndices, as amostras bootstrap correspondentes s√£o constru√≠das, e um modelo √© ajustado a cada amostra. Essas amostras nos ajudam a entender a variabilidade do modelo.

**Lemma 1:** A estimativa usual de $\beta$ (coeficientes) via m√≠nimos quadrados, dada por $\hat{\beta} = (H^TH)^{-1}H^Ty$ minimiza o erro quadr√°tico m√©dio no conjunto de treinamento, conforme ilustrado na equa√ß√£o (8.2) [^8.2]. Al√©m disso, a matriz de covari√¢ncia estimada para $\hat{\beta}$, $\text{Var}(\hat{\beta}) = (H^TH)^{-1}\hat{\sigma}^2$  onde $\hat{\sigma}^2$ √© o erro quadr√°tico m√©dio estimado,  reflete a incerteza associada √†s estimativas dos par√¢metros do modelo [^8.2].
$$
\hat{\beta} = (H^TH)^{-1}H^Ty \\
\text{Var}(\hat{\beta}) = (H^TH)^{-1}\hat{\sigma}^2
$$
$\blacksquare$

```mermaid
graph TB
    subgraph "Least Squares Estimation"
        direction TB
        A["Input: Data Matrix 'H', Response Vector 'y'"]
        B["Compute: H<sup>T</sup>H"]
        C["Compute: (H<sup>T</sup>H)<sup>-1</sup>"]
        D["Compute: H<sup>T</sup>y"]
        E["Estimate Coefficients: Œ≤ÃÇ = (H<sup>T</sup>H)<sup>-1</sup>H<sup>T</sup>y"]
         F["Estimate Variance: Var(Œ≤ÃÇ) = (H<sup>T</sup>H)<sup>-1</sup>œÉÃÇ¬≤"]

        A --> B
        B --> C
        C --> D
        D --> E
        C --> F
     end
```

> üí° **Exemplo Num√©rico:** Suponha que temos um problema de regress√£o com duas vari√°veis preditoras ($x_1$ e $x_2$) e uma vari√°vel resposta $y$.  Temos as seguintes observa√ß√µes:
>
> | Observa√ß√£o | $x_1$ | $x_2$ | $y$  |
> |------------|-------|-------|------|
> | 1          | 1     | 2     | 5    |
> | 2          | 2     | 3     | 8    |
> | 3          | 3     | 4     | 11   |
> | 4          | 4     | 5     | 14   |
>
> Adicionamos uma coluna de 1's para o intercepto:
> $H = \begin{bmatrix} 1 & 1 & 2 \\ 1 & 2 & 3 \\ 1 & 3 & 4 \\ 1 & 4 & 5 \end{bmatrix}$ , $y = \begin{bmatrix} 5 \\ 8 \\ 11 \\ 14 \end{bmatrix}$
>
> $\text{Step 1: Compute } H^T H = \begin{bmatrix} 4 & 10 & 14 \\ 10 & 30 & 41 \\ 14 & 41 & 54 \end{bmatrix}$
> $\text{Step 2: Compute } (H^T H)^{-1} = \begin{bmatrix} 2.666 & -1.333 & 0.333 \\ -1.333 & 1.666 & -0.666 \\ 0.333 & -0.666 & 0.333 \end{bmatrix}$
> $\text{Step 3: Compute } H^T y = \begin{bmatrix} 38 \\ 110 \\ 152 \end{bmatrix}$
> $\text{Step 4: Compute } \hat{\beta} = (H^T H)^{-1} H^T y = \begin{bmatrix} 2 \\ 1 \\ 1.5 \end{bmatrix}$
> $\text{Step 5: Calculate residuals: } \hat{y} = H\hat{\beta} = [5.0, 8.0, 11.0, 14.0]^T$. Residuals =  $y - \hat{y} = [0, 0, 0, 0]^T$.
> $\text{Step 6: Compute } \hat{\sigma}^2 = \frac{\sum_{i=1}^N (y_i - \hat{y}_i)^2}{N} = 0$. Since residuals are zero, $\hat{\sigma}^2$ is zero. In a real scenario we would have residuals and consequently, $\hat{\sigma}^2$.
> $\text{Step 7: Compute }  \text{Var}(\hat{\beta}) = (H^TH)^{-1}\hat{\sigma}^2 = \begin{bmatrix} 0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}$.
>
> Neste exemplo idealizado, o erro √© zero e a matriz de covari√¢ncia tamb√©m, o que n√£o aconteceria em um cen√°rio real. Em um problema real, a vari√¢ncia dos coeficientes indicaria a incerteza em suas estimativas.

**Conceito 2: Linearidade e N√£o Linearidade em Modelos**
Modelos lineares s√£o caracterizados por fun√ß√µes de decis√£o lineares e s√£o adequados para problemas onde a rela√ß√£o entre as caracter√≠sticas e a sa√≠da pode ser aproximada por uma combina√ß√£o linear [^8.2]. No entanto, modelos n√£o-lineares, como √°rvores de decis√£o, s√£o mais flex√≠veis e podem capturar rela√ß√µes complexas e intera√ß√µes entre as caracter√≠sticas [^8.7]. O *bumping* se torna particularmente √∫til em modelos n√£o-lineares, pois ajuda a explorar o espa√ßo de modelos, encontrando uma combina√ß√£o de par√¢metros e decis√µes que melhor se adaptam aos dados. As √°rvores de decis√£o, por exemplo, ao serem ajustadas em diferentes amostras bootstrap, resultam em diferentes parti√ß√µes de dados, permitindo ao bumping encontrar estruturas e rela√ß√µes mais robustas.

**Corol√°rio 1:** A combina√ß√£o de modelos lineares, por meio do *model averaging* e do *stacking*, pode melhorar a precis√£o e robustez de um modelo. O *stacking*, em particular, utiliza regress√µes sobre os resultados de diversos modelos para gerar um √∫nico modelo que √© capaz de superar a performance individual de cada modelo base, utilizando as predi√ß√µes cruzadas de cada um deles.

**Conceito 3: Bumping e a Busca Estoc√°stica em Modelos de √Årvore**
O *bumping* √© uma t√©cnica de busca estoc√°stica que utiliza o *bootstrap* para explorar o espa√ßo de modelos e encontrar uma solu√ß√£o mais adequada [^8.9]. Em modelos de √°rvore, o *bumping* usa o *bootstrap* para gerar uma cole√ß√£o de √°rvores. Em vez de calcular uma m√©dia de seus resultados, o *bumping* seleciona a √°rvore que apresenta o menor erro de treinamento no conjunto original [^8.9]. Essa estrat√©gia permite que o m√©todo evite ficar preso em m√≠nimos locais e explore diferentes parti√ß√µes dos dados, especialmente em problemas com intera√ß√µes complexas entre as caracter√≠sticas. O *bumping* busca, assim, uma √°rvore "melhor", que represente um √≥timo local no espa√ßo de todos os modelos de √°rvores poss√≠veis [^8.9].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

A regress√£o linear pode ser utilizada para a classifica√ß√£o ao se ajustar um modelo linear a uma matriz de indicadores. Essa abordagem minimiza o erro quadr√°tico m√©dio, onde cada classe √© representada por um vetor indicador [^8.2]. Apesar da sua simplicidade, a regress√£o linear como classificador pode sofrer com problemas de *masking* quando as classes est√£o sobrepostas ou apresentam uma complexidade n√£o linear. Nesses casos, a regress√£o linear pode gerar limites de decis√£o sub√≥timos ou mesmo inconsistentes com os dados. A utiliza√ß√£o de m√©todos mais robustos, como o *bootstrap*, a **maximum likelihood** e o *bumping* se torna relevante quando as suposi√ß√µes de linearidade n√£o se sustentam, ou para melhorar a estabilidade e precis√£o das estimativas.

```mermaid
flowchart TD
  subgraph "Linear Regression for Classification"
    A["Encode Classes as Indicator Vectors"] --> B["Estimate Coefficients using Least Squares"]
    B --> C["Apply Decision Rule: Class = argmax(prediction)"]
    C --> D["Analyze Limitations: Overfitting, Masking"]
  end
```

**Lemma 2:** A regress√£o linear em uma matriz de indicadores pode ser vista como um caso especial de um modelo de classifica√ß√£o linear, onde as classes s√£o codificadas como vetores indicadores. A decis√£o de classe √© dada pelo vetor indicador correspondente √† classe com maior valor de predi√ß√£o linear.
$$
\hat{y}_i = \sum_{j=1}^{k} \beta_j x_{ij} \\
\text{Classe}(x_i) = argmax_k(\hat{y}_{ik})
$$
$\blacksquare$

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com 3 classes (A, B, e C) e duas vari√°veis preditoras ($x_1$ e $x_2$).  Os dados podem ser representados como:
>
> | Observa√ß√£o | $x_1$ | $x_2$ | Classe |
> |------------|-------|-------|--------|
> | 1          | 1     | 2     | A      |
> | 2          | 2     | 3     | A      |
> | 3          | 3     | 4     | B      |
> | 4          | 4     | 5     | B      |
> | 5          | 1     | 4     | C      |
> | 6          | 2     | 5     | C      |
>
> Transformamos as classes em vetores indicadores: A=[1,0,0], B=[0,1,0], C=[0,0,1]. Criamos ent√£o 3 problemas de regress√£o (um para cada classe).
> A matriz H para a regress√£o da classe A √©:
> $H_A = \begin{bmatrix} 1 & 1 & 2 \\ 1 & 2 & 3 \\ 1 & 3 & 4 \\ 1 & 4 & 5 \\ 1 & 1 & 4 \\ 1 & 2 & 5 \end{bmatrix}$ e o vetor resposta para a classe A  $y_A = \begin{bmatrix} 1 \\ 1 \\ 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}$
>
> Ap√≥s realizar a regress√£o para cada classe, vamos supor que as predi√ß√µes para uma nova observa√ß√£o $x_{new} = [3,3]$ s√£o $\hat{y}_A(x_{new}) = 0.2, \hat{y}_B(x_{new}) = 0.6, \hat{y}_C(x_{new}) = 0.1$. A classe predita √© B, pois ela tem a maior predi√ß√£o.

**Corol√°rio 2:**  Em cen√°rios com separa√ß√£o linear clara entre classes, a regress√£o linear com uma matriz de indicadores pode gerar resultados compar√°veis a outros m√©todos de classifica√ß√£o linear. No entanto, quando as classes s√£o n√£o linearmente separ√°veis, a regress√£o de indicadores pode apresentar instabilidade, levando √† necessidade de regulariza√ß√£o ou utiliza√ß√£o de m√©todos mais sofisticados, como *boosting* ou *bagging*, que s√£o formas de combinar m√∫ltiplos resultados de modelos similares.

√â importante mencionar as limita√ß√µes da regress√£o linear para classifica√ß√£o. *As extrapola√ß√µes geradas podem levar a valores fora do intervalo [0, 1] em compara√ß√£o com m√©todos como a regress√£o log√≠stica, que garante estimativas de probabilidade consistentes*. Apesar dessas limita√ß√µes, *a regress√£o de indicadores oferece uma abordagem simples para a classifica√ß√£o e pode ser uma op√ß√£o interessante quando o objetivo principal √© uma fronteira de decis√£o linear*.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas cruciais para controlar a complexidade de modelos de classifica√ß√£o, prevenindo *overfitting* e melhorando a interpretabilidade. As penalidades L1 e L2 s√£o frequentemente utilizadas para induzir a *sparsity* dos modelos e controlar a magnitude dos coeficientes. Na regress√£o log√≠stica, a penalidade L1 (Lasso) for√ßa alguns coeficientes a zero, realizando uma sele√ß√£o de vari√°veis impl√≠cita, enquanto a penalidade L2 (Ridge) reduz a magnitude dos coeficientes, aumentando a robustez do modelo. *A combina√ß√£o das duas penalidades no Elastic Net busca equilibrar os benef√≠cios de ambas abordagens*.

**Lemma 3:** A penalidade L1 em modelos de classifica√ß√£o log√≠stica induz a coeficientes esparsos devido √† sua forma geom√©trica. Em situa√ß√µes onde h√° muitas vari√°veis preditoras, o L1 tem uma forte capacidade de reduzir o problema a um subconjunto mais relevante de caracter√≠sticas, conforme detalhado no texto [^8.2.2].
$$
l(0) = \sum_{i=1}^N \left[y_i \log(p(x_i)) + (1-y_i)\log(1-p(x_i))\right] - \lambda \sum_{j=1}^p |\beta_j|
$$
**Prova do Lemma 3:** A penalidade L1 (Lasso) introduz uma fun√ß√£o de penaliza√ß√£o que √© linear em rela√ß√£o aos coeficientes (em valor absoluto). Para minimizar a fun√ß√£o de custo, a L1 tende a for√ßar certos coeficientes a zero. Isso ocorre porque a penalidade L1 introduz um "canto" ou "quina" no espa√ßo de busca dos par√¢metros, onde a solu√ß√£o √≥tima frequentemente se encontra em um eixo, for√ßando alguns coeficientes a serem nulos. A penalidade L2, por outro lado, produz uma superf√≠cie de busca mais "suave", onde as solu√ß√µes s√£o distribu√≠das entre as vari√°veis. A combina√ß√£o dessas caracter√≠sticas (Elastic Net) produz uma regi√£o de busca mista, permitindo uma regulariza√ß√£o mais flex√≠vel e robusta. $\blacksquare$

```mermaid
graph LR
 subgraph "L1 Regularization"
  direction LR
  A["Loss Function: 'l(Œ∏)'"]
  B["Regularization Term: 'Œª * Œ£|Œ≤_j|'"]
  C["Objective: Minimize 'l(Œ∏) - Œª * Œ£|Œ≤_j|'"]
  A --> C
  B --> C
  D["Geometric Consequence: Corner Solutions and Sparsity"]
  C --> D
 end
```

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o log√≠stica com duas vari√°veis preditoras ($x_1$ e $x_2$) e uma vari√°vel de resposta bin√°ria $y$ (0 ou 1). A fun√ß√£o de custo (log-verossimilhan√ßa) √© dada por $l(0) = \sum_{i=1}^N \left[y_i \log(p(x_i)) + (1-y_i)\log(1-p(x_i))\right]$. Vamos adicionar a penalidade L1.
>
> Vamos supor que sem regulariza√ß√£o os coeficientes s√£o: $\beta_0 = 1, \beta_1 = 2, \beta_2 = -1$. Com L1 regulariza√ß√£o, a fun√ß√£o de custo se torna $l(0) = \sum_{i=1}^N \left[y_i \log(p(x_i)) + (1-y_i)\log(1-p(x_i))\right] - \lambda (|\beta_1| + |\beta_2|)$.
>
> Para $\lambda = 0.5$, o modelo de regress√£o log√≠stica com L1 regulariza√ß√£o pode ajustar os par√¢metros de forma que os novos coeficientes se tornem $\beta_0 = 0.8, \beta_1 = 1.2, \beta_2 = 0$, ou seja, for√ßou $\beta_2$ para 0.  Isso significa que a vari√°vel $x_2$ foi removida do modelo, indicando que ela pode ser menos relevante para a classifica√ß√£o nesse caso. Se $\lambda$ for alto o suficiente, mais coeficientes podem ser zerados, simplificando o modelo.

**Corol√°rio 3:** A esparsidade induzida pela penalidade L1 aumenta a interpretabilidade do modelo, identificando as vari√°veis mais relevantes para a classifica√ß√£o. Essa caracter√≠stica √© muito valiosa em cen√°rios onde se busca uma compreens√£o mais profunda dos fatores que influenciam a vari√°vel resposta.

> ‚ö†Ô∏è **Ponto Crucial**: A escolha adequada do tipo de regulariza√ß√£o, e do seu par√¢metro, pode ter um impacto significativo na qualidade da classifica√ß√£o e na interpretabilidade do modelo.

### Separating Hyperplanes e Perceptrons

O conceito de **separating hyperplanes** busca encontrar um hiperplano que divide as classes da forma mais eficiente poss√≠vel. Em particular, a ideia de maximizar a margem de separa√ß√£o leva ao conceito de hiperplanos √≥timos, onde a dist√¢ncia entre as classes e a fronteira de decis√£o √© maximizada. O Perceptron de Rosenblatt √© um algoritmo que busca encontrar um hiperplano separador por meio de atualiza√ß√µes iterativas dos pesos. O Perceptron converge se os dados s√£o linearmente separ√°veis, mas pode oscilar em cen√°rios n√£o linearmente separ√°veis, demonstrando a necessidade de m√©todos mais robustos ou de pr√©-processamento dos dados. O *bumping*, ao gerar diferentes modelos de √°rvore, pode contornar o problema da n√£o-linearidade, buscando uma representa√ß√£o melhor dos dados que separe as classes de forma adequada.

### Bumping em Modelos de √Årvore: Um estudo de caso detalhado

O **bumping**, em modelos de √°rvore, aplica o conceito do bootstrap para perturbar a base de dados e assim, encontrar um modelo com melhor desempenho. A perturba√ß√£o nos dados de treinamento gera uma s√©rie de modelos de √°rvore, onde cada um deles captura informa√ß√µes diferentes sobre os dados. A sele√ß√£o final do modelo √© realizada ao se comparar o desempenho de cada uma das √°rvores no conjunto original de treinamento, o que permite ao *bumping* evitar o *overfitting* e selecionar a melhor solu√ß√£o.

O processo do *bumping* pode ser resumido da seguinte forma:
1. **Gera√ß√£o de Amostras Bootstrap:** Gera-se uma cole√ß√£o de amostras bootstrap $Z^{*b}$, com $b = 1, 2, \ldots, B$,  a partir do conjunto de dados original.
2. **Ajuste de Modelos de √Årvore:** Para cada amostra bootstrap $Z^{*b}$, um modelo de √°rvore $f^{*b}(x)$ √© ajustado.
3. **Avalia√ß√£o do Desempenho:** O erro de previs√£o de cada modelo $f^{*b}(x)$ √© avaliado no conjunto de dados original.
4. **Sele√ß√£o do Modelo:**  Seleciona-se o modelo $f^{*b'}(x)$ que apresenta o menor erro m√©dio quadr√°tico sobre o conjunto de treinamento original.
$$
\hat{b} = argmin_{b} \frac{1}{N} \sum_{i=1}^N (y_i - f^{*b}(x_i))^2
$$

A natureza estoc√°stica do processo de *bumping* permite ao m√©todo escapar de √≥timos locais, que muitas vezes s√£o gerados por modelos de √°rvore que s√£o muito sens√≠veis √†s particularidades do conjunto de dados original.

```mermaid
graph TB
 subgraph "Bumping Process"
  direction TB
  A["Original Data: 'Z'"]
  B["Generate Bootstrap Samples: 'Z*b', b=1...B"]
  C["Fit Tree Model 'f*b(x)' to each 'Z*b'"]
  D["Evaluate Prediction Error of each 'f*b(x)' on original 'Z'"]
  E["Select Best Model 'f*b'(x)' based on minimum error"]
  A --> B
  B --> C
  C --> D
  D --> E
 end
```

> üí° **Exemplo Num√©rico:** Vamos supor que temos um conjunto de dados de treinamento com 100 amostras. Aplicamos o *bumping* com 10 amostras bootstrap. Cada amostra bootstrap √© usada para treinar uma √°rvore de decis√£o. Cada √°rvore √© ent√£o avaliada no conjunto de dados original e o erro m√©dio quadr√°tico (MSE) √© calculado. Os MSEs obtidos foram:
> | √Årvore | MSE |
> |--------|-----|
> | 1 | 0.5 |
> | 2 | 0.7 |
> | 3 | 0.4 |
> | 4 | 0.6 |
> | 5 | 0.8 |
> | 6 | 0.9 |
> | 7 | 0.5 |
> | 8 | 0.45|
> | 9 | 0.65|
> | 10| 0.75|
>
> O *bumping* selecionaria a √°rvore 3, pois ela obteve o menor MSE (0.4) dentre todas as √°rvores. A √°rvore 3 √© o modelo final selecionado.

### Pergunta Te√≥rica Avan√ßada: Quais as vantagens e desvantagens do Bumping em rela√ß√£o a outros m√©todos de combina√ß√£o de modelos como o Bagging?

**Resposta:**
O *bagging* e o *bumping* s√£o ambos baseados em amostragem bootstrap e podem reduzir a vari√¢ncia de modelos inst√°veis. No entanto, eles diferem na forma como combinam os resultados de modelos ajustados em amostras bootstrap. O *bagging* calcula a m√©dia das predi√ß√µes de todos os modelos, enquanto o *bumping* seleciona apenas o melhor modelo com base no seu desempenho no conjunto de treinamento original.

A principal vantagem do *bumping* √© a sua capacidade de evitar m√≠nimos locais, selecionando uma solu√ß√£o que represente um √≥timo local no espa√ßo de solu√ß√µes. Em contraste, o *bagging* pode suavizar as diferen√ßas entre os modelos, o que pode levar a uma perda de informa√ß√£o. O *bagging* √© especialmente eficaz quando todos os modelos t√™m um bom desempenho e a vari√¢ncia √© o principal problema. No entanto, quando existem modelos com desempenho significativamente pior do que outros, o *bumping* pode gerar melhores resultados.

**Lemma 4:** O *bagging* reduz a vari√¢ncia de estimadores inst√°veis, ao calcular a m√©dia das previs√µes de um conjunto de modelos. No entanto, o *bagging* √© menos eficaz em problemas onde existem m√∫ltiplos m√≠nimos locais. Formalmente, podemos mostrar que a vari√¢ncia de um estimador bagged √© dada por
$$
Var(\bar{f}_{bag}) = \frac{1}{B} Var(f_b) + \frac{B-1}{B}Cov(f_i, f_j)
$$
onde $f_b$ √© o estimador do bootstrap e $B$ √© o n√∫mero de amostras bootstrap. $\blacksquare$

```mermaid
graph TB
  subgraph "Bagging Variance"
    direction TB
    A["Variance of Bagged Estimator: 'Var(fÃÑ_bag)'"]
    B["Variance Component: '(1/B) * Var(f_b)'"]
    C["Covariance Component: '((B-1)/B) * Cov(f_i, f_j)'"]
    A --> B
    A --> C
    D["B: Number of Bootstrap Samples"]
    E["f_b: Estimator from Bootstrap Sample"]
    B --> D
    C --> E
  end
```

**Corol√°rio 4:** O *bumping*, ao escolher o melhor modelo com base no desempenho do conjunto de dados original, tende a selecionar um estimador que √© mais apropriado do ponto de vista de seu ajuste e desempenho. Em contrapartida, o *bagging*, ao suavizar os resultados, n√£o √© capaz de evitar √≥timos locais t√£o facilmente como o *bumping*. No entanto, √© importante notar que a vari√¢ncia do *bumping* pode ser alta, uma vez que a variabilidade na sele√ß√£o de qual modelo √© o melhor introduz ru√≠do no processo.

> ‚ö†Ô∏è **Ponto Crucial**: A escolha entre *bagging* e *bumping* depende da natureza do problema. O *bagging* √© mais apropriado para modelos que s√£o inst√°veis mas onde todas as amostras bootstraps levam a modelos razo√°veis. O *bumping* √© mais adequado quando existem m√∫ltiplos m√≠nimos locais e se busca uma solu√ß√£o que combine o melhor ajuste aos dados.

> üí° **Exemplo Num√©rico:**  Vamos comparar o *bagging* e o *bumping* usando o exemplo de modelos de √°rvores. Suponha que temos 3 modelos de √°rvores ajustados em amostras bootstrap. Para uma nova entrada $x_{new}$ as predi√ß√µes s√£o $f_1(x_{new}) = 0.2$, $f_2(x_{new}) = 0.8$, $f_3(x_{new}) = 0.3$. Al√©m disso, vamos supor que no conjunto de treino, os erros quadr√°ticos m√©dios foram $MSE_1 = 0.6$, $MSE_2=0.2$ e $MSE_3=0.5$.
>
> **Bagging:** A predi√ß√£o do *bagging* √© a m√©dia das predi√ß√µes individuais: $\hat{f}_{bag}(x_{new}) = (0.2 + 0.8 + 0.3) / 3 = 0.43$.
>
> **Bumping:** O *bumping* selecionaria o modelo 2, pois ele obteve o menor erro no conjunto de treinamento (MSE=0.2). Ent√£o a predi√ß√£o √© $\hat{f}_{bump}(x_{new}) = 0.8$.
>
> Observa-se que *bagging* gera uma predi√ß√£o m√©dia, que pode suavizar as particularidades dos modelos. *Bumping* escolhe o melhor modelo, o que pode levar a resultados melhores se um dos modelos for significativamente melhor que os outros.

### Conclus√£o

Este cap√≠tulo explorou m√©todos de infer√™ncia e *model averaging* com um foco especial no m√©todo de *bumping* aplicado a modelos de √°rvore. O *bumping* demonstrou ser uma t√©cnica promissora para encontrar melhores solu√ß√µes em modelos com instabilidades e m√∫ltiplos √≥timos locais, como √© o caso das √°rvores de decis√£o. O *bumping*, ao utilizar amostragem *bootstrap* e sele√ß√£o do modelo com melhor desempenho no conjunto original, consegue melhorar a robustez e precis√£o dos modelos, evitando os problemas de *overfitting* e outros problemas associados a algoritmos gulosos. Em resumo, o *bumping* e o *bagging* oferecem abordagens robustas para aprimorar modelos e obter melhores previs√µes, com cada m√©todo tendo suas particularidades e cen√°rios de aplica√ß√£o apropriados. A combina√ß√£o de diferentes t√©cnicas de infer√™ncia e *model averaging* permite um aprofundamento na an√°lise dos dados, e uma maior precis√£o e robustez dos modelos.

<!-- END DOCUMENT -->
### Footnotes
[^8.1]: "In this chapter we provide a general exposition of the maximum likelihood approach, as well as the Bayesian method for inference. The bootstrap, introduced in Chapter 7, is discussed in this context, and its relation to maximum likelihood and Bayes is described. Finally, we present some related techniques for model averaging and improvement, including committee methods, bagging, stacking and bumping." *(Trecho de Model Inference and Averaging)*
[^8.2]: "Denote the training data by $Z = \{z_1, z_2, \ldots, z_N\}$, with $z_i = (x_i, y_i)$, $i = 1, 2, \ldots, N$. Here $x_i$ is a one-dimensional input, and $y_i$ the outcome, either continuous or categorical. As an example, consider the $N = 50$ data points shown in the left panel of Figure 8.1. Suppose we decide to fit a cubic spline to the data, with three knots placed at the quartiles of the X values. This is a seven-dimensional linear space of functions, and can be represented, for example, by a linear expansion of B-spline basis functions (see Section 5.9.2): $\mu(x) = \sum_{j=1}^7 \beta_j h_j(x)$. Here the $h_j(x)$, $j = 1, 2, \ldots, 7$ are the seven functions shown in the right panel of Figure 8.1. We can think of $\mu(x)$ as representing the conditional mean $E(Y|X = x)$. Let H be the $N \times 7$ matrix with ijth element $h_j(x_i)$. The usual estimate of $\beta$, obtained by minimizing the squared error over the training set, is given by $\hat{\beta} = (H^T H)^{-1} H^T y$. The corresponding fit $\hat{\mu}(x) = \sum_{j=1}^7 \hat{\beta}_j h_j(x)$ is shown in the top left panel of Figure 8.2. The estimated covariance matrix of $\hat{\beta}$ is $\text{Var}(\hat{\beta}) = (H^T H)^{-1} \hat{\sigma}^2$, where we have estimated the noise variance by $\hat{\sigma}^2 = \sum_{i=1}^N (y_i - \hat{\mu}(x_i))^2/N$." *(Trecho de Model Inference and Averaging)*
[^8.2.1]: "The bootstrap method provides a direct computational way of assessing uncertainty, by sampling from the training data. Here we illustrate the bootstrap in a simple one-dimensional smoothing problem, and show its connection to maximum likelihood." *(Trecho de Model Inference and Averaging)*
[^8.2.2]: "It turns out that the parametric bootstrap agrees with least squares in the previous example because the model (8.5) has additive Gaussian errors. In general, the parametric bootstrap agrees not with least squares but with maximum likelihood, which we now review." *(Trecho de Model Inference and Averaging)*
[^8.7]: "Earlier we introduced the bootstrap as a way of assessing the accuracy of a parameter estimate or a prediction. Here we show how to use the bootstrap to improve the estimate or prediction itself. In Section 8.4 we investigated the relationship between the bootstrap and Bayes approaches, and found that the bootstrap mean is approximately a posterior average. Bagging further exploits this connection.  Consider first the regression problem. Suppose we fit a model to our training data $Z = \{(x_1, y_1), (x_2, y_2), \ldots, (x_N, y_N)\}$, obtaining the prediction $f(x)$ at input $x$. Bootstrap aggregation or bagging averages this prediction over a collection of bootstrap samples, thereby reducing its variance. For each bootstrap sample $Z^{*b}$, $b = 1, 2, \ldots, B$, we fit our model, giving prediction $f^{*b}(x)$. The bagging estimate is defined by $\hat{f}_{bag}(x) = \frac{1}{B} \sum_{b=1}^B f^{*b}(x)$." *(Trecho de Model Inference and Averaging)*
[^8.9]: "The final method described in this chapter does not involve averaging or combining models, but rather is a technique for finding a better single model. Bumping uses bootstrap sampling to move randomly through model space. For problems where fitting method finds many local minima, bumping can help the method to avoid getting stuck in poor solutions. As in bagging, we draw bootstrap samples and fit a model to each. But rather than average the predictions, we choose the model estimated from a bootstrap sample that best fits the training data." *(Trecho de Model Inference and Averaging)*
