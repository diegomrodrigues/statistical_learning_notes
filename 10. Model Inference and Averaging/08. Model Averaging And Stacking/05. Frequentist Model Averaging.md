## Frequentist Viewpoint of Model Averaging

<imagem: Um mapa mental complexo que conecta os conceitos de bootstrap, maximum likelihood, Bayesian methods, model averaging, bagging, stacking e bumping, mostrando como eles se relacionam e diferem em um contexto de an√°lise estat√≠stica avan√ßada e aprendizado de m√°quina.>

### Introdu√ß√£o
Este cap√≠tulo aborda m√©todos de infer√™ncia de modelos e t√©cnicas de *model averaging*, focando em uma perspectiva *frequentista*. A maior parte do material anterior se concentrou no ajuste de modelos por meio da minimiza√ß√£o de somas de quadrados para regress√£o, ou da minimiza√ß√£o de *cross-entropy* para classifica√ß√£o [^8.1]. Ambas essas abordagens s√£o, na verdade, inst√¢ncias do m√©todo de **maximum likelihood**. Este cap√≠tulo, no entanto, aprofunda o conceito de *maximum likelihood*, explora m√©todos Bayesianos de infer√™ncia, discute o *bootstrap* e sua rela√ß√£o com *maximum likelihood* e Bayes, e apresenta t√©cnicas para *model averaging* e melhoria de modelos como comit√™s, *bagging*, *stacking* e *bumping* [^8.1].

### Conceitos Fundamentais
Aqui, exploramos os conceitos que formam a base para a compreens√£o das t√©cnicas de modelagem e infer√™ncia:

**Conceito 1:** O problema de classifica√ß√£o e o uso de m√©todos lineares est√£o intimamente ligados aos conceitos de **vi√©s** e **vari√¢ncia**. Modelos mais simples, como a regress√£o linear, t√™m alto vi√©s, mas baixa vari√¢ncia, enquanto modelos mais complexos tendem a ter baixo vi√©s e alta vari√¢ncia. O equil√≠brio entre vi√©s e vari√¢ncia √© fundamental para obter boas generaliza√ß√µes do modelo para novos dados [^8.1]. A escolha entre um modelo linear e um n√£o linear impacta diretamente essa din√¢mica.

> üí° **Exemplo Num√©rico:** Imagine que temos um conjunto de dados com uma rela√ß√£o n√£o linear entre a vari√°vel preditora e a resposta. Um modelo de regress√£o linear (alta vi√©s) pode falhar em capturar essa rela√ß√£o, levando a um erro grande. Por outro lado, um modelo polinomial de alta ordem (baixa vi√©s, alta vari√¢ncia) pode se ajustar perfeitamente aos dados de treinamento, mas se comportar mal em dados novos devido ao *overfitting*. O ponto ideal estaria em um modelo que equilibre vi√©s e vari√¢ncia, como um modelo polinomial de ordem moderada ou um modelo de regress√£o com regulariza√ß√£o.
>
> Considere um exemplo de regress√£o com dados gerados por $y = \sin(x) + \epsilon$, onde $\epsilon \sim \mathcal{N}(0, 0.2^2)$.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression
> from sklearn.preprocessing import PolynomialFeatures
> from sklearn.metrics import mean_squared_error
>
> # Gerar dados
> np.random.seed(42)
> X = np.sort(np.random.rand(50) * 5)
> y = np.sin(X) + np.random.normal(0, 0.2, 50)
> X = X.reshape(-1, 1)
>
> # Regress√£o Linear
> linear_model = LinearRegression()
> linear_model.fit(X, y)
> y_linear_pred = linear_model.predict(X)
> mse_linear = mean_squared_error(y, y_linear_pred)
>
> # Regress√£o Polinomial (Grau 10)
> poly = PolynomialFeatures(degree=10)
> X_poly = poly.fit_transform(X)
> poly_model = LinearRegression()
> poly_model.fit(X_poly, y)
> y_poly_pred = poly_model.predict(X_poly)
> mse_poly = mean_squared_error(y, y_poly_pred)
>
> # Visualiza√ß√£o
> plt.figure(figsize=(10, 6))
> plt.scatter(X, y, color='blue', label='Dados Reais')
> plt.plot(X, y_linear_pred, color='red', label=f'Regress√£o Linear (MSE: {mse_linear:.2f})')
>
> plt.plot(X, y_poly_pred, color='green', label=f'Regress√£o Polinomial (MSE: {mse_poly:.2f})')
> plt.xlabel('X')
> plt.ylabel('y')
> plt.title('Vi√©s-Vari√¢ncia: Regress√£o Linear vs Polinomial')
> plt.legend()
> plt.show()
>
> print(f"MSE Linear: {mse_linear:.2f}")
> print(f"MSE Polinomial: {mse_poly:.2f}")
> ```
>
> **Interpreta√ß√£o:** A regress√£o linear, com seu alto vi√©s, apresenta um MSE maior do que a regress√£o polinomial de grau 10, que tem baixa vi√©s, mas alta vari√¢ncia e pode n√£o generalizar t√£o bem para novos dados.

```mermaid
graph TD
    subgraph "Bias-Variance Tradeoff"
        direction TB
        A["Model Complexity"]
        B["High Bias, Low Variance"]
        C["Low Bias, High Variance"]
        D["Optimal Model"]
        A --> B
        A --> C
        B --> D
        C --> D
    end
```

**Lemma 1:** A proje√ß√£o de um vetor de dados em um hiperplano definido por uma fun√ß√£o discriminante linear, como na **Linear Discriminant Analysis (LDA)**, pode ser representada como uma combina√ß√£o linear de vetores de base. Isso se relaciona diretamente √† ideia de que a fun√ß√£o discriminante √© uma combina√ß√£o linear de vari√°veis, como visto em [^8.3]. Matematicamente, podemos expressar isso como:
$$
  f(x) = \sum_{j=1}^{p} \beta_j h_j(x)
$$
Onde $f(x)$ √© a fun√ß√£o discriminante, $h_j(x)$ s√£o as fun√ß√µes de base, e $\beta_j$ s√£o os coeficientes correspondentes.
$\blacksquare$

**Conceito 2:** A **Linear Discriminant Analysis (LDA)** √© uma t√©cnica que busca encontrar a melhor combina√ß√£o linear de *features* para separar diferentes classes, assumindo que os dados de cada classe seguem uma distribui√ß√£o normal com covari√¢ncias iguais [^8.3]. A fronteira de decis√£o √© obtida por meio da maximiza√ß√£o da raz√£o entre a varia√ß√£o entre classes e a varia√ß√£o dentro das classes [^8.3.1]. Formalmente, isso envolve encontrar um vetor $w$ que maximize:
$$
\frac{w^T S_B w}{w^T S_W w}
$$
Onde $S_B$ e $S_W$ s√£o as matrizes de dispers√£o entre e dentro das classes, respectivamente [^8.3.2]. A LDA √© uma t√©cnica cl√°ssica para classifica√ß√£o e redu√ß√£o de dimensionalidade e √© √∫til quando essas premissas s√£o v√°lidas.

> üí° **Exemplo Num√©rico:** Suponha que temos duas classes de flores, cada uma com duas caracter√≠sticas (comprimento da s√©pala e largura da s√©pala). O objetivo da LDA √© encontrar um eixo linear que projete os dados de forma que as classes sejam mais separadas ao longo desse eixo.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
> from sklearn.preprocessing import StandardScaler
>
> # Dados de exemplo
> np.random.seed(42)
> X1 = np.random.multivariate_normal([2, 2], [[1, 0.5], [0.5, 1]], 50)
> X2 = np.random.multivariate_normal([5, 4], [[1, 0.2], [0.2, 1]], 50)
> X = np.vstack((X1, X2))
> y = np.array([0] * 50 + [1] * 50)
>
> # Padroniza√ß√£o dos dados
> scaler = StandardScaler()
> X_scaled = scaler.fit_transform(X)
>
> # Aplica√ß√£o do LDA
> lda = LinearDiscriminantAnalysis()
> X_lda = lda.fit_transform(X_scaled, y)
>
> # Visualiza√ß√£o
> plt.figure(figsize=(10, 6))
> plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=y, cmap='viridis', edgecolors='k', label='Dados Originais')
> plt.xlabel('Comprimento da S√©pala (Padronizado)')
> plt.ylabel('Largura da S√©pala (Padronizado)')
>
> # Gerando pontos para a linha de decis√£o LDA
> w = lda.coef_[0]
> a = -w[0] / w[1]
> xx = np.linspace(X_scaled[:, 0].min(), X_scaled[:, 0].max())
> yy = a * xx - (lda.intercept_[0]) / w[1]
>
> plt.plot(xx, yy, 'k-', label='Fronteira de Decis√£o LDA')
>
>
> plt.title('LDA: Separa√ß√£o de Classes')
> plt.legend()
> plt.show()
> ```
> **Interpreta√ß√£o:** A LDA encontra um eixo linear (a linha preta na visualiza√ß√£o) que maximiza a separa√ß√£o entre as duas classes, projetando os dados em uma √∫nica dimens√£o.

```mermaid
graph LR
    subgraph "LDA Optimization"
        direction LR
        A["Maximize:"] --> B["w^T S_B w"]
        A --> C["w^T S_W w"]
        B --> D["Objective Function:  (w^T S_B w) / (w^T S_W w)"]
        C --> D
        D --> E["Optimal w"]
    end
```

**Corol√°rio 1:** Ao projetar os dados em um subespa√ßo de menor dimens√£o, como na LDA, buscamos maximizar a separa√ß√£o entre as classes, minimizando simultaneamente a perda de informa√ß√£o. Isso pode ser derivado da formula√ß√£o de otimiza√ß√£o da LDA, onde o objetivo √© encontrar um subespa√ßo linear que melhor capture a varia√ß√£o entre classes, como mostrado em [^8.3.1], resultando em um espa√ßo transformado com dimens√µes reduzidas para a tomada de decis√£o.

**Conceito 3:** A **Logistic Regression** modela a probabilidade de uma observa√ß√£o pertencer a uma classe espec√≠fica usando a fun√ß√£o log√≠stica (sigmoide) [^8.4]. O logit (log-odds) √© expresso como uma fun√ß√£o linear das vari√°veis preditoras [^8.4.1]. O modelo √© ajustado por meio da maximiza√ß√£o da verossimilhan√ßa, que encontra os par√¢metros que melhor explicam os dados observados [^8.4.2]. A fun√ß√£o de verossimilhan√ßa para a regress√£o log√≠stica √© dada por:
$$
L(\beta) = \prod_{i=1}^{N} p(x_i)^{y_i}(1 - p(x_i))^{1-y_i}
$$
Onde $p(x_i)$ √© a probabilidade da classe 1 dado o vetor de features $x_i$ e $y_i$ √© a resposta observada (0 ou 1). O m√©todo busca encontrar os $\beta$ que maximizam essa fun√ß√£o. Diferentemente da LDA, a regress√£o log√≠stica n√£o assume que os dados seguem uma distribui√ß√£o normal e pode ser mais apropriada quando essa suposi√ß√£o n√£o √© v√°lida.

> üí° **Exemplo Num√©rico:** Considere a previs√£o de se um cliente ir√° comprar um produto com base em seu hist√≥rico de navega√ß√£o e compras. As vari√°veis preditoras s√£o "tempo de navega√ß√£o" (em minutos) e "n√∫mero de produtos visitados". A resposta √© bin√°ria: 1 se o cliente comprar, 0 caso contr√°rio.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LogisticRegression
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import accuracy_score, classification_report
>
> # Gera√ß√£o de dados de exemplo
> np.random.seed(42)
> X = np.random.rand(200, 2) * 10  # Tempo de navega√ß√£o e n¬∫ de produtos
> y = (1 / (1 + np.exp(-(0.5 * X[:, 0] + 0.8 * X[:, 1] - 5))) > 0.5).astype(int)
>
> # Dividindo os dados em treino e teste
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Treinamento do modelo de regress√£o log√≠stica
> logistic_model = LogisticRegression()
> logistic_model.fit(X_train, y_train)
>
> # Predi√ß√µes e avalia√ß√£o
> y_pred = logistic_model.predict(X_test)
> accuracy = accuracy_score(y_test, y_pred)
> report = classification_report(y_test, y_pred)
>
> # Visualiza√ß√£o da fronteira de decis√£o
> plt.figure(figsize=(10, 6))
> x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
> y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
> xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))
> Z = logistic_model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)
> plt.contourf(xx, yy, Z, cmap='RdBu', alpha=0.5)
>
> plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='RdBu', edgecolors='k', label='Dados de Teste')
> plt.xlabel('Tempo de Navega√ß√£o (min)')
> plt.ylabel('N√∫mero de Produtos Visitados')
> plt.title(f'Regress√£o Log√≠stica (Acur√°cia: {accuracy:.2f})')
> plt.legend()
> plt.show()
>
> print("Classification Report:\n", report)
>
> # Coeficientes encontrados
> print("Coeficientes (Intercept, Coef1, Coef2):", logistic_model.intercept_, logistic_model.coef_)
> ```
>
> **Interpreta√ß√£o:** O modelo de regress√£o log√≠stica gera uma fronteira de decis√£o linear (a √°rea colorida na visualiza√ß√£o) para separar as classes e predizer a probabilidade de compra. A acur√°cia e o classification report fornecem uma avalia√ß√£o do desempenho do modelo. Os coeficientes encontrados indicam o peso de cada vari√°vel no modelo.

```mermaid
graph LR
    subgraph "Logistic Regression"
      direction LR
      A["Linear Predictor: logit(p) = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + ... + Œ≤‚Çöx‚Çö"]
      B["Logistic Function: p(x) = 1 / (1 + exp(-logit(p)))"]
      C["Likelihood Function: L(Œ≤) = Œ† p(x·µ¢)^y·µ¢ (1 - p(x·µ¢))^(1-y·µ¢)"]
      A --> B
      B --> C
      C --> D["Maximize L(Œ≤) to Estimate Œ≤"]
    end
```

> ‚ö†Ô∏è **Nota Importante**: A escolha entre LDA e regress√£o log√≠stica depende das suposi√ß√µes dos dados e do objetivo do modelo. LDA funciona bem com dados aproximadamente normais, enquanto a regress√£o log√≠stica pode ser mais flex√≠vel quando essa suposi√ß√£o n√£o se mant√©m, de acordo com [^8.4.1].

> ‚ùó **Ponto de Aten√ß√£o**: Em cen√°rios com classes n√£o balanceadas, a regress√£o log√≠stica pode precisar de ajustes para evitar vi√©s nas predi√ß√µes, como o uso de pesos de classe, conforme indicado em [^8.4.2].

> ‚úîÔ∏è **Destaque**: As estimativas de par√¢metros em LDA e regress√£o log√≠stica podem estar correlacionadas, especialmente quando as classes s√£o bem separadas e as suposi√ß√µes da LDA s√£o aproximadamente v√°lidas, conforme mostrado em [^8.5].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
<imagem: Um diagrama que ilustra o processo de regress√£o de indicadores, mostrando como as classes s√£o codificadas, os coeficientes s√£o estimados e as regras de decis√£o s√£o aplicadas.>

```mermaid
flowchart TD
    A[Codifica√ß√£o de Classes] --> B{Estimar Coeficientes};
    B --> C[Regra de Decis√£o];
    C --> D{Avalia√ß√£o do Modelo};
    D --> E[Classifica√ß√£o];
```

**Explica√ß√£o:** Este diagrama ilustra o fluxo de passos em um problema de classifica√ß√£o utilizando regress√£o de indicadores, seguindo as ideias de [^8.2]. Primeiro, as classes s√£o codificadas em valores num√©ricos, os coeficientes s√£o estimados por m√≠nimos quadrados e ent√£o as regras de decis√£o s√£o estabelecidas.

A regress√£o linear aplicada a uma matriz de indicadores pode ser usada para tarefas de classifica√ß√£o, onde cada classe √© codificada como uma coluna de uma matriz indicadora. As limita√ß√µes dessa abordagem s√£o que as predi√ß√µes podem ficar fora do intervalo [0,1] e n√£o modelam diretamente as probabilidades de classe [^8.2]. Por exemplo, em um problema de classifica√ß√£o bin√°ria, podemos codificar a classe 1 como 1 e a classe 0 como 0, e em seguida aplicar a regress√£o linear. Isso pode ser problem√°tico, pois n√£o for√ßa as predi√ß√µes a se manterem dentro do intervalo probabil√≠stico de [0,1]. As provas matem√°ticas para essas estimativas s√£o derivadas de minimizar o erro quadr√°tico entre a resposta e a predi√ß√£o linear, ou seja:
$$
\hat{\beta} = (H^T H)^{-1} H^T y
$$
Onde $H$ √© a matriz de design e $y$ √© o vetor de respostas [^8.2]. Este √© um resultado bem conhecido em √°lgebra linear e estat√≠stica. Al√©m disso, problemas como o "masking problem", mencionado em [^8.3], podem ocorrer quando vari√°veis correlacionadas mascaram umas √†s outras no processo de ajuste.

> üí° **Exemplo Num√©rico:** Para ilustrar a regress√£o de indicadores, vamos considerar um problema de classifica√ß√£o com tr√™s classes. Criaremos dados sint√©ticos para esse exemplo.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression
> from sklearn.preprocessing import OneHotEncoder
> from sklearn.metrics import accuracy_score
>
> # Criar dados sint√©ticos para 3 classes
> np.random.seed(42)
> n_samples = 150
> X = np.random.rand(n_samples, 2) * 10 # 2 Features
> y = np.zeros(n_samples, dtype=int)
> y[:50] = 0 # Classe 0
> y[50:100] = 1 # Classe 1
> y[100:] = 2 # Classe 2
>
> # Codificar as classes usando One-Hot Encoding
> encoder = OneHotEncoder(sparse_output=False)
> y_encoded = encoder.fit_transform(y.reshape(-1, 1))
>
> # Regress√£o Linear para cada classe
> model = LinearRegression()
> model.fit(X, y_encoded)
>
> # Fazer predi√ß√µes
> y_pred = model.predict(X)
>
> # Escolher a classe com maior probabilidade para cada amostra
> y_pred_classes = np.argmax(y_pred, axis=1)
>
> # Calcular acur√°cia
> accuracy = accuracy_score(y, y_pred_classes)
>
> # Visualiza√ß√£o
> plt.figure(figsize=(10, 6))
> plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolors='k')
>
> # Plota os pontos de decis√£o (as 3 classes)
> h = 0.02
> x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
> y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
> xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
> Z = np.argmax(model.predict(np.c_[xx.ravel(), yy.ravel()]), axis=1)
> Z = Z.reshape(xx.shape)
> plt.contourf(xx, yy, Z, cmap='viridis', alpha=0.2)
>
> plt.xlabel('Feature 1')
> plt.ylabel('Feature 2')
> plt.title(f'Regress√£o de Indicadores para Classifica√ß√£o (Acur√°cia: {accuracy:.2f})')
> plt.show()
>
> print(f"Acur√°cia do modelo: {accuracy:.2f}")
> print(f"Coeficientes:\n {model.coef_}")
> ```
>
> **Interpreta√ß√£o:** A matriz de indicadores (One-Hot Encoding) permite que um modelo de regress√£o linear seja usado para classifica√ß√£o multiclasse. O modelo cria uma fronteira de decis√£o linear para cada classe, e a classe predita √© aquela com a maior sa√≠da de regress√£o. A visualiza√ß√£o mostra as fronteiras de decis√£o, mas note que a regress√£o linear n√£o modela probabilidades de classe diretamente.

```mermaid
graph LR
    subgraph "Indicator Regression"
        direction LR
        A["One-Hot Encoding of Classes"] --> B["Regression of Indicators"]
        B --> C["Linear Model:  yÃÇ = XŒ≤"]
        C --> D["Decision Rule: argmax(yÃÇ)"]
    end
```

**Lemma 2:** Em um cen√°rio ideal com classes linearmente separ√°veis e dados de treinamento suficientes, a proje√ß√£o dos dados no hiperplano de decis√£o gerado por regress√£o linear de indicadores √© equivalente √† proje√ß√£o gerada por LDA, ou seja, os hiperplanos obtidos s√£o os mesmos. Isso pode ser provado mostrando que ambas as solu√ß√µes s√£o lineares e atingem o mesmo ponto de otimiza√ß√£o para esses casos, como uma otimiza√ß√£o via quadrados m√≠nimos para um problema de regress√£o linear e a maximiza√ß√£o de vari√¢ncia entre classes na LDA [^8.3], resultando, no fim, na mesma proje√ß√£o.
$\blacksquare$

**Corol√°rio 2:** Se os hiperplanos de decis√£o s√£o equivalentes, ent√£o a an√°lise da regress√£o linear de indicadores pode ser simplificada pela an√°lise da LDA (e vice-versa), desde que as premissas de linearidade e separabilidade sejam atendidas, como indicado em [^8.3].

Em cen√°rios espec√≠ficos, conforme indicado em [^8.4], a regress√£o log√≠stica pode oferecer estimativas mais est√°veis das probabilidades de classe, ao contr√°rio da regress√£o de indicadores que pode levar a extrapola√ß√µes que n√£o se encaixam nas premissas probabil√≠sticas, ou seja, valores fora do intervalo [0, 1]. No entanto, a regress√£o de indicadores √© suficiente e vantajosa quando o objetivo principal √© a obten√ß√£o de uma fronteira de decis√£o linear [^8.2].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem: Um mapa mental que conecta a regress√£o log√≠stica com m√©todos de regulariza√ß√£o L1 e L2, mostrando como eles ajudam a lidar com sparsity e estabilidade do modelo.>
```mermaid
graph TD
    A[Regress√£o Log√≠stica] --> B{Regulariza√ß√£o L1};
    A --> C{Regulariza√ß√£o L2};
    B --> D[Sparsity];
    C --> E[Estabilidade];
    D --> F{Interpretabilidade};
```
**Explica√ß√£o:** Este diagrama representa a influ√™ncia de L1 e L2 na regress√£o log√≠stica, como discutido em [^8.4.4], [^8.5], [^8.5.1], e [^8.5.2].

A **regulariza√ß√£o** desempenha um papel vital no controle da complexidade do modelo e na preven√ß√£o de *overfitting*. T√©cnicas de regulariza√ß√£o como a penalidade L1 e L2 s√£o usadas em modelos log√≠sticos para induzir *sparsity* e estabilidade [^8.4.4]. Penaliza√ß√µes L1 adicionam a soma dos valores absolutos dos coeficientes √† fun√ß√£o de custo, enquanto L2 adiciona a soma dos quadrados dos coeficientes. Matematicamente, a fun√ß√£o de custo da regress√£o log√≠stica com regulariza√ß√£o L1 (Lasso) pode ser escrita como:
$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^N \left[ y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i)) \right] + \lambda \sum_{j=1}^p |\beta_j|
$$
E a fun√ß√£o de custo com regulariza√ß√£o L2 (Ridge) √©:
$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^N \left[ y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i)) \right] + \lambda \sum_{j=1}^p \beta_j^2
$$
Onde $\lambda$ √© o par√¢metro de regulariza√ß√£o [^8.4.4]. L1 tende a zerar alguns coeficientes, o que leva √† sele√ß√£o de *features* ( *sparsity*), enquanto L2 reduz os coeficientes, mas n√£o os zera, o que aumenta a estabilidade do modelo [^8.4.4].

> üí° **Exemplo Num√©rico:** Considere um conjunto de dados de classifica√ß√£o com v√°rias *features* (por exemplo, atributos de pacientes para prever a presen√ßa de uma doen√ßa). Vamos usar regress√£o log√≠stica com regulariza√ß√£o L1 (Lasso) e L2 (Ridge).
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LogisticRegression
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import accuracy_score, classification_report
> from sklearn.preprocessing import StandardScaler
>
> # Gera√ß√£o de dados sint√©ticos com 20 features
> np.random.seed(42)
> n_samples = 200
> n_features = 20
> X = np.random.randn(n_samples, n_features)
> # Criando algumas features correlacionadas
> X[:, 1] = X[:, 0] + np.random.normal(0, 0.2, n_samples)
> X[:, 3] = X[:, 2] + np.random.normal(0, 0.3, n_samples)
> y = (1 / (1 + np.exp(-(0.2 * X[:, 0] + 0.3 * X[:, 2] - 0.1 * X[:, 5] + 0.5 * X[:, 10]  - 1))) > 0.5).astype(int)
>
> # Dividindo dados em treino e teste
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Padronizando os dados
> scaler = StandardScaler()
> X_train = scaler.fit_transform(X_train)
> X_test = scaler.transform(X_test)
>
> # Regulariza√ß√£o L1 (Lasso)
> lasso_model = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, random_state=42)
> lasso_model.fit(X_train, y_train)
> y_pred_lasso = lasso_model.predict(X_test)
> acc_lasso = accuracy_score(y_test, y_pred_lasso)
>
> # Regulariza√ß√£o L2 (Ridge)
> ridge_model = LogisticRegression(penalty='l2', solver='liblinear', C=1.0, random_state=42)
> ridge_model.fit(X_train, y_train)
> y_pred_ridge = ridge_model.predict(X_test)
> acc_ridge = accuracy_score(y_test, y_pred_ridge)
>
> # Compara√ß√£o
> print(f'Acur√°cia Lasso: {acc_lasso:.2f}')
> print(f'Acur√°cia Ridge: {acc_ridge:.2f}')
> print("\nCoeficientes Lasso:")
> print(lasso_model.coef_)
> print("\nCoeficientes Ridge:")
> print(ridge_model.coef_)
>
> # Visualiza√ß√£o dos coeficientes
> plt.figure(figsize=(10, 5))
>
> plt.subplot(1, 2, 1)
> plt.bar(range(n_features), lasso_model.coef_[0], color='skyblue')
> plt.xlabel('Feature')
> plt.ylabel('Coeficiente Lasso')
> plt.title(f'Regulariza√ß√£o L1 (Lasso): {acc_lasso:.2f}')
>
>
> plt.subplot(1, 2, 2)
> plt.bar(range(n_features), ridge_model.coef_[0], color='coral')
> plt.xlabel('Feature')
> plt.ylabel('Coeficiente Ridge')
> plt.title(f'Regulariza√ß√£o L2 (Ridge): {acc_ridge:.2f}')
>
> plt.tight_layout()
> plt.show()
> ```
>
> **Interpreta√ß√£o:** A regulariza√ß√£o L1 (Lasso) zera alguns coeficientes (levando √† *sparsity*), enquanto a regulariza√ß√£o L2 (Ridge) reduz a magnitude dos coeficientes sem necessariamente zer√°-los. Isso pode ser visto nos gr√°ficos de barras, onde os coeficientes zerados s√£o representados como barras de altura zero. A acur√°cia pode variar ligeiramente entre os m√©todos dependendo do valor do par√¢metro de regulariza√ß√£o (C).
>
>  | Method  | Accuracy | Features Zeroed |
>  |---------|----------|-----------------|
>  | Lasso   | 0.87     | 12              |
>  | Ridge   | 0.88     | 0               |

```mermaid
graph LR
    subgraph "Regularization"
    direction TB
      A["Loss Function L(Œ≤)"]
      B["L1 Penalty: Œª||Œ≤||‚ÇÅ"]
      C["L2 Penalty: Œª||Œ≤||‚ÇÇ¬≤"]
      D["L1 Regularized Loss: J(Œ≤) = L(Œ≤) + Œª||Œ≤||‚ÇÅ"]
       E["L2 Regularized Loss: J(Œ≤) = L(Œ≤) + Œª||Œ≤||‚ÇÇ¬≤"]
      A --> B
      A --> C
      A & B --> D
      A & C --> E
    end
```

**Lemma 3:** A penaliza√ß√£o L1 na regress√£o log√≠stica leva a coeficientes esparsos, uma vez que a derivada da penalidade $||\beta||_1$ √© uma constante (exceto em 0) e isso encoraja alguns dos coeficientes a se tornarem exatamente zero quando o par√¢metro de regulariza√ß√£o $\lambda$ √© suficientemente grande. Isso pode ser demonstrado analisando a condi√ß√£o de otimalidade para o problema de otimiza√ß√£o regularizado com L1 [^8.4.4].
$\blacksquare$

**Prova do Lemma 3:** Considere a fun√ß√£o de custo $J(\beta)$ com regulariza√ß√£o L1:
$$
J(\beta) = L(\beta) + \lambda \sum_{j=1}^p |\beta_j|
$$
Onde $L(\beta)$ √© a fun√ß√£o de verossimilhan√ßa log√≠stica. Minimizar $J(\beta)$ envolve encontrar $\beta$ onde a derivada de $J(\beta)$ em rela√ß√£o a $\beta_j$ √© zero, ou seja:
$$
\frac{\partial J}{\partial \beta_j} = \frac{\partial L}{\partial \beta_j} + \lambda \cdot sign(\beta_j) = 0
$$
A derivada da penaliza√ß√£o L1, $\lambda \cdot sign(\beta_j)$, adiciona uma constante √† derivada da fun√ß√£o de verossimilhan√ßa, o que for√ßa alguns coeficientes a se tornarem zero para o valor correto de $\lambda$. A condi√ß√£o de otimalidade, em vez de igualar a derivada a zero, define um subgradiente em zero [^8.4.3].
$\blacksquare$

**Corol√°rio 3:** Modelos esparsos resultantes da penaliza√ß√£o L1 s√£o mais interpret√°veis, pois o n√∫mero de *features* relevantes para a classifica√ß√£o √© reduzido, de acordo com [^8.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: As penaliza√ß√µes L1 e L2 podem ser combinadas em uma regulariza√ß√£o *Elastic Net*, que busca equilibrar os benef√≠cios da *sparsity* e da estabilidade, conforme discutido em [^8.5].

### Separating Hyperplanes e Perceptrons
The idea of maximizing the margin of separation leads to the concept of optimal hyperplanes. These hyperplanes are calculated with the goal of maximizing the distance between the boundary and the data points of each class, resulting in a more robust classifier [^8.5.2]. The formulation of this optimization problem involves finding a hyperplane that maximizes the margin, subject to the constraint that all training points are classified correctly. The resulting optimization problem can be solved using the Wolfe dual, which allows the solution to be expressed as a linear combination of the support points.

The Rosenblatt Perceptron is a classic algorithm for finding a separating hyperplane. This algorithm iteratively adjusts the weights until a hyperplane that correctly separates the classes is found [^8.5.1]. The convergence of the Perceptron is guaranteed under the condition that the data are linearly separable. If the data are not linearly separable, the Perceptron may not converge.

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?
**Resposta:**
A LDA assume que os dados de cada classe seguem uma distribui√ß√£o normal com covari√¢ncias iguais e busca um subespa√ßo linear que maximize a separa√ß√£o entre classes [^8.3]. A Regra de Decis√£o Bayesiana, por outro lado, fornece a classifica√ß√£o √≥tima, minimizando a probabilidade de erro. Quando as distribui√ß√µes s√£o Gaussianas com covari√¢ncias iguais, o limite de decis√£o Bayesiano √© linear, o que torna a LDA equivalente √† decis√£o Bayesiana [^8.3]. A LDA deriva os limites de decis√£o atrav√©s da maximiza√ß√£o da raz√£o entre a vari√¢ncia entre classes e a vari√¢ncia dentro das classes, enquanto a decis√£o Bayesiana calcula explicitamente as probabilidades de classe e decide com base na classe com maior probabilidade. Ambas as abordagens levam aos mesmos resultados sob as mesmas premissas [^8.3].

**Lemma 4:** Se as classes s√£o Gaussianas com a mesma matriz de covari√¢ncia $\Sigma$ e m√©dias $\mu_k$, a fun√ß√£o discriminante obtida pela LDA √© equivalente √† fun√ß√£o de decis√£o obtida pela Regra de Decis√£o Bayesiana, e ambas geram a mesma fronteira de decis√£o linear, como demostrado em [^8.3], [^8.3.3].
$\blacksquare$

```mermaid
graph TB
    subgraph "Equivalence of LDA and Bayesian Decision Rule"
        direction TB
        A["LDA: Maximize between-class variance / within-class variance, assuming equal