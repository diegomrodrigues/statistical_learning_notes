## Linear Regression in Model Averaging

```mermaid
graph LR
    subgraph "Model Averaging Process"
        direction TB
        A["Multiple Models: f1(x), f2(x), ..., fm(x)"]
        B["Input Data: x"]
        C["Linear Combination:  $\sum w_i * f_i(x)$"]
        D["Optimal Weights: w1, w2, ..., wm"]
        E["Final Prediction: yÃÇ"]
        B --> A
        A --> C
         D --> C
        C --> E
    end
```

### Introdu√ß√£o
O conceito de **model averaging**, ou m√©dia de modelos, √© uma poderosa ferramenta no aprendizado estat√≠stico que busca melhorar a precis√£o e a robustez das previs√µes atrav√©s da combina√ß√£o de m√∫ltiplos modelos. Em vez de depender de um √∫nico modelo para fazer previs√µes, o model averaging combina as previs√µes de v√°rios modelos, muitas vezes com diferentes estruturas ou par√¢metros, para produzir uma estimativa final mais precisa. [^8.1] A ideia central √© que, ao combinar as perspectivas de diversos modelos, podemos reduzir tanto o vi√©s quanto a vari√¢ncia, levando a um desempenho preditivo superior. Modelos de regress√£o linear, devido a sua simplicidade e interpretabilidade, s√£o componentes fundamentais em diversas abordagens de model averaging e s√£o extensamente explorados no contexto fornecido [^8.8].

### Conceitos Fundamentais
**Conceito 1:** O **problema de classifica√ß√£o** busca, dado um conjunto de dados de treinamento, aprender uma fun√ß√£o que mapeia entradas para classes ou categorias. M√©todos lineares, como regress√£o linear, s√£o frequentemente empregados devido √† sua simplicidade computacional e interpretabilidade. No entanto, podem apresentar *vi√©s* em rela√ß√£o a classificadores n√£o lineares e apresentar problemas de vari√¢ncia se n√£o forem usados com cautela [^8.2].

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com duas classes (0 e 1). Temos duas vari√°veis de entrada, $x_1$ e $x_2$, e 5 pontos de dados. Usamos regress√£o linear para classificar os dados. A matriz de design $X$ √©:
> ```python
> import numpy as np
> X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6]])
> ```
> A matriz indicadora $Y$ (onde 0 √© codificado como [1,0] e 1 como [0,1]) √©
> ```python
> Y = np.array([[1, 0], [1, 0], [0, 1], [0, 1], [1, 0]])
> ```
> Calculamos os coeficientes $\beta$ usando a f√≥rmula dos m√≠nimos quadrados: $\hat{\beta} = (X^TX)^{-1}X^TY$. Os outputs podem ser interpretados como *scores* para cada classe, e a classe com maior *score* √© selecionada.

**Lemma 1:** Em um contexto de classifica√ß√£o, a regress√£o linear pode ser aplicada atrav√©s da **regress√£o de uma matriz indicadora**. Se tivermos *K* classes, podemos representar cada observa√ß√£o atrav√©s de um vetor de *K* dimens√µes, onde a componente correspondente √† classe correta √© 1, e as demais s√£o 0. Uma regress√£o linear dessas matrizes indicadoras, realizada separadamente para cada classe, resulta em fun√ß√µes lineares que podem ser usadas para decis√£o. A decis√£o √© dada atrav√©s da escolha da classe cujo output seja o maior. A matriz indicadora tamb√©m pode ser interpretada como um conjunto de *k* regress√µes lineares que estimam a probabilidade da observa√ß√£o pertencer a cada classe. Embora seja simples, o m√©todo pode ser inst√°vel em algumas situa√ß√µes [^8.2].

$$
Y = X\beta + \epsilon
$$
Onde $Y$ √© a matriz indicadora, $X$ √© a matriz de entrada, $\beta$ s√£o os coeficientes e $\epsilon$ √© o erro.

```mermaid
graph LR
    subgraph "Linear Regression for Indicator Matrix"
        direction TB
        A["Input Matrix: X"]
        B["Indicator Matrix: Y (K Classes)"]
         C["Coefficient Matrix: Œ≤"]
        D["Error Term: Œµ"]
        E["Linear Regression Model: Y = XŒ≤ + Œµ"]
        A --> E
        B --> E
        C --> E
        D --> E
         E --> F["Output: Scores for each class"]
    end
```

**Conceito 2:** A **Linear Discriminant Analysis (LDA)** assume que as classes t√™m distribui√ß√µes gaussianas com a mesma matriz de covari√¢ncia. A fun√ß√£o discriminante de LDA √© linear e pode ser derivada da regra de decis√£o Bayesiana sob essas suposi√ß√µes. LDA pode ser visto como um caso especial de regress√£o linear quando os par√¢metros s√£o estimados com covari√¢ncias iguais [^8.3]. A fun√ß√£o discriminante em LDA √© constru√≠da para projetar os dados em uma dire√ß√£o que maximize a separa√ß√£o entre as classes, usando m√©dias de classe e a covari√¢ncia comum.

**Corol√°rio 1:** Dado o Lemma 1, a equival√™ncia entre a regress√£o linear com matriz indicadora e o LDA sob as suposi√ß√µes de normalidade e covari√¢ncia comum, mostra que a fun√ß√£o discriminante de LDA pode ser vista como uma forma de regress√£o linear que √© orientada pela estrutura das classes no espa√ßo de entrada, onde os coeficientes da regress√£o s√£o afetados pela covari√¢ncia comum, garantindo uma separa√ß√£o linear otimizada. [^8.3.1]

**Conceito 3:** **Logistic Regression** modela a probabilidade de uma observa√ß√£o pertencer a uma determinada classe usando uma fun√ß√£o log√≠stica da combina√ß√£o linear das entradas. A fun√ß√£o *logit* transforma probabilidades em log-odds, que s√£o modeladas linearmente. Logistic Regression √© amplamente utilizado devido √† sua flexibilidade e capacidade de gerar estimativas de probabilidade.  O modelo √© estimado atrav√©s de maximiza√ß√£o da verossimilhan√ßa [^8.4].

> ‚ö†Ô∏è **Nota Importante**: A Regress√£o Log√≠stica √© um modelo probabil√≠stico linear usado para problemas de classifica√ß√£o bin√°ria, onde a probabilidade de um evento ocorrer √© modelada usando uma fun√ß√£o log√≠stica. **Refer√™ncia ao t√≥pico [^8.4.1]**.

> ‚ùó **Ponto de Aten√ß√£o**: A regress√£o log√≠stica, assim como o LDA, s√£o sens√≠veis a classes n√£o-balanceadas, sendo necess√°rio cuidado extra na modelagem quando h√° desbalanceamento. **Conforme indicado em [^8.4.2]**.

> ‚úîÔ∏è **Destaque**: Tanto o LDA quanto a Regress√£o Log√≠stica, s√£o modelos lineares que visam encontrar uma fronteira linear que separa as classes, embora seus mecanismos de estima√ß√£o de par√¢metros sejam diferentes. **Baseado no t√≥pico [^8.5]**.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction TB
        A["Design Matrix: H"]
        B["Indicator Matrix: y"]
         C["Coefficient Matrix: Œ≤ÃÇ"]
        D["Least Squares Solution: Œ≤ÃÇ = (H·µÄH)‚Åª¬πH·µÄy"]
        A --> D
        B --> D
         D --> E["Predicted Output"]
        E --> F["Class with max output assigned"]
    end
```

A regress√£o linear com matriz de indicadores √© uma abordagem simples para classifica√ß√£o. Em vez de ajustar uma √∫nica fun√ß√£o de regress√£o para uma resposta cont√≠nua, √© constru√≠do um modelo de regress√£o linear para cada classe, onde a vari√°vel resposta √© um indicador (0 ou 1) da pertin√™ncia da observa√ß√£o √†quela classe [^8.2]. Em ess√™ncia, essa abordagem estima probabilidades ou scores que podem ser interpretados como indicadores de pertin√™ncia √† classe. O modelo √© estimado usando m√≠nimos quadrados. Seja $H$ a matriz de design, onde cada linha representa um vetor de caracter√≠sticas de uma observa√ß√£o, e $y$ √© a matriz de indicadores, a solu√ß√£o para os par√¢metros $\beta$ √© dada por:

$$
\hat{\beta} = (H^TH)^{-1}H^Ty
$$

Onde $\hat{\beta}$ √© a matriz de coeficientes, que cont√©m um vetor de coeficientes para cada classe. A previs√£o para uma nova observa√ß√£o √© obtida calculando $H_{new}\hat{\beta}$, onde $H_{new}$ representa o vetor de features da observa√ß√£o, e atribuindo a classe com maior valor de sa√≠da. Apesar de sua simplicidade, essa abordagem pode ser sens√≠vel a outliers e problemas de *multicolinearidade*.  O modelo de regress√£o linear n√£o tem restri√ß√µes sobre os outputs, que podem ficar fora do intervalo \[0, 1], o que pode resultar em previs√µes sem significado em algumas aplica√ß√µes.

> üí° **Exemplo Num√©rico:** Vamos considerar um conjunto de dados com tr√™s amostras e duas features, com duas classes (0 e 1). A matriz de design $H$ (incluindo um intercepto) e a matriz de indicadores $Y$ podem ser representadas como:
>
> ```python
> import numpy as np
> # Matriz de design H com 3 amostras, 2 features e intercepto
> H = np.array([[1, 2, 3],
>               [1, 4, 5],
>               [1, 6, 7]])
>
> # Matriz indicadora Y (3 amostras, 2 classes)
> Y = np.array([[1, 0],  # Classe 0
>               [0, 1],  # Classe 1
>               [1, 0]]) # Classe 0
> ```
>
> Para calcular $\hat{\beta}$, primeiro calculamos $H^T H$:
>
> ```python
> HT_H = np.dot(H.T, H)
> print("HT_H:\n", HT_H)
> ```
>
> Em seguida, calculamos a inversa de $(H^T H)$:
>
> ```python
> HT_H_inv = np.linalg.inv(HT_H)
> print("Inversa de HT_H:\n", HT_H_inv)
> ```
>
> Agora, calculamos $H^T Y$:
>
> ```python
> HT_Y = np.dot(H.T, Y)
> print("HT_Y:\n", HT_Y)
> ```
>
> Finalmente, calculamos $\hat{\beta}$:
>
> ```python
> beta_hat = np.dot(HT_H_inv, HT_Y)
> print("Beta_hat:\n", beta_hat)
> ```
> O resultado √© uma matriz de coeficientes $\hat{\beta}$, onde cada coluna cont√©m os coeficientes para a regress√£o linear de cada classe. Podemos obter previs√µes para novas amostras usando esses coeficientes. Note que os outputs da regress√£o podem n√£o ser diretamente interpret√°veis como probabilidades, j√° que n√£o est√£o restritos ao intervalo [0, 1].

**Lemma 2:** Dada a matriz de design $H$ e a matriz de indicadores $Y$, o resultado da aplica√ß√£o da regress√£o linear atrav√©s de m√≠nimos quadrados pode ser visto como uma proje√ß√£o dos dados em um subespa√ßo que √© definido pelos vetores coluna de $H$. Essa proje√ß√£o busca minimizar a dist√¢ncia entre a matriz indicadora e a sua proje√ß√£o nesse subespa√ßo, de modo que a decis√£o de classe √© feita atrav√©s da compara√ß√£o de dist√¢ncias projetadas [^8.2].

**Corol√°rio 2:**  Se o subespa√ßo definido por $H$ for bem escolhido, tal proje√ß√£o pode resultar em um conjunto de scores que permite uma separa√ß√£o linear eficaz das classes, o que significa que podemos usar uma regra de decis√£o linear simples (e.g., escolher a classe cujo valor projetado √© o maior) para classificar novas observa√ß√µes. No entanto, o Lemma 2 destaca que a escolha da matriz $H$ √© crucial, e a regress√£o de indicadores pode n√£o funcionar bem se os dados n√£o forem adequadamente representados no espa√ßo definido por $H$. O t√≥pico [^8.3] tamb√©m menciona que as covari√¢ncias entre classes podem confundir o resultado, o que leva √† necessidade de abordagens mais robustas como a LDA, que leva em considera√ß√£o a estrutura das classes e sua vari√¢ncia.

>  ‚ÄúEm alguns cen√°rios, conforme apontado em [^8.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1].‚Äù

>  ‚ÄúNo entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^8.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear.‚Äù

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["Loss Function: -l(Œ≤)"]
        B["L1 Regularization: Œª‚àë|Œ≤‚±º|"]
        C["L2 Regularization: Œª‚àëŒ≤‚±º¬≤"]
        D["L1 Penalized Cost: -l(Œ≤) + Œª‚àë|Œ≤‚±º|"]
        E["L2 Penalized Cost: -l(Œ≤) + Œª‚àëŒ≤‚±º¬≤"]
        A --> D
        B --> D
        A --> E
        C --> E

        D --> F["Sparse Coefficients"]
        E --> G["Reduced Coefficient Values"]

    end
```

Em problemas de classifica√ß√£o, a regulariza√ß√£o √© essencial para evitar o *overfitting* e melhorar a generaliza√ß√£o dos modelos. As t√©cnicas de regulariza√ß√£o mais comuns s√£o L1 (Lasso) e L2 (Ridge). Na regulariza√ß√£o L1, um termo de penaliza√ß√£o proporcional ao valor absoluto dos coeficientes √© adicionado √† fun√ß√£o de custo [^8.4.4]. Isso leva √† esparsidade dos coeficientes, selecionando automaticamente as vari√°veis mais relevantes. Na regulariza√ß√£o L2, o termo de penaliza√ß√£o √© proporcional ao quadrado dos coeficientes, o que reduz o valor dos coeficientes, mas n√£o necessariamente os leva a zero [^8.4.4].
No contexto de regress√£o log√≠stica, a fun√ß√£o de custo √© a *log-likelihood* negativa, que √© modificada da seguinte forma com a regulariza√ß√£o L1:

$$
-l(\beta) + \lambda \sum_{j=1}^{p}|\beta_j|
$$

E com regulariza√ß√£o L2:

$$
-l(\beta) + \lambda \sum_{j=1}^{p}\beta_j^2
$$

Onde *$l(\beta)$* √© a log-likelihood, *$\beta$* s√£o os coeficientes, *$\lambda$* √© o par√¢metro de regulariza√ß√£o, e *p* √© o n√∫mero de features.
A escolha do par√¢metro *$\lambda$* √© crucial para obter um modelo com bom desempenho, e √© normalmente feita atrav√©s de cross-validation.

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com regress√£o log√≠stica com 3 vari√°veis de entrada ($x_1, x_2, x_3$) e 100 amostras. Ajustamos o modelo com diferentes valores de regulariza√ß√£o L1 (Lasso) e L2 (Ridge):
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import accuracy_score
>
> # Gerar dados de exemplo
> np.random.seed(42)
> X = np.random.rand(100, 3)
> y = np.random.randint(0, 2, 100)
>
> # Dividir em treino e teste
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Regulariza√ß√£o L1 (Lasso) com diferentes valores de lambda
> for C in [0.1, 0.5, 1.0]: # C = 1/lambda
>     model_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=C, random_state=42)
>     model_l1.fit(X_train, y_train)
>     y_pred_l1 = model_l1.predict(X_test)
>     accuracy_l1 = accuracy_score(y_test, y_pred_l1)
>     print(f"L1 (lambda={1/C:.2f}) - Accuracy: {accuracy_l1:.4f}, Coeficientes: {model_l1.coef_}")
>
> # Regulariza√ß√£o L2 (Ridge) com diferentes valores de lambda
> for C in [0.1, 0.5, 1.0]: # C = 1/lambda
>     model_l2 = LogisticRegression(penalty='l2', C=C, random_state=42)
>     model_l2.fit(X_train, y_train)
>     y_pred_l2 = model_l2.predict(X_test)
>     accuracy_l2 = accuracy_score(y_test, y_pred_l2)
>     print(f"L2 (lambda={1/C:.2f}) - Accuracy: {accuracy_l2:.4f}, Coeficientes: {model_l2.coef_}")
>
>
> ```
>
> A sa√≠da do c√≥digo acima mostrar√° a acur√°cia e os coeficientes para cada valor de $\lambda$. Observamos que a regulariza√ß√£o L1 tende a zerar alguns coeficientes, enquanto a L2 reduz o valor dos coeficientes, mas n√£o necessariamente os leva a zero. A escolha do valor ideal de $\lambda$ √© geralmente feita usando valida√ß√£o cruzada.

**Lemma 3:** A penaliza√ß√£o L1 em modelos log√≠sticos introduz uma tend√™ncia √† esparsidade nos coeficientes, devido √† natureza n√£o diferenci√°vel do valor absoluto em zero, o que faz com que os coeficientes sejam levados a zero quando a regulariza√ß√£o √© forte o suficiente.  Este efeito n√£o √© obtido atrav√©s da regulariza√ß√£o L2 [^8.4.4].

**Prova do Lemma 3:** A penalidade L1 introduz um termo que √© linear nos coeficientes, o que corresponde a um prior de Laplace sobre os coeficientes. A otimiza√ß√£o da log-verossimilhan√ßa com uma penalidade L1 corresponde √† busca do m√°ximo a posteriori (MAP) sob este prior. Devido √† forma da distribui√ß√£o de Laplace (com pico em zero), os coeficientes que n√£o contribuem significativamente para a verossimilhan√ßa s√£o levados a zero na solu√ß√£o √≥tima. Este efeito √© muito mais forte do que na regulariza√ß√£o L2, que penaliza de forma quadr√°tica os coeficientes, sendo tamb√©m mais propenso √† esparsidade [^8.4.3] [^8.4.4]. $\blacksquare$

**Corol√°rio 3:** A esparsidade introduzida pela regulariza√ß√£o L1 melhora a interpretabilidade do modelo, pois os coeficientes que s√£o zero implicam que suas respectivas vari√°veis n√£o t√™m impacto sobre a probabilidade de pertencimento √† classe. Isso n√£o acontece na regulariza√ß√£o L2, onde os coeficientes podem ser pequenos, mas raramente exatamente zero, dificultando a interpreta√ß√£o do modelo. A esparsidade tamb√©m tem um efeito de sele√ß√£o de vari√°veis, sendo que modelos com regulariza√ß√£o L1 s√£o capazes de selecionar automaticamente um subconjunto das vari√°veis originais [^8.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: L1 e L2 podem ser combinadas (Elastic Net) para aproveitar vantagens de ambos os tipos de regulariza√ß√£o, conforme discutido em [^8.5].
### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Separating Hyperplanes"
        direction TB
        A["Data points from two classes"]
        B["Hyperplane:  w·µÄx + b = 0"]
        C["Margin Maximization"]
        D["Support Vectors"]
        E["Optimal Separating Hyperplane"]
        A --> B
        B --> C
        C --> D
        D --> E
        E --> F["Classification"]

    end
```

O conceito de *separating hyperplanes* emerge da ideia de encontrar uma fronteira linear que melhor separa os dados de diferentes classes. A ideia √© maximizar a margem entre os pontos mais pr√≥ximos ao hiperplano, os vetores de suporte [^8.5.2]. A formula√ß√£o do problema de otimiza√ß√£o para encontrar esses hiperplanos envolve o uso de multiplicadores de Lagrange e a dualidade de Wolfe, para encontrar a solu√ß√£o. O resultado final √© que os hiperplanos de decis√£o s√£o formados por combina√ß√µes lineares dos vetores de suporte, ou seja, os dados que s√£o mais relevantes para a defini√ß√£o da fronteira de decis√£o.
Os Perceptrons, como o Perceptron de Rosenblatt, s√£o uma forma antiga e simples de encontrar separadores lineares. Eles ajustam os pesos iterativamente, utilizando as classifica√ß√µes erradas. O algoritmo do perceptron converge sob condi√ß√µes espec√≠ficas de separabilidade linear, mas pode n√£o encontrar a margem m√°xima entre as classes [^8.5.1].
O SVM (Support Vector Machine) √© uma extens√£o do conceito de *separating hyperplane* que √© mais sofisticado, e n√£o √© mencionado no contexto.

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?
**Resposta:**
A Linear Discriminant Analysis (LDA) e a Regra de Decis√£o Bayesiana, sob a suposi√ß√£o de que as classes t√™m distribui√ß√µes gaussianas com a mesma matriz de covari√¢ncia, s√£o essencialmente equivalentes [^8.3].
A Regra de Decis√£o Bayesiana atribui uma observa√ß√£o √† classe que possui a maior probabilidade *a posteriori*, dadas as observa√ß√µes. Essa regra pode ser escrita como:
$$
arg \, max_k \, P(C_k | x) = arg \, max_k \frac{p(x|C_k)P(C_k)}{p(x)}
$$
Onde $P(C_k|x)$ √© a probabilidade *a posteriori* da classe *k*, dado o vetor de entrada $x$. $p(x|C_k)$ √© a fun√ß√£o de verossimilhan√ßa da entrada $x$ dada a classe $k$, $P(C_k)$ √© a probabilidade *a priori* da classe $k$ e $p(x)$ √© a probabilidade marginal de $x$, que n√£o depende de *k* e pode ser ignorada na decis√£o.

Sob a suposi√ß√£o de que a classe k tem uma distribui√ß√£o normal com m√©dia $\mu_k$ e covari√¢ncia $\Sigma$ (a mesma para todas as classes), a fun√ß√£o de verossimilhan√ßa se torna:

$$
p(x|C_k) = \frac{1}{(2\pi)^{p/2} |\Sigma|^{1/2}} exp(-\frac{1}{2}(x-\mu_k)^T\Sigma^{-1}(x-\mu_k))
$$

Se substituirmos essa express√£o na regra de decis√£o Bayesiana e tomarmos o logaritmo, e desprezarmos termos que n√£o dependem de *k*, o resultado √© uma fun√ß√£o linear:

$$
\delta_k(x) =  x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + log \, P(C_k)
$$

Esta fun√ß√£o √© linear em $x$ e, portanto, tem a mesma forma da fun√ß√£o discriminante da LDA. A LDA, por sua vez, estima os par√¢metros a partir dos dados de treino, enquanto que a regra de decis√£o Bayesiana, em geral, assume que esses par√¢metros s√£o conhecidos. No entanto, quando os par√¢metros s√£o estimados atrav√©s de m√©todos de m√°xima verossimilhan√ßa, o resultado √© que o LDA coincide com a regra de decis√£o bayesiana sob as mesmas condi√ß√µes [^8.3.3].
O detalhe crucial √© que a escolha das m√©dias e covari√¢ncias influencia o resultado. Quando assumimos covari√¢ncias iguais para todas as classes, as fronteiras de decis√£o tornam-se lineares, conforme descrito na LDA. A deriva√ß√£o dos limites de decis√£o, as proje√ß√µes lineares e a forma como a escolha das m√©dias e da covari√¢ncia influenciam o resultado s√£o exatamente as mesmas para os dois m√©todos [^8.3.1].

**Lemma 4:** Sob a suposi√ß√£o de distribui√ß√µes gaussianas com covari√¢ncias iguais, a fun√ß√£o discriminante da LDA pode ser vista como a implementa√ß√£o da regra de decis√£o Bayesiana, utilizando a estimativa de m√°xima verossimilhan√ßa dos par√¢metros e usando as mesmas proje√ß√µes lineares [^8.3].

**Corol√°rio 4:** Quando a suposi√ß√£o de covari√¢ncias iguais √© relaxada, a regra de decis√£o bayesiana leva a fronteiras quadr√°ticas, e n√£o lineares. Isso significa que, embora a regra bayesiana continue aplic√°vel, a forma da fun√ß√£o discriminante e os limites de decis√£o podem mudar drasticamente. O QDA (Quadratic Discriminant Analysis) √© uma generaliza√ß√£o do LDA que leva em conta que cada classe pode ter sua pr√≥pria matriz de covari√¢ncia, o que resulta em fronteiras de decis√£o mais flex√≠veis [^8.3].

> ‚ö†Ô∏è **Ponto Crucial**: A ado√ß√£o ou n√£o de covari√¢ncias iguais impacta fortemente o tipo de fronteira de decis√£o (linear vs. quadr√°tica), conforme discutido em [^8.3.1].

### Linear Regression para Model Averaging
```mermaid
graph LR
    subgraph "Linear Regression in Model Averaging"
        direction TB
        A["Model Outputs: f1(x), f2(x), ..., fm(x)"]
        B["Target Variable: Y"]
        C["Regression Matrix: F (Model Predictions)"]
        D["Optimal Weights: w"]
        E["Linear Regression Model: Y = Fw + Œµ"]
         F["Weight Calculation: w = (F·µÄF)‚Åª¬πF·µÄY"]
         A --> C
        B --> E
        C --> E
        D --> E
        E --> F
        F --> G["Final Averaged Prediction: yÃÇ =  ‚àë wi * fi(x)"]

    end
```

Em model averaging, o objetivo √© combinar as previs√µes de m√∫ltiplos modelos para obter uma previs√£o final mais precisa. Uma forma de fazer isso √© atrav√©s da regress√£o linear, onde cada modelo √© tratado como uma vari√°vel explicativa na regress√£o. O valor final √© dado pela combina√ß√£o linear dos outputs dos modelos [^8.8]. Essa abordagem, conhecida como *stacking*, busca encontrar os melhores pesos para combinar os modelos.

A regress√£o linear √© utilizada para aprender esses pesos a partir dos dados de treinamento, de forma que o output do modelo combinado minimize o erro de previs√£o. Os pesos da regress√£o linear representam a import√¢ncia relativa de cada modelo na previs√£o final.
Seja $f_1(x), f_2(x), \ldots, f_m(x)$ o output de M modelos diferentes em um ponto de entrada $x$. O objetivo do *model averaging* √© encontrar os pesos $w_1, w_2, \ldots, w_m$ tal que a previs√£o final $\hat{y}$ seja:
$$
\hat{y} = \sum_{i=1}^m w_i f_i(x)
$$
Onde o objetivo √© obter valores de $w_i$ que minimizem a fun√ß√£o de custo no conjunto de treinamento. A solu√ß√£o para os pesos √© dada por:
$$
w = (F^T F)^{-1} F^T Y
$$

Onde $F$ √© uma matriz com as sa√≠das dos modelos no conjunto de treinamento, cada coluna sendo o vetor de previs√µes de um modelo, e $Y$ √© o vetor dos valores alvo.

> üí° **Exemplo Num√©rico:** Considere um cen√°rio de model averaging com 3 modelos. Temos um conjunto de dados de treino com 5 observa√ß√µes e o valor alvo $Y$:
>
> ```python
> import numpy as np
>
> # Sa√≠das dos modelos para 5 observa√ß√µes
> F = np.array([[2.1, 3.2, 1.8],
>               [1.9, 3.0, 2.2],
>               [2.5, 3.5, 2.5],
>               [2.3, 3.3, 2.7],
>               [2.8, 3.8, 2.9]])
>
> # Valores alvo correspondentes
> Y = np.array([2.5, 2.1, 3.0, 2.8, 3.2])
> ```
>
> Para calcular os pesos $w$, primeiro calculamos $F^T F$:
> ```python
> FT_F = np.dot(F.T, F)
> print("FT_F:\n", FT_F)
> ```
> Em seguida, calculamos a inversa de $(F^T F)$:
> ```python
> FT_F_inv = np.linalg.inv(FT_F)
> print("Inversa de FT_F:\n", FT_F_inv)
> ```
> Agora, calculamos $F^T Y$:
> ```python
> FT_Y = np.dot(F.T, Y)
> print("FT_Y:\n", FT_Y)
> ```
> Finalmente, calculamos os pesos $w$:
> ```python
> w = np.dot(FT_F_inv, FT_Y)
> print("Pesos (w):\n", w)
> ```
> Os pesos $w$ s√£o os coeficientes da regress√£o linear que combina os outputs dos modelos. Para prever um novo exemplo, basta obter as predi√ß√µes de cada modelo no novo exemplo e usar esses pesos para obter a previs√£o final combinada. Por exemplo, se as previs√µes de um novo exemplo s√£o \[2.2, 3.1, 2.0], a previs√£o combinada ser√° dada por:
> ```python
> new_x = np.array([2.2, 3.1, 2.0])
> y_hat = np.dot(new_x, w)
> print("Previs√£o combinada:", y_hat)
> ```
> Este exemplo num√©rico ilustra como a regress√£o linear √© usada para combinar as previs√µes dos modelos, de forma que o resultado final seja uma m√©dia ponderada das previs√µes individuais.

Em particular, esta abordagem √© descrita no contexto da se√ß√£o 8.8: *Model Averaging and Stacking*.

### Desafios Te√≥ricos do Model Averaging com Regress√£o Linear
A regress√£o linear, embora simples, apresenta alguns desafios te√≥ricos quando usada no contexto de *model averaging*. Um dos desafios √© a escolha do conjunto de modelos a serem combinados. A escolha inadequada dos modelos pode levar a resultados piores do que o uso de um √∫nico modelo.  Al√©m disso, a regress√£o linear pode dar pesos muito altos a modelos que se ajustam bem aos dados de treinamento mas generalizam mal para novos dados (*overfitting*). Para lidar com este problema, m√©todos como *cross-validation* e *regulariza√ß√£o* s√£o utilizados.  A se√ß√£o 8.8 demonstra que *stacked generalization* busca usar *cross-validation* para avaliar as previs√µes dos modelos que ser√£o combinadas, minimizando o efeito de modelos que s√£o bons apenas nos dados de treino.  Um problema em potencial √© que a matriz $F^TF$ pode ser mal condicionada, o que dificulta a obten√ß√£o de pesos est√°veis.

### Conclus√£o
A regress√£o linear √© uma ferramenta flex√≠vel e √∫til no contexto de model averaging, permitindo a combina√ß√£o de diversos modelos para melhorar a precis√£o das previs√µes. No entanto, √© essencial considerar os desafios te√≥ricos associados a este m√©todo, como a sele√ß√£o de modelos, o risco de *overfitting* e a estabilidade dos pesos. Uma compreens√£o profunda desses conceitos √© crucial para a aplica√ß√£o eficaz de t√©cnicas de model averaging em problemas reais.

### Refer√™ncias
[^8.1]: "For most of this book, the fitting (learning) of models has been achieved by minimizing a sum of squares for regression, or by minimizing cross-entropy for classification. In fact, both of these minimizations are instances of the maximum likelihood approach to fitting." *(Trecho de Model Inference and Averaging)*
[^8.2]: "Denote the training data by Z = {z1,2,...,zN}, with zi = (xi, yi), i = 1,2,..., N. Here xi is a one-dimensional input, and y·µ¢ the outcome, either continuous or categorical. As an example, consider the N = 50 data points shown in the left panel of Figure 8.1." *(Trecho de Model Inference and Averaging)*
[^8.3]: "There is actually a close connection between the least squares estimates (8.2) and (8.3), the bootstrap, and maximum likelihood. Suppose we further assume that the model errors are Gaussian," *(Trecho de Model Inference and Averaging)*
[^8.3.1]: "Suppose we divide to fit a cubic spline to the data, with three knots placed at the quartiles of the X values. This is a seven-dimensional linear space of functions, and can be represented, for example, by a linear expansion of B-spline basis functions (see Section 5.9.2):" *(Trecho de Model Inference and Averaging)*
[^8.3.2]: "Here the h;(x), j = 1, 2, ..., 7 are the seven functions shown in the right panel of Figure 8.1. We can think of Œº(x) as representing the conditional mean E(Y|X = x)." *(Trecho de Model Inference and Averaging)*
[^8.3.3]: "Let H be the N√ó7 matrix with ijth element hj(xi). The usual estimate of ·∫û, obtained by minimizing the squared error over the training set, is given by" *(Trecho de Model Inference and Averaging)*
[^8.4]: "It turns out that the parametric bootstrap agrees with least squares in the previous example because the model (8.5) has additive Gaussian errors. In general, the parametric bootstrap agrees not with least squares but with maximum likelihood, which we now review." *(Trecho de Model Inference and Averaging)*
[^8.4.1]: "We begin by specifying a probability density or probability mass function for our observations" *(Trecho de Model Inference and Averaging)*
[^8.4.2]: "In this expression 0 represents one or more unknown parameters that govern the distribution of Z. This is called a parametric model for Z. As an example, if Z has a normal distribution with mean ¬µ and variance œÉ¬≤, then" *(Trecho de Model Inference and Averaging)*
[^8.4.3]: "and" *(Trecho de Model Inference and Averaging)*
[^8.4.4]: "Maximum likelihood is based on the likelihood function, given by" *(Trecho de Model Inference and Averaging)*
[^8.4.5]: "the probability of the observed data under the model ge. The likelihood is defined only up to a positive multiplier, which we have taken to be one." *(Trecho de Model Inference and Averaging)*
[^8.5]: "The likelihood function can be used to assess the precision of Œ∏. We need a few more definitions. The score function is defined by" *(Trecho de Model Inference and Averaging)*
[^8.5.1]: "When I(0) is evaluated at 0 = 0, it is often called the observed information. The Fisher information (or expected information) is" *(Trecho de Model Inference and Averaging)*
[^8.5.2]: "Finally, let Œ∏‚ÇÄ denote the true value of 0." *(Trecho de Model Inference and Averaging)*
[^8.8]: "Here we discuss Bayesian model averaging more generally. We have a set of candidate models Mm, m = 1,..., M for our training set Z. These models may be of the same type with different parameter values (e.g., subsets in linear regression), or different models for the same task (e.g., neural networks and regression trees)." *(Trecho de Model Inference and Averaging)*
