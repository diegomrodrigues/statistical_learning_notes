## Committee Methods: Model Averaging and Combination for Enhanced Prediction

<imagem: Mapa mental complexo conectando a ideia de ensembles, m√©todos de comit√™, bagging, boosting, stacking e bumping. O mapa mental deve incluir os principais pontos de cada t√©cnica e suas rela√ß√µes, destacando como m√©todos de comit√™ se encaixam em uma categoria maior de model averaging>

### Introdu√ß√£o

Neste cap√≠tulo, exploramos uma variedade de t√©cnicas para aprimorar a infer√™ncia de modelos e a precis√£o preditiva, com foco em m√©todos que combinam m√∫ltiplas fontes de informa√ß√£o ou modelos preditivos. Os m√©todos de comit√™, em particular, representam uma abordagem poderosa para modelagem preditiva, aproveitando a for√ßa da diversidade para obter previs√µes mais robustas e precisas. Este cap√≠tulo visa detalhar o funcionamento desses m√©todos e discutir sua relev√¢ncia no contexto do aprendizado estat√≠stico [^8.1].

### Conceitos Fundamentais

**Conceito 1:** O conceito de **ensemble learning** √© central para a compreens√£o dos m√©todos de comit√™. Em vez de confiar em um √∫nico modelo, os ensembles combinam as previs√µes de v√°rios modelos, muitas vezes de maneiras simples, como uma m√©dia [^8.1]. Essa combina√ß√£o pode levar a uma redu√ß√£o da vari√¢ncia e a previs√µes mais est√°veis, em especial quando os modelos individuais s√£o propensos √† alta vari√¢ncia. Os m√©todos de comit√™ exploram essa ideia de forma direta e eficaz.

```mermaid
graph TB
  subgraph "Ensemble Learning"
    A["Multiple Models"]
    B["Individual Predictions"]
    C["Combination Strategy (e.g., Average)"]
    D["Final Prediction"]
    A --> B
    B --> C
    C --> D
  end
```

**Lemma 1:** *A m√©dia de estimativas independentes de um par√¢metro possui uma vari√¢ncia menor do que a vari√¢ncia de qualquer estimativa individual.*

**Prova:** Sejam $\hat{\theta_1}, \hat{\theta_2}, \ldots, \hat{\theta_n}$ estimativas independentes de um par√¢metro $\theta$, cada uma com vari√¢ncia $\sigma^2$. A m√©dia dessas estimativas √© dada por:
$$ \bar{\theta} = \frac{1}{n} \sum_{i=1}^n \hat{\theta_i} $$
A vari√¢ncia da m√©dia √©:
$$ Var(\bar{\theta}) = Var \left( \frac{1}{n} \sum_{i=1}^n \hat{\theta_i} \right) = \frac{1}{n^2} \sum_{i=1}^n Var(\hat{\theta_i}) = \frac{1}{n^2} \cdot n \sigma^2 = \frac{\sigma^2}{n} $$
Como $\frac{\sigma^2}{n} < \sigma^2$ para $n > 1$, a vari√¢ncia da m√©dia √© menor do que a vari√¢ncia de qualquer estimativa individual. $\blacksquare$

```mermaid
graph TB
  subgraph "Variance Reduction"
    direction TB
    A["Individual Estimates: Œ∏ÃÇ‚ÇÅ, ..., Œ∏ÃÇ‚Çô, Var(Œ∏ÃÇ·µ¢) = œÉ¬≤"]
    B["Average Estimate: Œ∏ÃÑ = (1/n)‚àëŒ∏ÃÇ·µ¢"]
    C["Variance of Average: Var(Œ∏ÃÑ) = œÉ¬≤/n"]
    A --> B
    B --> C
  end
```

> üí° **Exemplo Num√©rico:** Considere que temos tr√™s modelos independentes que estimam a altura de uma pessoa, com as seguintes estimativas (em cm) e vari√¢ncias:
>
> *   Modelo 1: $\hat{\theta_1} = 170$, $Var(\hat{\theta_1}) = 10$
> *   Modelo 2: $\hat{\theta_2} = 173$, $Var(\hat{\theta_2}) = 10$
> *   Modelo 3: $\hat{\theta_3} = 168$, $Var(\hat{\theta_3}) = 10$
>
> A m√©dia das estimativas √©:
>
> $$ \bar{\theta} = \frac{170 + 173 + 168}{3} = 170.33 $$
>
> A vari√¢ncia da m√©dia √©:
>
> $$ Var(\bar{\theta}) = \frac{10}{3} \approx 3.33 $$
>
> Como esperado, a vari√¢ncia da m√©dia (3.33) √© menor que a vari√¢ncia de cada estimativa individual (10). Isso ilustra como a combina√ß√£o de estimativas independentes reduz a incerteza.

**Conceito 2:** Os **m√©todos de comit√™**, conforme mencionado em [^8.1], s√£o uma forma de ensemble learning onde as previs√µes de v√°rios modelos s√£o combinadas para obter um resultado final. Esses m√©todos frequentemente utilizam uma m√©dia simples das previs√µes de modelos individuais, o que pode ser visto como uma forma direta de model averaging. A abordagem de comit√™ busca, de maneira geral, simplificar a combina√ß√£o de modelos, tratando-os com igual import√¢ncia e sem pesos.

**Corol√°rio 1:** Se as estimativas s√£o n√£o-independentes, a vari√¢ncia da m√©dia ainda pode ser menor que a vari√¢ncia de cada estimativa individual se a correla√ß√£o for positiva, mas o efeito da redu√ß√£o da vari√¢ncia √© atenuado em rela√ß√£o ao caso independente.

> üí° **Exemplo Num√©rico:** Suponha que temos dois modelos que estimam a probabilidade de um cliente comprar um produto, e esses modelos t√™m uma correla√ß√£o positiva entre eles.
> * Modelo 1: Probabilidade estimada $\hat{p_1} = 0.6$, com vari√¢ncia $Var(\hat{p_1}) = 0.02$
> * Modelo 2: Probabilidade estimada $\hat{p_2} = 0.7$, com vari√¢ncia $Var(\hat{p_2}) = 0.02$
> * Covari√¢ncia entre os modelos: $Cov(\hat{p_1}, \hat{p_2}) = 0.01$
>
> A m√©dia das estimativas √© $\bar{p} = \frac{0.6+0.7}{2} = 0.65$. A vari√¢ncia da m√©dia, considerando a n√£o-independ√™ncia, √©:
>
> $Var(\bar{p}) = \frac{1}{2^2}[Var(\hat{p_1}) + Var(\hat{p_2}) + 2Cov(\hat{p_1},\hat{p_2})] = \frac{1}{4}[0.02 + 0.02 + 2(0.01)] = \frac{0.06}{4} = 0.015$
>
> Note que, mesmo com a correla√ß√£o positiva, a vari√¢ncia da m√©dia (0.015) √© menor do que a vari√¢ncia de cada estimativa individual (0.02), mas o efeito da redu√ß√£o √© menor do que seria se os modelos fossem independentes (onde a vari√¢ncia seria 0.01).

```mermaid
graph TB
    subgraph "Committee Method"
        A["Multiple Models"]
        B["Individual Predictions"]
        C["Equal Weighted Average"]
        D["Final Prediction"]
        A --> B
        B --> C
        C --> D
    end
```

**Conceito 3:** O **model averaging**, tamb√©m introduzido em [^8.1], engloba uma classe mais ampla de t√©cnicas em que modelos s√£o combinados por meio de uma m√©dia ponderada. Diferente de m√©todos de comit√™, que utilizam pesos iguais, o model averaging pode atribuir pesos diferentes aos modelos com base em seu desempenho ou complexidade [^8.8]. Essa abordagem oferece maior flexibilidade e pode levar a uma melhor precis√£o preditiva.
> ‚ö†Ô∏è **Nota Importante**: Apesar da simplicidade dos m√©todos de comit√™, √© essencial considerar o grau de diversidade entre os modelos combinados. Modelos muito similares podem n√£o fornecer melhorias significativas.

```mermaid
graph TB
    subgraph "Model Averaging"
        A["Multiple Models"]
        B["Individual Predictions"]
        C["Weighted Average"]
        D["Final Prediction"]
        A --> B
        B --> C
        C --> D
    end
```

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

<imagem: Diagrama em estilo flowchart que explica o processo de um m√©todo de comit√™ para classifica√ß√£o, mostrando os passos de treinamento de modelos individuais, combina√ß√£o de previs√µes e decis√£o final>

```mermaid
flowchart TD
  subgraph Treinamento
    A[Conjunto de Treinamento] --> B(Treinar Modelo 1)
    A --> C(Treinar Modelo 2)
    A --> D(Treinar Modelo N)
  end
    B --> E[Predi√ß√µes Modelo 1]
    C --> F[Predi√ß√µes Modelo 2]
    D --> G[Predi√ß√µes Modelo N]
  subgraph Combina√ß√£o
     E & F & G --> H(Combinar Predi√ß√µes)
  end
    H --> I[Previs√£o Final]
```
**Explica√ß√£o:** Este diagrama ilustra o processo de treinamento e combina√ß√£o em um m√©todo de comit√™, onde m√∫ltiplos modelos s√£o treinados e suas previs√µes s√£o agregadas.

Ao discutir como m√©todos de comit√™ se relacionam com regress√£o linear e m√≠nimos quadrados, √© √∫til considerar como essas t√©cnicas de regress√£o podem ser usadas para construir modelos base para os comit√™s. Em uma abordagem direta, modelos lineares podem ser usados como os modelos individuais de um comit√™, e a previs√£o combinada seria uma m√©dia das previs√µes lineares [^8.1]. A regress√£o de indicadores, por exemplo, poderia ser utilizada para construir modelos base que s√£o combinados em um m√©todo de comit√™. Como descrito em [^8.2], a regress√£o linear tamb√©m pode ser usada como um meio de ponderar modelos, embora a discuss√£o sobre *stacked generalization* em [^8.8] indique que modelos mais complexos de pondera√ß√£o podem ser √∫teis.

**Lemma 2:** *O erro de generaliza√ß√£o de um ensemble de modelos pode ser decomposto em uma soma de bias e vari√¢ncia, onde a m√©dia das previs√µes reduz a vari√¢ncia, enquanto o bias √© dado pelo bias m√©dio dos modelos individuais.*
**Prova:** Seja $L(\hat{f}, y)$ a fun√ß√£o de custo do modelo $\hat{f}$ sobre o valor $y$. Podemos decompor o erro esperado de um ensemble $\hat{f}_{ens}(x)$ como:
$$ E_x[L(\hat{f}_{ens}(x),y)] = Bias^2(\hat{f}_{ens}(x)) + Var(\hat{f}_{ens}(x)) $$
Onde o bias do ensemble √© aproximadamente igual a m√©dia do bias dos modelos individuais, i.e.:
$$Bias(\hat{f}_{ens}(x)) \approx \frac{1}{B} \sum_{b=1}^{B} Bias(\hat{f}_{b}(x))$$
E a vari√¢ncia do ensemble √© dada por:
$$Var(\hat{f}_{ens}(x)) = \frac{1}{B^2} Var(\sum_{b=1}^{B}\hat{f}_{b}(x))$$
Se os modelos individuais forem independentes, a vari√¢ncia √© reduzida em um fator $1/B$. $\blacksquare$

```mermaid
graph TB
  subgraph "Ensemble Error Decomposition"
    direction TB
    A["Generalization Error: E[L(fÃÇ‚Çë‚Çô‚Çõ(x), y)]"]
    B["Bias Component: Bias¬≤(fÃÇ‚Çë‚Çô‚Çõ(x)) ‚âà (1/B)‚àëBias(fÃÇ_b(x))"]
    C["Variance Component: Var(fÃÇ‚Çë‚Çô‚Çõ(x)) = (1/B¬≤)Var(‚àëfÃÇ_b(x))"]
    A --> B
    A --> C
  end
```

> üí° **Exemplo Num√©rico:** Imagine que estamos modelando a temperatura (em ¬∞C) com base na hora do dia usando modelos lineares. Temos tr√™s modelos individuais:
> * Modelo 1: $\hat{f}_1(x) = 10 + 2x$ (onde x √© a hora do dia, variando de 0 a 23).
> * Modelo 2: $\hat{f}_2(x) = 8 + 2.2x$.
> * Modelo 3: $\hat{f}_3(x) = 12 + 1.8x$.
>
> Suponha que o valor real da temperatura seja $y = 25$ √†s 10h ($x=10$). As previs√µes individuais e erros quadrados seriam:
>
>  *   Modelo 1: $\hat{f}_1(10) = 30$, $L(\hat{f}_1, y) = (30-25)^2 = 25$
>  *   Modelo 2: $\hat{f}_2(10) = 30$, $L(\hat{f}_2, y) = (30-25)^2 = 25$
>  *   Modelo 3: $\hat{f}_3(10) = 30$, $L(\hat{f}_3, y) = (30-25)^2 = 25$
>  A m√©dia das previs√µes (comit√™) √©:
>
> $$ \hat{f}_{ens}(10) = \frac{30+30+30}{3} = 30 $$
>
> A vari√¢ncia de cada modelo individual √© alta. No entanto, a vari√¢ncia do comit√™ √© menor porque todos os modelos est√£o sobrestimando o valor real.
>
> Para exemplificar a redu√ß√£o da vari√¢ncia, vamos adicionar mais ru√≠do aos modelos individuais
>
> * Modelo 1: $\hat{f}_1(10) = 28$, $L(\hat{f}_1, y) = (28-25)^2 = 9$
> * Modelo 2: $\hat{f}_2(10) = 32$, $L(\hat{f}_2, y) = (32-25)^2 = 49$
> * Modelo 3: $\hat{f}_3(10) = 26$, $L(\hat{f}_3, y) = (26-25)^2 = 1$
>
> A m√©dia das previs√µes agora √©:
>
> $$ \hat{f}_{ens}(10) = \frac{28+32+26}{3} = 28.67 $$
> O erro √© $L(\hat{f}_{ens}, y) = (28.67 - 25)^2 = 13.4$. Note que o erro m√©dio dos modelos individuais √© $(9+49+1)/3 = 19.67$. O erro do comit√™ foi menor do que a m√©dia dos erros individuais, ilustrando o benef√≠cio da combina√ß√£o. A vari√¢ncia das estimativas individuais √© maior, mas a vari√¢ncia da estimativa combinada √© menor.

**Corol√°rio 2:** O teorema anterior indica que, ao combinar modelos que s√£o independentes e t√™m baixo bias individual, podemos obter um ensemble com erro de generaliza√ß√£o menor do que qualquer modelo individual. M√©todos de comit√™, quando bem aplicados, se aproveitam desse princ√≠pio.

> ‚ùó **Ponto de Aten√ß√£o**: Em m√©todos de comit√™, todos os modelos t√™m o mesmo peso. √â importante garantir que todos os modelos contribuintes sejam razoavelmente competentes e que a diversidade entre eles seja maximizada para que o ensemble funcione corretamente.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

<imagem: Mapa mental mostrando como a sele√ß√£o de vari√°veis e regulariza√ß√£o se encaixam no processo de m√©todos de comit√™, detalhando como t√©cnicas como L1 e L2 podem ser usadas nos modelos base e como esses modelos podem ser combinados>
A sele√ß√£o de vari√°veis e a regulariza√ß√£o desempenham um papel crucial em m√©todos de comit√™, pois podem melhorar a estabilidade e o desempenho dos modelos individuais que comp√µem o comit√™. A regulariza√ß√£o, como a penalidade L1 e L2 mencionadas em [^8.8], podem ser aplicadas aos modelos base antes de serem combinados, ajudando a evitar overfitting e melhorando a generaliza√ß√£o. A sele√ß√£o de vari√°veis, por sua vez, permite que cada modelo base se concentre em um subconjunto relevante de atributos, o que pode aumentar a diversidade entre eles e levar a melhores resultados no ensemble final. M√©todos como bagging, discutidos em [^8.7], podem se beneficiar da regulariza√ß√£o para melhorarem a estabilidade dos modelos treinados em diferentes amostras bootstrap.

```mermaid
graph TB
  subgraph "Regularization in Committee Methods"
    direction TB
    A["Base Models"]
    B["Feature Selection"]
    C["Regularization (L1, L2)"]
    D["Combined Predictions"]
    A --> B
    A --> C
    B & C --> D
  end
```

**Lemma 3:** *A regulariza√ß√£o L1 em um modelo de regress√£o induz a esparsidade nos coeficientes, selecionando automaticamente as vari√°veis mais importantes.*
**Prova:** Considere um modelo de regress√£o com fun√ß√£o de custo $J(\beta)$ e regulariza√ß√£o L1 dada por:
$$ L(\beta) = J(\beta) + \lambda \sum_{j=1}^p |\beta_j| $$
Onde $\lambda$ √© o par√¢metro de regulariza√ß√£o. A penaliza√ß√£o L1 for√ßa muitos coeficientes $\beta_j$ a serem exatamente zero, efetivamente selecionando as vari√°veis mais relevantes para o modelo. Isso √© demonstrado pela geometria do problema de otimiza√ß√£o, onde os contornos da fun√ß√£o de custo se interceptam com as regi√µes onde alguns $\beta_j$ s√£o nulos. $\blacksquare$

```mermaid
graph TB
    subgraph "L1 Regularization"
        direction TB
        A["Cost Function: J(Œ≤)"]
        B["L1 Penalty: Œª‚àë|Œ≤‚±º|"]
        C["Regularized Cost: L(Œ≤) = J(Œ≤) + Œª‚àë|Œ≤‚±º|"]
        A --> C
        B --> C
        D["Sparse Coefficients Œ≤"]
        C --> D
    end
```

> üí° **Exemplo Num√©rico:** Vamos criar um exemplo com regress√£o linear e regulariza√ß√£o L1 (Lasso). Considere um problema de regress√£o com 5 vari√°veis preditoras ($x_1, x_2, x_3, x_4, x_5$) e uma vari√°vel resposta $y$. Os dados de treinamento s√£o:

```python
import numpy as np
from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

X_train = np.array([[1, 2, 3, 4, 5],
                    [2, 4, 5, 1, 3],
                    [3, 1, 2, 5, 4],
                    [4, 5, 1, 3, 2],
                    [5, 3, 4, 2, 1]])
y_train = np.array([10, 15, 13, 18, 16])

```

> Usando o sklearn, podemos ajustar um modelo Lasso com $\lambda = 1$.
```python
lasso_model = make_pipeline(StandardScaler(), Lasso(alpha=1.0))
lasso_model.fit(X_train, y_train)
print("Lasso coefficients:", lasso_model.named_steps['lasso'].coef_)
```
> A sa√≠da mostra que alguns coeficientes foram reduzidos a zero, indicando a sele√ß√£o de vari√°veis mais importantes.
>
> Vamos agora diminuir $\lambda = 0.1$ para observar um efeito menor na esparsidade dos coeficientes:
```python
lasso_model = make_pipeline(StandardScaler(), Lasso(alpha=0.1))
lasso_model.fit(X_train, y_train)
print("Lasso coefficients (lambda = 0.1):", lasso_model.named_steps['lasso'].coef_)
```
> Ao reduzir o $\lambda$, a penaliza√ß√£o L1 se torna menos intensa, e mais coeficientes s√£o diferentes de zero.
>  Este exemplo demonstra como o par√¢metro de regulariza√ß√£o controla a esparsidade do modelo. Em um m√©todo de comit√™, diferentes valores de $\lambda$ podem ser usados em modelos base para promover diversidade.

**Corol√°rio 3:** Aplicar regulariza√ß√£o L1 em modelos base de um m√©todo de comit√™ pode n√£o apenas melhorar o desempenho de cada modelo, mas tamb√©m contribuir para a diversidade do ensemble, uma vez que cada modelo pode se concentrar em um subconjunto diferente de vari√°veis.

> ‚úîÔ∏è **Destaque**: A escolha da t√©cnica de regulariza√ß√£o (L1, L2, elastic net) e do m√©todo de sele√ß√£o de vari√°veis deve levar em considera√ß√£o as caracter√≠sticas espec√≠ficas do conjunto de dados e a natureza dos modelos base utilizados no comit√™.

### Separating Hyperplanes e Perceptrons

<imagem: Diagrama que mostra a rela√ß√£o entre hyperplanes, perceptrons e m√©todos de comit√™ para classifica√ß√£o, mostrando como os modelos base (por exemplo, perceptrons) geram hyperplanes e como esses modelos s√£o combinados para criar decis√µes de comit√™>
Em rela√ß√£o a separating hyperplanes e perceptrons, um m√©todo de comit√™ pode utilizar modelos lineares como o perceptron como os classificadores base. Como discutido em [^8.8], os m√©todos de comit√™ normalmente combinam as previs√µes destes modelos lineares, o que pode ser interpretado como a combina√ß√£o das decis√µes de m√∫ltiplos hiperplanos. Ao combinar as previs√µes, o comit√™ tenta criar uma decis√£o mais robusta, menos sens√≠vel √†s varia√ß√µes dos dados, ou a decis√µes particulares de um √∫nico hiperplano.  O uso de perceptrons dentro de um m√©todo de comit√™ oferece uma forma de explorar o poder de diversos hiperplanos sem incorrer na complexidade de um √∫nico modelo com muitos par√¢metros. As t√©cnicas de bagging discutidas em [^8.7] ou boosting (mencionado em [^8.8]) podem, nesse contexto, levar a ensembles que melhoram a capacidade de discrimina√ß√£o de modelos lineares individuais.

```mermaid
graph TB
    subgraph "Committee of Hyperplanes"
        direction TB
        A["Perceptrons (Base Models)"]
        B["Individual Hyperplanes"]
        C["Combined Decision (e.g. Averaging)"]
        A --> B
        B --> C
    end
```

> üí° **Exemplo Num√©rico:** Suponha que temos um problema de classifica√ß√£o bin√°ria em 2D, onde os pontos s√£o dados por $(x_1, x_2)$ e pertencem √† classe 0 ou 1. Vamos usar Perceptrons como modelos base.
>
> Modelo 1: Perceptron define um hiperplano (linha) $0.5x_1 + 0.3x_2 - 1 = 0$.
> Modelo 2: Perceptron define um hiperplano (linha) $-0.2x_1 + 0.8x_2 + 0.5 = 0$.
>
> Para classificar um ponto, digamos $(x_1 = 2, x_2 = 1)$, cada perceptron calcula:
>
> *   Modelo 1: $0.5(2) + 0.3(1) - 1 = 1.3 - 1 = 0.3 > 0$.
> *   Modelo 2: $-0.2(2) + 0.8(1) + 0.5 = -0.4 + 0.8 + 0.5 = 0.9 > 0$.
>
> Assumindo que um valor positivo corresponde √† classe 1 e um valor negativo √† classe 0, ambos os perceptrons classificam o ponto como classe 1. Um m√©todo de comit√™ combinaria essas previs√µes (por exemplo, por vota√ß√£o ou m√©dia) para tomar uma decis√£o final. Se ambos os modelos concordam em uma previs√£o (por exemplo, classe 1), o comit√™ classificaria o ponto como classe 1. Caso contr√°rio, a decis√£o poderia ser baseada na maioria ou em outra fun√ß√£o de combina√ß√£o.

### Pergunta Te√≥rica Avan√ßada: Qual a rela√ß√£o entre a m√©dia das previs√µes em um m√©todo de comit√™ e a m√©dia posterior em um modelo Bayesiano, e como o bootstrap se encaixa nessa rela√ß√£o?
**Resposta:** Em um m√©todo de comit√™, a m√©dia das previs√µes √© uma combina√ß√£o direta das predi√ß√µes de modelos individuais, geralmente sem peso [^8.8]. Em um contexto Bayesiano, a m√©dia posterior √© a expectativa da vari√°vel de interesse (por exemplo, uma previs√£o) com rela√ß√£o √† distribui√ß√£o posterior dos par√¢metros. Conforme abordado em [^8.2], h√° uma rela√ß√£o interessante entre esses conceitos. Sob certas condi√ß√µes (prior n√£o-informativa e erros Gaussianos), o bootstrap aproxima a distribui√ß√£o posterior dos par√¢metros. A m√©dia das predi√ß√µes de modelos obtidas com os par√¢metros boostrap √© uma aproxima√ß√£o da m√©dia posterior Bayesiana.
**Lemma 4:** *Se as previs√µes individuais de um ensemble podem ser consideradas como amostras de uma distribui√ß√£o, a m√©dia das previs√µes converge para a expectativa dessa distribui√ß√£o.*
**Prova:** Sejam $\hat{y_1}, \hat{y_2}, \ldots, \hat{y_n}$ as previs√µes de um ensemble, consideradas amostras de uma distribui√ß√£o com valor esperado $\mu$. A m√©dia das previs√µes √© dada por:
$$ \bar{y} = \frac{1}{n} \sum_{i=1}^n \hat{y_i} $$
Pela lei dos grandes n√∫meros, √† medida que o n√∫mero de previs√µes $n$ aumenta, a m√©dia amostral $\bar{y}$ converge em probabilidade para o valor esperado $\mu$, ou seja:
$$ \lim_{n \to \infty} P(|\bar{y} - \mu| > \epsilon) = 0 \quad \forall \epsilon > 0 $$
Essa converg√™ncia implica que a m√©dia das previs√µes se aproxima do valor esperado da distribui√ß√£o das previs√µes, ou seja, a m√©dia posterior. $\blacksquare$

```mermaid
graph TB
    subgraph "Averaging and Expectation"
    direction TB
        A["Ensemble Predictions: yÃÇ‚ÇÅ, ..., yÃÇ‚Çô"]
        B["Sample Average: yÃÑ = (1/n)‚àëyÃÇ·µ¢"]
        C["Expectation: Œº"]
        D["Convergence: yÃÑ ‚Üí Œº as n ‚Üí ‚àû"]
        A --> B
        B --> D
        C --> D
    end
```

**Corol√°rio 4:** Quando usado de maneira apropriada, o bootstrap oferece uma forma pr√°tica de construir aproxima√ß√µes da m√©dia posterior, por meio da gera√ß√£o de amostras e do uso das m√©dias amostrais.
> ‚ö†Ô∏è **Ponto Crucial**: Embora a m√©dia das previs√µes em um m√©todo de comit√™ e a m√©dia posterior possam ser relacionadas sob certas condi√ß√µes, √© crucial reconhecer suas diferen√ßas conceituais. O m√©todo de comit√™ foca em reduzir a vari√¢ncia da predi√ß√£o agregada, enquanto a infer√™ncia bayesiana busca a distribui√ß√£o posterior completa.

### Conclus√£o
Os m√©todos de comit√™ representam uma abordagem fundamental para a modelagem preditiva, oferecendo maneiras robustas e eficazes de combinar m√∫ltiplos modelos. Ao usar a diversidade das previs√µes, esses m√©todos podem alcan√ßar maior precis√£o e estabilidade. As an√°lises te√≥ricas e os exemplos apresentados neste cap√≠tulo destacam a relev√¢ncia dos m√©todos de comit√™ no contexto da infer√™ncia estat√≠stica e do aprendizado de m√°quina. Futuras dire√ß√µes de pesquisa podem explorar m√©todos mais sofisticados para sele√ß√£o e combina√ß√£o de modelos base em ensembles, bem como a aplica√ß√£o dessas t√©cnicas a problemas mais complexos e conjuntos de dados. <!-- END DOCUMENT -->
### Footnotes
[^8.1]: "In this chapter we provide a general exposition of the maximum likelihood approach, as well as the Bayesian method for inference. The bootstrap, introduced in Chapter 7, is discussed in this context, and its relation to maximum likelihood and Bayes is described. Finally, we present some related techniques for model averaging and improvement, including committee methods, bagging, stacking and bumping." *(Trecho de Model Inference and Averaging)*
[^8.2]: "The corresponding fit (x) = ‚àë=1 Œ≤jhj (x) is shown in the top left panel of Figure 8.2. The estimated covariance matrix of √ü is Var(√ü) = (HH)-102" *(Trecho de Model Inference and Averaging)*
[^8.7]: "Earlier we introduced the bootstrap as a way of assessing the accuracy of a parameter estimate or a prediction. Here we show how to use the bootstrap to improve the estimate or prediction itself." *(Trecho de Model Inference and Averaging)*
[^8.8]: "Here we discuss Bayesian model averaging more generally. We have a set of candidate models Mm, m = 1,..., M for our training set Z." *(Trecho de Model Inference and Averaging)*
