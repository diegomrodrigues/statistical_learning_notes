Okay, let's enhance the text with practical numerical examples to solidify the understanding of SVMs as a penalized regression approach in RKHS.

## T√≠tulo: SVMs como Regress√£o Penalizada em RKHS: Uma Abordagem de Ajuste de Fun√ß√£o

```mermaid
graph LR
    A["Dados de Entrada (x, y)"] --> B("Transforma√ß√£o de Features com Kernel");
    B --> C("Minimiza√ß√£o do Risco Emp√≠rico Penalizado");
    C --> D["Fun√ß√£o de Decis√£o f(x) em RKHS"];
    D --> E("Classifica√ß√£o/Regress√£o");
    style B fill:#f9f,stroke:#333,stroke-width:2px
    style C fill:#ccf,stroke:#333,stroke-width:2px
```

### Introdu√ß√£o

Al√©m da vis√£o tradicional das **Support Vector Machines (SVMs)** como m√©todos de classifica√ß√£o baseados na maximiza√ß√£o da margem, as SVMs tamb√©m podem ser interpretadas como uma forma de **regress√£o penalizada** em um **Espa√ßo de Hilbert com Kernel Reprodutor (RKHS)**. Essa perspectiva oferece uma vis√£o complementar sobre o funcionamento das SVMs, conectando-as com outros m√©todos de ajuste de fun√ß√£o e destacando o papel da regulariza√ß√£o na constru√ß√£o de modelos robustos e com boa capacidade de generaliza√ß√£o.

Neste cap√≠tulo, vamos analisar a SVM como um problema de ajuste de fun√ß√£o, onde o objetivo √© encontrar uma fun√ß√£o que minimiza um certo erro, sujeito a uma restri√ß√£o de regulariza√ß√£o que controla a complexidade do modelo. Discutiremos como a fun√ß√£o de perda *hinge loss* e o termo de regulariza√ß√£o em SVMs se relacionam com outras fun√ß√µes de perda e regulariza√ß√µes comuns em problemas de regress√£o. Exploraremos como a teoria dos RKHS fornece uma base para entender a rela√ß√£o entre as fun√ß√µes *kernel* e as fun√ß√µes de ajuste no espa√ßo de *features* transformado.

A vis√£o das SVMs como um m√©todo de regress√£o penalizada em um RKHS oferece *insights* valiosos sobre as propriedades dos modelos SVM e sua conex√£o com outras t√©cnicas de aprendizado de m√°quina, o que contribui para uma compreens√£o mais profunda do funcionamento e das aplica√ß√µes das SVMs.

### SVMs como um Problema de Ajuste de Fun√ß√£o

**Conceito 1: O Problema de Ajuste de Fun√ß√£o e a Minimiza√ß√£o do Risco Emp√≠rico**

No aprendizado de m√°quina, o problema de ajuste de fun√ß√£o consiste em encontrar uma fun√ß√£o $f(x)$ que se aproxima o m√°ximo poss√≠vel dos valores de resposta $y$ em fun√ß√£o das *features* $x$. Em muitos problemas, como a regress√£o, o objetivo √© encontrar uma fun√ß√£o que minimize um certo erro ou perda entre a fun√ß√£o $f(x)$ e o valor de resposta $y$. Essa busca √© geralmente feita atrav√©s da minimiza√ß√£o do risco emp√≠rico:

$$ \min_f \frac{1}{N} \sum_{i=1}^{N} L(y_i, f(x_i)) $$

onde $L(y_i, f(x_i))$ √© uma fun√ß√£o de perda que quantifica o erro entre a predi√ß√£o $f(x_i)$ e o valor de resposta $y_i$.

No contexto de classifica√ß√£o, o problema de ajuste de fun√ß√£o consiste em encontrar uma fun√ß√£o $f(x)$ que separe as classes de forma adequada, e a fun√ß√£o de perda mede a inadequa√ß√£o da classifica√ß√£o. A fun√ß√£o de perda √© a medida utilizada para definir qu√£o errado um modelo est√° em rela√ß√£o √† tarefa de aprender.

**Lemma 1:** O problema de ajuste de fun√ß√£o consiste em encontrar uma fun√ß√£o $f(x)$ que minimize uma fun√ß√£o de perda, a qual quantifica a diferen√ßa entre as predi√ß√µes e os valores de resposta.

A demonstra√ß√£o desse lemma se baseia na an√°lise da formula√ß√£o geral de problemas de aprendizado de m√°quina, onde o objetivo √© minimizar o erro entre a predi√ß√£o do modelo e o valor desejado.

**Conceito 2: O Crit√©rio de Otimiza√ß√£o das SVMs como um Ajuste de Fun√ß√£o Penalizado**

O crit√©rio de otimiza√ß√£o das SVMs, para o caso n√£o separ√°vel, pode ser expresso como:

```mermaid
graph LR
    subgraph "SVM Optimization Criterion"
        direction LR
        A["Objective Function"] --> B["Regularization Term: 1/2 * ||Œ≤||¬≤"]
        A --> C["Loss Term: C * Œ£Œæ·µ¢"]
        B --> D["Optimization Subject to Constraints"]
        C --> D
        D --> E["Constraints: y·µ¢(x·µ¢·µÄŒ≤ + Œ≤‚ÇÄ) ‚â• 1 - Œæ·µ¢;  Œæ·µ¢ ‚â• 0"]

        style A fill:#f9f,stroke:#333,stroke-width:2px
    end
```
$$ \min_{\beta, \beta_0, \xi} \frac{1}{2} ||\beta||^2 + C \sum_{i=1}^{N} \xi_i $$

sujeito a:

$$ y_i(x_i^T\beta + \beta_0) \geq 1 - \xi_i, \quad \forall i $$
$$ \xi_i \geq 0, \quad \forall i $$

Esse crit√©rio pode ser interpretado como um problema de ajuste de fun√ß√£o penalizado, onde:

*   O termo $\frac{1}{2} ||\beta||^2$ √© um termo de regulariza√ß√£o que penaliza a complexidade da fun√ß√£o de decis√£o, mantendo os coeficientes do modelo pequenos e controlando o *overfitting*.
*   O termo $C \sum_{i=1}^{N} \xi_i$ √© um termo que penaliza os erros de classifica√ß√£o (as amostras que violam a margem). As vari√°veis de folga $\xi_i$ s√£o utilizadas para representar o grau de inadequa√ß√£o dos dados em rela√ß√£o √† margem. A restri√ß√£o $\xi_i \geq 0$ garante que as vari√°veis de folga sejam n√£o negativas, o que faz com que o modelo n√£o seja penalizado por erros nulos ou pequenos.

A restri√ß√£o $y_i(x_i^T\beta + \beta_0) \geq 1 - \xi_i$ pode ser vista como uma forma de definir uma fun√ß√£o de perda espec√≠fica, conhecida como ***hinge loss***, que √© dada por:

$$ L(y_i, f(x_i)) = [1 - y_i f(x_i)]_+ $$

onde $f(x_i) = x_i^T\beta + \beta_0$, e $[z]_+$ significa que se o valor dentro do colchete for positivo, o resultado √© o pr√≥prio valor, e se for negativo, o resultado √© 0. O *hinge loss* penaliza erros de classifica√ß√£o, mas n√£o penaliza pontos que est√£o corretamente classificados e a uma dist√¢ncia suficiente do hiperplano de decis√£o.

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o bin√°ria com duas amostras:
>
> - Amostra 1: $x_1 = [1, 2]$, $y_1 = 1$
> - Amostra 2: $x_2 = [2, 1]$, $y_2 = -1$
>
> Suponha que ap√≥s a otimiza√ß√£o, tenhamos os seguintes par√¢metros para o SVM:
>
> - $\beta = [-0.5, 0.5]$
> - $\beta_0 = 0.2$
>
> Vamos calcular o valor da fun√ß√£o de decis√£o $f(x)$ para cada amostra:
>
> $f(x_1) = x_1^T\beta + \beta_0 = [1, 2] \cdot [-0.5, 0.5] + 0.2 = -0.5 + 1 + 0.2 = 0.7$
>
> $f(x_2) = x_2^T\beta + \beta_0 = [2, 1] \cdot [-0.5, 0.5] + 0.2 = -1 + 0.5 + 0.2 = -0.3$
>
> Agora, vamos calcular o *hinge loss* para cada amostra:
>
> $L(y_1, f(x_1)) = [1 - y_1 f(x_1)]_+ = [1 - 1 * 0.7]_+ = [0.3]_+ = 0.3$
>
> $L(y_2, f(x_2)) = [1 - y_2 f(x_2)]_+ = [1 - (-1) * (-0.3)]_+ = [1 - 0.3]_+ = [0.7]_+ = 0.7$
>
> Observe que ambas as amostras t√™m *hinge loss* diferente de zero, pois nenhuma est√° no lado correto da margem com uma dist√¢ncia maior ou igual a 1. O modelo tentar√° minimizar a soma desses *losses* penalizando os erros de classifica√ß√£o, juntamente com o termo de regulariza√ß√£o.

**Corol√°rio 1:** As SVMs podem ser interpretadas como um m√©todo de ajuste de fun√ß√£o penalizado, onde a fun√ß√£o de custo combina um termo de regulariza√ß√£o que controla a complexidade do modelo com uma fun√ß√£o de perda que penaliza os erros de classifica√ß√£o.

A demonstra√ß√£o desse corol√°rio se baseia na an√°lise da fun√ß√£o de custo das SVMs, que pode ser decomposta em um termo de regulariza√ß√£o (a norma ao quadrado de $\beta$) e uma fun√ß√£o de perda (*hinge loss*).

### A Fun√ß√£o de Perda Hinge Loss e Outras Alternativas

```mermaid
graph LR
    A["Hinge Loss: [1 - yf(x)]+"] -->|Classification| B("SVM");
    C["Squared Error: (y - f(x))¬≤"] -->|Regression| D("Linear Regression");
    E["Log-Loss: -[ylog(p(x)) + (1-y)log(1-p(x))]"] -->|Classification| F("Logistic Regression");
    G["Absolute Error: |y - f(x)|"] -->|Regression| H("Robust Regression");
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style C fill:#ccf,stroke:#333,stroke-width:2px
    style E fill:#aaf,stroke:#333,stroke-width:2px
    style G fill:#afa,stroke:#333,stroke-width:2px
```

A fun√ß√£o de perda **hinge loss**, utilizada nas SVMs, √© uma fun√ß√£o espec√≠fica projetada para problemas de classifica√ß√£o. A fun√ß√£o de perda *hinge loss* √© definida como:

$$ L(y, f(x)) = [1 - y f(x)]_+ $$

onde $y \in \{-1, 1\}$ √© o r√≥tulo da classe e $f(x)$ √© a fun√ß√£o de decis√£o. A fun√ß√£o *hinge loss* penaliza linearmente erros de classifica√ß√£o e n√£o penaliza pontos que est√£o corretamente classificados e a uma dist√¢ncia suficiente da margem. A propriedade de n√£o penalizar os dados corretamente classificados leva √† esparsidade da solu√ß√£o, onde o modelo s√≥ depende dos vetores de suporte.

Outras fun√ß√µes de perda comuns em problemas de regress√£o e classifica√ß√£o incluem:

1.  **Erro Quadr√°tico:**
    $$ L(y, f(x)) = (y - f(x))^2 $$
    O erro quadr√°tico √© uma fun√ß√£o de perda comum em problemas de regress√£o e penaliza fortemente erros grandes, o que a torna sens√≠vel a *outliers*.
2.  **Log-Loss ou Entropia Cruzada:**
    $$ L(y, f(x)) = - [y \log(p(x)) + (1-y) \log(1-p(x))] $$
    onde $p(x)$ √© a probabilidade de pertencer √† classe 1, e essa fun√ß√£o √© utilizada em problemas de classifica√ß√£o log√≠stica. O log-loss penaliza o modelo de forma mais suave quando as classes s√£o mais sobrepostas.
3.  **Erro Absoluto:**
    $$ L(y, f(x)) = |y - f(x)| $$
    O erro absoluto √© uma fun√ß√£o de perda robusta a *outliers*, mas n√£o √© diferenci√°vel na origem, o que dificulta sua otimiza√ß√£o usando gradiente.

Cada fun√ß√£o de perda tem caracter√≠sticas e propriedades espec√≠ficas, e a escolha da fun√ß√£o de perda apropriada depende da natureza do problema e das propriedades que se desejam obter no modelo resultante. A fun√ß√£o *hinge loss* √© uma escolha adequada para problemas de classifica√ß√£o, pois ela leva √† maximiza√ß√£o da margem, √† esparsidade dos modelos (somente os vetores de suporte s√£o importantes para a solu√ß√£o) e √† robustez em rela√ß√£o a dados ruidosos ou *outliers*.

> üí° **Exemplo Num√©rico:**
>
> Vamos comparar o *hinge loss* com o erro quadr√°tico para o mesmo exemplo anterior:
>
> - Amostra 1: $x_1 = [1, 2]$, $y_1 = 1$, $f(x_1) = 0.7$
> - Amostra 2: $x_2 = [2, 1]$, $y_2 = -1$, $f(x_2) = -0.3$
>
> *Hinge Loss* (j√° calculado):
>
> $L_{hinge}(y_1, f(x_1)) = 0.3$
> $L_{hinge}(y_2, f(x_2)) = 0.7$
>
> Erro Quadr√°tico:
>
> $L_{quad}(y_1, f(x_1)) = (y_1 - f(x_1))^2 = (1 - 0.7)^2 = 0.09$
> $L_{quad}(y_2, f(x_2)) = (y_2 - f(x_2))^2 = (-1 - (-0.3))^2 = (-0.7)^2 = 0.49$
>
> Observe que o *hinge loss* atribui um valor maior de perda para amostras que est√£o dentro da margem ou classificadas incorretamente, enquanto o erro quadr√°tico penaliza o erro de predi√ß√£o em si. Para a amostra 1, que est√° no lado correto mas dentro da margem, o *hinge loss* √© maior que o erro quadr√°tico. Para a amostra 2, que est√° no lado errado, o *hinge loss* tamb√©m √© maior.
>
> Para um exemplo de regress√£o, considere que $y_1=2$ e $f(x_1)=1.5$, e $y_2=5$ e $f(x_2)=6$.
>
> Erro Quadr√°tico:
>
> $L_{quad}(y_1, f(x_1)) = (y_1 - f(x_1))^2 = (2 - 1.5)^2 = 0.25$
> $L_{quad}(y_2, f(x_2)) = (y_2 - f(x_2))^2 = (5 - 6)^2 = 1$
>
> Erro Absoluto:
>
> $L_{abs}(y_1, f(x_1)) = |y_1 - f(x_1)| = |2 - 1.5| = 0.5$
> $L_{abs}(y_2, f(x_2)) = |y_2 - f(x_2)| = |5 - 6| = 1$

**Lemma 3:** A fun√ß√£o de perda *hinge loss* em SVMs leva √† maximiza√ß√£o da margem e a modelos esparsos, onde a solu√ß√£o depende apenas dos vetores de suporte, e com boa robustez a *outliers*.

A demonstra√ß√£o desse lemma se baseia na an√°lise da forma da fun√ß√£o de perda *hinge loss*, que √© zero para pontos que est√£o no lado correto da margem e cresce linearmente para pontos classificados incorretamente. A natureza da fun√ß√£o leva a solu√ß√µes esparsas, onde apenas vetores de suporte s√£o importantes, e a margem de separa√ß√£o leva a modelos mais robustos a *outliers*.

### Regulariza√ß√£o em SVMs e o Controle da Complexidade do Modelo

```mermaid
graph LR
    subgraph "Regularization and Model Complexity"
        direction TB
    A["High C Value"] --> B["Lower Regularization Strength"];
    B --> C["More Complex Model"];
    C --> D["Low Bias, High Variance"];
    E["Low C Value"] --> F["Higher Regularization Strength"];
    F --> G["Less Complex Model"];
    G --> H["High Bias, Low Variance"];
    end
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style E fill:#ccf,stroke:#333,stroke-width:2px
```

O termo $\frac{1}{2} ||\beta||^2$ na fun√ß√£o de custo das SVMs √© um termo de **regulariza√ß√£o**, especificamente a regulariza√ß√£o L2, tamb√©m conhecida como regulariza√ß√£o *ridge*, que penaliza a complexidade da fun√ß√£o de decis√£o e ajuda a evitar o *overfitting*. A regulariza√ß√£o L2 adiciona √† fun√ß√£o de custo a soma dos quadrados dos coeficientes do modelo, o que reduz a magnitude desses coeficientes e torna o modelo mais est√°vel.

A regulariza√ß√£o tamb√©m influencia a escolha dos vetores de suporte. Ao reduzir a magnitude dos coeficientes, a regulariza√ß√£o L2 faz com que menos amostras se tornem vetores de suporte, o que leva a modelos mais simples e com melhor capacidade de generaliza√ß√£o.

A escolha do par√¢metro de regulariza√ß√£o $C$ controla a for√ßa da regulariza√ß√£o. Valores altos de $C$ levam a modelos mais complexos, com menor regulariza√ß√£o, enquanto valores baixos de $C$ levam a modelos mais simples, com maior regulariza√ß√£o, como j√° mencionado em [^12.2].

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar o mesmo problema de classifica√ß√£o e comparar o efeito de diferentes valores de $C$. Para simplificar, vamos assumir que, ap√≥s o treinamento com $C=1$, encontramos $\beta = [-0.5, 0.5]$. Agora, vamos treinar com um valor de $C=0.1$ (maior regulariza√ß√£o) e $C=10$ (menor regulariza√ß√£o).
>
> Com $C=0.1$, a regulariza√ß√£o √© mais forte, e o modelo tende a ter coeficientes menores. Suponha que o modelo encontre $\beta = [-0.2, 0.2]$.
>
> Com $C=10$, a regulariza√ß√£o √© mais fraca, e o modelo tem mais liberdade para ajustar os dados. Suponha que o modelo encontre $\beta = [-0.8, 0.8]$.
>
> A norma L2 de $\beta$ para cada caso √©:
>
> -  $C=0.1$: $||\beta||^2 = (-0.2)^2 + (0.2)^2 = 0.08$
> -  $C=1$: $||\beta||^2 = (-0.5)^2 + (0.5)^2 = 0.5$
> -  $C=10$: $||\beta||^2 = (-0.8)^2 + (0.8)^2 = 1.28$
>
> O termo de regulariza√ß√£o $\frac{1}{2} ||\beta||^2$ ser√° maior para $C=10$ do que para $C=0.1$. Isso significa que, para valores maiores de $C$, o modelo pode se ajustar mais aos dados de treinamento, mas pode ter um desempenho pior em dados n√£o vistos, enquanto para valores menores de $C$, o modelo √© mais simples e pode generalizar melhor, mas pode ter um vi√©s maior.

A combina√ß√£o do termo de regulariza√ß√£o com a fun√ß√£o de perda *hinge loss* √© fundamental para a constru√ß√£o de modelos SVM robustos e com boa capacidade de generaliza√ß√£o. A regulariza√ß√£o controla a complexidade do modelo, enquanto a fun√ß√£o de perda *hinge loss* promove a esparsidade da solu√ß√£o e leva √† maximiza√ß√£o da margem, um resultado que garante boa capacidade de generaliza√ß√£o.

**Corol√°rio 2:** A regulariza√ß√£o L2 e a escolha do par√¢metro C controlam a complexidade do modelo SVM e seu comportamento em dados de treinamento e teste, e um equil√≠brio apropriado entre complexidade e ajuste √© crucial para um bom desempenho.

A demonstra√ß√£o desse corol√°rio se baseia na an√°lise da fun√ß√£o de custo da SVM e como o termo de regulariza√ß√£o L2 e o par√¢metro C afetam a magnitude dos coeficientes e o n√∫mero de vetores de suporte, e, por consequ√™ncia, a generaliza√ß√£o do modelo.

### Conex√£o com o Problema Dual e o Uso de Kernels

```mermaid
graph LR
    A["Input Data (x)"] --> B("Mapping to RKHS with Kernel K(x, x')");
    B --> C["Dual Optimization Problem (Œ±)"];
    C --> D("Decision Function: f(x) = Œ£ Œ±·µ¢y·µ¢K(x·µ¢, x) + Œ≤‚ÇÄ");
    style B fill:#f9f,stroke:#333,stroke-width:2px
```

A utiliza√ß√£o de **kernels** em SVMs transforma o espa√ßo de *features* e permite que o modelo construa fronteiras de decis√£o n√£o lineares. A fun√ß√£o de custo das SVMs com *kernels* pode ser expressa como:

$$ \min_{\alpha} \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_i \alpha_j y_i y_j K(x_i, x_j) - \sum_{i=1}^{N} \alpha_i $$
sujeito a:
$$ 0 \leq \alpha_i \leq C $$
$$ \sum_{i=1}^{N} \alpha_i y_i = 0 $$

Nessa formula√ß√£o, a fun√ß√£o *kernel* $K(x_i, x_j)$ substitui o produto interno $x_i^T x_j$ no espa√ßo original de *features*, e os par√¢metros do modelo s√£o determinados atrav√©s da maximiza√ß√£o da fun√ß√£o objetivo acima, e sujeitos √†s restri√ß√µes de igualdade e desigualdade.

The decision function of the kernel SVM is given by:
$$ f(x) = \sum_{i \in SV} \alpha_i y_i K(x_i, x) + \beta_0 $$

where support vectors, constants $\alpha_i$ and bias $\beta_0$ are defined according to the KKT conditions and the optimization criteria of the dual problem.

A fun√ß√£o de decis√£o da SVM com *kernel* √© dada por:

$$ f(x) = \sum_{i \in SV} \alpha_i y_i K(x_i, x) + \beta_0 $$

onde os vetores de suporte, as constantes $\alpha_i$ e o *bias* $\beta_0$ s√£o definidos de acordo com as condi√ß√µes KKT e o crit√©rio de otimiza√ß√£o do problema dual.

A utiliza√ß√£o de *kernels* no contexto da fun√ß√£o de perda e regulariza√ß√£o das SVMs permite construir modelos complexos e capazes de lidar com dados de alta dimens√£o, sem explicitar a transforma√ß√£o para o espa√ßo de *features* transformado.

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um exemplo com um *kernel* linear e outro com um *kernel* gaussiano (RBF). Suponha que temos duas amostras:
>
> - $x_1 = [1, 1]$, $y_1 = 1$
> - $x_2 = [2, 2]$, $y_2 = -1$
>
> *Kernel* Linear: $K(x_i, x_j) = x_i^T x_j$
>
> $K(x_1, x_1) = [1, 1] \cdot [1, 1] = 2$
> $K(x_1, x_2) = [1, 1] \cdot [2, 2] = 4$
> $K(x_2, x_1) = [2, 2] \cdot [1, 1] = 4$
> $K(x_2, x_2) = [2, 2] \cdot [2, 2] = 8$
>
> *Kernel* Gaussiano (RBF): $K(x_i, x_j) = \exp(-\gamma ||x_i - x_j||^2)$, com $\gamma = 0.5$
>
> $K(x_1, x_1) = \exp(-0.5 * 0) = 1$
> $K(x_1, x_2) = \exp(-0.5 * ||[1, 1] - [2, 2]||^2) = \exp(-0.5 * (1^2 + 1^2)) = \exp(-1) \approx 0.368$
> $K(x_2, x_1) = \exp(-0.5 * ||[2, 2] - [1, 1]||^2) = \exp(-0.5 * (1^2 + 1^2)) = \exp(-1) \approx 0.368$
> $K(x_2, x_2) = \exp(-0.5 * 0) = 1$
>
> Usando esses valores de *kernel*, o problema de otimiza√ß√£o dual √© resolvido para encontrar os valores de $\alpha_i$. Se por exemplo, ap√≥s a otimiza√ß√£o, $\alpha_1 = 0.5$, $\alpha_2 = 0.2$, e $\beta_0=0.1$, a fun√ß√£o de decis√£o para um novo ponto $x=[1.5, 1.5]$ usando o *kernel* linear seria:
>
> $f(x) = \alpha_1 y_1 K(x_1, x) + \alpha_2 y_2 K(x_2, x) + \beta_0$
>
> $K(x_1, x) = [1, 1] \cdot [1.5, 1.5] = 3$
> $K(x_2, x) = [2, 2] \cdot [1.5, 1.5] = 6$
>
> $f(x) = 0.5 * 1 * 3 + 0.2 * (-1) * 6 + 0.1 = 1.5 - 1.2 + 0.1 = 0.4$
>
> A fun√ß√£o de decis√£o para um novo ponto $x=[1.5, 1.5]$ usando o *kernel* gaussiano (RBF) seria:
>
> $K(x_1, x) = \exp(-0.5 * ||[1, 1] - [1.5, 1.5]||^2) = \exp(-0.5 * (0.5^2 + 0.5^2)) \approx 0.882$
> $K(x_2, x) = \exp(-0.5 * ||[2, 2] - [1.5, 1.5]||^2) = \exp(-0.5 * (0.5^2 + 0.5^2)) \approx 0.882$
>
> $f(x) = 0.5 * 1 * 0.882 + 0.2 * (-1) * 0.882 + 0.1 = 0.441 - 0.1764 + 0.1 =  0.3646$
>
> Observe que a escolha do *kernel* influencia o resultado da fun√ß√£o de decis√£o.

**Corol√°rio 3:** O uso de *kernels* em SVMs, juntamente com a fun√ß√£o de perda *hinge loss* e o termo de regulariza√ß√£o, leva a modelos com bom desempenho e com capacidade de generalizar para novos dados.

A demonstra√ß√£o desse corol√°rio se baseia na an√°lise da formula√ß√£o da SVM com *kernels*, e como a fun√ß√£o de perda *hinge loss* leva √† maximiza√ß√£o da margem e √† esparsidade da solu√ß√£o, e como o termo de regulariza√ß√£o controla a complexidade do modelo, e os *kernels* mapeiam os dados em espa√ßos de alta dimens√£o, que permite modelar rela√ß√µes n√£o lineares.

### Conclus√£o

Neste cap√≠tulo, exploramos a vis√£o das **Support Vector Machines (SVMs)** como um m√©todo de **regress√£o penalizada** em um **Espa√ßo de Hilbert com Kernel Reprodutor (RKHS)**. Vimos como a fun√ß√£o de custo das SVMs combina um termo de regulariza√ß√£o com uma fun√ß√£o de perda *hinge loss*, e como essa combina√ß√£o leva a modelos robustos e com boa capacidade de generaliza√ß√£o.

Analisamos a fun√ß√£o de perda *hinge loss* e como ela se compara a outras fun√ß√µes de perda comuns em problemas de regress√£o e classifica√ß√£o. Vimos como a regulariza√ß√£o L2 controla a complexidade do modelo e como o par√¢metro $C$ determina o compromisso entre a maximiza√ß√£o da margem e a toler√¢ncia a erros. Exploramos tamb√©m como o *kernel trick* √© utilizado para mapear os dados para um espa√ßo de alta dimens√£o, transformando um problema de classifica√ß√£o n√£o linear em um problema linear no espa√ßo de *features* transformado.

A compreens√£o das SVMs como um m√©todo de regress√£o penalizada em um RKHS proporciona uma vis√£o complementar sobre a formula√ß√£o desse m√©todo e sua rela√ß√£o com outras t√©cnicas de aprendizado de m√°quina. A combina√ß√£o da teoria dos RKHS com a utiliza√ß√£o de *kernels* e a formula√ß√£o do problema de otimiza√ß√£o fazem das SVMs uma ferramenta poderosa e flex√≠vel para problemas de classifica√ß√£o e regress√£o.

### Footnotes

[^12.1]: "In this chapter we describe generalizations of linear decision boundaries for classification. Optimal separating hyperplanes are introduced in Chapter 4 for the case when two classes are linearly separable. Here we cover extensions to the nonseparable case, where the classes overlap. These techniques are then generalized to what is known as the support vector machine, which produces nonlinear boundaries by constructing a linear boundary in a large, transformed version of the feature space." *(Trecho de  "Support Vector Machines and Flexible Discriminants")*

[^12.2]: "In Chapter 4 we discussed a technique for constructing an optimal separating hyperplane between two perfectly separated classes. We review this and generalize to the nonseparable case, where the classes may not be separable by a linear boundary." *(Trecho de  "Support Vector Machines and Flexible Discriminants")*

[^12.3]: "The support vector machine classifier is an extension of this idea, where the dimension of the enlarged space is allowed to get very large, infinite in some cases. It might seem that the computations would become prohibitive. It would also seem that with sufficient basis functions, the data would be separable, and overfitting would occur. We first show how the SVM technology deals with these issues. We then see that in fact the SVM classifier is solving a function-fitting problem using a particular criterion and form of regularization, and is part of a much bigger class of problems that includes the smoothing splines of Chapter 5." *(Trecho de  "Support Vector Machines and Flexible Discriminants")*
