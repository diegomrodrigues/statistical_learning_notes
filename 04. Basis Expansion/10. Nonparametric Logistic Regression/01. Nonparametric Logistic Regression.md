## Extensão de Splines de Suavização para Regressão Logística Não Paramétrica

### Introdução
Em continuidade ao capítulo sobre *Basis Expansions and Regularization*, e em particular à seção sobre **Smoothing Splines** [^5.4], este capítulo explora a extensão do problema de *smoothing spline* para outros domínios. Especificamente, focaremos na aplicação de *smoothing splines* em **regressão logística não paramétrica**. O conceito chave é transferir a tecnologia de *smoothing splines* para outros domínios [^frase_chave], o que permite modelar relações não lineares entre preditores e a probabilidade de um evento.

### Conceitos Fundamentais

**Regressão Logística Não Paramétrica** é uma técnica que combina os princípios da regressão logística com a flexibilidade dos métodos não paramétricos. Em vez de assumir uma forma funcional específica para a relação entre os preditores e a resposta, a regressão logística não paramétrica permite que os dados determinem a forma da função.

O modelo básico da regressão logística é dado por [^5.28]:
$$\
\log \left(\frac{Pr(Y = 1|X = x)}{Pr(Y = 0|X = x)}\right) = f(x),
$$
onde $f(x)$ é uma função que modela a relação entre o preditor $X$ e o log-odds da probabilidade de $Y = 1$.  Em regressão logística paramétrica, $f(x)$ seria uma função linear. Na regressão logística não paramétrica, $f(x)$ é uma função suave estimada a partir dos dados.

A probabilidade condicional é dada por [^5.29]:
$$\
Pr(Y = 1|X = x) = \frac{e^{f(x)}}{1 + e^{f(x)}}.
$$

Para ajustar $f(x)$ de forma suave, é utilizado um critério de log-verossimilhança penalizada [^5.30]:
$$\
l(f; \lambda) = \sum_{i=1}^{N} [y_i \log p(x_i) + (1 - y_i) \log (1 - p(x_i))] - \frac{\lambda}{2} \int \{f''(t)\}^2 dt,
$$
onde $p(x_i) = Pr(Y = 1|X = x_i)$, $y_i$ são os valores observados da variável resposta (0 ou 1), e $\lambda$ é o parâmetro de suavização. O primeiro termo da equação é a log-verossimilhança baseada na distribuição binomial, análoga à regressão logística paramétrica. O segundo termo penaliza a curvatura da função $f(x)$, promovendo a suavidade.

Argumentos semelhantes aos utilizados na seção sobre *smoothing splines* [^5.4] mostram que a função $f$ ótima é um *spline* natural de dimensão finita com nós nos valores únicos de $x$ [^5.30]. Isso significa que podemos representar $f(x)$ como uma combinação linear de funções de base $N_j(x)$:
$$\
f(x) = \sum_{j=1}^{N} N_j(x) \theta_j.
$$

Para encontrar os coeficientes $\theta_j$, maximizamos a log-verossimilhança penalizada. As derivadas primeira e segunda da log-verossimilhança são [^5.31, ^5.32]:
$$\
\frac{\partial l(\theta)}{\partial \theta} = N^T (y - p) - \lambda \Omega \theta,
$$
$$\
\frac{\partial^2 l(\theta)}{\partial \theta \partial \theta^T} = -N^T WN - \lambda \Omega,
$$
onde $p$ é o vetor de tamanho $N$ com elementos $p(x_i)$, $W$ é uma matriz diagonal com pesos $p(x_i)(1 - p(x_i))$, e $\Omega$ é a matriz de penalização. Como a primeira derivada é não linear em $\theta$, usamos um algoritmo iterativo como o Newton-Raphson [^5.31]. A equação de atualização pode ser escrita como [^5.33]:
$$\
\theta^{new} = (N^T WN + \lambda \Omega)^{-1} N^T W (N \theta^{old} + W^{-1} (y - p)) = (N^T WN + \lambda \Omega)^{-1} N^T W z,
$$
onde $z$ é a *working response*. Em termos dos valores ajustados [^5.34]:
$$\
f^{new} = N (N^T WN + \lambda \Omega)^{-1} N^T W (f^{old} + W^{-1} (y - p)) = S_{\lambda, W} z.
$$

A equação acima sugere que a atualização se ajusta a um *smoothing spline* ponderado à resposta de trabalho $z$ [^5.34]. A forma de [^5.34] é sugestiva e pode ser substituída por qualquer operador de regressão não paramétrico (ponderado), obtendo famílias gerais de modelos de regressão logística não paramétrica. Embora $x$ seja unidimensional aqui, este procedimento generaliza-se naturalmente para $x$ de dimensão superior [^5.34]. Essas extensões estão no centro dos modelos aditivos generalizados.

### Conclusão

Este capítulo demonstrou como o problema de *smoothing spline* pode ser estendido para a regressão logística não paramétrica. A chave é construir um critério de verossimilhança penalizada e encontrar a função que minimiza este critério. O resultado é um modelo flexível que pode capturar relações não lineares entre os preditores e a variável resposta. Este método pode ser estendido para modelos aditivos generalizados, permitindo a modelagem de dados complexos.

### Referências
[^frase_chave]: "The smoothing spline problem can be extended to other domains, such as logistic regression, by transferring the technology to other domains."
[^5.4]: Seção 5.4 do texto original, que introduz o conceito de *smoothing splines*.
[^5.28]: Equação 5.28 do texto original, que define o modelo de regressão logística não paramétrica.
[^5.29]: Equação 5.29 do texto original, que define a probabilidade condicional.
[^5.30]: Equação 5.30 do texto original, que define o critério de log-verossimilhança penalizada.
[^5.31]: Equação 5.31 do texto original, que define a primeira derivada da log-verossimilhança.
[^5.32]: Equação 5.32 do texto original, que define a segunda derivada da log-verossimilhança.
[^5.33]: Equação 5.33 do texto original, que define a equação de atualização.
[^5.34]: Equação 5.34 do texto original, que define a atualização em termos dos valores ajustados.
<!-- END -->