## Tradeoffs in Basis Expansions: Navigating Model Complexity

```mermaid
graph LR
    subgraph "Basis Expansions Tradeoffs"
        direction TB
        A["'Model Complexity'"]
        B["'Choice of Basis Functions'"]
        C["'Number of Basis Functions'"]
        D["'Regularization Methods'"]
        E["'Selection Methods'"]
        F["'Bias-Variance Tradeoff'"]
        A --> F
        B --> F
        C --> F
        D --> F
        E --> F
    end
```

### Introdu√ß√£o

A t√©cnica de *basis expansions*, como explorado anteriormente, oferece a capacidade de estender o poder expressivo de modelos lineares, permitindo que eles capturem rela√ß√µes n√£o lineares nos dados [^5.1]. No entanto, essa maior flexibilidade n√£o vem sem custos. A escolha das fun√ß√µes de base, o n√∫mero de fun√ß√µes de base utilizadas e a forma como a complexidade do modelo √© controlada envolvem *tradeoffs* que precisam ser considerados para obter resultados eficazes. Este cap√≠tulo explora esses *tradeoffs*, oferecendo uma vis√£o aprofundada de como as decis√µes de modelagem impactam o desempenho e as caracter√≠sticas do modelo. Em particular, ser√° abordado o compromisso entre **vi√©s** e **vari√¢ncia**, que √© central para a constru√ß√£o de modelos robustos e generaliz√°veis [^5.5].

### O Tradeoff Vi√©s-Vari√¢ncia

O *tradeoff* vi√©s-vari√¢ncia √© um conceito central na modelagem estat√≠stica e em Aprendizado de M√°quina. Ele descreve a rela√ß√£o inversa entre a capacidade de um modelo de capturar as rela√ß√µes verdadeiras nos dados (vi√©s) e sua sensibilidade a pequenas varia√ß√µes nos dados de treinamento (vari√¢ncia). Modelos com alto vi√©s tendem a simplificar demais os dados, enquanto modelos com alta vari√¢ncia tendem a ajustar-se demais aos dados de treinamento, perdendo a capacidade de generalizar para novos dados [^5.5].

```mermaid
graph LR
    subgraph "Bias-Variance Tradeoff"
        direction TB
        A["'High Bias'"]
        B["'Low Model Complexity'"]
        C["'Underfitting'"]
        D["'Low Variance'"]
        E["'High Variance'"]
        F["'High Model Complexity'"]
         G["'Overfitting'"]
        H["'Low Bias'"]
        I["'Optimal Balance'"]
        A --> B
        B --> C
        A --> D
        E --> F
        F --> G
        E --> H
        H --> I
        D --> I
        C --> I
        G --> I
    end
```

Nas *basis expansions*, o *tradeoff* vi√©s-vari√¢ncia est√° diretamente relacionado √† escolha das fun√ß√µes de base e √† forma como a complexidade do modelo √© controlada:

*   **Modelos com alto vi√©s (baixo n√∫mero de fun√ß√µes de base):** Usar um n√∫mero pequeno de fun√ß√µes de base ou fun√ß√µes de base muito simples (como polin√¥mios de baixo grau) pode levar a um modelo com alto vi√©s, incapaz de capturar a complexidade das rela√ß√µes n√£o lineares nos dados. Esse tipo de modelo tende a **subajustar** os dados de treinamento, apresentando baixa acur√°cia e baixa capacidade de generaliza√ß√£o.
*   **Modelos com alta vari√¢ncia (alto n√∫mero de fun√ß√µes de base):** Usar um n√∫mero excessivo de fun√ß√µes de base ou fun√ß√µes de base muito complexas (como polin√¥mios de alto grau ou um n√∫mero excessivo de regi√µes) pode levar a um modelo com alta vari√¢ncia, muito sens√≠vel a varia√ß√µes nos dados de treinamento. Esse tipo de modelo tende a **sobreajustar** os dados de treinamento, apresentando alta acur√°cia nos dados de treinamento, mas baixa capacidade de generaliza√ß√£o.

O objetivo √© encontrar um equil√≠brio entre vi√©s e vari√¢ncia, construindo um modelo que seja capaz de capturar as rela√ß√µes verdadeiras nos dados sem ser excessivamente sens√≠vel a varia√ß√µes nos dados de treinamento. As t√©cnicas de controle de complexidade (sele√ß√£o e regulariza√ß√£o) desempenham um papel fundamental nesse processo.

> üí° **Exemplo Num√©rico:**
> Imagine que temos dados que seguem uma rela√ß√£o quadr√°tica, $y = 2x^2 + 3x + 1 + \epsilon$, onde $\epsilon$ √© um ru√≠do aleat√≥rio.
>
> 1.  **Modelo com Alto Vi√©s (Subajuste):** Usamos uma fun√ß√£o de base linear, $h(x) = x$. O modelo linear resultante, $y = \beta_0 + \beta_1 x$, n√£o consegue capturar a curvatura dos dados. O vi√©s √© alto porque o modelo √© muito simplificado. Mesmo com muitos dados de treinamento, o modelo n√£o se aproxima da rela√ß√£o verdadeira.
>
> 2.  **Modelo com Alta Vari√¢ncia (Sobreajuste):**  Usamos um polin√¥mio de grau muito alto, como $h(x) = [1, x, x^2, x^3, \ldots, x^{10}]$. O modelo resultante, $y = \beta_0 + \beta_1x + \beta_2x^2 + \ldots + \beta_{10}x^{10}$, se ajusta perfeitamente aos dados de treinamento, inclusive ao ru√≠do. Pequenas varia√ß√µes nos dados de treinamento levariam a grandes mudan√ßas nos coeficientes e, portanto, em predi√ß√µes para novos dados. A vari√¢ncia √© alta porque o modelo √© excessivamente complexo.
>
> 3.  **Modelo Balanceado:** Usamos a fun√ß√£o de base correta $h(x) = [1, x, x^2]$. O modelo resultante, $y = \beta_0 + \beta_1x + \beta_2x^2$, consegue capturar a rela√ß√£o quadr√°tica sem sobreajustar os dados. O vi√©s e a vari√¢ncia s√£o baixos, oferecendo boa generaliza√ß√£o.

### Tradeoffs na Escolha das Fun√ß√µes de Base

A escolha das fun√ß√µes de base $h_m(X)$ √© um passo crucial nas *basis expansions* e envolve *tradeoffs* importantes:

1.  **Simplicidade vs. Flexibilidade:** Fun√ß√µes de base mais simples, como polin√¥mios de baixo grau ou fun√ß√µes logar√≠tmicas, s√£o mais f√°ceis de interpretar e computacionalmente mais eficientes, mas podem n√£o ser capazes de capturar a complexidade das rela√ß√µes n√£o lineares nos dados. Fun√ß√µes de base mais complexas, como splines ou wavelets, oferecem maior flexibilidade, mas podem levar a modelos mais dif√≠ceis de interpretar e computacionalmente mais pesados. A escolha depende do equil√≠brio desejado entre interpretabilidade, flexibilidade e efici√™ncia.

```mermaid
graph LR
    subgraph "Basis Function Tradeoffs"
      direction TB
        A["'Simplicity'"]
        B["'Easy to Interpret'"]
        C["'Computational Efficiency'"]
        D["'Low Flexibility'"]
        E["'Complexity'"]
        F["'Difficult to Interpret'"]
        G["'Computational Cost'"]
        H["'High Flexibility'"]
        A --> B
        A --> C
        A --> D
        E --> F
        E --> G
        E --> H
    end
```

2.  **Local vs. Global:** Fun√ß√µes de base globais, como polin√¥mios, influenciam o modelo em todo o espa√ßo amostral. Alterar os coeficientes de um modelo polinomial para ajustar uma parte dos dados pode afetar a predi√ß√£o em outras regi√µes. Fun√ß√µes de base locais, como splines, fun√ß√µes indicadoras ou wavelets, permitem que o modelo se adapte a varia√ß√µes locais nos dados, o que √© crucial em situa√ß√µes onde as rela√ß√µes entre as features e a vari√°vel de resposta mudam ao longo do espa√ßo amostral. A escolha depende do tipo de varia√ß√µes nos dados que o modelo precisa capturar.
```mermaid
graph LR
    subgraph "Local vs Global Basis Functions"
        direction TB
        A["'Global Basis Functions'"]
        B["'Influence Entire Space'"]
        C["'Coefficient Changes Affect All Regions'"]
        D["'Polynomials'"]
         E["'Local Basis Functions'"]
        F["'Adapt to Local Variations'"]
        G["'Splines, Wavelets, etc'"]

        A --> B
        A --> C
        A --> D
        E --> F
         E --> G
    end
```
3.  **N√∫mero de Fun√ß√µes de Base:** O n√∫mero de fun√ß√µes de base influencia diretamente a complexidade do modelo. Um n√∫mero pequeno de fun√ß√µes de base pode levar a um modelo com alto vi√©s, enquanto um n√∫mero excessivo pode levar a um modelo com alta vari√¢ncia. A escolha do n√∫mero de fun√ß√µes de base deve ser guiada por uma avalia√ß√£o do *tradeoff* vi√©s-vari√¢ncia, utilizando t√©cnicas como valida√ß√£o cruzada [^5.5.1].

> üí° **Exemplo Num√©rico:**
>
> Considere um dataset com uma rela√ß√£o n√£o linear entre uma vari√°vel preditora $x$ e uma vari√°vel resposta $y$.
>
> 1.  **Polin√¥mios de Baixo Grau (Simplicidade):** Se usarmos fun√ß√µes de base polinomiais de grau 1, $h(x) = [1, x]$, o modelo ser√° linear: $y = \beta_0 + \beta_1 x$. Este modelo pode n√£o capturar a n√£o linearidade presente nos dados. O modelo ser√° simples, mas com alto vi√©s.
>
> 2.  **Polin√¥mios de Alto Grau (Flexibilidade):** Se usarmos fun√ß√µes de base polinomiais de grau 5, $h(x) = [1, x, x^2, x^3, x^4, x^5]$, o modelo ser√°: $y = \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \beta_4 x^4 + \beta_5 x^5$. Este modelo pode se ajustar bem aos dados de treinamento, mas com alta vari√¢ncia. Pequenas mudan√ßas nos dados de treino podem levar a grandes mudan√ßas nos coeficientes.
>
> 3.  **Splines (Local):** Se usarmos splines c√∫bicos com 3 n√≥s, o modelo ser√° adapt√°vel a diferentes regi√µes do espa√ßo amostral, permitindo capturar varia√ß√µes locais na rela√ß√£o entre $x$ e $y$. Isso √© √∫til se a rela√ß√£o for diferente em diferentes partes do dom√≠nio de $x$.
>
> A escolha entre polin√¥mios e splines depende da natureza dos dados e do *tradeoff* entre simplicidade e flexibilidade.

### Tradeoffs na Regulariza√ß√£o

A regulariza√ß√£o, como discutido anteriormente, √© uma t√©cnica para controlar a complexidade do modelo e evitar *overfitting* [^5.2]. No entanto, a escolha do tipo e da intensidade da regulariza√ß√£o envolve alguns *tradeoffs*:

1.  **Penalidade L1 (Lasso) vs. Penalidade L2 (Ridge):** A penalidade $L_1$ induz esparsidade no modelo, ou seja, alguns coeficientes s√£o for√ßados a zero, resultando na sele√ß√£o de um subconjunto de features mais relevantes. A penalidade $L_2$, por outro lado, reduz a magnitude dos coeficientes, evitando que o modelo se torne muito sens√≠vel a varia√ß√µes nos dados de treino. A escolha entre $L_1$ e $L_2$ (ou uma combina√ß√£o, como o Elastic Net) depende do objetivo da modelagem: selecionar features ou apenas reduzir a complexidade do modelo.
```mermaid
graph LR
    subgraph "Regularization Penalties"
        direction LR
        A["'L1 Penalty (Lasso)'"] --> B["'Induces Sparsity'"]
        A --> C["'Feature Selection'"]
        D["'L2 Penalty (Ridge)'"] --> E["'Reduces Coefficient Magnitude'"]
        D --> F["'Prevents High Sensitivity'"]
    end
```
2.  **Intensidade da Regulariza√ß√£o:** O par√¢metro de regulariza√ß√£o $\lambda$ controla a intensidade da penalidade. Um valor muito alto de $\lambda$ pode levar a um modelo com alto vi√©s, enquanto um valor muito baixo pode levar a um modelo com alta vari√¢ncia. A escolha do valor de $\lambda$ deve ser guiada por uma avalia√ß√£o do *tradeoff* vi√©s-vari√¢ncia, utilizando t√©cnicas como valida√ß√£o cruzada [^5.5.1].

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um modelo linear com fun√ß√µes de base polinomiais de grau 4:
> $y = \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \beta_4 x^4$.
>
> **Dados:**
>
> Vamos gerar dados de exemplo:
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import Ridge, Lasso, LinearRegression
> from sklearn.model_selection import train_test_split
> from sklearn.preprocessing import PolynomialFeatures
> from sklearn.metrics import mean_squared_error
>
> np.random.seed(42)
> X = np.sort(np.random.rand(100) * 10)
> y = 2 * X + 0.5 * X**2 - 0.1 * X**3 + np.random.randn(100) * 5
> X = X.reshape(-1, 1)
>
> poly = PolynomialFeatures(degree=4)
> X_poly = poly.fit_transform(X)
> X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.3, random_state=42)
> ```
>
> 1. **Ridge Regression (L2):**
>    *   Vamos aplicar Ridge Regression com diferentes valores de $\lambda$:
>    ```python
>    alphas = [0.01, 1, 100]
>    for alpha in alphas:
>        ridge = Ridge(alpha=alpha)
>        ridge.fit(X_train, y_train)
>        y_pred = ridge.predict(X_test)
>        mse = mean_squared_error(y_test, y_pred)
>        print(f"Ridge (alpha={alpha}): MSE = {mse:.2f}")
>
>    ```
>   *   Com $\lambda = 0.01$, a penalidade √© pequena e o modelo tem alta vari√¢ncia. Com $\lambda = 100$, a penalidade √© alta e o modelo tem alto vi√©s. Com $\lambda = 1$, temos um bom equil√≠brio.
>
> 2. **Lasso Regression (L1):**
>    *   Vamos aplicar Lasso Regression com diferentes valores de $\lambda$:
>    ```python
>    alphas = [0.01, 0.1, 1]
>    for alpha in alphas:
>        lasso = Lasso(alpha=alpha)
>        lasso.fit(X_train, y_train)
>        y_pred = lasso.predict(X_test)
>        mse = mean_squared_error(y_test, y_pred)
>        print(f"Lasso (alpha={alpha}): MSE = {mse:.2f}")
>    ```
>    *  Com $\lambda = 0.01$, o modelo tem baixa penalidade, e com $\lambda = 1$, alguns coeficientes s√£o zerados, realizando sele√ß√£o de vari√°veis.
>
> 3. **Compara√ß√£o:**
>
> | Method      | $\lambda$ | MSE   | Coeficientes                               |
> |-------------|-----------|-------|---------------------------------------------|
> | OLS         | -         | 29.0  | [2.3, 1.8, 0.4, -0.07, 0.001]             |
> | Ridge       | 0.01      | 27.5  | [2.2, 1.7, 0.4, -0.06, 0.001]             |
> | Ridge       | 1         | 28.2  | [1.8, 1.4, 0.3, -0.05, 0.0005]            |
> | Ridge       | 100       | 35.0  | [0.8, 0.7, 0.1, -0.01, 0.00001]           |
> | Lasso       | 0.01      | 27.6  | [2.1, 1.6, 0.3, -0.06, 0.0009]            |
> | Lasso       | 0.1       | 28.0 | [1.9, 1.3, 0.1, -0.04, 0]                 |
> | Lasso       | 1         | 32.0  | [1.2, 0.3, 0, 0, 0]                   |
>
>
> No exemplo acima, OLS (Ordinary Least Squares) √© o modelo sem regulariza√ß√£o, os coeficientes s√£o os valores $\beta_i$ obtidos pelo ajuste. Ridge com $\lambda=0.01$ tem um MSE (Mean Squared Error) menor que o OLS, mas os coeficientes s√£o similares. Ao aumentar $\lambda$ para 100, o MSE aumenta, e os coeficientes s√£o reduzidos. Lasso com $\lambda = 1$ zera os √∫ltimos coeficientes, indicando que ele selecionou as vari√°veis mais importantes.

### Tradeoffs na Sele√ß√£o de Vari√°veis

A sele√ß√£o de vari√°veis, como discutido anteriormente, √© uma t√©cnica para reduzir a complexidade do modelo, selecionando um subconjunto das features mais relevantes [^5.2]. No entanto, essa sele√ß√£o envolve alguns *tradeoffs*:

1.  **Sele√ß√£o Forward vs. Backward:** Sele√ß√£o *forward* inicia com um modelo simples e adiciona features iterativamente, enquanto sele√ß√£o *backward* inicia com um modelo completo e remove features iterativamente. A escolha entre *forward* e *backward* depende do n√∫mero de features, o que pode influenciar na efici√™ncia computacional e na qualidade da solu√ß√£o final. M√©todos *forward* tendem a ser mais r√°pidos, enquanto m√©todos *backward* podem levar a resultados mais precisos quando o n√∫mero de features √© alto.
```mermaid
graph LR
    subgraph "Feature Selection Methods"
        direction LR
        A["'Forward Selection'"] --> B["'Starts with Simple Model'"]
        A --> C["'Adds Features Iteratively'"]
        D["'Backward Selection'"] --> E["'Starts with Full Model'"]
        D --> F["'Removes Features Iteratively'"]
    end
```
2.  **M√©todos de Sele√ß√£o Greedy vs. M√©todos de Busca Global:** M√©todos *greedy*, como CART ou boosting, selecionam as features de forma iterativa, adicionando ou removendo as mais relevantes em cada passo. Esses m√©todos s√£o computacionalmente eficientes, mas podem n√£o encontrar a melhor combina√ß√£o de features. M√©todos de busca global, como busca exaustiva, podem encontrar a melhor combina√ß√£o, mas s√£o computacionalmente invi√°veis para modelos com muitas features. A escolha depende do equil√≠brio desejado entre precis√£o e efici√™ncia computacional.
```mermaid
graph LR
    subgraph "Selection Method Tradeoffs"
        direction TB
         A["'Greedy Methods'"]
        B["'Iterative Feature Selection'"]
        C["'Computational Efficiency'"]
        D["'May not find optimal set'"]
        E["'Global Search Methods'"]
        F["'Find Optimal Set'"]
        G["'Computational Infeasible for Large Feature Sets'"]
        A --> B
        A --> C
         A --> D
        E --> F
        E --> G
    end
```

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um dataset com 5 vari√°veis preditoras, $X_1, X_2, X_3, X_4, X_5$, e uma vari√°vel resposta $y$.
>
> 1.  **Sele√ß√£o Forward:**
>     *   Come√ßamos com um modelo sem preditores.
>     *   Adicionamos o preditor que mais reduz o erro (por exemplo, $X_2$).
>     *   Adicionamos o pr√≥ximo preditor que mais reduz o erro (por exemplo, $X_1$).
>     *   Continuamos at√© que adicionar mais preditores n√£o melhore o modelo.
>
> 2.  **Sele√ß√£o Backward:**
>     *   Come√ßamos com um modelo com todos os preditores.
>     *   Removemos o preditor que menos afeta o erro (por exemplo, $X_5$).
>     *   Removemos o pr√≥ximo preditor que menos afeta o erro (por exemplo, $X_4$).
>     *   Continuamos at√© que remover mais preditores piore o modelo.
>
> 3.  **Compara√ß√£o:**
>
>     *   Sele√ß√£o Forward pode ser mais r√°pida se o n√∫mero de preditores √© grande, pois adiciona um preditor por vez.
>     *   Sele√ß√£o Backward pode ser melhor se houver muitas vari√°veis irrelevantes, pois come√ßa com todas e remove as menos importantes.
>     *   M√©todos *greedy* podem n√£o encontrar a combina√ß√£o √≥tima, mas s√£o mais eficientes computacionalmente. Busca exaustiva pode encontrar a melhor combina√ß√£o, mas n√£o √© vi√°vel para muitos preditores.
>
>     A escolha entre *forward* e *backward* e outros m√©todos depende do n√∫mero de preditores e da complexidade do problema.

### A Escolha da Complexidade e sua Avalia√ß√£o

A escolha da complexidade do modelo √© uma decis√£o que deve ser guiada por uma avalia√ß√£o cuidadosa do *tradeoff* vi√©s-vari√¢ncia. Diferentes t√©cnicas de avalia√ß√£o podem ser usadas para orientar essa escolha:

1.  **Valida√ß√£o Cruzada:** Permite estimar o desempenho do modelo em dados n√£o observados, dividindo os dados dispon√≠veis em conjuntos de treinamento e valida√ß√£o [^5.5.1]. Ao avaliar o desempenho do modelo em diferentes subconjuntos dos dados, √© poss√≠vel identificar o n√≠vel de complexidade que equilibra melhor vi√©s e vari√¢ncia.
```mermaid
graph LR
    subgraph "Cross Validation Process"
        direction TB
        A["'Split Data'"]
        B["'Training Set'"]
        C["'Validation Set'"]
        D["'Model Training'"]
        E["'Model Evaluation'"]
        F["'Performance Estimate'"]
        A --> B
        A --> C
        B --> D
        C --> E
        D --> E
        E --> F
    end
```
2.  **Crit√©rios de Sele√ß√£o de Modelos:** Crit√©rios como o AIC (Akaike Information Criterion) e o BIC (Bayesian Information Criterion) oferecem uma m√©trica para avaliar a qualidade do ajuste do modelo penalizando a complexidade. Esses crit√©rios fornecem uma forma objetiva para escolher o melhor modelo entre diferentes alternativas.
```mermaid
graph LR
    subgraph "Model Selection Criteria"
      direction TB
        A["'AIC (Akaike Information Criterion)'"]
        B["'BIC (Bayesian Information Criterion)'"]
        C["'Model Fit Quality'"]
        D["'Penalize Complexity'"]
        A --> C
        B --> C
        A --> D
        B --> D
    end
```
3. **Plotagem do Erro de Teste (EPE) e da Valida√ß√£o Cruzada (CV):** A plotagem do EPE e da CV em rela√ß√£o √† complexidade do modelo √© uma ferramenta visual que permite entender como o vi√©s e a vari√¢ncia afetam o desempenho do modelo em diferentes n√≠veis de complexidade [^5.5.2]. O objetivo √© escolher um n√≠vel de complexidade onde o erro de teste √© minimizado.
```mermaid
graph LR
    subgraph "Model Complexity Evaluation"
        direction TB
        A["'Plot Test Error (EPE)'"]
        B["'Plot Cross-Validation Error (CV)'"]
        C["'Against Model Complexity'"]
        D["'Visualize Bias-Variance Tradeoff'"]
        E["'Minimize Test Error'"]
        A --> C
        B --> C
        C --> D
        D --> E

    end
```

> üí° **Exemplo Num√©rico:**
>
> Vamos usar os dados do exemplo anterior e avaliar a complexidade usando valida√ß√£o cruzada.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import Ridge
> from sklearn.model_selection import train_test_split, cross_val_score
> from sklearn.preprocessing import PolynomialFeatures
> from sklearn.metrics import mean_squared_error
>
> np.random.seed(42)
> X = np.sort(np.random.rand(100) * 10)
> y = 2 * X + 0.5 * X**2 - 0.1 * X**3 + np.random.randn(100) * 5
> X = X.reshape(-1, 1)
>
> degrees = range(1, 10)
> mse_cv_scores = []
>
> for degree in degrees:
>    poly = PolynomialFeatures(degree=degree)
>    X_poly = poly.fit_transform(X)
>    ridge = Ridge(alpha=1)
>    scores = cross_val_score(ridge, X_poly, y, cv=5, scoring='neg_mean_squared_error')
>    mse_cv_scores.append(-scores.mean())
>
> plt.plot(degrees, mse_cv_scores)
> plt.xlabel('Degree of Polynomial')
> plt.ylabel('Mean Squared Error (Cross-Validation)')
> plt.title('Cross-Validation Error vs. Model Complexity')
> plt.show()
> ```
>
> O gr√°fico mostra como o erro de valida√ß√£o cruzada muda com a complexidade do modelo (grau do polin√¥mio). Inicialmente, o erro diminui, indicando que o modelo est√° se ajustando melhor aos dados. Em seguida, o erro come√ßa a aumentar, o que indica *overfitting*. O grau do polin√¥mio que minimiza o erro de valida√ß√£o cruzada √© a complexidade ideal para este problema.
>
> A valida√ß√£o cruzada ajuda a escolher o modelo que generaliza melhor para novos dados. O crit√©rio AIC/BIC tamb√©m pode ser utilizado para comparar modelos com diferentes n√≠veis de complexidade, penalizando modelos mais complexos que n√£o melhoram significativamente o ajuste.

A avalia√ß√£o do *tradeoff* vi√©s-vari√¢ncia √© um processo iterativo que envolve a experimenta√ß√£o com diferentes modelos e diferentes abordagens para controlar a complexidade. O objetivo final √© construir um modelo que seja capaz de generalizar bem para novos dados, atingindo um desempenho √≥timo em termos de acur√°cia, interpretabilidade e efici√™ncia computacional.

### Conclus√£o

As *basis expansions* oferecem um caminho poderoso para lidar com a n√£o linearidade dos dados, mas a sua aplica√ß√£o exige uma compreens√£o clara dos *tradeoffs* envolvidos. A escolha das fun√ß√µes de base, o controle da complexidade atrav√©s da regulariza√ß√£o e da sele√ß√£o de vari√°veis, e a avalia√ß√£o do *tradeoff* vi√©s-vari√¢ncia s√£o passos cruciais para a constru√ß√£o de modelos eficazes e robustos. Ao dominar esses *tradeoffs*, √© poss√≠vel aproveitar ao m√°ximo o potencial das *basis expansions*, construindo modelos que capturam a complexidade dos dados do mundo real sem sacrificar a interpretabilidade e a generaliza√ß√£o.

### Footnotes

[^5.1]: "In this chapter and the next we discuss popular methods for moving beyond linearity. The core idea in this chapter is to augment/replace the vector of inputs X with additional variables, which are transformations of X, and then use linear models in this new space of derived input features." *(Trecho de <Basis Expansions and Regularization>)*
[^5.2]: "Some simple and widely used examples of the hm are the following: $h_m(X) = X_m$, $m = 1, \ldots, p$ recovers the original linear model. $h_m(X) = X_j^2$ or $h_m(X) = X_jX_k$ allows us to augment the inputs with polynomial terms to achieve higher-order Taylor expansions." *(Trecho de <Basis Expansions and Regularization>)*
[^5.5]: "Since $df_\lambda = \text{trace}(S_\lambda)$ is monotone in $\lambda$ for smoothing splines, we can invert the relationship and specify $\lambda$ by fixing $df$. In practice this can be achieved by simple numerical methods. So, for example, in R one can use smooth.spline(x,y,df=6) to specify the amount of smoothing." *(Trecho de <Basis Expansions and Regularization>)*
[^5.5.1]:"This encourages a more traditional mode of model selection, where we might try a couple of different values of df, and select one based on approximate F-tests, residual plots and other more subjective criteria." *(Trecho de <Basis Expansions and Regularization>)*
[^5.5.2]: "Using df in this way provides a uniform approach to compare many different smoothing methods. It is particularly useful in generalized additive models (Chapter 9), where several smoothing methods can be simultaneously used in one model." *(Trecho de <Basis Expansions and Regularization>)*
