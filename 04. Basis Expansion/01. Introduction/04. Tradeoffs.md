## Tradeoffs in Basis Expansions: Navigating Model Complexity

```mermaid
graph LR
    subgraph "Basis Expansions Tradeoffs"
        direction TB
        A["'Model Complexity'"]
        B["'Choice of Basis Functions'"]
        C["'Number of Basis Functions'"]
        D["'Regularization Methods'"]
        E["'Selection Methods'"]
        F["'Bias-Variance Tradeoff'"]
        A --> F
        B --> F
        C --> F
        D --> F
        E --> F
    end
```

### IntroduÃ§Ã£o

A tÃ©cnica de *basis expansions*, como explorado anteriormente, oferece a capacidade de estender o poder expressivo de modelos lineares, permitindo que eles capturem relaÃ§Ãµes nÃ£o lineares nos dados [^5.1]. No entanto, essa maior flexibilidade nÃ£o vem sem custos. A escolha das funÃ§Ãµes de base, o nÃºmero de funÃ§Ãµes de base utilizadas e a forma como a complexidade do modelo Ã© controlada envolvem *tradeoffs* que precisam ser considerados para obter resultados eficazes. Este capÃ­tulo explora esses *tradeoffs*, oferecendo uma visÃ£o aprofundada de como as decisÃµes de modelagem impactam o desempenho e as caracterÃ­sticas do modelo. Em particular, serÃ¡ abordado o compromisso entre **viÃ©s** e **variÃ¢ncia**, que Ã© central para a construÃ§Ã£o de modelos robustos e generalizÃ¡veis [^5.5].

### O Tradeoff ViÃ©s-VariÃ¢ncia

O *tradeoff* viÃ©s-variÃ¢ncia Ã© um conceito central na modelagem estatÃ­stica e em Aprendizado de MÃ¡quina. Ele descreve a relaÃ§Ã£o inversa entre a capacidade de um modelo de capturar as relaÃ§Ãµes verdadeiras nos dados (viÃ©s) e sua sensibilidade a pequenas variaÃ§Ãµes nos dados de treinamento (variÃ¢ncia). Modelos com alto viÃ©s tendem a simplificar demais os dados, enquanto modelos com alta variÃ¢ncia tendem a ajustar-se demais aos dados de treinamento, perdendo a capacidade de generalizar para novos dados [^5.5].

```mermaid
graph LR
    subgraph "Bias-Variance Tradeoff"
        direction TB
        A["'High Bias'"]
        B["'Low Model Complexity'"]
        C["'Underfitting'"]
        D["'Low Variance'"]
        E["'High Variance'"]
        F["'High Model Complexity'"]
         G["'Overfitting'"]
        H["'Low Bias'"]
        I["'Optimal Balance'"]
        A --> B
        B --> C
        A --> D
        E --> F
        F --> G
        E --> H
        H --> I
        D --> I
        C --> I
        G --> I
    end
```

Nas *basis expansions*, o *tradeoff* viÃ©s-variÃ¢ncia estÃ¡ diretamente relacionado Ã  escolha das funÃ§Ãµes de base e Ã  forma como a complexidade do modelo Ã© controlada:

*   **Modelos com alto viÃ©s (baixo nÃºmero de funÃ§Ãµes de base):** Usar um nÃºmero pequeno de funÃ§Ãµes de base ou funÃ§Ãµes de base muito simples (como polinÃ´mios de baixo grau) pode levar a um modelo com alto viÃ©s, incapaz de capturar a complexidade das relaÃ§Ãµes nÃ£o lineares nos dados. Esse tipo de modelo tende a **subajustar** os dados de treinamento, apresentando baixa acurÃ¡cia e baixa capacidade de generalizaÃ§Ã£o.
*   **Modelos com alta variÃ¢ncia (alto nÃºmero de funÃ§Ãµes de base):** Usar um nÃºmero excessivo de funÃ§Ãµes de base ou funÃ§Ãµes de base muito complexas (como polinÃ´mios de alto grau ou um nÃºmero excessivo de regiÃµes) pode levar a um modelo com alta variÃ¢ncia, muito sensÃ­vel a variaÃ§Ãµes nos dados de treinamento. Esse tipo de modelo tende a **sobreajustar** os dados de treinamento, apresentando alta acurÃ¡cia nos dados de treinamento, mas baixa capacidade de generalizaÃ§Ã£o.

O objetivo Ã© encontrar um equilÃ­brio entre viÃ©s e variÃ¢ncia, construindo um modelo que seja capaz de capturar as relaÃ§Ãµes verdadeiras nos dados sem ser excessivamente sensÃ­vel a variaÃ§Ãµes nos dados de treinamento. As tÃ©cnicas de controle de complexidade (seleÃ§Ã£o e regularizaÃ§Ã£o) desempenham um papel fundamental nesse processo.

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Imagine que temos dados que seguem uma relaÃ§Ã£o quadrÃ¡tica, $y = 2x^2 + 3x + 1 + \epsilon$, onde $\epsilon$ Ã© um ruÃ­do aleatÃ³rio.
>
> 1.  **Modelo com Alto ViÃ©s (Subajuste):** Usamos uma funÃ§Ã£o de base linear, $h(x) = x$. O modelo linear resultante, $y = \beta_0 + \beta_1 x$, nÃ£o consegue capturar a curvatura dos dados. O viÃ©s Ã© alto porque o modelo Ã© muito simplificado. Mesmo com muitos dados de treinamento, o modelo nÃ£o se aproxima da relaÃ§Ã£o verdadeira.
>
> 2.  **Modelo com Alta VariÃ¢ncia (Sobreajuste):**  Usamos um polinÃ´mio de grau muito alto, como $h(x) = [1, x, x^2, x^3, \ldots, x^{10}]$. O modelo resultante, $y = \beta_0 + \beta_1x + \beta_2x^2 + \ldots + \beta_{10}x^{10}$, se ajusta perfeitamente aos dados de treinamento, inclusive ao ruÃ­do. Pequenas variaÃ§Ãµes nos dados de treinamento levariam a grandes mudanÃ§as nos coeficientes e, portanto, em prediÃ§Ãµes para novos dados. A variÃ¢ncia Ã© alta porque o modelo Ã© excessivamente complexo.
>
> 3.  **Modelo Balanceado:** Usamos a funÃ§Ã£o de base correta $h(x) = [1, x, x^2]$. O modelo resultante, $y = \beta_0 + \beta_1x + \beta_2x^2$, consegue capturar a relaÃ§Ã£o quadrÃ¡tica sem sobreajustar os dados. O viÃ©s e a variÃ¢ncia sÃ£o baixos, oferecendo boa generalizaÃ§Ã£o.

### Tradeoffs na Escolha das FunÃ§Ãµes de Base

A escolha das funÃ§Ãµes de base $h_m(X)$ Ã© um passo crucial nas *basis expansions* e envolve *tradeoffs* importantes:

1.  **Simplicidade vs. Flexibilidade:** FunÃ§Ãµes de base mais simples, como polinÃ´mios de baixo grau ou funÃ§Ãµes logarÃ­tmicas, sÃ£o mais fÃ¡ceis de interpretar e computacionalmente mais eficientes, mas podem nÃ£o ser capazes de capturar a complexidade das relaÃ§Ãµes nÃ£o lineares nos dados. FunÃ§Ãµes de base mais complexas, como splines ou wavelets, oferecem maior flexibilidade, mas podem levar a modelos mais difÃ­ceis de interpretar e computacionalmente mais pesados. A escolha depende do equilÃ­brio desejado entre interpretabilidade, flexibilidade e eficiÃªncia.

```mermaid
graph LR
    subgraph "Basis Function Tradeoffs"
      direction TB
        A["'Simplicity'"]
        B["'Easy to Interpret'"]
        C["'Computational Efficiency'"]
        D["'Low Flexibility'"]
        E["'Complexity'"]
        F["'Difficult to Interpret'"]
        G["'Computational Cost'"]
        H["'High Flexibility'"]
        A --> B
        A --> C
        A --> D
        E --> F
        E --> G
        E --> H
    end
```

2.  **Local vs. Global:** FunÃ§Ãµes de base globais, como polinÃ´mios, influenciam o modelo em todo o espaÃ§o amostral. Alterar os coeficientes de um modelo polinomial para ajustar uma parte dos dados pode afetar a prediÃ§Ã£o em outras regiÃµes. FunÃ§Ãµes de base locais, como splines, funÃ§Ãµes indicadoras ou wavelets, permitem que o modelo se adapte a variaÃ§Ãµes locais nos dados, o que Ã© crucial em situaÃ§Ãµes onde as relaÃ§Ãµes entre as features e a variÃ¡vel de resposta mudam ao longo do espaÃ§o amostral. A escolha depende do tipo de variaÃ§Ãµes nos dados que o modelo precisa capturar.
```mermaid
graph LR
    subgraph "Local vs Global Basis Functions"
        direction TB
        A["'Global Basis Functions'"]
        B["'Influence Entire Space'"]
        C["'Coefficient Changes Affect All Regions'"]
        D["'Polynomials'"]
         E["'Local Basis Functions'"]
        F["'Adapt to Local Variations'"]
        G["'Splines, Wavelets, etc'"]

        A --> B
        A --> C
        A --> D
        E --> F
         E --> G
    end
```
3.  **NÃºmero de FunÃ§Ãµes de Base:** O nÃºmero de funÃ§Ãµes de base influencia diretamente a complexidade do modelo. Um nÃºmero pequeno de funÃ§Ãµes de base pode levar a um modelo com alto viÃ©s, enquanto um nÃºmero excessivo pode levar a um modelo com alta variÃ¢ncia. A escolha do nÃºmero de funÃ§Ãµes de base deve ser guiada por uma avaliaÃ§Ã£o do *tradeoff* viÃ©s-variÃ¢ncia, utilizando tÃ©cnicas como validaÃ§Ã£o cruzada [^5.5.1].

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Considere um dataset com uma relaÃ§Ã£o nÃ£o linear entre uma variÃ¡vel preditora $x$ e uma variÃ¡vel resposta $y$.
>
> 1.  **PolinÃ´mios de Baixo Grau (Simplicidade):** Se usarmos funÃ§Ãµes de base polinomiais de grau 1, $h(x) = [1, x]$, o modelo serÃ¡ linear: $y = \beta_0 + \beta_1 x$. Este modelo pode nÃ£o capturar a nÃ£o linearidade presente nos dados. O modelo serÃ¡ simples, mas com alto viÃ©s.
>
> 2.  **PolinÃ´mios de Alto Grau (Flexibilidade):** Se usarmos funÃ§Ãµes de base polinomiais de grau 5, $h(x) = [1, x, x^2, x^3, x^4, x^5]$, o modelo serÃ¡: $y = \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \beta_4 x^4 + \beta_5 x^5$. Este modelo pode se ajustar bem aos dados de treinamento, mas com alta variÃ¢ncia. Pequenas mudanÃ§as nos dados de treino podem levar a grandes mudanÃ§as nos coeficientes.
>
> 3.  **Splines (Local):** Se usarmos splines cÃºbicos com 3 nÃ³s, o modelo serÃ¡ adaptÃ¡vel a diferentes regiÃµes do espaÃ§o amostral, permitindo capturar variaÃ§Ãµes locais na relaÃ§Ã£o entre $x$ e $y$. Isso Ã© Ãºtil se a relaÃ§Ã£o for diferente em diferentes partes do domÃ­nio de $x$.
>
> A escolha entre polinÃ´mios e splines depende da natureza dos dados e do *tradeoff* entre simplicidade e flexibilidade.

### Tradeoffs na RegularizaÃ§Ã£o

A regularizaÃ§Ã£o, como discutido anteriormente, Ã© uma tÃ©cnica para controlar a complexidade do modelo e evitar *overfitting* [^5.2]. No entanto, a escolha do tipo e da intensidade da regularizaÃ§Ã£o envolve alguns *tradeoffs*:

1.  **Penalidade L1 (Lasso) vs. Penalidade L2 (Ridge):** A penalidade $L_1$ induz esparsidade no modelo, ou seja, alguns coeficientes sÃ£o forÃ§ados a zero, resultando na seleÃ§Ã£o de um subconjunto de features mais relevantes. A penalidade $L_2$, por outro lado, reduz a magnitude dos coeficientes, evitando que o modelo se torne muito sensÃ­vel a variaÃ§Ãµes nos dados de treino. A escolha entre $L_1$ e $L_2$ (ou uma combinaÃ§Ã£o, como o Elastic Net) depende do objetivo da modelagem: selecionar features ou apenas reduzir a complexidade do modelo.
```mermaid
graph LR
    subgraph "Regularization Penalties"
        direction LR
        A["'L1 Penalty (Lasso)'"] --> B["'Induces Sparsity'"]
        A --> C["'Feature Selection'"]
        D["'L2 Penalty (Ridge)'"] --> E["'Reduces Coefficient Magnitude'"]
        D --> F["'Prevents High Sensitivity'"]
    end
```
2.  **Intensidade da RegularizaÃ§Ã£o:** O parÃ¢metro de regularizaÃ§Ã£o $\lambda$ controla a intensidade da penalidade. Um valor muito alto de $\lambda$ pode levar a um modelo com alto viÃ©s, enquanto um valor muito baixo pode levar a um modelo com alta variÃ¢ncia. A escolha do valor de $\lambda$ deve ser guiada por uma avaliaÃ§Ã£o do *tradeoff* viÃ©s-variÃ¢ncia, utilizando tÃ©cnicas como validaÃ§Ã£o cruzada [^5.5.1].

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que temos um modelo linear com funÃ§Ãµes de base polinomiais de grau 4:
> $y = \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \beta_4 x^4$.
>
> **Dados:**
>
> Vamos gerar dados de exemplo:
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import Ridge, Lasso, LinearRegression
> from sklearn.model_selection import train_test_split
> from sklearn.preprocessing import PolynomialFeatures
> from sklearn.metrics import mean_squared_error
>
> np.random.seed(42)
> X = np.sort(np.random.rand(100) * 10)
> y = 2 * X + 0.5 * X**2 - 0.1 * X**3 + np.random.randn(100) * 5
> X = X.reshape(-1, 1)
>
> poly = PolynomialFeatures(degree=4)
> X_poly = poly.fit_transform(X)
> X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.3, random_state=42)
> ```
>
> 1. **Ridge Regression (L2):**
>    *   Vamos aplicar Ridge Regression com diferentes valores de $\lambda$:
>    ```python
>    alphas = [0.01, 1, 100]
>    for alpha in alphas:
>        ridge = Ridge(alpha=alpha)
>        ridge.fit(X_train, y_train)
>        y_pred = ridge.predict(X_test)
>        mse = mean_squared_error(y_test, y_pred)
>        print(f"Ridge (alpha={alpha}): MSE = {mse:.2f}")
>
>    ```
>   *   Com $\lambda = 0.01$, a penalidade Ã© pequena e o modelo tem alta variÃ¢ncia. Com $\lambda = 100$, a penalidade Ã© alta e o modelo tem alto viÃ©s. Com $\lambda = 1$, temos um bom equilÃ­brio.
>
> 2. **Lasso Regression (L1):**
>    *   Vamos aplicar Lasso Regression com diferentes valores de $\lambda$:
>    ```python
>    alphas = [0.01, 0.1, 1]
>    for alpha in alphas:
>        lasso = Lasso(alpha=alpha)
>        lasso.fit(X_train, y_train)
>        y_pred = lasso.predict(X_test)
>        mse = mean_squared_error(y_test, y_pred)
>        print(f"Lasso (alpha={alpha}): MSE = {mse:.2f}")
>    ```
>    *  Com $\lambda = 0.01$, o modelo tem baixa penalidade, e com $\lambda = 1$, alguns coeficientes sÃ£o zerados, realizando seleÃ§Ã£o de variÃ¡veis.
>
> 3. **ComparaÃ§Ã£o:**
>
> | Method      | $\lambda$ | MSE   | Coeficientes                               |
> |-------------|-----------|-------|---------------------------------------------|
> | OLS         | -         | 29.0  | [2.3, 1.8, 0.4, -0.07, 0.001]             |
> | Ridge       | 0.01      | 27.5  | [2.2, 1.7, 0.4, -0.06, 0.001]             |
> | Ridge       | 1         | 28.2  | [1.8, 1.4, 0.3, -0.05, 0.0005]            |
> | Ridge       | 100       | 35.0  | [0.8, 0.7, 0.1, -0.01, 0.00001]           |
> | Lasso       | 0.01      | 27.6  | [2.1, 1.6, 0.3, -0.06, 0.0009]            |
> | Lasso       | 0.1       | 28.0 | [1.9, 1.3, 0.1, -0.04, 0]                 |
> | Lasso       | 1         | 32.0  | [1.2, 0.3, 0, 0, 0]                   |
>
>
> No exemplo acima, OLS (Ordinary Least Squares) Ã© o modelo sem regularizaÃ§Ã£o, os coeficientes sÃ£o os valores $\beta_i$ obtidos pelo ajuste. Ridge com $\lambda=0.01$ tem um MSE (Mean Squared Error) menor que o OLS, mas os coeficientes sÃ£o similares. Ao aumentar $\lambda$ para 100, o MSE aumenta, e os coeficientes sÃ£o reduzidos. Lasso com $\lambda = 1$ zera os Ãºltimos coeficientes, indicando que ele selecionou as variÃ¡veis mais importantes.

### Tradeoffs na SeleÃ§Ã£o de VariÃ¡veis

A seleÃ§Ã£o de variÃ¡veis, como discutido anteriormente, Ã© uma tÃ©cnica para reduzir a complexidade do modelo, selecionando um subconjunto das features mais relevantes [^5.2]. No entanto, essa seleÃ§Ã£o envolve alguns *tradeoffs*:

1.  **SeleÃ§Ã£o Forward vs. Backward:** SeleÃ§Ã£o *forward* inicia com um modelo simples e adiciona features iterativamente, enquanto seleÃ§Ã£o *backward* inicia com um modelo completo e remove features iterativamente. A escolha entre *forward* e *backward* depende do nÃºmero de features, o que pode influenciar na eficiÃªncia computacional e na qualidade da soluÃ§Ã£o final. MÃ©todos *forward* tendem a ser mais rÃ¡pidos, enquanto mÃ©todos *backward* podem levar a resultados mais precisos quando o nÃºmero de features Ã© alto.
```mermaid
graph LR
    subgraph "Feature Selection Methods"
        direction LR
        A["'Forward Selection'"] --> B["'Starts with Simple Model'"]
        A --> C["'Adds Features Iteratively'"]
        D["'Backward Selection'"] --> E["'Starts with Full Model'"]
        D --> F["'Removes Features Iteratively'"]
    end
```
2.  **MÃ©todos de SeleÃ§Ã£o Greedy vs. MÃ©todos de Busca Global:** MÃ©todos *greedy*, como CART ou boosting, selecionam as features de forma iterativa, adicionando ou removendo as mais relevantes em cada passo. Esses mÃ©todos sÃ£o computacionalmente eficientes, mas podem nÃ£o encontrar a melhor combinaÃ§Ã£o de features. MÃ©todos de busca global, como busca exaustiva, podem encontrar a melhor combinaÃ§Ã£o, mas sÃ£o computacionalmente inviÃ¡veis para modelos com muitas features. A escolha depende do equilÃ­brio desejado entre precisÃ£o e eficiÃªncia computacional.
```mermaid
graph LR
    subgraph "Selection Method Tradeoffs"
        direction TB
         A["'Greedy Methods'"]
        B["'Iterative Feature Selection'"]
        C["'Computational Efficiency'"]
        D["'May not find optimal set'"]
        E["'Global Search Methods'"]
        F["'Find Optimal Set'"]
        G["'Computational Infeasible for Large Feature Sets'"]
        A --> B
        A --> C
         A --> D
        E --> F
        E --> G
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que temos um dataset com 5 variÃ¡veis preditoras, $X_1, X_2, X_3, X_4, X_5$, e uma variÃ¡vel resposta $y$.
>
> 1.  **SeleÃ§Ã£o Forward:**
>     *   ComeÃ§amos com um modelo sem preditores.
>     *   Adicionamos o preditor que mais reduz o erro (por exemplo, $X_2$).
>     *   Adicionamos o prÃ³ximo preditor que mais reduz o erro (por exemplo, $X_1$).
>     *   Continuamos atÃ© que adicionar mais preditores nÃ£o melhore o modelo.
>
> 2.  **SeleÃ§Ã£o Backward:**
>     *   ComeÃ§amos com um modelo com todos os preditores.
>     *   Removemos o preditor que menos afeta o erro (por exemplo, $X_5$).
>     *   Removemos o prÃ³ximo preditor que menos afeta o erro (por exemplo, $X_4$).
>     *   Continuamos atÃ© que remover mais preditores piore o modelo.
>
> 3.  **ComparaÃ§Ã£o:**
>
>     *   SeleÃ§Ã£o Forward pode ser mais rÃ¡pida se o nÃºmero de preditores Ã© grande, pois adiciona um preditor por vez.
>     *   SeleÃ§Ã£o Backward pode ser melhor se houver muitas variÃ¡veis irrelevantes, pois comeÃ§a com todas e remove as menos importantes.
>     *   MÃ©todos *greedy* podem nÃ£o encontrar a combinaÃ§Ã£o Ã³tima, mas sÃ£o mais eficientes computacionalmente. Busca exaustiva pode encontrar a melhor combinaÃ§Ã£o, mas nÃ£o Ã© viÃ¡vel para muitos preditores.
>
>     A escolha entre *forward* e *backward* e outros mÃ©todos depende do nÃºmero de preditores e da complexidade do problema.

### A Escolha da Complexidade e sua AvaliaÃ§Ã£o

A escolha da complexidade do modelo Ã© uma decisÃ£o que deve ser guiada por uma avaliaÃ§Ã£o cuidadosa do *tradeoff* viÃ©s-variÃ¢ncia. Diferentes tÃ©cnicas de avaliaÃ§Ã£o podem ser usadas para orientar essa escolha:

1.  **ValidaÃ§Ã£o Cruzada:** Permite estimar o desempenho do modelo em dados nÃ£o observados, dividindo os dados disponÃ­veis em conjuntos de treinamento e validaÃ§Ã£o [^5.5.1]. Ao avaliar o desempenho do modelo em diferentes subconjuntos dos dados, Ã© possÃ­vel identificar o nÃ­vel de complexidade que equilibra melhor viÃ©s e variÃ¢ncia.
```mermaid
graph LR
    subgraph "Cross Validation Process"
        direction TB
        A["'Split Data'"]
        B["'Training Set'"]
        C["'Validation Set'"]
        D["'Model Training'"]
        E["'Model Evaluation'"]
        F["'Performance Estimate'"]
        A --> B
        A --> C
        B --> D
        C --> E
        D --> E
        E --> F
    end
```
2.  **CritÃ©rios de SeleÃ§Ã£o de Modelos:** CritÃ©rios como o AIC (Akaike Information Criterion) e o BIC (Bayesian Information Criterion) oferecem uma mÃ©trica para avaliar a qualidade do ajuste do modelo penalizando a complexidade. Esses critÃ©rios fornecem uma forma objetiva para escolher o melhor modelo entre diferentes alternativas.
```mermaid
graph LR
    subgraph "Model Selection Criteria"
      direction TB
        A["'AIC (Akaike Information Criterion)'"]
        B["'BIC (Bayesian Information Criterion)'"]
        C["'Model Fit Quality'"]
        D["'Penalize Complexity'"]
        A --> C
        B --> C
        A --> D
        B --> D
    end
```
3. **Plotagem do Erro de Teste (EPE) e da ValidaÃ§Ã£o Cruzada (CV):** A plotagem do EPE e da CV em relaÃ§Ã£o Ã  complexidade do modelo Ã© uma ferramenta visual que permite entender como o viÃ©s e a variÃ¢ncia afetam o desempenho do modelo em diferentes nÃ­veis de complexidade [^5.5.2]. O objetivo Ã© escolher um nÃ­vel de complexidade onde o erro de teste Ã© minimizado.
```mermaid
graph LR
    subgraph "Model Complexity Evaluation"
        direction TB
        A["'Plot Test Error (EPE)'"]
        B["'Plot Cross-Validation Error (CV)'"]
        C["'Against Model Complexity'"]
        D["'Visualize Bias-Variance Tradeoff'"]
        E["'Minimize Test Error'"]
        A --> C
        B --> C
        C --> D
        D --> E

    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Vamos usar os dados do exemplo anterior e avaliar a complexidade usando validaÃ§Ã£o cruzada.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import Ridge
> from sklearn.model_selection import train_test_split, cross_val_score
> from sklearn.preprocessing import PolynomialFeatures
> from sklearn.metrics import mean_squared_error
>
> np.random.seed(42)
> X = np.sort(np.random.rand(100) * 10)
> y = 2 * X + 0.5 * X**2 - 0.1 * X**3 + np.random.randn(100) * 5
> X = X.reshape(-1, 1)
>
> degrees = range(1, 10)
> mse_cv_scores = []
>
> for degree in degrees:
>    poly = PolynomialFeatures(degree=degree)
>    X_poly = poly.fit_transform(X)
>    ridge = Ridge(alpha=1)
>    scores = cross_val_score(ridge, X_poly, y, cv=5, scoring='neg_mean_squared_error')
>    mse_cv_scores.append(-scores.mean())
>
> plt.plot(degrees, mse_cv_scores)
> plt.xlabel('Degree of Polynomial')
> plt.ylabel('Mean Squared Error (Cross-Validation)')
> plt.title('Cross-Validation Error vs. Model Complexity')
> plt.show()
> ```
>
> O grÃ¡fico mostra como o erro de validaÃ§Ã£o cruzada muda com a complexidade do modelo (grau do polinÃ´mio). Inicialmente, o erro diminui, indicando que o modelo estÃ¡ se ajustando melhor aos dados. Em seguida, o erro comeÃ§a a aumentar, o que indica *overfitting*. O grau do polinÃ´mio que minimiza o erro de validaÃ§Ã£o cruzada Ã© a complexidade ideal para este problema.
>
> A validaÃ§Ã£o cruzada ajuda a escolher o modelo que generaliza melhor para novos dados. O critÃ©rio AIC/BIC tambÃ©m pode ser utilizado para comparar modelos com diferentes nÃ­veis de complexidade, penalizando modelos mais complexos que nÃ£o melhoram significativamente o ajuste.

A avaliaÃ§Ã£o do *tradeoff* viÃ©s-variÃ¢ncia Ã© um processo iterativo que envolve a experimentaÃ§Ã£o com diferentes modelos e diferentes abordagens para controlar a complexidade. O objetivo final Ã© construir um modelo que seja capaz de generalizar bem para novos dados, atingindo um desempenho Ã³timo em termos de acurÃ¡cia, interpretabilidade e eficiÃªncia computacional.

### ConclusÃ£o

As *basis expansions* oferecem um caminho poderoso para lidar com a nÃ£o linearidade dos dados, mas a sua aplicaÃ§Ã£o exige uma compreensÃ£o clara dos *tradeoffs* envolvidos. A escolha das funÃ§Ãµes de base, o controle da complexidade atravÃ©s da regularizaÃ§Ã£o e da seleÃ§Ã£o de variÃ¡veis, e a avaliaÃ§Ã£o do *tradeoff* viÃ©s-variÃ¢ncia sÃ£o passos cruciais para a construÃ§Ã£o de modelos eficazes e robustos. Ao dominar esses *tradeoffs*, Ã© possÃ­vel aproveitar ao mÃ¡ximo o potencial das *basis expansions*, construindo modelos que capturam a complexidade dos dados do mundo real sem sacrificar a interpretabilidade e a generalizaÃ§Ã£o.

### Footnotes

[^5.1]: "In this chapter and the next we discuss popular methods for moving beyond linearity. The core idea in this chapter is to augment/replace the vector of inputs X with additional variables, which are transformations of X, and then use linear models in this new space of derived input features." *(Trecho de <Basis Expansions and Regularization>)*
[^5.2]: "Some simple and widely used examples of the hm are the following: $h_m(X) = X_m$, $m = 1, \ldots, p$ recovers the original linear model. $h_m(X) = X_j^2$ or $h_m(X) = X_jX_k$ allows us to augment the inputs with polynomial terms to achieve higher-order Taylor expansions." *(Trecho de <Basis Expansions and Regularization>)*
[^5.5]: "Since $df_\lambda = \text{trace}(S_\lambda)$ is monotone in $\lambda$ for smoothing splines, we can invert the relationship and specify $\lambda$ by fixing $df$. In practice this can be achieved by simple numerical methods. So, for example, in R one can use smooth.spline(x,y,df=6) to specify the amount of smoothing." *(Trecho de <Basis Expansions and Regularization>)*
[^5.5.1]:"This encourages a more traditional mode of model selection, where we might try a couple of different values of df, and select one based on approximate F-tests, residual plots and other more subjective criteria." *(Trecho de <Basis Expansions and Regularization>)*
[^5.5.2]: "Using df in this way provides a uniform approach to compare many different smoothing methods. It is particularly useful in generalized additive models (Chapter 9), where several smoothing methods can be simultaneously used in one model." *(Trecho de <Basis Expansions and Regularization>)*
