## Overfitting em Modelos de Aprendizado Estat√≠stico: Uma An√°lise Detalhada com Foco em Random Forests

```mermaid
graph TB
    subgraph "Overfitting Conceptual Framework"
        A["Data with Underlying Patterns + Noise"]
        B["Model Training"]
        C["Overfitted Model: Captures Patterns and Noise"]
        D["Good Performance on Training Data"]
        E["Poor Generalization to New Data"]
        A --> B
        B --> C
        C --> D
        C --> E
    end
```

### Introdu√ß√£o
O conceito de **overfitting** √© central no campo do aprendizado estat√≠stico e se manifesta quando um modelo se ajusta excessivamente aos dados de treinamento, capturando n√£o apenas os padr√µes subjacentes, mas tamb√©m o ru√≠do presente neles [^15.1]. Este fen√¥meno resulta em uma performance excelente nos dados de treinamento, mas uma generaliza√ß√£o fraca para novos dados, comprometendo a utilidade pr√°tica do modelo. Um modelo com *overfitting* possui alta complexidade, baixa vari√¢ncia e alto vi√©s [^15.1], o que √© particularmente problem√°tico para modelos com muitas vari√°veis e par√¢metros. Abordagens como **random forests**, embora robustas, tamb√©m podem sucumbir ao overfitting em certas situa√ß√µes, conforme ser√° discutido em detalhe neste cap√≠tulo [^15.3.4].

### Conceitos Fundamentais
**Conceito 1: Vi√©s e Vari√¢ncia**
O problema de *overfitting* est√° intimamente ligado ao *trade-off* entre **vi√©s** e **vari√¢ncia**. O **vi√©s** se refere ao erro que √© introduzido por aproximar um problema real complexo atrav√©s de um modelo simplificado. Um modelo com alto vi√©s tende a subestimar a complexidade dos dados e n√£o captura os padr√µes relevantes, resultando em *underfitting*. Por outro lado, a **vari√¢ncia** √© a sensibilidade do modelo a pequenas varia√ß√µes nos dados de treinamento. Um modelo com alta vari√¢ncia se ajusta excessivamente ao ru√≠do nos dados de treinamento, resultando em *overfitting* [^15.1]. M√©todos lineares de classifica√ß√£o, por exemplo, geralmente t√™m alto vi√©s e baixa vari√¢ncia. Enquanto que modelos n√£o lineares como √°rvores de decis√£o, t√™m o oposto: baixo vi√©s e alta vari√¢ncia [^15.2]. O objetivo √© encontrar um equil√≠brio entre esses dois aspectos, minimizando o erro total.
```mermaid
graph LR
    subgraph "Bias-Variance Tradeoff"
        direction LR
        A["High Bias: Underfitting"] --> B["Oversimplified Model"]
        B --> C["Fails to Capture Data Patterns"]
        D["High Variance: Overfitting"] --> E["Model Fits Noise"]
        E --> F["Poor Generalization"]
        G["Goal: Balance Bias and Variance"]
        C & F --> G
    end
```

> üí° **Exemplo Num√©rico:** Suponha que temos um conjunto de dados com uma rela√ß√£o c√∫bica entre a vari√°vel independente ($x$) e a vari√°vel dependente ($y$), mas tentamos ajustar um modelo linear. Este modelo ter√° alto vi√©s porque ele n√£o consegue capturar a rela√ß√£o c√∫bica. Se usarmos um modelo polinomial de alta ordem, ele pode se ajustar aos dados de treinamento perfeitamente (baixo vi√©s), mas se adaptar√° a ru√≠dos, resultando em alta vari√¢ncia. O objetivo √© encontrar um modelo que se ajuste bem aos dados, sem se ajustar em demasia ao ru√≠do.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression
> from sklearn.preprocessing import PolynomialFeatures
> from sklearn.pipeline import make_pipeline
>
> # Gerar dados com uma rela√ß√£o c√∫bica e ru√≠do
> np.random.seed(42)
> x = np.sort(np.random.rand(50) * 5)
> y = 2 + 3*x - 0.8 * x**2 + 0.1 * x**3 + np.random.randn(50) * 2
>
> # Ajustar um modelo linear
> model_linear = LinearRegression()
> model_linear.fit(x.reshape(-1, 1), y)
> y_linear = model_linear.predict(x.reshape(-1, 1))
>
> # Ajustar um modelo polinomial de grau 3
> model_poly = make_pipeline(PolynomialFeatures(3), LinearRegression())
> model_poly.fit(x.reshape(-1, 1), y)
> y_poly = model_poly.predict(x.reshape(-1, 1))
>
> # Plotar os resultados
> plt.figure(figsize=(8,6))
> plt.scatter(x, y, label="Dados", color='blue')
> plt.plot(x, y_linear, color='red', label="Modelo Linear (Alto Vi√©s)")
> plt.plot(x, y_poly, color='green', label="Modelo Polinomial (Baixo Vi√©s e Alta Vari√¢ncia)")
> plt.xlabel("x")
> plt.ylabel("y")
> plt.title("Exemplo de Vi√©s e Vari√¢ncia")
> plt.legend()
> plt.show()
> ```

**Lemma 1:** *Em modelos lineares, o aumento da complexidade (n√∫mero de vari√°veis) tende a diminuir o vi√©s e aumentar a vari√¢ncia, o que tamb√©m acontece em modelos n√£o lineares, de forma mais acentuada. Em particular, a complexidade do modelo √© diretamente relacionada com a capacidade de ajuste e a ocorr√™ncia de overfitting.*

**Conceito 2: Random Forests e Vari√¢ncia**
**Random forests** s√£o modelos *ensemble* que visam reduzir a vari√¢ncia atrav√©s da agrega√ß√£o de √°rvores de decis√£o [^15.1]. Em ess√™ncia, o m√©todo cria m√∫ltiplas √°rvores de decis√£o, cada uma treinada em um subconjunto aleat√≥rio dos dados de treinamento e utilizando um subconjunto aleat√≥rio de vari√°veis preditoras. As predi√ß√µes de cada √°rvore s√£o ent√£o agregadas (por meio de vota√ß√£o majorit√°ria para classifica√ß√£o ou m√©dia para regress√£o) para gerar a predi√ß√£o final [^15.1, ^15.2]. A ideia chave √© que, ao proibir que √°rvores sejam altamente correlacionadas, atrav√©s do uso de subconjuntos aleat√≥rios de vari√°veis [^15.2], a vari√¢ncia total do modelo √© reduzida. No entanto, como cada √°rvore ainda tem sua pr√≥pria vari√¢ncia [^15.2], random forests podem apresentar *overfitting* se as √°rvores forem muito complexas.

```mermaid
graph LR
    subgraph "Random Forest Architecture"
        direction TB
        A["Training Data"]
        B["Random Subsets of Data and Features"]
        C["Multiple Decision Trees"]
        D["Aggregate Predictions"]
        A --> B
        B --> C
        C --> D
    end
```

**Corol√°rio 1:** *A redu√ß√£o da correla√ß√£o entre as √°rvores em random forests diminui a vari√¢ncia do modelo final, entretanto a complexidade de cada √°rvore individual ainda contribui para a ocorr√™ncia de overfitting em certas condi√ß√µes.* [^15.2]

**Conceito 3: Overfitting e o N√∫mero de √Årvores**
Intuitivamente, aumentar o n√∫mero de √°rvores em um random forest deveria melhorar o desempenho. De fato, isso acontece at√© certo ponto. No entanto, como o m√©todo projeta uma aproxima√ß√£o da expectativa (Equa√ß√£o 15.3), √© poss√≠vel que modelos com muitas √°rvores resultem em uma complexidade desnecess√°ria, apresentando *overfitting* [^15.3.4]. Em outras palavras, embora aumentar o n√∫mero de √°rvores n√£o leve a *overfitting* no sentido tradicional (onde a performance nos dados de treino melhora e nos dados de teste piora), o modelo pode se tornar muito espec√≠fico para os dados de treinamento, n√£o generalizando bem para dados n√£o vistos, e incorrendo em vari√¢ncia indesej√°vel. Isso se deve ao fato de que, mesmo com a aleatoriza√ß√£o, cada √°rvore tenta capturar o m√°ximo de informa√ß√£o poss√≠vel dos dados de treinamento, eventualmente incluindo ru√≠do [^15.3.4].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
```mermaid
graph TB
    subgraph "Linear Regression for Classification"
      direction TB
      A["Input Data: Features X and Class Labels Y"]
      B["Indicator Matrix Creation"]
      C["Linear Regression: y ‚âà XŒ≤"]
      D["Minimizing RSS: ||y - XŒ≤||¬≤"]
      E["Potential Overfitting (High Variance)"]
      A --> B
      B --> C
      C --> D
      D --> E
    end
```

Em modelos lineares, como a regress√£o linear aplicada a uma matriz de indicadores para classifica√ß√£o [^15.1], o *overfitting* pode ocorrer quando h√° um n√∫mero elevado de vari√°veis preditoras em rela√ß√£o ao n√∫mero de observa√ß√µes. Em tal cen√°rio, o modelo pode se ajustar ao ru√≠do nos dados de treinamento, resultando em coeficientes que n√£o generalizam bem para novos dados. A abordagem de m√≠nimos quadrados busca minimizar o erro nos dados de treinamento, mas n√£o imp√µe qualquer restri√ß√£o √† complexidade do modelo. Isso leva a um modelo com alta vari√¢ncia e, consequentemente, suscet√≠vel ao *overfitting*.

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com 100 observa√ß√µes e 150 vari√°veis preditoras bin√°rias (dummy variables). Ao aplicar regress√£o linear diretamente sobre esta matriz de indicadores para prever a classe (0 ou 1), o modelo pode gerar coeficientes que se ajustam perfeitamente aos dados de treinamento (erro zero), mas que n√£o generalizam bem para dados de teste. Este √© um cen√°rio cl√°ssico onde o n√∫mero de vari√°veis √© maior que o n√∫mero de observa√ß√µes, resultando em overfitting. A matriz $X$ tem dimens√µes 100x150. O vetor de par√¢metros $\beta$ ser√° encontrado atrav√©s da minimiza√ß√£o da fun√ß√£o de custo da regress√£o linear. Em um caso de *overfitting* o modelo se torna muito adaptado ao ru√≠do dos dados, e $\beta$ n√£o ter√° valores que representem o fen√¥meno subjacente, mas o ru√≠do espec√≠fico.

**Lemma 2:** *O uso de regress√£o linear em uma matriz de indicadores pode levar a overfitting quando o n√∫mero de vari√°veis √© compar√°vel ou maior do que o n√∫mero de observa√ß√µes.*

**Corol√°rio 2:** *Regulariza√ß√£o, como penalidades L1 e L2, podem ser aplicadas para controlar a complexidade do modelo de regress√£o linear, atenuando o overfitting.*

Em compara√ß√£o com abordagens mais sofisticadas como a regress√£o log√≠stica, a regress√£o linear em matriz de indicadores pode apresentar pior desempenho quando h√° separa√ß√£o perfeita das classes, devido √† sua tend√™ncia a extrapolar para fora do intervalo [0, 1]. A regress√£o log√≠stica, por outro lado, lida melhor com esta situa√ß√£o. Contudo, em certas circunst√¢ncias, a regress√£o linear pode ser uma alternativa v√°lida.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
```mermaid
graph LR
    subgraph "Regularization Methods"
        direction LR
        A["L1 Regularization (Lasso)"] --> B["Adds penalty: Œª‚àë|Œ≤j|"]
        B --> C["Encourages Sparsity (Feature Selection)"]
        D["L2 Regularization (Ridge)"] --> E["Adds penalty: Œª‚àëŒ≤j¬≤"]
        E --> F["Shrinks Coefficients"]
        G["Elastic Net"] --> H["Combines L1 and L2 Penalties"]
        C & F --> H
    end
```

Para mitigar o *overfitting*, t√©cnicas de sele√ß√£o de vari√°veis e regulariza√ß√£o s√£o essenciais. Em modelos lineares, a regulariza√ß√£o L1 (Lasso) promove a esparsidade, for√ßando alguns coeficientes a serem exatamente zero [^15.2, ^15.3.4]. Isso efetivamente remove as vari√°veis menos importantes do modelo, reduzindo sua complexidade e, consequentemente, a vari√¢ncia. A regulariza√ß√£o L2 (Ridge), por sua vez, encolhe os coeficientes em dire√ß√£o a zero, mas n√£o os torna exatamente zero [^15.2]. Ambas as penalidades podem ser combinadas (Elastic Net) para aproveitar as vantagens de ambas as abordagens [^15.2].

> üí° **Exemplo Num√©rico:** Imagine que voc√™ est√° usando regress√£o linear para modelar o pre√ßo de casas com 100 vari√°veis, algumas das quais s√£o altamente correlacionadas ou pouco relevantes. Ao aplicar a regulariza√ß√£o L1 (Lasso), alguns dos coeficientes associados a vari√°veis pouco importantes ser√£o levados a zero, efetivamente removendo essas vari√°veis do modelo. A regulariza√ß√£o L2 (Ridge), por outro lado, reduzir√° os valores de todos os coeficientes, incluindo aqueles associados a vari√°veis importantes, melhorando a estabilidade do modelo.
>
> Vamos usar um exemplo com dados simulados para ilustrar a diferen√ßa entre L1 (Lasso) e L2 (Ridge) usando Python:
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression, Lasso, Ridge
> from sklearn.preprocessing import StandardScaler
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import mean_squared_error, r2_score
> import pandas as pd
>
> # Generate a dataset with 100 samples, 10 features, and some noise
> np.random.seed(42)
> n_samples = 100
> n_features = 10
> X = np.random.randn(n_samples, n_features)
> true_coefs = np.array([5, -3, 2, 0, 0, 0, -1, 4, 0, 0]) # True coefficients where some are zero
> y = np.dot(X, true_coefs) + np.random.normal(0, 2, n_samples)
>
> # Split the data into training and testing sets
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Scale the features
> scaler = StandardScaler()
> X_train_scaled = scaler.fit_transform(X_train)
> X_test_scaled = scaler.transform(X_test)
>
> # Fit ordinary linear regression model
> model_ols = LinearRegression()
> model_ols.fit(X_train_scaled, y_train)
> y_pred_ols = model_ols.predict(X_test_scaled)
> mse_ols = mean_squared_error(y_test, y_pred_ols)
> r2_ols = r2_score(y_test, y_pred_ols)
>
> # Fit Lasso regression model
> lambda_lasso = 0.1
> model_lasso = Lasso(alpha=lambda_lasso)
> model_lasso.fit(X_train_scaled, y_train)
> y_pred_lasso = model_lasso.predict(X_test_scaled)
> mse_lasso = mean_squared_error(y_test, y_pred_lasso)
> r2_lasso = r2_score(y_test, y_pred_lasso)
>
> # Fit Ridge regression model
> lambda_ridge = 1.0
> model_ridge = Ridge(alpha=lambda_ridge)
> model_ridge.fit(X_train_scaled, y_train)
>y_pred_ridge = model_ridge.predict(X_test_scaled)
> mse_ridge = mean_squared_error(y_test, y_pred_ridge)
> r2_ridge = r2_score(y_test, y_pred_ridge)
>
> # Create DataFrame for comparing results
> results = pd.DataFrame({
>    'Method': ['OLS', 'Lasso', 'Ridge'],
>    'MSE': [mse_ols, mse_lasso, mse_ridge],
>    'R2': [r2_ols, r2_lasso, r2_ridge],
>    'Parameters': [model_ols.coef_, model_lasso.coef_, model_ridge.coef_]
> })
> print(results)
>
> # Visualizing coefficients
> plt.figure(figsize=(10, 6))
> plt.plot(true_coefs, 'o-', label='True Coefficients', color='black')
> plt.plot(model_ols.coef_, 'o-', label='OLS Coefficients', color='blue')
> plt.plot(model_lasso.coef_, 'o-', label='Lasso Coefficients', color='green')
> plt.plot(model_ridge.coef_, 'o-', label='Ridge Coefficients', color='red')
> plt.xlabel('Feature Index')
> plt.ylabel('Coefficient Value')
> plt.title('Comparison of Coefficients')
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
>
> This code will output the coefficients for each model. Note how Lasso drives some coefficients to zero, performing variable selection, while Ridge shrinks coefficients without setting them to zero.  The MSE and R2 values are also computed and printed, so that it is possible to assess which model is best for the task.

Em random forests, a sele√ß√£o de um subconjunto de vari√°veis em cada *split* tamb√©m atua como uma forma de regulariza√ß√£o. Ao impedir que todas as vari√°veis sejam usadas em todos os *splits*, o m√©todo induz uma maior variedade de √°rvores de decis√£o e evita que o modelo se torne excessivamente dependente de vari√°veis espec√≠ficas [^15.2]. Contudo, mesmo com estas medidas, o *overfitting* ainda pode ocorrer se o modelo for excessivamente complexo, ou seja, se as √°rvores crescerem muito [^15.3.4].

**Lemma 3:** *A penaliza√ß√£o L1 em regress√£o log√≠stica promove a esparsidade nos coeficientes, reduzindo a complexidade do modelo e mitigando o overfitting.*

**Prova do Lemma 3:** A penaliza√ß√£o L1 adiciona um termo $\lambda \sum_{j=1}^p |\beta_j|$ √† fun√ß√£o de custo da regress√£o log√≠stica, onde $\lambda$ √© um par√¢metro de regulariza√ß√£o que controla a intensidade da penalidade. A minimiza√ß√£o desta fun√ß√£o de custo leva a coeficientes $\beta_j$ esparsos, pois a penalidade L1 for√ßa alguns coeficientes a zero.  $\blacksquare$

**Corol√°rio 3:** *O Elastic Net combina penalidades L1 e L2 para obter um modelo regularizado que balanceia esparsidade e estabilidade.*

> ‚ö†Ô∏è **Ponto Crucial**: A escolha dos par√¢metros de regulariza√ß√£o e a complexidade do modelo s√£o cruciais para evitar o *overfitting*, tanto em modelos lineares quanto em modelos *ensemble* como random forests. [^15.3.4]

### Separating Hyperplanes e Perceptrons
```mermaid
graph LR
    subgraph "Separating Hyperplanes and Overfitting"
        direction LR
        A["Linearly Separable Data"] --> B["Perfect Hyperplane"]
        C["Non-Linearly Separable Data"] --> D["Complex Decision Boundary"]
        E["Overfitting: Captures Noise"]
        B & D --> E
    end
```

O conceito de hiperplanos separadores est√° intimamente ligado ao problema de *overfitting*. Quando o conjunto de dados √© linearmente separ√°vel, um hiperplano pode ser encontrado para separar as classes perfeitamente. No entanto, em dados reais, a separa√ß√£o linear nem sempre √© poss√≠vel ou desej√°vel. Modelos muito complexos, como o *Perceptron*, podem, em certas circunst√¢ncias, encontrar fronteiras de decis√£o que se adaptam excessivamente aos dados de treinamento, incluindo ru√≠do [^15.1, ^15.2, ^15.3.4].

O m√©todo do *Perceptron* √© um exemplo de um algoritmo que, sob condi√ß√µes espec√≠ficas (como separabilidade linear), converge para um hiperplano separador. No entanto, em dados n√£o linearmente separ√°veis, o *Perceptron* pode levar a um *overfitting* se n√£o for aplicado com alguma forma de regulariza√ß√£o ou controle de complexidade. A busca por hiperplanos √≥timos, por sua vez, tenta maximizar a margem de separa√ß√£o entre as classes, o que pode ajudar a reduzir o *overfitting*.

### Random Forests e Overfitting: Uma An√°lise Detalhada

#### Como Random Forests Podem Sofrer Overfitting
Embora seja amplamente aceito que random forests n√£o sofrem *overfitting* no sentido tradicional, isso √© uma simplifica√ß√£o [^15.3.4]. A Equa√ß√£o 15.3 mostra que a previs√£o de um random forest converge para a expectativa da predi√ß√£o de uma √°rvore aleat√≥ria, mas essa expectativa ainda pode ser complexa e apresentar *overfitting*.

O principal mecanismo de prote√ß√£o contra o *overfitting* em random forests √© a redu√ß√£o da correla√ß√£o entre as √°rvores [^15.2]. Ao selecionar aleatoriamente um subconjunto de vari√°veis em cada *split* [^15.2], as √°rvores s√£o for√ßadas a explorar diferentes aspectos dos dados. Em situa√ß√µes em que poucas vari√°veis s√£o relevantes em rela√ß√£o ao n√∫mero total, o m√©todo pode apresentar dificuldades. Quando o n√∫mero de vari√°veis preditoras √© alto, mas poucas s√£o realmente relevantes, a chance de selecionar uma vari√°vel relevante em cada *split* pode ser pequena. Nessas condi√ß√µes, modelos *ensemble* como o *boosting* podem apresentar vantagens [^15.2].

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com 1000 vari√°veis preditoras, mas apenas 5 delas s√£o realmente informativas. Em um random forest, a sele√ß√£o aleat√≥ria de um subconjunto de vari√°veis em cada split pode dificultar a sele√ß√£o das 5 vari√°veis informativas, a menos que a quantidade de vari√°veis selecionadas em cada *split* seja alta. Se a quantidade for baixa, o modelo vai construir √°rvores com pouca informa√ß√£o, e ter√° dificuldades de gerar predi√ß√µes acuradas.

**Lemma 4:** *O mecanismo de sele√ß√£o aleat√≥ria de vari√°veis em random forests induz descorrela√ß√£o entre as √°rvores, diminuindo a vari√¢ncia do modelo.*

**Corol√°rio 4:** *Quando o n√∫mero de vari√°veis relevantes √© pequeno em rela√ß√£o ao n√∫mero de vari√°veis totais, a probabilidade de selecionar vari√°veis relevantes em cada split diminui, e random forests podem apresentar pior desempenho.* [^15.3.4]

#### Overfitting e o Controle da Complexidade das √Årvores
O *overfitting* em random forests pode ocorrer quando as √°rvores individuais se tornam muito complexas, isto √©, quando elas s√£o crescidas at√© a profundidade m√°xima poss√≠vel [^15.3.4]. Embora o m√©todo tenda a ser robusto, √© poss√≠vel limitar a profundidade m√°xima das √°rvores para controlar a complexidade geral do modelo e diminuir o overfitting [^15.3.4]. Isso geralmente √© feito por meio do controle do tamanho m√≠nimo do n√≥ terminal (o ponto onde a √°rvore para de se dividir).
```mermaid
graph TB
    subgraph "Tree Complexity Control in Random Forests"
      direction TB
      A["Unconstrained Tree Growth"]
      B["Potential for Overfitting"]
      C["Limiting Tree Depth"]
      D["Controlling Terminal Node Size"]
      E["Reduced Complexity"]
       A --> B
      B --> C
      C --> D
      D --> E
    end
```

> üí° **Exemplo Num√©rico:** Em um random forest, limitar a profundidade m√°xima de cada √°rvore, ou o n√∫mero m√≠nimo de amostras em cada folha da √°rvore, √© um m√©todo eficaz para impedir que cada √°rvore se ajuste demais aos dados de treinamento, o que leva ao overfitting. Por exemplo, vamos considerar um cen√°rio em que o modelo est√° se ajustando excessivamente e performando mal no teste. Abaixo, um exemplo de como ajustar os hiperpar√¢metros com o objetivo de reduzir overfitting.
>
> ```python
> import numpy as np
> import pandas as pd
> from sklearn.model_selection import train_test_split
> from sklearn.ensemble import RandomForestClassifier
> from sklearn.metrics import accuracy_score
>
> # Generate synthetic data with overfitting
> np.random.seed(42)
> n_samples = 500
> n_features = 20
> X = np.random.rand(n_samples, n_features)
> y = np.random.randint(0, 2, n_samples)
>
> # Add noise to the features to create overfitting
> for i in range(n_features):
>    X[:,i] += np.random.normal(0, 0.3, n_samples) * (y * 2 -1)
>
> # Split data into training and testing
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Train a Random Forest with default settings (prone to overfitting)
> rf_default = RandomForestClassifier(random_state=42)
> rf_default.fit(X_train, y_train)
> y_pred_default = rf_default.predict(X_test)
> accuracy_default = accuracy_score(y_test, y_pred_default)
>
> # Train a Random Forest with limited max_depth and min_samples_leaf
> rf_tuned = RandomForestClassifier(max_depth=5, min_samples_leaf=10, random_state=42)
> rf_tuned.fit(X_train, y_train)
> y_pred_tuned = rf_tuned.predict(X_test)
> accuracy_tuned = accuracy_score(y_test, y_pred_tuned)
>
> print(f'Accuracy with default settings: {accuracy_default:.4f}')
> print(f'Accuracy with tuned settings: {accuracy_tuned:.4f}')
>
> # Comparing train and test performance
> y_train_pred_default = rf_default.predict(X_train)
> accuracy_train_default = accuracy_score(y_train, y_train_pred_default)
>
> y_train_pred_tuned = rf_tuned.predict(X_train)
> accuracy_train_tuned = accuracy_score(y_train, y_train_pred_tuned)
>
> print(f'Training accuracy with default settings: {accuracy_train_default:.4f}')
> print(f'Training accuracy with tuned settings: {accuracy_train_tuned:.4f}')
>
> results_table = pd.DataFrame({
>    'Model': ['Default', 'Tuned'],
>    'Test Accuracy': [accuracy_default, accuracy_tuned],
>    'Training Accuracy': [accuracy_train_default, accuracy_train_tuned]
> })
> print(results_table)
>
> ```
> The results will show that the accuracy on the test set is improved by tuning the hyperparameters, while the performance in the training set is reduced, which is a sign that overfitting is reduced.

> ‚ö†Ô∏è **Nota Importante**: Na pr√°tica, random forests geralmente n√£o necessitam de ajuste cuidadoso do tamanho das √°rvores, pois o m√©todo √© bastante robusto. Contudo, em situa√ß√µes onde h√° grande disparidade entre o n√∫mero de vari√°veis preditoras e o n√∫mero de vari√°veis relevantes, esta pode ser uma op√ß√£o para se levar em considera√ß√£o. [^15.3.4]

### Pergunta Te√≥rica Avan√ßada: Como a escolha de "m" (n√∫mero de vari√°veis selecionadas aleatoriamente) afeta a vari√¢ncia e o vi√©s em random forests?
**Resposta:** A escolha de *m*, o n√∫mero de vari√°veis selecionadas aleatoriamente em cada *split*, √© um par√¢metro cr√≠tico que afeta diretamente o desempenho de um random forest. Conforme mostrado na Figura 15.7, quando *m* √© muito pequeno, a probabilidade de uma vari√°vel relevante ser selecionada em um *split* diminui, o que pode levar a um maior vi√©s e, paradoxalmente, √† redu√ß√£o da vari√¢ncia devido √† alta descorrela√ß√£o entre as √°rvores. Por outro lado, quando *m* √© muito grande, a correla√ß√£o entre as √°rvores aumenta, reduzindo os benef√≠cios da agrega√ß√£o e aumentando a vari√¢ncia [^15.2]. Idealmente, *m* deve ser escolhido para balancear essas duas for√ßas, sendo uma op√ß√£o o uso de valida√ß√£o cruzada para escolher o valor ideal.
* A redu√ß√£o de m resulta em √°rvores com maior vi√©s individual.
* O aumento de m resulta em √°rvores mais correlacionadas, o que aumenta a vari√¢ncia do modelo.
* O ideal √© encontrar um valor de m que balanceie estes dois efeitos.

```mermaid
graph LR
    subgraph "Effect of 'm' in Random Forests"
        direction TB
        A["Small 'm' (few features per split)"]
        B["High Bias: Each tree has limited information"]
        C["Low Variance: Trees are highly uncorrelated"]
        D["Large 'm' (many features per split)"]
        E["Low Bias: Trees can capture all relations"]
        F["High Variance: Trees are highly correlated"]
        A --> B
        A --> C
        D --> E
        D --> F
        G["Optimal 'm'"]
        C & E --> G
    end
```

### Conclus√£o
O *overfitting* √© um problema omnipresente no aprendizado estat√≠stico. Modelos como random forests, embora robustos e vers√°teis, n√£o s√£o imunes a esse problema. O segredo para um bom desempenho reside no entendimento dos mecanismos subjacentes que contribuem para o *overfitting*, o que inclui a complexidade do modelo, a correla√ß√£o entre as √°rvores, e a influ√™ncia de fatores como o n√∫mero de vari√°veis preditoras relevantes. Atrav√©s de uma combina√ß√£o cuidadosa de sele√ß√£o de vari√°veis, regulariza√ß√£o e otimiza√ß√£o de par√¢metros, √© poss√≠vel mitigar o *overfitting* e construir modelos preditivos que generalizem bem para dados n√£o vistos.

[^15.1]: "Bagging or bootstrap aggregation (section 8.7) is a technique for reducing the variance of an estimated prediction function. Bagging seems to work especially well for high-variance, low-bias procedures, such as trees." *(Trecho do documento)*
[^15.2]: "The essential idea in bagging (Section 8.7) is to average many noisy but approximately unbiased models, and hence reduce the variance." *(Trecho do documento)*
[^15.3.4]: "When the number of variables is large, but the fraction of relevant variables small, random forests are likely to perform poorly with small m. At each split the chance can be small that the relevant variables will be selected." *(Trecho do documento)*
<!-- END DOCUMENT -->
