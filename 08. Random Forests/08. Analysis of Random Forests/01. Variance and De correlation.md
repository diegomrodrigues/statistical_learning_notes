## Variance and the De-Correlation Effect in Random Forests

```mermaid
graph LR
    subgraph "Random Forest Variance Reduction"
        direction TB
        A["Bagging: Averaging noisy trees"]
        B["High variance individual trees"]
        C["Random Forest: De-correlation"]
        D["Reduced correlation between trees"]
        E["Lower variance of the ensemble"]
        A --> B
        A --> C
        C --> D
        D --> E
    end
```

### Introdu√ß√£o

A ideia central por tr√°s do **bagging** √© reduzir a vari√¢ncia de um modelo estat√≠stico pela m√©dia de m√∫ltiplas vers√µes ruidosas, mas aproximadamente n√£o viesadas, do mesmo modelo [^15.1]. √Årvores de decis√£o, devido √† sua capacidade de modelar intera√ß√µes complexas e baixa tend√™ncia, s√£o candidatas ideais para o processo de *bagging*. No entanto, a vari√¢ncia das √°rvores individuais √© notavelmente alta, e o *bagging* se beneficia significativamente da m√©dia. Conforme discutido em [^15.1], um modelo de *Random Forests* surge como uma extens√£o substancial do *bagging*, buscando reduzir ainda mais a correla√ß√£o entre as √°rvores, sem aumentar significativamente a vari√¢ncia das mesmas. Esta se√ß√£o explora em detalhes o efeito de *de-correla√ß√£o* e como ele impacta a vari√¢ncia do *Random Forest*.

### Entendendo a Vari√¢ncia em *Random Forests*

Para compreender o mecanismo de *de-correla√ß√£o* dentro de *Random Forests*, devemos examinar como a vari√¢ncia de um conjunto de √°rvores √© afetada. Conforme apresentado no contexto, a vari√¢ncia de uma m√©dia de *B* vari√°veis aleat√≥rias i.i.d., cada uma com vari√¢ncia $\sigma^2$, √© dada por $\sigma^2/B$. No entanto, em *bagging* e *Random Forests*, as √°rvores n√£o s√£o independentes. Se as vari√°veis s√£o apenas i.d. (identicamente distribu√≠das, mas n√£o necessariamente independentes), com uma correla√ß√£o *pairwise* positiva *œÅ*, a vari√¢ncia da m√©dia √© dada por [^15.2]:
$$ \sigma^2 \left( \rho + \frac{1-\rho}{B} \right) $$ [^15.2]

```mermaid
graph LR
    subgraph "Variance of Averaged Correlated Variables"
        direction TB
        A["Variance of average"]
        B["œÉ¬≤: Variance of individual tree"]
        C["œÅ: Pairwise correlation"]
        D["B: Number of trees"]
        E["Formula: œÉ¬≤ * (œÅ + (1-œÅ)/B)"]
        A --> B
        A --> C
        A --> D
        A --> E
    end
```

> üí° **Exemplo Num√©rico:** Suponha que temos um conjunto de √°rvores onde cada √°rvore tem uma vari√¢ncia $\sigma^2 = 4$. Vamos considerar dois cen√°rios: um com alta correla√ß√£o entre as √°rvores, $\rho = 0.8$, e outro com baixa correla√ß√£o, $\rho = 0.2$. Se usarmos $B = 10$ √°rvores, a vari√¢ncia da m√©dia das √°rvores em cada cen√°rio √©:
>
> *   **Cen√°rio 1 (Alta Correla√ß√£o):** $\text{Vari√¢ncia} = 4 \times (0.8 + \frac{1 - 0.8}{10}) = 4 \times (0.8 + 0.02) = 4 \times 0.82 = 3.28$
> *   **Cen√°rio 2 (Baixa Correla√ß√£o):** $\text{Vari√¢ncia} = 4 \times (0.2 + \frac{1 - 0.2}{10}) = 4 \times (0.2 + 0.08) = 4 \times 0.28 = 1.12$
>
> Este exemplo mostra que a vari√¢ncia da m√©dia das √°rvores √© significativamente menor quando a correla√ß√£o entre as √°rvores √© baixa.

Conforme *B* aumenta, o segundo termo desaparece, mas o primeiro termo persiste, indicando que a correla√ß√£o entre as √°rvores limita o benef√≠cio da m√©dia. A chave para o *Random Forest* √© reduzir a correla√ß√£o entre as √°rvores para diminuir a vari√¢ncia, e isso √© alcan√ßado atrav√©s da sele√ß√£o aleat√≥ria de vari√°veis no processo de crescimento da √°rvore [^15.2].

### Mecanismo de *De-Correla√ß√£o*

O *Random Forest* emprega um m√©todo espec√≠fico para reduzir a correla√ß√£o entre as √°rvores. Ao construir uma √°rvore em um conjunto de dados *bootstrap*, ao inv√©s de usar todas as vari√°veis de entrada para cada n√≥, apenas um subconjunto aleat√≥rio de tamanho *m ‚â§ p* das vari√°veis √© considerado como candidatos para a divis√£o. Este processo √© repetido recursivamente at√© que o tamanho m√≠nimo do n√≥ seja atingido [^15.2].

```mermaid
graph LR
    subgraph "Random Forest De-correlation Process"
        direction TB
        A["Bootstrap dataset"]
        B["For each node:"]
        C["Select m variables randomly (m < p)"]
        D["Choose best split variable among m"]
        E["Split the node"]
        F["Repeat until min node size"]
        A --> B
        B --> C
        C --> D
        D --> E
        E --> F
    end
```

O algoritmo, conforme resumido em [^15.2] *Algorithm 15.1*, demonstra este procedimento de sele√ß√£o aleat√≥ria de vari√°veis. Para cada √°rvore *b* de 1 a *B*:

1. Uma amostra *bootstrap* $Z^*$ de tamanho *N* √© obtida dos dados de treinamento.
2. A √°rvore $T_b$ √© crescida nos dados de *bootstrap*, onde em cada n√≥:
   i. Um subconjunto de *m* vari√°veis √© selecionado aleatoriamente de um total de *p* vari√°veis.
   ii. A melhor vari√°vel e ponto de divis√£o s√£o escolhidos dentro deste subconjunto de *m*.
   iii. O n√≥ √© dividido em dois n√≥s filhos.

Este processo continua at√© o tamanho m√≠nimo do n√≥, *$n_{min}$*, ser alcan√ßado. A previs√£o em um novo ponto *x* √© obtida atrav√©s da m√©dia das predi√ß√µes das *B* √°rvores (para regress√£o) ou atrav√©s do voto da maioria (para classifica√ß√£o) [^15.2].

#### Lemma 5: Impacto da Sele√ß√£o Aleat√≥ria na Correla√ß√£o das √Årvores

**Declara√ß√£o:** A sele√ß√£o aleat√≥ria de *m* vari√°veis em cada n√≥ durante o crescimento da √°rvore *Random Forest* reduz a correla√ß√£o entre as √°rvores em compara√ß√£o com um cen√°rio sem sele√ß√£o aleat√≥ria, onde todas as *p* vari√°veis s√£o consideradas.
**Prova:** Consideremos duas √°rvores, $T_1$ e $T_2$, constru√≠das usando *bootstrap* e sele√ß√£o de vari√°vel. Se *m=p*, as √°rvores s√£o equivalentes ao cen√°rio de *bagging*, onde as divis√µes s√£o feitas considerando todas as vari√°veis, levando a uma maior correla√ß√£o. No entanto, com *m<p*, a probabilidade de duas √°rvores selecionarem as mesmas vari√°veis para divis√£o em n√≥s an√°logos diminui, o que induz uma menor correla√ß√£o.

```mermaid
graph LR
    subgraph "Lemma 5: Effect of Random Selection on Correlation"
        direction TB
        A["m = p (Bagging): All variables used"]
        B["High correlation between trees"]
        C["m < p (Random Forest): Subset of variables"]
        D["Lower probability of same variable selection"]
        E["Reduced correlation between trees"]
        A --> B
        C --> D
        D --> E
    end
```

> üí° **Exemplo Num√©rico:** Suponha que temos um dataset com $p=10$ vari√°veis.
>
> *   **Caso 1: Bagging (m=p=10):** Se usarmos bagging, onde $m=10$, cada √°rvore tem acesso a todas as 10 vari√°veis em cada n√≥. Isso resulta em √°rvores muito semelhantes, com alta correla√ß√£o entre elas.
> *   **Caso 2: Random Forest (m=3):** Agora, se usarmos random forest com $m=3$, cada √°rvore seleciona aleatoriamente 3 das 10 vari√°veis para cada divis√£o. Isso introduz diversidade e reduz a correla√ß√£o. Por exemplo, na primeira divis√£o, a √°rvore $T_1$ pode usar as vari√°veis 1, 3 e 7 enquanto a √°rvore $T_2$ usa as vari√°veis 2, 5 e 9.
>
> A chance de $T_1$ e $T_2$ selecionarem as mesmas vari√°veis para divis√£o √© menor do que se tivessem acesso a todas as 10 vari√°veis, diminuindo a correla√ß√£o entre elas.

A probabilidade de uma vari√°vel relevante ser selecionada em um dado n√≥ √© *m/p*. Com *m* significativamente menor que *p*, a correla√ß√£o entre as √°rvores √© reduzida, pois nem todas as √°rvores s√£o constru√≠das usando as mesmas vari√°veis para decis√£o. A redu√ß√£o desta correla√ß√£o diminui a vari√¢ncia do *Random Forest* final. $\blacksquare$

#### Corol√°rio 5: Rela√ß√£o entre 'm' e a Correla√ß√£o das √Årvores

**Declara√ß√£o:** Conforme *m* (o n√∫mero de vari√°veis selecionadas aleatoriamente) diminui, a correla√ß√£o entre as √°rvores no *Random Forest* tamb√©m diminui, resultando em menor vari√¢ncia do modelo.
**Prova:** A prova decorre diretamente do Lemma 5. Reduzir o n√∫mero de vari√°veis *m* que s√£o consideradas para divis√£o aumenta a diversidade entre as √°rvores, diminuindo a probabilidade de que √°rvores distintas sigam os mesmos caminhos de decis√£o. Essa diversidade reduz a correla√ß√£o entre as √°rvores, o que se traduz em uma vari√¢ncia reduzida da m√©dia das √°rvores (o resultado do modelo *Random Forest*). A equa√ß√£o da vari√¢ncia do resultado m√©dio de *B* √°rvores mostra claramente que quanto menor a correla√ß√£o *œÅ*, menor a vari√¢ncia final [^15.2]. $\blacksquare$

```mermaid
graph LR
    subgraph "Corollary 5: Relationship between 'm' and Correlation"
        direction TB
        A["Decreasing 'm' (number of randomly selected variables)"]
        B["Increased tree diversity"]
        C["Reduced correlation (œÅ) between trees"]
        D["Lower variance of the Random Forest model"]
        A --> B
        B --> C
        C --> D
    end
```

> üí° **Exemplo Num√©rico:** Vamos analisar a vari√¢ncia com diferentes valores de *m* usando a f√≥rmula da vari√¢ncia com correla√ß√£o. Suponha $\sigma^2 = 4$, $B=100$, e que a correla√ß√£o $\rho$ seja uma fun√ß√£o de *m*, $\rho = m/p$. Vamos considerar um problema com $p=10$.
>
> *   **m = 1:** $\rho = 1/10 = 0.1$. $\text{Vari√¢ncia} = 4 \times (0.1 + \frac{1 - 0.1}{100}) \approx 4 \times 0.109 = 0.436$
> *   **m = 5:** $\rho = 5/10 = 0.5$. $\text{Vari√¢ncia} = 4 \times (0.5 + \frac{1 - 0.5}{100}) \approx 4 \times 0.505 = 2.02$
> *   **m = 10 (Bagging):** $\rho = 10/10 = 1$. $\text{Vari√¢ncia} = 4 \times (1 + \frac{1 - 1}{100}) = 4 \times 1 = 4$
>
> Este exemplo ilustra como a redu√ß√£o de *m* diminui a correla√ß√£o entre as √°rvores, levando a uma menor vari√¢ncia do modelo final. Quando $m=p$ (Bagging), a vari√¢ncia da m√©dia se aproxima da vari√¢ncia das √°rvores individuais.

### F√≥rmula da Vari√¢ncia e Limite de Erro

A forma limite (quando B ‚Üí ‚àû) do estimador de regress√£o *Random Forest* √© dada por [^15.4]:
$$ \hat{f}_{rf}(x) = E_{\Theta | Z} [T(x; \Theta(Z))]$$
onde *Z* representa os dados de treinamento e *Œò* representa os par√¢metros da √°rvore. A vari√¢ncia do estimador *Random Forest*, conforme apresentado no contexto, √© dada por [^15.5]:
$$Var[\hat{f}_{rf}(x)] = \rho(x) \sigma^2(x)$$
onde *œÅ(x)* √© a correla√ß√£o amostral entre qualquer par de √°rvores e *œÉ¬≤(x)* √© a vari√¢ncia amostral de qualquer √°rvore sorteada aleatoriamente [^15.8]. Essa formula√ß√£o demonstra como a vari√¢ncia do modelo *Random Forest* √© diretamente proporcional √† correla√ß√£o entre as √°rvores. Reduzindo *œÅ*, diminu√≠mos a vari√¢ncia.

```mermaid
graph LR
 subgraph "Random Forest Variance Formula"
    direction TB
    A["Var[fÃÇ_rf(x)]"]
    B["œÅ(x): Correlation between trees"]
    C["œÉ¬≤(x): Variance of a single tree"]
    D["Formula: œÅ(x) * œÉ¬≤(x)"]
    A --> B
    A --> C
    A --> D
 end
```

> üí° **Exemplo Num√©rico:** Suponha que a vari√¢ncia de uma √°rvore individual em um certo ponto *x* seja $\sigma^2(x) = 2$ e que a correla√ß√£o entre as √°rvores nesse ponto seja $\rho(x) = 0.3$. A vari√¢ncia do Random Forest nesse ponto seria:
>
> $$Var[\hat{f}_{rf}(x)] = 0.3 \times 2 = 0.6$$
>
> Se, por outro lado, a correla√ß√£o entre as √°rvores fosse menor, por exemplo, $\rho(x) = 0.1$, a vari√¢ncia do Random Forest seria:
>
> $$Var[\hat{f}_{rf}(x)] = 0.1 \times 2 = 0.2$$
>
> Isso demonstra claramente como a redu√ß√£o da correla√ß√£o leva a uma menor vari√¢ncia do modelo.

### A Import√¢ncia de 'm'

A escolha de *m* √© crucial. Tipicamente, os valores para *m* s√£o $\sqrt{p}$ para classifica√ß√£o e *p/3* para regress√£o, ou mesmo valores t√£o baixos quanto 1 [^15.2], [^15.3]. Reduzir *m* diminui a correla√ß√£o entre as √°rvores e, portanto, diminui a vari√¢ncia, conforme discutido em [^15.3]. Entretanto, se *m* for muito pequeno, cada √°rvore individual pode se tornar muito inst√°vel, resultando em um aumento na vari√¢ncia individual das √°rvores e no erro generalizado.

>‚ö†Ô∏è **Nota Importante**: A escolha ideal de *m* depende do problema espec√≠fico, necessitando ser considerada como um par√¢metro de *tuning* [^15.3].

### An√°lise Te√≥rica Avan√ßada

#### Pergunta Te√≥rica Avan√ßada: Como a amostragem *bootstrap* e a sele√ß√£o aleat√≥ria de vari√°veis afetam a covari√¢ncia condicional entre as √°rvores no *Random Forest* e por que essa covari√¢ncia √© zero?

**Resposta:** A amostragem *bootstrap* e a sele√ß√£o aleat√≥ria de vari√°veis s√£o mecanismos essenciais para introduzir aleatoriedade e diversidade na constru√ß√£o das √°rvores em um *Random Forest*. A amostragem *bootstrap* envolve o sorteio aleat√≥rio de amostras com reposi√ß√£o a partir do conjunto de dados original. Isso significa que cada √°rvore √© constru√≠da em um subconjunto ligeiramente diferente dos dados, o que j√° come√ßa a gerar √°rvores menos correlacionadas entre si. A sele√ß√£o aleat√≥ria de vari√°veis durante a divis√£o de cada n√≥, como descrito anteriormente, adiciona uma outra camada de diversidade.

Formalmente, a amostragem *bootstrap* e a sele√ß√£o de vari√°veis s√£o independentes e identicamente distribu√≠das para cada √°rvore. Portanto, a covari√¢ncia condicional entre duas √°rvores avaliadas em um mesmo ponto *x*, dada uma amostra de treino *Z*, √©:

$$ Cov(T_1(x), T_2(x) | Z) = 0$$
onde *T1(x)* e *T2(x)* representam as previs√µes das duas √°rvores e *Z* os dados de treino.

Este resultado pode ser demonstrado atrav√©s da seguinte expans√£o:

$$Cov(T_1(x), T_2(x) | Z) = E[T_1(x)T_2(x)|Z] - E[T_1(x)|Z]E[T_2(x)|Z]$$

Se as √°rvores s√£o constru√≠das independentemente, a m√©dia condicional do produto √© igual ao produto das m√©dias condicionais. Ou seja, como a amostragem e a sele√ß√£o de vari√°veis s√£o i.i.d., podemos escrever:

$$ E[T_1(x)T_2(x)|Z] = E[T_1(x)|Z]E[T_2(x)|Z]$$

Logo, a covari√¢ncia √© zero. Isso significa que, dada uma amostra *Z* fixa, as previs√µes das diferentes √°rvores podem ser consideradas como independentes, o que √© crucial para a redu√ß√£o da vari√¢ncia. Essa independ√™ncia condicional n√£o deve ser confundida com a independ√™ncia n√£o condicional entre as √°rvores.

```mermaid
graph LR
    subgraph "Conditional Covariance of Trees"
        direction TB
        A["Bootstrap sampling and random variable selection"]
        B["Independent tree construction given Z"]
         C["Cov(T1(x), T2(x) | Z) = E[T1(x)T2(x)|Z] - E[T1(x)|Z]E[T2(x)|Z]"]
        D["E[T1(x)T2(x)|Z] = E[T1(x)|Z]E[T2(x)|Z]"]
        E["Conditional Covariance: 0"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

#### Pergunta Te√≥rica Avan√ßada: Decomponha a vari√¢ncia total do estimador do *Random Forest* em termos da vari√¢ncia da m√©dia das √°rvores e da vari√¢ncia dentro das amostras *bootstrap*. Quais os efeitos da sele√ß√£o aleat√≥ria de vari√°veis nesta decomposi√ß√£o?

**Resposta:** A vari√¢ncia total do estimador *Random Forest*, denotada por *Var(T(x;Œò(Z)))*, pode ser decomposta em duas partes [^15.9]:

$$Var(T(x; \Theta(Z))) = Var_Z (E_{\Theta|Z} (T(x; \Theta(Z)))) + E_Z (Var_{\Theta|Z} (T(x; \Theta(Z))))$$

O primeiro termo, *Var<sub>Z</sub>(E<sub>Œò|Z</sub>(T(x; Œò(Z))))*, representa a vari√¢ncia da m√©dia das predi√ß√µes do *Random Forest* devido √† variabilidade dos dados de treino (*Z*). √â a vari√¢ncia que buscamos reduzir com o uso do *Random Forest*. O segundo termo, *E<sub>Z</sub>(Var<sub>Œò|Z</sub>(T(x; Œò(Z))))*, representa a m√©dia das vari√¢ncias condicionais das √°rvores individuais, dado um conjunto de dados de treino fixo. Essa vari√¢ncia vem da aleatoriedade introduzida pela sele√ß√£o de *bootstrap* e pela sele√ß√£o aleat√≥ria de vari√°veis.

A sele√ß√£o aleat√≥ria de vari√°veis (*m<p*) afeta significativamente ambos os termos. Ao diminuir *m*, aumentamos a diversidade entre as √°rvores, o que reduz a correla√ß√£o entre elas. Isso reduz a vari√¢ncia da m√©dia das predi√ß√µes (*Var<sub>Z</sub>(E<sub>Œò|Z</sub>(T(x; Œò(Z))))*), permitindo que o modelo *Random Forest* se beneficie mais da m√©dia. Por outro lado, reduzir *m* tamb√©m aumenta a vari√¢ncia das √°rvores individuais (*Var<sub>Œò|Z</sub>(T(x; Œò(Z))))*, mas como o primeiro termo domina na vari√¢ncia do estimador do *Random Forest*, o efeito geral √© de uma redu√ß√£o da vari√¢ncia.

```mermaid
graph LR
    subgraph "Variance Decomposition"
        direction TB
        A["Total Variance Var(T(x;Œò(Z)))"]
        B["Variance of average predictions due to training data Var_Z (E_(Œò|Z) (T(x; Œò(Z))))"]
        C["Average within sample tree variance E_Z (Var_(Œò|Z) (T(x; Œò(Z))))"]
        D["Random variable selection m<p reduces correlation and first term but increases second term"]
        A --> B
        A --> C
         B & C --> D
    end
```

> üí° **Exemplo Num√©rico:** Vamos ilustrar essa decomposi√ß√£o com valores hipot√©ticos. Suponha que a vari√¢ncia total do modelo Random Forest seja *Var(T(x;Œò(Z))) = 1.5*. Suponha tamb√©m que:
> * A vari√¢ncia da m√©dia das predi√ß√µes devido aos dados de treino √© *Var<sub>Z</sub>(E<sub>Œò|Z</sub>(T(x; Œò(Z)))) = 0.8*
> * A m√©dia das vari√¢ncias condicionais das √°rvores individuais √© *E<sub>Z</sub>(Var<sub>Œò|Z</sub>(T(x; Œò(Z)))) = 0.7*
>
> Ent√£o, *1.5 = 0.8 + 0.7*. Reduzir *m* pode diminuir a vari√¢ncia da m√©dia para, por exemplo, *0.5*, e aumentar a vari√¢ncia das √°rvores individuais para *1.0*. O resultado total seria uma redu√ß√£o da vari√¢ncia do Random Forest para *1.5 = 0.5 + 1.0*.

#### Pergunta Te√≥rica Avan√ßada: Como o aumento do n√∫mero de √°rvores *B* impacta o termo de correla√ß√£o *œÅ* e a vari√¢ncia do *Random Forest*?

**Resposta:** O aumento do n√∫mero de √°rvores *B* em um *Random Forest* influencia a vari√¢ncia do modelo, principalmente atrav√©s da sua intera√ß√£o com a correla√ß√£o *œÅ*. Conforme apresentado na equa√ß√£o da vari√¢ncia do estimador *Random Forest* [^15.2]:
$$ \sigma^2 \left( \rho + \frac{1-\rho}{B} \right) $$
√† medida que *B* tende ao infinito, o termo *(1 - œÅ) / B* tende a zero. Isso indica que o aumento de *B* reduz o impacto da parte da vari√¢ncia que depende da correla√ß√£o das √°rvores. No entanto, a correla√ß√£o *œÅ* n√£o √© afetada diretamente pelo n√∫mero de √°rvores *B*, mas sim pela sele√ß√£o aleat√≥ria de vari√°veis (*m*). A converg√™ncia da vari√¢ncia √© dada por:
$$Var[\hat{f}_{rf}(x)] = \rho(x) \sigma^2(x)$$

A redu√ß√£o da vari√¢ncia com o aumento de *B* √©, portanto, um processo assint√≥tico, que implica que, mesmo com um n√∫mero muito grande de √°rvores, a vari√¢ncia n√£o ser√° zero a menos que *œÅ* tamb√©m seja zero (ou pelo menos tenda a zero). Em outras palavras, adicionar mais √°rvores leva a uma diminui√ß√£o da vari√¢ncia, mas a redu√ß√£o m√°xima √© limitada pelo n√≠vel de *de-correla√ß√£o* entre as √°rvores, que √© controlado pela escolha de *m*. Se *œÅ* √© alto, o aumento de *B* trar√° um benef√≠cio marginal, e √© por isso que o m√©todo de escolha de *m* e a sele√ß√£o aleat√≥ria de vari√°veis s√£o t√£o importantes para o sucesso de um *Random Forest*.

```mermaid
graph LR
    subgraph "Impact of Number of Trees B"
        direction TB
        A["Increasing the number of trees B"]
        B["Term (1 - œÅ) / B approaches zero as B increases"]
        C["Variance converges to œÅœÉ¬≤"]
        D["Correlation œÅ not affected by B directly but by m"]
        E["Higher B has marginal impact if œÅ is high"]
        A --> B
        A --> C
        B --> C
        C --> D
        D --> E
    end
```

> üí° **Exemplo Num√©rico:** Suponha que tenhamos √°rvores com $\sigma^2=4$ e $\rho = 0.6$.
> *   **B = 10:** $\text{Vari√¢ncia} = 4 \times (0.6 + \frac{1 - 0.6}{10}) = 4 \times (0.6 + 0.04) = 2.56$
> *   **B = 100:** $\text{Vari√¢ncia} = 4 \times (0.6 + \frac{1 - 0.6}{100}) = 4 \times (0.6 + 0.004) = 2.416$
> *   **B = 1000:** $\text{Vari√¢ncia} = 4 \times (0.6 + \frac{1 - 0.6}{1000}) = 4 \times (0.6 + 0.0004) = 2.4016$
>
> Observe que o aumento de *B* reduz a vari√¢ncia, mas a redu√ß√£o √© limitada pela correla√ß√£o *œÅ*. Mesmo com B=1000, a vari√¢ncia ainda est√° pr√≥xima de $4 \times 0.6 = 2.4$, que √© o limite quando B tende ao infinito.

### Conclus√£o

A t√©cnica de *Random Forests* √© uma extens√£o poderosa do *bagging*, que reduz a correla√ß√£o entre as √°rvores atrav√©s da sele√ß√£o aleat√≥ria de vari√°veis. A vari√¢ncia do estimador *Random Forest* √© diretamente afetada pela correla√ß√£o das √°rvores e pelo tamanho *m* do subconjunto de vari√°veis selecionado. Ao entender esses mecanismos, podemos ajustar os par√¢metros para otimizar o desempenho do modelo em diferentes contextos. A combina√ß√£o da amostragem *bootstrap* e da sele√ß√£o aleat√≥ria de vari√°veis resulta em um m√©todo robusto com alta capacidade de generaliza√ß√£o e uma vari√¢ncia reduzida quando comparado com o *bagging* e √°rvores de decis√£o individuais. O equil√≠brio entre o vi√©s e a vari√¢ncia √© otimizado, e a correla√ß√£o residual entre as √°rvores, embora n√£o seja zero, √© substancialmente reduzida para uma melhor performance do modelo.

### Footnotes
[^15.1]: "Bagging or bootstrap aggregation (section 8.7) is a technique for reducing the variance of an estimated prediction function. Bagging seems to work especially well for high-variance, low-bias procedures, such as trees." *(Trecho de <Random Forests>)*
[^15.2]: "The essential idea in bagging (Section 8.7) is to average many noisy but approximately unbiased models, and hence reduce the variance... The idea in random forests (Algorithm 15.1) is to improve the variance reduction of bagging by reducing the correlation between the trees, without increasing the variance too much." *(Trecho de <Random Forests>)*
[^15.3]: "Typically values for m are ‚àöp or even as low as 1... In practice the best values for these parameters will depend on the problem, and they should be treated as tuning parameters." *(Trecho de <Random Forests>)*
[^15.4]: "The limiting form (B ‚Üí ‚àû) of the random forest regression estimator is frf(x) = EezT(x; Œò(Z)), where we have made explicit the dependence on the training data Z." *(Trecho de <Random Forests>)*
[^15.5]:  "Varfrf(x) = p(x)œÉ¬≤(x)." *(Trecho de <Random Forests>)*
[^15.8]: "‚Ä¢ p(x) is the sampling correlation between any pair of trees used in the averaging: p(x) = corr[T(x; Œò‚ÇÅ(Œñ)), T(x; Œò2(Œñ))], where O‚ÇÅ(Z) and O2(Z) are a randomly drawn pair of random forest trees grown to the randomly sampled Z; ‚Ä¢ œÉ¬≤(x) is the sampling variance of any single randomly drawn tree, œÉ¬≤(x) = VarT(x; Œò(Œñ))." *(Trecho de <Random Forests>)*
[^15.9]: "Vare,zT(x; (Z)) = VarzEojzT(x; Œò(Œñ)) + EzVare\zT(x; Œò(Œñ)). The second term is the within-Z variance a result of the randomization." *(Trecho de <Random Forests>)*
<!-- END DOCUMENT -->
