## √Årvores como Candidatas para Bagging

```mermaid
graph LR
    subgraph "Ensemble Methods"
        direction TB
        A["Bagging"]
        B["Boosting"]
        C["Random Forests"]
    end
    A --> D["Reduces Variance"]
    B --> E["Weighted Voting of Weak Learners"]
    C --> F["Decorrelated Trees"]
    D --> G["Effective with High Variance Learners (e.g., Decision Trees)"]
    F --> G
```

### Introdu√ß√£o
O conceito de **bagging** ou *bootstrap aggregation* surge como uma t√©cnica para reduzir a vari√¢ncia de uma fun√ß√£o de predi√ß√£o estimada, conforme mencionado em [^15.1]. Este m√©todo se mostra particularmente eficaz em procedimentos de alta vari√¢ncia e baixo vi√©s, como as √°rvores de decis√£o. Em problemas de regress√£o, o bagging envolve ajustar a mesma √°rvore de regress√£o repetidamente em amostras bootstrap dos dados de treinamento, e ent√£o calcular a m√©dia dos resultados. Para classifica√ß√£o, um comit√™ de √°rvores vota na classe predita [^15.1]. Diferentemente do **boosting**, onde um comit√™ de *learners* fracos evolui ao longo do tempo e seus membros votam de forma ponderada, o bagging mant√©m a estrutura de um comit√™ de *learners* independentes, focando na redu√ß√£o de vari√¢ncia [^15.1]. **Random Forests**, introduzido por Breiman em 2001, √© uma modifica√ß√£o substancial do bagging que constr√≥i uma cole√ß√£o de √°rvores decorrelacionadas, com desempenho similar ao boosting em muitos problemas, mas com um processo de treinamento e ajuste mais simples [^15.1]. Este cap√≠tulo explora as caracter√≠sticas e mecanismos dos Random Forests, com √™nfase nas √°rvores como candidatas ideais para o bagging.

### Conceitos Fundamentais

**Conceito 1:** O **problema de classifica√ß√£o** envolve a aloca√ß√£o de observa√ß√µes a categorias ou classes predefinidas. M√©todos lineares de classifica√ß√£o, como LDA e Regress√£o Log√≠stica, fazem suposi√ß√µes sobre a forma das fronteiras de decis√£o, o que pode introduzir vi√©s, especialmente quando as rela√ß√µes entre as vari√°veis n√£o s√£o lineares. √Årvores de decis√£o, por sua vez, podem capturar intera√ß√µes complexas nos dados, mas s√£o propensas a alta vari√¢ncia [^15.1]. O uso de √°rvores em bagging busca mitigar essa alta vari√¢ncia por meio da agrega√ß√£o, sem aumentar o vi√©s.

**Lemma 1:** *A esperan√ßa da m√©dia de B √°rvores geradas por bagging (identicamente distribu√≠das) √© igual √† esperan√ßa de qualquer uma das √°rvores individuais.* Isso significa que o vi√©s das √°rvores em bagging √© igual ao vi√©s de uma √∫nica √°rvore, e a melhoria vem da redu√ß√£o de vari√¢ncia [^15.2]. Formalmente, seja $T_b(x)$ a predi√ß√£o da b-√©sima √°rvore, ent√£o $$E[\frac{1}{B} \sum_{b=1}^B T_b(x)] = E[T_b(x)].$$
> üí° **Exemplo Num√©rico:** Suponha que temos 3 √°rvores (B=3) treinadas em amostras bootstrap diferentes. Para uma dada observa√ß√£o *x*, as predi√ß√µes das √°rvores s√£o: $T_1(x) = 5$, $T_2(x) = 7$, e $T_3(x) = 6$. A predi√ß√£o do bagging √© a m√©dia: $\frac{5 + 7 + 6}{3} = 6$. Se o valor esperado de cada √°rvore individual $E[T_b(x)]$ fosse 6, ent√£o o valor esperado da m√©dia das √°rvores seria tamb√©m 6, conforme expresso no Lemma 1.
```mermaid
graph LR
    subgraph "Bagging Expectation"
        direction TB
        A["Individual Tree Prediction: 'E[T_b(x)]'"]
        B["Averaged Predictions: 'E[1/B * Œ£(T_b(x))]'"]
        A -- "Identically Distributed Trees" --> B
        B -- "Lemma 1: Equality" --> C["'E[1/B * Œ£(T_b(x))] = E[T_b(x)]'"]
    end
```

**Conceito 2:** A **Linear Discriminant Analysis (LDA)** assume que as classes seguem distribui√ß√µes normais com covari√¢ncias iguais. As fronteiras de decis√£o resultantes s√£o lineares. No entanto, essa suposi√ß√£o nem sempre se mant√©m nos dados reais [^4.3]. O uso de LDA, embora simples, pode levar a um modelo com alto vi√©s em cen√°rios n√£o lineares. √Årvores de decis√£o, em contraste, n√£o fazem tais suposi√ß√µes e podem se ajustar a diversas formas de fronteiras de decis√£o, mesmo que de forma complexa e ruidosa [^15.1]. A combina√ß√£o de √°rvores em bagging aborda a instabilidade das √°rvores, sem comprometer a flexibilidade para modelar n√£o-linearidades.

**Corol√°rio 1:** Se as √°rvores individuais em um modelo de bagging s√£o decorrelacionadas, a vari√¢ncia do estimador agregado √© reduzida proporcionalmente ao n√∫mero de √°rvores *B*. Ou seja, se $\text{Var}(T_b(x)) = \sigma^2$ e $\text{Cor}(T_b(x),T_{b'}(x)) = \rho$, ent√£o a vari√¢ncia do estimador de bagging √© dada por $$\text{Var}(\frac{1}{B}\sum_{b=1}^B T_b(x)) = \frac{\sigma^2}{B} + \frac{B-1}{B}\rho\sigma^2$$ que se aproxima de $\rho\sigma^2$ quando $B$ tende ao infinito, indicando que a correla√ß√£o entre as √°rvores limita o benef√≠cio do bagging [^15.2].
> üí° **Exemplo Num√©rico:** Suponha que a vari√¢ncia da predi√ß√£o de cada √°rvore seja $\sigma^2 = 4$ e que a correla√ß√£o entre as √°rvores seja $\rho = 0.5$. Se usarmos 10 √°rvores (B=10), a vari√¢ncia da predi√ß√£o do bagging ser√° $\frac{4}{10} + \frac{9}{10} \times 0.5 \times 4 = 0.4 + 1.8 = 2.2$. Se usarmos 100 √°rvores (B=100), a vari√¢ncia ser√° $\frac{4}{100} + \frac{99}{100} \times 0.5 \times 4 = 0.04 + 1.98 = 2.02$.  Como podemos observar, o aumento no n√∫mero de √°rvores reduz a vari√¢ncia, embora ela se aproxime de $\rho\sigma^2=2$ quando B √© grande, o que mostra como a correla√ß√£o limita a redu√ß√£o da vari√¢ncia.
```mermaid
graph LR
    subgraph "Variance of Bagged Estimator"
        direction TB
        A["Var(T_b(x)) = 'œÉ¬≤'"]
        B["Cor(T_b(x), T_{b'}(x)) = 'œÅ'"]
        C["Variance of Bagged Estimator: 'Var(1/B Œ£(T_b(x))) = œÉ¬≤/B + ((B-1)/B)œÅœÉ¬≤'"]
        A & B --> C
        C --> D["As 'B' increases, variance approaches 'œÅœÉ¬≤'"]
    end
```

**Conceito 3:** A **Regress√£o Log√≠stica** modela a probabilidade de uma observa√ß√£o pertencer a uma classe usando a fun√ß√£o log√≠stica. O modelo assume uma rela√ß√£o linear entre os preditores e o *logit* da probabilidade [^4.4]. Assim como o LDA, a Regress√£o Log√≠stica √© um modelo linear e pode ser inadequado para rela√ß√µes complexas. √Årvores de decis√£o, com sua capacidade de modelar intera√ß√µes, oferecem uma alternativa. A combina√ß√£o de √°rvores em um m√©todo de ensemble como o random forest, aproveita sua capacidade de modelar n√£o-linearidades, ao mesmo tempo que reduz a vari√¢ncia atrav√©s do processo de agrega√ß√£o [^15.1].
> ‚ö†Ô∏è **Nota Importante**: A escolha entre m√©todos lineares como LDA e Regress√£o Log√≠stica ou modelos n√£o lineares como √°rvores de decis√£o depende da estrutura dos dados e da complexidade da rela√ß√£o entre as vari√°veis e a vari√°vel resposta.
> ‚ùó **Ponto de Aten√ß√£o**: Bagging e Random Forests s√£o especialmente √∫teis quando os dados exibem rela√ß√µes n√£o lineares e onde o uso de modelos mais simples podem gerar modelos com alto vi√©s.
> ‚úîÔ∏è **Destaque**: Random Forests, ao introduzir aleatoriedade na sele√ß√£o das vari√°veis em cada divis√£o, consegue reduzir a correla√ß√£o entre as √°rvores, resultando em uma vari√¢ncia menor em compara√ß√£o com o bagging simples [^15.2].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction TB
        A["Classes as Indicator Matrix: 'Y'"]
        B["Linear Regression Model: 'Y = XB + E'"]
        C["Coefficients Estimated: 'B = (X·µÄX)‚Åª¬πX·µÄY'"]
        D["Prediction: '≈∂ = XB'"]
        E["Class Prediction based on '≈∂'"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

A regress√£o linear pode ser aplicada na classifica√ß√£o atrav√©s da regress√£o em matrizes de indicadores, onde cada classe √© representada por uma coluna na matriz, e os valores assumem 0 ou 1 dependendo da classe da observa√ß√£o [^4.2]. Embora esta abordagem possa parecer direta, ela possui limita√ß√µes. O problema principal √© que a regress√£o linear n√£o restringe as predi√ß√µes entre 0 e 1, podendo gerar valores fora desse intervalo, dificultando a interpreta√ß√£o em termos de probabilidades de classe [^4.2]. Al√©m disso, a regress√£o linear minimiza o erro quadr√°tico m√©dio, o que n√£o √© ideal para classifica√ß√£o, onde o objetivo √© maximizar a precis√£o da previs√£o da classe correta [^15.1].

A regress√£o linear com matrizes de indicadores pode ser expressa como:

$$Y = XB + E$$

Onde Y √© a matriz de indicadores, X √© a matriz de preditores, B √© a matriz de coeficientes, e E √© a matriz de erros. Os coeficientes B s√£o estimados via o m√©todo de m√≠nimos quadrados. Em problemas de classifica√ß√£o, essa t√©cnica pode ser inadequada para determinar fronteiras de decis√£o precisas, pois o erro quadr√°tico n√£o √© uma m√©trica diretamente relacionada √† correta classifica√ß√£o.

**Lemma 2:** Em condi√ß√µes ideais, a fronteira de decis√£o obtida por regress√£o linear em uma matriz de indicadores para um problema de classifica√ß√£o bin√°ria √© equivalente √† fronteira de decis√£o de um modelo discriminante linear. Isso ocorre quando as classes s√£o bem separadas e h√° um n√∫mero suficiente de dados, o que leva a que ambas abordagens encontrem hiperplanos de separa√ß√£o similares [^4.2].
**Prova do Lemma 2:** Seja $y_i \in \{0, 1\}$ as classes de resposta, e $x_i$ os preditores. Na regress√£o linear, buscamos minimizar $||Y-XB||^2$, enquanto na an√°lise discriminante linear (LDA) buscamos encontrar um hiperplano que separe as classes. Quando as classes s√£o bem separadas, ambas abordagens tendem a convergir para hiperplanos similares. Na regress√£o linear, temos:

$$ \hat{Y} = XB\qquad \text{onde} \quad B = (X^T X)^{-1}X^TY $$

e na LDA, o hiperplano √© dado por:

$$ w^T x + b = 0  $$

onde $w$ e $b$ s√£o par√¢metros do discriminante linear. Quando as classes s√£o linearmente separ√°veis e as vari√¢ncias s√£o iguais, $w$ e $b$ obtidos pela LDA e os coeficientes B da regress√£o linear se relacionam de tal maneira que o mesmo hiperplano de decis√£o √© gerado, estabelecendo a equival√™ncia sob certas condi√ß√µes. $\blacksquare$
> üí° **Exemplo Num√©rico:** Vamos considerar um exemplo simples com duas classes e dois preditores. Suponha que temos as seguintes observa√ß√µes:
> Classe 0: (1, 1), (2, 1), (1, 2)
> Classe 1: (2, 3), (3, 2), (3, 3)
> A matriz de indicadores Y teria as linhas [1, 0], [1, 0], [1, 0], [0, 1], [0, 1], [0, 1]. A matriz X teria as linhas [1, 1], [2, 1], [1, 2], [2, 3], [3, 2], [3, 3]. Ao aplicar a regress√£o linear, vamos encontrar uma matriz B que minimiza o erro quadr√°tico, e que sob a condi√ß√£o de separabilidade linear,  fornecer√° um hiperplano de separa√ß√£o similar ao que seria encontrado por LDA.
```python
import numpy as np
from sklearn.linear_model import LinearRegression
X = np.array([[1, 1], [2, 1], [1, 2], [2, 3], [3, 2], [3, 3]])
Y = np.array([[1, 0], [1, 0], [1, 0], [0, 1], [0, 1], [0, 1]])

model = LinearRegression()
model.fit(X,Y)

print("Coeficientes B:\n", model.coef_)
print("Intercepto:\n", model.intercept_)

```
> A sa√≠da deste c√≥digo mostra os coeficientes que definem o hiperplano de separa√ß√£o.

**Corol√°rio 2:** Como a regress√£o linear pode ser interpretada como uma forma de discriminante linear, suas limita√ß√µes em modelar n√£o-linearidades tamb√©m se aplicam a esse contexto. Ou seja, se as classes n√£o s√£o linearmente separ√°veis, ou se as rela√ß√µes entre as vari√°veis n√£o forem lineares, a regress√£o linear em matrizes de indicadores ter√° um desempenho sub√≥timo [^4.2]. Isso ressalta a import√¢ncia de m√©todos mais flex√≠veis, como as √°rvores de decis√£o, e da necessidade de t√©cnicas como bagging para reduzir a alta vari√¢ncia dessas √°rvores [^15.1].

A regress√£o de indicadores, embora √∫til para introduzir conceitos b√°sicos, pode levar a extrapola√ß√µes fora do intervalo [0,1], especialmente quando aplicada em conjunto com modelos lineares. O uso de m√©todos mais flex√≠veis, como √°rvores de decis√£o e random forests, torna-se essencial para obter modelos robustos e precisos em problemas complexos de classifica√ß√£o [^15.1].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["L1 Regularization"]
        B["L2 Regularization"]
        C["Elastic Net Regularization"]
        D["Random Forests (Variable Selection)"]
    end
    A --> E["Induces Sparsity"]
    B --> F["Shrinks Coefficients"]
    C --> G["Balance between Sparsity and Coefficient Shrinkage"]
    D --> H["Random Variable Selection for Decorrelation"]
    E --> I["Reduces Overfitting"]
    F --> I
    G --> I
    H --> I
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas cruciais para melhorar a generaliza√ß√£o de modelos de classifica√ß√£o e para evitar o overfitting [^4.4.4], [^4.5]. Modelos complexos com muitas vari√°veis tendem a se ajustar ao ru√≠do nos dados de treinamento, perdendo a capacidade de generalizar para novos dados. A regulariza√ß√£o L1 adiciona uma penalidade √† soma dos valores absolutos dos coeficientes no modelo. Isso tende a gerar modelos esparsos, onde muitos coeficientes s√£o exatamente zero, efetivamente realizando sele√ß√£o de vari√°veis [^4.4.4]. A regulariza√ß√£o L2, por outro lado, adiciona uma penalidade √† soma dos quadrados dos coeficientes, o que tende a encolher todos os coeficientes em dire√ß√£o a zero sem gerar esparsidade completa. A combina√ß√£o dessas duas penalidades resulta no *Elastic Net*, que busca um equil√≠brio entre esparsidade e redu√ß√£o dos coeficientes [^4.5].

No contexto da Regress√£o Log√≠stica, a fun√ß√£o de custo penalizada pela regulariza√ß√£o L1 pode ser escrita como:

$$-\frac{1}{N} \sum_{i=1}^{N} [y_i \log(p_i) + (1 - y_i)\log(1 - p_i)] + \lambda \sum_{j=1}^{p} |\beta_j|$$

Onde $p_i$ √© a probabilidade predita, $y_i$ √© o valor da classe (0 ou 1), $\beta_j$ s√£o os coeficientes do modelo, e $\lambda$ √© o par√¢metro de regulariza√ß√£o que controla o balan√ßo entre ajuste aos dados e esparsidade dos coeficientes.
> üí° **Exemplo Num√©rico:** Suponha que estamos ajustando um modelo de regress√£o log√≠stica com regulariza√ß√£o L1. A fun√ß√£o de custo sem regulariza√ß√£o √© o erro log√≠stico (cross-entropy). Ao adicionarmos a regulariza√ß√£o L1, a fun√ß√£o de custo √© modificada. Vamos considerar um cen√°rio com dois preditores e um par√¢metro de regulariza√ß√£o $\lambda=0.5$. Os coeficientes s√£o $\beta_1 = 2$ e $\beta_2 = -1$. A penalidade L1 √© dada por $\lambda(|\beta_1| + |\beta_2|) = 0.5 \times (|2| + |-1|) = 1.5$.  Quando otimizamos o modelo, a regulariza√ß√£o L1 for√ßa os coeficientes a serem menores. Em um cen√°rio onde $\beta_1$ √© um coeficiente menos importante, a regulariza√ß√£o L1 poderia eventualmente zerar $\beta_1$, deixando um modelo esparso com apenas $\beta_2$ como preditor relevante.
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import accuracy_score
>
> # Gerando dados sint√©ticos
> np.random.seed(42)
> X = np.random.rand(100, 10)
> y = np.random.randint(0, 2, 100)
>
> # Dividindo os dados em treino e teste
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
>
> # Treinando um modelo de regress√£o log√≠stica sem regulariza√ß√£o
> model_no_reg = LogisticRegression(penalty=None, solver='lbfgs')
> model_no_reg.fit(X_train, y_train)
> y_pred_no_reg = model_no_reg.predict(X_test)
>
> # Treinando um modelo com regulariza√ß√£o L1
> model_l1_reg = LogisticRegression(penalty='l1', C=0.5, solver='liblinear') # C √© o inverso de lambda
> model_l1_reg.fit(X_train, y_train)
> y_pred_l1_reg = model_l1_reg.predict(X_test)
>
>
> print("Acur√°cia sem regulariza√ß√£o:", accuracy_score(y_test, y_pred_no_reg))
> print("Acur√°cia com regulariza√ß√£o L1:", accuracy_score(y_test, y_pred_l1_reg))
> print("Coeficientes sem regulariza√ß√£o:", model_no_reg.coef_)
> print("Coeficientes com regulariza√ß√£o L1:", model_l1_reg.coef_)
> ```
> Este c√≥digo exemplifica como a regulariza√ß√£o L1 pode zerar alguns coeficientes (tornando o modelo esparso), o que facilita a interpreta√ß√£o e pode melhorar a generaliza√ß√£o, embora possa sacrificar a acur√°cia em alguns casos. A escolha de lambda (C) √© crucial e deve ser feita por valida√ß√£o cruzada.

**Lemma 3:** A penaliza√ß√£o L1 em modelos de classifica√ß√£o log√≠stica induz esparsidade nos coeficientes do modelo, ou seja, muitos coeficientes tornam-se exatamente zero.
**Prova do Lemma 3:** A penaliza√ß√£o L1 tem a forma $\lambda \sum_{j=1}^p |\beta_j|$. Ao tentar minimizar a fun√ß√£o de custo com essa penalidade, a derivada da penalidade em rela√ß√£o a $\beta_j$ √© $\lambda \cdot \text{sign}(\beta_j)$. Essa fun√ß√£o derivada n√£o √© zero em $\beta_j = 0$, logo durante o processo de otimiza√ß√£o, quando um $\beta_j$ se aproxima de zero, a otimiza√ß√£o √© induzida a torna-lo exatamente zero, pois o gradiente da fun√ß√£o de custo (incluindo a penalidade) n√£o √© zero nesse ponto. Isso gera um modelo com muitos $\beta_j$ iguais a zero, o que caracteriza a esparsidade [^4.4.4]. $\blacksquare$

**Corol√°rio 3:** A esparsidade induzida pela regulariza√ß√£o L1 facilita a interpreta√ß√£o do modelo, pois as vari√°veis com coeficientes zero n√£o contribuem para a predi√ß√£o, revelando as vari√°veis mais relevantes para a classifica√ß√£o. Isso auxilia na compreens√£o do processo e das rela√ß√µes nos dados [^4.4.5].

Random forests utilizam uma estrat√©gia diferente para evitar o overfitting, baseada na sele√ß√£o aleat√≥ria de vari√°veis em cada divis√£o da √°rvore. Ao inv√©s de considerar todas as vari√°veis para a divis√£o, um subconjunto aleat√≥rio de *m* vari√°veis √© selecionado como candidato. Esse processo de sele√ß√£o aleat√≥ria induz uma descorrela√ß√£o entre as √°rvores, o que resulta em uma redu√ß√£o da vari√¢ncia no modelo agregado [^15.2].
> ‚ö†Ô∏è **Ponto Crucial**: A regulariza√ß√£o L1 e L2, assim como a sele√ß√£o aleat√≥ria de vari√°veis em Random Forests, s√£o ferramentas essenciais para evitar o overfitting e construir modelos de classifica√ß√£o robustos.

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Perceptron Learning"
        direction TB
        A["Initial Weights 'w' and bias 'b'"]
        B["For each data point 'x_i', with class 'y_i'"]
        C["Calculate 'w·µÄx_i + b'"]
        D["If misclassified: Update 'w' and 'b'"]
        E["Iterate until convergence or max iterations"]
        A --> B
        B --> C
        C -- "Misclassified" --> D
        C -- "Correctly classified" --> B
        D --> B
        B --> E
    end
```

A ideia de maximizar a margem de separa√ß√£o em classificadores lineares leva ao conceito de hiperplanos separadores √≥timos [^4.5.2]. Em um problema de classifica√ß√£o bin√°ria, o objetivo √© encontrar um hiperplano que separe as duas classes de forma que a dist√¢ncia (margem) entre o hiperplano e os pontos de dados mais pr√≥ximos de cada classe seja a maior poss√≠vel. Este hiperplano √© definido por uma fun√ß√£o linear:
$$w^Tx+b = 0$$
onde *w* √© o vetor de pesos, *x* √© o vetor de caracter√≠sticas e *b* √© o bias. A ideia de maximiza√ß√£o da margem leva a um problema de otimiza√ß√£o quadr√°tica, no qual procuramos maximizar a margem e garantir que todos os pontos de dados estejam corretamente classificados [^4.5.2].

O Perceptron de Rosenblatt √© um algoritmo para aprendizado de um hiperplano separador linear. Ele itera sobre os dados, atualizando o vetor de pesos *w* e o bias *b* quando encontra um ponto mal classificado. O algoritmo tem converg√™ncia garantida sob a hip√≥tese de separabilidade linear, o que significa que, se existir um hiperplano que separe perfeitamente as classes, o Perceptron o encontrar√° em um n√∫mero finito de itera√ß√µes [^4.5.1]. No entanto, se os dados n√£o s√£o linearmente separ√°veis, o algoritmo n√£o converge, e este √© um dos principais motivos pelos quais m√©todos como √°rvores de decis√£o e Random Forests s√£o t√£o importantes [^15.1].
> üí° **Exemplo Num√©rico:** Vamos simular um problema de classifica√ß√£o bin√°ria com dados linearmente separ√°veis: Classe 1: (1, 1), (2, 2), (3, 1); Classe 2: (4, 4), (5, 5), (6, 4). O perceptron itera atualizando os pesos de forma a encontrar um hiperplano que separe os dados. Vamos ilustrar uma poss√≠vel itera√ß√£o:
> 1. Inicializa√ß√£o: $w = [0, 0]$, $b=0$.
> 2. Processa ponto (1,1) - Classe 1:  $w^Tx + b = 0*1 + 0*1 + 0 = 0$.  Como 0 < 0 (crit√©rio de classifica√ß√£o errado), atualizamos $w = w + x = [1, 1]$ e $b = b+1 = 1$.
> 3. Processa ponto (4,4) - Classe 2: $w^Tx + b = 1*4 + 1*4 + 1 = 9$. Como 9 > 0 (classificado como classe 1, que est√° incorreto), atualizamos $w = w - x = [-3, -3]$ e $b = b - 1 = 0$.
> Este processo continua at√© que todos os pontos sejam classificados corretamente.
> ```python
> import numpy as np
>
> class Perceptron:
>    def __init__(self, learning_rate=0.1, n_iterations=100):
>        self.learning_rate = learning_rate
>        self.n_iterations = n_iterations
>        self.weights = None
>        self.bias = None
>    def fit(self, X, y):
>        self.weights = np.zeros(X.shape[1])
>        self.bias = 0
>        for _ in range(self.n_iterations):
>          errors = 0
>          for xi, yi in zip(X, y):
>            if (np.dot(xi, self.weights) + self.bias) > 0 :
>              prediction = 1
>            else:
>              prediction = -1
>            if prediction != yi:
>                errors += 1
>                self.weights += self.learning_rate * yi * xi
>                self.bias += self.learning_rate * yi
>          if errors == 0:
>            break
>    def predict(self, X):
>      predictions = []
>      for xi in X:
>        if np.dot(xi, self.weights) + self.bias > 0:
>          predictions.append(1)
>        else:
>          predictions.append(-1)
>      return np.array(predictions)
>
>
> X = np.array([[1, 1], [2, 2], [3, 1], [4, 4], [5, 5], [6, 4]])
> y = np.array([1, 1, 1, -1, -1, -1])
>
> perceptron = Perceptron()
> perceptron.fit(X,y)
>
> test_X = np.array([[2,1],[5,6]])
> predictions = perceptron.predict(test_X)
> print("Pesos:", perceptron.weights)
> print("Bias:", perceptron.bias)
> print("Predi√ß√µes:", predictions)
> ```
> Este exemplo mostra como o perceptron aprende um hiperplano separador por meio de ajustes iterativos dos pesos e do bias, at√© classificar corretamente os pontos de treinamento. Em casos n√£o linearmente separ√°veis, o perceptron n√£o convergir√° para uma solu√ß√£o.

### Pergunta Te√≥rica Avan√ßada (Exemplo): Qual a rela√ß√£o entre a escolha do par√¢metro *m* em random forests e a complexidade e variabilidade do modelo?
```mermaid
graph LR
    subgraph "Impact of 'm' in Random Forests"
        direction TB
        A["High 'm' (close to 'p')"]
        B["Low 'm'"]
        C["Intermediate 'm'"]
    end
    A --> D["More correlated trees"]
    A --> E["Higher variance"]
    A --> F["Lower bias"]
    B --> G["Less correlated trees"]
    B --> H["Lower variance"]
    B --> I["Potentially higher bias"]
    C --> J["Balance of variance and bias"]
    D & E & F --> K["Model Complexity Considerations"]
    G & H & I --> K
    J --> K
```

**Resposta:**
Em Random Forests, o par√¢metro *m* controla o n√∫mero de vari√°veis candidatas a serem consideradas em cada divis√£o de uma √°rvore. Se *m* √© pr√≥ximo de *p*, o n√∫mero total de vari√°veis, as √°rvores tendem a ficar mais correlacionadas, com maior vari√¢ncia e menor vi√©s. Isso ocorre porque cada √°rvore ter√° acesso a quase todas as mesmas vari√°veis para cada divis√£o, levando a uma alta similaridade entre as √°rvores. Por outro lado, um valor pequeno de *m* induz √°rvores mais diversas e menos correlacionadas, resultando em menor vari√¢ncia no modelo agregado, mas com um potencial aumento do vi√©s [^15.2].

**Lemma 4:** A escolha de um valor muito pequeno de *m* aumenta a variabilidade da *contribui√ß√£o individual* de cada vari√°vel em cada √°rvore, o que pode levar a um modelo com maior vi√©s.
**Prova do Lemma 4:**  Quando m √© pequeno, cada √°rvore vai usar um n√∫mero muito reduzido de vari√°veis, sem incluir muitas vezes as vari√°veis relevantes, o que impede que a √°rvore se ajuste apropriadamente aos dados. Logo a previs√£o individual de cada √°rvore √© mais enviesada. $\blacksquare$

**Corol√°rio 4:** A escolha de um valor de *m* intermedi√°rio busca um equil√≠brio entre a redu√ß√£o da correla√ß√£o entre as √°rvores (para diminuir a vari√¢ncia) e a inclus√£o de vari√°veis relevantes (para reduzir o vi√©s). Um bom valor de *m* √© um hiperpar√¢metro que precisa ser ajustado usando valida√ß√£o cruzada ou outros m√©todos de ajuste de hiperpar√¢metros [^15.3].
> üí° **Exemplo Num√©rico:** Suponha que temos um problema de classifica√ß√£o com 10 vari√°veis (p=10). Se escolhermos $m=1$, cada √°rvore na random forest considerar√° apenas uma vari√°vel aleat√≥ria a cada divis√£o. Isso resultar√° em √°rvores muito diversas, e possivelmente com alto vi√©s, pois elas perdem a oportunidade de combinar informa√ß√µes de vari√°veis relevantes que n√£o est√£o selecionadas. Se escolhermos $m=9$, as √°rvores ter√£o acesso a quase todas as vari√°veis em cada divis√£o, resultando em √°rvores muito similares e correlacionadas. Uma escolha intermedi√°ria como $m=3$ busca um equil√≠brio entre diversidade e utiliza√ß√£o de vari√°veis relevantes. Usar valida√ß√£o cruzada para encontrar o valor ideal de m √© fundamental.
> ```python
> import numpy as np
> from sklearn.ensemble import RandomForestClassifier
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import accuracy_score
>
> # Gerando dados sint√©ticos
> np.random.seed(42)
> X = np.random.rand(100, 10)
> y = np.random.randint(0, 2, 100)
>
> # Dividindo os dados em treino e teste
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
>
> # Treinando modelos com diferentes valores de m
> model_m1 = RandomForestClassifier(max_features=1, random_state=42)
> model_m1.fit(X_train, y_train)
> y_pred_m1 = model_m1.predict(X_test)
>
> model_m3 = RandomForestClassifier(max_features=3, random_state=42)
> model_m3.fit(X_train, y_train)
> y_pred_m3 = model_m3.predict(X_test)
>
> model_m9 = RandomForestClassifier(max_features=9, random_state=42)
> model_m9.fit(X_train, y_train)
> y_pred_m9 = model_m9.predict(X_test)
>
> print("Acur√°cia com m=1:", accuracy_score(y_test, y_pred_m1))
> print("Acur√°cia com m=3:", accuracy_score(y_test, y_pred_m3))
> print("Acur√°cia com m=9:", accuracy_score(y_test, y_pred_m9))
> ```
> Este exemplo mostra como diferentes valores de *m* podem afetar a acur√°cia de um modelo Random Forest. O valor ideal depende da estrutura dos dados.

> ‚ö†Ô∏è **Ponto Crucial**: A escolha do par√¢metro *m* em random forests √© crucial para equilibrar o vi√©s e a vari√¢ncia do modelo. Valores muito altos de *m* levam a modelos mais similares entre si, com alta vari√¢ncia, e valores muito baixos de *m* levam a modelos enviesados e pouco adaptados aos dados.

### Conclus√£o

As √°rvores de decis√£o, com sua capacidade de capturar intera√ß√µes complexas e n√£o-linearidades, s√£o candidatas ideais para o bagging, e especialmente para o random forest. A combina√ß√£o da flexibilidade das √°rvores com t√©cnicas de agrega√ß√£o, e em particular a randomiza√ß√£o na sele√ß√£o de vari√°veis do random forest, leva a modelos robustos e de alta precis√£o, com baixa vari√¢ncia e vi√©s adequadamente balanceado, que se destacam em diversas aplica√ß√µes [^15.1].

### Refer√™ncias
[^15.1]: "Bagging or bootstrap aggregation (section 8.7) is a technique for reducing the variance of an estimated prediction function. Bagging seems to work especially well for high-variance, low-bias procedures, such as trees. For regression, we simply fit the same regression tree many times to bootstrap-sampled versions of the training data, and average the result. For classification, a committee of trees each cast a vote for the predicted class. Boosting in Chapter 10 was initially proposed as a committee method as well, although unlike bagging, the committee of weak learners evolves over time, and the members cast a weighted vote. Boosting appears to dominate bagging on most problems, and became the preferred choice. Random forests (Breiman, 2001) is a substantial modification of bagging that builds a large collection of de-correlated trees, and then averages them. On many problems the performance of random forests is very similar to boosting, and they are simpler to train and tune. As a consequence, random forests are popular, and are implemented in a variety of packages." *(Trecho de <Random Forests>)*
[^15.2]: "The essential idea in bagging (Section 8.7) is to average many noisy but approximately unbiased models, and hence reduce the variance. Trees are ideal candidates for bagging, since they can capture complex interaction structures in the data, and if grown sufficiently deep, have relatively low bias. Since trees are notoriously noisy, they benefit greatly from the averaging. Moreover, since each tree generated in bagging is identically distributed (i.d.), the expectation of an average of B such trees is the same as the expectation of any one of them. This means the bias of bagged trees is the same as that of the individual trees, and the only hope of improvement is through variance reduction. This is in contrast to boosting, where the trees are grown in an adaptive way to remove bias, and hence are not i.d. An average of B i.i.d. random variables, each with variance œÉ¬≤, has variance œÉ¬≤/B. If the variables are simply i.d. (identically distributed, but not necessarily independent) with positive pairwise correlation œÅ, the variance of the average is (Exercise 15.1) œÉ¬≤/B + (1-1/B)œÅœÉ¬≤. As B increases, the second