## Boosting e Bagging: Uma An√°lise Comparativa
```mermaid
flowchart LR
    subgraph "Bagging"
        A["Bootstrap Samples"] --> B["Train Multiple Trees"]
        B --> C["Aggregate Predictions (Averaging/Voting)"]
    end
    subgraph "Boosting"
        D["Sequential Training"] --> E["Weighted Weak Learners"]
        E --> F["Combine Weighted Predictions"]
        F --> G["Adaptive Weights"]
        G --> D
    end
    C --> H("Final Prediction - Bagging")
    F --> I("Final Prediction - Boosting")
    H & I --> J("Compare Performance")
```

### Introdu√ß√£o

O objetivo principal de m√©todos de aprendizado como **Boosting** e **Bagging** √© reduzir a vari√¢ncia de um modelo de predi√ß√£o estimado. O **Bagging** (ou *bootstrap aggregation*) √© uma t√©cnica que funciona especialmente bem para procedimentos com alta vari√¢ncia e baixo vi√©s, como √°rvores de decis√£o [^15.1]. J√° o **Boosting**, embora tamb√©m seja um m√©todo de comit√™, evolui seus aprendizes fracos ao longo do tempo, atribuindo votos ponderados [^15.1]. Embora o Boosting tenha se mostrado superior ao Bagging em muitos casos, os Random Forests, uma modifica√ß√£o substancial do Bagging, surgem como uma alternativa popular por sua simplicidade de treinamento e ajuste [^15.1].

### Conceitos Fundamentais

**Conceito 1:** O **problema da classifica√ß√£o** consiste em atribuir uma classe a uma determinada observa√ß√£o, baseado em um conjunto de *features*. M√©todos lineares, embora mais simples, podem apresentar limita√ß√µes em rela√ß√£o √† capacidade de capturar complexidade nos dados [^4.1]. O uso de modelos mais complexos, como √°rvores, leva a um *trade-off* entre vi√©s e vari√¢ncia: modelos complexos podem se ajustar bem aos dados de treinamento (baixo vi√©s), mas s√£o mais propensos a varia√ß√µes em novos dados (alta vari√¢ncia) [^15.1]. O bagging, e em especial os random forests, s√£o estrat√©gias para mitigar essa alta vari√¢ncia.

**Lemma 1:**  *O vi√©s de um ensemble de √°rvores geradas via bagging √© igual ao vi√©s de uma √∫nica √°rvore.* Isso ocorre porque cada √°rvore gerada por bagging √© id√™nticamente distribu√≠da (i.d.) [^15.2]. Formalmente:
$$ E[\frac{1}{B}\sum_{b=1}^{B} T_b(x)] = E[T_b(x)] $$
Onde $T_b(x)$ representa uma √°rvore gerada via bagging e B o n√∫mero total de √°rvores. O averaging n√£o altera o vi√©s, apenas a vari√¢ncia.
```mermaid
graph TB
    subgraph "Lemma 1: Bagging Bias"
      direction TB
        A["E[1/B * Œ£ T_b(x)]"] --> B["E[T_b(x)]"]
        B --> C["Bias is preserved"]
    end
```

> üí° **Exemplo Num√©rico:**
> Suponha que temos um modelo de √°rvore de decis√£o que, em m√©dia, erra a previs√£o do valor de uma vari√°vel alvo por 0.5 unidades (vi√©s). Se aplicarmos Bagging com 100 √°rvores ($B=100$), cada uma treinada em diferentes amostras bootstrap do mesmo conjunto de dados, o vi√©s do modelo Bagging continuar√° sendo de 0.5 unidades, pois o averaging n√£o altera o vi√©s. Ou seja, a m√©dia dos erros ainda √© 0.5, mesmo com a combina√ß√£o de m√∫ltiplas √°rvores. Isso est√° expresso no Lemma 1. No entanto, a vari√¢ncia da previs√£o do modelo ser√° reduzida, fazendo com que as previs√µes sejam mais est√°veis.
>
> Digamos que a vari√¢ncia de uma √°rvore individual √© $\sigma^2=1.0$. Se as √°rvores forem independentes, a vari√¢ncia do ensemble de Bagging ser√° $\sigma^2/B = 1/100 = 0.01$. Isso representa uma redu√ß√£o dr√°stica na vari√¢ncia, sem alterar o vi√©s.

**Conceito 2:** A **Linear Discriminant Analysis (LDA)** busca encontrar uma combina√ß√£o linear de *features* que separe melhor as classes, assumindo que as classes seguem distribui√ß√µes normais com covari√¢ncias semelhantes [^4.3]. J√° o **Bagging**, por sua vez, n√£o faz essas suposi√ß√µes e utiliza bootstrapping para criar m√∫ltiplos conjuntos de treinamento e treinar v√°rias √°rvores, combinando suas previs√µes para reduzir a vari√¢ncia [^15.1].
```mermaid
flowchart LR
    subgraph "LDA Assumptions"
        A["Gaussian distributions"] --> B["Equal covariance matrices"]
    end
    subgraph "Bagging Assumptions"
        C["No distribution assumptions"]
        C --> D["Bootstrap sampling"]
    end
    B --> E["Find Linear Combinations (LDA)"]
    D --> F["Train Multiple Trees (Bagging)"]
    E --> G("Class Separation")
    F --> G
```

**Corol√°rio 1:** A combina√ß√£o de previs√µes no Bagging n√£o melhora o vi√©s, apenas reduz a vari√¢ncia. A expectativa da m√©dia de B √°rvores i.d. √© a mesma da expectativa de uma √∫nica √°rvore [^15.2].

**Conceito 3:** A **Logistic Regression** modela a probabilidade de pertencimento a uma classe por meio de uma fun√ß√£o sigmoide aplicada a uma combina√ß√£o linear de *features*, otimizando os par√¢metros via maximiza√ß√£o da verossimilhan√ßa [^4.4]. O **Boosting**, ao contr√°rio do Bagging, ajusta sequencialmente as √°rvores, dando pesos maiores aos exemplos mal classificados e construindo uma combina√ß√£o ponderada dessas √°rvores [^15.1].

> ‚ö†Ô∏è **Nota Importante**: O Boosting evolui seus aprendizes fracos ao longo do tempo, atribuindo votos ponderados, diferentemente do Bagging, que usa uma m√©dia simples ou um voto majorit√°rio [^15.1].

> ‚ùó **Ponto de Aten√ß√£o**: O Boosting tem o potencial de reduzir tanto o vi√©s quanto a vari√¢ncia, enquanto o Bagging √© eficaz principalmente na redu√ß√£o da vari√¢ncia [^15.2].

> ‚úîÔ∏è **Destaque**: Random Forests s√£o uma modifica√ß√£o do Bagging que utilizam a sele√ß√£o aleat√≥ria de vari√°veis para diminuir a correla√ß√£o entre √°rvores, melhorando ainda mais a redu√ß√£o da vari√¢ncia [^15.2].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
flowchart TD
  subgraph "Regress√£o de Indicadores"
    A["Codificar Classes"] --> B["Estimar Coeficientes via LS"]
    B --> C["Aplicar Regra de Decis√£o"]
    C --> D["Analisar Limita√ß√µes"]
  end
```
**Explica√ß√£o:** Este diagrama mostra o fluxo da regress√£o de indicadores e suas etapas.

A regress√£o linear, quando aplicada a uma matriz de indicadores, busca estimar os coeficientes que melhor separam as classes, utilizando o m√©todo de **m√≠nimos quadrados**. No entanto, essa abordagem pode apresentar limita√ß√µes, especialmente quando as classes n√£o s√£o linearmente separ√°veis [^4.2]. Al√©m disso, a regress√£o linear pode produzir resultados fora do intervalo [0,1], quando utilizada para classifica√ß√£o [^4.2]. Embora eficaz em alguns contextos, a regress√£o de indicadores pode ser menos robusta do que m√©todos probabil√≠sticos como a regress√£o log√≠stica em cen√°rios complexos [^4.4].

> üí° **Exemplo Num√©rico:**
> Vamos considerar um problema de classifica√ß√£o bin√°ria com duas classes, 0 e 1, onde temos duas *features*, $x_1$ e $x_2$. Para aplicar regress√£o linear para classifica√ß√£o, codificamos a classe 0 como 0 e a classe 1 como 1. A matriz de design $X$ cont√©m os valores de $x_1$ e $x_2$ para cada amostra, junto com uma coluna de 1 para o intercepto. A vari√°vel resposta $y$ cont√©m os r√≥tulos de classe (0 ou 1). Suponha que temos os seguintes dados:
>
> $X = \begin{bmatrix} 1 & 2 & 3 \\ 1 & 3 & 1 \\ 1 & 4 & 4 \\ 1 & 5 & 2 \\ 1 & 1 & 2 \end{bmatrix}$ e $y = \begin{bmatrix} 0 \\ 0 \\ 1 \\ 1 \\ 0 \end{bmatrix}$
>
> Usando m√≠nimos quadrados para estimar os coeficientes $\beta$, resolvemos a equa√ß√£o normal: $\beta = (X^T X)^{-1} X^T y$.
>
> Primeiro, calculamos $X^T X$:
> $X^T X = \begin{bmatrix} 5 & 15 & 12 \\ 15 & 55 & 43 \\ 12 & 43 & 34 \end{bmatrix}$
>
> Em seguida, calculamos $(X^T X)^{-1}$:
> $(X^T X)^{-1} \approx \begin{bmatrix} 0.989 & -0.438 & -0.219 \\ -0.438 & 0.219 & 0.017 \\ -0.219 & 0.017 & 0.109 \end{bmatrix}$
>
> Agora, calculamos $X^T y$:
> $X^T y = \begin{bmatrix} 2 \\ 9 \\ 8 \end{bmatrix}$
>
> Finalmente, estimamos os coeficientes $\beta$:
> $\beta = (X^T X)^{-1} X^T y = \begin{bmatrix} 0.989 & -0.438 & -0.219 \\ -0.438 & 0.219 & 0.017 \\ -0.219 & 0.017 & 0.109 \end{bmatrix} \begin{bmatrix} 2 \\ 9 \\ 8 \end{bmatrix} \approx \begin{bmatrix} -1.62 \\ 0.77 \\ 0.20 \end{bmatrix}$
>
> Portanto, a equa√ß√£o de regress√£o linear √© aproximadamente:
> $\hat{y} = -1.62 + 0.77x_1 + 0.20x_2$
>
> Para classificar uma nova amostra, usamos uma regra de decis√£o: se $\hat{y} > 0.5$, classificamos como classe 1; caso contr√°rio, como classe 0. Note que $\hat{y}$ pode ser um valor fora do intervalo [0, 1], o que √© uma limita√ß√£o da regress√£o linear para classifica√ß√£o.

**Lemma 2:** *Em certas condi√ß√µes, as proje√ß√µes nos hiperplanos de decis√£o geradas pela regress√£o linear podem ser equivalentes √†s proje√ß√µes obtidas por discriminantes lineares.* Formalmente, isso pode ser demonstrado atrav√©s da an√°lise das matrizes de proje√ß√£o e das matrizes de covari√¢ncia das classes [^4.3].

**Corol√°rio 2:** Essa equival√™ncia simplifica a an√°lise e permite uma melhor compreens√£o da rela√ß√£o entre m√©todos baseados em m√≠nimos quadrados e m√©todos discriminantes [^4.3].
No entanto, em cen√°rios mais complexos, √© essencial considerar as limita√ß√µes da regress√£o de indicadores e analisar alternativas como a regress√£o log√≠stica.
‚ÄúEm alguns cen√°rios, a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1].‚Äù [^4.4]
‚ÄúNo entanto, h√° situa√ß√µes em que a regress√£o de indicadores √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear.‚Äù [^4.2]

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
```mermaid
graph LR
    subgraph "Regularization Techniques"
      direction LR
        A["L1 Regularization"] --> B["Promotes Sparsity"]
        C["L2 Regularization"] --> D["Shrinks Coefficients"]
        E["Elastic Net"] --> F["Combines L1 and L2"]
    end
    B --> G("Feature Selection")
    D --> H("Stability")
    F --> I("Balance of Sparsity and Stability")
```
A regulariza√ß√£o √© uma t√©cnica essencial para evitar o *overfitting* em modelos de classifica√ß√£o, adicionando um termo de penalidade √† fun√ß√£o de custo. A regulariza√ß√£o L1 promove a esparsidade, levando alguns coeficientes a zero, enquanto a regulariza√ß√£o L2 encolhe todos os coeficientes em dire√ß√£o a zero [^4.4.4]. M√©todos como o Elastic Net combinam ambas as penalidades, visando tanto a esparsidade quanto a estabilidade [^4.5].

**Lemma 3:** *A penaliza√ß√£o L1 na classifica√ß√£o log√≠stica induz coeficientes esparsos.* Isso pode ser demonstrado analisando a otimiza√ß√£o da fun√ß√£o de custo com penaliza√ß√£o L1, que leva a solu√ß√µes onde alguns coeficientes s√£o nulos [^4.4.4].
```mermaid
graph TB
    subgraph "Lemma 3: L1 Sparsity"
    direction TB
    A["Cost Function: J(Œ≤)"] --> B["L1 Penalty: ŒªŒ£|Œ≤_j|"]
    B --> C["Non-differentiable at zero"]
    C --> D["Some coefficients become zero"]
    D --> E["Sparse solution"]
    end
```
**Prova do Lemma 3:** A fun√ß√£o de custo com penaliza√ß√£o L1 √©:
$$ J(\beta) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(p_i) + (1-y_i) \log(1-p_i)] + \lambda \sum_{j=1}^{p} |\beta_j| $$
onde o termo  $ \lambda \sum_{j=1}^{p} |\beta_j| $ penaliza a magnitude dos coeficientes, levando a solu√ß√µes esparsas. A n√£o-diferenciabilidade da norma L1 no zero induz uma solu√ß√£o onde alguns coeficientes s√£o exatamente zero, selecionando as vari√°veis mais relevantes [^4.4.3]. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o bin√°ria usando regress√£o log√≠stica com duas features, $x_1$ e $x_2$. Os coeficientes estimados sem regulariza√ß√£o s√£o $\beta_0 = -2$, $\beta_1 = 1.5$, e $\beta_2 = 0.8$. A fun√ß√£o de custo original (sem regulariza√ß√£o) pode levar a *overfitting*.
>
> Agora, aplicamos a regulariza√ß√£o L1 com $\lambda = 0.5$. A fun√ß√£o de custo agora inclui um termo de penalidade:
> $$ J(\beta) = \text{fun√ß√£o de custo original} + 0.5(|\beta_1| + |\beta_2|) $$
>
> Ao otimizar esta fun√ß√£o de custo, alguns coeficientes podem ser levados a zero. Por exemplo, os coeficientes estimados ap√≥s regulariza√ß√£o L1 podem ser: $\beta_0 = -1.8$, $\beta_1 = 1.2$ e $\beta_2 = 0.0$. O coeficiente $\beta_2$ foi exatamente zerado, o que indica que a *feature* $x_2$ n√£o √© t√£o relevante quanto $x_1$ para a classifica√ß√£o. Esta √© uma caracter√≠stica da regulariza√ß√£o L1 que induz esparsidade no modelo, simplificando-o e melhorando sua interpretabilidade.
>
> Se utiliz√°ssemos a regulariza√ß√£o L2 com o mesmo lambda, os coeficientes seriam reduzidos, mas n√£o zerados, como por exemplo $\beta_0=-1.9, \beta_1=1.3, \beta_2=0.6$.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.preprocessing import StandardScaler
>
> # Simulated Data
> X = np.array([[1, 2], [2, 3], [3, 1], [4, 3], [5, 2], [1, 1], [2, 2], [3, 3]])
> y = np.array([0, 0, 0, 1, 1, 0, 1, 1])
>
> # Scale Data
> scaler = StandardScaler()
> X_scaled = scaler.fit_transform(X)
>
> # L1 Regularization
> model_l1 = LogisticRegression(penalty='l1', C=1, solver='liblinear', random_state=42)
> model_l1.fit(X_scaled, y)
>
> # L2 Regularization
> model_l2 = LogisticRegression(penalty='l2', C=1, solver='liblinear', random_state=42)
> model_l2.fit(X_scaled,y)
>
> print("L1 Coefficients:", model_l1.coef_)
> print("L2 Coefficients:", model_l2.coef_)
> ```
>
>  A regulariza√ß√£o L1 gera coeficientes esparsos. J√° a regulariza√ß√£o L2 contrai os coeficientes.

**Corol√°rio 3:** A esparsidade resultante da regulariza√ß√£o L1 facilita a interpretabilidade do modelo, identificando as vari√°veis mais importantes para a classifica√ß√£o [^4.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: L1 e L2 podem ser combinadas (Elastic Net) para aproveitar vantagens de ambos os tipos de regulariza√ß√£o [^4.5].

### Separating Hyperplanes e Perceptrons
O conceito de **hiperplano separador** busca definir a fronteira de decis√£o que maximiza a margem entre as classes. A formula√ß√£o deste problema geralmente envolve a otimiza√ß√£o de um funcional que penaliza as classifica√ß√µes incorretas, levando ao problema dual de Wolfe, cujas solu√ß√µes s√£o combina√ß√µes lineares de pontos de suporte [^4.5.2]. O **Perceptron de Rosenblatt**, por sua vez, √© um algoritmo que ajusta os pesos de forma iterativa, garantindo converg√™ncia sob certas condi√ß√µes de separabilidade linear [^4.5.1].

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**
A LDA assume que as classes seguem distribui√ß√µes Gaussianas com covari√¢ncias iguais e estima os par√¢metros a partir dos dados de treinamento, utilizando estes para definir uma fronteira de decis√£o linear [^4.3]. A Regra de Decis√£o Bayesiana tamb√©m busca a melhor decis√£o baseada nas probabilidades a posteriori das classes, onde, sob a mesma hip√≥tese de Gaussianas com covari√¢ncias iguais, tamb√©m leva a uma fronteira linear. Em condi√ß√µes ideais (como par√¢metros populacionais conhecidos) e a mesma suposi√ß√£o, ambas s√£o equivalentes [^4.3]. A diferen√ßa reside na pr√°tica, pois a LDA estima os par√¢metros amostrais, enquanto a Regra Bayesiana assume que estes s√£o conhecidos.

**Lemma 4:**  *Sob a suposi√ß√£o de distribui√ß√µes Gaussianas com covari√¢ncias iguais, a fronteira de decis√£o obtida por LDA √© equivalente √† fronteira de decis√£o Bayesiana.* Isso pode ser demonstrado atrav√©s da an√°lise das fun√ß√µes discriminantes lineares e da formula√ß√£o da regra de decis√£o Bayesiana, mostrando que ambas levam √† mesma fronteira de decis√£o [^4.3], [^4.3.3].
```mermaid
graph LR
    subgraph "Lemma 4: LDA vs. Bayes"
        direction LR
        A["Gaussian Distributions"] --> B["Equal Covariance Matrices"]
        B --> C["LDA Discriminant Function"]
        B --> D["Bayes Decision Rule"]
        C & D --> E["Equivalent Decision Boundary"]
    end
```

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos duas classes, A e B, com distribui√ß√µes Gaussianas. A classe A tem m√©dia $\mu_A = [1, 1]$ e a classe B tem m√©dia $\mu_B = [3, 3]$. Ambas as classes t√™m a mesma matriz de covari√¢ncia $\Sigma = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$.
>
> **LDA:** A LDA estima as m√©dias e a covari√¢ncia a partir de amostras de treinamento e encontra um hiperplano linear que separa as classes. Em nosso exemplo, como as classes t√™m a mesma covari√¢ncia, a fronteira de decis√£o √© uma linha perpendicular √† linha que conecta as m√©dias, aproximadamente no ponto m√©dio, que √© $[2, 2]$.
>
> **Regra de Decis√£o Bayesiana:**  A regra Bayesiana calcula as probabilidades a posteriori de cada classe, dados os dados e a distribui√ß√£o de cada classe. Com distribui√ß√µes Gaussianas e covari√¢ncias iguais, a fronteira de decis√£o tamb√©m √© uma linha reta que passa pelo ponto m√©dio das m√©dias das classes. Assim, neste cen√°rio simplificado, a fronteira obtida por LDA e pela regra Bayesiana s√£o aproximadamente iguais. Se utilizarmos as mesmas estimativas da m√©dia amostral, a fronteira ser√° exatamente a mesma.

**Corol√°rio 4:** Ao relaxar a hip√≥tese de covari√¢ncias iguais, a fronteira de decis√£o Bayesiana se torna quadr√°tica, levando √† an√°lise discriminante quadr√°tica (QDA) [^4.3].

> ‚ö†Ô∏è **Ponto Crucial**: A ado√ß√£o ou n√£o de covari√¢ncias iguais impacta fortemente o tipo de fronteira de decis√£o (linear vs. quadr√°tica) [^4.3.1].

### Conclus√£o

Nesta se√ß√£o, exploramos as diferen√ßas e similaridades entre **Boosting** e **Bagging**, dois m√©todos de *ensemble* poderosos para melhorar a performance de modelos de predi√ß√£o, al√©m de m√©todos estat√≠sticos e de aprendizado de m√°quina para classifica√ß√£o. O **Bagging**, especialmente em sua forma de Random Forests, reduz a vari√¢ncia atrav√©s da combina√ß√£o de √°rvores descorrelacionadas, enquanto o **Boosting** ajusta seus aprendizes fracos de forma iterativa, tendo potencial para reduzir tanto o vi√©s quanto a vari√¢ncia. M√©todos como LDA, regress√£o linear e log√≠stica, al√©m dos hiperplanos separadores, mostram as abordagens e desafios de classifica√ß√£o, com a import√¢ncia de m√©todos de regulariza√ß√£o e sele√ß√£o de vari√°veis para evitar o *overfitting*.

### Footnotes

[^15.1]: "Bagging or bootstrap aggregation (section 8.7) is a technique for reducing the variance of an estimated prediction function. Bagging seems to work especially well for high-variance, low-bias procedures, such as trees. For regression, we simply fit the same regression tree many times to bootstrap-sampled versions of the training data, and average the result. For classification, a committee of trees each cast a vote for the predicted class. Boosting in Chapter 10 was initially proposed as a committee method as well, although unlike bagging, the committee of weak learners evolves over time, and the members cast a weighted vote. Boosting appears to dominate bagging on most problems, and became the preferred choice. Random forests (Breiman, 2001) is a substantial modification of bagging that builds a large collection of de-correlated trees, and then averages them. On many problems the performance of random forests is very similar to boosting, and they are simpler to train and tune. As a consequence, random forests are popular, and are implemented in a variety of packages." *(Trecho de Random Forests)*
[^15.2]: "The essential idea in bagging (Section 8.7) is to average many noisy but approximately unbiased models, and hence reduce the variance. Trees are ideal candidates for bagging, since they can capture complex interaction structures in the data, and if grown sufficiently deep, have relatively low bias. Since trees are notoriously noisy, they benefit greatly from the averaging. Moreover, since each tree generated in bagging is identically distributed (i.d.), the expectation of an average of B such trees is the same as the expectation of any one of them. This means the bias of bagged trees is the same as that of the individual trees, and the only hope of improvement is through variance reduction. This is in contrast to boosting, where the trees are grown in an adaptive way to remove bias, and hence are not i.d. An average of B i.i.d. random variables, each with variance œÉ¬≤, has variance œÉ¬≤/B. If the variables are simply i.d. (identically distributed, but not necessarily independent) with positive pairwise correlation œÅ, the variance of the average is (Exercise 15.1) œÉ¬≤/B + œÅœÉ¬≤(1-1/B). As B increases, the second term disappears, but the first remains, and hence the size of the correlation of pairs of bagged trees limits the benefits of averaging. The idea in random forests (Algorithm 15.1) is to improve the variance reduction of bagging by reducing the correlation between the trees, without increasing the variance too much." *(Trecho de Random Forests)*
[^4.1]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.2]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.3]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.3.1]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.3.2]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.3.3]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.4]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.4.1]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.4.2]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.4.3]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.4.4]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.4.5]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.5]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.5.1]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
[^4.5.2]: "Conte√∫do extra√≠do conforme escrito no contexto e utilizado no cap√≠tulo" *(Trecho de <Nome do Documento>)*
