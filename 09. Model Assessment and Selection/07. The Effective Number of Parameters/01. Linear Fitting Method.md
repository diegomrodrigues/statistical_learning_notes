## Avalia√ß√£o e Sele√ß√£o de Modelos em M√©todos de Ajuste Linear

```mermaid
graph LR
    subgraph "Generaliza√ß√£o do Modelo"
    A["Dados de Treinamento"] --> B("Modelo de Aprendizado")
    B --> C["Predi√ß√µes"]
    C --> D["Dados de Teste Independentes"]
    D --> E{"Avalia√ß√£o do Desempenho"}
    end
```

### Introdu√ß√£o
O desempenho de **generaliza√ß√£o** de um m√©todo de aprendizado refere-se √† sua capacidade preditiva em dados de teste independentes. A avalia√ß√£o desse desempenho √© crucial na pr√°tica, pois orienta a escolha do m√©todo de aprendizado ou modelo e fornece uma medida da qualidade do modelo selecionado [^7.1]. Este cap√≠tulo explora m√©todos para avaliar o desempenho e como eles s√£o usados para selecionar modelos, come√ßando com a discuss√£o da intera√ß√£o entre **vi√©s**, **vari√¢ncia** e **complexidade do modelo** [^7.1].

### Conceitos Fundamentais
**Conceito 1: Problema de Classifica√ß√£o e M√©todos Lineares**
O problema de classifica√ß√£o envolve atribuir um r√≥tulo de classe a uma entrada com base em um conjunto de dados de treinamento. Modelos lineares, como a regress√£o linear aplicada a uma matriz indicadora de classe, s√£o frequentemente utilizados devido √† sua simplicidade e interpretabilidade. No entanto, o uso de tais modelos lineares pode levar a um trade-off entre **vi√©s** (o qu√£o distante a predi√ß√£o m√©dia do modelo est√° do valor real) e **vari√¢ncia** (a sensibilidade das predi√ß√µes do modelo a varia√ß√µes nos dados de treinamento) [^7.2]. Por exemplo, modelos excessivamente complexos podem se ajustar perfeitamente aos dados de treinamento (baixo vi√©s), mas podem generalizar mal para novos dados (alta vari√¢ncia), um fen√¥meno conhecido como *overfitting*.

> üí° **Exemplo Num√©rico:** Considere um dataset com 100 pontos, onde a rela√ß√£o real √© quadr√°tica ($y = x^2 + \epsilon$, com $\epsilon$ sendo um ru√≠do aleat√≥rio). Se usarmos um modelo linear simples ($y = \beta_0 + \beta_1x$), teremos um alto vi√©s porque o modelo n√£o captura a curvatura dos dados. Se usarmos um modelo polinomial de grau 9 ($y = \beta_0 + \beta_1x + \ldots + \beta_9x^9$), poderemos obter um ajuste perfeito aos dados de treinamento (baixo vi√©s no treinamento), mas a alta vari√¢ncia far√° com que o modelo se ajuste muito ao ru√≠do, generalizando mal para novos dados.
    
    ```python
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.linear_model import LinearRegression
    from sklearn.preprocessing import PolynomialFeatures
    from sklearn.metrics import mean_squared_error

    # Generate synthetic data
    np.random.seed(42)
    X = np.sort(np.random.rand(100) * 10)
    y = X**2 + np.random.randn(100) * 5

    # Linear model
    linear_model = LinearRegression()
    linear_model.fit(X.reshape(-1, 1), y)
    y_linear_pred = linear_model.predict(X.reshape(-1, 1))
    mse_linear = mean_squared_error(y, y_linear_pred)

    # Polynomial model (degree 9)
    poly_features = PolynomialFeatures(degree=9)
    X_poly = poly_features.fit_transform(X.reshape(-1, 1))
    poly_model = LinearRegression()
    poly_model.fit(X_poly, y)
    y_poly_pred = poly_model.predict(X_poly)
    mse_poly = mean_squared_error(y, y_poly_pred)

    # Plotting
    plt.figure(figsize=(10, 5))
    plt.scatter(X, y, color='blue', label='Dados Originais')
    plt.plot(X, y_linear_pred, color='red', label=f'Linear (MSE={mse_linear:.2f})')
    plt.plot(X, y_poly_pred, color='green', label=f'Polinomial (MSE={mse_poly:.2f})')
    plt.xlabel('X')
    plt.ylabel('y')
    plt.title('Bias-Variance Tradeoff')
    plt.legend()
    plt.show()
    ```
    
    Este exemplo demonstra que, embora o modelo polinomial se ajuste melhor aos dados de treinamento (menor MSE), ele pode n√£o generalizar bem para novos dados devido √† sua alta complexidade e vari√¢ncia.

```mermaid
graph LR
    subgraph "Trade-off Vi√©s-Vari√¢ncia"
    A["Complexidade do Modelo"] --> B("Baixo Vi√©s / Alta Vari√¢ncia")
    A --> C("Alto Vi√©s / Baixa Vari√¢ncia")
    B --> D{"Overfitting"}
    C --> E{"Underfitting"}
    end
```

**Lemma 1:** Dada uma fun√ß√£o discriminante linear $f(x) = w^Tx + b$, onde $w$ √© o vetor de pesos e $b$ √© o bias, a superf√≠cie de decis√£o $f(x) = 0$ divide o espa√ßo de entrada em regi√µes distintas, cada uma correspondente a uma classe [^4.3]. A escolha de $w$ e $b$ determina a orienta√ß√£o e posi√ß√£o dessa superf√≠cie, influenciando o desempenho da classifica√ß√£o.

$$f(x) = w^Tx + b$$
$$f(x) = 0 \implies w^Tx = -b$$

*Prova:* A equa√ß√£o $w^Tx + b = 0$ define um hiperplano no espa√ßo de caracter√≠sticas. A fun√ß√£o discriminante $f(x)$ gera valores positivos para um lado deste hiperplano (uma classe) e valores negativos para o outro lado (outra classe). Portanto, a escolha adequada dos par√¢metros $w$ e $b$ √© fundamental para a separa√ß√£o eficaz das classes. $\blacksquare$

**Conceito 2: Linear Discriminant Analysis (LDA)**
A **Linear Discriminant Analysis (LDA)** √© um m√©todo de classifica√ß√£o que assume que as classes s√£o geradas a partir de distribui√ß√µes Gaussianas com as mesmas matrizes de covari√¢ncia [^4.3]. O objetivo da LDA √© encontrar a melhor combina√ß√£o linear das caracter√≠sticas para separar as classes, projetando os dados em um espa√ßo de dimens√£o inferior maximizando a separa√ß√£o entre as m√©dias das classes e minimizando a vari√¢ncia dentro de cada classe [^4.3.1], [^4.3.2], [^4.3.3].

> üí° **Exemplo Num√©rico:** Imagine um dataset com duas classes, onde cada classe tem duas features. A Classe 1 tem m√©dia $\mu_1 = [2, 2]$ e a Classe 2 tem m√©dia $\mu_2 = [5, 5]$. Ambas as classes compartilham a mesma matriz de covari√¢ncia, por exemplo, $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$. A LDA ir√° encontrar um vetor $w$ que maximiza a dist√¢ncia entre as proje√ß√µes das m√©dias das classes e minimiza a vari√¢ncia dentro das classes. Em termos pr√°ticos, o vetor $w$ define a dire√ß√£o na qual os dados ser√£o projetados para melhor separar as classes.
   
   ```python
   import numpy as np
   import matplotlib.pyplot as plt
   from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

   # Generate synthetic data
   np.random.seed(42)
   mean1 = [2, 2]
   mean2 = [5, 5]
   cov = [[1, 0.5], [0.5, 1]]
   X1 = np.random.multivariate_normal(mean1, cov, 100)
   X2 = np.random.multivariate_normal(mean2, cov, 100)
   X = np.vstack((X1, X2))
   y = np.hstack((np.zeros(100), np.ones(100)))

   # Apply LDA
   lda = LinearDiscriminantAnalysis()
   lda.fit(X, y)
   X_lda = lda.transform(X)

    # Calculate the linear decision boundary
   w = lda.coef_[0]
   b = lda.intercept_[0]
   x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
   y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
   xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))
   Z = lda.predict(np.c_[xx.ravel(), yy.ravel()])
   Z = Z.reshape(xx.shape)
   
   # Plotting
   plt.figure(figsize=(10, 5))
   plt.subplot(1, 2, 1)
   plt.scatter(X1[:, 0], X1[:, 1], color='blue', label='Class 0')
   plt.scatter(X2[:, 0], X2[:, 1], color='red', label='Class 1')
   plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdBu)
   plt.xlabel('Feature 1')
   plt.ylabel('Feature 2')
   plt.title('Original Data with LDA Boundary')
   plt.legend()
    
   plt.subplot(1, 2, 2)
   plt.scatter(X_lda[y==0], np.zeros(100), color='blue', label='Class 0')
   plt.scatter(X_lda[y==1], np.zeros(100), color='red', label='Class 1')
   plt.xlabel('LDA Projection')
   plt.title('LDA Projection')
   plt.legend()
   plt.tight_layout()
   plt.show()
   ```
   
   Neste exemplo, a LDA projeta os dados em uma dimens√£o, maximizando a separa√ß√£o entre as m√©dias das classes e minimizando a vari√¢ncia dentro de cada classe. A linha vertical em um gr√°fico separa as proje√ß√µes.

```mermaid
graph LR
    subgraph "LDA"
    A["Dados de Entrada"] --> B["Calcular M√©dias por Classe"]
    B --> C["Calcular Matriz de Covari√¢ncia"]
    C --> D["Encontrar Vetor w que Maximize a Separa√ß√£o"]
    D --> E["Projetar Dados em w"]
    E --> F["Classificar Projetado"]
    end
```

**Corol√°rio 1:** A fun√ß√£o discriminante linear da LDA pode ser expressa como uma proje√ß√£o dos dados para um espa√ßo de menor dimens√£o, onde a separa√ß√£o entre as classes √© maximizada. Essa proje√ß√£o pode ser obtida atrav√©s do c√°lculo dos autovetores da matriz de covari√¢ncia conjunta, seguida pela proje√ß√£o dos dados nestes autovetores [^4.3.1].

$$W = S_W^{-1}S_B$$
Onde $S_W$ √© a matriz de covari√¢ncia *within-class* e $S_B$ √© a matriz de covari√¢ncia *between-class*. Os autovetores de $W$ definem as dire√ß√µes de m√°xima separabilidade das classes.

**Conceito 3: Regress√£o Log√≠stica**
A **Regress√£o Log√≠stica** √© um modelo estat√≠stico que estima a probabilidade de uma entrada pertencer a uma classe espec√≠fica, utilizando uma fun√ß√£o log√≠stica para modelar a rela√ß√£o entre as vari√°veis preditoras e a probabilidade de sa√≠da [^4.4]. O modelo √© ajustado maximizando a verossimilhan√ßa dos dados observados, ou seja, a probabilidade de observar os r√≥tulos de classe dados os valores das caracter√≠sticas [^4.4.1], [^4.4.2]. A **fun√ß√£o logit** transforma a probabilidade de uma classe em uma escala linear, que √© modelada como uma combina√ß√£o linear de par√¢metros e caracter√≠sticas [^4.4.3].

A fun√ß√£o log√≠stica √© definida como:

$$p(x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x)}}$$

Onde $p(x)$ √© a probabilidade de pertencer √† classe 1 e $\beta_0$ e $\beta_1$ s√£o os par√¢metros do modelo.
> ‚ö†Ô∏è **Nota Importante**: A regress√£o log√≠stica √© especialmente √∫til quando a vari√°vel resposta √© bin√°ria ou categ√≥rica, e ela n√£o assume uma distribui√ß√£o gaussiana nos erros [^4.4.1].
> ‚ùó **Ponto de Aten√ß√£o**: Em situa√ß√µes onde as classes n√£o s√£o balanceadas, a regress√£o log√≠stica pode precisar de ajustes para evitar o vi√©s para a classe majorit√°ria [^4.4.2].
> ‚úîÔ∏è **Destaque**: A regress√£o log√≠stica, assim como a LDA, busca uma fronteira linear entre as classes, mas usando uma fun√ß√£o log√≠stica para estimar as probabilidades [^4.5].

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria onde temos uma √∫nica vari√°vel preditora, 'idade' e a vari√°vel alvo √© 'comprou_produto' (0 ou 1). Ap√≥s o treinamento de um modelo de regress√£o log√≠stica, obtemos os coeficientes: $\beta_0 = -5$ e $\beta_1 = 0.2$. Ent√£o, para uma pessoa com 30 anos, a probabilidade de comprar o produto √©:

> $$p(idade=30) = \frac{1}{1 + e^{-(-5 + 0.2*30)}} = \frac{1}{1 + e^{-1}} \approx \frac{1}{1 + 0.368} \approx 0.73 $$
> Isso indica uma probabilidade de 73% da pessoa comprar o produto.

    ```python
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.linear_model import LogisticRegression
    from sklearn.metrics import classification_report, confusion_matrix

    # Generate synthetic data
    np.random.seed(42)
    age = np.random.randint(18, 65, 200)
    prob = 1 / (1 + np.exp(-(-5 + 0.2*age) )) # Logit function
    bought = np.random.binomial(1, prob)

    # Logistic regression model
    log_model = LogisticRegression()
    log_model.fit(age.reshape(-1, 1), bought)

    # Predictions
    age_range = np.linspace(18, 65, 100).reshape(-1, 1)
    y_prob = log_model.predict_proba(age_range)[:, 1]

    # Decision boundary
    decision_boundary = -log_model.intercept_[0] / log_model.coef_[0][0]
    # Metrics
    y_pred = log_model.predict(age.reshape(-1, 1))
    print("Classification Report:\n", classification_report(bought, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(bought, y_pred))
    
    # Plotting
    plt.figure(figsize=(8, 6))
    plt.scatter(age, bought, color='blue', alpha=0.5, label='Data Points')
    plt.plot(age_range, y_prob, color='red', label='Probability Curve')
    plt.axvline(decision_boundary, color='green', linestyle='--', label='Decision Boundary')
    plt.xlabel('Age')
    plt.ylabel('Probability of Buying')
    plt.title('Logistic Regression Example')
    plt.legend()
    plt.grid(True)
    plt.show()
    ```

   Este exemplo ilustra como a regress√£o log√≠stica estima probabilidades de classe e define uma fronteira de decis√£o baseada nesses valores. O gr√°fico mostra os pontos de dados, a curva de probabilidade e a fronteira de decis√£o.

```mermaid
graph LR
    subgraph "Regress√£o Log√≠stica"
    A["Vari√°veis Preditoras (x)"] --> B("Combina√ß√£o Linear: Œ≤0 + Œ≤1x")
    B --> C("Fun√ß√£o Log√≠stica: 1 / (1 + exp(-z))")
    C --> D("Probabilidade de Classe: p(x)")
    D --> E("Decis√£o de Classifica√ß√£o")
    end
```

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
flowchart TD
  subgraph "Regress√£o de Indicadores"
    A["Codificar Classes"] --> B["Estimar Coeficientes via LS"]
    B --> C["Aplicar Regra de Decis√£o"]
    C --> D["Comparar com M√©todos Probabil√≠sticos"]
  end
```

**Explica√ß√£o:** O diagrama acima representa o fluxo de dados em um modelo de regress√£o de indicadores para classifica√ß√£o, um m√©todo alternativo que busca uma fronteira de decis√£o linear no espa√ßo de caracter√≠sticas [^4.2].

A regress√£o linear pode ser adaptada para problemas de classifica√ß√£o atrav√©s da codifica√ß√£o das classes usando uma matriz de indicadores [^4.2]. Por exemplo, em um problema de classifica√ß√£o bin√°ria, uma classe pode ser representada por 0 e a outra por 1. O modelo de regress√£o linear √© ent√£o ajustado usando o m√©todo dos m√≠nimos quadrados, onde o objetivo √© minimizar a soma dos quadrados dos erros entre as predi√ß√µes e os valores reais [^4.2]. No entanto, a regress√£o linear em matrizes de indicadores possui algumas limita√ß√µes, como a dificuldade em lidar com classes n√£o linearmente separ√°veis e a possibilidade de gerar predi√ß√µes fora do intervalo [0, 1].

**Lemma 2:** Em certas condi√ß√µes, a proje√ß√£o nos hiperplanos de decis√£o gerados pela regress√£o linear com matriz de indicadores √© equivalente √† proje√ß√£o gerada por discriminantes lineares, como a LDA [^4.2], [^4.3]. Essa equival√™ncia ocorre quando os pressupostos de distribui√ß√£o gaussiana e covari√¢ncias iguais entre as classes, utilizados na LDA, s√£o razo√°veis [^4.3].
*Prova:* Suponha que a regress√£o linear minimize:
$$ \sum_{i=1}^{N} (y_i - \hat{y}_i)^2 $$
onde $y_i$ s√£o os indicadores de classe e $\hat{y}_i$ s√£o as predi√ß√µes do modelo de regress√£o. Para um problema de classifica√ß√£o bin√°ria, a LDA tamb√©m define um hiperplano que separa as classes, e, sob certas condi√ß√µes, esse hiperplano coincide com o gerado pela regress√£o linear. $\blacksquare$

**Corol√°rio 2:** A an√°lise da equival√™ncia entre as proje√ß√µes nos hiperplanos de decis√£o, estabelecida no Lemma 2, sugere que, em muitas situa√ß√µes pr√°ticas, o uso da regress√£o linear com matrizes de indicadores pode fornecer resultados semelhantes aos da LDA, especialmente quando o objetivo principal √© determinar a fronteira de decis√£o [^4.3].
"Em alguns cen√°rios, conforme apontado em [^4.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1]."
"No entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^4.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear."

> üí° **Exemplo Num√©rico:** Para ilustrar a regress√£o de indicadores, vamos considerar um dataset simples com duas classes e duas features. O objetivo √© prever a qual classe um ponto pertence, usando regress√£o linear para matrizes de indicadores.
    
   ```python
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import mean_squared_error

    # Generate synthetic data
    np.random.seed(42)
    X = np.random.rand(100, 2) * 10
    y = np.array([0 if x[0] + x[1] < 10 else 1 for x in X]) # Classes are roughly separated by x1 + x2 = 10

    # Linear Regression for indicator matrix
    model = LinearRegression()
    model.fit(X, y)
    
    # Decision Boundary
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = np.round(Z)
    Z = Z.reshape(xx.shape)
    
    # Predictions
    y_pred = np.round(model.predict(X))
    mse = mean_squared_error(y, y_pred)

    # Plotting
    plt.figure(figsize=(8, 6))
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu, edgecolors='k', label='Data Points')
    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdBu)
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.title(f'Linear Regression for Classification (MSE={mse:.2f})')
    plt.legend()
    plt.show()
   ```
   
   Este exemplo demonstra como a regress√£o linear pode ser utilizada para classifica√ß√£o, apesar das limita√ß√µes como a poss√≠vel extrapola√ß√£o fora do intervalo [0, 1]. A fronteira de decis√£o √© linear, representada pelo contorno no gr√°fico, e a cor dos pontos indica a classe real.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regulariza√ß√£o"
        A["Fun√ß√£o de Custo"]
        B["Termo de Perda (MSE, Log Loss)"]
        C["Termo de Regulariza√ß√£o (L1, L2)"]
        A --> B
        A --> C
        C --> D{"Penaliza Coeficientes Grandes"}
    end
```
A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas importantes para melhorar a performance de modelos classificat√≥rios, especialmente em situa√ß√µes onde existem muitas vari√°veis preditoras [^4.4.4], [^4.5]. A regulariza√ß√£o adiciona termos de penaliza√ß√£o √† fun√ß√£o de custo, que for√ßa os par√¢metros do modelo a assumir valores menores, o que ajuda a evitar o *overfitting* e melhorar a generaliza√ß√£o [^4.5.1]. As penalidades L1 (Lasso) e L2 (Ridge) s√£o frequentemente utilizadas nesse contexto. A penalidade L1 tende a gerar modelos mais esparsos, definindo alguns coeficientes como exatamente zero, enquanto a penalidade L2 reduz os coeficientes de forma mais uniforme [^4.4.4]. O **Elastic Net**, √© uma combina√ß√£o das penalidades L1 e L2, que combina as vantagens de ambas [^4.5].

> üí° **Exemplo Num√©rico:** Vamos considerar um modelo de regress√£o log√≠stica para prever se um paciente tem uma doen√ßa com base em 10 caracter√≠sticas. Para evitar o overfitting e melhorar a interpretabilidade, aplicamos regulariza√ß√£o L1 (Lasso) e L2 (Ridge) e comparamos os resultados.

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from sklearn.pipeline import Pipeline

# Generate synthetic data
np.random.seed(42)
n_samples = 200
n_features = 10
X = np.random.rand(n_samples, n_features)
true_coefs = np.array([3, -2, 0, 0.8, -0.5, 1.2, 0, 0, -0.3, 0.7]) # Only a few variables are relevant
y_prob = 1 / (1 + np.exp(-(np.dot(X, true_coefs))))
y = np.random.binomial(1, y_prob)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Logistic Regression with L1 and L2 regularization
l1_model = LogisticRegression(penalty='l1', solver='liblinear', C=0.1, random_state=42)
l2_model = LogisticRegression(penalty='l2', C=0.1, random_state=42)

l1_model.fit(X_train_scaled, y_train)
l2_model.fit(X_train_scaled, y_train)

y_pred_l1 = l1_model.predict(X_test_scaled)
y_pred_l2 = l2_model.predict(X_test_scaled)

accuracy_l1 = accuracy_score(y_test, y_pred_l1)
accuracy_l2 = accuracy_score(y_test, y_pred_l2)
print(f"L1 accuracy: {accuracy_l1:.2f}")
print(f"L2 accuracy: {accuracy_l2:.2f}")

print("\nL1 Classification Report:\n", classification_report(y_test, y_pred_l1))
print("\nL2 Classification Report:\n", classification_report(y_test, y_pred_l2))


# Compare coefficients
coefs_l1 = l1_model.coef_.flatten()
coefs_l2 = l2_model.coef_.flatten()

# Create dataframe for comparison
comparison = pd.DataFrame({
    'Feature': [f'Feature {i+1}' for i in range(n_features)],
    'True Coef': true_coefs,
    'L1 Coef': coefs_l1,
    'L2 Coef': coefs_l2
})
print("\nCoefficient Comparison:")
print(comparison)

# Plot the coefficients
plt.figure(figsize=(10, 6))
plt.plot(range(1, n_features + 1), true_coefs, marker='o', linestyle='-', label='True Coefficients', color='blue')
plt.plot(range(1, n_features + 1), coefs_l1, marker='x', linestyle='--', label='L1 Coefficients', color='red')
plt.plot(range(1, n_features + 1), coefs_l2, marker='^', linestyle='-.', label='L2 Coefficients', color='green')
plt.xlabel('Feature Index')
plt.ylabel('Coefficient Value')
plt.title('Comparison of True, L1, and L2 Regularized Coefficients')
plt.legend()
plt.grid(True)
plt.show()

```

  Este exemplo mostra que a regulariza√ß√£o L1 leva a coeficientes esparsos (alguns coeficientes s√£o exatamente 0), enquanto a regulariza√ß√£o L2 reduz todos os coeficientes, mas n√£o necessariamente para zero. O c√≥digo tamb√©m compara os valores dos coeficientes com os valores verdadeiros e mostra o desempenho em termos de acur√°cia.

```mermaid
graph LR
    subgraph "Compara√ß√£o L1 vs L2"
    A["Regulariza√ß√£o L1"] --> B["Coeficientes Esparsos (Lasso)"]
    A --> C{"Penalidade: Œª‚àë|Œ≤|"}
    B --> D{"Sele√ß√£o de Vari√°veis Impl√≠cita"}
    E["Regulariza√ß√£o L2"] --> F["Reduz Coeficientes Uniformemente (Ridge)"]
    E --> G{"Penalidade: Œª‚àëŒ≤¬≤"}
        F --> H{"Sem Sele√ß√£o de Vari√°veis Expl√≠cita"}
    end
```

**Lemma 3:** A penaliza√ß√£o L1 em modelos de classifica√ß√£o log√≠stica leva a coeficientes esparsos, o que significa que muitas das vari√°veis n√£o ter√£o influ√™ncia na predi√ß√£o [^4.4.4].

*Prova:* A penaliza√ß√£o L1 adiciona um termo proporcional √† soma dos valores absolutos dos coeficientes √† fun√ß√£o de custo. Durante a otimiza√ß√£o, o modelo tende a zerar os coeficientes que t√™m pouco impacto no desempenho do modelo, pois isso resulta em uma redu√ß√£o da fun√ß√£o de custo total [^4.4.3]. $\blacksquare$
**Corol√°rio 3:** A esparsidade dos coeficientes resultante da penaliza√ß√£o L1 pode simplificar a interpreta√ß√£o dos modelos classificat√≥rios, uma vez que apenas as vari√°veis mais relevantes permanecem no modelo [^4.4.5].
> ‚ö†Ô∏è **Ponto Crucial**: L1 e L2 podem ser combinadas (Elastic Net) para aproveitar vantagens de ambos os tipos de regulariza√ß√£o, conforme discutido em [^4.5].

### Separating Hyperplanes e Perceptrons
A ideia de maximizar a **margem de separa√ß√£o** entre as classes leva ao conceito de **hiperplanos √≥timos**, onde o objetivo √© encontrar um hiperplano que n√£o apenas separe as classes, mas tamb√©m maximize a dist√¢ncia entre os pontos de dados mais pr√≥ximos de cada classe [^4.5.2]. Esse problema de otimiza√ß√£o pode ser formulado como um problema de programa√ß√£o quadr√°tica, onde as solu√ß√µes s√£o encontradas a partir de combina√ß√µes lineares dos pontos de suporte [^4.5.2]. O **Perceptron** de Rosenblatt √© um algoritmo simples que aprende a separar linearmente os dados, ajustando os pesos de uma fun√ß√£o linear iterativamente at√© que a converg√™ncia seja alcan√ßada. Se os dados s√£o linearmente separ√°veis, o Perceptron ir√° convergir para uma solu√ß√£o que separa perfeitamente as classes [^4.5.1].

> üí° **Exemplo Num√©rico:** Vamos simular o treinamento de um perceptron para um dataset linearmente separ√°vel e mostrar como ele ajusta a fronteira de decis√£o iterativamente.
 
    ```python
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.linear_model import Perceptron
    from sklearn.metrics import accuracy_score

    # Generate synthetic data (linearly separable)
    np.random.seed(42)
    X = np.random.rand(100, 2) * 10
    y = np.array([0 if x[0] - x[1] > 1 else 1 for x in X]) # linear separation

    # Train Perceptron
    perceptron = Perceptron(max_iter=1000, tol=1e-3, random_state=42)
    perceptron.fit(X, y)

    # Decision boundary
    w = perceptron.coef_[0]
    b = perceptron.intercept_[0]
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))
    Z = perceptron.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    
    # Predictions
    y_pred = perceptron.predict(X)
    accuracy = accuracy_score(y, y_pred)
    print(f"Accuracy: {accuracy:.2f}")


    # Plotting
    plt.figure(figsize=(8, 6))
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu, edgecolors='k')
    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdBu)
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.title(f'Perceptron - Decision Boundary (Accuracy: {accuracy:.2f})')
    plt.show()
    ```

  Este exemplo ilustra como o perceptron ajusta iterativamente os pesos para encontrar uma fronteira de decis√£o linear. No gr√°fico, a fronteira √© representada pelo contorno, separando os pontos de diferentes classes, e a acur√°cia √© impressa para mostrar a performance.

```mermaid
graph LR
  subgraph "Perceptron"
    A["Dados de Entrada"] --> B["Inicializar Pesos"]
    B --> C["Iterar sobre os Dados"]
    C --> D{"Calcular Sa√≠da: f(x) = w^T * x + b"}
    D --> E{"Verificar Classifica√ß√£o"}
    E -- "Incorreta" --> F["Ajustar Pesos"]
    F --> C
    E -- "Correta" --> G["Pr√≥ximo Ponto"]
    G --> C
    C --> H{"Convergiu?"}
    H -- "N√£o" --> C
    H -- "Sim" --> I["Fronteira de Decis√£o Final"]
  end
```
### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?
**Resposta:**
A LDA e a Regra de Decis√£o Bayesiana (com covari√¢ncias iguais) s√£o m√©todos de classifica√ß√£o que compartilham muitos pressupostos, mas diferem na sua abordagem de deriva√ß√£o da fronteira de decis√£o [^4.3]. Ambas assumem que as classes prov√™m de distribui√ß√µes Gaussianas com m√©dias e covari√¢ncias, mas enquanto a LDA estima essas m√©dias e covari√¢ncias usando os dados de treinamento e calcula a fronteira de decis√£o a partir delas, a Regra de Decis√£o Bayesiana parte da probabilidade condicional (baseada na distribui√ß√£o Gaussiana) e atribui a cada ponto a classe com maior probabilidade posterior.

**Lemma 4:** Sob a hip√≥tese de distribui√ß√µes Gaussianas com covari√¢ncias iguais para todas as classes, a fronteira de decis√£o obtida pela LDA √© equivalente √†quela obtida pela Regra de Decis√£o Bayesiana [^4.3], [^4.3.3].
*Prova:* A Regra de Decis√£o Bayesiana atribui um ponto $x$ √† classe $k$ se $P(G=k|X=x)$ √© m√°xima. Sob a hip√≥tese de distribui√ß√µes Gaussianas com covari√¢ncias iguais, a probabilidade condicional $P(G=k|X=x)$ pode ser escrita como:

$$ P(G=k|X=x) \propto \exp\left(-\frac{1}{2}(x-\mu_k)^T \Sigma^{-1} (x-\mu_k) \right) P(G=k) $$

onde $\mu_k$ √© a m√©dia da classe $k$ e $\Sigma$ √© a matriz de covari√¢ncia comum.  Tomando o log dessa express√£o e desprezando os termos que n√£o dependem de $k$, temos:
$$ \delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T \Sigma^{-1}\mu_k + \log P(G=k) $$
que √© uma fun√ß√£o linear de x. A LDA tamb√©m resulta numa fun√ß√£o discriminante linear similar, o que demonstra a equival√™ncia entre as duas abordagens quando as condi√ß√µes s√£o respeitadas.  $\blacksquare