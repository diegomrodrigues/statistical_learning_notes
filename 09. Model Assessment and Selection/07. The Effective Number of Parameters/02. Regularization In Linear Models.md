## Regulariza√ß√£o em Modelos Lineares

```mermaid
graph LR
    subgraph "Regularization Impact"
        direction TB
        A["Model Complexity"] --> B["Overfitting Risk"]
        B --> C["Regularization Needed"]
        C --> D["Penalty Term Addition"]
        D --> E["Bias Increase, Variance Decrease"]
        E --> F["Improved Generalization"]
    end
```

### Introdu√ß√£o

A regulariza√ß√£o √© uma t√©cnica fundamental no aprendizado de m√°quina, especialmente em modelos lineares, onde a complexidade do modelo pode levar a problemas de overfitting [^7.2]. Este cap√≠tulo explora as diversas t√©cnicas de regulariza√ß√£o, focando em como elas impactam o vi√©s, a vari√¢ncia e a complexidade dos modelos lineares, com base nos princ√≠pios de modelagem estat√≠stica e otimiza√ß√£o descritos em [^7.1]. A regulariza√ß√£o adiciona termos de penalidade √† fun√ß√£o de custo, incentivando solu√ß√µes mais simples e robustas, melhorando a capacidade de generaliza√ß√£o do modelo [^7.2].

### Conceitos Fundamentais

**Conceito 1: Overfitting e Necessidade de Regulariza√ß√£o.**

Overfitting ocorre quando um modelo se ajusta muito bem aos dados de treinamento, mas tem um desempenho ruim em dados novos e n√£o vistos [^7.2]. Modelos lineares com muitos par√¢metros podem se tornar muito flex√≠veis, capturando o ru√≠do nos dados de treinamento em vez dos padr√µes subjacentes. A regulariza√ß√£o, atrav√©s da introdu√ß√£o de um termo de penalidade, restringe os coeficientes do modelo, simplificando a fun√ß√£o de decis√£o e reduzindo a complexidade do modelo [^7.2]. Em termos de bias-variance tradeoff, a regulariza√ß√£o aumenta o vi√©s, reduzindo a vari√¢ncia, levando a um melhor desempenho em dados n√£o vistos [^7.3]. Um exemplo cl√°ssico de overfitting √© um modelo linear que se ajusta perfeitamente a todos os pontos de treinamento, mas falha ao prever novos dados [^7.2].

> üí° **Exemplo Num√©rico:** Suponha que temos um dataset com 10 pontos e ajustamos um polin√¥mio de grau 9, um modelo muito complexo. Esse modelo pode passar por todos os pontos de treinamento, apresentando erro zero nesses dados, mas se comportar√° muito mal para novos dados, com grande vari√¢ncia e alta probabilidade de erro. A regulariza√ß√£o ajuda a evitar isso, usando modelos mais simples.

**Lemma 1:** Para um modelo linear $f(X) = X^T\beta$, o overfitting aumenta √† medida que o n√∫mero de par√¢metros $|\beta|$ cresce, o que leva a um alto grau de vari√¢ncia, enquanto a adi√ß√£o de um termo de penalidade ao custo de otimiza√ß√£o $\frac{\lambda}{2} \|\beta\|^2_2$  restringe a norma dos coeficientes, resultando em menor vari√¢ncia e potencialmente maior bias.

*Prova:* A adi√ß√£o do termo de penaliza√ß√£o ao custo de otimiza√ß√£o, ou seja, $\text{argmin}_\beta \sum_i (y_i - x_i^T\beta)^2 + \frac{\lambda}{2} \|\beta\|^2_2$, imp√µe uma restri√ß√£o nos valores dos par√¢metros $\beta$. √Ä medida que $\lambda$ aumenta, a norma $\|\beta\|_2$ √© for√ßada a diminuir, o que leva a coeficientes menores e, consequentemente, a uma fun√ß√£o de decis√£o mais simples. A redu√ß√£o na magnitude dos coeficientes leva a uma menor sensibilidade √†s varia√ß√µes nos dados de treinamento (menor vari√¢ncia), mas pode levar a um ajuste menos preciso (maior bias) aos dados de treinamento, melhorando assim a capacidade de generaliza√ß√£o. $\blacksquare$

```mermaid
graph LR
    subgraph "Lemma 1: Regularization Impact on Parameters"
        direction TB
        A["Model Complexity: |Œ≤| increases"] --> B["Variance Increase"]
        B --> C["Overfitting Risk"]
        C --> D["Regularization: Add Œª/2 ||Œ≤||¬≤"]
        D --> E["Norm of Œ≤ decreases"]
        E --> F["Variance Decrease"]
        F --> G["Bias Increase (Potentially)"]
        G --> H["Improved Generalization"]
    end
```

> üí° **Exemplo Num√©rico:**
>
> Considere um modelo linear com dois par√¢metros, $\beta_1$ e $\beta_2$, e a fun√ß√£o de custo sem regulariza√ß√£o: $J(\beta) = \sum_{i=1}^n (y_i - x_{i1}\beta_1 - x_{i2}\beta_2)^2$.
>
> 1. **Sem Regulariza√ß√£o:** Ao ajustar sem regulariza√ß√£o, $\beta_1$ e $\beta_2$ podem assumir valores grandes para se ajustar ao ru√≠do nos dados de treinamento, resultando em alta vari√¢ncia.
>
> 2. **Com Regulariza√ß√£o L2:** Adicionando a regulariza√ß√£o L2, a fun√ß√£o de custo se torna: $J(\beta) = \sum_{i=1}^n (y_i - x_{i1}\beta_1 - x_{i2}\beta_2)^2 + \frac{\lambda}{2}(\beta_1^2 + \beta_2^2)$.
>    Se $\lambda = 1$, valores muito grandes de $\beta_1$ e $\beta_2$ aumentar√£o o valor da fun√ß√£o de custo, fazendo com que $\beta_1$ e $\beta_2$ tenham valores menores, reduzindo a vari√¢ncia.
>
>     Suponha que encontramos os seguintes valores para os coeficientes usando m√≠nimos quadrados sem regulariza√ß√£o: $\hat{\beta}_{OLS} = [5.2, -3.8]$.
>
>     Agora, utilizando Ridge regression com $\lambda=1$, obtemos:  $\hat{\beta}_{ridge} = [2.5, -1.9]$. Observe como os valores s√£o menores, o que leva √† menor vari√¢ncia.

**Conceito 2: Regulariza√ß√£o L1 (Lasso).**

A regulariza√ß√£o L1, ou Lasso, adiciona a soma dos valores absolutos dos coeficientes como termo de penalidade na fun√ß√£o de custo:
$$ J(\beta) = \frac{1}{N} \sum_{i=1}^{N} (y_i - x_i^T\beta)^2 + \lambda \|\beta\|_1 $$
onde $\|\beta\|_1 = \sum_{j=1}^{p} |\beta_j|$ √© a norma L1 dos coeficientes. O termo de penalidade L1 incentiva a esparsidade dos coeficientes, ou seja, muitos coeficientes tornam-se exatamente zero [^7.3]. Isso pode ser √∫til para sele√ß√£o de vari√°veis, identificando as vari√°veis mais importantes para a predi√ß√£o e excluindo as irrelevantes. Ao minimizar a fun√ß√£o de custo, a regulariza√ß√£o L1 for√ßa alguns coeficientes a zero, efetivamente removendo essas vari√°veis do modelo.

```mermaid
graph LR
    subgraph "L1 Regularization (Lasso)"
        direction LR
        A["Loss Function: J(Œ≤)"] --> B["RSS: (1/N)‚àë(y·µ¢ - x·µ¢·µÄŒ≤)¬≤"]
        A --> C["Penalty Term: Œª||Œ≤||‚ÇÅ"]
        C --> D["Induces Sparsity"]
        D --> E["Feature Selection"]
    end
```

**Corol√°rio 1:** A esparsidade induzida pela regulariza√ß√£o L1 pode ser vista como um m√©todo de sele√ß√£o de vari√°veis intr√≠nseco ao modelo, pois ele elimina vari√°veis pouco relevantes atrav√©s do ajuste de seus coeficientes para zero. Esse processo facilita a interpreta√ß√£o do modelo e melhora sua generaliza√ß√£o em datasets com muitas vari√°veis [^7.4].

> üí° **Exemplo Num√©rico:**
>
>  Suponha que temos 5 vari√°veis preditoras ($x_1, x_2, x_3, x_4, x_5$). Ap√≥s ajustar um modelo linear com regulariza√ß√£o Lasso, obtemos os seguintes coeficientes: $\hat{\beta} = [2.3, 0, -1.5, 0.8, 0]$. As vari√°veis $x_2$ e $x_5$ s√£o consideradas irrelevantes pelo modelo pois os coeficientes correspondentes foram zerados pela regulariza√ß√£o L1.

**Conceito 3: Regulariza√ß√£o L2 (Ridge).**

A regulariza√ß√£o L2, ou Ridge, adiciona a soma dos quadrados dos coeficientes como termo de penalidade na fun√ß√£o de custo:
$$ J(\beta) = \frac{1}{N} \sum_{i=1}^{N} (y_i - x_i^T\beta)^2 + \frac{\lambda}{2} \|\beta\|_2^2 $$
onde $\|\beta\|_2^2 = \sum_{j=1}^{p} \beta_j^2$ √© o quadrado da norma L2 dos coeficientes. O termo de penalidade L2 reduz a magnitude dos coeficientes, mas n√£o necessariamente os for√ßa a zero [^7.4]. A regulariza√ß√£o L2 √© √∫til para reduzir a vari√¢ncia do modelo e melhorar sua estabilidade. Reduzir a magnitude dos coeficientes leva a uma fun√ß√£o de decis√£o mais suave e menos propensa a grandes varia√ß√µes devido a ru√≠do nos dados de treinamento.

```mermaid
graph LR
    subgraph "L2 Regularization (Ridge)"
        direction LR
        A["Loss Function: J(Œ≤)"] --> B["RSS: (1/N)‚àë(y·µ¢ - x·µ¢·µÄŒ≤)¬≤"]
        A --> C["Penalty Term: (Œª/2)||Œ≤||‚ÇÇ¬≤"]
         C --> D["Reduces Coefficient Magnitude"]
        D --> E["Reduces Variance"]
        E --> F["Improves Stability"]

    end
```

> ‚ö†Ô∏è **Nota Importante**: A regulariza√ß√£o L2 √© particularmente eficaz quando h√° multicolinearidade entre as vari√°veis preditoras, pois evita que os coeficientes se tornem muito grandes para compensar a alta correla√ß√£o entre as vari√°veis. **Refer√™ncia ao t√≥pico [^7.3]**.

> ‚ùó **Ponto de Aten√ß√£o**: Diferente do Lasso, a regulariza√ß√£o Ridge n√£o zera os coeficientes, sendo menos eficiente para sele√ß√£o de vari√°veis, mas ainda √∫til para melhorar a generaliza√ß√£o do modelo atrav√©s da redu√ß√£o da norma dos coeficientes. **Conforme indicado em [^7.4]**.

> ‚úîÔ∏è **Destaque**: A escolha do m√©todo de regulariza√ß√£o adequado depende do problema em quest√£o. Se o foco √© sele√ß√£o de vari√°veis e um modelo esparso, o Lasso pode ser mais adequado, mas se a estabilidade e a redu√ß√£o da magnitude dos coeficientes s√£o mais importantes, o Ridge pode ser prefer√≠vel. **Baseado no t√≥pico [^7.4]**.

> üí° **Exemplo Num√©rico:**
>
> Considere um cen√°rio de multicolinearidade, onde duas vari√°veis preditoras ($x_1$ e $x_2$) s√£o altamente correlacionadas. Sem regulariza√ß√£o, seus coeficientes podem se tornar muito grandes e opostos, tentando compensar a informa√ß√£o redundante que elas fornecem. Por exemplo, $\hat{\beta} = [100, -95]$. Usando Ridge, a regulariza√ß√£o reduz esses valores, por exemplo $\hat{\beta}_{ridge} = [20, -15]$, tornando o modelo mais est√°vel e menos sens√≠vel a pequenas mudan√ßas nos dados.
>
> ```python
> import numpy as np
> from sklearn.linear_model import Ridge
>
> # Dados de exemplo com multicolinearidade
> X = np.array([[1, 2, 2], [1, 3, 3], [1, 4, 4], [1, 5, 5], [1, 6, 6]])
> y = np.array([2, 3, 4, 5, 6])
>
> # Ridge Regression com lambda=1
> ridge = Ridge(alpha=1)
> ridge.fit(X, y)
> print(f"Coeficientes Ridge: {ridge.coef_}")
>
> # Para comparar com OLS, podemos usar alpha = 0
> ridge_ols = Ridge(alpha=0)
> ridge_ols.fit(X,y)
> print(f"Coeficientes OLS (Ridge com alpha=0): {ridge_ols.coef_}")
> ```

### Regress√£o Linear e M√≠nimos Quadrados com Regulariza√ß√£o

```mermaid
graph LR
    subgraph "Regularized Linear Regression Process"
        direction TB
        A["Input Data (X, y)"] --> B["Apply Regularization (L1, L2, Elastic Net)"]
        B --> C["Optimize Regularized Cost Function"]
        C --> D["Obtain Regularized Coefficients (Œ≤ÃÇ)"]
        D --> E["Apply Regularized Model to New Data"]
    end
```

A regress√£o linear com m√≠nimos quadrados busca minimizar a soma dos erros quadrados entre os valores previstos e os valores reais, conforme definido em [^7.2]. No entanto, em modelos lineares com muitas vari√°veis ou quando h√° multicolinearidade, o ajuste de m√≠nimos quadrados pode levar a coeficientes muito grandes e a um modelo com alta vari√¢ncia [^7.2]. Para resolver esse problema, a regulariza√ß√£o √© adicionada √† fun√ß√£o de custo, impondo uma restri√ß√£o sobre a magnitude dos coeficientes [^7.3].

**Lemma 2:** Para um modelo linear com regulariza√ß√£o L2 (Ridge), o estimador dos par√¢metros $\beta$ √© dado por $\hat{\beta}_{ridge} = (X^TX + \lambda I)^{-1}X^Ty$, onde $I$ √© a matriz identidade, e para um modelo com regulariza√ß√£o L1 (Lasso), n√£o existe uma solu√ß√£o anal√≠tica simples, exigindo m√©todos num√©ricos para otimiza√ß√£o.

*Prova:* Para o Ridge, a fun√ß√£o de custo √© $J(\beta) = \sum_i (y_i - x_i^T\beta)^2 + \lambda \sum_j \beta_j^2$. A minimiza√ß√£o envolve derivar $J(\beta)$ em rela√ß√£o a $\beta$ e igualar a zero. Isso leva a: $-2X^T(y - X\beta) + 2\lambda\beta = 0$. Resolvendo para $\beta$, obtemos $\hat{\beta}_{ridge} = (X^TX + \lambda I)^{-1}X^Ty$. Para o Lasso, o termo de regulariza√ß√£o L1 n√£o √© diferenci√°vel em $\beta=0$, portanto n√£o h√° uma solu√ß√£o anal√≠tica direta e m√©todos de otimiza√ß√£o iterativos (ex: gradient descent) s√£o necess√°rios. $\blacksquare$

```mermaid
graph LR
    subgraph "Lemma 2: Derivation of Ridge Estimator"
        direction TB
        A["Cost Function: J(Œ≤) = ‚àë(y·µ¢ - x·µ¢·µÄŒ≤)¬≤ + Œª‚àëŒ≤‚±º¬≤"] --> B["Derivative w.r.t Œ≤: -2X·µÄ(y - XŒ≤) + 2ŒªŒ≤ = 0"]
        B --> C["Solve for Œ≤: (X·µÄX + ŒªI)Œ≤ = X·µÄy"]
        C --> D["Ridge Estimator: Œ≤ÃÇ_ridge = (X·µÄX + ŒªI)‚Åª¬πX·µÄy"]
         subgraph "Lasso: No Analytical Solution"
            D -->E["L1 penalty not differentiable at Œ≤=0"]
            E--> F["Numerical Optimization Needed"]
        end
    end
```

> üí° **Exemplo Num√©rico:**
>
>   Suponha que temos uma matriz de design $X$ com dimens√µes 3x2 e um vetor de respostas $y$ de dimens√£o 3x1:
>   $$ X = \begin{bmatrix} 1 & 2 \\ 1 & 3 \\ 1 & 4 \end{bmatrix} , \quad y = \begin{bmatrix} 5 \\ 6 \\ 7 \end{bmatrix} $$
>
>   Para calcular $\hat{\beta}_{ridge}$ com $\lambda = 0.5$, primeiro calculamos $X^TX$:
>
>   $$ X^TX = \begin{bmatrix} 1 & 1 & 1 \\ 2 & 3 & 4 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 1 & 3 \\ 1 & 4 \end{bmatrix} = \begin{bmatrix} 3 & 9 \\ 9 & 29 \end{bmatrix} $$
>
>   Em seguida, somamos $\lambda I$:
>   $$ X^TX + \lambda I = \begin{bmatrix} 3 & 9 \\ 9 & 29 \end{bmatrix} + 0.5 \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} = \begin{bmatrix} 3.5 & 9 \\ 9 & 29.5 \end{bmatrix} $$
>
>   Calculamos a inversa:
>
>   $$ (X^TX + \lambda I)^{-1} \approx \begin{bmatrix} 0.908 & -0.275 \\ -0.275 & 0.107 \end{bmatrix} $$
>
>    Calculamos $X^Ty$:
>
>  $$ X^Ty = \begin{bmatrix} 1 & 1 & 1 \\ 2 & 3 & 4 \end{bmatrix} \begin{bmatrix} 5 \\ 6 \\ 7 \end{bmatrix} = \begin{bmatrix} 18 \\ 56 \end{bmatrix} $$
>
>  Finalmente, calculamos $\hat{\beta}_{ridge}$:
>   $$ \hat{\beta}_{ridge} = (X^TX + \lambda I)^{-1} X^Ty \approx \begin{bmatrix} 0.908 & -0.275 \\ -0.275 & 0.107 \end{bmatrix} \begin{bmatrix} 18 \\ 56 \end{bmatrix} \approx \begin{bmatrix} 1.45 \\ 1.09 \end{bmatrix} $$
>   Comparando com a solu√ß√£o de m√≠nimos quadrados, $\hat{\beta}_{OLS} = [4, 0.5]$, vemos que os coeficientes s√£o menores com o ridge, e s√£o mais est√°veis.
>
>```python
> import numpy as np
> from numpy.linalg import inv
>
> # Matrizes e vetores do exemplo
> X = np.array([[1, 2], [1, 3], [1, 4]])
> y = np.array([5, 6, 7])
> lam = 0.5
>
> # C√°lculo de X^TX
> XtX = X.T @ X
>
> # C√°lculo de X^Ty
> XtY = X.T @ y
>
> # Ridge regression
> beta_ridge = inv(XtX + lam * np.eye(2)) @ XtY
>
> # M√≠nimos quadrados
> beta_ols = inv(XtX) @ XtY
>
> print(f"Beta Ridge: {beta_ridge}")
> print(f"Beta OLS: {beta_ols}")
>```

**Corol√°rio 2:** O estimador do Ridge $\hat{\beta}_{ridge}$ √© sempre definido, mesmo quando $X^TX$ √© singular (n√£o invert√≠vel), o que √© comum em situa√ß√µes com muitas vari√°veis, enquanto o estimador de m√≠nimos quadrados, $\hat{\beta}_{OLS} = (X^TX)^{-1}X^Ty$, n√£o tem solu√ß√£o se $X^TX$ for singular.  A regulariza√ß√£o L2 adiciona um vi√©s ao modelo, mas reduz a vari√¢ncia, tornando a solu√ß√£o mais est√°vel e robusta.

```mermaid
graph LR
    subgraph "Corolario 2: Stability of Ridge Estimator"
    direction TB
        A["X^TX is singular"] --> B["OLS Estimator: (X^TX)‚Åª¬πX^Ty - Not Defined"]
        A --> C["Ridge Estimator: (X^TX + ŒªI)‚Åª¬πX^Ty - Always Defined"]
        C --> D["L2 Regularization Introduces Bias"]
        D --> E["Reduced Variance"]
        E --> F["Stable and Robust Solution"]
     end
```

‚ÄúA regulariza√ß√£o L2 (Ridge), conforme apontado em [^7.3], tem uma solu√ß√£o anal√≠tica direta e √© mais simples de implementar que o Lasso, mas n√£o induz esparsidade."

"No entanto, como discutido em [^7.4], a regulariza√ß√£o L1 (Lasso) √© ideal quando se quer um modelo esparso e sele√ß√£o de vari√°veis, embora a otimiza√ß√£o seja mais complexa."

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization in Classification"
        direction TB
        A["Classification Models"] --> B["Logistic Regression"]
        A --> C["LDA"]
         B --> D["Regularization (L1, L2, Elastic Net)"]
        C --> D
        D --> E["Impact on Model Complexity, Bias, Variance"]
     end
```

Em problemas de classifica√ß√£o, os m√©todos de regulariza√ß√£o L1 e L2 tamb√©m s√£o aplic√°veis, como na regress√£o log√≠stica [^7.4]. Na regress√£o log√≠stica, a fun√ß√£o de custo √© geralmente a log-verossimilhan√ßa negativa, e um termo de penalidade (L1 ou L2) √© adicionado a ela para regularizar os coeficientes [^7.4.4]. A regulariza√ß√£o L1 leva a coeficientes esparsos, o que √© √∫til para selecionar as vari√°veis mais relevantes para classifica√ß√£o [^7.4.5]. A regulariza√ß√£o L2 reduz a magnitude dos coeficientes, evitando que o modelo se torne excessivamente complexo e ajudando a reduzir a vari√¢ncia.

**Lemma 3:** A penaliza√ß√£o L1 na regress√£o log√≠stica resulta em um problema de otimiza√ß√£o n√£o diferenci√°vel na origem, o que causa esparsidade nos coeficientes do modelo. A penaliza√ß√£o L2, embora n√£o gere esparsidade, resulta em uma fun√ß√£o de custo diferenci√°vel, que pode ser otimizada com m√©todos de gradiente.

*Prova:* A fun√ß√£o de custo para regress√£o log√≠stica com regulariza√ß√£o L1 √©: $$ J(\beta) = -\sum_i [y_i \log(p_i) + (1-y_i) \log(1-p_i)] + \lambda \sum_j |\beta_j| $$ onde $p_i = \frac{1}{1 + e^{-x_i^T\beta}}$. A derivada do termo de regulariza√ß√£o $\lambda \sum_j |\beta_j|$ em rela√ß√£o a $\beta_j$ √© $\lambda$ se $\beta_j > 0$, $-\lambda$ se $\beta_j < 0$, e n√£o √© definida para $\beta_j=0$. Essa descontinuidade em $\beta_j=0$ for√ßa alguns coeficientes a zero durante a otimiza√ß√£o. A regulariza√ß√£o L2, por outro lado, √© diferenci√°vel em todo o dom√≠nio, o que leva a uma solu√ß√£o suave. $\blacksquare$

```mermaid
graph LR
    subgraph "Lemma 3: Regularization in Logistic Regression"
        direction TB
        A["Logistic Regression Cost Function"] --> B["L1 Penalty: Œª‚àë|Œ≤‚±º| - Non-Differentiable at Œ≤‚±º=0"]
        B --> C["Induces Sparsity"]
        A --> D["L2 Penalty: Œª/2‚àëŒ≤‚±º¬≤ - Differentiable"]
         D --> E["Smooth Solution (no sparsity)"]
    end
```

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um problema de classifica√ß√£o bin√°ria com duas vari√°veis preditoras ($x_1$, $x_2$). Ap√≥s aplicar regress√£o log√≠stica com regulariza√ß√£o L1 e L2, comparamos os resultados:
>
> 1. **Regress√£o Log√≠stica com Regulariza√ß√£o L1 (Lasso):**
>    Suponha que ap√≥s o ajuste, os coeficientes sejam $\hat{\beta} = [0.8, 0]$. O modelo selecionou apenas a vari√°vel $x_1$ como relevante para a classifica√ß√£o.
>
> 2. **Regress√£o Log√≠stica com Regulariza√ß√£o L2 (Ridge):**
>     Ap√≥s ajuste, os coeficientes resultam em $\hat{\beta} = [0.5, 0.2]$. Ambas as vari√°veis s√£o consideradas relevantes, mas com coeficientes de menor magnitude.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
>
> # Dados de exemplo
> X = np.array([[1, 2], [1, 3], [2, 2], [3, 1], [4, 3], [5, 2]])
> y = np.array([0, 0, 0, 1, 1, 1])
>
> # Logistic regression com L1
> logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1)
> logreg_l1.fit(X, y)
> print(f"Coeficientes L1: {logreg_l1.coef_}")
>
> # Logistic regression com L2
> logreg_l2 = LogisticRegression(penalty='l2', C=1)
> logreg_l2.fit(X, y)
> print(f"Coeficientes L2: {logreg_l2.coef_}")
> ```
> A regulariza√ß√£o L1 gera um modelo esparso, enquanto a L2 reduz a magnitude dos coeficientes.

**Corol√°rio 3:** Modelos de classifica√ß√£o regularizados, como regress√£o log√≠stica com regulariza√ß√£o L1 ou L2, podem ser usados tanto para melhorar a precis√£o preditiva quanto para simplificar a interpreta√ß√£o do modelo. Modelos com regulariza√ß√£o L1 s√£o preferidos quando se busca selecionar vari√°veis, enquanto modelos com regulariza√ß√£o L2 s√£o mais adequados quando o objetivo √© um modelo est√°vel com vari√¢ncia reduzida [^7.5.1].

> ‚ö†Ô∏è **Ponto Crucial**: A regulariza√ß√£o Elastic Net combina regulariza√ß√µes L1 e L2 para aproveitar as vantagens de ambas, permitindo tanto sele√ß√£o de vari√°veis (esparsidade) quanto redu√ß√£o da magnitude dos coeficientes, dada por $J(\beta) =  \frac{1}{N} \sum_{i=1}^{N} (y_i - x_i^T\beta)^2 + \lambda_1 \|\beta\|_1 + \frac{\lambda_2}{2} \|\beta\|_2^2$. **Conforme discutido em [^7.5]**.

```mermaid
graph LR
    subgraph "Elastic Net Regularization"
        direction LR
        A["Loss Function: J(Œ≤)"] --> B["RSS: (1/N)‚àë(y·µ¢ - x·µ¢·µÄŒ≤)¬≤"]
        A --> C["L1 Penalty: Œª‚ÇÅ||Œ≤||‚ÇÅ"]
        A --> D["L2 Penalty: (Œª‚ÇÇ/2)||Œ≤||‚ÇÇ¬≤"]
        C & D --> E["Combines Sparsity and Stability"]
    end
```

> üí° **Exemplo Num√©rico**:
>
> Considere o mesmo problema de regress√£o linear com 5 vari√°veis preditoras. Ajustamos um modelo Elastic Net com $\lambda_1 = 0.5$ e $\lambda_2 = 0.5$.
>
> Ap√≥s a otimiza√ß√£o, os coeficientes podem ser $\hat{\beta} = [1.2, 0, -0.8, 0.3, 0]$. O Elastic Net eliminou duas vari√°veis como o Lasso, e reduziu a magnitude dos outros coeficientes, como o Ridge. O modelo se torna esparso, e mais est√°vel.
>
> ```python
> import numpy as np
> from sklearn.linear_model import ElasticNet
>
> # Dados de exemplo
> X = np.array([[1, 2, 1, 3, 2], [1, 3, 2, 1, 4], [2, 2, 3, 2, 5], [3, 1, 4, 3, 2], [4, 3, 5, 1, 1]])
> y = np.array([2, 3, 4, 5, 6])
>
> # Elastic Net com lambda1 = 0.5 e lambda2 = 0.5 (l1_ratio = 0.5)
> elastic_net = ElasticNet(alpha=1, l1_ratio=0.5)
> elastic_net.fit(X,y)
>
> print(f"Coeficientes Elastic Net: {elastic_net.coef_}")
> ```

### Separating Hyperplanes e Regulariza√ß√£o

Hiperplanos separadores (separating hyperplanes), como os usados em Support Vector Machines (SVMs), tamb√©m se beneficiam da regulariza√ß√£o, conforme mencionado em [^7.5.2]. O objetivo √© encontrar o hiperplano que melhor separa as classes de dados, maximizando a margem entre elas [^7.5.2]. A regulariza√ß√£o √© usada para evitar que o modelo se torne muito complexo e se adapte ao ru√≠do nos dados. Na formula√ß√£o do SVM, um termo de penalidade √© usado para controlar a complexidade do modelo, prevenindo overfitting.

### Pergunta Te√≥rica Avan√ßada: Qual a rela√ß√£o entre as penalidades L1 e L2 na formula√ß√£o Bayesiana e quais os impactos na distribui√ß√£o a posteriori dos par√¢metros?

**Resposta:**

Em um contexto Bayesiano, a regulariza√ß√£o L1 (Lasso) e L2 (Ridge) podem ser vistas como imposi√ß√£o de distribui√ß√µes a priori sobre os par√¢metros do modelo [^7.7]. A regulariza√ß√£o L2 corresponde a uma distribui√ß√£o a priori Gaussiana sobre os par√¢metros, $p(\beta) \propto \exp(-\frac{\lambda}{2} \|\beta\|_2^2)$, onde o par√¢metro $\lambda$ controla a precis√£o (inversa da vari√¢ncia) da distribui√ß√£o. J√° a regulariza√ß√£o L1 corresponde a uma distribui√ß√£o a priori de Laplace, $p(\beta) \propto \exp(-\lambda \|\beta\|_1)$, que possui uma densidade maior pr√≥xima de zero e, portanto, promove esparsidade [^7.7].

```mermaid
graph LR
    subgraph "Bayesian Interpretation of Regularization"
         direction TB
        A["L2 Regularization (Ridge)"] --> B["Gaussian Prior: p(Œ≤) ‚àù exp(-Œª/2 ||Œ≤||‚ÇÇ¬≤)"]
        A --> C["Shrinks Parameters Towards Zero"]
        B --> D["Controls Precision via Œª"]

        E["L1 Regularization (Lasso)"] --> F["Laplace Prior: p(Œ≤) ‚àù exp(-Œª||Œ≤||‚ÇÅ)"]
         E --> G["Promotes Sparsity"]
         F --> H["High Density Near Zero"]
    end
```

Na pr√°tica, essas prioris direcionam a solu√ß√£o da otimiza√ß√£o da verossimilhan√ßa (likelihood) para regi√µes do espa√ßo de par√¢metros que possuem menor complexidade. A priori gaussiana (L2) tende a encolher os par√¢metros uniformemente em dire√ß√£o a zero, enquanto a priori laplaciana (L1) tende a encolher os par√¢metros a zero ou a mant√™-los longe de zero, resultando em esparsidade [^7.8].
Em um contexto bayesiano, as estimativas a posteriori dos par√¢metros dependem tanto da prior como da verossimilhan√ßa dos dados [^7.7]. A escolha da prior impacta diretamente a distribui√ß√£o a posteriori e, consequentemente, a incerteza sobre os valores dos par√¢metros.

**Lemma 4:** A escolha entre prioris Gaussiana (L2) ou Laplaceana (L1) √© crucial para determinar o comportamento dos par√¢metros do modelo. A distribui√ß√£o a posteriori, $p(\beta|D)$, √© obtida usando o teorema de Bayes: $p(\beta|D) \propto p(D|\beta)p(\beta)$, onde $D$ s√£o os dados.

*Prova:* No contexto Bayesiano, a regulariza√ß√£o √© integrada na infer√™ncia atrav√©s do uso de distribui√ß√µes a priori sobre os par√¢metros. A prior Gaussiana $p(\beta) \propto \exp(-\frac{\lambda}{2} \|\beta\|^2_2)$ corresponde √† penaliza√ß√£o L2 (Ridge), e a prior Laplaceana $p(\beta) \propto \exp(-\lambda \|\beta\|_1)$ corresponde √† penaliza√ß√£o L1 (Lasso). A distribui√ß√£o a posteriori √© dada pela combina√ß√£o da prior com a verossimilhan√ßa dos dados, e o ponto √≥timo da distribui√ß√£o a posteriori √© usado como estimativa dos par√¢metros do modelo. A prior gaussiana leva a um modelo suave (menor norma dos coeficientes), enquanto a prior laplaceana leva a um modelo esparso (coeficientes iguais a zero). $\blacksquare$

```mermaid
graph LR
     subgraph "Lemma 4: Bayesian Inference"
        direction TB
         A["Posterior Distribution: p(Œ≤|D)"] --> B["Bayes Theorem: p(Œ≤|D) ‚àù p(D|Œ≤)p(Œ≤)"]
         B --> C["p(D|Œ≤) is the likelihood"]
         B --> D["p(Œ≤) is the prior (Gaussian or Laplace)"]
         D --> E["Impacts Posterior Distribution"]
         E --> F["L2 (Gaussian) = Smooth Model"]
         E --> G["L1 (Laplace) = Sparse Model"]

    end
```

**Corol√°rio 4:** A regulariza√ß√£o bayesiana fornece um framework probabil√≠stico para quantificar a incerteza nos par√¢metros, expressa pela vari√¢ncia da distribui√ß√£o a posteriori, ao contr√°rio da regulariza√ß√£o cl√°ssica, que fornece apenas uma estimativa pontual (point estimate).

> ‚ö†Ô∏è **Ponto Crucial**: A escolha da prior (L1 vs. L2) √© uma forma de incorporar cren√ßas sobre o modelo, e afeta o tradeoff entre vi√©s e vari√¢ncia, al√©m de influenciar a interpretabilidade do modelo final [^7.8].

### Conclus√£o

A regulariza√ß√£o √© uma t√©cnica essencial para melhorar a capacidade de generaliza√ß√£o de modelos lineares. A escolha entre L1, L2, ou outras formas de regulariza√ß√£o, depende dos objetivos espec√≠ficos do problema, como sele√ß√£o de vari√°veis, redu√ß√£o de vari√¢ncia ou esparsidade do modelo. Este cap√≠tulo explorou as diferentes t√©cnicas de regulariza√ß√£o e seus impactos em termos de vi√©s e vari√¢ncia, fornecendo uma vis√£o abrangente sobre a import√¢ncia da regulariza√ß√£o em modelos lineares.

### Footnotes

[^7.1]: "The generalization performance of a learning method relates to its predic-tion capability on independent test data. Assessment of this performance is extremely important in practice, since it guides the choice of learning method or model, and gives us a measure of the quality of the ultimately chosen model." *(Trecho de <Model Assessment and Selection>)*
[^7.2]: "Figure 7.1 illustrates the important issue in assessing the ability of a learning method to generalize. Consider first the case of a quantitative or interval scale response. We have a target variable Y, a vector of inputs X, and a prediction model f(X) that has been estimated from a training set T. The loss function for measuring errors between Y and f(X) is denoted by L(Y, f(X)). Typical choices are" *(Trecho de <Model Assessment and Selection>)*
[^7.3]: "Hence there is a decrease in bias but an increase in variance. There is some intermediate model complexity that gives minimum expected test error." *(Trecho de <Model Assessment and Selection>)*
[^7.4]: "For a linear model family such as ridge regression, we can break down the bias more finely. Let Œ≤ denote the parameters of the best-fitting linear approximation to f:" *(Trecho de <Model Assessment and Selection>)*
[^7.4.4]: "-2 I(G = k) log ≈øpk (X)" *(Trecho de <Model Assessment and Selection>)*
[^7.4.5]: "we produce G(X) directly. Typical loss functions are" *(Trecho de <Model Assessment and Selection>)*
[^7.5]: "The methods in this chapter are designed for situations where there is insufficient data to split it into three parts." *(Trecho de <Model Assessment and Selection>)*
[^7.5.1]: "For the k-nearest-neighbor regression fit, these expressions have the sim-ple form" *(Trecho de <Model Assessment and Selection>)*
[^7.5.2]:  "If we are in a data-rich situation, the best approach for both problems is to randomly divide the dataset into three parts: a training set, a validation set, and a test set." *(Trecho de <Model Assessment and Selection>)*
[^7.7]: "The Bayesian information criterion (BIC), like AIC, is applicable in settings where the fitting is carried out by maximization of a log-likelihood." *(Trecho de <Model Assessment and Selection>)*
[^7.8]: "Suppose we have a set of candidate