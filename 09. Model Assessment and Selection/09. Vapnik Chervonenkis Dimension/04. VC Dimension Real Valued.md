Okay, here's the revised text with all mathematical expressions formatted using LaTeX notation:

## Avalia√ß√£o e Sele√ß√£o de Modelos: Dimens√£o VC para Fun√ß√µes com Valores Reais

```mermaid
graph LR
    subgraph "Model Evaluation and Selection"
        direction TB
        A["Model Complexity"] --> B["Bias"];
        A --> C["Variance"];
        B --> D["Underfitting"];
        C --> E["Overfitting"];
        D --> F["High Bias, Low Variance"];
        E --> G["Low Bias, High Variance"];
        F & G --> H["Trade-off"];
        H --> I["Optimal Model"];
        I --> J["Generalization"];

        J --> K["VC Dimension"];
        K --> L["Model Capacity"];
        L --> M["Regularization Methods"];

    end
```

### Introdu√ß√£o

A capacidade de um modelo de aprendizado de generalizar, ou seja, seu desempenho em dados de teste independentes, √© crucial. A avalia√ß√£o desse desempenho guia a escolha do m√©todo de aprendizado e fornece uma medida da qualidade do modelo final [^7.1]. Este cap√≠tulo explora os m√©todos essenciais para avalia√ß√£o de desempenho e como eles s√£o usados na sele√ß√£o de modelos. Come√ßamos discutindo a rela√ß√£o entre **vi√©s, vari√¢ncia e complexidade do modelo**, e aprofundaremos a teoria da Dimens√£o de Vapnik-Chervonenkis para fun√ß√µes com valores reais.

### Conceitos Fundamentais

**Conceito 1:** *Problema de Generaliza√ß√£o e Complexidade do Modelo*

O problema central na avalia√ß√£o de modelos √© entender como um modelo treinado em um conjunto de dados espec√≠fico se comportar√° em dados n√£o vistos. Modelos simples podem ter alto vi√©s, pois s√£o incapazes de capturar padr√µes complexos nos dados, enquanto modelos complexos podem apresentar alta vari√¢ncia, sendo sens√≠veis ao ru√≠do e com baixo desempenho em dados n√£o vistos (overfitting) [^7.2]. O objetivo √© encontrar um equil√≠brio ideal, ou seja, um modelo com vi√©s e vari√¢ncia aceit√°veis.

**Lemma 1:** *Decomposi√ß√£o do Erro Quadr√°tico*

O erro quadr√°tico esperado de um modelo de regress√£o pode ser decomposto em tr√™s componentes: a vari√¢ncia do ru√≠do (erro irredut√≠vel), o vi√©s ao quadrado e a vari√¢ncia do modelo:

$$
Err(x_0) = \sigma^2 + [Ef(x_0) - f(x_0)]^2 + E[f(x_0) - Ef(x_0)]^2 = \sigma^2 + Bias^2(f(x_0)) + Var(f(x_0))
$$

onde:
- $Err(x_0)$ representa o erro de predi√ß√£o esperado no ponto de entrada $x_0$
- $\sigma^2$ √© a vari√¢ncia do ru√≠do (erro irredut√≠vel).
- $[Ef(x_0) - f(x_0)]^2$ √© o vi√©s ao quadrado, medindo a diferen√ßa entre o valor m√©dio previsto pelo modelo ($Ef(x_0)$) e o valor verdadeiro $f(x_0)$.
- $E[f(x_0) - Ef(x_0)]^2$ √© a vari√¢ncia do modelo, medindo a variabilidade das previs√µes do modelo em torno de sua m√©dia.

Essa decomposi√ß√£o √© fundamental para entender o compromisso entre vi√©s e vari√¢ncia na escolha da complexidade do modelo [^7.3].

> üí° **Exemplo Num√©rico:** Vamos considerar um exemplo simples para ilustrar a decomposi√ß√£o do erro quadr√°tico. Suponha que o valor verdadeiro de uma vari√°vel em $x_0$ seja $f(x_0) = 5$. Temos um modelo com ru√≠do $\sigma^2 = 0.5$. Ap√≥s v√°rias execu√ß√µes do modelo, obtemos as seguintes previs√µes: 4, 4.5, 5.5, e 6. A m√©dia das previs√µes, $Ef(x_0)$, √© 5.
>
>  - **Vi√©s ao quadrado:** $[Ef(x_0) - f(x_0)]^2 = (5-5)^2 = 0$.
>  - **Vari√¢ncia do modelo:** $E[f(x_0) - Ef(x_0)]^2 = \frac{(4-5)^2 + (4.5-5)^2 + (5.5-5)^2 + (6-5)^2}{4} = \frac{1 + 0.25 + 0.25 + 1}{4} = 0.625$.
>  - **Erro total:** $Err(x_0) = 0.5 + 0 + 0.625 = 1.125$
>
>  Este exemplo demonstra que o erro total √© composto do erro irredut√≠vel, e a vari√¢ncia do modelo, pois o vi√©s √© zero nesse cen√°rio espec√≠fico.

```mermaid
graph TD
    subgraph "Error Decomposition"
        direction TB
        A["Err(x‚ÇÄ)"]
        B["œÉ¬≤ (Irreducible Error)"]
        C["Bias¬≤(f(x‚ÇÄ)) = (Ef(x‚ÇÄ) - f(x‚ÇÄ))¬≤"]
        D["Var(f(x‚ÇÄ)) = E[(f(x‚ÇÄ) - Ef(x‚ÇÄ))¬≤]"]
        A --> B
        A --> C
        A --> D
    end
```

**Conceito 2:** *Dimens√£o VC*

A **Dimens√£o de Vapnik-Chervonenkis (VC)** √© uma medida da complexidade de uma classe de fun√ß√µes, representando o n√∫mero m√°ximo de pontos que podem ser "estilha√ßados" por essa classe [^7.9]. Um conjunto de pontos √© estilha√ßado por uma classe de fun√ß√µes se, para cada poss√≠vel atribui√ß√£o de r√≥tulos bin√°rios a esses pontos, existe uma fun√ß√£o na classe que os separa perfeitamente [^7.9]. A Dimens√£o VC oferece um crit√©rio para medir a capacidade de um modelo de se ajustar a um dado conjunto de dados, fornecendo insights sobre o risco de overfitting.

**Corol√°rio 1:** *Dimens√£o VC para Fun√ß√µes Indicadoras Lineares*

A dimens√£o VC de fun√ß√µes indicadoras lineares no espa√ßo $R^p$ √© $p+1$. Isso significa que $p+1$ pontos podem ser estilha√ßados por hiperplanos em $p$ dimens√µes, mas nenhum conjunto de $p+2$ pontos pode ser estilha√ßado [^7.9]. Fun√ß√µes indicadoras lineares s√£o fun√ß√µes que geram valores bin√°rios (0 ou 1) indicando a classe a que um dado ponto pertence. A dimens√£o VC de uma fun√ß√£o indicadora linear √© igual ao n√∫mero de par√¢metros mais um (o intercepto).

> üí° **Exemplo Num√©rico:** Em um espa√ßo bidimensional ($R^2$), uma linha (hiperplano em 2D) pode estilha√ßar at√© 3 pontos. Considere tr√™s pontos n√£o colineares. Podemos desenhar linhas para separar cada combina√ß√£o poss√≠vel de classes (0 ou 1). No entanto, com 4 pontos em $R^2$ em configura√ß√£o gen√©rica, n√£o conseguiremos separ√°-los para todas as combina√ß√µes de r√≥tulos bin√°rios com apenas uma linha. Portanto, a dimens√£o VC para fun√ß√µes lineares em $R^2$ √© 3. A quantidade de par√¢metros de um modelo linear em $R^2$ √© 3: dois coeficientes e um intercepto ($ax + by + c = 0$).

```mermaid
graph LR
    subgraph "VC Dimension for Linear Indicator Functions"
        direction TB
        A["Linear Indicator Function in R^p"]
        B["VC Dimension = p + 1"]
        C["p + 1 points can be shattered"]
        D["No set of p + 2 points can be shattered"]
        A --> B
        B --> C
        B --> D

    end
```

**Conceito 3:** *Extens√£o da Dimens√£o VC para Fun√ß√µes com Valores Reais*

A defini√ß√£o de Dimens√£o VC √© originalmente aplicada a fun√ß√µes indicadoras, mas ela pode ser estendida para fun√ß√µes com valores reais $g(x,a)$ considerando a classe de fun√ß√µes indicadoras que divide o espa√ßo de sa√≠da em regi√µes onde $g(x, \alpha) - \beta > 0$, onde $\beta$ varia ao longo do range da fun√ß√£o $g(x, a)$ [^7.9]. A dimens√£o VC desta classe de indicadoras √© a dimens√£o VC da fun√ß√£o $g(x,a)$. Isso permite medir a complexidade de classes de fun√ß√µes com valores reais, que s√£o cruciais para modelar diversos fen√¥menos.

```mermaid
graph LR
    subgraph "Extending VC Dimension to Real-Valued Functions"
        direction TB
        A["Real-valued function g(x, a)"]
        B["Indicator function class: g(x, Œ±) - Œ≤ > 0"]
        C["Œ≤ varies over the range of g(x, a)"]
        D["VC Dimension of indicator class = VC Dimension of g(x, a)"]
        A --> B
        B --> C
        C --> D
    end
```

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
 subgraph "Linear Regression for Classification"
    direction TB
    A["Input Data"] --> B["Indicator Matrix Encoding"];
    B --> C["Linear Regression"];
    C --> D["Coefficient Estimation"];
    D --> E["Decision Rule"];
    E --> F["Classification Output"];
 end
```

A regress√£o linear pode ser usada para classifica√ß√£o ao aplicar o m√©todo de m√≠nimos quadrados a uma matriz indicadora de classes [^7.1]. Cada coluna dessa matriz representa uma classe, e os elementos indicam se uma dada amostra pertence a essa classe. O modelo obtido por regress√£o linear pode ser usado para estimar a classe mais prov√°vel de cada nova amostra.

No entanto, a regress√£o linear em matrizes indicadoras tem limita√ß√µes. As previs√µes podem cair fora do intervalo [0,1], tornando as interpreta√ß√µes de probabilidade inv√°lidas [^7.2]. Al√©m disso, a regress√£o linear n√£o leva em conta a natureza categ√≥rica das vari√°veis de resposta. Apesar disso, a regress√£o linear em matrizes indicadoras pode ser eficiente em certos casos, quando o principal interesse √© a fronteira de decis√£o linear.

**Lemma 2:** *A Equival√™ncia Assint√≥tica da Regress√£o Linear e LDA*

Em algumas condi√ß√µes espec√≠ficas, quando o objetivo principal √© obter uma fronteira de decis√£o, a regress√£o linear de uma matriz indicadora pode produzir fronteiras de decis√£o que se aproximam das encontradas via Linear Discriminant Analysis (LDA) [^7.2]. Ambos os m√©todos compartilham a mesma estrutura de decis√£o linear, mas os coeficientes dos modelos podem ser obtidos por diferentes crit√©rios.

**Corol√°rio 2:** *Fronteiras de Decis√£o Lineares*

As proje√ß√µes lineares de regress√£o podem, em certos contextos, levar √†s mesmas fronteiras de decis√£o obtidas atrav√©s de outros m√©todos como LDA [^7.2]. Isso destaca como diferentes abordagens de classifica√ß√£o podem convergir para solu√ß√µes semelhantes sob certas condi√ß√µes.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o cruciais para evitar o overfitting, especialmente quando lidamos com modelos complexos ou dados com muitas vari√°veis preditoras [^7.2]. Na regress√£o log√≠stica, m√©todos como a penaliza√ß√£o L1 e L2 s√£o usados para controlar a complexidade do modelo e melhorar a generaliza√ß√£o [^7.3].

A penaliza√ß√£o L1 (Lasso) tende a produzir modelos com coeficientes esparsos, ou seja, muitos coeficientes s√£o exatamente zero, facilitando a sele√ß√£o de vari√°veis relevantes [^7.3]. A penaliza√ß√£o L2 (Ridge) encolhe os coeficientes em dire√ß√£o a zero, mas raramente os torna exatamente zero, o que √© √∫til para evitar multicolinearidade e melhorar a estabilidade do modelo [^7.3].

> üí° **Exemplo Num√©rico:** Suponha que estamos treinando um modelo de regress√£o log√≠stica para prever se um cliente ir√° comprar um produto (1) ou n√£o (0), baseado em 5 vari√°veis preditoras: idade, renda, tempo de navega√ß√£o no site, n√∫mero de produtos adicionados ao carrinho e n√∫mero de visitas √† p√°gina. Usando um modelo de regress√£o log√≠stica sem regulariza√ß√£o, obtemos:
>
> $$ \text{log}\left(\frac{p}{1-p}\right) = -0.5 + 0.02*\text{idade} + 0.001*\text{renda} + 0.1*\text{tempo\_navega√ß√£o} + 0.2*\text{carrinho} - 0.05*\text{visitas}$$
>
>Aplicando penaliza√ß√£o L1 (Lasso) com $\lambda = 0.1$, podemos obter:
>
> $$ \text{log}\left(\frac{p}{1-p}\right) = -0.3 + 0.01*\text{idade} + 0.08*\text{tempo\_navega√ß√£o} + 0.15*\text{carrinho} $$
>
>Observe que a penaliza√ß√£o L1 zerou os coeficientes de "renda" e "visitas", indicando que essas vari√°veis s√£o menos relevantes para a predi√ß√£o, o que simplifica o modelo e o torna mais interpret√°vel. Agora, aplicando L2 (Ridge) com $\lambda = 0.1$, podemos ter um resultado como:
>
> $$ \text{log}\left(\frac{p}{1-p}\right) = -0.4 + 0.015*\text{idade} + 0.0008*\text{renda} + 0.09*\text{tempo\_navega√ß√£o} + 0.18*\text{carrinho} - 0.03*\text{visitas} $$
>
>Aqui, todos os coeficientes s√£o reduzidos, mas nenhum √© exatamente zero. Ridge ajuda a lidar com multicolinearidade, o que pode acontecer se vari√°veis como tempo de navega√ß√£o e n√∫mero de visitas estiverem correlacionadas.

```mermaid
graph LR
 subgraph "Regularization Techniques"
    direction TB
    A["Logistic Regression"]
    B["L1 Penalty (Lasso)"]
    C["L2 Penalty (Ridge)"]
    D["Elastic Net (L1 + L2)"]

    A --> B
    A --> C
    B & C --> D

    B --> E["Sparse coefficients"]
    C --> F["Shrink coefficients"]
    E --> G["Variable Selection"]
    F --> H["Multicollinearity Handling"]

  end
```

**Lemma 3:** *Penaliza√ß√£o L1 e Esparsidade*

A penaliza√ß√£o L1 em modelos de regress√£o log√≠stica leva a coeficientes esparsos, o que significa que alguns coeficientes ser√£o exatamente zero.

**Prova do Lemma 3:**
A penaliza√ß√£o L1 adiciona um termo proporcional √† soma dos valores absolutos dos coeficientes √† fun√ß√£o de custo da regress√£o log√≠stica:
$$
L(\beta) = - \sum_{i=1}^N [y_i \log(p(x_i)) + (1-y_i)\log(1-p(x_i))] + \lambda \sum_{j=1}^p|\beta_j|
$$

onde $\lambda$ controla a intensidade da penaliza√ß√£o. A penaliza√ß√£o L1 gera solu√ß√µes esparsas porque a fun√ß√£o $ |\beta_j| $ tem uma "ponta" em $ \beta_j = 0 $, o que faz com que o otimizador tenda a empurrar alguns coeficientes para exatamente zero [^7.3]. $\blacksquare$

```mermaid
graph LR
  subgraph "L1 Penalty and Sparsity"
    direction TB
    A["Cost Function: L(Œ≤) = ‚àíŒ£ [y·µ¢ log(p(x·µ¢)) + (1-y·µ¢)log(1-p(x·µ¢))] + ŒªŒ£|Œ≤‚±º|"]
    B["L1 penalty term: ŒªŒ£|Œ≤‚±º|"]
    C["'Point' at Œ≤‚±º = 0"]
    D["Optimizer tends to push coefficients to 0"]
    A --> B
    B --> C
    C --> D

  end
```

**Corol√°rio 3:** *Interpretabilidade de Modelos Classificat√≥rios*

A esparsidade induzida pela penaliza√ß√£o L1 facilita a interpreta√ß√£o dos modelos classificat√≥rios, pois apenas as vari√°veis mais relevantes s√£o mantidas no modelo final [^7.3]. Isso √© especialmente √∫til em cen√°rios com alta dimensionalidade onde a interpretabilidade √© crucial.

> ‚ö†Ô∏è **Ponto Crucial:** A combina√ß√£o das penalidades L1 e L2, Elastic Net, permite equilibrar a esparsidade da penaliza√ß√£o L1 e a estabilidade da penaliza√ß√£o L2, conforme discutido em [^7.3].

### Separating Hyperplanes e Perceptrons

A ideia de maximizar a margem de separa√ß√£o entre as classes leva ao conceito de **hiperplanos √≥timos** [^7.2]. A dist√¢ncia entre a margem e o hiperplano de decis√£o √© maximizada, melhorando a robustez do classificador a dados n√£o vistos. A formula√ß√£o matem√°tica desse problema envolve otimiza√ß√£o, utilizando a dualidade de Wolfe e o conceito de vetores de suporte [^7.3].

O **Perceptron de Rosenblatt** √© um algoritmo de aprendizado para classificar dados linearmente separ√°veis. O Perceptron aprende os par√¢metros de um hiperplano que separa as classes ajustando os pesos iterativamente at√© convergir, desde que os dados sejam linearmente separ√°veis [^7.3].

```mermaid
graph LR
    subgraph "Perceptron Learning"
        direction TB
        A["Linearly Separable Data"]
        B["Perceptron Algorithm"]
        C["Iterative Weight Adjustment"]
        D["Hyperplane Parameters"]
        E["Convergence"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

### Pergunta Te√≥rica Avan√ßada (Exemplo): Como a escolha da fun√ß√£o de perda influencia o comportamento do *bias-variance tradeoff* em problemas de classifica√ß√£o?

**Resposta:**
A fun√ß√£o de perda escolhida afeta profundamente o comportamento do *bias-variance tradeoff*. Por exemplo, a fun√ß√£o de perda de erro quadr√°tico √© adequada para problemas de regress√£o, enquanto a fun√ß√£o de perda 0-1 √© mais apropriada para problemas de classifica√ß√£o. A perda 0-1 penaliza igualmente todas as classifica√ß√µes incorretas, enquanto o erro quadr√°tico penaliza erros maiores de maneira proporcional ao quadrado da magnitude do erro. No contexto de classifica√ß√£o, a perda 0-1 n√£o se decomp√µe em componentes de vi√©s e vari√¢ncia da mesma forma que o erro quadr√°tico, o que faz com que os modelos tenham uma intera√ß√£o mais complexa entre vi√©s e vari√¢ncia em compara√ß√£o com o erro quadr√°tico [^7.3]. Especificamente, a minimiza√ß√£o da perda 0-1 pode gerar modelos com alto vi√©s (classificando a maioria dos pontos corretamente, mas com uma probabilidade de classe incorreta) e baixa vari√¢ncia, mesmo que o modelo n√£o capture a estrutura real das probabilidades da classe [^7.3].

> üí° **Exemplo Num√©rico:** Imagine que temos um problema de classifica√ß√£o bin√°ria com apenas um preditor ($x$) e a resposta verdadeira seja $y=1$ se $x>0$ e $y=0$ se $x \le 0$. Usando a perda 0-1, um classificador simples que sempre prediz $y=1$ ter√° um erro baixo (50% dos casos certos), mas alto vi√©s, pois sempre prediz a mesma classe, n√£o dependendo de $x$. Se usarmos um modelo mais complexo que tente capturar a depend√™ncia entre x e y, ele ter√° uma alta vari√¢ncia e maior chance de errar se treinado com poucos exemplos, apesar de que seu vi√©s poderia ser baixo se treinado com mais dados.

```mermaid
graph LR
    subgraph "Loss Function Impact on Bias-Variance Tradeoff"
        direction TB
        A["Choice of Loss Function"]
        B["Squared Error Loss"]
        C["0-1 Loss"]
        D["Regression Problems"]
        E["Classification Problems"]
        F["Decomposition into Bias & Variance"]
        G["Complex Interaction between Bias and Variance"]
        A --> B
        A --> C
        B --> D
        C --> E
        C --> F
        C --> G

    end
```

**Lemma 4:** *Comportamento da Perda 0-1*

A fun√ß√£o de perda 0-1 n√£o se decomp√µe em componentes de vi√©s e vari√¢ncia da mesma forma que o erro quadr√°tico, e sua minimiza√ß√£o n√£o necessariamente leva a modelos com baixa vari√¢ncia ou alto vi√©s.
**Prova do Lemma 4:** A decomposi√ß√£o do erro em vi√©s e vari√¢ncia depende da fun√ß√£o de perda. Para a perda 0-1, o erro √© bin√°rio (0 ou 1), enquanto que a decomposi√ß√£o de vi√©s e vari√¢ncia exige a defini√ß√£o de um valor m√©dio (esperan√ßa). A perda 0-1 n√£o fornece diretamente uma decomposi√ß√£o significativa do erro em componentes de vi√©s e vari√¢ncia, pois a m√©dia da perda 0-1 n√£o reflete o erro de predi√ß√£o cont√≠nuo do modelo.
$\blacksquare$

```mermaid
graph LR
 subgraph "0-1 Loss Properties"
    direction TB
    A["0-1 Loss Function"]
    B["Binary Error (0 or 1)"]
    C["No Direct Decomposition into Bias and Variance"]
    D["Minimization does not guarantee low variance or high bias"]
    A --> B
    B --> C
    C --> D
  end
```

**Corol√°rio 4:** *Diferen√ßas nos Modelos de Classifica√ß√£o e Regress√£o*

As fun√ß√µes de perda usadas influenciam o comportamento do *bias-variance tradeoff*, o que significa que a escolha do modelo e seus par√¢metros devem ser ajustados levando em considera√ß√£o as diferen√ßas nas propriedades dessas fun√ß√µes de perda, levando a escolhas distintas de par√¢metros para classifica√ß√£o e regress√£o [^7.3].

> ‚ö†Ô∏è **Ponto Crucial**: A escolha da fun√ß√£o de perda √© crucial, e um modelo com baixa perda 0-1 n√£o significa necessariamente baixo erro de previs√£o quando se considera outras m√©tricas e o efeito do bias-variance tradeoff.

As perguntas devem ser altamente relevantes, **avaliar a compreens√£o profunda de conceitos te√≥ricos-chave**, podem envolver deriva√ß√µes matem√°ticas e provas, e focar em an√°lises te√≥ricas.

### Conclus√£o

Este cap√≠tulo abordou a rela√ß√£o fundamental entre vi√©s, vari√¢ncia e complexidade do modelo, com √™nfase na dimens√£o VC para fun√ß√µes com valores reais e suas implica√ß√µes na avalia√ß√£o de modelos. Foram discutidos detalhes sobre a regress√£o linear em matriz de indicadores, sele√ß√£o de vari√°veis, regulariza√ß√£o, e m√©todos de *separating hyperplanes*. A an√°lise aprofundada do comportamento de classifica√ß√£o com perda 0-1 refor√ßa a complexidade de se obter modelos com boa generaliza√ß√£o, e a necessidade de escolher m√©todos que equilibrem vi√©s e vari√¢ncia. A compreens√£o desses conceitos te√≥ricos √© essencial para o desenvolvimento de modelos de aprendizado de m√°quina eficazes e robustos.

### Footnotes

[^7.1]: "The generalization performance of a learning method relates to its prediction capability on independent test data. Assessment of this performance is extremely important in practice, since it guides the choice of learning method or model, and gives us a measure of the quality of the ultimately chosen model." *(Trecho de "Model Assessment and Selection")*
[^7.2]: "Figure 7.1 illustrates the important issue in assessing the ability of a learning method to generalize. Consider first the case of a quantitative or interval scale response. We have a target variable Y, a vector of inputs X, and a prediction model f(X) that has been estimated from a training set T." *(Trecho de "Model Assessment and Selection")*
[^7.3]: "The story is similar for a qualitative or categorical response G taking one of K values in a set G, labeled for convenience as 1, 2, ..., K." *(Trecho de "Model Assessment and Selection")*
[^7.9]: "A difficulty in using estimates of in-sample error is the need to specify the number of parameters (or the complexity) d used in the fit. Although the effective number of parameters introduced in Section 7.6 is useful for some nonlinear models, it is not fully general. The Vapnik-Chervonenkis (VC) theory provides such a general measure of complexity, and gives associated bounds on the optimism." *(Trecho de "Model Assessment and Selection")*

<!-- END DOCUMENT -->
