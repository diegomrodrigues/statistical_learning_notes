## Avalia√ß√£o e Sele√ß√£o de Modelos: Foco na Aproxima√ß√£o de Laplace

<imagem: Mapa mental abrangente que conecta os principais conceitos abordados no cap√≠tulo, como Bias-Variance Tradeoff, m√©todos de avalia√ß√£o (AIC, BIC, Cross-validation, Bootstrap), e aproxima√ß√µes como a de Laplace, demonstrando suas interrela√ß√µes e o papel crucial na sele√ß√£o de modelos>

### Introdu√ß√£o
A **performance de generaliza√ß√£o** de um m√©todo de aprendizado refere-se √† sua capacidade de prever com precis√£o dados de teste independentes [^7.1]. A avalia√ß√£o dessa performance √© de suma import√¢ncia na pr√°tica, pois guia a escolha do m√©todo de aprendizado ou modelo e fornece uma medida da qualidade do modelo escolhido [^7.1]. Este cap√≠tulo explora os principais m√©todos para avalia√ß√£o de performance e como eles s√£o usados na sele√ß√£o de modelos, iniciando com uma discuss√£o sobre a rela√ß√£o entre **bias, vari√¢ncia e complexidade do modelo** [^7.1]. A complexidade do modelo, como discutido em [^7.2], afeta diretamente o tradeoff entre bias e vari√¢ncia e, consequentemente, a performance de generaliza√ß√£o.

### Conceitos Fundamentais

**Conceito 1:** O **problema de classifica√ß√£o** envolve o aprendizado de um modelo $f(X)$ a partir de um conjunto de dados de treinamento $T$, de forma que $f(X)$ seja capaz de prever a classe ou valor correto de uma nova amostra de dados n√£o vista. M√©todos lineares s√£o frequentemente usados devido √† sua simplicidade e interpretabilidade, mas podem apresentar **bias** se a rela√ß√£o verdadeira entre as vari√°veis de entrada e sa√≠da n√£o for linear [^7.2]. O vi√©s surge quando o modelo √© muito simplificado e n√£o consegue capturar adequadamente a complexidade dos dados, enquanto a **vari√¢ncia** surge quando o modelo √© muito complexo e se ajusta ao ru√≠do presente no conjunto de dados de treinamento, levando a uma m√° generaliza√ß√£o [^7.2]. Por exemplo, um modelo linear simples pode apresentar alto vi√©s se a rela√ß√£o entre as vari√°veis for altamente n√£o-linear, enquanto um modelo muito complexo, como um polin√¥mio de alta ordem, pode apresentar alta vari√¢ncia se for ajustado a um conjunto de dados com ru√≠do. Encontrar um modelo com um equil√≠brio adequado entre bias e vari√¢ncia √© crucial para a boa performance de generaliza√ß√£o [^7.2].

```mermaid
graph TB
    subgraph "Bias-Variance Tradeoff"
    direction TB
        A["Model Complexity"]
        B["Bias: Underfitting, Simplification"]
        C["Variance: Overfitting, Noise"]
        D["Generalization Performance"]
        A --> B
        A --> C
        B -- "Inverse Relationship" --> D
        C -- "Inverse Relationship" --> D
    end
```

> üí° **Exemplo Num√©rico:** Imagine que queremos prever o pre√ßo de uma casa com base em seu tamanho (em metros quadrados). Temos um conjunto de dados com 10 casas.
>
> *   **Modelo 1 (Simples):** $pre√ßo = \beta_0 + \beta_1 \cdot tamanho$.  Este modelo linear pode ter um **alto bias** se a rela√ß√£o entre tamanho e pre√ßo n√£o for linear (por exemplo, se casas muito grandes tiverem um aumento de pre√ßo menos acentuado do que as casas pequenas).
>
> *   **Modelo 2 (Complexo):** $pre√ßo = \beta_0 + \beta_1 \cdot tamanho + \beta_2 \cdot tamanho^2 + \beta_3 \cdot tamanho^3$. Este modelo polinomial pode se ajustar muito bem aos dados de treino (baixo bias), mas pode apresentar **alta vari√¢ncia**. Ele pode capturar ru√≠dos ou varia√ß√µes aleat√≥rias nos dados de treinamento e apresentar um desempenho ruim para novas casas.
>
>   ```python
>   import numpy as np
>   import matplotlib.pyplot as plt
>   from sklearn.linear_model import LinearRegression
>   from sklearn.preprocessing import PolynomialFeatures
>   from sklearn.pipeline import make_pipeline
>
>   # Dados de exemplo (tamanho em m^2, pre√ßo em R$)
>   tamanho = np.array([50, 60, 70, 80, 90, 100, 110, 120, 130, 140]).reshape(-1, 1)
>   preco = np.array([150000, 180000, 220000, 250000, 280000, 300000, 320000, 330000, 340000, 350000]) + np.random.normal(0, 20000, 10)
>
>   # Modelo 1: Regress√£o Linear
>   modelo1 = LinearRegression()
>   modelo1.fit(tamanho, preco)
>
>   # Modelo 2: Regress√£o Polinomial de grau 3
>   modelo2 = make_pipeline(PolynomialFeatures(3), LinearRegression())
>   modelo2.fit(tamanho, preco)
>
>   # Plot dos resultados
>   tamanho_plot = np.linspace(40, 150, 100).reshape(-1, 1)
>   preco_modelo1 = modelo1.predict(tamanho_plot)
>   preco_modelo2 = modelo2.predict(tamanho_plot)
>
>   plt.figure(figsize=(8, 6))
>   plt.scatter(tamanho, preco, color='blue', label='Dados Reais')
>   plt.plot(tamanho_plot, preco_modelo1, color='red', label='Modelo Linear (Alto Bias)')
>   plt.plot(tamanho_plot, preco_modelo2, color='green', label='Modelo Polinomial (Alta Vari√¢ncia)')
>   plt.xlabel("Tamanho (m¬≤)")
>   plt.ylabel("Pre√ßo (R$)")
>   plt.legend()
>   plt.title("Ilustra√ß√£o do Bias-Vari√¢ncia Tradeoff")
>   plt.show()
>   ```
>
>   Neste exemplo, o modelo linear simplificado n√£o se ajusta bem aos dados, sugerindo um vi√©s. J√° o modelo polinomial segue os dados de treinamento de forma mais precisa, mas pode apresentar um comportamento inst√°vel para novos dados, o que exemplifica a alta vari√¢ncia.

**Lemma 1:** Dado um modelo de classifica√ß√£o linear $f(X) = w^T X + b$, onde $w$ s√£o os pesos e $b$ o bias, a fun√ß√£o discriminante pode ser decomposta em termos de suas proje√ß√µes nas dire√ß√µes dos autovetores da matriz de covari√¢ncia das classes, isso permite uma an√°lise mais detalhada da dire√ß√£o do hiperplano de decis√£o e da separabilidade das classes.
$$
f(X) = \sum_{i=1}^p w_i x_i + b
$$
onde $x_i$ s√£o os componentes do vetor de entrada $X$ e $w_i$ s√£o os pesos correspondentes. Cada componente $w_i x_i$ pode ser interpretado como uma proje√ß√£o de $X$ na dire√ß√£o de $w_i$. Decompondo $X$ em uma base ortonormal dada por seus autovetores $v_i$, podemos expressar:
$$
X = \sum_{i=1}^p c_i v_i
$$
onde $c_i$ s√£o os coeficientes de proje√ß√£o de $X$ nos autovetores $v_i$. Substituindo na fun√ß√£o discriminante, temos:
$$
f(X) = \sum_{i=1}^p w_i \sum_{j=1}^p c_j v_{i,j} + b = \sum_{j=1}^p c_j \sum_{i=1}^p w_i v_{i,j} + b = \sum_{j=1}^p c_j  \hat{w}_j + b
$$
onde $\hat{w}_j = \sum_{i=1}^p w_i v_{i,j}$ √© a proje√ß√£o do vetor de pesos $w$ no autovetor $v_j$. $\blacksquare$

```mermaid
graph LR
    subgraph "Linear Discriminant Function Decomposition"
        direction LR
        A["f(X) = w·µÄX + b"]
        B["X = ‚àë c·µ¢v·µ¢ (Eigenvector Decomposition)"]
        C["f(X) = ‚àë c‚±º≈µ‚±º + b (Projected Space)"]
        A --> B
        B --> C
    end
```

**Conceito 2:** **Linear Discriminant Analysis (LDA)** √© uma t√©cnica de classifica√ß√£o que assume que as classes seguem uma distribui√ß√£o normal com a mesma matriz de covari√¢ncia [^7.3]. O objetivo do LDA √© encontrar uma proje√ß√£o linear dos dados que maximize a separa√ß√£o entre as classes [^7.3.1]. A **fronteira de decis√£o** do LDA √© um hiperplano, determinado pela m√©dia das m√©dias das classes e pela matriz de covari√¢ncia comum [^7.3.2]. O LDA √© um m√©todo de classifica√ß√£o √∫til quando as suposi√ß√µes de normalidade e covari√¢ncias iguais s√£o razo√°veis, o que o torna uma abordagem menos complexa e, em geral, com boa performance em problemas bem definidos [^7.3.3]. A fun√ß√£o discriminante linear derivada pelo LDA √© √≥tima, no sentido que maximiza a separa√ß√£o entre as classes, sob as premissas do modelo [^7.3].

**Corol√°rio 1:** A fun√ß√£o discriminante linear do LDA pode ser vista como uma proje√ß√£o dos dados em um subespa√ßo de dimens√£o reduzida, maximizando a separabilidade entre classes, o que √© equivalente a encontrar a melhor dire√ß√£o de proje√ß√£o que separa as classes [^7.3.1]. Especificamente, o LDA procura a proje√ß√£o dos dados no subespa√ßo que maximiza a raz√£o entre a vari√¢ncia interclasses e a vari√¢ncia intraclasses. Essa proje√ß√£o pode ser expressa como:
$$
W_{opt} = \underset{W}{\mathrm{argmax}} \frac{|W^T S_B W|}{|W^T S_W W|}
$$
onde $S_B$ √© a matriz de vari√¢ncia interclasses e $S_W$ √© a matriz de vari√¢ncia intraclasses. A solu√ß√£o para este problema √© dada pelos autovetores de $(S_W^{-1} S_B)$. Essa proje√ß√£o reduz a dimensionalidade, enquanto mant√©m o m√°ximo de informa√ß√µes relevantes para a classifica√ß√£o, o que implica em um melhor desempenho computacional em datasets com muitas vari√°veis. $\blacksquare$

```mermaid
graph TB
    subgraph "LDA Optimization"
        direction TB
        A["Maximize Separation"]
        B["W‚Çí‚Çö‚Çú = argmax (W·µÄS_B W) / (W·µÄS_W W)"]
        C["S_B: Interclass Variance"]
        D["S_W: Intraclass Variance"]
        A --> B
        B --> C
        B --> D
    end
```

> üí° **Exemplo Num√©rico:**  Suponha que temos dados de duas classes, cada uma com duas vari√°veis. Queremos aplicar LDA para encontrar a melhor proje√ß√£o linear que separa essas classes. Vamos usar dados sint√©ticos para ilustrar o processo.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
>
> # Dados de exemplo
> np.random.seed(42)
> mean1 = [2, 2]
> cov1 = [[1, 0.5], [0.5, 1]]
> class1 = np.random.multivariate_normal(mean1, cov1, 100)
>
> mean2 = [5, 5]
> cov2 = [[1, -0.5], [-0.5, 1]]
> class2 = np.random.multivariate_normal(mean2, cov2, 100)
>
> X = np.concatenate((class1, class2))
> y = np.array([0] * 100 + [1] * 100) # Classes 0 e 1
>
> # Aplicar LDA
> lda = LinearDiscriminantAnalysis()
> lda.fit(X, y)
> X_lda = lda.transform(X)
>
> # Plot dos dados originais e projetados
> plt.figure(figsize=(12, 6))
> plt.subplot(1, 2, 1)
> plt.scatter(class1[:, 0], class1[:, 1], label='Classe 0', marker='o')
> plt.scatter(class2[:, 0], class2[:, 1], label='Classe 1', marker='x')
> plt.xlabel('Feature 1')
> plt.ylabel('Feature 2')
> plt.title('Dados Originais')
> plt.legend()
>
> plt.subplot(1, 2, 2)
> plt.scatter(X_lda[:100, 0], [0] * 100, label='Classe 0', marker='o')
> plt.scatter(X_lda[100:, 0], [0] * 100, label='Classe 1', marker='x')
> plt.xlabel('LDA Componente 1')
> plt.yticks([])
> plt.title('Dados Projetados por LDA')
> plt.legend()
>
> plt.tight_layout()
> plt.show()
>
> # Imprimir os coeficientes do LDA
> print("Coeficientes do LDA:", lda.coef_)
> ```
>
>  O c√≥digo gera dados sint√©ticos, aplica LDA e mostra a proje√ß√£o dos dados em uma √∫nica dimens√£o (ap√≥s o LDA), onde as classes est√£o mais separadas. Os coeficientes do LDA representam a dire√ß√£o no espa√ßo original que maximiza a separa√ß√£o das classes.

**Conceito 3:** A **Regress√£o Log√≠stica** √© um m√©todo para classifica√ß√£o que estima a probabilidade de uma amostra pertencer a uma determinada classe usando a fun√ß√£o log√≠stica [^7.4]. A fun√ß√£o **logit** √© utilizada para transformar a probabilidade em uma escala log-odds, tornando o problema linear [^7.4.1]. A fun√ß√£o log√≠stica mapeia qualquer valor real entre 0 e 1, o que permite a interpreta√ß√£o da sa√≠da como uma probabilidade de pertin√™ncia √† classe [^7.4.1]. O modelo √© ajustado por meio da **maximiza√ß√£o da verossimilhan√ßa** [^7.4.2], encontrando os par√¢metros que melhor se ajustam aos dados de treinamento. A regress√£o log√≠stica √© uma alternativa ao LDA quando as suposi√ß√µes de normalidade e covari√¢ncias iguais n√£o s√£o v√°lidas [^7.4.3]. Ao inv√©s de assumir uma distribui√ß√£o normal, a regress√£o log√≠stica modela a probabilidade de pertin√™ncia √† classe diretamente, por meio da fun√ß√£o log√≠stica, e o aprendizado se d√° pelo ajuste dos par√¢metros do modelo para maximizar a verossimilhan√ßa dos dados observados, comumente utilizando algoritmos de otimiza√ß√£o como o gradiente descendente [^7.4.4]. A regress√£o log√≠stica tamb√©m oferece flexibilidade com rela√ß√£o √† separabilidade linear dos dados, pois pode ser facilmente adaptada para modelar rela√ß√µes n√£o-lineares entre os preditores e a vari√°vel resposta atrav√©s de transforma√ß√µes dos preditores [^7.4.5].

> ‚ö†Ô∏è **Nota Importante**: √â crucial entender que, enquanto o LDA se baseia em suposi√ß√µes sobre as distribui√ß√µes das classes, a regress√£o log√≠stica modela diretamente a probabilidade de pertin√™ncia √† classe, o que a torna mais robusta em certos cen√°rios. **Refer√™ncia ao t√≥pico [^7.4.1]**.

> ‚ùó **Ponto de Aten√ß√£o**: Em situa√ß√µes de classes n√£o balanceadas, a regress√£o log√≠stica pode ser mais sens√≠vel, pois a maximiza√ß√£o da verossimilhan√ßa pode levar a modelos que favorecem a classe majorit√°ria. √â importante utilizar t√©cnicas como o balanceamento de classes ou a utiliza√ß√£o de pesos para corrigir este problema. **Conforme indicado em [^7.4.2]**.

> ‚úîÔ∏è **Destaque**: As estimativas dos par√¢metros em LDA e em regress√£o log√≠stica est√£o fortemente relacionadas, com ambas as abordagens buscando encontrar o hiperplano que melhor separa as classes. Em certos casos, como quando as classes possuem distribui√ß√µes normais com covari√¢ncias iguais, a regress√£o log√≠stica e o LDA podem produzir resultados semelhantes. **Baseado no t√≥pico [^7.5]**.

```mermaid
graph TB
    subgraph "Logistic Regression"
    direction TB
        A["Probability Estimation using Logistic Function"]
        B["Logit Function: Linearization of Probability"]
        C["Likelihood Maximization for Parameter Estimation"]
        A --> B
        A --> C
    end
```

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
<imagem: Diagrama de fluxo detalhado em Mermaid, mostrando o processo de regress√£o de indicadores, desde a codifica√ß√£o das classes at√© a aplica√ß√£o da regra de decis√£o, e destacando a conex√£o com m√©todos probabil√≠sticos como LDA e regress√£o log√≠stica>

```mermaid
flowchart TD
    A[Codificar Classes com Matriz Indicadora] --> B{Estimar Coeficientes via M√≠nimos Quadrados}
    B --> C[Aplicar Regra de Decis√£o Baseada em Previs√µes]
    C --> D{Comparar com M√©todos Probabil√≠sticos (LDA, Regress√£o Log√≠stica)}
    D --> E{Avaliar e Selecionar o Melhor Modelo}
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#ccf,stroke:#333,stroke-width:2px
    style C fill:#cfc,stroke:#333,stroke-width:2px
    style D fill:#ffc,stroke:#333,stroke-width:2px
    style E fill:#aaf,stroke:#333,stroke-width:2px
```

A **regress√£o linear** pode ser aplicada para problemas de classifica√ß√£o utilizando uma **matriz de indicadores**, onde cada coluna representa uma classe e os valores indicam a pertin√™ncia a esta classe. A regress√£o linear estima os coeficientes que minimizam a soma dos erros quadrados entre os valores observados e as previs√µes do modelo. Assim, podemos utilizar o modelo linear para calcular o valor da resposta para cada classe, onde cada resposta pode ser vista como um score que indica a pertin√™ncia do objeto a cada classe. A classe predita para um novo objeto √© aquela com o maior valor de resposta. No entanto, a regress√£o linear pode apresentar algumas limita√ß√µes, como o fato de as previs√µes n√£o serem necessariamente probabilidades, podendo assumir valores fora do intervalo [0, 1], o que as torna dif√≠ceis de interpretar como probabilidades [^7.1], [^7.2]. Adicionalmente, a regress√£o linear assume que a resposta √© uma combina√ß√£o linear das vari√°veis de entrada, o que pode n√£o ser verdade para dados de classifica√ß√£o.

**Lemma 2:** A solu√ß√£o de m√≠nimos quadrados para um problema de regress√£o linear com matriz de indicadores pode ser expressa como:
$$
\hat{W} = (X^T X)^{-1} X^T Y
$$
onde $X$ √© a matriz de dados, $Y$ √© a matriz de indicadores das classes, e $\hat{W}$ s√£o os coeficientes estimados.
O hiperplano de decis√£o gerado por essa abordagem pode ser derivado da an√°lise dos scores preditos para cada classe.
Para uma classifica√ß√£o em duas classes, um novo dado $x_0$ ser√° alocado √† classe 1 se:
$$
\hat{W}_1^T x_0 > \hat{W}_2^T x_0
$$
onde $\hat{W}_1$ e $\hat{W}_2$ s√£o os vetores de pesos associados √† classe 1 e 2, respectivamente. A diferen√ßa dos scores de classes definir√° a fronteira de decis√£o linear. Sob certas condi√ß√µes, a fronteira de decis√£o obtida por este m√©todo de m√≠nimos quadrados √© equivalente √†quela obtida por an√°lise discriminante linear (LDA), quando a matriz de covari√¢ncia √© assumida ser igual para todas as classes. $\blacksquare$

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction LR
        A["Indicator Matrix Y"]
        B["Coefficient Estimation: ≈¥ = (X·µÄX)‚Åª¬π X·µÄY"]
        C["Decision Boundary: ≈¥‚ÇÅ·µÄx‚ÇÄ > ≈¥‚ÇÇ·µÄx‚ÇÄ"]
         A --> B
         B --> C
    end
```

> üí° **Exemplo Num√©rico:** Suponha que temos 3 amostras e 2 classes, com dados de entrada bidimensionais. A matriz de dados X e a matriz de indicadores Y s√£o:
>
> $$X = \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \end{bmatrix} \quad Y = \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix}$$
>
> *   **Passo 1: Calcule** $X^T X$:
>  $$
>   X^T X = \begin{bmatrix} 1 & 2 & 3 \\ 2 & 1 & 3 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \end{bmatrix} = \begin{bmatrix} 14 & 13 \\ 13 & 14 \end{bmatrix}
>   $$
> *   **Passo 2: Calcule** $(X^T X)^{-1}$:
> $$
> (X^T X)^{-1} = \frac{1}{14^2 - 13^2}\begin{bmatrix} 14 & -13 \\ -13 & 14 \end{bmatrix} = \frac{1}{27} \begin{bmatrix} 14 & -13 \\ -13 & 14 \end{bmatrix} =  \begin{bmatrix} 0.5185 & -0.4815 \\ -0.4815 & 0.5185 \end{bmatrix}
> $$
> *   **Passo 3: Calcule** $X^T Y$:
>  $$
>   X^T Y = \begin{bmatrix} 1 & 2 & 3 \\ 2 & 1 & 3 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix} = \begin{bmatrix} 4 & 2 \\ 5 & 1 \end{bmatrix}
>  $$
> *   **Passo 4: Calcule** $\hat{W} = (X^T X)^{-1} X^T Y$:
>  $$
> \hat{W} = \begin{bmatrix} 0.5185 & -0.4815 \\ -0.4815 & 0.5185 \end{bmatrix}  \begin{bmatrix} 4 & 2 \\ 5 & 1 \end{bmatrix} = \begin{bmatrix} 0.67 & 0.55 \\ 0.67 & -0.55 \end{bmatrix}
>  $$
>
>  As colunas de $\hat{W}$ s√£o os coeficientes para cada classe. Para classificar um novo ponto $x_0 = [2, 2]$, calculamos os scores para cada classe.
>   
> *   **Score para a Classe 1:** $\hat{W}_1^T x_0 =  \begin{bmatrix} 0.67 & 0.67 \end{bmatrix} \begin{bmatrix} 2 \\ 2 \end{bmatrix} = 2.68$
> *   **Score para a Classe 2:** $\hat{W}_2^T x_0 = \begin{bmatrix} 0.55 & -0.55 \end{bmatrix} \begin{bmatrix} 2 \\ 2 \end{bmatrix} = 0$
>
>   Como o score da classe 1 √© maior, $x_0$ seria classificado como pertencente √† classe 1.
>
>   ```python
>   import numpy as np
>
>   # Dados de exemplo
>   X = np.array([[1, 2], [2, 1], [3, 3]])
>   Y = np.array([[1, 0], [0, 1], [1, 0]])
>
>   # C√°lculo dos coeficientes
>   XTX = X.T @ X
>   XTX_inv = np.linalg.inv(XTX)
>   XTY = X.T @ Y
>   W_hat = XTX_inv @ XTY
>
>   # Novo ponto para classificar
>   x0 = np.array([2, 2])
>
>   # Calcular os scores
>   score_classe1 = W_hat[:, 0] @ x0
>   score_classe2 = W_hat[:, 1] @ x0
>
>   print("Matriz de Coeficientes W_hat:\n", W_hat)
>   print("Score para a Classe 1:", score_classe1)
>   print("Score para a Classe 2:", score_classe2)
>
>   if score_classe1 > score_classe2:
>       print("O ponto x0 √© classificado como Classe 1.")
>   else:
>       print("O ponto x0 √© classificado como Classe 2.")
>   ```

**Corol√°rio 2:** Sob condi√ß√µes de homocedasticidade, o hiperplano de decis√£o derivado da regress√£o linear de indicadores coincide com o derivado por LDA. Isso mostra a rela√ß√£o entre o m√©todo de m√≠nimos quadrados e LDA, e pode simplificar a an√°lise de modelos lineares em certos cen√°rios. Especificamente, se as classes t√™m vari√¢ncias iguais e distribui√ß√µes normais, a fronteira de decis√£o encontrada pela regress√£o de indicadores ser√° a mesma que a encontrada pelo LDA [^7.3]. A regress√£o de indicadores pode ser vista como uma aproxima√ß√£o do LDA, com a vantagem da sua computa√ß√£o mais simples, baseada em estimativas de m√≠nimos quadrados, ao inv√©s de estimativas baseadas na distribui√ß√£o de classes, assumida pelo LDA. $\blacksquare$

A regress√£o log√≠stica, por outro lado, modela a probabilidade de pertin√™ncia √† classe utilizando a fun√ß√£o log√≠stica, que √© mais adequada para problemas de classifica√ß√£o do que um modelo linear que pode produzir valores fora do intervalo [0,1]. A regress√£o log√≠stica utiliza a fun√ß√£o logit para linearizar o problema e a maximiza√ß√£o da verossimilhan√ßa para estimar os par√¢metros do modelo. Em alguns cen√°rios, como apontado em [^7.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1]. No entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^7.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem: Mapa mental que interconecta regulariza√ß√£o L1, regulariza√ß√£o L2, Elastic Net, sparsity, e estabilidade do modelo, mostrando suas rela√ß√µes com LDA e regress√£o log√≠stica, conforme discutido nos t√≥picos [^7.5]>
```mermaid
graph TB
    subgraph "Regularization Techniques"
        direction TB
        A["L1 Regularization (Lasso)"]
        B["L2 Regularization (Ridge)"]
        C["Elastic Net Regularization"]
        D["Sparsity: Feature Selection"]
        E["Stability: Robustness to Noise"]
        A -- "Promotes" --> D
        B -- "Promotes" --> E
        C -- "Combines" --> A & B
    end
```

A **sele√ß√£o de vari√°veis** e a **regulariza√ß√£o** s√£o t√©cnicas fundamentais em classifica√ß√£o, especialmente quando h√° um grande n√∫mero de vari√°veis ou quando se busca modelos mais simples e interpret√°veis [^7.5]. A **regulariza√ß√£o L1** adiciona a soma dos valores absolutos dos coeficientes √† fun√ß√£o de custo, promovendo a **sparsity** no modelo, ou seja, for√ßando que muitos coeficientes sejam zero [^7.4.4]. Isso √© √∫til para sele√ß√£o de vari√°veis, pois as vari√°veis com coeficientes nulos s√£o efetivamente removidas do modelo. Por outro lado, a **regulariza√ß√£o L2** adiciona a soma dos quadrados dos coeficientes √† fun√ß√£o de custo, levando a coeficientes menores, mas n√£o necessariamente zero [^7.4.4]. A regulariza√ß√£o L2 promove a **estabilidade** do modelo, reduzindo o impacto de pequenas varia√ß√µes nos dados de treinamento. Uma combina√ß√£o dessas t√©cnicas, conhecida como **Elastic Net**, combina as vantagens de ambos os m√©todos, usando tanto a norma L1 quanto a norma L2 para regularizar o modelo.

**Lemma 3:** A penaliza√ß√£o L1 na regress√£o log√≠stica leva √† esparsidade dos coeficientes.
Na regress√£o log√≠stica regularizada com L1, a fun√ß√£o de custo a ser minimizada √© dada por:
$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^N \left[ y_i \log(\sigma(\beta^T x_i)) + (1-y_i) \log(1 - \sigma(\beta^T x_i)) \right] + \lambda \sum_{j=1}^p |\beta_j|
$$
onde $\sigma(\cdot)$ √© a fun√ß√£o log√≠stica, $\beta$ √© o vetor de par√¢metros do modelo, $x_i$ √© a i-√©sima amostra do conjunto de treinamento, $y_i$ √© a classe correspondente, e $\lambda$ √© o par√¢metro de regulariza√ß√£o. O termo $\lambda \sum_{j=1}^p |\beta_j|$ √© a penaliza√ß√£o L1. A sub-derivada do termo de penaliza√ß√£o L1 √© $\lambda \cdot \text{sign}(\beta_j)$. Se o vetor de par√¢metros $\beta$ for inicializado com um valor n√£o-zero, ent√£o a penaliza√ß√£o L1 ir√° "pux√°-los" em dire√ß√£o a zero durante o processo de otimiza√ß√£o. Quando $\beta_j$ atingir zero, a sub-derivada mudar√° seu sinal, e esse par√¢metro permanecer√° em zero, portanto promovendo a esparsidade dos par√¢metros. $\blacksquare$

```mermaid
graph LR
    subgraph "L1 Regularization Mechanism"
        direction LR
        A["Cost Function J(Œ≤) + Œª‚àë|Œ≤‚±º|"]
        B["Subgradient of |Œ≤‚±º| is sign(Œ≤‚±º)"]
        C["Œ≤‚±º pulled towards zero"]
        A --> B
        B --> C
    end
```

**Prova do Lemma 3:** Para demonstrar como a penaliza√ß√£o L1 leva √† esparsidade, analisemos o gradiente da fun√ß√£o de custo. Para o termo de regulariza√ß√£o L1, a subderivada da norma L1 √© $\lambda \text{sign}(\beta_j)$, onde sign √© a fun√ß√£o sinal que retorna -1 se $\beta_j$ < 0, 0 se $\beta_j$=0 e 1 se $\beta_j$ > 0. Durante a otimiza√ß√£o, se um coeficiente $\beta_j$ √© positivo, sua atualiza√ß√£o ser√° influenciada por $-\lambda$, levando-o em dire√ß√£o a zero. Se ele for negativo, sua atualiza√ß√£o ser√° influenciada por $+\lambda$, tamb√©m levando-o em dire√ß√£o a zero. Quando o coeficiente $\beta_j$ atinge zero, ele √© "puxado" em ambas as dire√ß√µes pela regulariza√ß√£o, a n√£o ser que haja um forte sinal do termo de verossimilhan√ßa que o leve para longe de zero. Assim, o efeito da penalidade L1 √© empurrar os par√¢metros para zero, resultando num modelo esparso [^7.4.4], [^7.4.3]. $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere um problema de regress√£o log√≠stica com 5 vari√°veis (features). Vamos comparar os coeficientes obtidos com e sem regulariza√ß√£o L1.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LogisticRegression
> from sklearn.preprocessing import StandardScaler
> from sklearn.model_selection import train_test_split
>
> # Criar dados sint√©ticos
> np.random.seed(42)
> X = np.random.rand(100, 5)
> y = np.random.randint(0, 2, 100)
>
> # Normalizar os dados
> scaler = StandardScaler()
> X = scaler.fit_transform(X)
>
> # Dividir os dados
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Modelo de regress√£o log√≠stica sem regulariza√ß√£o
> modelo_sem_regularizacao = LogisticRegression(penalty=None, solver='lbfgs')
> modelo_sem_regularizacao.fit(X_train, y_train)
>
> # Modelo de regress√£o log√≠stica com regulariza√ß√£o L1
> modelo_com_regularizacao = LogisticRegression(penalty='l1', solver='liblinear', C=0.1)
> modelo_com_regularizacao.fit(X_train, y_train)
>
> # Obter os coeficientes
> coef_sem_regularizacao = modelo_sem_regularizacao.coef_[0]
> coef_com_regularizacao = modelo_com_regularizacao.coef_[0]
>
> # Plotar os coeficientes
> plt.figure(figsize=(10, 5))
> plt.bar(np.arange(5)-0.2, coef_sem_regularizacao, width=0.4, label='Sem Regulariza√ß√£o', color='skyblue')
> plt.bar(np.arange(5)+0.2, coef_com_regularizacao, width=0.4, label='Com Regulariza√ß√£o L1', color='salmon')
> plt.xticks(np.arange(5), ['Feature 1', 'Feature 2', 'Feature 3', 'Feature 4', 'Feature 5'])
> plt.xlabel("Features")
> plt.ylabel("Coeficientes")
> plt.title("Compara√ß√£o de Coeficientes com e sem Regulariza√ß√£o L1")
> plt.legend()
> plt.show()
>
> # Mostrar os coeficientes
> print("Coeficientes sem regulariza√ß√£o:", coef_sem_regularizacao)
> print("Coeficientes com regulariza√ß√£o L1:", coef_com_regularizacao)
>
>   ```
>   A figura e os resultados mostram que a regulariza√ß√£o L1 zera alguns coeficientes, resultando em um modelo mais simples e com apenas as vari√°veis mais relevantes. O valor de `C` controla a for√ßa da regulariza√ß√£o L1. Valores menores de `C` aumentam a regulariza√ß√£o e tendem a gerar mais zeros nos coeficientes.

**Corol√°rio 3:** A esparsidade induzida pela regulariza√ß√£o L1 pode simplificar a interpreta√ß√£o do modelo, pois as vari√°veis com coeficientes nulos s√£o consideradas irrelevantes para a classifica√ß√£o [^7.4.5]. Isso resulta em um modelo mais simples e f√°cil de analisar, focando nas vari√°veis que realmente importam para a decis√£o, al√©m de reduzir os problemas de *overfitting*. A regulariza√ß√£o L1 pode ser vista como um m√©todo de sele√ß√£o autom√°tica de vari√°veis, onde apenas os preditores mais importantes s√£o mantidos no modelo. $\blacksquare$

> ‚ö†Ô∏è **Ponto Crucial**: L1 e L2 podem ser combinadas (Elastic Net) para aproveitar vantagens de ambos os tipos de regulariza√ß√£o, ou seja, induzir esparsidade e garantir estabilidade, o que √© especialmente √∫til quando se lida com conjuntos de dados complexos e com um grande n√∫mero de vari√°veis [^7.5].

### Separating Hyperplanes e Perceptrons
A busca por **hiperplanos separadores √≥timos**