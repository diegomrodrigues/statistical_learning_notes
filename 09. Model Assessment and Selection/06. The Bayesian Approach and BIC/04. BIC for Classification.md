Okay, let's enhance this text with practical numerical examples where appropriate, following your guidelines.

## Bayesian Information Criterion (BIC) para Classifica√ß√£o

```mermaid
graph LR
    subgraph "BIC for Model Selection"
        direction TB
        A["Data"] --> B("Model 1: Simple");
        A --> C("Model 2: Complex");
        B --> D{"Log-Likelihood"};
        C --> E{"Log-Likelihood"};
        D --> F{"BIC Calculation"};
        E --> G{"BIC Calculation"};
        F --> H{"Compare BIC Values"};
        G --> H;
        H --> I("Select Model with Lower BIC");
        style I fill:#ccf,stroke:#333,stroke-width:2px
    end
```

### Introdu√ß√£o

Este cap√≠tulo explora o uso do **Bayesian Information Criterion (BIC)** como uma ferramenta para sele√ß√£o de modelos no contexto de classifica√ß√£o. O BIC, derivado de princ√≠pios Bayesianos, oferece uma abordagem para balancear a complexidade do modelo com seu ajuste aos dados [^7.7]. A import√¢ncia da avalia√ß√£o do desempenho de um modelo de aprendizado √© central na pr√°tica, pois ela guia a escolha do melhor m√©todo e nos d√° uma medida da qualidade do modelo escolhido [^7.1]. Este cap√≠tulo se aprofunda nos conceitos-chave de avalia√ß√£o de desempenho, particularmente aqueles que envolvem o BIC em modelos de classifica√ß√£o, e como eles s√£o usados para selecionar modelos ideais [^7.1].

### Conceitos Fundamentais

**Conceito 1: Generaliza√ß√£o e Avalia√ß√£o de Modelos**

A capacidade de um modelo de aprendizado de generalizar, ou seja, de realizar previs√µes corretas em dados de teste independentes, √© um fator cr√≠tico [^7.1]. O processo de avalia√ß√£o dessa capacidade √© essencial, pois nos orienta na escolha do melhor m√©todo e quantifica a qualidade do modelo final. A avalia√ß√£o de modelos busca quantificar o qu√£o bem um modelo ajustado aos dados de treino se comporta em novos dados, n√£o vistos durante o processo de treinamento. O objetivo √© escolher um modelo que n√£o apenas se ajuste bem aos dados de treino, mas que tamb√©m generalize bem para dados futuros [^7.1].

**Lemma 1:** *A generaliza√ß√£o do erro de um modelo √© medida por sua performance em dados independentes de teste.*
A avalia√ß√£o do desempenho de um modelo √© um processo emp√≠rico, e a generaliza√ß√£o reflete a sua capacidade de fazer previs√µes em dados n√£o observados [^7.1].

**Conceito 2: Trade-off entre Vi√©s, Vari√¢ncia e Complexidade do Modelo**

A complexidade de um modelo impacta diretamente o equil√≠brio entre vi√©s e vari√¢ncia [^7.2]. Modelos mais complexos tendem a ter menor vi√©s, mas maior vari√¢ncia, pois se adaptam mais aos ru√≠dos nos dados de treinamento. Por outro lado, modelos mais simples t√™m maior vi√©s, mas menor vari√¢ncia, pois s√£o menos suscet√≠veis aos ru√≠dos. O objetivo √© encontrar um n√≠vel de complexidade que minimize o erro de generaliza√ß√£o, ou seja, que encontre um equil√≠brio entre vi√©s e vari√¢ncia [^7.2]. A complexidade do modelo deve ser escolhida para atingir o ponto em que o erro de teste esperado √© m√≠nimo [^7.2].

> üí° **Exemplo Num√©rico:** Considere um cen√°rio de classifica√ß√£o com duas classes.
> - **Modelo Simples (Linear):** Um modelo linear pode ter um vi√©s alto, pois pode n√£o conseguir capturar rela√ß√µes n√£o lineares nos dados, resultando em um erro de treinamento e teste relativamente alto. No entanto, sua vari√¢ncia √© baixa, sendo menos sens√≠vel a varia√ß√µes no conjunto de treinamento.
> - **Modelo Complexo (√Årvore de Decis√£o Profunda):** Uma √°rvore de decis√£o profunda pode ter um vi√©s muito baixo no treinamento, ajustando-se muito bem aos dados de treinamento. No entanto, ela pode ter uma alta vari√¢ncia, generalizando mal para dados n√£o vistos, o que resulta em um bom desempenho de treinamento, mas ruim no teste.
>
> O BIC nos ajuda a escolher entre esses modelos, penalizando o modelo complexo devido ao seu maior n√∫mero de par√¢metros.
>
> ```mermaid
> graph LR
>     A[Modelo Simples] -->|Baixa Vari√¢ncia, Alto Vi√©s| B(Erro Alto no Teste);
>     C[Modelo Complexo] -->|Alta Vari√¢ncia, Baixo Vi√©s| D(Erro Alto no Teste);
>     E[Modelo Ideal] -->|Baixa Vari√¢ncia, Baixo Vi√©s| F(Erro M√≠nimo no Teste);
>     style E fill:#ccf,stroke:#333,stroke-width:2px
> ```

```mermaid
graph TD
    subgraph "Bias-Variance Tradeoff"
      direction TB
        A["Model Complexity"]
        B["Bias"]
        C["Variance"]
        D["Test Error"]
        A --> B
        A --> C
        B --> D
        C --> D
        style D fill:#ccf,stroke:#333,stroke-width:2px
    end
    
```

**Corol√°rio 1:** *O erro de teste esperado, que avalia a performance de generaliza√ß√£o de um modelo, √© uma fun√ß√£o da sua complexidade. Atingir um erro m√≠nimo envolve um trade-off entre vi√©s e vari√¢ncia.*
Este trade-off √© central para o problema da sele√ß√£o de modelos, e o BIC oferece um crit√©rio para balancear esses dois fatores [^7.2].

**Conceito 3: Log-Verossimilhan√ßa e Deviance**

Em modelos de classifica√ß√£o, uma fun√ß√£o de perda comum √© a **log-verossimilhan√ßa**, tamb√©m relacionada √† **deviance** [^7.2]. A log-verossimilhan√ßa mede o qu√£o bem um modelo prediz as probabilidades de classe corretas. Para uma resposta qualitativa ou categ√≥rica, G, que assume K valores, o modelo estima as probabilidades $p_k(X) = Pr(G = k|X)$ [^7.2]. A log-verossimilhan√ßa √© usada para quantificar o ajuste do modelo aos dados, e o objetivo √© maximizar esta fun√ß√£o para modelos de classifica√ß√£o [^7.2].

> üí° **Exemplo Num√©rico:** Suponha um problema de classifica√ß√£o bin√°ria com duas classes (0 e 1). Temos um conjunto de dados com 5 amostras, com as classes verdadeiras e as probabilidades previstas por um modelo, conforme abaixo:
>
> | Amostra | Classe Verdadeira (y) | Probabilidade Prevista P(y=1)  |
> |---|---|---|
> | 1 | 1 | 0.9 |
> | 2 | 0 | 0.2 |
> | 3 | 1 | 0.7 |
> | 4 | 0 | 0.1 |
> | 5 | 1 | 0.6 |
>
> A log-verossimilhan√ßa para cada amostra √© calculada como:
> - Se $y_i = 1$: $log(p_i)$
> - Se $y_i = 0$: $log(1 - p_i)$
>
> Os resultados s√£o:
> - Amostra 1: $log(0.9) \approx -0.105$
> - Amostra 2: $log(1 - 0.2) = log(0.8) \approx -0.223$
> - Amostra 3: $log(0.7) \approx -0.357$
> - Amostra 4: $log(1 - 0.1) = log(0.9) \approx -0.105$
> - Amostra 5: $log(0.6) \approx -0.511$
>
> A log-verossimilhan√ßa total do modelo √© a soma das log-verossimilhan√ßas das amostras:
> $LogLik = -0.105 - 0.223 - 0.357 - 0.105 - 0.511 = -1.301$
>
> A deviance √© definida como -2 * log-verossimilhan√ßa, ent√£o a deviance nesse exemplo √©:
> $Deviance = -2 * (-1.301) = 2.602$
>
> Um modelo com uma log-verossimilhan√ßa maior (e deviance menor) se ajusta melhor aos dados.

```mermaid
graph LR
    subgraph "Log-Likelihood and Deviance"
        direction TB
        A["Data"] --> B["Model Predictions"];
        B --> C{"Log-Likelihood per Sample: log(p) if y=1, log(1-p) if y=0"};
        C --> D["Total Log-Likelihood: Sum of Log-Likelihoods"];
        D --> E{"Deviance = -2 * Log-Likelihood"};
    end
```

> ‚ö†Ô∏è **Nota Importante**: A deviance, definida como -2 vezes a log-verossimilhan√ßa, √© uma medida comum para avaliar o ajuste de modelos estat√≠sticos [^7.2].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regression Approaches for Classification"
        direction LR
        A["Input Data"] --> B["Linear Regression on Indicator Matrix"];
        A --> C["Logistic Regression"];
        B --> D["Linear Decision Boundaries"];
        C --> E["Probabilistic Estimates"];
        D --> F["Limitations: Extrapolation, Non-Probabilistic"];
        E --> G["More Stable and Interpretable"];
    end
```

A regress√£o linear, quando aplicada a uma matriz de indicadores, pode ser utilizada para classifica√ß√£o, apesar de suas limita√ß√µes [^4.2]. A ideia b√°sica envolve codificar as classes em vari√°veis bin√°rias (matriz de indicadores) e aplicar regress√£o linear. Contudo, essa abordagem ignora a natureza categ√≥rica das vari√°veis de resposta, n√£o fornecendo estimativas de probabilidade adequadas e sofrendo de problemas de extrapola√ß√£o fora do intervalo [0,1] [^4.2]. Em situa√ß√µes onde o foco principal √© a fronteira de decis√£o linear e n√£o as estimativas de probabilidade, a regress√£o em matriz de indicadores pode ser suficiente [^4.2].

**Lemma 2:** *Em certas condi√ß√µes, a proje√ß√£o nos hiperplanos de decis√£o gerados por regress√£o linear sobre uma matriz de indicadores √© equivalente √† proje√ß√£o obtida por discriminantes lineares.*
Essa equival√™ncia sugere uma rela√ß√£o entre essas abordagens em casos espec√≠ficos, mas suas limita√ß√µes s√£o importantes [^4.2], [^4.3].

**Corol√°rio 2:** *Essa equival√™ncia pode simplificar a an√°lise do modelo em cen√°rios espec√≠ficos, oferecendo uma interpreta√ß√£o linear das decis√µes de classifica√ß√£o.*
A regress√£o de indicadores, apesar de sua simplicidade, n√£o se ajusta bem em situa√ß√µes onde o objetivo √© estimar probabilidades com precis√£o.

Comparativamente, a regress√£o log√≠stica √© mais adequada para modelar probabilidades, fornecendo estimativas mais est√°veis e interpret√°veis [^4.4]. Enquanto a regress√£o de indicadores tenta ajustar uma linha reta (ou hiperplano) √†s classes, a regress√£o log√≠stica usa a fun√ß√£o log√≠stica para modelar as probabilidades das classes [^4.4].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["Model Complexity"] --> B["L1 Regularization (Lasso)"];
        A --> C["L2 Regularization (Ridge)"];
        B --> D["Sparse Coefficients"];
        C --> E["Reduced Coefficient Magnitude"];
         D & E --> F["Improved Generalization"];
         F --> G["Elastic Net (L1+L2)"];
    end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas cruciais para melhorar a generaliza√ß√£o de modelos de classifica√ß√£o, especialmente quando h√° um grande n√∫mero de preditores [^4.5]. A **regulariza√ß√£o L1** (Lasso) e a **regulariza√ß√£o L2** (Ridge) s√£o comumente usadas para controlar a complexidade do modelo e evitar o *overfitting* [^4.4.4]. A regulariza√ß√£o L1 penaliza a soma dos valores absolutos dos coeficientes, o que pode levar a coeficientes esparsos (i.e., alguns coeficientes s√£o exatamente zero), promovendo a sele√ß√£o de vari√°veis [^4.5]. A regulariza√ß√£o L2 penaliza a soma dos quadrados dos coeficientes, o que reduz a magnitude dos coeficientes, tornando o modelo mais est√°vel e menos sens√≠vel a pequenas mudan√ßas nos dados de treinamento [^4.5].

> üí° **Exemplo Num√©rico:** Vamos considerar um cen√°rio de classifica√ß√£o com 10 preditores (X1, X2, ..., X10). Ajustamos um modelo de regress√£o log√≠stica com e sem regulariza√ß√£o L1 (Lasso), e observe os coeficientes resultantes:
>
> **Modelo sem regulariza√ß√£o:**
>
> | Preditores | Coeficientes |
> |------------|--------------|
> | X1         | 1.2          |
> | X2         | -0.8         |
> | X3         | 0.5          |
> | X4         | -0.3         |
> | X5         | 0.7          |
> | X6         | -0.2         |
> | X7         | 0.4          |
> | X8         | -0.1         |
> | X9         | 0.2          |
> | X10        | -0.6         |
>
> **Modelo com regulariza√ß√£o L1 (Lasso):**
>
> | Preditores | Coeficientes |
> |------------|--------------|
> | X1         | 1.0          |
> | X2         | -0.6         |
> | X3         | 0.0          |
> | X4         | 0.0         |
> | X5         | 0.5          |
> | X6         | 0.0        |
> | X7         | 0.0          |
> | X8         | 0.0          |
> | X9         | 0.0          |
> | X10        | -0.3         |
>
> Observe que a regulariza√ß√£o L1 zerou os coeficientes de v√°rios preditores (X3, X4, X6, X7, X8 e X9), indicando que eles n√£o s√£o t√£o relevantes para o modelo. Isso simplifica o modelo e pode melhorar a generaliza√ß√£o, al√©m de facilitar a interpreta√ß√£o.

**Lemma 3:** *A penaliza√ß√£o L1 em classifica√ß√£o log√≠stica leva a coeficientes esparsos, facilitando a sele√ß√£o de vari√°veis relevantes para o modelo.*
Essa propriedade de esparsidade √© particularmente √∫til quando h√° muitos preditores e apenas alguns s√£o verdadeiramente importantes [^4.4.4].

**Prova do Lemma 3:** A regulariza√ß√£o L1 adiciona um termo de penaliza√ß√£o √† fun√ß√£o de custo, dado por $ \lambda \sum_{j=1}^p |\beta_j| $, onde $\lambda$ √© o par√¢metro de regulariza√ß√£o e $\beta_j$ s√£o os coeficientes do modelo. A natureza da penaliza√ß√£o L1 for√ßa alguns dos coeficientes a serem exatamente zero durante a otimiza√ß√£o, gerando um modelo esparso. A otimiza√ß√£o com L1 geralmente envolve m√©todos de otimiza√ß√£o n√£o suaves, como *subgradients* [^4.4.3], demonstrando o efeito da penaliza√ß√£o L1 na sele√ß√£o de vari√°veis. $\blacksquare$

**Corol√°rio 3:** *A esparsidade dos coeficientes, induzida pela regulariza√ß√£o L1, leva a modelos mais interpret√°veis, facilitando a identifica√ß√£o dos preditores mais relevantes.*
O uso da regulariza√ß√£o L1 resulta em um modelo mais simples e focado nos preditores mais importantes, melhorando a interpretabilidade e a generaliza√ß√£o [^4.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: √â poss√≠vel combinar a regulariza√ß√£o L1 e L2, criando um m√©todo chamado Elastic Net, para aproveitar vantagens de ambos os tipos de regulariza√ß√£o [^4.5].

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Separating Hyperplanes"
        direction TB
        A["Data with Class Labels"] --> B["Search for Optimal Hyperplane"];
        B --> C{"Maximize Margin of Separation"};
        C --> D["Support Vector Machines (SVM)"];
        B --> E["Perceptron Algorithm"];
        E --> F{"Convergence to Separating Hyperplane (if data is separable)"};
    end
```

A ideia de maximizar a **margem de separa√ß√£o** entre as classes leva ao conceito de **hiperplanos √≥timos**, que s√£o a base dos *Support Vector Machines* (SVMs) e de outros m√©todos de classifica√ß√£o linear [^4.5.2]. Hiperplanos √≥timos s√£o obtidos resolvendo um problema de otimiza√ß√£o que busca maximizar a dist√¢ncia entre o hiperplano e os pontos de dados mais pr√≥ximos (os chamados vetores de suporte). Este problema de otimiza√ß√£o pode ser resolvido atrav√©s da formula√ß√£o dual de Wolfe, que muitas vezes √© mais computacionalmente trat√°vel [^4.5.2]. As solu√ß√µes para esses problemas de otimiza√ß√£o s√£o combina√ß√µes lineares dos pontos de suporte, destacando a import√¢ncia desses pontos na defini√ß√£o da fronteira de decis√£o [^4.5.2].

O **Perceptron de Rosenblatt** √© um algoritmo de aprendizado de m√°quina que, sob condi√ß√µes espec√≠ficas de separabilidade dos dados, garante converg√™ncia para um hiperplano que separa as classes [^4.5.1]. A converg√™ncia do Perceptron depende da exist√™ncia de uma fronteira de separa√ß√£o linear perfeita.

### Pergunta Te√≥rica Avan√ßada: Qual a rela√ß√£o entre a formula√ß√£o do BIC e a aproxima√ß√£o de Laplace para a probabilidade posterior de um modelo?

**Resposta:**

O **Bayesian Information Criterion (BIC)** √© um crit√©rio de sele√ß√£o de modelo derivado de uma aproxima√ß√£o da probabilidade posterior de um modelo, dada pelos dados [^7.7]. Em ess√™ncia, o BIC busca o modelo que maximiza a probabilidade posterior aproximada, que √© uma combina√ß√£o da verossimilhan√ßa dos dados sob o modelo e da complexidade do modelo. A complexidade √© penalizada na forma de um termo que cresce com o n√∫mero de par√¢metros e o tamanho da amostra, evitando o *overfitting* [^7.7]. A aproxima√ß√£o de Laplace √© um m√©todo para aproximar a integral da probabilidade posterior utilizando uma fun√ß√£o gaussiana, centrada no m√°ximo da fun√ß√£o de verossimilhan√ßa, que √© utilizada para derivar o BIC.

```mermaid
graph LR
  subgraph "BIC and Laplace Approximation"
      direction TB
      A["Bayesian Posterior Probability"] --> B["Laplace Approximation"];
      B --> C["Log Posterior Approximation"];
      C --> D["-2 * Log-Likelihood term"];
      C --> E["Penalty Term: (log N) * d"];
      D & E --> F["BIC Formulation"];
  end
```

**Lemma 4:** *A aproxima√ß√£o de Laplace para a integral da probabilidade posterior de um modelo, dada pelos dados, leva √† formula√ß√£o do BIC, mostrando a conex√£o entre esses dois conceitos.*
A aproxima√ß√£o de Laplace da integral que define a probabilidade posterior de um modelo ($Pr(Z|M_m)$), usando o m√©todo *Laplace‚Äôs method* e algumas simplifica√ß√µes (Ripley, 1996), pode ser derivada da seguinte forma:
$$ log \, Pr(Z|M_m) = log \, Pr(Z|\hat{\theta}_m,M_m) - \frac{d_m}{2} log \, N + O(1) $$.
Onde $\hat{\theta}_m$ √© a estimativa de m√°xima verossimilhan√ßa e $d_m$ √© o n√∫mero de par√¢metros livres no modelo $M_m$ [^7.7].

> üí° **Exemplo Num√©rico:** Suponha que temos dois modelos de classifica√ß√£o para os mesmos dados:
>
> - **Modelo 1 (M1):** Um modelo log√≠stico com 3 par√¢metros e uma log-verossimilhan√ßa m√°xima de -500.
> - **Modelo 2 (M2):** Um modelo mais complexo com 7 par√¢metros e uma log-verossimilhan√ßa m√°xima de -480.
>
> Temos 100 amostras no nosso dataset. Vamos calcular o BIC para cada modelo:
>
> Para o **Modelo 1 (M1):**
> $$ BIC_{M1} = -2 * (-500) + (log(100)) * 3 = 1000 + 4.605 * 3 \approx 1000 + 13.815 \approx 1013.815$$
>
> Para o **Modelo 2 (M2):**
> $$ BIC_{M2} = -2 * (-480) + (log(100)) * 7 = 960 + 4.605 * 7 \approx 960 + 32.235 \approx 992.235 $$
>
> Como o BIC do Modelo 2 √© menor que o BIC do Modelo 1, o BIC indica que o Modelo 2 (mais complexo) √© prefer√≠vel neste caso, pois, mesmo com mais par√¢metros, o ganho em verossimilhan√ßa compensa a penalidade do BIC.
>
> Se tiv√©ssemos um dataset menor, com apenas 30 amostras, o BIC do Modelo 1 seria:
> $$BIC_{M1} = -2 * (-500) + (log(30)) * 3 = 1000 + 3.401 * 3 \approx 1000 + 10.203 = 1010.203$$
> E o BIC do Modelo 2 seria:
> $$BIC_{M2} = -2 * (-480) + (log(30)) * 7 = 960 + 3.401 * 7 \approx 960 + 23.807 = 983.807$$
>
> Em um dataset ainda menor, com 10 amostras, o BIC do Modelo 1 seria:
> $$BIC_{M1} = -2 * (-500) + (log(10)) * 3 = 1000 + 2.303 * 3 \approx 1000 + 6.909 = 1006.909$$
> E o BIC do Modelo 2 seria:
> $$BIC_{M2} = -2 * (-480) + (log(10)) * 7 = 960 + 2.303 * 7 \approx 960 + 16.121 = 976.121$$
>
> Observe como o tamanho da amostra (N) influencia a penalidade imposta no BIC. Com amostras pequenas, a penalidade sobre modelos complexos (Modelo 2) √© reduzida.

**Corol√°rio 4:** *O BIC pode ser interpretado como uma aproxima√ß√£o da probabilidade posterior de um modelo, que penaliza a complexidade do modelo para evitar o overfitting.*

The formulation of the BIC is given by:
$$ BIC = -2 \, loglik + (log \, N) \, d $$.
Where loglik is the maximized log-likelihood of the model and *d* is the number of parameters of the model. The penalty for complexity ($log \, N * d$) emerges directly from the Laplace approximation.

> ‚ö†Ô∏è **Ponto Crucial**: A motiva√ß√£o Bayesiana do BIC justifica sua capacidade de escolher modelos mais simples quando a evid√™ncia nos dados n√£o suporta uma complexidade maior, o que √© crucial na sele√ß√£o de modelos de classifica√ß√£o [^7.7].

### Conclus√£o

O BIC oferece um crit√©rio pr√°tico e fundamentado teoricamente para a sele√ß√£o de modelos de classifica√ß√£o. Ele equilibra o ajuste aos dados com a complexidade do modelo, penalizando modelos complexos em favor de modelos mais simples, que tendem a generalizar melhor. Ao combinar princ√≠pios Bayesianos com uma an√°lise de complexidade, o BIC se torna uma ferramenta valiosa no arsenal de um profissional de estat√≠stica e aprendizado de m√°quina, que busca modelos robustos e interpret√°veis.

### Footnotes

[^7.1]: "The generalization performance of a learning method relates to its prediction capability on independent test data. Assessment of this performance is extremely important in practice, since it guides the choice of learning method or model, and gives us a measure of the quality of the ultimately chosen model." *(Trecho de "Model Assessment and Selection")*
[^7.2]: "Figure 7.1 illustrates the important issue in assessing the ability of a learning method to generalize. Consider first the case of a quantitative or interval scale response. We have a target variable Y, a vector of inputs X, and a prediction model f(X) that has been estimated from a training set T." *(Trecho de "Model Assessment and Selection")*
[^7.7]: "The Bayesian information criterion (BIC), like AIC, is applicable in settings where the fitting is carried out by maximization of a log-likelihood. The generic form of BIC is BIC = -2 loglik + (log N) ¬∑ d" *(Trecho de "Model Assessment and Selection")*
[^4.2]: "We begin the chapter with a discussion of the interplay between bias, variance and model complexity." *(Trecho de "Linear Regression of an Indicator Matrix")*
[^4.3]: "We now turn to a direct linear method for classification, called linear discriminant analysis (LDA)." *(Trecho de "Linear Discriminant Analysis (LDA)")*
[^4.4]: "Logistic regression is another popular approach for binary classification, where we model directly the probabilities pk(x)." *(Trecho de "Logistic Regression")*
[^4.4.4]: "An alternative, often better strategy is to fit a regularized version of the logistic regression model, by adding a penalty term to the likelihood." *(Trecho de "Logistic Regression")*
[^4.5]: "In order to handle all these situations, we will introduce the notion of a separating hyperplane. This geometric idea turns out to be central for linear classification." *(Trecho de "Separating Hyperplanes")*
[^4.5.1]: "Here we describe the oldest of these classifiers, called the perceptron, invented by Rosenblatt in 1957." *(Trecho de "Separating Hyperplanes")*
[^4.5.2]: "The maximum margin method is described here. It solves the problem by maximizing the distance between separating hyperplane and data." *(Trecho de "Separating Hyperplanes")*
