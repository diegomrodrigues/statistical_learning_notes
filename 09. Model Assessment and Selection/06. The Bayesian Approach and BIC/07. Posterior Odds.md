## Avalia√ß√£o e Sele√ß√£o de Modelos: Foco em Posterior Odds

<imagem: Diagrama de fluxo mostrando o processo de avalia√ß√£o de modelos, desde a divis√£o dos dados em conjuntos de treino, valida√ß√£o e teste, at√© a aplica√ß√£o de m√©todos de sele√ß√£o (AIC, BIC, Cross-Validation) e avalia√ß√£o final da performance do modelo, com √™nfase no conceito de Posterior Odds.>

### Introdu√ß√£o

A capacidade de generaliza√ß√£o de um m√©todo de aprendizado, ou seja, a sua performance preditiva em dados independentes de teste, √© fundamental [^7.1]. A avalia√ß√£o dessa performance √© crucial na pr√°tica, pois ela orienta a escolha do m√©todo ou modelo de aprendizado e fornece uma medida da qualidade do modelo escolhido. Este cap√≠tulo detalha os m√©todos essenciais para avalia√ß√£o de desempenho e como eles s√£o usados para sele√ß√£o de modelos. Iniciamos explorando a intera√ß√£o entre **bias**, **variance** e a **complexidade do modelo**, culminando com uma discuss√£o aprofundada sobre o conceito de **Posterior Odds** para sele√ß√£o de modelos Bayesianos [^7.1], [^7.7].

### Conceitos Fundamentais

**Conceito 1: Generaliza√ß√£o e Erro de Predi√ß√£o**

A **generaliza√ß√£o** refere-se √† capacidade de um modelo de aprendizado de desempenhar bem em dados n√£o vistos, ou seja, dados diferentes daqueles utilizados no treinamento [^7.1]. Para quantificar essa capacidade, utilizamos **fun√ß√µes de perda** que medem o erro entre as predi√ß√µes do modelo $\hat{f}(X)$ e os valores verdadeiros $Y$. As escolhas t√≠picas incluem o **erro quadr√°tico m√©dio** $L(Y, \hat{f}(X)) = (Y - \hat{f}(X))^2$ e o **erro absoluto** $L(Y, \hat{f}(X)) = |Y - \hat{f}(X)|$. √â importante notar que a complexidade do modelo, ao buscar adaptar-se aos dados de treino, pode levar a um decr√©scimo no *bias*, mas tamb√©m a um aumento na *variance* [^7.2]. O objetivo √©, portanto, encontrar uma complexidade intermedi√°ria que minimize o **erro de teste esperado**.

**Lemma 1:** A decomposi√ß√£o do Erro de Predi√ß√£o

O **erro de teste** para um dado conjunto de treinamento $T$, definido como $Err_T = E[L(Y, \hat{f}(X)) | T]$, √© uma vari√°vel aleat√≥ria que depende de $T$. O **erro de teste esperado**, definido como $Err = E[L(Y, \hat{f}(X))] = E[Err_T]$, √© uma medida mais est√°vel e estatisticamente trat√°vel [^7.2]. Usando o erro quadr√°tico, podemos decompor o erro em:
$$
Err(x_0) = E[(Y - \hat{f}(x_0))^2 | X=x_0] = \sigma^2 + Bias^2(\hat{f}(x_0)) + Var(\hat{f}(x_0))
$$
onde:
- $\sigma^2$ √© a vari√¢ncia do erro irredut√≠vel.
- $Bias^2(\hat{f}(x_0)) = [E\hat{f}(x_0) - f(x_0)]^2$ √© o bias ao quadrado.
- $Var(\hat{f}(x_0)) = E[\hat{f}(x_0) - E\hat{f}(x_0)]^2$ √© a vari√¢ncia.

Esta decomposi√ß√£o √© fundamental para entender o trade-off entre *bias* e *variance* [^7.3]. $\blacksquare$
```mermaid
graph TB
    subgraph "Decomposition of Expected Test Error"
        direction TB
        A["Expected Test Error: Err(x_0)"]
        B["Irreducible Error: œÉ¬≤"]
        C["Squared Bias: Bias¬≤(fÃÇ(x_0)) = (E[fÃÇ(x_0)] - f(x_0))¬≤"]
        D["Variance: Var(fÃÇ(x_0)) = E[(fÃÇ(x_0) - E[fÃÇ(x_0)])¬≤]"]
        A --> B
        A --> C
        A --> D
    end
```

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo de regress√£o para prever o pre√ßo de casas ($Y$) com base no tamanho em metros quadrados ($X$). O verdadeiro modelo √© $f(x) = 500 + 100x$, mas nosso modelo $\hat{f}(x)$ √© estimado com dados de treinamento.
>
> 1.  **Erro Irredut√≠vel:** Existe uma varia√ß√£o no pre√ßo das casas que n√£o pode ser explicada pelo tamanho, $\sigma^2 = 5000$.
> 2.  **Bias:** Se nosso modelo de regress√£o linear subestima os pre√ßos, por exemplo, com $\hat{f}(x) = 400 + 80x$, ent√£o o $Bias^2$ pode ser calculado para um $x_0 = 10$: $Bias^2(\hat{f}(10)) = [E(\hat{f}(10)) - f(10)]^2 = [(400 + 80 \cdot 10) - (500 + 100 \cdot 10)]^2 = (1200 - 1500)^2 = 90000$.
> 3.  **Vari√¢ncia:** Se, devido √† aleatoriedade dos dados de treinamento, o modelo pode variar bastante, digamos que $Var(\hat{f}(10)) = 20000$.
>
> O erro total esperado para $x_0 = 10$ seria ent√£o: $Err(10) = 5000 + 90000 + 20000 = 115000$. Este exemplo ilustra como o erro de predi√ß√£o √© composto de diferentes fontes, e como a complexidade do modelo (aqui, os par√¢metros do modelo) influencia o *bias* e a *vari√¢ncia*. Um modelo mais complexo (por exemplo, um polin√¥mio de maior grau) poderia reduzir o bias, mas aumentaria a vari√¢ncia.

**Conceito 2: An√°lise Discriminante Linear (LDA)**

A **An√°lise Discriminante Linear (LDA)** √© um m√©todo de classifica√ß√£o que assume que as classes seguem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia [^7.3]. O objetivo da LDA √© encontrar uma **fun√ß√£o discriminante linear** que maximize a separa√ß√£o entre as classes, ou seja, uma proje√ß√£o dos dados em um espa√ßo de menor dimens√£o que preserve a informa√ß√£o relevante para a classifica√ß√£o. A fun√ß√£o discriminante linear √© dada por:

$$ \delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + log(\pi_k) $$

Onde:
- $x$ √© o vetor de caracter√≠sticas.
- $\Sigma$ √© a matriz de covari√¢ncia comum.
- $\mu_k$ √© o vetor de m√©dias da classe k.
- $\pi_k$ √© a probabilidade a priori da classe k.

As suposi√ß√µes de normalidade e covari√¢ncias iguais podem ser limitantes, mas a LDA √© um m√©todo eficaz e computacionalmente eficiente para classifica√ß√£o [^7.3.1], [^7.3.2], [^7.3.3].
```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction LR
        A["Discriminant Function: Œ¥k(x)"]
        B["Linear Term: x·µÄŒ£‚Åª¬πŒºk"]
        C["Quadratic Term: -1/2 Œºk·µÄŒ£‚Åª¬πŒºk"]
        D["Prior Probability: log(œÄk)"]
        A --> B
        A --> C
        A --> D
    end
```
**Corol√°rio 1:** Fronteiras de Decis√£o na LDA

Sob as suposi√ß√µes da LDA, as fronteiras de decis√£o entre as classes s√£o lineares e definidas pelos pontos onde $\delta_k(x) = \delta_l(x)$ para classes $k$ e $l$ [^7.3.1]. As derivadas dessas fronteiras s√£o diretamente influenciadas pelas m√©dias e pela matriz de covari√¢ncia compartilhada. Essas proje√ß√µes lineares s√£o a base para classificar novos pontos de dados, alinhando-os com as classes previamente definidas. A an√°lise das equa√ß√µes da LDA revela a import√¢ncia da invers√£o da matriz de covari√¢ncia e como essa transforma√ß√£o afeta a classifica√ß√£o [^7.3.1].

> üí° **Exemplo Num√©rico:** Suponha que temos duas classes, A e B, com as seguintes m√©dias e matriz de covari√¢ncia comum:
>  - $\mu_A = [1, 2]^T$
>  - $\mu_B = [3, 4]^T$
>  - $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
>  - $\pi_A = 0.6$ e $\pi_B = 0.4$
>
>  A inversa da matriz de covari√¢ncia √©:
>  $\Sigma^{-1} = \frac{1}{0.75} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$
>
>  A fun√ß√£o discriminante para a classe A √©:
>  $\delta_A(x) = x^T \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} + \log(0.6)$
>  $\delta_A(x) = x^T \begin{bmatrix} 0 \\ 2 \end{bmatrix} - \frac{1}{2} (0+2) + \log(0.6)$
>  $\delta_A(x) = 2x_2 - 1 + \log(0.6)$
>
>  De forma semelhante para a classe B, temos:
>  $\delta_B(x) = 2x_2 - 5 + \log(0.4)$
>
>  A fronteira de decis√£o √© definida por $\delta_A(x) = \delta_B(x)$, o que leva a:
>  $2x_2 - 1 + \log(0.6) = 2x_2 - 5 + \log(0.4)$
>  $4 = \log(0.4) - \log(0.6) = \log(0.4/0.6)$
>
>  Assim, a fronteira de decis√£o seria $2x_2 - 1 + \log(0.6) = 2x_2 - 5 + \log(0.4)$, que simplificando ( e aproximando o valor do log) temos $4 \approx -0.405$, resultando em uma reta, como esperado em LDA, e em um erro de aproxima√ß√£o por conta da aproxima√ß√£o do log. Este exemplo num√©rico mostra como a fun√ß√£o discriminante √© calculada e como os par√¢metros das classes influenciam a fronteira de decis√£o.

**Conceito 3: Regress√£o Log√≠stica**

A **Regress√£o Log√≠stica** √© um m√©todo para classifica√ß√£o que modela a probabilidade de pertencer a uma classe utilizando uma fun√ß√£o sigmoide ou log√≠stica. A probabilidade de pertencer a classe 1, $p(X)$, √© modelada pela seguinte equa√ß√£o:

$$ logit(p(X)) = log \left( \frac{p(X)}{1-p(X)} \right) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_n X_n $$

onde:
- $logit(p(X))$ √© a transforma√ß√£o logit da probabilidade, que mapeia a probabilidade de [0,1] para (-‚àû,+‚àû).
- $\beta_0$ √© o intercepto.
- $\beta_1, \beta_2, \ldots, \beta_n$ s√£o os coeficientes do modelo.
- $X_1, X_2, \ldots, X_n$ s√£o as vari√°veis preditoras.

Os par√¢metros s√£o estimados por **m√°xima verossimilhan√ßa**, maximizando a probabilidade dos dados observados [^7.4]. A fun√ß√£o de verossimilhan√ßa √© dada por:
$$L(\beta) = \sum_i y_i \log(p(x_i)) + (1 - y_i) \log(1 - p(x_i))$$

A Regress√£o Log√≠stica √© um m√©todo flex√≠vel, que n√£o requer as suposi√ß√µes de normalidade da LDA [^7.4], [^7.4.1], [^7.4.2], [^7.4.3], [^7.4.4], [^7.4.5]. Ela √© amplamente utilizada em problemas de classifica√ß√£o bin√°ria e pode ser estendida para problemas com m√∫ltiplas classes [^7.4].
```mermaid
graph LR
    subgraph "Logistic Regression Model"
    direction LR
    A["Logit Transformation: logit(p(X))"]
    B["Linear Combination of Predictors: Œ≤‚ÇÄ + Œ≤‚ÇÅX‚ÇÅ + ... + Œ≤‚ÇôX‚Çô"]
    A --> B
    end
```

> ‚ö†Ô∏è **Nota Importante**: A regress√£o log√≠stica modela diretamente a probabilidade de pertencimento a uma classe, o que pode ser mais adequado em muitos casos do que as fun√ß√µes discriminantes da LDA. [^7.4.1]
> ‚ùó **Ponto de Aten√ß√£o**: A presen√ßa de classes n√£o balanceadas pode distorcer as estimativas de par√¢metros e probabilidades na regress√£o log√≠stica, exigindo t√©cnicas como undersampling ou oversampling para mitigar esses efeitos. [^7.4.2]
> ‚úîÔ∏è **Destaque**: A regress√£o log√≠stica e a LDA compartilham um modelo linear, o que resulta em fronteiras de decis√£o lineares. No entanto, a abordagem de estima√ß√£o dos par√¢metros √© diferente: a LDA usa uma abordagem de m√≠nimos quadrados, enquanto a regress√£o log√≠stica usa m√°xima verossimilhan√ßa. [^7.5]

> üí° **Exemplo Num√©rico:** Suponha que estamos modelando a probabilidade de um cliente comprar um produto (Y=1) baseado na sua idade ($X_1$) e renda ($X_2$). Ap√≥s a estima√ß√£o dos par√¢metros via m√°xima verossimilhan√ßa, temos:
>  $$logit(p(X)) = -5 + 0.05X_1 + 0.001X_2$$
>
>  Para um cliente de 30 anos e renda de 5000, a probabilidade de compra √©:
>  $$logit(p(X)) = -5 + 0.05 \cdot 30 + 0.001 \cdot 5000 = -5 + 1.5 + 5 = 1.5$$
>
>  Para calcular a probabilidade, usamos a fun√ß√£o inversa do logit (fun√ß√£o sigmoide):
>  $$p(X) = \frac{e^{logit(p(X))}}{1 + e^{logit(p(X))}} = \frac{e^{1.5}}{1 + e^{1.5}} \approx 0.818$$
>
>  Isso significa que um cliente com essas caracter√≠sticas tem uma probabilidade de aproximadamente 81.8% de comprar o produto. A regress√£o log√≠stica nos permite modelar probabilidades diretamente e usar esses valores para classifica√ß√£o, definindo um limiar, como 0.5, para classificar um cliente como comprador ou n√£o comprador. A fun√ß√£o de verossimilhan√ßa ser√° maximizada para encontrar os valores √≥timos dos par√¢metros $\beta$.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

<imagem: Mapa mental mostrando as conex√µes entre regress√£o linear para classifica√ß√£o, codifica√ß√£o de classes, estima√ß√£o via m√≠nimos quadrados, regra de decis√£o e compara√ß√µes com m√©todos probabil√≠sticos.>

```mermaid
flowchart TD
  subgraph "Indicator Regression for Classification"
    A["Encode Classes into Indicator Variables"] --> B["Estimate Coefficients via Least Squares (LS)"]
    B --> C["Apply Decision Rule"]
    C --> D["Compare with Probabilistic Methods"]
  end
```

A regress√£o linear pode ser utilizada para classifica√ß√£o atrav√©s da codifica√ß√£o de classes em vari√°veis indicadoras. Por exemplo, em um problema com $K$ classes, podemos definir uma matriz de indicadores $Y$ de dimens√£o $N \times K$, onde cada linha representa uma observa√ß√£o e cada coluna representa uma classe. Cada elemento $y_{ik}$ da matriz indica se a observa√ß√£o $i$ pertence √† classe $k$ ($y_{ik}=1$) ou n√£o ($y_{ik}=0$) [^7.2]. Os coeficientes do modelo s√£o ent√£o estimados via m√≠nimos quadrados, buscando minimizar a soma dos erros quadr√°ticos entre as predi√ß√µes e os valores verdadeiros.

A limita√ß√£o dessa abordagem reside no fato de que a regress√£o linear n√£o restringe as predi√ß√µes ao intervalo [0,1], o que pode levar a estimativas de probabilidade inv√°lidas [^7.2]. Al√©m disso, a regress√£o linear n√£o considera a vari√¢ncia e a covari√¢ncia entre as classes da mesma forma que a LDA. Apesar dessas limita√ß√µes, a regress√£o de indicadores pode gerar resultados √∫teis para a classifica√ß√£o, principalmente quando o objetivo principal √© a constru√ß√£o de uma fronteira de decis√£o linear.

**Lemma 2:** Proje√ß√£o em Hiperplanos de Decis√£o

A regress√£o linear em uma matriz de indicadores, em condi√ß√µes espec√≠ficas, produzir√° proje√ß√µes nos hiperplanos de decis√£o que s√£o equivalentes aos discriminantes lineares da LDA, especialmente em cen√°rios onde as classes possuem vari√¢ncias semelhantes [^7.3]. Essa equival√™ncia ocorre quando as suposi√ß√µes da LDA s√£o razoavelmente satisfeitas, mostrando a conex√£o entre a abordagem de m√≠nimos quadrados e a modelagem probabil√≠stica de classes. $\blacksquare$

```mermaid
graph TB
    subgraph "Equivalence between Linear Regression and LDA"
        direction TB
        A["Linear Regression on Indicator Matrix"]
        B["LDA Discriminant Analysis"]
        C["Project onto Decision Hyperplanes"]
        D["Equivalent Under Specific Conditions"]
        A --> C
        B --> C
        C --> D
    end
```

**Corol√°rio 2:** Simplifica√ß√£o da An√°lise do Modelo

A equival√™ncia entre proje√ß√µes da regress√£o linear e discriminantes lineares permite simplificar a an√°lise do modelo em certos casos, possibilitando usar a intui√ß√£o da regress√£o linear para a compreens√£o da LDA e vice-versa [^7.3]. A interpreta√ß√£o dos coeficientes da regress√£o linear em termos de separa√ß√£o das classes pode auxiliar na compreens√£o dos mecanismos de classifica√ß√£o, principalmente em contextos onde a modelagem probabil√≠stica da LDA √© menos intuitiva [^7.2], [^7.3].

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com 3 classes e 2 preditores. Vamos usar regress√£o linear para modelar um problema de classifica√ß√£o. Criamos uma matriz indicadora $Y$ onde:
>
> - A classe 1 √© codificada como $[1, 0, 0]$
> - A classe 2 √© codificada como $[0, 1, 0]$
> - A classe 3 √© codificada como $[0, 0, 1]$
>
> Usando dados simulados, aplicamos regress√£o linear para cada classe:
>
> ```python
> import numpy as np
> from sklearn.linear_model import LinearRegression
>
> # Dados simulados (N=100, 2 preditores)
> np.random.seed(42)
> X = np.random.rand(100, 2) * 10
>
> # Classes simuladas
> Y = np.zeros((100,3))
> for i in range(100):
>    if X[i, 0] + X[i, 1] < 8:
>        Y[i,0] = 1 # Classe 1
>    elif X[i, 0] - X[i,1] > 0:
>        Y[i,1] = 1  # Classe 2
>    else:
>        Y[i,2] = 1 # Classe 3
>
> # Regress√£o linear para cada classe
> models = []
> for k in range(3):
>    model = LinearRegression()
>    model.fit(X, Y[:,k])
>    models.append(model)
>
> # Coeficientes obtidos
> for k, model in enumerate(models):
>   print(f"Classe {k+1}: Intercept = {model.intercept_:.2f}, Coefs = {model.coef_}")
> ```
>
> O output do c√≥digo acima seria algo como:
> ```
> Classe 1: Intercept = 1.38, Coefs = [-0.0619472  -0.02291968]
> Classe 2: Intercept = 0.07, Coefs = [0.0468602  -0.0463345]
> Classe 3: Intercept = -0.46, Coefs = [0.0150870   0.0692542]
> ```
>
> Os coeficientes s√£o usados para prever a classe: Para um novo ponto $x = [5, 3]$, calculamos as predi√ß√µes para cada classe:
>
> -  $\hat{y}_1(x) = 1.38 - 0.0619*5 - 0.0229*3 \approx  1.08$
> -  $\hat{y}_2(x) = 0.07 + 0.0468*5 - 0.0463*3 \approx 0.16$
> -  $\hat{y}_3(x) = -0.46 + 0.0150*5 + 0.0692*3 \approx -0.23$
>
>  Classificamos o ponto $x$ na classe com maior valor de $\hat{y}_k(x)$, neste caso classe 1. Note que os valores previstos n√£o est√£o entre 0 e 1, e o objetivo principal √© a separa√ß√£o de classes, n√£o a estima√ß√£o de probabilidades. A regress√£o linear com codifica√ß√£o de classes nos permite obter proje√ß√µes lineares para classifica√ß√£o.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

<imagem: Mapa mental que relaciona m√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o em classifica√ß√£o, com conex√µes para LDA, regress√£o log√≠stica e hiperplanos, destacando as penalidades L1 e L2.>

A sele√ß√£o de vari√°veis √© crucial para melhorar a interpretabilidade e a performance dos modelos de classifica√ß√£o, especialmente em contextos de alta dimens√£o [^7.5]. A **regulariza√ß√£o**, em particular, √© uma t√©cnica que adiciona um termo de penalidade √† fun√ß√£o de custo do modelo, visando evitar o sobreajuste e reduzir a complexidade do modelo [^7.4.4].

Em modelos log√≠sticos, a regulariza√ß√£o √© frequentemente implementada atrav√©s de penalidades L1 e L2. A penalidade L1, tamb√©m conhecida como **Lasso**, adiciona a soma dos valores absolutos dos coeficientes √† fun√ß√£o de custo, induzindo a esparsidade dos coeficientes, ou seja, muitos coeficientes s√£o levados a zero. A penalidade L2, tamb√©m conhecida como **Ridge**, adiciona a soma dos quadrados dos coeficientes √† fun√ß√£o de custo, o que tende a reduzir a magnitude dos coeficientes, sem lev√°-los a zero. Matematicamente, essas penalidades podem ser expressas como:

$$
L_1 = \lambda \sum_{j=1}^p |\beta_j|
$$
$$
L_2 = \lambda \sum_{j=1}^p \beta_j^2
$$
onde:
- $\lambda$ √© o par√¢metro de regulariza√ß√£o que controla a intensidade da penalidade.
- $\beta_j$ s√£o os coeficientes do modelo.
- $p$ √© o n√∫mero de par√¢metros.
```mermaid
graph LR
    subgraph "Regularization Penalties"
        direction LR
        A["L1 Penalty (Lasso) :  Œª‚àë|Œ≤‚±º| "]
        B["L2 Penalty (Ridge) : Œª‚àëŒ≤‚±º¬≤"]
    end
```
**Lemma 3:** Esparsidade em Modelos Log√≠sticos com Penalidade L1

A penalidade L1 em classifica√ß√£o log√≠stica leva a coeficientes esparsos devido √† sua natureza geom√©trica e ao mecanismo de otimiza√ß√£o [^7.4.4]. Os contornos da penalidade L1, em formato de losango, fazem com que os coeficientes sejam levados a zero de forma mais eficaz em compara√ß√£o com a penalidade L2, que tem contornos em formato de c√≠rculo. A otimiza√ß√£o da fun√ß√£o de custo penalizada busca um ponto onde a fun√ß√£o de verossimilhan√ßa se cruza com um contorno da penalidade L1, o que geralmente leva a que os coeficientes se anulem em algumas dimens√µes [^7.4.4]. $\blacksquare$
```mermaid
graph TB
  subgraph "L1 Regularization and Sparsity"
    direction TB
    A["L1 Penalty Geometry"]
    B["Contour of L1 Penalty: Diamond Shape"]
    C["Optimization Seeks Corner Solutions"]
    D["Leads to Sparse Coefficients"]
    A --> B
    B --> C
    C --> D
  end
```

**Prova do Lemma 3:**
O problema de otimiza√ß√£o da regress√£o log√≠stica com regulariza√ß√£o L1 √© dado por:
$$ \min_\beta - \sum_i [y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda \sum_{j=1}^p |\beta_j| $$
Onde $\lambda > 0$ √© o par√¢metro de regulariza√ß√£o. Para analisar o efeito da penalidade L1, podemos considerar um caso simples com dois par√¢metros, $\beta_1$ e $\beta_2$, onde a fun√ß√£o de verossimilhan√ßa √© denotada por $L(\beta_1, \beta_2)$. A regulariza√ß√£o L1 adiciona $\lambda (|\beta_1| + |\beta_2|)$ ao custo. Ao tentar minimizar esse custo, a solu√ß√£o √≥tima frequentemente ocorre em um canto onde um ou mais coeficientes s√£o zero [^7.4.3]. Isso ocorre porque o gradiente da penalidade L1 n√£o √© diferenci√°vel em $\beta_j = 0$, criando um "ponto de quebra" onde a solu√ß√£o √≥tima pode se concentrar. Em contraste, a penalidade L2 possui derivadas cont√≠nuas e tende a gerar coeficientes pequenos, mas raramente exatamente zero. $\blacksquare$

**Corol√°rio 3:** Interpretabilidade de Modelos Classificat√≥rios

A esparsidade induzida pela penalidade L1 melhora a interpretabilidade dos modelos classificat√≥rios, identificando as vari√°veis mais relevantes para a classifica√ß√£o [^7.4.5]. Ao reduzir o n√∫mero de vari√°veis relevantes, a an√°lise de resultados torna-se mais focada e mais f√°cil de interpretar. Al√©m disso, a esparsidade pode melhorar a efici√™ncia computacional do modelo, ao reduzir a dimensionalidade do problema.

> ‚ö†Ô∏è **Ponto Crucial**: As penalidades L1 e L2 podem ser combinadas em uma √∫nica penalidade, denominada **Elastic Net**, que busca aproveitar os benef√≠cios de ambos os tipos de regulariza√ß√£o. Essa abordagem permite flexibilidade na constru√ß√£o de modelos esparsos e ao mesmo tempo est√°veis [^7.5].

> üí° **Exemplo Num√©rico:** Suponha que estamos usando regress√£o log√≠stica com 5 preditores e queremos comparar o efeito da regulariza√ß√£o L1 e L2. Utilizamos dados simulados e aplicamos os seguintes modelos:
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import accuracy_score
> import pandas as pd
>
> # Dados simulados
> np.random.seed(42)
> X = np.random.rand(100, 5)
> y = np.random.randint(0, 2, 100)
>
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
>
> # Modelos sem regulariza√ß√£o, com L1 (Lasso) e L2 (Ridge)
> model_none = LogisticRegression(penalty=None, solver='lbfgs', random_state=42)
> model_l1 = LogisticRegression(penalty='l1', C=0.5, solver='liblinear', random_state=42)  # C √© inverso de lambda
> model_l2 = LogisticRegression(penalty='l2', C=0.5, solver='lbfgs', random_state=42) # C √© inverso de lambda
>
> model_none.fit(X_train, y_train)
> model_l1.fit(X_train, y_train)
> model_l2.fit(X_train, y_train)
>
> # Avalia√ß√£o
> y_pred_none = model_none.predict(X_test)
> y_pred_l1 = model_l1.predict(X_test)
> y_pred_l2 = model_l2.predict(X_test)
>
> acc_none = accuracy_score(y_test, y_pred_none)
> acc_l1 = accuracy_score(y_test, y_pred_l1)
> acc_l2 = accuracy_score(y_test, y_pred_l2)
>
> # Compara√ß√£o
> results = pd.DataFrame({
>    'Method': ['None', 'L1 (Lasso)', 'L2 (Ridge)'],
>    'Accuracy': [acc_none, acc_l1, acc_l2],
>    'Coefs': [model_none.coef_, model_l1.coef_, model_l2.coef_]
> })
>
> print(results)
>
> ```
>
> O output do c√≥digo seria algo como:
>
> ```
>        Method  Accuracy                                             Coefs
> 0        None    0.65  [[ 0.172,  -0.573,  -0.024,  -0.598,  -0.477]]
> 1   L1 (Lasso)    0.65  [[0.        ,-0.0613,  0.       ,-0.0245, -0.        ]]
> 2  L2 (Ridge)    0.65  [[0.038,  -0.152, -0.014, -0.193, -0.184]]
> ```
>
> Podemos observar que o modelo L1 (Lasso) zerou alguns coeficientes, indicando que as vari√°veis correspondentes n√£o s√£o t√£o importantes para a classifica√ß√£o. O modelo L2 (Ridge) reduziu a magnitude de todos os coeficientes. Apesar da acur√°cia ser a mesma nesse exemplo, em outros casos a regulariza√ß√£o pode evitar overfitting e melhorar a generaliza√ß√£o. Este exemplo ilustra o efeito da regulariza√ß√£o L1 e L2 na magnitude dos coeficientes em um modelo log√≠stico.

### Separating Hyperplanes e Perceptrons

<imagem: Diagrama mostrando a maximiza√ß√£o da margem de separa√ß√£o entre classes, destacando os conceitos de hiperplanos √≥timos, pontos de suporte e a converg√™ncia do Perceptron.>

A ideia de **hiperplanos separadores** surge da necessidade de dividir o espa√ßo de caracter√≠sticas em regi√µes correspondentes √†s classes, maximizando a margem de separa√ß√£o entre as mesmas [^7.5.2]. Um hiperplano √© definido por uma equa√ß√£o linear no espa√ßo de caracter√≠sticas, e o objetivo da otimiza√ß√£o √© encontrar um hiperplano que maximize a dist√¢ncia entre ele e os pontos de dados mais pr√≥ximos, chamados de **pontos de suporte**.

A formula√ß√£o desse problema de otimiza√ß√£o geralmente envolve a minimiza√ß√£o do erro de classifica√ß√£o sujeito a uma restri√ß√£o que garante uma margem de separa√ß√£o m√≠nima. A solu√ß√£o desse problema √© dada por uma combina√ß√£o linear dos pontos de suporte, o que confere ao modelo uma forte depend√™ncia das observa√ß√µes mais relevantes para a defini√ß√£o das fronteiras de decis√£o. O problema de otimiza√ß√£o pode ser resolvido atrav√©s de uma formula√ß√£o dual, o que torna o problema mais trat√°vel em termos computacionais [^7.5.2].

O **Perceptron de Rosenblatt** √© um algoritmo de aprendizado que busca encontrar um hiperplano separador atrav√©s de um procedimento iterativo [^7.5.1]. O algoritmo inicializa os par√¢metros do hiperplano com valores aleat√≥rios e, em cada itera√ß√£o, ajusta os par√¢metros com base nas classifica√ß√µes erradas, movendo o hiperplano na dire√ß√£o correta para classificar os pontos de dados. Sob condi√ß√µes espec√≠ficas, como a **separabilidade linear** dos dados, o Perceptron converge para um hiperplano que separa perfeitamente as classes. A velocidade e a estabilidade da converg√™ncia dependem da taxa de aprendizado do algoritmo [^7.5.1].
```mermaid
graph TB
    subgraph "Perceptron Algorithm"
    direction TB
        A["Initialize Hyperplane Parameters"]
        B["Iterate Over Data Points"]
        C["If Misclassified, Update Hyperplane"]
        D["Converge to Separating Hyperplane (if linearly separable)"]
        A --> B
        B --> C
        C --> B
        C --> D
    end
```

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com dois preditores, $x_1$ e $x_2$. O perceptron busca encontrar um hiperplano definido por $w_0 + w_1x_1 + w_2x_2 = 0$. Vamos simular um conjunto de dados linearmente separ√°vel:
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Dados simulados
> np.random.seed(42)
> X = np.random.rand(100, 2) * 10
> y = np.where(X[:, 0] + X[:, 1] > 10, 1, -1) # Dados linearmente separ√°veis
>
> # Inicializa√ß√£o dos pesos
> w = np.random.rand(3)  # w = [w0, w1, w2]
> learning_rate = 0.1
> epochs = 100
>
> # Fun√ß√£o de previs√£o do perceptron
> def predict(x, w):
>    return np.sign(np.dot(np.insert(x, 0, 1), w))
>
> # Treinamento do Perceptron
> for epoch in range(epochs):
>    misclassified = 0
>    for i in range(len(X)):
>        x = X[i]
>        y_true = y[i]
>        y_pred = predict(x, w)
>        if y_pred != y_true:
>            misclassified +=1
>            w[0] += learning_rate * y_true
>            w[1] += learning_rate * y_true * x[0