## Model Selection Using the Akaike Information Criterion (AIC)
<imagem: Mapa mental mostrando a estrutura do AIC, desde a defini√ß√£o do conceito de informa√ß√£o at√© a sua aplica√ß√£o na sele√ß√£o de modelos estat√≠sticos e de Machine Learning, conectando-o com o tradeoff bias-vari√¢ncia e outros crit√©rios de sele√ß√£o, como o BIC.>

### Introdu√ß√£o
A sele√ß√£o de modelos estat√≠sticos e de machine learning √© um passo crucial na an√°lise de dados e na constru√ß√£o de modelos preditivos precisos. O objetivo √© escolher o modelo que melhor se ajusta aos dados, evitando o overfitting (quando o modelo se ajusta demais aos dados de treinamento e tem um desempenho ruim em dados n√£o vistos) e o underfitting (quando o modelo √© muito simplista e n√£o captura padr√µes importantes nos dados). O **Akaike Information Criterion (AIC)** [^7.1] √© uma ferramenta estat√≠stica amplamente utilizada para abordar esse problema, oferecendo uma medida de qualidade do modelo que leva em considera√ß√£o tanto o ajuste aos dados quanto a complexidade do modelo. Este cap√≠tulo explorar√° o AIC em profundidade, examinando suas bases te√≥ricas, aplica√ß√µes pr√°ticas e limita√ß√µes.

### Conceitos Fundamentais
Antes de nos aprofundarmos no AIC, √© essencial revisarmos alguns conceitos fundamentais [^7.2]:

**Conceito 1:** O **problema de sele√ß√£o de modelos** surge da necessidade de escolher o modelo que melhor equilibra o ajuste aos dados e a sua complexidade. Um modelo muito simples pode n√£o capturar os padr√µes nos dados (underfitting), enquanto um modelo muito complexo pode se ajustar excessivamente aos dados de treinamento e apresentar um desempenho ruim em novos dados (overfitting). A complexidade do modelo √© frequentemente expressa em termos do n√∫mero de par√¢metros ajust√°veis no modelo. O objetivo √© encontrar um modelo com um n√≠vel de complexidade √≥timo que minimize o erro de generaliza√ß√£o.

**Lemma 1:** *O erro de generaliza√ß√£o de um modelo, ou seja, sua capacidade de fazer previs√µes precisas em novos dados, √© influenciado pelo trade-off entre vi√©s e vari√¢ncia*. [^7.2] Um modelo complexo tende a ter baixo vi√©s (ou seja, √© capaz de se ajustar bem aos dados de treinamento) e alta vari√¢ncia (ou seja, suas previs√µes podem variar muito dependendo dos dados de treinamento), enquanto um modelo simples tende a ter alto vi√©s e baixa vari√¢ncia. O objetivo da sele√ß√£o de modelos √© encontrar um ponto de equil√≠brio que minimize o erro total de generaliza√ß√£o.

```mermaid
graph TB
    subgraph "Generalization Error Trade-off"
        direction TB
        A["Generalization Error"]
        B["Bias Component: 'High for simple models'"]
        C["Variance Component: 'High for complex models'"]
        A --> B
        A --> C
    end
```

> üí° **Exemplo Num√©rico:** Considere um dataset simulado com uma rela√ß√£o quadr√°tica entre a vari√°vel independente $x$ e a vari√°vel dependente $y$. Vamos ajustar tr√™s modelos: um modelo linear (simples), um modelo quadr√°tico (adequado) e um modelo polinomial de grau 5 (complexo).
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression
> from sklearn.preprocessing import PolynomialFeatures
> from sklearn.metrics import mean_squared_error
>
> # Dados simulados
> np.random.seed(42)
> X = np.sort(np.random.rand(50) * 10)
> y = 2 * X**2 + 3 * X + 5 + np.random.randn(50) * 10
>
> # Modelos
> X = X.reshape(-1, 1) # Transforma X em uma matriz de coluna
>
> # 1. Modelo Linear
> model_linear = LinearRegression()
> model_linear.fit(X, y)
> y_pred_linear = model_linear.predict(X)
> mse_linear = mean_squared_error(y, y_pred_linear)
>
> # 2. Modelo Quadr√°tico
> poly_features = PolynomialFeatures(degree=2)
> X_poly = poly_features.fit_transform(X)
> model_quadratic = LinearRegression()
> model_quadratic.fit(X_poly, y)
> y_pred_quadratic = model_quadratic.predict(X_poly)
> mse_quadratic = mean_squared_error(y, y_pred_quadratic)
>
> # 3. Modelo Polinomial Grau 5
> poly_features_5 = PolynomialFeatures(degree=5)
> X_poly_5 = poly_features_5.fit_transform(X)
> model_poly5 = LinearRegression()
> model_poly5.fit(X_poly_5, y)
> y_pred_poly5 = model_poly5.predict(X_poly_5)
> mse_poly5 = mean_squared_error(y, y_pred_poly5)
>
> # Gr√°fico
> plt.figure(figsize=(10, 6))
> plt.scatter(X, y, label='Dados Originais')
> plt.plot(X, y_pred_linear, color='red', label=f'Linear (MSE={mse_linear:.2f})')
> plt.plot(X, y_pred_quadratic, color='green', label=f'Quadr√°tico (MSE={mse_quadratic:.2f})')
> plt.plot(X, y_pred_poly5, color='blue', label=f'Polinomial 5 (MSE={mse_poly5:.2f})')
> plt.xlabel('X')
> plt.ylabel('y')
> plt.title('Compara√ß√£o de Modelos')
> plt.legend()
> plt.show()
>
> print(f"MSE Linear: {mse_linear:.2f}")
> print(f"MSE Quadr√°tico: {mse_quadratic:.2f}")
> print(f"MSE Polinomial (Grau 5): {mse_poly5:.2f}")
> ```
> Este exemplo demonstra que o modelo quadr√°tico se ajusta melhor aos dados, com o menor erro quadr√°tico m√©dio (MSE). O modelo linear sofre de underfitting (alto vi√©s), enquanto o modelo de grau 5 sofre de overfitting (alta vari√¢ncia).

**Conceito 2:** A **verossimilhan√ßa (likelihood)** de um modelo √© a probabilidade dos dados observados dados os par√¢metros do modelo. A ideia √© maximizar essa probabilidade encontrando os par√¢metros que melhor explicam os dados. Modelos mais complexos podem gerar verossimilhan√ßas maiores, mas tamb√©m podem sofrer de overfitting. A verossimilhan√ßa penalizada, como a utilizada no AIC, busca um balan√ßo entre a qualidade do ajuste do modelo aos dados (medida pela verossimilhan√ßa) e a complexidade do modelo.

**Corol√°rio 1:** *Modelos com maior n√∫mero de par√¢metros geralmente levam a verossimilhan√ßas mais altas nos dados de treinamento*, mas podem n√£o ser os mais adequados em dados n√£o vistos, demonstrando a import√¢ncia de penalizar a complexidade em crit√©rios como o AIC. [^7.1, ^7.2]

```mermaid
graph TB
    subgraph "Likelihood and Model Complexity"
        direction TB
        A["Model Complexity"]
        B["Likelihood on Training Data: 'Increases with complexity'"]
        C["Generalization Performance: 'Decreases with overfitting'"]
        A --> B
        A --> C
    end
```

**Conceito 3:** O **AIC** √© uma medida da qualidade relativa de um modelo estat√≠stico para um dado conjunto de dados. Ele se baseia na teoria da informa√ß√£o e quantifica a perda de informa√ß√£o quando um determinado modelo √© usado para aproximar o processo que gerou os dados. *O AIC √© definido como: $$AIC = -2 \cdot loglik + 2d$$, onde $loglik$ √© o logaritmo da verossimilhan√ßa maximizada do modelo e $d$ √© o n√∫mero de par√¢metros no modelo* [^7.5]. O primeiro termo mede o ajuste do modelo aos dados (quanto maior a verossimilhan√ßa, menor o termo), e o segundo termo penaliza a complexidade do modelo (quanto mais par√¢metros, maior o termo).

```mermaid
graph TB
    subgraph "AIC Calculation"
        direction TB
        A["AIC"]
        B["-2 * loglik: 'Measures goodness of fit'"]
        C["2 * d: 'Penalty for model complexity'"]
        A --> B
        A --> C
    end
```

> üí° **Exemplo Num√©rico:** Considere dois modelos para ajustar um conjunto de dados:
>
> *   **Modelo 1:** Regress√£o linear simples com 2 par√¢metros (inclina√ß√£o e intercepto). Log-verossimilhan√ßa maximizada: -150.
> *   **Modelo 2:** Regress√£o polinomial de grau 3 com 4 par√¢metros. Log-verossimilhan√ßa maximizada: -130.
>
> C√°lculo do AIC para cada modelo:
>
> *   Modelo 1: $AIC_1 = -2 \cdot (-150) + 2 \cdot 2 = 300 + 4 = 304$
> *   Modelo 2: $AIC_2 = -2 \cdot (-130) + 2 \cdot 4 = 260 + 8 = 268$
>
> Apesar do modelo 2 ter um melhor ajuste aos dados (maior log-verossimilhan√ßa), o AIC penaliza o modelo 2 pela sua complexidade. Nesse caso, o AIC indica que o modelo 2 tem melhor qualidade relativa porque possui um menor valor de AIC.
>
> ```python
> import numpy as np
>
> # Dados de exemplo
> loglik_model1 = -150
> params_model1 = 2
> loglik_model2 = -130
> params_model2 = 4
>
> # Calcula o AIC para cada modelo
> aic_model1 = -2 * loglik_model1 + 2 * params_model1
> aic_model2 = -2 * loglik_model2 + 2 * params_model2
>
> print(f"AIC do Modelo 1: {aic_model1}")
> print(f"AIC do Modelo 2: {aic_model2}")
>
> # Tabela comparando os modelos
> print("\nCompara√ß√£o dos Modelos:")
> print("| Modelo | Log-Verossimilhan√ßa | Par√¢metros | AIC |")
> print("|--------|--------------------|------------|-----|")
> print(f"| Modelo 1 | {loglik_model1} | {params_model1} | {aic_model1} |")
> print(f"| Modelo 2 | {loglik_model2} | {params_model2} | {aic_model2} |")
>
> # Verifica qual modelo tem o menor AIC
> if aic_model1 < aic_model2:
>    print("\nModelo 1 tem menor AIC e melhor qualidade relativa.")
> else:
>    print("\nModelo 2 tem menor AIC e melhor qualidade relativa.")
> ```

> ‚ö†Ô∏è **Nota Importante**: √â crucial lembrar que o AIC *n√£o √© uma medida da qualidade absoluta de um modelo*, mas sim uma medida da qualidade relativa comparada com outros modelos. Um valor baixo de AIC indica um bom modelo em rela√ß√£o a outros que est√£o sendo considerados, mas n√£o significa que esse modelo seja perfeito.

> ‚ùó **Ponto de Aten√ß√£o**: O AIC assume que os modelos considerados est√£o pr√≥ximos do modelo verdadeiro, e sua aplica√ß√£o pode ser problem√°tica quando essa premissa n√£o √© v√°lida. Em particular, o AIC tende a selecionar modelos mais complexos quando o tamanho da amostra √© grande.

> ‚úîÔ∏è **Destaque**: Uma das vantagens do AIC √© sua aplicabilidade a uma ampla gama de modelos, incluindo modelos lineares, n√£o lineares, de regress√£o e de classifica√ß√£o, conforme ser√° demonstrado adiante.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
A aplica√ß√£o da regress√£o linear em matriz de indicadores para classifica√ß√£o √© um exemplo interessante de como um modelo de regress√£o pode ser usado para problemas de classifica√ß√£o [^4.2]. O processo consiste em codificar as classes usando uma matriz indicadora e ent√£o aplicar a regress√£o linear para estimar os coeficientes. Um mapa mental (Mermaid) pode ilustrar essa ideia:

```mermaid
graph TD
  A["Classification Data"] --> B["Indicator Matrix Encoding"]
  B --> C["Linear Regression"]
  C --> D["Class Prediction"]
  D --> E["Model Evaluation"]
```
**Explica√ß√£o:** Este diagrama representa o fluxo do processo de regress√£o de indicadores para classifica√ß√£o.

Nesse contexto, embora a regress√£o linear n√£o seja diretamente projetada para classifica√ß√£o, ela pode ser usada como uma aproxima√ß√£o para obten√ß√£o de fronteiras de decis√£o lineares. No entanto, a regress√£o linear em matriz de indicadores apresenta algumas limita√ß√µes, como a poss√≠vel extrapola√ß√£o de valores fora do intervalo [0,1], que podem ser interpretados como probabilidades.

**Lemma 2:** A regress√£o de indicadores, sob certas condi√ß√µes, pode produzir um hiperplano de decis√£o equivalente √†quele obtido pela an√°lise discriminante linear (LDA), quando as classes t√™m covari√¢ncias iguais [^4.3].

**Prova do Lemma 2:**
Vamos considerar o caso de duas classes. Seja $X$ a matriz de dados e $Y$ a matriz indicadora correspondente √†s classes. No contexto da regress√£o, os coeficientes $\beta$ s√£o estimados por:

$$ \beta = (X^T X)^{-1} X^T Y $$
A proje√ß√£o de uma nova amostra $x_0$ para predi√ß√£o √©:

$$ \hat{y}_0 = x_0^T \beta $$

A regra de decis√£o na regress√£o de indicadores envolve comparar o valor predito com um threshold (0.5 no caso de 2 classes) e classificar a amostra de acordo.

Na LDA, as fun√ß√µes discriminantes s√£o da forma:
$$ \delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T \Sigma^{-1}\mu_k + \log(\pi_k) $$
onde $\Sigma$ √© a matriz de covari√¢ncia comum (assumida igual), $\mu_k$ s√£o as m√©dias das classes e $\pi_k$ s√£o as probabilidades a priori. A decis√£o √© dada pela classe $k$ que maximiza $\delta_k(x)$.

Quando as classes t√™m covari√¢ncias iguais e as probabilidades a priori s√£o iguais, os hiperplanos de decis√£o na LDA s√£o lineares. Podemos mostrar que, sob essas condi√ß√µes, os hiperplanos de decis√£o gerados pela regress√£o linear e pela LDA s√£o equivalentes.

O hiperplano de decis√£o da regress√£o de indicadores √© definido por
$$ x_0^T \beta = 0.5 $$
e o hiperplano da LDA (para duas classes) √© dado por
$$ x_0^T \Sigma^{-1} (\mu_2 - \mu_1) = constant $$

Se as covari√¢ncias das classes s√£o iguais, a regress√£o de indicadores aproxima-se do LDA, resultando em hiperplanos semelhantes. Portanto, as proje√ß√µes nos hiperplanos de decis√£o em ambos os m√©todos, sob estas condi√ß√µes, s√£o equivalentes. $\blacksquare$

**Corol√°rio 2:** A limita√ß√£o da regress√£o linear na classifica√ß√£o reside na sua inadequa√ß√£o para estimar probabilidades diretamente e na sua sensibilidade a outliers, sendo mais apropriada para cen√°rios em que a decis√£o bin√°ria √© suficiente e a separa√ß√£o linear √© uma boa aproxima√ß√£o [^4.4].

> üí° **Exemplo Num√©rico:**
> Vamos considerar um exemplo simples de classifica√ß√£o com duas classes e duas vari√°veis preditoras.
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression
>
> # Dados de exemplo
> X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])
> y = np.array([0, 0, 1, 1, 0, 1]) # classes 0 e 1
>
> # 1. Codifica√ß√£o da Matriz Indicadora
> # Neste caso, j√° temos y com 0 e 1, n√£o precisa de matriz indicadora
>
> # 2. Regress√£o Linear
> model = LinearRegression()
> model.fit(X, y)
>
> # 3. Predi√ß√£o para Visualiza√ß√£o
> x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
> y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
> xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),
>                     np.arange(y_min, y_max, 0.02))
> Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
> Z = Z.reshape(xx.shape)
>
> # 4. Visualiza√ß√£o
> plt.figure(figsize=(8, 6))
> plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha=0.5)
> plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu, edgecolors='k')
> plt.xlabel('X1')
> plt.ylabel('X2')
> plt.title('Regress√£o Linear para Classifica√ß√£o')
> plt.colorbar()
> plt.show()
>
> # Exemplo de predi√ß√£o
> new_sample = np.array([[4, 5]])
> prediction = model.predict(new_sample)
> print(f"Predi√ß√£o para [4, 5]: {prediction[0]:.2f}")
>
> # Classifica√ß√£o
> threshold = 0.5
> class_prediction = 1 if prediction[0] >= threshold else 0
> print(f"Classe Predita para [4, 5]: {class_prediction}")
> ```
> Neste exemplo, a regress√£o linear cria uma fronteira linear entre as classes, e podemos ver como pontos pr√≥ximos da classe 0 obt√™m valores de predi√ß√£o menores que 0.5, e pontos da classe 1 obt√™m valores maiores que 0.5. Para classificar, podemos usar o limiar de 0.5.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas fundamentais para controlar a complexidade de modelos, evitar overfitting e melhorar o desempenho de modelos de classifica√ß√£o [^7.2, ^7.5]. Em particular, a regulariza√ß√£o adiciona termos de penalidade √† fun√ß√£o de custo que √© otimizada durante o treinamento, incentivando modelos mais simples.

Uma aplica√ß√£o comum da regulariza√ß√£o √© em modelos de regress√£o log√≠stica, onde termos de penalidade L1 (Lasso) e L2 (Ridge) s√£o adicionados √† fun√ß√£o de log-verossimilhan√ßa.

A regulariza√ß√£o L1 tende a tornar os coeficientes do modelo esparsos, ou seja, alguns coeficientes s√£o reduzidos a zero, efetivamente selecionando as vari√°veis mais relevantes [^7.5].

**Lemma 3:** *A penaliza√ß√£o L1 na regress√£o log√≠stica resulta em coeficientes esparsos, uma vez que a penalidade L1 (ou seja, a soma dos valores absolutos dos coeficientes) incentiva coeficientes a se tornarem exatamente zero*. [^4.4.4]

**Prova do Lemma 3:**
A fun√ß√£o de custo para regress√£o log√≠stica com regulariza√ß√£o L1 √© dada por:

$$ J(\beta) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(\sigma(\beta^T x_i)) + (1-y_i)\log(1-\sigma(\beta^T x_i))] + \lambda \sum_{j=1}^{p} |\beta_j| $$
onde $\sigma$ √© a fun√ß√£o log√≠stica, $\beta$ s√£o os coeficientes, $x_i$ s√£o os dados de entrada, $y_i$ s√£o os r√≥tulos e $\lambda$ √© o par√¢metro de regulariza√ß√£o.

The L1 penalty adds a penalty directly proportional to the sum of the absolute values of the coefficients. When we optimize this cost function, the L1 penalty causes some coefficients to become exactly zero, resulting in a sparse model, i.e., using a subset of the original variables. Geometrically, the contour of the objective function, together with the penalty, tends to "touch" the axes, leading to zero coefficients. $\blacksquare$

```mermaid
graph LR
    subgraph "L1 Regularization Effect"
        direction LR
        A["Cost Function with L1 Penalty"] --> B["Sum of Absolute Coefficients: 'Œ£|Œ≤j|'"]
        B --> C["Sparse Coefficients: 'Some become zero'"]
    end
```
**Corol√°rio 3:** A esparsidade promovida pela regulariza√ß√£o L1 facilita a interpreta√ß√£o do modelo, uma vez que apenas as vari√°veis mais relevantes s√£o mantidas.

> ‚ö†Ô∏è **Ponto Crucial**: A regulariza√ß√£o L2, por sua vez, reduz a magnitude dos coeficientes sem necessariamente torn√°-los zero, levando a um modelo mais est√°vel e menos sens√≠vel a pequenas mudan√ßas nos dados. A escolha entre L1 e L2 (ou uma combina√ß√£o delas, como a Elastic Net) depende do contexto e dos objetivos do problema. [^7.5]

> üí° **Exemplo Num√©rico:** Vamos comparar a regulariza√ß√£o L1 (Lasso) e L2 (Ridge) em um problema de classifica√ß√£o bin√°ria usando regress√£o log√≠stica.
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LogisticRegression
> from sklearn.model_selection import train_test_split
> from sklearn.preprocessing import StandardScaler
> from sklearn.metrics import accuracy_score
>
> # Gerando dados de exemplo
> np.random.seed(42)
> X = np.random.rand(100, 10) # 10 features, algumas irrelevantes
> y = np.random.randint(0, 2, 100)
>
> # Separando dados de treino e teste
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Normalizando os dados
> scaler = StandardScaler()
> X_train = scaler.fit_transform(X_train)
> X_test = scaler.transform(X_test)
>
> # Modelos
> # 1. Regress√£o Log√≠stica sem Regulariza√ß√£o
> model_no_reg = LogisticRegression(penalty=None, solver='lbfgs', random_state=42)
> model_no_reg.fit(X_train, y_train)
> y_pred_no_reg = model_no_reg.predict(X_test)
>
> # 2. Regress√£o Log√≠stica com Regulariza√ß√£o L1 (Lasso)
> model_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=0.1, random_state=42)
> model_l1.fit(X_train, y_train)
> y_pred_l1 = model_l1.predict(X_test)
>
> # 3. Regress√£o Log√≠stica com Regulariza√ß√£o L2 (Ridge)
> model_l2 = LogisticRegression(penalty='l2', solver='lbfgs', C=0.1, random_state=42)
> model_l2.fit(X_train, y_train)
> y_pred_l2 = model_l2.predict(X_test)
>
> # Avalia√ß√£o
> acc_no_reg = accuracy_score(y_test, y_pred_no_reg)
> acc_l1 = accuracy_score(y_test, y_pred_l1)
> acc_l2 = accuracy_score(y_test, y_pred_l2)
>
> # Coeficientes
> coef_no_reg = model_no_reg.coef_[0]
> coef_l1 = model_l1.coef_[0]
> coef_l2 = model_l2.coef_[0]
>
> print(f"Acur√°cia sem regulariza√ß√£o: {acc_no_reg:.2f}")
> print(f"Acur√°cia com regulariza√ß√£o L1: {acc_l1:.2f}")
> print(f"Acur√°cia com regulariza√ß√£o L2: {acc_l2:.2f}")
>
> # Mostra coeficientes
> print("\nCoeficientes:")
> print(f"Sem Regulariza√ß√£o: {coef_no_reg}")
> print(f"Com L1: {coef_l1}")
> print(f"Com L2: {coef_l2}")
>
> # Tabela comparando os modelos
> print("\nCompara√ß√£o dos Modelos:")
> print("| Modelo | Acur√°cia | Coeficientes (L1 s√£o esparsos) |")
> print("|--------|----------|-------------------------------|")
> print(f"| Sem Reg | {acc_no_reg:.2f} | {coef_no_reg}  |")
> print(f"| L1      | {acc_l1:.2f} | {coef_l1}  |")
> print(f"| L2      | {acc_l2:.2f} | {coef_l2}  |")
>
> # Visualiza√ß√£o dos coeficientes
> plt.figure(figsize=(10, 6))
> plt.bar(range(len(coef_no_reg)), coef_no_reg, color='blue', label='Sem Regulariza√ß√£o', alpha=0.7)
> plt.bar(range(len(coef_l1)), coef_l1, color='red', label='L1 (Lasso)', alpha=0.7)
> plt.bar(range(len(coef_l2)), coef_l2, color='green', label='L2 (Ridge)', alpha=0.7)
> plt.xlabel('Feature')
> plt.ylabel('Coeficiente')
> plt.title('Compara√ß√£o dos Coeficientes por Regulariza√ß√£o')
> plt.legend()
> plt.show()
> ```
> Observa-se que os coeficientes com regulariza√ß√£o L1 s√£o mais esparsos, com v√°rios coeficientes iguais a zero, indicando a sele√ß√£o de vari√°veis. A regulariza√ß√£o L2 reduz a magnitude dos coeficientes sem zer√°-los. Este exemplo ilustra como diferentes tipos de regulariza√ß√£o afetam os coeficientes e a esparsidade do modelo.

### Separating Hyperplanes e Perceptrons
A ideia de encontrar um **hiperplano** que separa os dados em classes distintas √© central em muitos m√©todos de classifica√ß√£o linear, incluindo m√°quinas de vetores de suporte (SVMs) e o Perceptron [^4.5.2].

The objective is to find a hyperplane that maximizes the margin between the classes, that is, the distance between the hyperplane and the closest samples of each class, also known as support vectors. This hyperplane can be expressed as a linear combination of the support points.

O Perceptron de Rosenblatt √© um algoritmo cl√°ssico de aprendizado de m√°quinas que busca encontrar um hiperplano que separa linearmente as classes. O algoritmo ajusta iterativamente os pesos do hiperplano, at√© que os dados sejam separados corretamente. O algoritmo Perceptron converge para um hiperplano separador em um n√∫mero finito de passos se os dados forem linearmente separ√°veis [^4.5.1].

### Pergunta Te√≥rica Avan√ßada
**Pergunta:** *Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana, considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?*

**Resposta:**
A **Linear Discriminant Analysis (LDA)** e a **Regra de Decis√£o Bayesiana** s√£o ambas t√©cnicas de classifica√ß√£o que podem ser utilizadas quando as classes t√™m distribui√ß√µes Gaussianas [^4.3]. No entanto, existem diferen√ßas fundamentais em suas abordagens e resultados.

A LDA assume que as classes seguem distribui√ß√µes Gaussianas com m√©dias diferentes e a mesma matriz de covari√¢ncia. Sob esta hip√≥tese, a fronteira de decis√£o entre duas classes ser√° um hiperplano. A LDA encontra esse hiperplano projetando os dados em um subespa√ßo de menor dimens√£o, onde a separa√ß√£o entre as classes √© maximizada.

A Regra de Decis√£o Bayesiana, por sua vez, √© um m√©todo mais geral que busca classificar as amostras na classe com a maior probabilidade a posteriori, usando o Teorema de Bayes:
$$ P(G = k|X = x) = \frac{P(X = x|G = k)P(G=k)}{P(X=x)} $$
onde $G$ √© a vari√°vel de classe, $X$ s√£o os dados de entrada, $P(G=k)$ √© a probabilidade a priori da classe k, $P(X=x|G=k)$ √© a verossimilhan√ßa dos dados na classe k e $P(G=k|X=x)$ √© a probabilidade a posteriori da classe $k$ dado $x$.

Sob a hip√≥tese de que as classes seguem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia, a Regra de Decis√£o Bayesiana leva a uma fronteira de decis√£o linear, assim como na LDA. De fato, a LDA pode ser vista como um caso especial da Regra de Decis√£o Bayesiana sob essa hip√≥tese.

**Lemma 4:** *Quando as classes seguem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia, o limite de decis√£o derivado da Regra de Decis√£o Bayesiana √© equivalente ao limite de decis√£o encontrado pela LDA*. [^4.3, ^4.3.3]

**Prova do Lemma 4:**
Vamos considerar o caso de duas classes, $G=1$ e $G=2$.
Na LDA, a fun√ß√£o discriminante √© da forma:
$$ \delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T \Sigma^{-1}\mu_k + \log(\pi_k) $$
e a decis√£o √© dada por $k = argmax_k \delta_k(x)$. A fronteira de decis√£o (quando $\delta_1(x) = \delta_2(x)$) ser√° um hiperplano.

Na Regra de Decis√£o Bayesiana, a decis√£o √© dada pela classe que maximiza a probabilidade a posteriori, ou seja:
$$ argmax_k P(G = k|X = x) = argmax_k \frac{P(X = x|G = k)P(G=k)}{P(X=x)} $$
Como $P(X=x)$ √© comum a todas as classes, isso se torna:
$$ argmax_k P(X = x|G = k)P(G=k) $$

Se $P(X = x|G = k)$ √© uma gaussiana com m√©dia $\mu_k$ e covari√¢ncia $\Sigma$, ent√£o:
$$ P(X = x|G = k) = (2\pi)^{-\frac{p}{2}}|\Sigma|^{-\frac{1}{2}}exp(-\frac{1}{2}(x-\mu_k)^T \Sigma^{-1}(x-\mu_k)) $$

A decis√£o √© dada pela classe que maximiza o log da probabilidade a posteriori (que √© equivalente √† maximizar a probabilidade a posteriori):
$$ argmax_k \log P(X = x|G = k) + log P(G=k) $$

Substituindo a Gaussiana, e simplificando, resulta na decis√£o dada por:
$$ argmax_k  x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T \Sigma^{-1}\mu_k + log(\pi_k) $$

Que √© exatamente a forma da LDA. Portanto, a regra de decis√£o Bayesiana, sob a hip√≥tese de Gaussianas com covari√¢ncia igual, resulta na mesma regra de decis√£o da LDA. $\blacksquare$

```mermaid
graph TB
    subgraph "Equivalence of LDA and Bayesian Decision Rule"
    direction TB
    A["LDA Discriminant Function: 'Œ¥k(x)'"]
    B["Bayesian Decision Rule: 'argmax P(G=k|X=x)'"]
    C["Gaussian distributions with equal covariance 'Œ¥k(x) is equivalent to argmax P(G=k|X=x)'"]
    A --> C
    B --> C

    end
```
**Corol√°rio 4:** Se a hip√≥tese de covari√¢ncias iguais n√£o √© satisfeita, a Regra de Decis√£o Bayesiana leva a fronteiras de decis√£o quadr√°ticas, e podemos obter o m√©todo QDA (Quadratic Discriminant Analysis). [^4.3]

> ‚ö†Ô∏è **Ponto Crucial**: A diferen√ßa fundamental reside nas premissas e na abordagem. A LDA √© um m√©todo discriminativo que encontra um hiperplano √≥timo para separar as classes, enquanto a Regra de Decis√£o Bayesiana √© um m√©todo gerador que estima as probabilidades a posteriori e classifica as amostras com base nessas probabilidades. Sob a hip√≥tese de distribui√ß√µes Gaussianas com covari√¢ncias iguais, os resultados s√£o equivalentes.

### Conclus√£o
Neste cap√≠tulo, exploramos o Akaike Information Criterion (AIC) como uma ferramenta fundamental para a sele√ß√£o de modelos estat√≠sticos e de machine learning, examinando suas bases te√≥ricas, aplica√ß√µes e limita√ß√µes. O AIC permite encontrar um equil√≠brio adequado entre o ajuste aos dados e a complexidade do modelo, evitando tanto o underfitting quanto o overfitting. Ao longo deste cap√≠tulo, tamb√©m abordamos conceitos relacionados √† classifica√ß√£o, como a regress√£o linear de matrizes indicadoras, m√©todos de regulariza√ß√£o, hiperplanos separadores e, finalmente, exploramos as diferen√ßas entre a LDA e a Regra de Decis√£o Bayesiana. Esses conhecimentos s√£o essenciais para uma compreens√£o profunda da teoria e pr√°tica da modelagem estat√≠stica e da ci√™ncia de dados.

<!-- END DOCUMENT -->
### Footnotes
[^7.1]: "The generalization performance of a learning method relates to its prediction capability on independent test data. Assessment of this performance is extremely important in practice, since it guides the choice of learning method or model, and gives us a measure of the quality of the ultimately chosen model."
[^7.2]: "Figure 7.1 illustrates the important issue in assessing the ability of a learning method to generalize. Consider first the case of a quantitative or interval scale response. We have a target variable Y, a vector of inputs X, and a prediction model f(X) that has been estimated from a training set T."
[^7.3]: "Test error, also referred to as generalization error, is the prediction error over an independent test sample  ErrT = E[L(Y, f(X))|T]"
[^7.4]: "Unfortunately training error is not a good estimate of the test error, as seen in Figure 7.1. Training error consistently decreases with model complexity, typically dropping to zero if we increase the model complexity enough."
[^7.5]: "In this chapter we describe a number of methods for estimating the expected test error for a model. Typically our model will have a tuning parameter or parameters a and so we can write our predictions as fa(x). The tuning parameter varies the complexity of our model, and we wish to find the value of a that minimizes error, that is, produces the minimum of the average test error curve in Figure 7.1"
[^4.1]: "The generalization performance of a learning method relates to its prediction capability on independent test data."
[^4.2]: "Consider first the case of a quantitative or interval scale response. We have a target variable Y, a vector of inputs X, and a prediction model f(X) that has been estimated from a training set T."
[^4.3]: "The story is similar for a qualitative or categorical response G taking one of K values in a set G, labeled for convenience as 1, 2, ..., K."
[^4.4]: "We would like to know the expected test error of our estimated model f.