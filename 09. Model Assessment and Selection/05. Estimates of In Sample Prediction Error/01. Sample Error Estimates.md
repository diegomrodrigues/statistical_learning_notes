## In-Sample Error Estimates for Model Selection

```mermaid
graph LR
    A["Model Evaluation"] --> B{"Choice of Learning Method"}
    A --> C{"Measure of Quality"}
    B --> D["Generalization Performance"]
    C --> D
    D --> E{"Prediction on Independent Test Data"}

```

### Introdu√ß√£o
A avalia√ß√£o da performance de modelos de aprendizado √© crucial na pr√°tica, pois ela direciona a escolha do m√©todo de aprendizado ou modelo e fornece uma medida da qualidade do modelo escolhido [^7.1]. A performance de generaliza√ß√£o de um m√©todo de aprendizado relaciona-se √† sua capacidade de predi√ß√£o em dados de teste independentes. Neste cap√≠tulo, s√£o descritos e ilustrados os principais m√©todos para avalia√ß√£o de desempenho, mostrando como s√£o utilizados para selecionar modelos [^7.1]. A discuss√£o inicial aborda a intera√ß√£o entre **vi√©s**, **vari√¢ncia** e **complexidade do modelo**, conceitos fundamentais para a compreens√£o da necessidade de m√©todos adequados de avalia√ß√£o.

### Conceitos Fundamentais
**Conceito 1:** O **problema de classifica√ß√£o** consiste em atribuir um r√≥tulo de classe a um dado de entrada. M√©todos lineares s√£o amplamente utilizados para abordar esse problema, buscando uma fronteira de decis√£o linear que separa as classes. No entanto, o uso de modelos com complexidade inadequada pode levar a problemas de *underfitting* (alto vi√©s) ou *overfitting* (alta vari√¢ncia) [^7.2]. Por exemplo, um modelo linear muito simples pode n√£o capturar as nuances dos dados, resultando em um alto vi√©s. Por outro lado, um modelo muito complexo pode se ajustar excessivamente aos dados de treinamento, resultando em baixa vari√¢ncia no treinamento, mas alta vari√¢ncia em dados n√£o vistos.

> üí° **Exemplo Num√©rico:** Imagine um problema de classifica√ß√£o com dados bidimensionais onde as classes s√£o separadas por uma curva. Um modelo linear (uma linha reta) teria um alto vi√©s, pois n√£o conseguiria capturar a forma da fronteira de decis√£o. Um polin√¥mio de grau muito alto, por outro lado, poderia se ajustar perfeitamente aos dados de treinamento, mas teria um desempenho ruim em dados novos (alta vari√¢ncia), pois se ajustaria ao ru√≠do espec√≠fico do conjunto de treino. Um modelo com um grau polinomial intermedi√°rio poderia apresentar o melhor compromisso entre vi√©s e vari√¢ncia.

**Lemma 1:** *A decomposi√ß√£o do erro em vi√©s e vari√¢ncia* oferece uma forma de entender o compromisso entre ajuste do modelo aos dados e sua capacidade de generaliza√ß√£o. Para o erro quadr√°tico, o erro esperado de predi√ß√£o em um ponto $x_0$ pode ser decomposto da seguinte forma [^7.3]:

$$Err(x_0) = \sigma^2 + Bias^2(f(x_0)) + Var(f(x_0))$$

onde $\sigma^2$ √© a vari√¢ncia do erro aleat√≥rio, $Bias^2(f(x_0))$ √© o vi√©s ao quadrado e $Var(f(x_0))$ √© a vari√¢ncia da previs√£o. Essa decomposi√ß√£o mostra que o erro total √© a soma dessas tr√™s componentes.

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o onde o verdadeiro relacionamento entre a entrada $x$ e a sa√≠da $y$ √© dado por $y = 2x + 3 + \epsilon$, onde $\epsilon$ √© um ru√≠do com distribui√ß√£o normal com m√©dia 0 e vari√¢ncia $\sigma^2 = 1$.
>
> 1.  **Modelo com alto vi√©s:** Suponha que nosso modelo seja $f(x) = x + 2$. O vi√©s ser√° $Bias(f(x)) = E[f(x)] - (2x+3) = (x+2) - (2x+3) = -x -1$. Para um ponto $x_0 = 2$, o vi√©s ao quadrado ser√° $(-2-1)^2 = 9$.
> 2.  **Modelo com alta vari√¢ncia:** Suponha que nosso modelo seja obtido a partir de um modelo muito flex√≠vel, que se ajusta ao ru√≠do em um conjunto de dados muito pequeno, tal que $Var(f(x_0)) = 4$.
> 3. **Erro total:** O erro esperado para $x_0=2$ ser√°: $Err(x_0) = 1 + 9 + 4 = 14$. Isso ilustra como o erro total √© influenciado tanto pelo vi√©s quanto pela vari√¢ncia do modelo.
>
> ```mermaid
> graph LR
>     A["Err(x‚ÇÄ)"] --> B["œÉ¬≤"]
>     A --> C["Bias¬≤(f(x‚ÇÄ))"]
>     A --> D["Var(f(x‚ÇÄ))"]
>     B -->|"+1"| A
>     C -->|"+9"| A
>     D -->|"+4"| A
>
> ```

**Conceito 2:** A **Linear Discriminant Analysis (LDA)** √© uma t√©cnica cl√°ssica para classifica√ß√£o que assume a normalidade das classes e covari√¢ncias iguais [^7.3]. O LDA busca projetar os dados em um subespa√ßo linear que maximiza a separa√ß√£o entre as m√©dias das classes e minimiza a vari√¢ncia dentro de cada classe [^7.3.1]. A fronteira de decis√£o linear no LDA √© dada por [^7.3.2]:

$$x^T \Sigma^{-1}(\mu_k - \mu_l) - \frac{1}{2}(\mu_k^T \Sigma^{-1} \mu_k - \mu_l^T \Sigma^{-1} \mu_l) = 0$$

onde $\mu_k$ e $\mu_l$ s√£o as m√©dias das classes $k$ e $l$ e $\Sigma$ √© a matriz de covari√¢ncia comum.

> üí° **Exemplo Num√©rico:** Considere duas classes, com as seguintes m√©dias e matriz de covari√¢ncia comum:
>
> Classe 1: $\mu_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$
> Classe 2: $\mu_2 = \begin{bmatrix} 3 \\ 2 \end{bmatrix}$
> Matriz de covari√¢ncia: $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
>
> Para calcular a fronteira de decis√£o, precisamos de $\Sigma^{-1}$:
> $\Sigma^{-1} = \frac{1}{0.75} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$
>
> Agora, podemos calcular a diferen√ßa das m√©dias:
> $\mu_1 - \mu_2 = \begin{bmatrix} -2 \\ -1 \end{bmatrix}$
>
> E o termo quadr√°tico:
> $\mu_1^T \Sigma^{-1} \mu_1 = \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} = 1.33 -0.67 - 0.67 + 1.33 = 1.32$
> $\mu_2^T \Sigma^{-1} \mu_2 = \begin{bmatrix} 3 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 2 \end{bmatrix} = 11.97 - 8.04 - 4.02 + 5.32 = 5.23$
>
> A fronteira de decis√£o √© dada por:
>
> $\begin{bmatrix} x_1 & x_2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} -2 \\ -1 \end{bmatrix} - \frac{1}{2}(1.32 - 5.23) = 0$
>
> $\begin{bmatrix} x_1 & x_2 \end{bmatrix} \begin{bmatrix} -1.99 \\ 0.67 \end{bmatrix} + 1.955 = 0$
> $-1.99x_1 + 0.67x_2 + 1.955 = 0$
>
>  Esta √© a equa√ß√£o da linha que separa as duas classes no espa√ßo de caracter√≠sticas.

**Corol√°rio 1:** No LDA, a fun√ß√£o discriminante linear pode ser vista como uma proje√ß√£o dos dados sobre um vetor que indica a dire√ß√£o de m√°xima separa√ß√£o entre as classes [^7.3.3]. Essa proje√ß√£o resulta em um espa√ßo de menor dimens√£o, que pode simplificar a an√°lise do modelo e facilitar a tomada de decis√£o. A fun√ß√£o discriminante linear, $ \delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2} \mu_k^T\Sigma^{-1}\mu_k + \log\pi_k$ onde $\pi_k$ √© a probabilidade *a priori* da classe $k$ e $\delta_k(x)$ √© usada para alocar a observa√ß√£o $x$ √† classe $k$ que resulta no maior valor de $\delta_k(x)$.
```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction LR
        A["Œ¥‚Çñ(x)"] --> B["x·µÄŒ£‚Åª¬πŒº‚Çñ"]
        A --> C["- 1/2 Œº‚Çñ·µÄŒ£‚Åª¬πŒº‚Çñ"]
         A --> D["+ log œÄ‚Çñ"]
        B --> E["Linear Term"]
        C --> F["Quadratic Term"]
        D --> G["Prior Probability"]

    end
```

> üí° **Exemplo Num√©rico:** Usando os dados do exemplo anterior, assumindo que as probabilidades *a priori* s√£o iguais ($\pi_1 = \pi_2 = 0.5$), podemos calcular a fun√ß√£o discriminante para cada classe e alocar um novo ponto $x$ √† classe com maior valor. Para um ponto $x = \begin{bmatrix} 2 \\ 1.5 \end{bmatrix}$, temos:
>
> $\delta_1(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \frac{1}{2}(1.32) + \log(0.5) = 0.665 - 0.66 = 0.005 + \log(0.5) \approx -0.688$
>
> $\delta_2(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 2 \end{bmatrix} - \frac{1}{2}(5.23) + \log(0.5) = 4.655 - 2.615 -0.693 \approx 1.347$
>
> Como $\delta_2(x) > \delta_1(x)$, o ponto $x$ seria alocado √† Classe 2.

**Conceito 3:** A **Regress√£o Log√≠stica** √© uma t√©cnica de modelagem estat√≠stica que estima a probabilidade de um evento bin√°rio [^7.4]. Em vez de assumir uma distribui√ß√£o normal para a resposta, ela modela a probabilidade usando a fun√ß√£o log√≠stica, que est√° entre 0 e 1. A probabilidade de um evento $y=1$ √© dada por [^7.4.1]:

$$p(x) = \frac{1}{1 + e^{-(\beta_0 + \beta^T x)}}$$

onde $\beta_0$ √© o intercepto, $\beta$ √© o vetor de coeficientes e $x$ s√£o as vari√°veis preditoras. A Regress√£o Log√≠stica tamb√©m maximiza a verossimilhan√ßa para estimar os par√¢metros. A fun√ß√£o de log-verossimilhan√ßa √© dada por [^7.4.2]:
$$L(\beta) = \sum_{i=1}^{N} y_i \log(p(x_i)) + (1 - y_i) \log(1 - p(x_i))$$
onde $y_i$ s√£o os r√≥tulos de classe (0 ou 1).
```mermaid
graph LR
  subgraph "Logistic Regression"
    direction TB
    A["p(x) = 1 / (1 + e^(-(Œ≤‚ÇÄ + Œ≤·µÄx)))"]
    B["Probability of y=1"]
    C["Œ≤‚ÇÄ: Intercept"]
    D["Œ≤: Coefficient Vector"]
    E["x: Predictor Variables"]
    A --> B
    A --> C
    A --> D
    A --> E
  end
```

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com uma vari√°vel preditora $x$ e um modelo log√≠stico com $\beta_0 = -2$ e $\beta_1 = 1$. Para um valor de $x=1$, a probabilidade de $y=1$ √©:
>
> $p(x=1) = \frac{1}{1 + e^{-(-2 + 1 \cdot 1)}} = \frac{1}{1 + e^1} \approx \frac{1}{1 + 2.718} \approx 0.269$.
>
>  Se tiv√©ssemos $y=1$, o valor contribu√≠do para a log-verossimilhan√ßa seria $\log(0.269) \approx -1.312$.
>  Se $y=0$, o valor seria $\log(1-0.269) = \log(0.731) \approx -0.313$.
>
> Vamos agora calcular a log-verossimilhan√ßa para um conjunto de dados pequeno:
> $x = [1, 2, 0, 1]$
> $y = [0, 1, 0, 1]$
> $p(x) = [\frac{1}{1 + e^{-(-2+1)}}, \frac{1}{1 + e^{-(-2+2)}}, \frac{1}{1 + e^{-(-2+0)}}, \frac{1}{1 + e^{-(-2+1)}} ] \approx [0.269, 0.5, 0.119, 0.269]$
>
> $L(\beta) = (0)\log(0.269) + (1)\log(1-0.269) + (1)\log(0.5) + (0)\log(1-0.5) + (0)\log(0.119) + (1)\log(1-0.119) + (1)\log(0.269) + (0)\log(1-0.269) = 0 -0.313 -0.693 + 0 + 0 -0.127 -1.312 + 0 = -2.445$

> ‚ö†Ô∏è **Nota Importante**: Para **classes n√£o-balanceadas**, pode ser necess√°rio ajustar os *pesos* das classes para evitar que o modelo favore√ßa a classe majorit√°ria [^7.4.2]. Ajustar o *threshold* tamb√©m √© crucial.

> ‚ùó **Ponto de Aten√ß√£o**: As estimativas dos par√¢metros na regress√£o log√≠stica s√£o obtidas por meio da **maximiza√ß√£o da verossimilhan√ßa**, geralmente usando m√©todos iterativos como o *Gradiente Descendente* ou m√©todos *Newton-Raphson* [^7.4.3].

> ‚úîÔ∏è **Destaque**: Tanto LDA como Regress√£o Log√≠stica podem levar a fronteiras lineares e, sob certas suposi√ß√µes, podem ser relacionadas, especialmente quando as classes s√£o bem separadas e as covari√¢ncias s√£o semelhantes [^7.5]. No entanto, a Regress√£o Log√≠stica √© mais flex√≠vel ao lidar com dados n√£o normais [^7.5].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction TB
        A["Input Data"] --> B["Indicator Matrix Creation"]
        B --> C["Linear Regression (OLS)"]
        C --> D["Coefficient Estimation"]
        D --> E["Predictions"]
         E --> F["Decision Rule Application"]
         F --> G["Class Assignment"]
    end
```

A regress√£o linear pode ser adaptada para problemas de classifica√ß√£o atrav√©s da cria√ß√£o de uma matriz de indicadores, onde cada coluna indica a presen√ßa de uma observa√ß√£o em uma classe espec√≠fica. O objetivo √© estimar os coeficientes da regress√£o que melhor separam as classes usando o m√©todo dos m√≠nimos quadrados [^7.2]. Uma vez estimados os coeficientes, as previs√µes s√£o feitas usando uma regra de decis√£o, por exemplo, alocando cada observa√ß√£o √† classe com a maior previs√£o. No entanto, a regress√£o de indicadores apresenta algumas limita√ß√µes, incluindo a possibilidade de previs√µes fora do intervalo [0,1] e a falta de um modelo probabil√≠stico bem definido para as classes [^7.2].

**Lemma 2:** Sob certas condi√ß√µes, as proje√ß√µes nos hiperplanos de decis√£o geradas pela regress√£o linear e pelos discriminantes lineares s√£o equivalentes. Quando as classes t√™m aproximadamente a mesma vari√¢ncia e est√£o bem separadas, a regress√£o linear pode gerar uma fronteira de decis√£o linear similar √†quela encontrada pelo LDA [^7.2]. Em outras palavras, se as classes s√£o bem separ√°veis, o m√©todo de m√≠nimos quadrados aplicado √† matriz de indicadores minimiza a dist√¢ncia das proje√ß√µes ao espa√ßo ideal e ao mesmo tempo maximiza a separabilidade das classes.

**Corol√°rio 2:** A equival√™ncia entre regress√£o linear e discriminantes lineares pode simplificar a an√°lise do modelo, pois a regress√£o linear √© mais f√°cil de implementar e interpretar em alguns cen√°rios [^7.3]. Por exemplo, se o foco for apenas na obten√ß√£o de uma fronteira linear, a regress√£o de indicadores pode ser uma alternativa mais direta ao LDA. No entanto, quando o objetivo √© modelar as probabilidades das classes, os m√©todos probabil√≠sticos como a regress√£o log√≠stica podem ser mais apropriados [^7.4].

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com duas vari√°veis preditoras, x1 e x2, e 5 amostras. As classes s√£o 0 e 1. As amostras e a matriz de indicadores seriam:
>
> Amostras:  $X = \begin{bmatrix} 1 & 2 \\ 2 & 3 \\ 3 & 1 \\ 4 & 5 \\ 5 & 2 \end{bmatrix}$
> Classes: $y = [0, 1, 0, 1, 1]$
> Matriz de Indicadores (codificando a classe 1 como 1 e classe 0 como 0): $Y = \begin{bmatrix} 0 \\ 1 \\ 0 \\ 1 \\ 1 \end{bmatrix}$
>
> Usando regress√£o linear, resolvemos $\hat{\beta} = (X^TX)^{-1}X^TY$ para encontrar o melhor ajuste aos dados.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LinearRegression
>
> X = np.array([[1, 2], [2, 3], [3, 1], [4, 5], [5, 2]])
> Y = np.array([0, 1, 0, 1, 1])
>
> # Adiciona uma coluna de 1's para o intercepto
> X_b = np.c_[np.ones((X.shape[0], 1)), X]
>
> # Calcula os coeficientes usando a equa√ß√£o normal
> beta_hat = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ Y
>
> print("Coeficientes Beta (intercepto, x1, x2):", beta_hat)
>
> # Prevendo a classe para os dados
> predictions = X_b @ beta_hat
> print("Previs√µes:", predictions)
>
> # Usando uma regra de decis√£o para classificar, por exemplo, > 0.5 para classe 1
> classified = [1 if p > 0.5 else 0 for p in predictions]
> print("Classes Preditas:", classified)
> ```
>
> Executando o c√≥digo, teremos:
>
> `Coeficientes Beta (intercepto, x1, x2): [-0.188  0.228  0.043]`
> `Previs√µes: [-0.083  0.62   0.488  0.745  0.721]`
> `Classes Preditas: [0, 1, 0, 1, 1]`
>
> As predi√ß√µes resultantes podem ser interpretadas como escores de pertin√™ncia √† classe 1, sendo que valores acima de 0.5 indicam maior probabilidade de pertencer a essa classe.
>
Em algumas situa√ß√µes, a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1] [^7.4]. No entanto, h√° situa√ß√µes em que a regress√£o de indicadores √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear [^7.2].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["Regularization in Logistic Regression"] --> B["L1 (Lasso) Penalty:  Œª‚ÇÅ||Œ≤||‚ÇÅ"]
        A --> C["L2 (Ridge) Penalty:  Œª‚ÇÇ||Œ≤||‚ÇÇ¬≤"]
        A --> D["Elastic Net: Œª‚ÇÅ||Œ≤||‚ÇÅ + Œª‚ÇÇ||Œ≤||‚ÇÇ¬≤"]
        B --> E["Sparsity"]
        C --> F["Stability"]
        D --> G["Sparsity and Stability"]
    end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas essenciais para controlar a complexidade do modelo, melhorar a sua interpretabilidade e estabilidade, e evitar o *overfitting* [^7.4.4]. Em modelos de regress√£o log√≠stica, as penaliza√ß√µes L1 e L2 podem ser usadas para controlar a magnitude dos coeficientes, com a penaliza√ß√£o L1 favorecendo a *esparsidade* (coeficientes iguais a zero) e a penaliza√ß√£o L2 promovendo a *estabilidade* (coeficientes menores) [^7.5]. A fun√ß√£o de custo regularizada para um modelo de regress√£o log√≠stica pode ser escrita como:

$$J(\beta) = - \frac{1}{N}L(\beta) + \lambda_1 ||\beta||_1 + \lambda_2 ||\beta||_2^2$$

onde $L(\beta)$ √© a fun√ß√£o log-verossimilhan√ßa, $||\beta||_1$ √© a norma L1 dos coeficientes, $||\beta||_2$ √© a norma L2 dos coeficientes e $\lambda_1$ e $\lambda_2$ s√£o os par√¢metros de regulariza√ß√£o.

> üí° **Exemplo Num√©rico:** Vamos aplicar regulariza√ß√£o L1 (Lasso) e L2 (Ridge) a um modelo de regress√£o log√≠stica. Usaremos o mesmo conjunto de dados do exemplo anterior ($X$ e $y$) e definiremos diferentes valores de $\lambda$ para observar o efeito da regulariza√ß√£o.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.preprocessing import StandardScaler
>
> X = np.array([[1, 2], [2, 3], [3, 1], [4, 5], [5, 2]])
> y = np.array([0, 1, 0, 1, 1])
>
> # Padronizar os dados
> scaler = StandardScaler()
> X_scaled = scaler.fit_transform(X)
>
> # Regress√£o Log√≠stica sem regulariza√ß√£o
> logreg = LogisticRegression(penalty='none', solver='lbfgs')
> logreg.fit(X_scaled, y)
> print("Regress√£o Log√≠stica (sem regulariza√ß√£o):\n", logreg.coef_, logreg.intercept_)
>
> # Regress√£o Log√≠stica com regulariza√ß√£o L1 (Lasso)
> logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1) # C √© o inverso de lambda
> logreg_l1.fit(X_scaled, y)
> print("\nRegress√£o Log√≠stica (L1):\n", logreg_l1.coef_, logreg_l1.intercept_)
>
> logreg_l1_lambda01 = LogisticRegression(penalty='l1', solver='liblinear', C=10)
> logreg_l1_lambda01.fit(X_scaled, y)
> print("\nRegress√£o Log√≠stica (L1, lambda=0.1):\n", logreg_l1_lambda01.coef_, logreg_l1_lambda01.intercept_)
>
> # Regress√£o Log√≠stica com regulariza√ß√£o L2 (Ridge)
> logreg_l2 = LogisticRegression(penalty='l2', solver='lbfgs', C=1)
> logreg_l2.fit(X_scaled, y)
> print("\nRegress√£o Log√≠stica (L2):\n", logreg_l2.coef_, logreg_l2.intercept_)
>
> logreg_l2_lambda01 = LogisticRegression(penalty='l2', solver='lbfgs', C=10)
> logreg_l2_lambda01.fit(X_scaled, y)
> print("\nRegress√£o Log√≠stica (L2, lambda=0.1):\n", logreg_l2_lambda01.coef_, logreg_l2_lambda01.intercept_)
>
> ```
> Executando o c√≥digo, teremos os seguintes resultados:
> ```
> Regress√£o Log√≠stica (sem regulariza√ß√£o):
>  [[ 0.890  0.450]] [-0.221]
>
> Regress√£o Log√≠stica (L1):
>  [[0.   0.711]] [-0.181]
>
> Regress√£o Log√≠stica (L1, lambda=0.1):
>  [[ 1.159  0.715]] [-0.249]
>
> Regress√£o Log√≠stica (L2):
>  [[0.754 0.387]] [-0.222]
>
> Regress√£o Log√≠stica (L2, lambda=0.1):
>  [[0.854 0.435]] [-0.221]
>
> ```
>
> Observamos que a regulariza√ß√£o L1 (Lasso) torna um dos coeficientes zero, enquanto a regulariza√ß√£o L2 (Ridge) diminui os valores dos coeficientes, mas n√£o os leva a zero. Quanto menor o valor de C (maior o lambda), mais forte a regulariza√ß√£o. O L1 seleciona vari√°veis, promovendo a esparsidade, enquanto L2 encolhe os coeficientes, mantendo todas as vari√°veis no modelo.
>

**Lemma 3:** A penaliza√ß√£o L1 na classifica√ß√£o log√≠stica leva a coeficientes esparsos, pois ela for√ßa alguns coeficientes a serem exatamente zero [^7.4.4]. Matematicamente, isso acontece devido √† forma da norma L1, que tem uma descontinuidade na origem, o que leva a solu√ß√µes esparsas quando a fun√ß√£o de custo √© otimizada.

**Prova do Lemma 3:** O otimizador da fun√ß√£o de custo regularizada com norma L1 busca o m√≠nimo global da fun√ß√£o, onde se o coeficiente √≥timo $\beta_j$ est√° na origem $\beta_j = 0$, a derivada da fun√ß√£o de custo muda a dire√ß√£o. Para ver isso, podemos usar o subgradiente da norma L1, $\partial ||\beta||_1 / \partial \beta_j = sign(\beta_j)$, que resulta na minimiza√ß√£o do custo atrav√©s da anula√ß√£o de alguns dos coeficientes, favorecendo a esparsidade. $\blacksquare$

**Corol√°rio 3:** A esparsidade induzida pela penaliza√ß√£o L1 melhora a interpretabilidade do modelo, pois apenas as vari√°veis mais importantes permanecem ativas [^7.4.5]. Isso pode facilitar a compreens√£o dos fatores que impulsionam a classifica√ß√£o e permitir uma an√°lise mais direcionada dos dados. A sele√ß√£o de vari√°veis atrav√©s da regulariza√ß√£o L1 tamb√©m pode melhorar a efici√™ncia do modelo em termos de c√°lculo e armazenamento.

> ‚ö†Ô∏è **Ponto Crucial**: As penaliza√ß√µes L1 e L2 podem ser combinadas (Elastic Net) para aproveitar as vantagens de ambos os tipos de regulariza√ß√£o, oferecendo um bom compromisso entre esparsidade e estabilidade [^7.5]. O par√¢metro de regulariza√ß√£o controla a import√¢ncia da penaliza√ß√£o, variando entre apenas penaliza√ß√£o L1 ($\lambda_2 = 0$), apenas penaliza√ß√£o L2 ($\lambda_1 = 0$), e uma combina√ß√£o de ambas ($\lambda_1 > 0$, $\lambda_2 > 0$).

### Separating Hyperplanes e Perceptrons
A ideia de maximizar a margem de separa√ß√£o entre as classes leva ao conceito de hiperplanos separadores √≥timos. O problema de otimiza√ß√£o associado √† obten√ß√£o de um hiperplano √≥timo pode ser formulado usando o dual de Wolfe, onde as solu√ß√µes surgem como combina√ß√µes lineares dos pontos de suporte [^7.5.2]. O Perceptron de Rosenblatt √© um algoritmo de aprendizado que encontra um hiperplano separador para dados linearmente separ√°veis [^7.5.1]. Sob certas condi√ß√µes, o Perceptron converge para uma solu√ß√£o que separa as classes, embora a solu√ß√£o possa n√£o ser √∫nica, especialmente em dados sobrepostos.

### Pergunta Te√≥rica Avan√ßada (Exemplo): Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?
**Resposta:**

Sob a suposi√ß√£o de que as classes seguem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia, o LDA e a Regra de Decis√£o Bayesiana podem ser vistos como equivalentes [^7.3]. No entanto, a forma como cada um √© obtido e algumas implica√ß√µes pr√°ticas s√£o distintas.

**Lemma 4:** A equival√™ncia formal pode ser vista comparando a fun√ß√£o discriminante do LDA com a log-probabilidade da classe *a posteriori* na Regra de Decis√£o Bayesiana [^7.3], [^7.3.3]. Dado que temos duas classes e suas fun√ß√µes de densidade de probabilidade $f_1(x)$ e $f_2(x)$, onde $f_i(x) \sim N(\mu_i, \Sigma)$. A Regra de Decis√£o Bayesiana aloca $x$ √† classe $i$ que maximiza a probabilidade *a posteriori* $P(G=i|X=x) = \frac{\pi_i f_i(x)}{\pi_1 f_1(x) + \pi_2 f_2(x)}$, sendo $\pi_i$ as probabilidades *a priori* da classe $i$. Tomando o log dessa probabilidade e ignorando termos constantes com rela√ß√£o a *i*, a Regra de Decis√£o Bayesiana se resume a alocar $x$ √† classe $i$ que maximiza $\log f_i(x) + \log\pi_i$. Substituindo a fun√ß√£o de densidade de probabilidade normal e simplificando, temos $\delta_i(x) = x^T\Sigma^{-1}\mu_i - \frac{1}{2} \mu_i^T\Sigma^{-1}\mu_i + \log\pi_i$, que √© a mesma fun√ß√£o discriminante do LDA, demonstrando a equival√™ncia sob a suposi√ß√£o das distribui√ß√µes Gaussianas com a mesma covari√¢ncia. $\blacksquare$
```mermaid
graph LR
    subgraph "Equivalence: LDA and Bayesian Decision Rule"
        direction TB
        A["Bayesian Decision Rule"] --> B["Maximize P(G=i|X=x)"]
        B --> C["P(G=i|X=x) = (œÄ·µ¢f·µ¢(x)) / ‚àë‚Çñ(œÄ‚Çñf‚Çñ(x))"]
        C --> D["log(P(G=i|X=x))"]
        D --> E["Maximize log(f·µ¢(x)) + log(œÄ·µ¢)"]
         E --> F["Under Gaussian assumption: Œ¥·µ¢(x) = x·µÄŒ£‚Åª¬πŒº·µ¢ - 1/2 Œº·µ¢·µÄŒ£‚Åª¬πŒº·µ¢ + log(œÄ·µ¢)"]
        F --> G["LDA Discriminant Function"]
         G --> H["Equivalence"]

    end
```
**Corol√°rio 4:** Ao relaxar a hip√≥tese de covari√¢ncias iguais, surgem as fronteiras quadr√°ticas, dando origem ao **Quadratic Discriminant Analysis (QDA)** [^7.3]. O QDA permite uma maior flexibilidade na modelagem das classes, mas tamb√©m introduz mais par√¢metros a serem estimados, o que pode levar a problemas de *overfitting* em conjuntos de dados pequenos.

> ‚ö†Ô∏è **Ponto Crucial**: A escolha entre LDA e QDA (ou mesmo outras formas de fun√ß√µes discriminantes) depende da adequa√ß√£o das suposi√ß√µes aos dados, bem como o n√∫mero de amostras dispon√≠veis. A decis√£o de usar covari√¢ncias iguais ou separadas entre as classes impacta fortemente a forma da fronteira de decis√£o (linear vs. quadr√°tica) [^7.3.1].

### Conclus√£o
Este cap√≠tulo explorou conceitos fundamentais relacionados a in-sample error estimates, incluindo a rela√ß√£o entre vi√©s e vari√¢ncia, m√©todos como LDA e Regress√£o Log√≠stica para classifica√ß√£o, t√©cnicas de regress√£o de indicadores, sele√ß√£o de vari√°veis e regulariza√ß√£o, hiperplanos separadores e Perceptrons. M√©todos de avalia√ß√£o de performance com vi√©s e vari√¢ncia em modelos s√£o cruciais para selecionar o melhor modelo e par√¢metros.

### Footnotes
[^7.1]: "The generalization performance of a learning method relates to its prediction capability on independent test data. Assessment of this performance is extremely important in practice, since it guides the choice of learning method or model, and gives us a measure of the quality of the ultimately chosen model." *(Trecho de "The Elements of Statistical Learning")*
[^7.2]: "Figure 7.1 illustrates the important issue in assessing the ability of a learning method to generalize. Consider first the case of a quantitative or interval scale response. We have a target variable Y, a vector of inputs X, and a prediction model f(X) that has been estimated from a training set T." *(Trecho de "The Elements of Statistical Learning")*
[^7.3]: "The story is similar for a qualitative or categorical response G taking one of K values in a set G, labeled for convenience as 1, 2, ..., K. Typically we model the probabilities pk(X) = Pr(G = k|X) (or some monotone transformations fk(X)), and then ƒú(X) = arg maxk fk(X)." *(Trecho de "The Elements of Statistical Learning")*
[^7.3.1]: "Test error, also referred to as generalization error, is the prediction error over an independent test sample" *(Trecho de "The Elements of Statistical Learning")*
[^7.3.2]: "The first term is the variance of the target around its true mean f(x0), and cannot be avoided no matter how well we estimate