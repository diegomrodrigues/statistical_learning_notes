## Learning Curves e Valida√ß√£o Cruzada
<imagem: Mapa mental abrangente que conecta a complexidade do modelo, bias, variance, learning curves, diferentes abordagens de valida√ß√£o cruzada (k-fold, leave-one-out) e suas aplica√ß√µes na avalia√ß√£o e sele√ß√£o de modelos. Inclua links para as defini√ß√µes de erro de treinamento, erro de teste e otimismo do erro.>

### Introdu√ß√£o
A avalia√ß√£o do desempenho de um m√©todo de aprendizado √© crucial para determinar sua capacidade de generaliza√ß√£o, ou seja, sua efic√°cia ao lidar com dados n√£o vistos. Este cap√≠tulo explora m√©todos para avaliar e selecionar modelos de aprendizado, com foco nas curvas de aprendizado e t√©cnicas de valida√ß√£o cruzada. A compreens√£o da rela√ß√£o entre bias, variance e complexidade do modelo √© fundamental para a avalia√ß√£o do desempenho do aprendizado [^7.1]. M√©todos de valida√ß√£o s√£o necess√°rios para estimar o qu√£o bem um modelo generaliza para novos dados, ajudando na sele√ß√£o do modelo mais adequado para um problema espec√≠fico [^7.1].

### Conceitos Fundamentais

**Conceito 1:** O **problema de generaliza√ß√£o** centra-se na habilidade de um modelo de aprendizado em realizar predi√ß√µes precisas em dados de teste independentes, que n√£o foram utilizados durante o treinamento. A complexidade do modelo influencia diretamente o *trade-off* entre **bias** e **variance** [^7.2]. Um modelo com alta complexidade tende a ter baixo bias (ajusta-se bem aos dados de treinamento), mas alta variance (sensibilidade a pequenas mudan√ßas nos dados de treinamento, levando a um mau desempenho em dados n√£o vistos). Por outro lado, modelos com baixa complexidade tendem a ter alto bias (n√£o capturam a complexidade dos dados), mas baixa variance (s√£o mais est√°veis). O objetivo √© encontrar um ponto de equil√≠brio que minimize o erro de generaliza√ß√£o.

**Lemma 1:** O erro de previs√£o esperado pode ser decomposto em tr√™s componentes: ru√≠do irredut√≠vel, bias ao quadrado e variance. Essa decomposi√ß√£o oferece uma compreens√£o sobre as fontes de erro de previs√£o. Especificamente, para um modelo de regress√£o com um ponto de entrada $x_0$, o erro esperado pode ser expresso como:
$$Err(x_0) = \sigma^2 + [Ef(x_0) - f(x_0)]^2 + E[f(x_0) - Ef(x_0)]^2$$
onde $\sigma^2$ representa a vari√¢ncia irredut√≠vel, $[Ef(x_0) - f(x_0)]^2$ o bias ao quadrado e $E[f(x_0) - Ef(x_0)]^2$ a vari√¢ncia [^7.3]. Esta decomposi√ß√£o formaliza o *trade-off* entre vi√©s e vari√¢ncia. $\blacksquare$

```mermaid
graph LR
    subgraph "Expected Prediction Error Decomposition"
        direction TB
        A["Err(x_0)"]
        B["Irreducible Error: œÉ¬≤"]
        C["Bias¬≤: (E[fÃÇ(x_0)] - f(x_0))¬≤"]
        D["Variance: E[(fÃÇ(x_0) - E[fÃÇ(x_0)])¬≤]"]
        A --> B
        A --> C
        A --> D
    end
```

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o linear tentando ajustar dados gerados por uma fun√ß√£o quadr√°tica com algum ru√≠do.
>
> 1. **Cen√°rio com Underfitting (Alto Bias, Baixa Variance):** Um modelo linear simples (reta) √© usado para ajustar os dados. O modelo n√£o consegue capturar a curvatura dos dados, resultando em alto bias.  A vari√¢ncia √© baixa, pois o modelo n√£o muda muito se os dados de treinamento forem ligeiramente modificados.  Suponha que, em um ponto $x_0$, o valor real $f(x_0) = 5$, a previs√£o m√©dia do modelo seja $Ef(x_0) = 3$. Logo, o bias ao quadrado √© $(3-5)^2 = 4$. Se a vari√¢ncia for $E[f(x_0) - Ef(x_0)]^2 = 0.5$, e o ru√≠do irredut√≠vel for $\sigma^2 = 0.1$, o erro esperado seria $Err(x_0) = 0.1 + 4 + 0.5 = 4.6$.
>
> 2. **Cen√°rio com Overfitting (Baixo Bias, Alta Variance):** Um modelo de regress√£o polinomial de grau muito alto √© utilizado. O modelo se ajusta perfeitamente aos dados de treinamento, resultando em baixo bias. No entanto, ele √© muito sens√≠vel a pequenas mudan√ßas nos dados, resultando em alta vari√¢ncia.  Suponha que, no ponto $x_0$, $f(x_0) = 5$, e a previs√£o m√©dia $Ef(x_0) = 4.9$. O bias ao quadrado √© $(4.9-5)^2 = 0.01$.  A vari√¢ncia √© alta, digamos $E[f(x_0) - Ef(x_0)]^2 = 3$, e o ru√≠do irredut√≠vel √© novamente $\sigma^2 = 0.1$.  O erro esperado √© $Err(x_0) = 0.1 + 0.01 + 3 = 3.11$.
>
> 3. **Cen√°rio Ideal (Equil√≠brio):** Um modelo polinomial de grau adequado √© usado, capturando a curvatura dos dados sem se ajustar ao ru√≠do. O modelo tem baixo bias e baixa vari√¢ncia. Suponha que $Ef(x_0) = 4.95$, ent√£o o bias ao quadrado √© $(4.95-5)^2 = 0.0025$. A vari√¢ncia √© de $E[f(x_0) - Ef(x_0)]^2 = 0.3$, e o ru√≠do √© $\sigma^2 = 0.1$. O erro esperado √© $Err(x_0) = 0.1 + 0.0025 + 0.3 = 0.4025$.
>
> Este exemplo ilustra como o trade-off entre bias e vari√¢ncia influencia o erro total do modelo.
> ```mermaid
> graph LR
>     A[Underfitting] --> B(Alto Bias);
>     A --> C(Baixa Variance);
>     D[Overfitting] --> E(Baixo Bias);
>     D --> F(Alta Variance);
>     G[Equil√≠brio] --> H(Baixo Bias);
>     G --> I(Baixa Variance);
> ```

**Conceito 2:** A **Linear Discriminant Analysis (LDA)** √© um m√©todo de classifica√ß√£o linear que assume que as classes seguem uma distribui√ß√£o normal com mesma matriz de covari√¢ncia, resultando em fronteiras de decis√£o lineares [^4.3]. A fun√ß√£o discriminante linear, dada por $\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T \Sigma^{-1}\mu_k + \log \pi_k$, permite classificar um ponto $x$ na classe $k$ que maximiza $\delta_k(x)$ [^4.3.1]. A LDA simplifica a an√°lise de dados ao reduzir a dimensionalidade dos dados, utilizando proje√ß√µes lineares [^4.3.2]. No entanto, suas suposi√ß√µes de normalidade e covari√¢ncias iguais podem limitar seu desempenho em cen√°rios mais complexos [^4.3.3].

**Corol√°rio 1:** Em cen√°rios onde as classes podem ser bem separadas por proje√ß√µes lineares, a fun√ß√£o discriminante da LDA pode ser simplificada para a forma $\delta_k(x) = w_k^T x + b_k$, onde $w_k = \Sigma^{-1} \mu_k$ e $b_k = - \frac{1}{2}\mu_k^T \Sigma^{-1}\mu_k + \log \pi_k$. O limite de decis√£o entre duas classes $j$ e $k$ √© dado por $\{x \,|\, (w_j - w_k)^T x + (b_j - b_k) = 0 \}$, que representa um hiperplano linear. Esse corol√°rio estabelece uma rela√ß√£o direta entre a forma projetada dos dados e as decis√µes de classe [^4.3.1].

```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction TB
        A["Œ¥_k(x) = x·µÄŒ£‚Åª¬πŒº_k - 1/2 Œº_k·µÄŒ£‚Åª¬πŒº_k + log(œÄ_k)"]
        B["w_k = Œ£‚Åª¬πŒº_k"]
        C["b_k = -1/2 Œº_k·µÄŒ£‚Åª¬πŒº_k + log(œÄ_k)"]
        D["Simplified Discriminant: Œ¥_k(x) = w_k·µÄx + b_k"]
        E["Decision Boundary: (w_j - w_k)·µÄx + (b_j - b_k) = 0"]
        A --> B
        A --> C
        B & C --> D
        D --> E
    end
```

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com duas classes e dois preditores.
>
>  Suponha que as m√©dias das classes sejam $\mu_1 = [1, 1]^T$ e $\mu_2 = [3, 3]^T$, e a matriz de covari√¢ncia comum seja $\Sigma = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$. As probabilidades a priori das classes s√£o $\pi_1 = \pi_2 = 0.5$.
>
>   1. **Calculando os vetores w:** $w_1 = \Sigma^{-1}\mu_1 = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$ e $w_2 = \Sigma^{-1}\mu_2 = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} = \begin{bmatrix} 3 \\ 3 \end{bmatrix}$.
>   2. **Calculando os bias b:** $b_1 = - \frac{1}{2} \mu_1^T \Sigma^{-1} \mu_1 + \log \pi_1 = - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} + \log 0.5 = -1 - 0.693 = -1.693$ e $b_2 = - \frac{1}{2} \mu_2^T \Sigma^{-1} \mu_2 + \log \pi_2 = - \frac{1}{2} \begin{bmatrix} 3 & 3 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} + \log 0.5 = -9 - 0.693 = -9.693$.
>   3. **Fun√ß√µes discriminantes:** $\delta_1(x) = \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} - 1.693 = x_1 + x_2 - 1.693$ e $\delta_2(x) = \begin{bmatrix} 3 & 3 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} - 9.693 = 3x_1 + 3x_2 - 9.693$.
>   4. **Fronteira de decis√£o:** A fronteira de decis√£o entre as classes 1 e 2 √© dada por $\delta_1(x) = \delta_2(x)$, ou seja, $x_1 + x_2 - 1.693 = 3x_1 + 3x_2 - 9.693$, que simplifica para $2x_1 + 2x_2 = 8$, ou $x_1 + x_2 = 4$. Esta √© a equa√ß√£o de uma reta no espa√ßo dos preditores, que separa as duas classes.
>   Este exemplo mostra como a LDA utiliza as m√©dias, covari√¢ncia e probabilidades a priori para construir fronteiras de decis√£o lineares.

**Conceito 3:** A **Logistic Regression** modela a probabilidade de uma classe atrav√©s de uma fun√ß√£o sigmoide (ou log√≠stica) aplicada a uma combina√ß√£o linear das entradas [^4.4]. O *log-odds* √© modelado linearmente como:
$$ \log \frac{P(Y=1|X)}{1-P(Y=1|X)} = \beta_0 + \beta_1X_1 + \ldots + \beta_pX_p$$
[^4.4.1]
Os coeficientes s√£o estimados atrav√©s da maximiza√ß√£o da verossimilhan√ßa [^4.4.2], o que envolve encontrar os par√¢metros $\beta$ que maximizam a probabilidade dos dados observados. A regress√£o log√≠stica √© mais flex√≠vel que a LDA, pois n√£o requer suposi√ß√µes sobre a distribui√ß√£o dos preditores [^4.4.3]. Os termos de regulariza√ß√£o L1 e L2 podem ser adicionados para prevenir overfitting [^4.4.4] e para selecionar as vari√°veis mais importantes no modelo [^4.4.5].

```mermaid
graph LR
    subgraph "Logistic Regression Model"
        direction TB
        A["Log-Odds: log(P(Y=1|X) / (1-P(Y=1|X)))"]
        B["Linear Model: Œ≤‚ÇÄ + Œ≤‚ÇÅX‚ÇÅ + ... + Œ≤‚ÇöX‚Çö"]
        C["Sigmoid Function: P(Y=1|X) = 1 / (1 + e^(-(Œ≤‚ÇÄ + Œ≤‚ÇÅX‚ÇÅ + ... + Œ≤‚ÇöX‚Çö)))"]
         A --> B
        B --> C
    end
```

> ‚ö†Ô∏è **Nota Importante:** A regress√£o log√≠stica fornece estimativas probabil√≠sticas mais est√°veis, especialmente em compara√ß√£o com a regress√£o de indicadores, quando as probabilidades s√£o o foco central da an√°lise [^4.4.1].
> ‚ùó **Ponto de Aten√ß√£o:** O desempenho da regress√£o log√≠stica pode ser afetado por classes n√£o balanceadas; estrat√©gias como subamostragem ou sobreamostragem podem mitigar esse problema [^4.4.2].
> ‚úîÔ∏è **Destaque:** As estimativas dos par√¢metros tanto em LDA como na regress√£o log√≠stica est√£o relacionadas, indicando similaridades na base da modelagem linear [^4.5].

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com um √∫nico preditor.
>
>  Suponha que, ap√≥s ajustar um modelo de regress√£o log√≠stica, encontremos os coeficientes $\beta_0 = -2$ e $\beta_1 = 1$. A probabilidade de a classe ser 1, dado um valor do preditor $X$, √©:
>
>   $$ P(Y=1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1X)}} $$
>
>  1. **Para X = 1:** $ P(Y=1|X=1) = \frac{1}{1 + e^{-(-2 + 1*1)}} = \frac{1}{1 + e^{1}} \approx \frac{1}{1+2.718} \approx 0.269$. Isso indica que um valor de X=1 leva a uma baixa probabilidade de a classe ser 1.
>   2. **Para X = 3:** $ P(Y=1|X=3) = \frac{1}{1 + e^{-(-2 + 1*3)}} = \frac{1}{1 + e^{-1}} \approx \frac{1}{1+0.368} \approx 0.731$. Um valor de X=3 leva a uma alta probabilidade de a classe ser 1.
>   3.  **Log-Odds:** O log-odds para X = 1 √© $\log(\frac{0.269}{1-0.269}) = \log(\frac{0.269}{0.731}) \approx -1$. O log-odds para X=3 √© $\log(\frac{0.731}{1-0.731}) = \log(\frac{0.731}{0.269}) \approx 1$.
>
> Este exemplo demonstra como a regress√£o log√≠stica transforma uma combina√ß√£o linear dos preditores em probabilidades usando a fun√ß√£o sigmoide, permitindo a classifica√ß√£o de observa√ß√µes.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
```mermaid
graph LR
    A["Encode Classes with Indicator Matrix"] --> B["Linear Regression"]
    B --> C["Prediction via Projection"]
    C --> D["Performance Evaluation"]
```
**Explica√ß√£o:** Diagrama que representa o processo de utiliza√ß√£o da regress√£o linear para classifica√ß√£o. [^4.2]

A regress√£o linear pode ser utilizada para problemas de classifica√ß√£o codificando classes como vari√°veis indicadoras (matriz de indicadores) e estimando os coeficientes por m√≠nimos quadrados. Embora essa abordagem possa parecer simples, ela tem suas limita√ß√µes. Quando as classes s√£o bem separadas, a regress√£o linear tende a funcionar razoavelmente bem, retornando limites de decis√£o que s√£o lineares [^4.2]. No entanto, quando as classes se sobrep√µem ou quando se extrapolam previs√µes, a regress√£o linear pode produzir resultados fora do intervalo desejado para probabilidade (0 a 1). Para um problema de classifica√ß√£o de K classes, codificamos a vari√°vel resposta como um vetor de K dimens√µes, onde o k-√©simo elemento √© 1 se a observa√ß√£o pertencer a classe k e 0 caso contr√°rio [^4.2]. Assim, podemos aplicar a regress√£o linear e obter um vetor de predi√ß√µes para cada classe, e ent√£o, selecionamos a classe com a maior predi√ß√£o como a classe predita.

**Lemma 2:** Dada uma matriz de indicadores $Y$ com dimens√£o $N \times K$ (N observa√ß√µes e K classes), e uma matriz de preditores $X$ de dimens√£o $N \times p$, a proje√ß√£o do ponto $x_0$ no espa√ßo das classes atrav√©s da regress√£o linear de indicadores √© dada por $\hat{Y}_0 = x_0^T(X^TX)^{-1}X^TY$. Se os preditores $X$ s√£o ortogonais entre si e as classes s√£o bem separadas, essa proje√ß√£o pode se aproximar das proje√ß√µes obtidas com o uso de discriminantes lineares em certas condi√ß√µes. A matriz de coeficientes de regress√£o $\hat{B}=(X^TX)^{-1}X^TY$ captura as rela√ß√µes lineares entre os preditores e os indicadores de classe. $\blacksquare$

```mermaid
graph LR
    subgraph "Indicator Regression Projection"
        direction TB
        A["Indicator Matrix Y (N x K)"]
        B["Predictor Matrix X (N x p)"]
        C["Projection: YÃÇ‚ÇÄ = x‚ÇÄ·µÄ(X·µÄX)‚Åª¬πX·µÄY"]
        D["Regression Coefficients: BÃÇ = (X·µÄX)‚Åª¬πX·µÄY"]
        A & B --> C
        B --> D
    end
```

**Corol√°rio 2:** O resultado do Lemma 2 implica que, em cen√°rios onde as classes s√£o linearmente separ√°veis, a fronteira de decis√£o obtida pela regress√£o linear com matriz de indicadores √© essencialmente um hiperplano linear, semelhante √†quele produzido por discriminantes lineares. Isso sugere uma conex√£o entre as proje√ß√µes em hiperplanos de decis√£o lineares de diferentes abordagens e a possibilidade de utilizar a regress√£o de indicadores quando o foco principal √© a obten√ß√£o de fronteiras de decis√£o lineares [^4.3].

> Em cen√°rios onde uma fronteira de decis√£o linear √© suficiente, a regress√£o de indicadores pode ser vantajosa devido a sua simplicidade e facilidade de implementa√ß√£o [^4.2]. No entanto, em situa√ß√µes mais complexas, a regress√£o log√≠stica pode ser uma op√ß√£o melhor devido ao seu tratamento probabil√≠stico e capacidade de modelar as probabilidades com maior precis√£o [^4.4].

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com 2 classes e 2 preditores.
>
> 1. **Dados de treinamento:** Suponha que tenhamos 3 observa√ß√µes para cada classe, com os seguintes preditores $X$ e labels $Y$:
>
>    Classe 1: $X_1 = \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 2 & 1 \end{bmatrix}$, $Y_1 = \begin{bmatrix} 1 & 0 \\ 1 & 0 \\ 1 & 0 \end{bmatrix}$
>
>    Classe 2: $X_2 = \begin{bmatrix} 3 & 3 \\ 3 & 4 \\ 4 & 3 \end{bmatrix}$, $Y_2 = \begin{bmatrix} 0 & 1 \\ 0 & 1 \\ 0 & 1 \end{bmatrix}$
>
>    Concatenando, $X = \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 2 & 1 \\ 3 & 3 \\ 3 & 4 \\ 4 & 3 \end{bmatrix}$ e $Y = \begin{bmatrix} 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 0 & 1 \\ 0 & 1 \\ 0 & 1 \end{bmatrix}$.
> 2. **C√°lculo de  $\hat{B}$:** Usamos a f√≥rmula $\hat{B} = (X^TX)^{-1}X^TY$:
>
>    $X^TX = \begin{bmatrix} 1 & 1 & 2 & 3 & 3 & 4 \\ 1 & 2 & 1 & 3 & 4 & 3 \end{bmatrix} \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 2 & 1 \\ 3 & 3 \\ 3 & 4 \\ 4 & 3 \end{bmatrix} = \begin{bmatrix} 40 & 38 \\ 38 & 40 \end{bmatrix}$.
>
>    $(X^TX)^{-1} = \frac{1}{40^2-38^2} \begin{bmatrix} 40 & -38 \\ -38 & 40 \end{bmatrix} = \frac{1}{156} \begin{bmatrix} 40 & -38 \\ -38 & 40 \end{bmatrix} $
>
>    $X^TY = \begin{bmatrix} 1 & 1 & 2 & 3 & 3 & 4 \\ 1 & 2 & 1 & 3 & 4 & 3 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 0 & 1 \\ 0 & 1 \\ 0 & 1 \end{bmatrix} = \begin{bmatrix} 4 & 10 \\ 4 & 10 \end{bmatrix}$
>
>    $\hat{B} = \frac{1}{156} \begin{bmatrix} 40 & -38 \\ -38 & 40 \end{bmatrix} \begin{bmatrix} 4 & 10 \\ 4 & 10 \end{bmatrix} =  \frac{1}{156}\begin{bmatrix} 40 \cdot 4 - 38 \cdot 4 & 40 \cdot 10 - 38 \cdot 10 \\ -38 \cdot 4 + 40 \cdot 4 & -38 \cdot 10 + 40 \cdot 10 \end{bmatrix} = \frac{1}{156}\begin{bmatrix} 8 & 20 \\ 8 & 20 \end{bmatrix} = \begin{bmatrix} 0.051 & 0.128 \\ 0.051 & 0.128 \end{bmatrix}$
>
> 3.  **Predi√ß√£o:** Para um novo ponto $x_0 = \begin{bmatrix} 2 & 2 \end{bmatrix}$, a predi√ß√£o √© $\hat{Y}_0 = x_0^T \hat{B} = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 0.051 & 0.128 \\ 0.051 & 0.128 \end{bmatrix} = \begin{bmatrix} 0.204 & 0.512 \end{bmatrix}$.
>    A maior probabilidade √© 0.512, ent√£o o ponto seria classificado como pertencente √† classe 2.
>
> Este exemplo demonstra como a regress√£o linear com matrizes de indicadores pode ser usada para classifica√ß√£o, estimando os coeficientes e usando-os para prever a classe de novos pontos.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem: Mapa mental que ilustra a rela√ß√£o entre regulariza√ß√£o L1 e L2, modelos log√≠sticos, e sele√ß√£o de vari√°veis. Mostra como diferentes m√©todos de regulariza√ß√£o afetam a esparsidade, bias e vari√¢ncia do modelo. Inclua exemplos de modelos usando penaliza√ß√£o L1 e L2. >

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o fundamentais para melhorar o desempenho e a interpretabilidade de modelos de classifica√ß√£o, especialmente quando lidamos com um grande n√∫mero de preditores. A regulariza√ß√£o adiciona um termo de penaliza√ß√£o √† fun√ß√£o de perda, que for√ßa os coeficientes do modelo a diminu√≠rem e evita o *overfitting* [^4.4.4].

Em modelos log√≠sticos, a fun√ß√£o de custo √© geralmente definida como a *negative log-likelihood* e o objetivo √© encontrar os par√¢metros que minimizem o erro de classifica√ß√£o. A penaliza√ß√£o L1 (Lasso) adiciona um termo proporcional ao valor absoluto dos coeficientes:
$$ L_{Lasso}(\beta) = - \frac{1}{N} \sum_{i=1}^{N} [ y_i \log(p_i) + (1 - y_i) \log(1 - p_i)] + \lambda \sum_{j=1}^p |\beta_j|$$
onde $\lambda$ √© o par√¢metro de regulariza√ß√£o que controla a magnitude da penaliza√ß√£o [^4.4.4]. A penaliza√ß√£o L2 (Ridge) adiciona um termo proporcional ao quadrado dos coeficientes:
$$ L_{Ridge}(\beta) = - \frac{1}{N} \sum_{i=1}^{N} [ y_i \log(p_i) + (1 - y_i) \log(1 - p_i)] + \lambda \sum_{j=1}^p \beta_j^2$$
A penaliza√ß√£o L1 tende a produzir modelos esparsos, onde muitos coeficientes s√£o exatamente zero, atuando como um m√©todo de sele√ß√£o de vari√°veis. J√° a penaliza√ß√£o L2 reduz a magnitude dos coeficientes, prevenindo *overfitting* e melhorando a estabilidade do modelo [^4.5]. A combina√ß√£o de ambas as penaliza√ß√µes resulta no Elastic Net, que busca um compromisso entre esparsidade e estabilidade [^4.5].

```mermaid
graph LR
    subgraph "Regularization in Logistic Regression"
        direction TB
        A["Negative Log-Likelihood: L(Œ≤)"]
        B["L1 Penalty (Lasso): Œª‚àë|Œ≤‚±º|"]
        C["L2 Penalty (Ridge): Œª‚àëŒ≤‚±º¬≤"]
         D["Lasso Objective: L(Œ≤) + Œª‚àë|Œ≤‚±º|"]
        E["Ridge Objective: L(Œ≤) + Œª‚àëŒ≤‚±º¬≤"]
        F["Elastic Net: Compromise of L1 and L2"]
        A --> B
        A --> C
        A & B --> D
        A & C --> E
        B & C --> F
    end
```

**Lemma 3:** A penaliza√ß√£o L1 em regress√£o log√≠stica resulta em coeficientes esparsos devido √† natureza de sua fun√ß√£o de penaliza√ß√£o. A forma da penalidade L1 induz a que coeficientes menos relevantes sejam levados a zero, pois a solu√ß√£o √≥tima frequentemente se encontra em pontos onde um ou mais coeficientes s√£o exatamente zero, j√° que a norma L1 n√£o √© diferenci√°vel em zero. $\blacksquare$

**Prova do Lemma 3:** O problema de otimiza√ß√£o com penalidade L1 pode ser expresso como:
$$ \text{minimize } L(\beta) + \lambda ||\beta||_1$$
onde $L(\beta)$ representa a *negative log-likelihood* do modelo e $||\beta||_1$ √© a norma L1 dos coeficientes. A minimiza√ß√£o dessa fun√ß√£o leva a solu√ß√µes onde alguns coeficientes s√£o exatamente zero, devido a sua n√£o diferenciabilidade em $\beta_j=0$, enquanto outros s√£o diferentes de zero. Essa propriedade √© essencial para a sele√ß√£o de vari√°veis em regress√£o log√≠stica, pois remove os preditores menos relevantes do modelo, tornando-o mais interpret√°vel e robusto. $\blacksquare$

**Corol√°rio 3:** Modelos log√≠sticos com regulariza√ß√£o L1, que induzem √† esparsidade, tornam-se mais interpret√°veis, pois os coeficientes diferentes de zero indicam quais vari√°veis t√™m o maior impacto nas previs√µes do modelo. Essa esparsidade simplifica a an√°lise e permite que os especialistas se concentrem nos preditores mais relevantes, o que contribui para um melhor entendimento da rela√ß√£o entre os preditores e a vari√°vel resposta [^4.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: A escolha entre L1 e L2, ou uma combina√ß√£o atrav√©s do Elastic Net, depende do objetivo da modelagem. L1 √© prefer√≠vel quando se busca esparsidade e sele√ß√£o de vari√°veis, enquanto L2 oferece mais estabilidade e previne o *overfitting* [^4.5].

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o log√≠stica com 3 preditores.
>
>  Vamos usar dados simulados para ilustrar o efeito da regulariza√ß√£o.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.preprocessing import StandardScaler
>
> # Dados simulados
> np.random.seed(42)
> N = 100
> X = np.random.randn(N, 3)
> true_beta = np.array([1.5, -0.8, 0.0])  # O terceiro preditor n√£o √© relevante
> log_odds = X @ true_beta
> probs = 1 / (1 + np.exp(-log_odds))
> y = np.random.binomial(1, probs)
>
> scaler = StandardScaler()
> X_scaled = scaler.fit_transform(X)
>
> # Modelo sem regulariza√ß√£o
> model_none = LogisticRegression(penalty=None, solver='lbfgs').fit(X_scaled, y)
>
> # Modelo com regulariza√ß√£o L1 (Lasso)
> model_l1 = LogisticRegression(penalty='l1', C=0.5, solver='liblinear', random_state=42).fit(X_scaled, y)
>
> # Modelo com regulariza√ß√£o L2 (Ridge)
> model_l2 = LogisticRegression(penalty='l2', C=0.5, solver='lbfgs', random_state=42).fit(X_scaled, y)
>
> print("Coeficientes sem regulariza√ß√£o:", model_none.coef_)
> print("Coeficientes com regulariza√ß√£o L1:", model_l1.coef_)
> print("Coeficientes com regulariza√ß√£o L2:", model_l2.coef_)
> ```
>
> **Resultado:**
> ```
> Coeficientes sem regulariza√ß√£o: [[ 1.566  -0.812  0.041]]
> Coeficientes com regulariza√ß√£o L1: [[ 0.997 -0.184  0.   ]]
> Coeficientes com regulariza√ß√£o L2: [[ 1.221 -0.566  -0.011]]
> ```
>
>   1. **Sem regulariza√ß√£o:** Todos os coeficientes s√£o diferentes de zero, incluindo o terceiro que, na verdade, n√£o √© relevante.
>   2. **Regulariza√ß√£o L1:** O coeficiente do terceiro preditor foi reduzido a zero, realizando sele√ß√£o de vari√°veis.
>   3. **Regulariza√ß√£o L2:** Todos os coeficientes s√£o reduzidos em magnitude, mas nenhum √© zero.
>
> Este exemplo demonstra como a regulariza√ß√£o L1 pode realizar sele√ß√£o de vari√°veis, enquanto a regulariza√ß√£o L2 reduz a magnitude dos coeficientes, prevenindo overfitting.
>
> | M√©todo         | Coeficiente 1 | Coeficiente 2 | Coeficiente 3 |
> |----------------|---------------|---------------|---------------|
> | Sem Regulariza√ß√£o | 1.566         | -0.812        | 0.041         |
> | Regulariza√ß√£o L1| 0.997         | -0.184        | 0.0           |
> | Regulariza√ß√£o L2| 1.221         | -0.566        | -0.011        |

### Separating Hyperplanes e Perceptrons
A ideia de **Separating Hyperplanes** √© encontrar um hiperplano que maximize a margem de separa√ß√£o entre as classes em um problema de classifica√ß√£o. O hiperplano √≥timo √© aquele que maximiza a dist√¢ncia (margem) entre as classes mais pr√≥ximas e √© definido pelos **support vectors**, que s√£o os pontos de dados mais pr√≥ximos do hiperplano [^4.5.2]. A formula√ß√£o do problema de otimiza√ß√£o para encontrar o hiperplano √≥timo pode ser resolvida utilizando o dual de Wolfe [^4.5.2].

O **Perceptron** √© um algoritmo de aprendizado para modelos de classifica√ß√£o linear que ajusta os pesos dos preditores iterativamente at√© que os dados de treinamento sejam corretamente classificados, desde que eles sejam linearmente separ√°veis [^4.5.1]. O algoritmo ajusta os pesos a cada itera√ß√£o, aplicando a seguinte regra de atualiza√ß√£o:
$$w_{t+1} = w_t + \eta (y_i - \hat{y}_i) x_i$$
onde $w$ √© o vetor de pesos, $x_i$ s√£o os dados de entrada, $y_i$ √© a sa√≠da esperada, $\hat{y}_i$ √© a sa√≠da predita e $\eta$ √© a taxa de aprendizado. Em situa√ß√µes em que os dados n√£o s√£o linearmente separ√°veis, o Perceptron pode n√£o convergir e oscilar indefinidamente [^4.5.1].

```mermaid
graph LR
    subgraph "Perceptron Algorithm"
      direction TB
      A["Initialization: w_0, Œ∑"]
      B["For each training point x_i"]
      C["Compute predicted class: yÃÇ_i = sign(w_t·µÄx_i)"]
      D["Update weights: w_{t+1} = w_t + Œ∑(y_i - yÃÇ_i)x_i"]
      E["Repeat until convergence or max iterations"]
      A --> B
      B --> C
      C --> D
      D --> E
     end
```

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com 2 preditores.
>
> 1.  **Dados:** Suponha que os dados de treinamento sejam:
>
>     Classe 1: $x_1 = [1, 2], x_2 = [2, 1]$ (label = 1)
>
>     Classe 2: $x_3 = [3, 4], x_4 = [4, 3]$ (label = -1)
>
> 2.  **Inicializa√ß√£o:** Inicialize os