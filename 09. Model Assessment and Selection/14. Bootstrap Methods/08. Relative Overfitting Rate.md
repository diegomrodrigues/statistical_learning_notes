## Model Assessment and Selection: Focusing on Relative Overfitting Rate

```mermaid
graph LR
  subgraph "Model Assessment and Selection"
    A["Data"] --> B["Model Training"]
    B --> C{"Evaluate Model Performance"}
    C --> D["Calculate R"]
    D --> E{"Assess Overfitting"}
    E --> F{"Model Selection"}
    F --> G["Robust Model"]
  end
```

### Introdu√ß√£o

A avalia√ß√£o e sele√ß√£o de modelos s√£o etapas cruciais no desenvolvimento de modelos de aprendizado estat√≠stico. A capacidade de um modelo generalizar para dados n√£o vistos √© fundamental para seu sucesso pr√°tico [^7.1]. Este cap√≠tulo explora as metodologias para avalia√ß√£o de desempenho de modelos, com um foco especial na **Relative Overfitting Rate (R)** como um indicador chave na identifica√ß√£o de overfitting e sele√ß√£o de modelos robustos. Atrav√©s de um estudo aprofundado de conceitos como **Bias-Variance Decomposition**, **Cross-Validation**, **Bootstrap**, **AIC**, **BIC** e **MDL**, procuramos oferecer um guia avan√ßado para profissionais de estat√≠stica e aprendizado de m√°quina. A aten√ß√£o principal ser√° na utiliza√ß√£o de R como uma m√©trica para avaliar a qualidade dos modelos.

### Conceitos Fundamentais

**Conceito 1: Generaliza√ß√£o e Overfitting**
O desempenho de generaliza√ß√£o de um m√©todo de aprendizado refere-se √† sua capacidade de prever com precis√£o em dados de teste independentes [^7.1]. Um modelo que performa bem nos dados de treinamento, mas mal em dados n√£o vistos, √© considerado **overfit**. A capacidade de discernir entre esses cen√°rios √© essencial para a constru√ß√£o de modelos robustos e eficazes [^7.2]. Modelos complexos tendem a se ajustar aos ru√≠dos nos dados de treinamento, levando a baixa generaliza√ß√£o e alto overfitting.

**Lemma 1:** A rela√ß√£o entre vi√©s e vari√¢ncia est√° intrinsecamente ligada ao conceito de overfitting. Modelos complexos tendem a ter baixo vi√©s (melhor ajuste aos dados de treinamento) mas alta vari√¢ncia (alta sensibilidade a pequenas mudan√ßas nos dados de treinamento), o que leva ao overfitting [^7.2].

*Prova:*
$$Err(x_0) = \sigma^2 + Bias^2(f(x_0)) + Var(f(x_0))$$
Onde $Err(x_0)$ √© o erro esperado de predi√ß√£o em um ponto $x_0$, $\sigma^2$ √© a vari√¢ncia do ru√≠do, $Bias^2(f(x_0))$ √© o vi√©s ao quadrado e $Var(f(x_0))$ √© a vari√¢ncia do modelo. Modelos complexos diminuem o vi√©s, mas aumentam a vari√¢ncia, levando a overfitting. $\blacksquare$
> üí° **Exemplo Num√©rico:**
> Suponha que temos um dataset com 100 pontos, e queremos ajustar um modelo de regress√£o. Para um modelo linear simples, temos um vi√©s maior (ele n√£o consegue capturar a curvatura nos dados), mas a vari√¢ncia √© baixa (pequenas mudan√ßas nos dados n√£o mudam muito o modelo). Para um modelo polinomial de grau 10, o vi√©s √© muito baixo (ele ajusta muito bem aos dados de treino), mas a vari√¢ncia √© alta (pequenas mudan√ßas nos dados alteram muito o modelo). Vamos analisar o erro em um ponto espec√≠fico ($x_0$).
> - Para o modelo linear: $Bias^2(f(x_0)) = 0.5$, $Var(f(x_0)) = 0.1$, $\sigma^2 = 0.2$. Ent√£o, $Err(x_0) = 0.2 + 0.5 + 0.1 = 0.8$.
> - Para o modelo polinomial: $Bias^2(f(x_0)) = 0.05$, $Var(f(x_0)) = 0.9$, $\sigma^2 = 0.2$. Ent√£o, $Err(x_0) = 0.2 + 0.05 + 0.9 = 1.15$.
>
> Nesse caso, embora o modelo polinomial tenha um vi√©s menor, sua alta vari√¢ncia resulta em um erro total maior em compara√ß√£o com o modelo linear mais simples, ilustrando a necessidade de equilibrar vi√©s e vari√¢ncia.

**Conceito 2: Bias-Variance Decomposition e a Complexidade do Modelo**
A **Bias-Variance Decomposition** √© uma ferramenta chave para entender o comportamento do erro de predi√ß√£o [^7.3]. O erro total pode ser decomposto em tr√™s componentes: um erro irredut√≠vel (vari√¢ncia do ru√≠do), vi√©s ao quadrado e vari√¢ncia do modelo [^7.3]. √Ä medida que a complexidade do modelo aumenta, o vi√©s geralmente diminui, mas a vari√¢ncia tende a aumentar [^7.3.1]. A escolha da complexidade ideal √© um compromisso entre esses dois fatores, com o objetivo de minimizar o erro total de predi√ß√£o.

```mermaid
graph LR
    subgraph "Bias-Variance Decomposition"
      direction TB
        A["Total Error: E[ (y - fÃÇ(x))¬≤ ]"]
        B["Irreducible Error: œÉ¬≤"]
        C["Bias¬≤: (E[fÃÇ(x)] - f(x))¬≤"]
        D["Variance: E[ (fÃÇ(x) - E[fÃÇ(x)])¬≤ ]"]
        A --> B
        A --> C
        A --> D
    end
```

**Corol√°rio 1:**  Em problemas de classifica√ß√£o, o erro de predi√ß√£o n√£o √© mais uma simples soma de vi√©s ao quadrado e vari√¢ncia. A intera√ß√£o entre vi√©s e vari√¢ncia determina a taxa de erro, e a minimiza√ß√£o do erro de predi√ß√£o n√£o corresponde √† minimiza√ß√£o da soma de vi√©s ao quadrado e vari√¢ncia [^7.3.1]. Em modelos de classifica√ß√£o, pode haver cen√°rios onde o aumento do vi√©s n√£o necessariamente aumenta o erro de predi√ß√£o se a estimativa ainda estiver do lado correto da fronteira de decis√£o.
> üí° **Exemplo Num√©rico:**
> Em um problema de classifica√ß√£o bin√°ria, vamos comparar dois modelos: um modelo linear simples e uma rede neural profunda. O modelo linear pode ter um vi√©s maior, pois ele n√£o consegue capturar fronteiras de decis√£o complexas, mas a vari√¢ncia √© baixa, uma vez que ele √© pouco sens√≠vel aos dados de treinamento. A rede neural pode se ajustar muito bem aos dados de treinamento (baixo vi√©s), mas pequenas mudan√ßas nos dados de treinamento podem gerar uma fronteira de decis√£o muito diferente (alta vari√¢ncia).
>
> Suponha que ap√≥s o treinamento, o modelo linear cometa erros em 15% dos pontos no teste, e a rede neural em 10%. Contudo, ao realizar um bootstrap, vemos que o modelo linear apresenta uma varia√ß√£o de 2% nos erros e a rede neural 15%, indicando que a rede neural overfitta, mesmo apresentando um erro menor inicialmente. Nesse contexto, o modelo linear, apesar do vi√©s maior, apresenta uma melhor capacidade de generaliza√ß√£o. O c√°lculo do R pode auxiliar na identifica√ß√£o deste overfitting da rede neural.

**Conceito 3: Relative Overfitting Rate (R)**
A m√©trica **Relative Overfitting Rate (R)**, introduzida no contexto de m√©todos de bootstrap [^7.11], quantifica a extens√£o do overfitting. R compara a diferen√ßa entre a estimativa de erro no bootstrap leave-one-out e o erro de treinamento com a diferen√ßa entre a taxa de erro sem informa√ß√£o ( $\gamma$ ) e o erro de treinamento [^7.11]. Uma taxa de overfitting alta indica que o modelo est√° se ajustando em demasia aos dados de treinamento, e o modelo n√£o generalizar√° bem para dados n√£o vistos.

```mermaid
graph LR
    subgraph "Relative Overfitting Rate (R)"
      direction TB
        A["R = (Err_boot - Err_train) / (Œ≥ - Err_train)"]
        B["Err_boot: Bootstrap Error"]
        C["Err_train: Training Error"]
        D["Œ≥: No Information Error Rate"]
        A --> B
        A --> C
        A --> D
    end
```

> ‚ö†Ô∏è **Nota Importante**: A m√©trica R √© particularmente √∫til para avaliar a robustez de modelos em diferentes cen√°rios, especialmente quando se utilizam m√©todos como o bootstrap para estimar o erro de generaliza√ß√£o. **Refer√™ncia ao t√≥pico [^7.11]**.
> ‚ùó **Ponto de Aten√ß√£o**: Em modelos de classifica√ß√£o, onde as decis√µes s√£o bin√°rias ou multiclasse, R auxilia na identifica√ß√£o de overfitting, avaliando o quanto o modelo se ajusta aos dados de treinamento e se a capacidade de generaliza√ß√£o est√° comprometida. **Conforme indicado em [^7.11]**.
> ‚úîÔ∏è **Destaque**: O uso de R √© mais adequado em situa√ß√µes onde o modelo precisa ter uma boa capacidade de generaliza√ß√£o, sendo uma m√©trica fundamental para compara√ß√£o de modelos em situa√ß√µes complexas. **Baseado nos t√≥picos [^7.11]**.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
  subgraph "Linear Regression for Classification"
    A["Input Data"] --> B["Fit Linear Model using Least Squares"]
    B --> C["Calculate Training Error"]
    C --> D["Estimate Bias and Variance"]
    D --> E["Compute Relative Overfitting Rate (R)"]
    E --> F["Evaluate Generalization"]
  end
```

**Explica√ß√£o:** Este diagrama representa o fluxo de trabalho utilizando a regress√£o para classifica√ß√£o e a avalia√ß√£o utilizando a m√©trica R.

A regress√£o linear pode ser aplicada a problemas de classifica√ß√£o atrav√©s da regress√£o de uma **matriz de indicadores**, em que cada coluna representa uma classe. Essa abordagem, embora simples, pode sofrer de limita√ß√µes significativas [^7.2]. O **erro de treinamento** diminui √† medida que a complexidade do modelo aumenta, mas o modelo pode se tornar superajustado, resultando em baixa capacidade de generaliza√ß√£o. A estima√ß√£o do erro de generaliza√ß√£o utilizando a **Relative Overfitting Rate (R)** √© crucial para evitar modelos com overfitting.
A regress√£o linear minimiza a soma dos erros quadrados, que pode ser escrita da seguinte forma:

$$L(Y, f(X)) = \frac{1}{N} \sum_{i=1}^{N} (Y_i - f(X_i))^2$$

O vi√©s e a vari√¢ncia podem ser calculados como:

$$Err(x_0) = \sigma^2 + [Ef(x_0) - f(x_0)]^2 + E[f(x_0) - Ef(x_0)]^2$$

$$Err(x_0) = \sigma^2 + Bias^2(f(x_0)) + Var(f(x_0))$$
Onde:
*   $\sigma^2$ √© o erro irredut√≠vel
*   $Bias^2(f(x_0))$ √© o vi√©s ao quadrado
*   $Var(f(x_0))$ √© a vari√¢ncia

Em situa√ß√µes pr√°ticas, modelos overfit apresentam alto R. O modelo pode ter um vi√©s baixo e alta vari√¢ncia, levando a problemas de generaliza√ß√£o. A utiliza√ß√£o de regulariza√ß√£o pode reduzir a vari√¢ncia e melhorar a capacidade de generaliza√ß√£o do modelo.
> üí° **Exemplo Num√©rico:**
> Vamos usar um conjunto de dados de classifica√ß√£o bin√°ria com 100 amostras, onde a vari√°vel alvo √© representada como 0 ou 1. Ajustamos um modelo de regress√£o linear para prever essa vari√°vel usando 5 features. Ap√≥s o treinamento, calculamos o erro quadr√°tico m√©dio (MSE) no conjunto de treinamento e obtemos 0.15. Para estimar o erro de generaliza√ß√£o, usamos o bootstrap leave-one-out e obtemos um MSE de 0.30. Al√©m disso, calculamos a taxa de erro sem informa√ß√£o $\gamma$ como 0.5 (a pior poss√≠vel).
>
> Calculamos a Relative Overfitting Rate (R) da seguinte maneira:
> $$ R = \frac{Err_{boot} - Err_{treino}}{\gamma - Err_{treino}} = \frac{0.30 - 0.15}{0.5 - 0.15} = \frac{0.15}{0.35} \approx 0.43 $$
>
> Este valor de R=0.43 indica um overfitting significativo do modelo de regress√£o linear, pois o erro de generaliza√ß√£o √© substancialmente maior do que o erro de treinamento.
>
>  Agora vamos considerar um modelo de regress√£o linear com regulariza√ß√£o. Ap√≥s o treinamento, o erro de treinamento √© de 0.20, o erro de bootstrap √© de 0.25 e o erro sem informa√ß√£o √© 0.5. Calculamos R:
> $$ R = \frac{0.25 - 0.20}{0.5 - 0.20} = \frac{0.05}{0.3} \approx 0.167 $$
> Um valor de R menor indica que o modelo regularizado √© menos propenso a overfitting.

**Lemma 2:**  Sob condi√ß√µes de baixa complexidade do modelo e amostras bem representativas da popula√ß√£o, a diferen√ßa entre os erros de treinamento e teste, expressos atrav√©s de R, tende a ser baixa, indicando uma menor probabilidade de overfitting. Isso ocorre porque o modelo √© menos suscet√≠vel a se ajustar aos ru√≠dos nos dados de treinamento, e por consequ√™ncia generalizando melhor para dados n√£o vistos [^7.2].

*Prova:*
Em um cen√°rio ideal, o erro de treinamento √© similar ao erro de generaliza√ß√£o.
$$Err_{treino} \approx Err_{teste}$$
Consequentemente o R √© dado por:
$$ R = \frac{Err_{teste}- Err_{treino}}{no \ info \  erro - Err_{treino}} $$
Se $Err_{treino} \approx Err_{teste}$ ent√£o R tende a 0, indicando pouco ou nenhum overfitting. $\blacksquare$

**Corol√°rio 2:** Em cen√°rios de alta complexidade do modelo, R aumenta significativamente, indicando overfitting. Isso demonstra a necessidade de uma sele√ß√£o de modelos e avalia√ß√£o de desempenho bem estabelecidas utilizando a m√©trica R [^7.2].
> üí° **Exemplo Num√©rico:**
> Vamos usar o mesmo conjunto de dados de classifica√ß√£o bin√°ria, por√©m agora vamos ajustar um modelo polinomial de grau 10.  O modelo se ajusta muito bem aos dados de treinamento, com um erro de treinamento de 0.05, mas apresenta um erro de bootstrap de 0.4. A taxa de erro sem informa√ß√£o √© mantida em 0.5. Calculando R:
> $$ R = \frac{0.4 - 0.05}{0.5 - 0.05} = \frac{0.35}{0.45} \approx 0.78 $$
>  O alto valor de R indica que o modelo polinomial de grau 10 est√° sofrendo um overfitting severo. Isso demonstra a import√¢ncia da m√©trica R na identifica√ß√£o de modelos complexos que n√£o generalizam bem para dados n√£o vistos.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas importantes para controlar a complexidade do modelo e evitar o overfitting [^7.3]. M√©todos como **penaliza√ß√£o L1 (Lasso)** e **L2 (Ridge)** podem ser usados em modelos log√≠sticos para controlar a esparsidade dos coeficientes e a estabilidade do modelo. A ado√ß√£o de penaliza√ß√µes L1 e L2 em modelos log√≠sticos introduz um termo de penalidade na fun√ß√£o de custo, que √© minimizada durante o treinamento do modelo, conforme discutido em [^7.5].

```mermaid
graph LR
    subgraph "Regularization Techniques"
      direction LR
        A["Loss Function"] --> B["Original Loss"]
        A --> C["Regularization Term"]
        C --> D{"L1 Penalty: Œª||Œ≤||‚ÇÅ"}
        C --> E{"L2 Penalty: Œª||Œ≤||‚ÇÇ¬≤"}
    B --> F["Optimization"]
        D --> F
    E --> F
    end
```

**Lemma 3:**  A penaliza√ß√£o L1 (Lasso) leva a modelos esparsos ao for√ßar alguns coeficientes a serem exatamente zero, simplificando o modelo e diminuindo sua capacidade de overfitting, o que √© refletido em um baixo valor de R [^7.4.4].

*Prova:*
A penaliza√ß√£o L1 adiciona um termo proporcional ao valor absoluto dos coeficientes na fun√ß√£o de custo:
$$L(Œ≤) = - \sum_i (y_i \log(p_i) + (1 - y_i)\log(1-p_i)) + \lambda \sum_j |\beta_j|$$
onde $\lambda$ √© o par√¢metro de regulariza√ß√£o. Para valores altos de $\lambda$, muitos coeficientes $\beta$ tendem a zero, levando a um modelo esparso. A esparsidade reduz o overfitting.  $\blacksquare$
> üí° **Exemplo Num√©rico:**
> Vamos usar um problema de classifica√ß√£o com 20 features. Primeiro, treinamos um modelo de regress√£o log√≠stica sem regulariza√ß√£o, obtendo um erro de treinamento de 0.12 e um erro de bootstrap de 0.35. Calculamos R, assumindo $\gamma = 0.5$:
> $$R = \frac{0.35 - 0.12}{0.5 - 0.12} = \frac{0.23}{0.38} \approx 0.605$$
>
> Agora aplicamos a regulariza√ß√£o L1 (Lasso). Com $\lambda$=0.1, o modelo tem um erro de treinamento de 0.15 e um erro de bootstrap de 0.20. Calculando R:
> $$R = \frac{0.20 - 0.15}{0.5 - 0.15} = \frac{0.05}{0.35} \approx 0.143$$
>
> Com um $\lambda$ maior, $\lambda$=0.5, o erro de treinamento √© 0.18 e o erro de bootstrap 0.21.
> $$R = \frac{0.21 - 0.18}{0.5 - 0.18} = \frac{0.03}{0.32} \approx 0.093$$
>
> A redu√ß√£o de R com a regulariza√ß√£o L1 indica que o modelo se tornou menos propenso ao overfitting. A regulariza√ß√£o L1 auxilia na sele√ß√£o de features e reduz a complexidade do modelo.

**Corol√°rio 3:** A combina√ß√£o de penaliza√ß√µes L1 e L2, conhecida como **Elastic Net**, pode ser vantajosa ao aproveitar a capacidade de L1 de realizar sele√ß√£o de vari√°veis e a estabilidade de L2, oferecendo uma melhor combina√ß√£o entre esparsidade e generaliza√ß√£o. Essa abordagem tamb√©m auxilia a melhorar o desempenho em rela√ß√£o ao R [^7.5].
> üí° **Exemplo Num√©rico:**
> Vamos usar o mesmo conjunto de dados e modelo de regress√£o log√≠stica.  Aplicamos a regulariza√ß√£o Elastic Net com $\lambda_1$=0.1 e $\lambda_2$=0.1. Ap√≥s o treinamento, o erro de treinamento √© 0.16 e o erro de bootstrap √© 0.22. Calculando R:
>
>  $$R = \frac{0.22 - 0.16}{0.5 - 0.16} = \frac{0.06}{0.34} \approx 0.176$$
>  A compara√ß√£o com os valores de R obtidos para o modelo sem regulariza√ß√£o e com L1 e L2 mostra que o Elastic Net fornece uma boa combina√ß√£o entre vi√©s e vari√¢ncia.
> | Method | Train Error | Bootstrap Error | R |
> |--------|-------------|-----------------|----|
> | No Regularization | 0.12          | 0.35           | 0.605 |
> | Lasso (L1) Œª=0.1  | 0.15          | 0.20           | 0.143 |
> | Lasso (L1) Œª=0.5  | 0.18          | 0.21           | 0.093 |
> | Elastic Net       | 0.16          | 0.22           | 0.176 |

> O m√©todo Elastic Net obteve um R menor que o modelo sem regulariza√ß√£o. √â importante notar que a escolha dos par√¢metros de regulariza√ß√£o (Œª1 e Œª2) impacta diretamente no valor de R e na capacidade de generaliza√ß√£o do modelo.

> ‚ö†Ô∏è **Ponto Crucial**: A escolha do par√¢metro de regulariza√ß√£o √© fundamental. A valida√ß√£o cruzada pode ser utilizada para determinar o valor √≥timo que minimize o erro de generaliza√ß√£o e o R, equilibrando vi√©s e vari√¢ncia [^7.5].
### Separating Hyperplanes e Perceptrons
A ideia de maximizar a margem de separa√ß√£o entre as classes leva ao conceito de **hiperplanos √≥timos**, formulando um problema de otimiza√ß√£o que pode ser resolvido utilizando a teoria do dual de Wolfe [^7.5.2]. As solu√ß√µes emergem como combina√ß√µes lineares dos pontos de suporte. O **Perceptron de Rosenblatt** √© um algoritmo que busca iterativamente um hiperplano que separe as classes e, sob condi√ß√µes de linear separabilidade, garante a converg√™ncia [^7.5.1].

### Pergunta Te√≥rica Avan√ßada: Qual a rela√ß√£o entre Relative Overfitting Rate (R) e a escolha do melhor modelo?

**Resposta:**
R auxilia na escolha do melhor modelo ao quantificar o n√≠vel de overfitting. Modelos com alto R indicam que a capacidade de generaliza√ß√£o foi comprometida devido ao overfitting nos dados de treinamento, assim esses modelos devem ser descartados. Um modelo com baixo R indica um equil√≠brio adequado entre vi√©s e vari√¢ncia, possuindo uma capacidade de generaliza√ß√£o adequada. Modelos com valores baixos de R s√£o prefer√≠veis, indicando uma maior probabilidade de um modelo generalizar bem em dados n√£o vistos.
**Lemma 4:**  A rela√ß√£o entre R e as curvas de aprendizado pode ser ilustrada da seguinte forma. Em amostras de treino de baixa cardinalidade, o valor de R tende a ser maior, pois o modelo se ajusta aos dados de treino, o que reduz a capacidade de generaliza√ß√£o, j√° em amostras de treino de alta cardinalidade, o valor de R tende a diminuir, indicando uma redu√ß√£o do overfitting [^7.2].
> üí° **Exemplo Num√©rico:**
> Consideremos um problema de classifica√ß√£o. Inicialmente, treinamos um modelo com apenas 20 amostras e obtemos um R=0.7. √Ä medida que aumentamos o n√∫mero de amostras para 100, o valor de R cai para 0.3, e ao atingir 1000 amostras, o R cai para 0.1. O decr√©scimo em R demonstra que a adi√ß√£o de mais amostras auxilia o modelo a generalizar melhor e reduz a probabilidade de overfitting.
> ```mermaid
>  graph LR
>      A["20 Samples"] -->|R=0.7| B["Trained Model"]
>      B --> |R=0.3|C["100 Samples"]
>       C --> |R=0.1|D["1000 Samples"]
>  ```
```mermaid
graph LR
    subgraph "R vs Training Set Size"
        direction LR
        A["Small Training Set"] --> B["High R"]
        C["Large Training Set"] --> D["Low R"]
         B --> E{"Overfitting"}
        D --> F{"Good Generalization"}
        E & F
    end
```
**Corol√°rio 4:** A escolha de um modelo com menor R n√£o necessariamente garante o modelo com melhor desempenho, o R auxilia na identifica√ß√£o e compara√ß√£o de modelos overfit, juntamente com outros m√©todos como a valida√ß√£o cruzada [^7.10] e o bootstrap [^7.11].

> ‚ö†Ô∏è **Ponto Crucial**: A Relative Overfitting Rate (R) √© uma ferramenta poderosa para auxiliar na identifica√ß√£o de modelos com overfitting, entretanto n√£o deve ser usada como m√©trica √∫nica para escolha do melhor modelo [^7.12].

### Conclus√£o

A avalia√ß√£o e sele√ß√£o de modelos s√£o partes fundamentais do processo de modelagem. A compreens√£o dos conceitos de vi√©s e vari√¢ncia, juntamente com o uso de m√©todos como valida√ß√£o cruzada, bootstrap e m√©tricas como R, s√£o cruciais para a constru√ß√£o de modelos robustos e eficazes. A Relative Overfitting Rate (R) oferece uma m√©trica intuitiva para avaliar o quanto um modelo est√° sobreajustado aos dados de treinamento e pode ser usada em conjunto com outros crit√©rios para selecionar modelos que melhor generalizam em dados n√£o vistos.
<!-- END DOCUMENT -->
### Footnotes

[^7.1]: "The generalization performance of a learning method relates to its prediction capability on independent test data. Assessment of this performance is extremely important in practice, since it guides the choice of learning method or model, and gives us a measure of the quality of the ultimately chosen model." *(Trecho de "The Elements of Statistical Learning")*
[^7.2]: "Figure 7.1 illustrates the important issue in assessing the ability of a learning method to generalize." *(Trecho de "The Elements of Statistical Learning")*
[^7.3]: "As in Chapter 2, if we assume that Y = f(X) + Œµ where E(Œµ) = 0 and Var(Œµ) = œÉ¬≤, we can derive an expression for the expected prediction error of a regression fit f(X) at an input point X = x0, using squared-error loss:" *(Trecho de "The Elements of Statistical Learning")*
[^7.3.1]: "For the k-nearest-neighbor regression fit, these expressions have the simple form" *(Trecho de "The Elements of Statistical Learning")*
[^7.4.4]: "For a linear model family such as ridge regression, we can break down the bias more finely." *(Trecho de "The Elements of Statistical Learning")*
[^7.5]: "The methods of this chapter approximate the validation step either analytically (AIC, BIC, MDL, SRM) or by efficient sample re-use (cross-validation and the bootstrap)." *(Trecho de "The Elements of Statistical Learning")*
[^7.5.1]: "Before jumping into these topics, we first explore in more detail the nature of test error and the bias-variance tradeoff." *(Trecho de "The Elements of Statistical Learning")*
[^7.5.2]: "As in Chapter 2, if we assume that Y = f(X) + Œµ where E(Œµ) = 0 and Var(Œµ) = œÉ¬≤, we can derive an expression for the expected prediction error of a regression fit f(X) at an input point X = x0, using squared-error loss:" *(Trecho de "The Elements of Statistical Learning")*
[^7.10]: "Probably the simplest and most widely used method for estimating prediction error is cross-validation." *(Trecho de "The Elements of Statistical Learning")*
[^7.11]: "The bootstrap is a general tool for assessing statistical accuracy." *(Trecho de "The Elements of Statistical Learning")*
[^7.12]: "Figures 7.14 and 7.15 examine the question of whether cross-validation does a good job in estimating Errt, the error conditional on a given training set T (expression (7.15) on page 228), as opposed to the expected test error." *(Trecho de "The Elements of Statistical Learning")*
