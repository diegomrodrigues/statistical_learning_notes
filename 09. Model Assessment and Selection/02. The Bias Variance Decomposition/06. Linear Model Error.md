## Avalia√ß√£o e Sele√ß√£o de Modelos Lineares: Vi√©s, Vari√¢ncia e Complexidade

```mermaid
graph LR
    subgraph "Error Decomposition"
        direction TB
        A["Total Error: Err(x_0)"]
        B["Irreducible Error: $\sigma^2$"]
        C["Bias¬≤: Bias¬≤(f(x_0))"]
        D["Variance: Var(f(x_0))"]
        A --> B
        A --> C
        A --> D
     end
```

### Introdu√ß√£o

A avalia√ß√£o da performance de um modelo de aprendizado est√° intrinsecamente ligada √† sua capacidade de generaliza√ß√£o, ou seja, de fazer previs√µes precisas em dados que n√£o foram usados no treinamento. Esta capacidade √© crucial na pr√°tica, pois orienta a escolha do m√©todo de aprendizado ou modelo apropriado, al√©m de quantificar a qualidade do modelo selecionado [^7.1]. Este cap√≠tulo aborda os principais m√©todos para avaliar essa performance e como eles podem ser aplicados para selecionar os modelos mais adequados. Iniciamos com uma an√°lise da intera√ß√£o entre vi√©s, vari√¢ncia e complexidade do modelo [^7.1].

### Conceitos Fundamentais

**Conceito 1: Erro de Generaliza√ß√£o e a Decomposi√ß√£o do Erro**

O **erro de generaliza√ß√£o**, ou **test error**, √© a m√©trica que quantifica a capacidade de um modelo de aprendizado em prever com precis√£o dados independentes que n√£o foram utilizados no processo de treinamento. Em termos matem√°ticos, dado um modelo $f(X)$ treinado em um conjunto de dados de treinamento $T$, o erro de generaliza√ß√£o pode ser definido como:

$$
Err_T = E[L(Y, f(X))|T]
$$

onde $L(Y, f(X))$ √© a fun√ß√£o de perda que quantifica a diferen√ßa entre o valor verdadeiro $Y$ e a predi√ß√£o do modelo $f(X)$ e a esperan√ßa √© tomada sobre a distribui√ß√£o conjunta da popula√ß√£o [^7.2].

O erro de generaliza√ß√£o pode ser decomposto em tr√™s componentes: **vi√©s**, **vari√¢ncia** e **ru√≠do irredut√≠vel**, um conceito crucial para entender o compromisso entre complexidade do modelo e generaliza√ß√£o [^7.3].  O ru√≠do irredut√≠vel $\sigma^2$ √© a vari√¢ncia do target $Y$ em torno de sua m√©dia verdadeira $f(X)$ e n√£o pode ser reduzido por nenhum modelo, a menos que $\sigma^2=0$. O vi√©s $Bias(f(X))$ √© a diferen√ßa entre a m√©dia das predi√ß√µes do modelo e o valor verdadeiro do target, enquanto a vari√¢ncia $Var(f(X))$ √© a variabilidade das predi√ß√µes do modelo em torno de sua m√©dia. Matematicamente, essa decomposi√ß√£o √© expressa por [^7.3]:

$$
Err(x_0) = \sigma^2 + Bias^2(f(x_0)) + Var(f(x_0))
$$

onde $x_0$ representa um ponto de input. O objetivo √© minimizar $Err(x_0)$, mas a minimiza√ß√£o do vi√©s geralmente leva a um aumento da vari√¢ncia e vice-versa.

> üí° **Exemplo Num√©rico:** Imagine que estamos tentando prever o pre√ßo de casas ($Y$) com base em seu tamanho ($X$). Suponha que a rela√ß√£o verdadeira seja $Y = 2X + 5 + \epsilon$, onde $\epsilon$ √© um ru√≠do aleat√≥rio com $\sigma^2 = 1$. Se usarmos um modelo muito simples, como $f(X) = X + 2$, teremos um vi√©s alto. Se usarmos um modelo muito complexo, como um polin√¥mio de grau 10, o modelo pode se ajustar perfeitamente aos dados de treinamento (baixo vi√©s), mas ter√° alta vari√¢ncia, ou seja, pequenas varia√ß√µes nos dados de treinamento levar√£o a grandes varia√ß√µes nas predi√ß√µes.
>
> Para quantificar, vamos simular um conjunto de dados:
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression
> from sklearn.preprocessing import PolynomialFeatures
> from sklearn.metrics import mean_squared_error
>
> np.random.seed(42)
> X = np.sort(5 * np.random.rand(50, 1), axis=0)
> y_true = 2 * X.flatten() + 5
> y = y_true + np.random.normal(0, 1, 50) # Adding noise
>
> # Simple Model
> model_simple = LinearRegression()
> model_simple.fit(X, y)
> y_pred_simple = model_simple.predict(X)
>
> # Complex Model (Polynomial Regression)
> poly = PolynomialFeatures(degree=10)
> X_poly = poly.fit_transform(X)
> model_complex = LinearRegression()
> model_complex.fit(X_poly, y)
> y_pred_complex = model_complex.predict(X_poly)
>
> # Calculating bias and variance (approximated via repeated sampling)
> n_simulations = 100
> y_preds_simple = np.zeros((n_simulations, len(X)))
> y_preds_complex = np.zeros((n_simulations, len(X)))
>
> for i in range(n_simulations):
>   X_sample = np.sort(5 * np.random.rand(50, 1), axis=0)
>   y_sample = 2 * X_sample.flatten() + 5 + np.random.normal(0, 1, 50)
>   model_simple.fit(X_sample, y_sample)
>   y_preds_simple[i] = model_simple.predict(X_sample)
>
>   X_poly_sample = poly.fit_transform(X_sample)
>   model_complex.fit(X_poly_sample, y_sample)
>   y_preds_complex[i] = model_complex.predict(X_poly_sample)
>
>
> mean_y_pred_simple = np.mean(y_preds_simple, axis=0)
> mean_y_pred_complex = np.mean(y_preds_complex, axis=0)
>
> bias_simple = np.mean((y_true - mean_y_pred_simple)**2)
> bias_complex = np.mean((y_true - mean_y_pred_complex)**2)
>
> var_simple = np.mean(np.var(y_preds_simple, axis=0))
> var_complex = np.mean(np.var(y_preds_complex, axis=0))
>
> print(f"Simple Model Bias^2: {bias_simple:.2f}")
> print(f"Simple Model Variance: {var_simple:.2f}")
> print(f"Complex Model Bias^2: {bias_complex:.2f}")
> print(f"Complex Model Variance: {var_complex:.2f}")
>
> plt.figure(figsize=(10, 6))
> plt.scatter(X, y, color='blue', label='Dados reais')
> plt.plot(X, y_true, color='black', linestyle='-', linewidth=2, label='Fun√ß√£o verdadeira')
> plt.plot(X, y_pred_simple, color='red', label='Modelo Simples')
> plt.plot(X, y_pred_complex, color='green', label='Modelo Complexo')
>
> plt.xlabel('Tamanho da casa (X)')
> plt.ylabel('Pre√ßo da casa (Y)')
> plt.title('Vi√©s e Vari√¢ncia')
> plt.legend()
> plt.show()
> ```
> Os resultados mostrar√£o que o modelo simples tem um vi√©s maior (as predi√ß√µes est√£o sistematicamente erradas), mas menor vari√¢ncia (as predi√ß√µes s√£o mais est√°veis entre diferentes amostras de treinamento), enquanto o modelo complexo tem um vi√©s menor (as predi√ß√µes se aproximam da fun√ß√£o real), mas uma vari√¢ncia muito maior. Este exemplo demonstra o trade-off entre vi√©s e vari√¢ncia na pr√°tica.

> ‚ö†Ô∏è **Nota Importante**: A complexidade do modelo √© um fator determinante na magnitude do vi√©s e da vari√¢ncia. Modelos com alta complexidade tendem a ter baixo vi√©s, mas alta vari√¢ncia, enquanto modelos com baixa complexidade tendem a ter alto vi√©s, mas baixa vari√¢ncia. √â fundamental encontrar um equil√≠brio entre esses componentes para obter um bom desempenho de generaliza√ß√£o [^7.2], [^7.3].

**Lemma 1: Decomposi√ß√£o da Esperan√ßa do Erro Quadr√°tico**

Seja um modelo linear $f(X)=X\beta$, onde $X$ √© a matriz de features e $\beta$ √© o vetor de par√¢metros. Ao utilizar o erro quadr√°tico m√©dio como fun√ß√£o de perda, temos que:

$$
Err(X) = E[(Y-f(X))^2|X]
$$

Assumindo que $Y=f(X)+\epsilon$, com $E[\epsilon]=0$ e $Var(\epsilon)=\sigma^2$, a express√£o do erro pode ser decomposta da seguinte forma:
$$
Err(X) = E[(f(X)+\epsilon - X\beta)^2|X] = E[\epsilon^2|X] + E[(f(X)-X\beta)^2|X]
$$

```mermaid
graph LR
  subgraph "MSE Decomposition"
    direction TB
    A["Err(X) = E[(Y - XŒ≤)¬≤|X]"]
    B["Err(X) = E[Œµ¬≤|X] + E[(f(X) - XŒ≤)¬≤|X]"]
    C["Err(X) = $\sigma^2$ + E[(f(X) - E[XŒ≤|X] + E[XŒ≤|X] - XŒ≤)¬≤|X]"]
    D["Err(X) = $\sigma^2$ + (f(X) - E[XŒ≤|X])¬≤ + E[(E[XŒ≤|X] - XŒ≤)¬≤|X]"]
    A --> B
    B --> C
    C --> D
  end
```

$$
Err(X) = \sigma^2 + E[(f(X)-E[X\beta|X]+E[X\beta|X]-X\beta)^2|X]
$$
$$
Err(X) = \sigma^2 + (f(X)-E[X\beta|X])^2 + E[(E[X\beta|X]-X\beta)^2|X]
$$
O primeiro termo $\sigma^2$ √© o ru√≠do irredut√≠vel. O segundo termo, $(f(X)-E[X\beta|X])^2$, representa o vi√©s ao quadrado. O terceiro termo $E[(E[X\beta|X]-X\beta)^2|X]$, representa a vari√¢ncia do modelo. $\blacksquare$

**Conceito 2: Linear Discriminant Analysis (LDA)**

**Linear Discriminant Analysis (LDA)** √© uma t√©cnica para encontrar a combina√ß√£o linear de features que melhor separa duas ou mais classes. O LDA √© baseado na premissa de que os dados dentro de cada classe seguem uma distribui√ß√£o normal, com m√©dia e covari√¢ncia espec√≠ficas por classe [^4.3]. O objetivo principal do LDA √© projetar os dados para um espa√ßo de menor dimens√£o, mantendo a separa√ß√£o entre as classes. O LDA √© um classificador linear, onde a fronteira de decis√£o √© um hiperplano, e as suposi√ß√µes de normalidade s√£o cruciais para a formula√ß√£o do LDA [^4.3.1]. A fun√ß√£o discriminante do LDA para uma observa√ß√£o $x$ e uma classe $k$ √© dada por [^4.3.3]:

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log \pi_k
$$

onde $\mu_k$ √© a m√©dia da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum a todas as classes, e $\pi_k$ √© a probabilidade a priori da classe $k$. O LDA atribui uma observa√ß√£o √† classe que maximiza $\delta_k(x)$.

> üí° **Exemplo Num√©rico:** Vamos supor um cen√°rio de classifica√ß√£o com duas classes (0 e 1) e duas features ($X_1$ e $X_2$). As m√©dias das classes s√£o $\mu_0 = [1, 2]$ e $\mu_1 = [3, 4]$, e a matriz de covari√¢ncia compartilhada √© $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$. As probabilidades a priori s√£o $\pi_0 = 0.4$ e $\pi_1 = 0.6$. Dada uma nova observa√ß√£o $x = [2, 3]$, podemos calcular os discriminantes:
>
> $\text{Step 1: } \Sigma^{-1} = \frac{1}{0.75}\begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$
>
> $\text{Step 2: } \delta_0(x) = [2, 3] \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [1, 2]^T - \frac{1}{2}[1, 2] \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [1, 2]^T + \log(0.4) \approx -2.29$
>
> $\text{Step 3: } \delta_1(x) = [2, 3] \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [3, 4]^T - \frac{1}{2}[3, 4] \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [3, 4]^T + \log(0.6) \approx -0.46$
>
> Como $\delta_1(x) > \delta_0(x)$, a observa√ß√£o $x = [2, 3]$ seria classificada como pertencente √† classe 1.
>
> ```python
> import numpy as np
> from numpy.linalg import inv
>
> # Dados do Exemplo
> mu_0 = np.array([1, 2])
> mu_1 = np.array([3, 4])
> Sigma = np.array([[1, 0.5], [0.5, 1]])
> pi_0 = 0.4
> pi_1 = 0.6
> x = np.array([2, 3])
>
> # C√°lculos LDA
> Sigma_inv = inv(Sigma)
> delta_0 = x @ Sigma_inv @ mu_0 - 0.5 * mu_0 @ Sigma_inv @ mu_0 + np.log(pi_0)
> delta_1 = x @ Sigma_inv @ mu_1 - 0.5 * mu_1 @ Sigma_inv @ mu_1 + np.log(pi_1)
>
> print(f"Discriminante para a classe 0: {delta_0:.2f}")
> print(f"Discriminante para a classe 1: {delta_1:.2f}")
>
> if delta_1 > delta_0:
>   print("A observa√ß√£o pertence √† classe 1")
> else:
>   print("A observa√ß√£o pertence √† classe 0")
> ```
> Este exemplo demonstra como o LDA utiliza as informa√ß√µes das m√©dias e covari√¢ncias das classes para calcular discriminantes e classificar novas observa√ß√µes.

> ‚ùó **Ponto de Aten√ß√£o**: Uma suposi√ß√£o fundamental do LDA √© que as matrizes de covari√¢ncia das classes s√£o iguais. Quando essa suposi√ß√£o n√£o √© v√°lida, uma alternativa √© usar a an√°lise discriminante quadr√°tica (QDA). O LDA, por ser uma t√©cnica linear, n√£o √© capaz de capturar rela√ß√µes complexas entre as classes, resultando em modelos com vi√©s elevado se o limite de decis√£o real n√£o for linear [^4.3.2].

**Corol√°rio 1: Rela√ß√£o Entre LDA e Proje√ß√£o Linear**

O LDA pode ser interpretado como um m√©todo que projeta os dados originais para um subespa√ßo linear de menor dimens√£o onde as classes s√£o mais bem separadas. A dire√ß√£o da proje√ß√£o linear √© obtida a partir dos autovetores da matriz  $W^{-1}B$, onde $W$ representa a matriz de espalhamento dentro das classes e $B$ a matriz de espalhamento entre as classes. Essa proje√ß√£o linear garante a maximiza√ß√£o da separabilidade entre as classes no novo espa√ßo de menor dimensionalidade [^4.3.1].

```mermaid
graph LR
    subgraph "LDA Projection"
        direction TB
        A["Original Feature Space"]
        B["Compute W (Within-Class Scatter)"]
        C["Compute B (Between-Class Scatter)"]
        D["Eigenvectors of W‚Åª¬πB"]
        E["Projected Subspace"]
        A --> B
        A --> C
        B & C --> D
        D --> E
    end
```

**Conceito 3: Logistic Regression**

A **Logistic Regression** √© um modelo estat√≠stico utilizado para problemas de classifica√ß√£o bin√°ria, que modela a probabilidade de uma observa√ß√£o pertencer a uma determinada classe. Em vez de modelar diretamente a vari√°vel de sa√≠da (como em regress√£o linear), a regress√£o log√≠stica modela a probabilidade de pertin√™ncia a classe atrav√©s de uma fun√ß√£o sigmoidal (logit) [^4.4].  A forma da regress√£o log√≠stica √© dada por [^4.4.1]:

$$
p(X) = \frac{1}{1+e^{-(X\beta)}}
$$

onde $p(X)$ representa a probabilidade da observa√ß√£o pertencer a uma determinada classe, $X$ √© o vetor de features e $\beta$ √© o vetor de par√¢metros a serem estimados. A estimativa dos par√¢metros $\beta$ √© realizada por meio da maximiza√ß√£o da verossimilhan√ßa (Maximum Likelihood Estimation - MLE) [^4.4.2].

> üí° **Exemplo Num√©rico:** Suponha que temos uma feature $X$ e o modelo de regress√£o log√≠stica seja $p(X) = \frac{1}{1 + e^{-(2 + 1.5X)}}$. Se tivermos uma observa√ß√£o com $X = 1$, a probabilidade estimada de pertencer √† classe 1 seria $p(1) = \frac{1}{1 + e^{-(2 + 1.5*1)}} \approx \frac{1}{1 + e^{-3.5}} \approx 0.97$. Se $X = -1$, ent√£o $p(-1) = \frac{1}{1 + e^{-(2 - 1.5)}} \approx \frac{1}{1 + e^{-0.5}} \approx 0.38$. Isto indica que observa√ß√µes com $X = 1$ s√£o muito mais propensas a serem da classe 1, enquanto observa√ß√µes com $X = -1$ s√£o mais propensas √† classe 0.

> ‚úîÔ∏è **Destaque**: Tanto o LDA como a regress√£o log√≠stica podem ser utilizadas para classifica√ß√£o linear, mas a regress√£o log√≠stica n√£o assume normalidade nos preditores, sendo mais flex√≠vel e adequada em muitos cen√°rios reais [^4.4.5]. O m√©todo de otimiza√ß√£o (maximiza√ß√£o da verossimilhan√ßa) na regress√£o log√≠stica difere do LDA, e os coeficientes de regress√£o log√≠stica podem ser interpretados como log-odds ratios [^4.4.3], [^4.4.4].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Indicator Regression"
        direction TB
        A["Classes as Indicator Matrix"]
        B["LS Estimation of Coefficients: Œ≤ = (X·µÄX)‚Åª¬πX·µÄY"]
        C["Decision Rule: assign class based on predicted value"]
        A --> B
        B --> C
     end
```

A regress√£o linear, embora originalmente concebida para problemas de regress√£o, pode ser adaptada para problemas de classifica√ß√£o atrav√©s da regress√£o em uma matriz de indicadores. O processo consiste em codificar cada classe como um vetor bin√°rio (um "one-hot encoding"), transformando um problema de classifica√ß√£o em um problema de regress√£o. Os coeficientes s√£o estimados usando o m√©todo de m√≠nimos quadrados, e uma regra de decis√£o √© usada para atribuir cada observa√ß√£o a uma das classes.

A abordagem de regress√£o de indicadores tem suas limita√ß√µes [^4.2]. Em cen√°rios com mais de duas classes, a regress√£o de indicadores pode levar a fronteiras de decis√£o menos eficientes se comparadas com outros m√©todos como LDA ou regress√£o log√≠stica. Al√©m disso, as predi√ß√µes obtidas atrav√©s da regress√£o de indicadores podem extrapolar para valores fora do intervalo [0,1], dificultando a interpreta√ß√£o das sa√≠das como probabilidades.

**Lemma 2: Equival√™ncia com LDA sob Hip√≥teses Espec√≠ficas**
Sob condi√ß√µes espec√≠ficas, a regress√£o de indicadores √© equivalente √† proje√ß√£o linear obtida por LDA, ou seja, as proje√ß√µes nos hiperplanos de decis√£o gerados por ambos os m√©todos s√£o as mesmas. Considere um problema de classifica√ß√£o bin√°ria, onde as classes s√£o codificadas como $Y_i \in \{0, 1\}$. A regress√£o de indicadores busca um vetor de coeficientes $\beta$ que minimiza a soma dos erros quadrados: $\sum_{i=1}^N (Y_i - X_i\beta)^2$. Ao resolver este problema, obt√©m-se $\beta = (X^T X)^{-1} X^T Y$.

No LDA, a dire√ß√£o da proje√ß√£o √© dada pelo vetor $W^{-1}(\mu_1-\mu_0)$, onde $W$ √© a matriz de covari√¢ncia dentro da classe e $\mu_1$ e $\mu_0$ s√£o as m√©dias das classes. Sob certas condi√ß√µes, como classes com mesmo n√∫mero de observa√ß√µes e matrizes de covari√¢ncia id√™nticas, as proje√ß√µes nos hiperplanos de decis√£o da regress√£o de indicadores e do LDA s√£o equivalentes, indicando a semelhan√ßa matem√°tica entre essas duas abordagens em determinadas situa√ß√µes.
$\blacksquare$

**Corol√°rio 2: Rela√ß√£o com Fun√ß√µes Discriminantes Lineares**

Em problemas de classifica√ß√£o bin√°ria, √© poss√≠vel demonstrar que a regress√£o de indicadores se conecta com as fun√ß√µes discriminantes lineares. A fun√ß√£o discriminante linear obtida atrav√©s da regress√£o de indicadores para uma observa√ß√£o $x$ pode ser escrita como $f(x) = x^T \beta$. Ao compararmos com a fun√ß√£o discriminante do LDA, $\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log \pi_k$, notamos que o termo $x^T \beta$ da regress√£o de indicadores pode ser interpretado como uma proje√ß√£o linear que busca maximizar a separa√ß√£o entre as classes, similar ao objetivo do LDA. Em muitos casos, o termo $\beta$ pode ser interpretado como uma transforma√ß√£o do espa√ßo original de features que maximiza a separabilidade linear, conectando, assim, as duas abordagens.

Em certas circunst√¢ncias, a regress√£o de indicadores pode levar a estimativas menos est√°veis em compara√ß√£o com outros m√©todos como a regress√£o log√≠stica. Em casos onde as classes s√£o bem separadas, a regress√£o de indicadores, embora possa ser mais simples, ainda consegue obter bons resultados, especialmente quando o foco principal √© a fronteira de decis√£o linear.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["Objective Function"]
        B["L1 Regularization: $\lambda \sum |\beta|$"]
        C["L2 Regularization: $\lambda \sum \beta^2$"]
        D["Elastic Net: $\lambda_1 \sum |\beta| + \lambda_2 \sum \beta^2$"]
        A --> B
        A --> C
        A --> D
    end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas cruciais para a constru√ß√£o de modelos de classifica√ß√£o robustos e com boa capacidade de generaliza√ß√£o, especialmente quando h√° um grande n√∫mero de features.

A regulariza√ß√£o, em particular, busca controlar a complexidade do modelo atrav√©s da adi√ß√£o de termos de penalidade √† fun√ß√£o de custo, mitigando o risco de overfitting. A regulariza√ß√£o L1 (Lasso) penaliza a soma dos valores absolutos dos coeficientes [^4.4.4], promovendo a sparsity na solu√ß√£o, ou seja, induzindo muitos coeficientes a zero, resultando em modelos mais interpret√°veis e menos propensos a overfitting. A regulariza√ß√£o L2 (Ridge) penaliza a soma dos quadrados dos coeficientes, promovendo a estabilidade do modelo atrav√©s da redu√ß√£o da magnitude dos coeficientes. Uma combina√ß√£o dessas penalidades, conhecida como Elastic Net, busca balancear os benef√≠cios da sparsity da L1 e da estabilidade da L2 [^4.5].

A implementa√ß√£o da regulariza√ß√£o em modelos de classifica√ß√£o, como a regress√£o log√≠stica, envolve a inclus√£o de um termo de penaliza√ß√£o na fun√ß√£o de verossimilhan√ßa. Por exemplo, o problema de otimiza√ß√£o para a regress√£o log√≠stica com regulariza√ß√£o L1 pode ser escrito como [^4.4.4]:

$$
\text{min}_{\beta} \left\{ - \sum_{i=1}^{N} [y_i \log(p(x_i)) + (1-y_i)\log(1-p(x_i))] + \lambda \sum_{j=1}^p |\beta_j| \right\}
$$

onde $\lambda$ √© o par√¢metro de regulariza√ß√£o, que controla a intensidade da penalidade.

> üí° **Exemplo Num√©rico:** Vamos considerar a regress√£o log√≠stica para um problema de classifica√ß√£o bin√°ria com 3 features. O modelo sem regulariza√ß√£o pode ter par√¢metros $\beta = [2, -1, 0.5]$. Aplicando a regulariza√ß√£o L1, com $\lambda = 0.5$, alguns coeficientes podem ser reduzidos a zero. A nova solu√ß√£o pode ser $\beta_{L1} = [1.2, 0, 0]$. Aplicando a regulariza√ß√£o L2, a solu√ß√£o pode ser $\beta_{L2} = [1.8, -0.8, 0.4]$. Veja o exemplo abaixo usando `sklearn`:
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.preprocessing import StandardScaler
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import accuracy_score
> import pandas as pd
>
> # Criar um dataset de exemplo
> np.random.seed(42)
> n_samples = 100
> X = np.random.rand(n_samples, 3)
> y = (X[:, 0] + 2 * X[:, 1] - 1.5 * X[:, 2] + np.random.randn(n_samples) > 0).astype(int)
>
> # Dividir dados em treino e teste
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Padronizar as features
> scaler = StandardScaler()
> X_train_scaled = scaler.fit_transform(X_train)
> X_test_scaled = scaler.transform(X_test)
>
> # Modelo sem regulariza√ß√£o
> model_no_reg = LogisticRegression(penalty=None)
> model_no_reg.fit(X_train_scaled, y_train)
> y_pred_no_reg = model_no_reg.predict(X_test_scaled)
>
> # Modelo com regulariza√ß√£o L1 (Lasso)
> model_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0) # C = 1/lambda
> model_l1.fit(X_train_scaled, y_train)
> y_pred_l1 = model_l1.predict(X_test_scaled)
>
> # Modelo com regulariza√ß√£o L2 (Ridge)
> model_l2 = LogisticRegression(penalty='l2', C=1.0) # C = 1/lambda
> model_l2.fit(X_train_scaled, y_train)
> y_pred_l2 = model_l2.predict(X_test_scaled)
>
> # Imprimir os coeficientes e a acur√°cia
> print("Coeficientes (Sem Regulariza√ß√£o):", model_no_reg.coef_)
> print("Coeficientes (Regulariza√ß√£o L1):", model_l1.coef_)
> print("Coeficientes (Regulariza√ß√£o L2):", model_l2.coef_)
> print("Acur√°cia (Sem Regulariza√ß√£o):", accuracy_score(y_test, y_pred_no_reg))
> print("Acur√°cia (Regulariza√ß√£o L1):", accuracy_score(y_test, y_pred_l1))
> print("Acur√°cia (Regulariza√ß√£o L2):", accuracy_score(y_test, y_pred_l2))
>
> # Tabela para comparacao
> comparison_data = {
>   "Method": ["No Regularization", "L1 (Lasso)", "L2 (Ridge)"],
>   "Accuracy": [accuracy_score(y_test, y_pred_no_reg), accuracy_score(y_test, y_pred_l1), accuracy_score(y_test, y_pred_l2)],
>   "Coefficients": [model_no_reg.coef_[0].round(2), model_l1.coef_[0].round(2), model_l2.coef_[0].round(2)]
> }
>
> comparison_table = pd.DataFrame(comparison_data)
> print("\nComparison Table:")
> print(comparison_table)
> ```
> A sa√≠da mostrar√° como a regulariza√ß√£o L1 zera coeficientes (promovendo sparsity) e a L2 reduz a magnitude dos coeficientes.

**Lemma 3: Efeito da Penaliza√ß√£o L1 em Coeficientes**

Em regress√£o log√≠stica com penaliza√ß√£o L1, a minimiza√ß√£o da fun√ß√£o de custo com o termo de penaliza√ß√£o leva a coeficientes esparsos. A penalidade L1, ao ser adicionada √† fun√ß√£o de verossimilhan√ßa, promove o encolhimento de coeficientes em dire√ß√£o a zero, e alguns coeficientes podem se tornar exatamente zero. Essa propriedade da L1 √© dada pela natureza da penalidade, que possui uma derivada n√£o-cont√≠nua em zero, levando os coeficientes a serem "empurrados" para zero durante o processo de otimiza√ß√£o.

**Prova do Lemma 3:**
A penalidade L1 adiciona $\lambda \sum_{j=1}^{p}|\beta_j|$ √† fun√ß√£o de custo da regress√£o log√≠stica. Para coeficientes n√£o nulos ($\beta_j \neq 0$), a derivada do termo de penaliza√ß√£o com rela√ß√£o a $\beta_j$ √© $\lambda \text{sign}(\beta_j)$, onde $\text{sign}$ √© a fun√ß√£o sinal. A otimiza√ß√£o da fun√ß√£o de custo busca encontrar um m√≠nimo, e um coeficiente se torna exatamente zero se sua derivada parcial na fun√ß√£o de custo, antes da penaliza√ß√£o L1, for menor que $\lambda$ em valor absoluto. Quando um coeficiente √© nulo, a sua influ√™ncia na predi√ß√£o do modelo √© eliminada, produzindo um modelo mais simples e interpret√°vel.
$\blacksquare$

**Corol√°rio 3: Interpretabilidade e Sele√ß√£o de Features**

O Lemma 3 implica que a penaliza√ß√£o L1 n√£o s√≥ controla o overfitting, mas tamb√©m atua como um mecanismo de sele√ß√£o de vari√°veis, uma vez que muitos dos coeficientes da regress√£o log√≠stica com L1 se tornam zero. Isto facilita a identifica√ß√£o das features mais importantes para a predi√ß√£o, j√° que apenas os coeficientes n√£o nulos s√£o relevantes para o modelo. Esta propriedade √© muito √∫til em cen√°rios com um n√∫mero elevado de features, onde √© desej√°vel obter modelos mais parsimoniosos [^4.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: A escolha entre regulariza√ß√£o L1, L2 ou Elastic Net, bem como o ajuste do par√¢metro de regulariza√ß√£o, depende da natureza do problema, da complexidade dos dados e dos objetivos espec√≠ficos do problema de classifica√ß√£o. A valida√ß√£o cruzada, conforme mencionado mais adiante neste cap√≠tulo, pode auxiliar na escolha do m√©todo mais adequado de regulariza√ß√£o e na otimiza√ß√£o do par√¢metro correspondente [^4.5].

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Separating Hyperplanes"
        direction TB
        A["Feature Space"]
        B["Hyperplane"]
        C["Maximum Margin"]
        D["Support Vectors"]
        A --> B
        B --> C
        C --> D
    end
```

A busca por hiperplanos de separa√ß√£o, ou **separating hyperplanes**, √© uma abordagem fundamental em problemas de classifica√ß√£o. Um hiperplano √© uma generaliza√ß√£o de uma linha (em duas dimens√µes) para espa√ßos de maiores dimens√µes, onde ele separa o espa√ßo de features em regi√µes distintas, cada uma correspondente a uma classe diferente. O problema de encontrar o hiperplano √≥timo para separa√ß√£o envolve a maximiza√ß√£o da margem, ou seja, a dist√¢ncia entre o hiperplano e os pontos de treinamento mais pr√≥ximos [^4.5.2].

O problema de otimiza√ß√£o para encontrar o hiperplano separador com margem m√°xima pode ser formulado como um problema de programa√ß√£o quadr√°tica, com restri√ß√µes lineares. A solu√ß√£o √≥tima para este problema pode ser obtida utilizando o dual de Wolfe, onde a solu√ß√£o √© escrita em termos de combina√ß√µes lineares dos pontos de suporte, ou seja, os pontos de treinamento que s√£o cruciais para a determina√ß√£o do hiperplano.

O Perceptron de Rosenblatt √© um algoritmo que busca encontrar um hiperplano separador por meio de ajustes iterativos. Sob condi√ß√µes de separabilidade linear, o Perceptron converge para um hiperplano que separa as classes corretamente [^4.5.1]. No entanto, o Perceptron pode n√£o convergir se os dados n√£o forem linearmente separ√°veis.

### Pergunta Te√≥rica Avan√ßada (Exemplo): Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**

A **Regra de Decis√£o Bayesiana**, sob a hip√≥tese de distribui√ß√µes Gaussianas para as classes, define a regra de classifica√ß√£o que minimiza a probabilidade de erro. Essa regra atribui uma observa√ß√£o $x$ √† classe $k$ que maximiza a probabilidade condicional posterior $P(G=k|X=x)$, dada por:

$$
P(G=k|X=x) = \frac{P(X=x|G=k)P(G=k)}{P(X=x)}
$$

onde $P(X=x|G=k)$ √© a densidade de probabilidade condicional da observa√ß√£o $x$ na classe $k$ e $P(G=k)$ √© a probabilidade a priori da classe $k$.

Sob a suposi√ß√£o de que as densidades condicionais s√£o Gaussianas e que todas as classes compartilham a mesma matriz de covari√¢ncia $\Sigma$, temos que $P(X=x|G=k) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}}exp(-\frac{1}{2}(x-\mu_k)^T\Sigma^{-1}(x-\mu_k))$, onde $\mu_k$ √© a m√©dia da classe $k$ e $p$ √©