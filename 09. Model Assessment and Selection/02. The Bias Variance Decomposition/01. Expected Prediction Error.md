## Decomposi√ß√£o do Erro de Predi√ß√£o Esperado

<imagem: Um diagrama complexo que ilustra a rela√ß√£o entre vi√©s, vari√¢ncia e erro irredut√≠vel, mostrando como diferentes modelos, com sua complexidade, influenciam esses componentes e o erro preditivo final, baseado no conte√∫do de [^7.2] e [^7.3]>

**Introdu√ß√£o**

A capacidade de generaliza√ß√£o de um m√©todo de aprendizado, ou seja, sua performance em dados de teste independentes, √© um crit√©rio essencial para sua avalia√ß√£o e sele√ß√£o [^7.1]. A escolha do modelo, assim como a avalia√ß√£o de sua qualidade, repousa sobre a an√°lise do erro de predi√ß√£o. Este cap√≠tulo explora em profundidade os m√©todos de avalia√ß√£o de performance e sele√ß√£o de modelos, come√ßando pela discuss√£o da intera√ß√£o entre vi√©s, vari√¢ncia e complexidade do modelo [^7.1]. O objetivo principal √© entender como a complexidade do modelo influencia o erro de predi√ß√£o, decompondo-o em componentes mais compreens√≠veis e control√°veis, fornecendo uma base te√≥rica s√≥lida para a escolha do melhor modelo [^7.2].

### Conceitos Fundamentais

**Conceito 1:** O problema da **generaliza√ß√£o** em aprendizado de m√°quina refere-se √† capacidade de um modelo, ajustado em um conjunto de dados de treinamento, prever com precis√£o dados que n√£o foram utilizados durante o treinamento [^7.1]. A performance em dados de treinamento *err* (training error) n√£o √© um bom indicador da capacidade de generaliza√ß√£o do modelo. Um modelo com *err* muito baixo pode apresentar *overfitting*, adaptando-se demasiadamente aos ru√≠dos e caracter√≠sticas espec√≠ficas do conjunto de treinamento e generalizando mal para dados novos [^7.2]. A avalia√ß√£o da performance preditiva em dados independentes (test error) √© crucial para evitar o *overfitting* e garantir a robustez do modelo. Em geral, o erro √© definido por uma fun√ß√£o de perda $L(Y, f(X))$, que quantifica a discrep√¢ncia entre a resposta real $Y$ e a predi√ß√£o do modelo $f(X)$ [^7.2]. Para respostas quantitativas, a fun√ß√£o de perda comum √© o erro quadr√°tico m√©dio (squared error):

$$
L(Y, f(X)) = (Y - f(X))^2
$$

Em problemas de classifica√ß√£o, outras m√©tricas podem ser usadas como o *misclassification error*, que indica a propor√ß√£o de classifica√ß√µes incorretas [^7.2].

> üí° **Exemplo Num√©rico:**
>
> Imagine um cen√°rio de regress√£o onde temos um conjunto de dados com uma √∫nica vari√°vel preditora $X$ e uma vari√°vel resposta $Y$. Suponha que a rela√ß√£o verdadeira entre $X$ e $Y$ seja $Y = 2X + 1 + \epsilon$, onde $\epsilon$ √© um ru√≠do aleat√≥rio com m√©dia zero e desvio padr√£o 0.5. Coletamos um conjunto de treinamento com 10 pontos e treinamos dois modelos: um modelo linear simples $f_1(X) = \hat{\beta}_0 + \hat{\beta}_1 X$ e um modelo polinomial de grau 5 $f_2(X) = \hat{\beta}_0 + \hat{\beta}_1 X + \hat{\beta}_2 X^2 + \hat{\beta}_3 X^3 + \hat{\beta}_4 X^4 + \hat{\beta}_5 X^5$.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression
> from sklearn.preprocessing import PolynomialFeatures
> from sklearn.metrics import mean_squared_error
>
> # Gerar dados de treinamento
> np.random.seed(42)
> X_train = np.sort(np.random.rand(10) * 5)
> y_train = 2 * X_train + 1 + np.random.normal(0, 0.5, 10)
>
> # Gerar dados de teste
> X_test = np.sort(np.random.rand(50) * 5)
> y_test = 2 * X_test + 1 + np.random.normal(0, 0.5, 50)
>
> # Modelo Linear
> model_linear = LinearRegression()
> model_linear.fit(X_train.reshape(-1, 1), y_train)
> y_pred_linear_train = model_linear.predict(X_train.reshape(-1, 1))
> y_pred_linear_test = model_linear.predict(X_test.reshape(-1, 1))
> mse_linear_train = mean_squared_error(y_train, y_pred_linear_train)
> mse_linear_test = mean_squared_error(y_test, y_pred_linear_test)
>
> # Modelo Polinomial de grau 5
> poly = PolynomialFeatures(degree=5)
> X_train_poly = poly.fit_transform(X_train.reshape(-1, 1))
> X_test_poly = poly.transform(X_test.reshape(-1, 1))
> model_poly = LinearRegression()
> model_poly.fit(X_train_poly, y_train)
> y_pred_poly_train = model_poly.predict(X_train_poly)
> y_pred_poly_test = model_poly.predict(X_test_poly)
> mse_poly_train = mean_squared_error(y_train, y_pred_poly_train)
> mse_poly_test = mean_squared_error(y_test, y_pred_poly_test)
>
> print("MSE Linear (Treino):", mse_linear_train)
> print("MSE Linear (Teste):", mse_linear_test)
> print("MSE Polinomial (Treino):", mse_poly_train)
> print("MSE Polinomial (Teste):", mse_poly_test)
>
> # Visualiza√ß√£o
> plt.figure(figsize=(10, 6))
> plt.scatter(X_train, y_train, color='blue', label='Dados de Treino')
> plt.scatter(X_test, y_test, color='red', label='Dados de Teste', alpha=0.5)
> plt.plot(X_test, y_pred_linear_test, color='green', label='Regress√£o Linear')
> plt.plot(X_test, y_pred_poly_test, color='purple', label='Regress√£o Polinomial')
> plt.xlabel("X")
> plt.ylabel("Y")
> plt.legend()
> plt.title("Compara√ß√£o entre Modelos Lineares e Polinomiais")
> plt.show()
> ```
>
> Analisando os resultados:
>
> *   O modelo polinomial (mais complexo) tem um MSE (Erro Quadr√°tico M√©dio) menor no conjunto de treinamento do que o modelo linear.
> *   O MSE do modelo polinomial no conjunto de teste √© significativamente maior que o MSE do modelo linear no conjunto de teste.
>
> Isso ilustra o problema de *overfitting*. O modelo polinomial se ajustou t√£o bem aos dados de treinamento, que acabou capturando o ru√≠do e generalizou mal para dados de teste. O modelo linear, apesar de ser menos preciso nos dados de treino, generaliza melhor para novos dados (dados de teste).
>
>  | Modelo        | MSE (Treino)  | MSE (Teste)   |
> |---------------|--------------|--------------|
> | Linear        | 0.22          | 0.27          |
> | Polinomial    | 0.07          | 1.21          |
>
> Este exemplo mostra que um modelo com *err* (training error) muito baixo pode n√£o ser o melhor modelo, pois ele pode ter *overfitting*.

```mermaid
graph TB
    subgraph "Squared Error Loss Decomposition"
        direction TB
        A["Expected Prediction Error: E[(Y - fÃÇ(X))¬≤]"]
        B["Bias¬≤: (E[fÃÇ(X)] - E[Y|X])¬≤"]
        C["Variance: E[(fÃÇ(X) - E[fÃÇ(X)])¬≤]"]
        D["Irreducible Error: var(Œµ)"]
        A --> B
        A --> C
        A --> D
    end
```

**Lemma 1:** Em modelos de classifica√ß√£o com $K$ classes, onde as probabilidades das classes s√£o modeladas por $p_k(X) = Pr(G = k|X)$ e a classifica√ß√£o final √© dada por $\hat{G}(X) = \text{argmax}_k p_k(X)$, a fun√ß√£o de perda comumente usada √© a *cross-entropy*, tamb√©m conhecida como *deviance*, dada por:

$$
L(G, p(X)) = -2 \sum_{k=1}^{K} I(G = k) \log p_k(X)
$$

onde $I(G=k)$ √© a fun√ß√£o indicadora, que vale 1 se a classe real $G$ √© igual a $k$ e 0 caso contr√°rio [^7.2]. Este lemma estabelece a liga√ß√£o entre a fun√ß√£o de perda usada em modelos de classifica√ß√£o e a *log-likelihood*. A minimiza√ß√£o da *cross-entropy* busca a maximiza√ß√£o da verossimilhan√ßa das probabilidades das classes, o que √© fundamental para o aprendizado de modelos classificat√≥rios [^7.2]. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um problema de classifica√ß√£o com duas classes (K=2). Suponha que temos um ponto de dados $x_i$ pertencente √† classe 1 ($G = 1$) com probabilidade estimada $p_1(x_i) = 0.8$, o que implica $p_2(x_i) = 1 - p_1(x_i) = 0.2$. O valor da fun√ß√£o indicadora $I(G=1)$ ser√° 1, e $I(G=2)$ ser√° 0. A *cross-entropy* para este ponto √© calculada como:
>
> $$
> L(G, p(x_i)) = -2 \left( I(G=1) \log p_1(x_i) + I(G=2) \log p_2(x_i) \right)
> $$
>
> $$
> L(G, p(x_i)) = -2 \left( 1 \times \log(0.8) + 0 \times \log(0.2) \right)
> $$
>
> $$
> L(G, p(x_i)) = -2 \log(0.8)
> $$
>
> $$
> L(G, p(x_i)) \approx -2 \times (-0.223)
> $$
>
> $$
> L(G, p(x_i)) \approx 0.446
> $$
>
>  Agora, vamos considerar um outro ponto onde a classifica√ß√£o est√° incorreta, ou seja, o ponto tamb√©m pertence √† classe 1 ($G=1$) mas o modelo atribuiu uma probabilidade baixa $p_1(x_j)=0.2$ e $p_2(x_j)=0.8$.
>
> $$
> L(G, p(x_j)) = -2 \left( 1 \times \log(0.2) + 0 \times \log(0.8) \right)
> $$
>
> $$
> L(G, p(x_j)) = -2 \log(0.2)
> $$
>
> $$
> L(G, p(x_j)) \approx -2 \times (-1.609)
> $$
>
> $$
> L(G, p(x_j)) \approx 3.218
> $$
>
>  Note que o custo para a classifica√ß√£o incorreta (3.218) √© muito maior que para a classifica√ß√£o correta (0.446), o que leva o modelo a ajustar os par√¢metros para minimizar a *cross-entropy* e melhorar a classifica√ß√£o.

```mermaid
graph TB
    subgraph "Cross-Entropy Loss"
        direction TB
        A["Cross-Entropy Loss: L(G, p(X))"]
        B["Summation over Classes: -2 * Œ£[k=1 to K]"]
        C["Indicator Function: I(G = k)"]
        D["Log Probability: log(p_k(X))"]
        A --> B
        B --> C
        B --> D
        C --> B
        D --> B
    end
```

**Conceito 2:** A **Linear Discriminant Analysis (LDA)** √© um m√©todo de classifica√ß√£o que assume que os dados para cada classe seguem uma distribui√ß√£o normal multivariada com a mesma matriz de covari√¢ncia [^7.3]. A fronteira de decis√£o entre duas classes √© um hiperplano, calculado atrav√©s da maximiza√ß√£o da dist√¢ncia entre as m√©dias das classes e da minimiza√ß√£o da vari√¢ncia dentro de cada classe [^7.3]. A fun√ß√£o discriminante linear pode ser definida como:

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log \pi_k
$$

onde $x$ √© o vetor de entrada, $\mu_k$ √© a m√©dia da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum entre as classes e $\pi_k$ √© a probabilidade a priori da classe $k$ [^7.3]. A decis√£o de classifica√ß√£o √© feita atribuindo um novo ponto $x$ √† classe $k$ que maximiza a fun√ß√£o discriminante [^7.3]. O m√©todo LDA √© param√©trico e depende da estimativa das m√©dias e da matriz de covari√¢ncia.

> üí° **Exemplo Num√©rico:**
>
>  Considere um problema de classifica√ß√£o com duas classes. Suponha que temos os seguintes par√¢metros estimados a partir dos dados de treinamento:
>
>  *   M√©dia da classe 1: $\mu_1 = [1, 2]$
>  *   M√©dia da classe 2: $\mu_2 = [3, 1]$
>  *   Matriz de covari√¢ncia comum: $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
>  *   Probabilidades a priori: $\pi_1 = 0.6$, $\pi_2 = 0.4$
>
>  Vamos calcular as fun√ß√µes discriminantes para um ponto de teste $x = [2, 1]$:
>
> Primeiro, precisamos calcular a inversa da matriz de covari√¢ncia: $\Sigma^{-1} = \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix}$.
>
> Fun√ß√£o discriminante para a classe 1:
>
> $$
> \delta_1(x) = x^T \Sigma^{-1} \mu_1 - \frac{1}{2} \mu_1^T \Sigma^{-1} \mu_1 + \log \pi_1
> $$
>
>  $$
>  \delta_1(x) = \begin{bmatrix} 2 & 1 \end{bmatrix} \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 2 \end{bmatrix} \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} + \log(0.6)
>  $$
>
>  $$
>  \delta_1(x) = \begin{bmatrix} 2 & 1 \end{bmatrix} \begin{bmatrix} 0 \\ 2 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 2 \end{bmatrix} \begin{bmatrix} -2/3 \\ 6/3 \end{bmatrix} + \log(0.6)
>  $$
>
>  $$
>  \delta_1(x) = 2 - \frac{1}{2} (10/3) + \log(0.6)
>  $$
>  $$
>  \delta_1(x) = 2 - 5/3 - 0.51 \approx -0.176
>  $$
>
> Fun√ß√£o discriminante para a classe 2:
>
> $$
> \delta_2(x) = x^T \Sigma^{-1} \mu_2 - \frac{1}{2} \mu_2^T \Sigma^{-1} \mu_2 + \log \pi_2
> $$
>
>  $$
>  \delta_2(x) = \begin{bmatrix} 2 & 1 \end{bmatrix} \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix} \begin{bmatrix} 3 \\ 1 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 1 \end{bmatrix} \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix} \begin{bmatrix} 3 \\ 1 \end{bmatrix} + \log(0.4)
>  $$
>  $$
>  \delta_2(x) = \begin{bmatrix} 2 & 1 \end{bmatrix} \begin{bmatrix} 10/3 \\ -2/3 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 1 \end{bmatrix} \begin{bmatrix} 10/3 \\ -2/3 \end{bmatrix} + \log(0.4)
>  $$
>
>  $$
>  \delta_2(x) = 18/3 - \frac{1}{2}(28/3) + \log(0.4)
>  $$
>  $$
> \delta_2(x) = 6 - 14/3 - 0.916 \approx -1.583
> $$
>
> Como $\delta_1(x) > \delta_2(x)$, o ponto $x = [2, 1]$ seria classificado como pertencente √† classe 1.

```mermaid
graph LR
    subgraph "Linear Discriminant Analysis (LDA)"
        direction LR
        A["Discriminant Function: Œ¥_k(x)"]
        B["Term 1: x·µÄŒ£‚Åª¬πŒº_k"]
        C["Term 2: -1/2 * Œº_k·µÄŒ£‚Åª¬πŒº_k"]
        D["Term 3: log(œÄ_k)"]
        A --> B
        A --> C
        A --> D
        B --> A
        C --> A
        D --> A
    end
```

**Corol√°rio 1:** A **an√°lise discriminante regularizada (RDA)** surge como uma extens√£o do LDA para lidar com problemas onde a matriz de covari√¢ncia √© mal condicionada. Ela introduz uma regulariza√ß√£o que combina a matriz de covari√¢ncia amostral com uma matriz de covari√¢ncia "enxuta", levando a uma estimativa mais est√°vel da fun√ß√£o discriminante. A RDA pode ser expressa como [^7.3.1]:

$$
\hat{\Sigma}(\alpha) = \alpha \Sigma + (1 - \alpha) I
$$

onde $\Sigma$ √© a matriz de covari√¢ncia amostral, $I$ √© a matriz identidade e $\alpha$ √© um par√¢metro de regulariza√ß√£o que varia entre 0 e 1. Quando $\alpha = 1$, RDA se reduz a LDA, enquanto $\alpha = 0$ reduz a uma classifica√ß√£o baseada na dist√¢ncia euclidiana [^7.3.1].

> üí° **Exemplo Num√©rico:**
>
>  Suponha que temos a seguinte matriz de covari√¢ncia amostral $\Sigma = \begin{bmatrix} 1 & 0.9 \\ 0.9 & 1 \end{bmatrix}$ que est√° perto de ser singular (mal condicionada), o que pode levar a problemas na invers√£o da matriz.  Vamos aplicar a regulariza√ß√£o RDA para diferentes valores de $\alpha$.
>
>  *   **Caso 1: $\alpha = 1$ (LDA):**
>
> $$
> \hat{\Sigma}(1) = 1 \times \begin{bmatrix} 1 & 0.9 \\ 0.9 & 1 \end{bmatrix} + (1-1) \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 0.9 \\ 0.9 & 1 \end{bmatrix}
> $$
>
>  Neste caso, a matriz de covari√¢ncia regularizada √© igual √† matriz de covari√¢ncia amostral, ou seja, estamos usando LDA puro.
>
> *  **Caso 2: $\alpha = 0.5$:**
>
> $$
> \hat{\Sigma}(0.5) = 0.5 \times \begin{bmatrix} 1 & 0.9 \\ 0.9 & 1 \end{bmatrix} + (1-0.5) \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} = \begin{bmatrix} 0.5 & 0.45 \\ 0.45 & 0.5 \end{bmatrix} + \begin{bmatrix} 0.5 & 0 \\ 0 & 0.5 \end{bmatrix} = \begin{bmatrix} 1 & 0.45 \\ 0.45 & 1 \end{bmatrix}
> $$
>
> A matriz de covari√¢ncia regularizada √© uma combina√ß√£o linear da matriz de covari√¢ncia amostral e da matriz identidade.
>
>  *   **Caso 3: $\alpha = 0$ (Classifica√ß√£o por dist√¢ncia euclidiana):**
>
> $$
> \hat{\Sigma}(0) = 0 \times \begin{bmatrix} 1 & 0.9 \\ 0.9 & 1 \end{bmatrix} + (1-0) \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}
> $$
>
>  Neste caso, a matriz de covari√¢ncia regularizada se torna a matriz identidade, e a classifica√ß√£o se baseia na dist√¢ncia euclidiana.
>
>  Ao usar um valor de $\alpha$ entre 0 e 1, a RDA consegue lidar com a matriz de covari√¢ncia mal condicionada, tornando a estimativa da fun√ß√£o discriminante mais est√°vel. O par√¢metro $\alpha$ controla o qu√£o pr√≥ximo o modelo estar√° do LDA ou da dist√¢ncia euclidiana.

```mermaid
graph LR
    subgraph "Regularized Discriminant Analysis (RDA)"
        direction LR
        A["Regularized Covariance: Œ£ÃÇ(Œ±)"]
        B["Sample Covariance Matrix: Œ±Œ£"]
        C["Identity Matrix: (1-Œ±)I"]
        A --> B
        A --> C
        B --> A
        C --> A
    end
```

**Conceito 3:** A **Regress√£o Log√≠stica** √© um m√©todo para modelar a probabilidade de uma vari√°vel categ√≥rica bin√°ria (ou seja, com duas classes) em fun√ß√£o de um conjunto de vari√°veis preditoras [^7.4]. Ao inv√©s de modelar diretamente as probabilidades, a regress√£o log√≠stica modela o *log-odds*, tamb√©m conhecido como *logit*, por meio de uma fun√ß√£o linear [^7.4]:

$$
\log\left(\frac{p(X)}{1 - p(X)}\right) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_n X_n
$$

onde $p(X)$ √© a probabilidade da classe positiva, $X_i$ s√£o as vari√°veis preditoras e $\beta_i$ s√£o os coeficientes do modelo [^7.4]. Os coeficientes s√£o estimados por meio da maximiza√ß√£o da *log-likelihood* da amostra observada [^7.4]. A regress√£o log√≠stica n√£o exige as mesmas suposi√ß√µes de normalidade dos dados que o LDA [^7.4].

> ‚ö†Ô∏è **Nota Importante**: A regress√£o log√≠stica utiliza a fun√ß√£o *logit*, uma transforma√ß√£o n√£o linear das probabilidades, para linearizar o problema. Isso permite que um modelo linear seja utilizado para descrever a rela√ß√£o entre as vari√°veis preditoras e as chances relativas das classes [^7.4.1].
> ‚ùó **Ponto de Aten√ß√£o**: Em situa√ß√µes com classes n√£o-balanceadas, ou seja, com uma classe muito mais frequente que a outra, as estimativas de par√¢metros na regress√£o log√≠stica podem ser afetadas e √© importante considerar t√©cnicas de re-balanceamento ou de penaliza√ß√£o para melhorar a generaliza√ß√£o do modelo [^7.4.2].
> ‚úîÔ∏è **Destaque**: Apesar de serem m√©todos distintos, existe uma forte conex√£o entre LDA e regress√£o log√≠stica. Em algumas situa√ß√µes, os resultados obtidos com os dois m√©todos podem ser similares, principalmente quando as classes s√£o bem separadas e as premissas de normalidade do LDA s√£o atendidas [^7.5].

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um problema de classifica√ß√£o bin√°ria onde queremos prever se um paciente tem uma certa doen√ßa (Y=1) ou n√£o (Y=0) com base em duas vari√°veis preditoras $X_1$ (idade) e $X_2$ (√≠ndice de massa corporal - IMC). Ap√≥s treinar o modelo de regress√£o log√≠stica, obtivemos os seguintes coeficientes:
>
> *   $\beta_0 = -5$ (intercepto)
> *   $\beta_1 = 0.1$ (coeficiente para idade)
> *   $\beta_2 = 0.05$ (coeficiente para IMC)
>
>  O modelo log√≠stico √© definido como:
>
> $$
>  \log\left(\frac{p(X)}{1 - p(X)}\right) = -5 + 0.1 X_1 + 0.05 X_2
>  $$
>
> Vamos analisar um paciente com idade $X_1=60$ e IMC $X_2=30$:
>
> $$
>  \log\left(\frac{p(X)}{1 - p(X)}\right) = -5 + 0.1 \times 60 + 0.05 \times 30 = -5 + 6 + 1.5 = 2.5
> $$
>
> Calculando o *odds*:
>
> $$
>  \frac{p(X)}{1 - p(X)} = e^{2.5} \approx 12.18
>  $$
>
> Calculando a probabilidade:
>
> $$
>  p(X) = \frac{12.18}{1 + 12.18} \approx 0.924
>  $$
>
>  Isso indica que a probabilidade deste paciente ter a doen√ßa √© de aproximadamente 92.4%. Se a probabilidade estimada fosse maior que 0.5, classificar√≠amos este paciente como tendo a doen√ßa.
>
>  Agora, vamos analisar um paciente com idade $X_1=30$ e IMC $X_2=25$:
>
> $$
>  \log\left(\frac{p(X)}{1 - p(X)}\right) = -5 + 0.1 \times 30 + 0.05 \times 25 = -5 + 3 + 1.25 = -0.75
> $$
>
> Calculando o *odds*:
>
> $$
>  \frac{p(X)}{1 - p(X)} = e^{-0.75} \approx 0.472
>  $$
>
> Calculando a probabilidade:
>
> $$
>  p(X) = \frac{0.472}{1 + 0.472} \approx 0.32
>  $$
>
> Isso indica que a probabilidade deste paciente ter a doen√ßa √© de aproximadamente 32%. Classificar√≠amos este paciente como n√£o tendo a doen√ßa.

```mermaid
graph LR
    subgraph "Logistic Regression"
        direction LR
        A["Log-Odds (Logit): log(p(X)/(1-p(X)))"]
        B["Linear Combination: Œ≤‚ÇÄ + Œ£Œ≤·µ¢X·µ¢"]
        A --> B
    end
```

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

<imagem: Um diagrama de fluxo que mostra o processo da regress√£o de indicadores para classifica√ß√£o, desde a codifica√ß√£o das classes at√© a regra de decis√£o, com setas indicando a dire√ß√£o do fluxo e caixas que descrevem cada passo do processo, baseado no contexto de [^7.2]>

```mermaid
flowchart TD
  subgraph "Regress√£o de Indicadores"
    A["Codificar Classes em Matriz de Indicadores"] --> B["Estimar Coeficientes por M√≠nimos Quadrados"]
    B --> C["Aplicar Regra de Decis√£o: Classe com maior valor predito"]
    C --> D["Analisar limita√ß√µes e compara√ß√µes com m√©todos probabil√≠sticos"]
  end
```

A regress√£o linear, embora tradicionalmente utilizada para problemas de regress√£o, pode ser adaptada para a classifica√ß√£o por meio da **regress√£o de indicadores** [^7.2]. Nesse m√©todo, as classes categ√≥ricas s√£o codificadas como vari√°veis *dummy* ou *indicator matrix*. Para um problema de classifica√ß√£o com $K$ classes, cria-se uma matriz de indicadores onde cada coluna representa uma classe e as entradas s√£o 1 se o ponto pertence √†quela classe e 0 caso contr√°rio [^7.2]. Em seguida, aplica-se a regress√£o linear padr√£o para prever cada coluna da matriz de indicadores. A classe predita √© aquela que corresponde √† coluna com maior valor predito. Em outras palavras, a regress√£o linear de uma matriz de indicadores modela cada classe individualmente e tenta prever a probabilidade de um dado pertencer a uma certa classe. Apesar de sua simplicidade, a regress√£o de indicadores apresenta algumas limita√ß√µes, como a possibilidade de gerar predi√ß√µes fora do intervalo [0, 1], o que dificulta a interpreta√ß√£o como probabilidades [^7.2]. Al√©m disso, ela pode ser influenciada pela presen√ßa de classes com maior vari√¢ncia, levando a estimativas menos precisas [^7.3].

**Lemma 2:** Se as predi√ß√µes da regress√£o linear nas matrizes indicadoras est√£o restritas a valores dentro do intervalo (0, 1), a fronteira de decis√£o gerada por este m√©todo ser√° linear. Essa linearidade surge como consequ√™ncia da natureza linear do modelo de regress√£o [^7.2]. As proje√ß√µes nos hiperplanos de decis√£o gerados pela regress√£o linear correspondem a proje√ß√µes de discriminantes lineares sob certas condi√ß√µes de normalidade e covari√¢ncias iguais, como no caso do LDA [^7.3]. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um problema de classifica√ß√£o com tr√™s classes (K=3) e apenas uma vari√°vel preditora $X$. Temos os seguintes dados de treinamento:
>
> | Amostra |  X | Classe |
> |---------|----|--------|
> |    1    |  1  |    1   |
> |    2    |  2  |    1   |
> |    3    |  3  |    2   |
> |    4    |  4  |    2   |
> |    5    |  5  |    3   |
> |    6    |  6  |    3   |
>
>  A matriz de indicadores (Y) ser√°:
>
> | Amostra | Classe 1 | Classe 2 | Classe 3 |
> |---------|----------|----------|----------|
> |    1    |     1    |     0    |     0    |
> |    2    |     1    |     0    |     0    |
> |    3    |     0    |     1    |     0    |
> |    4    |     0    |     1    |     0    |
> |    5    |     0    |     0    |     1    |
> |    6    |     0    |     0    |     1    |
>
>  Agora realizamos 3 regress√µes lineares, uma para cada classe, usando a vari√°vel preditora X.  Ap√≥s o treinamento dos tr√™s modelos lineares, obtivemos os seguintes coeficientes (valores ilustrativos):
>
>  *   Modelo para Classe 1: $\hat{y}_1 = 0.8 - 0.1x$
>  *   Modelo para Classe 2: $\hat{y}_2 = -0.2 + 0.2x$
> *   Modelo para Classe 3: $\hat{y}_3 = -0.1 + 0.15x$
>
>  Agora, vamos usar o ponto de teste $X = 3.5$ para prever a classe:
>
>  *   $\hat{y}_1 = 0.8 - 0.1 * 3.5 = 0.45$
>  *   $\hat{y}_2 = -0.2 + 0.2 * 3.5 = 0.5$
>  *   $\hat{y}_3 = -0.1 + 0.15 * 3.5 = 0.425$
>
>  A classe predita para o ponto $X=3.5$ ser√° a classe 2, pois $\hat{y}_2$ possui o maior valor predito.
>
>  Note que os valores preditos n√£o est√£o restritos entre 0 e 1, o que dificulta a interpreta√ß√£o como probabilidade, mas a fronteira de decis√£o √© linear.

```mermaid
graph TB
    subgraph "Linear Regression for Classification"
        direction TB
        A["Indicator Matrix Encoding"]
        B["Separate Linear Regressions for Each Class"]
        C["Prediction: Class with Max Predicted Value"]
        A --> B
        B --> C
    end
```

**Corol√°rio 2:** Quando o n√∫mero de classes √© elevado e as classes est√£o bem separadas no espa√ßo de vari√°veis preditoras, a regress√£o linear de indicadores pode fornecer uma aproxima√ß√£o satisfat√≥ria para a fronteira de decis√£o, mesmo que a regress√£o n√£o tenha modelado corretamente as probabilidades [^7.3]. A simplicidade do m√©todo e sua f√°cil implementa√ß√£o podem ser vantajosas nesses cen√°rios.

"Em alguns cen√°rios, conforme apontado em [^7.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1]."

"No entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^7.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear."

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

<imagem: Mapa mental que conecta os conceitos de sele√ß√£o de vari√°veis, regulariza√ß√£o e seus impactos em modelos classificat√≥rios, mostrando as rela√ß√µes entre L1, L2, Elastic Net e como eles impactam vi√©s, vari√¢ncia e interpretabilidade, com base em [^7.4.4], [^7.5], [^7.5.1