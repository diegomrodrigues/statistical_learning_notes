## Avalia√ß√£o e Sele√ß√£o de Modelos: Foco na Covari√¢ncia entre Valores Ajustados e Verdadeiros

<imagem: Um diagrama complexo mostrando a rela√ß√£o entre diferentes m√©todos de avalia√ß√£o e sele√ß√£o de modelos, incluindo a decomposi√ß√£o de vi√©s-vari√¢ncia, valida√ß√£o cruzada e bootstrap. O diagrama deve ter setas indicando o fluxo de informa√ß√£o entre diferentes m√©todos, e mostrar tamb√©m como esses m√©todos se relacionam com a complexidade do modelo>

```mermaid
graph TD
 subgraph "Model Evaluation and Selection Framework"
  A["Training Data"] --> B("Model Training");
  B --> C("Model Prediction");
  C --> D("Performance Evaluation");
  D --> E("Model Selection");
  E --> F("Final Model");
  D --> G("Bias-Variance Analysis");
  G --> H("Model Complexity Control");
  H --> E;
  B --> I("Cross-Validation / Bootstrap");
  I --> D;
  subgraph "Performance Metrics"
   J("Accuracy");
   K("Precision");
   L("Recall");
   M("F1-Score");
   N("MSE");
   O("Log-Likelihood");
  end
  D --> J;
  D --> K;
    D --> L;
    D --> M;
    D --> N;
    D --> O;
 end
```

### Introdu√ß√£o
A performance de generaliza√ß√£o de um m√©todo de aprendizado refere-se √† sua capacidade preditiva em dados de teste independentes. Avaliar essa performance √© de extrema import√¢ncia na pr√°tica, pois guia a escolha do m√©todo ou modelo de aprendizado, e nos d√° uma medida da qualidade do modelo escolhido [^7.1]. Este cap√≠tulo descreve os m√©todos principais para avalia√ß√£o de performance e demonstra como eles s√£o usados para selecionar modelos. Iniciamos o cap√≠tulo discutindo a intera√ß√£o entre vi√©s, vari√¢ncia e complexidade do modelo [^7.1].

### Conceitos Fundamentais

**Conceito 1: Problema de Classifica√ß√£o e Generaliza√ß√£o**
O problema de classifica√ß√£o envolve, a partir de um conjunto de dados de entrada, identificar a qual categoria cada observa√ß√£o pertence. M√©todos lineares, como LDA e regress√£o log√≠stica, buscam criar uma fronteira de decis√£o linear no espa√ßo de caracter√≠sticas para separar as classes. A performance desses m√©todos √© avaliada pela sua capacidade de generaliza√ß√£o, ou seja, a precis√£o com que classificam dados que n√£o foram usados no treinamento [^7.1]. Um modelo linear com alta complexidade pode se ajustar muito bem aos dados de treinamento (baixo vi√©s), mas generalizar mal para novos dados (alta vari√¢ncia), e vice-versa [^7.2]. O *trade-off* entre vi√©s e vari√¢ncia √© crucial na escolha do modelo ideal.

> üí° **Exemplo Num√©rico:** Imagine um cen√°rio onde temos dados de pacientes (vari√°vel *X*: press√£o arterial, n√≠veis de glicose, etc.) e queremos classificar se eles t√™m ou n√£o diabetes (vari√°vel *Y*). Um modelo muito simples (ex: usando apenas press√£o arterial) pode ter alto vi√©s (subestima a complexidade da rela√ß√£o) e errar muitos diagn√≥sticos, tanto no treino quanto em novos dados. Por outro lado, um modelo muito complexo (ex: usando todas as intera√ß√µes entre todas as vari√°veis) pode ter baixa vi√©s no treino (acerta quase todos no treino), mas pode ter alta vari√¢ncia e errar muito em novos pacientes, pois aprendeu o "ru√≠do" dos dados de treinamento. O ponto ideal √© um modelo com equil√≠brio entre vi√©s e vari√¢ncia, que generaliza bem para pacientes n√£o vistos anteriormente.

**Lemma 1:**  Em um problema de classifica√ß√£o com duas classes, onde a fronteira de decis√£o linear √© definida por uma fun√ß√£o discriminante $f(x) = w^Tx + b$, o erro de classifica√ß√£o pode ser expresso como a probabilidade de um ponto $x$ ser classificado incorretamente, ou seja, $P(Y \neq \hat{Y} | X=x)$, onde $Y$ √© a classe verdadeira e $\hat{Y}$ √© a classe predita.  Em particular, o erro esperado de classifica√ß√£o, que √© o conceito de *test error*, pode ser definido como: $$ Err = E[I(G \neq \hat{G}(X))] $$, onde $G$ √© a classe verdadeira e $\hat{G}(X)$ √© a classe predita [^7.2].
Esta probabilidade depende da distribui√ß√£o das classes e da capacidade da fun√ß√£o discriminante de separar as classes, e a complexidade da fun√ß√£o $f$ impacta diretamente a capacidade de generaliza√ß√£o, dado o trade-off entre vi√©s e vari√¢ncia [^7.2].

**Conceito 2: Linear Discriminant Analysis (LDA)**
LDA assume que as classes possuem distribui√ß√£o normal multivariada com mesma matriz de covari√¢ncia [^7.3]. A ideia central √© projetar os dados em um subespa√ßo de menor dimens√£o que maximize a separabilidade entre as classes [^7.3.1]. A fronteira de decis√£o √© linear e definida pela diferen√ßa entre as m√©dias de classe e a matriz de covari√¢ncia compartilhada [^7.3.2]. Formalmente, a fun√ß√£o discriminante linear de LDA √© dada por:
$$ \delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log \pi_k $$
onde $x$ √© o vetor de entrada, $\mu_k$ √© a m√©dia da classe k, $\Sigma$ √© a matriz de covari√¢ncia comum, e $\pi_k$ √© a probabilidade a priori da classe k [^7.3.3]. LDA busca os par√¢metros que maximizam a dist√¢ncia entre as m√©dias das classes e minimizem a vari√¢ncia dentro de cada classe [^7.3.1].

> üí° **Exemplo Num√©rico:** Suponha que temos duas classes de flores, 'Iris Setosa' (classe 1) e 'Iris Versicolor' (classe 2), com duas caracter√≠sticas medidas: comprimento da s√©pala (X1) e largura da s√©pala (X2). Para classe 1, temos $\mu_1 = [5.0, 3.4]$ e para classe 2, $\mu_2 = [5.9, 2.7]$. A matriz de covari√¢ncia compartilhada √© $\Sigma = \begin{bmatrix} 0.3 & 0.1 \\ 0.1 & 0.2 \end{bmatrix}$.  Assumindo probabilidades a priori iguais ($\pi_1 = \pi_2 = 0.5$), podemos calcular $\Sigma^{-1} = \begin{bmatrix} 4 & -2 \\ -2 & 6 \end{bmatrix}$. Para uma nova flor com $x = [5.5, 3.0]$, a fun√ß√£o discriminante para classe 1 √© $\delta_1(x) = [5.5, 3.0] \cdot \begin{bmatrix} 4 & -2 \\ -2 & 6 \end{bmatrix} \cdot [5.0, 3.4]  - 0.5 \cdot [5.0, 3.4] \cdot \begin{bmatrix} 4 & -2 \\ -2 & 6 \end{bmatrix} \cdot [5.0, 3.4] + \log(0.5) \approx -1.88$, e para a classe 2 $\delta_2(x) \approx -1.76$.  Como $\delta_2(x) > \delta_1(x)$, classificar√≠amos essa flor como 'Iris Versicolor'.
>
> *Calculations:*
>
> $\Sigma^{-1} = \frac{1}{(0.3)(0.2) - (0.1)(0.1)} \begin{bmatrix} 0.2 & -0.1 \\ -0.1 & 0.3 \end{bmatrix} = \begin{bmatrix} 4 & -2 \\ -2 & 6 \end{bmatrix}$
>
> $\delta_1(x) = x^T \Sigma^{-1} \mu_1 - \frac{1}{2} \mu_1^T \Sigma^{-1} \mu_1 + \log \pi_1 = [5.5, 3.0] \cdot \begin{bmatrix} 4 & -2 \\ -2 & 6 \end{bmatrix} \cdot \begin{bmatrix} 5.0 \\ 3.4 \end{bmatrix} - 0.5 \cdot \begin{bmatrix} 5.0 \\ 3.4 \end{bmatrix}^T \cdot \begin{bmatrix} 4 & -2 \\ -2 & 6 \end{bmatrix} \cdot \begin{bmatrix} 5.0 \\ 3.4 \end{bmatrix}  + \log(0.5) = [5.5, 3.0] \cdot \begin{bmatrix} 13.2 \\ 10.4 \end{bmatrix} - 0.5 \cdot [5.0, 3.4]^T \cdot \begin{bmatrix} 13.2 \\ 10.4 \end{bmatrix}  -0.693 = 91.8 - 0.5 \cdot 99.6 - 0.693 = 91.8 - 49.8 - 0.693 = -1.88$
>
>$\delta_2(x) = [5.5, 3.0] \cdot \begin{bmatrix} 4 & -2 \\ -2 & 6 \end{bmatrix} \cdot [5.9, 2.7]  - 0.5 \cdot [5.9, 2.7] \cdot \begin{bmatrix} 4 & -2 \\ -2 & 6 \end{bmatrix} \cdot [5.9, 2.7] + \log(0.5) = [5.5, 3.0] \cdot \begin{bmatrix} 18.2 \\ 4.4 \end{bmatrix} - 0.5 \cdot [5.9, 2.7]^T \cdot \begin{bmatrix} 18.2 \\ 4.4 \end{bmatrix} - 0.693 = 113.3 - 0.5 \cdot 117.4 - 0.693  = 113.3 - 58.7 - 0.693 = -1.76$
>
```mermaid
graph TD
  subgraph "LDA Mathematical Framework"
    A["Input Data: X"] --> B["Estimate Class Means: Œº_k"];
    A --> C["Estimate Covariance Matrix: Œ£"];
    B & C --> D["Compute Discriminant Functions: Œ¥_k(x)"];
      D --> E("Decision Boundary");
    E --> F("Classification");
  end
```

**Corol√°rio 1:**  A fun√ß√£o discriminante linear $\delta_k(x)$ do LDA pode ser vista como uma proje√ß√£o dos dados no espa√ßo definido por $\Sigma^{-1}(\mu_k - \mu_{k'})$ para as classes $k$ e $k'$, seguida por um termo de bias, o que significa que dados classificados no lado positivo de um hiperplano definido por essa proje√ß√£o, ser√£o classificados como classe $k$ e dados no lado negativo como classe $k'$. Isso resulta em uma fronteira de decis√£o linear no espa√ßo de caracter√≠sticas original, demonstrando como a escolha de $\Sigma$ e $\mu$ define a separabilidade e a forma da fronteira [^7.3.1].

**Conceito 3: Logistic Regression**
Na regress√£o log√≠stica, a probabilidade de uma observa√ß√£o pertencer a uma classe √© modelada usando a fun√ß√£o log√≠stica (sigmoid), que transforma uma combina√ß√£o linear das vari√°veis de entrada em uma probabilidade entre 0 e 1 [^7.4]. O log-odds (logit) da probabilidade √© expresso como uma fun√ß√£o linear das vari√°veis de entrada [^7.4.1]. Os par√¢metros do modelo s√£o estimados maximizando a verossimilhan√ßa (likelihood) dos dados [^7.4.3]. A fun√ß√£o de log-verossimilhan√ßa √© dada por:
$$ L(\beta) = \sum_{i=1}^N \left[ y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i)) \right] $$
onde $y_i$ √© a classe verdadeira (0 ou 1) e $p(x_i)$ √© a probabilidade estimada [^7.4.4].
Regress√£o log√≠stica √© adequada quando n√£o se assume normalidade dos dados, ao contr√°rio do LDA [^7.4.5].

> üí° **Exemplo Num√©rico:** Vamos considerar um problema de classifica√ß√£o bin√°ria (classe 0 ou 1). Suponha que temos uma √∫nica vari√°vel preditora *x* e os coeficientes estimados s√£o $\beta_0 = -3$ e $\beta_1 = 2$. Para um dado $x = 2$, o log-odds √© dado por $\text{logit}(p) = -3 + 2*2 = 1$. A probabilidade estimada √© $p = \frac{1}{1 + e^{-1}} \approx 0.73$. Se usarmos um limiar de 0.5, essa observa√ß√£o seria classificada como classe 1.  A verossimilhan√ßa (likelihood) para essa observa√ß√£o seria $L_i = 1 \cdot \log(0.73) + (1-1) \cdot \log(1-0.73) = \log(0.73) \approx -0.31$.  A fun√ß√£o de log-verossimilhan√ßa √© a soma dessas contribui√ß√µes para todos os pontos de dados.
>
> *Calculations:*
>
> $\text{logit}(p) = \beta_0 + \beta_1x = -3 + 2 \cdot 2 = 1$
>
> $p = \frac{1}{1 + e^{-1}} \approx 0.73$
>
> $L_i = y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i)) = 1 \cdot \log(0.73) + 0 \cdot \log(0.27) \approx -0.31$

> ‚ö†Ô∏è **Nota Importante**: A escolha entre LDA e Regress√£o Log√≠stica depende das suposi√ß√µes sobre os dados. LDA funciona bem com dados Gaussianos com mesma covari√¢ncia, enquanto regress√£o log√≠stica √© mais flex√≠vel em rela√ß√£o √† distribui√ß√£o dos dados [^7.4.1].

> ‚ùó **Ponto de Aten√ß√£o**: Modelos de regress√£o log√≠stica podem sofrer com classes desbalanceadas, o que pode levar a estimativas de probabilidades enviesadas. Para lidar com isso, t√©cnicas como re-amostragem ou uso de pesos de classe podem ser empregadas [^7.4.2].

> ‚úîÔ∏è **Destaque**: Apesar de LDA e regress√£o log√≠stica possu√≠rem abordagens distintas, em muitos casos as estimativas dos par√¢metros podem apresentar correla√ß√µes. Ambos geram fronteiras de decis√£o lineares, mas os par√¢metros √≥timos s√£o encontrados atrav√©s de otimiza√ß√µes com fun√ß√µes objetivo diferentes [^7.5].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
```mermaid
graph TD
  subgraph "Indicator Regression Framework"
    A["Input Data and Indicator Matrix"] --> B["Least Squares Estimation"];
    B --> C["Predicted Values and Decision Rule"];
    C --> D["Limitations: Extrapolation and Instability"];
  end
```
**Explica√ß√£o:** O diagrama descreve o processo de regress√£o de indicadores para classifica√ß√£o, onde as classes s√£o codificadas em uma matriz de indicadores, os coeficientes s√£o estimados por m√≠nimos quadrados e as classes s√£o atribu√≠das de acordo com o maior valor predito. S√£o indicadas tamb√©m as limita√ß√µes deste processo, como extrapola√ß√£o fora de [0,1] e instabilidade [^7.2].

A regress√£o linear pode ser aplicada a problemas de classifica√ß√£o usando uma matriz de indicadores, que codifica cada classe como uma coluna bin√°ria [^7.2]. O m√©todo de m√≠nimos quadrados (least squares - LS) √© usado para estimar os coeficientes da regress√£o. As classes s√£o ent√£o atribu√≠das de acordo com o maior valor predito pela regress√£o linear [^7.2]. No entanto, essa abordagem possui limita√ß√µes. Os valores preditos podem extrapolar para fora do intervalo [0,1], o que n√£o faz sentido para probabilidades [^7.2]. Al√©m disso, em alguns casos a regress√£o de indicadores pode levar a instabilidade nas estimativas dos par√¢metros, principalmente quando h√° colinearidade entre as vari√°veis de entrada [^7.3]. A regress√£o de indicadores assume que a rela√ß√£o entre as vari√°veis independentes e a vari√°vel resposta √© linear, o que nem sempre √© verdade em problemas de classifica√ß√£o complexos [^7.2]. A regress√£o de indicadores busca minimizar a soma dos quadrados dos res√≠duos (dist√¢ncia entre o valor observado e o valor predito), o que n√£o √© o ideal quando se deseja minimizar o erro de classifica√ß√£o [^7.2].

> üí° **Exemplo Num√©rico:** Suponha que temos tr√™s classes (A, B, C) e duas vari√°veis preditoras (x1 e x2). Usamos codifica√ß√£o de indicadores para criar tr√™s colunas de resposta (Y_A, Y_B, Y_C), onde cada coluna indica a presen√ßa (1) ou aus√™ncia (0) da classe correspondente. Para uma observa√ß√£o com x1=1 e x2=2, as classes s√£o codificadas como:
>
> | Obs | x1 | x2 | Classe | Y_A | Y_B | Y_C |
> |---|---|---|---|---|---|---|
> | 1   | 1 | 2 | A | 1 | 0 | 0 |
> | 2   | 2 | 3 | B | 0 | 1 | 0 |
> | 3   | 3 | 4 | C | 0 | 0 | 1 |
>
> Aplicando a regress√£o linear com m√≠nimos quadrados, obtemos os coeficientes para cada coluna de resposta. Para classificar uma nova observa√ß√£o, calculamos o valor predito para cada coluna de resposta e escolhemos a classe correspondente √† coluna com o maior valor. Uma limita√ß√£o √© que podemos obter valores preditos fora do intervalo [0,1], perdendo a interpreta√ß√£o de probabilidade.

**Lemma 2:** Se considerarmos um problema de classifica√ß√£o com duas classes e codificarmos as classes como $Y \in \{0, 1\}$, a regress√£o linear da matriz de indicadores equivale a encontrar um hiperplano que melhor separa as classes no sentido de m√≠nimos quadrados. Em outras palavras, os coeficientes estimados pela regress√£o linear definem a dire√ß√£o normal do hiperplano e um offset. As proje√ß√µes dos pontos no hiperplano geram os valores preditos. Essa equival√™ncia formal entre a regress√£o linear e a constru√ß√£o de um hiperplano de decis√£o linear demonstra como esses m√©todos, aparentemente distintos, podem convergir para resultados similares em certas condi√ß√µes [^7.2].

**Corol√°rio 2:** Sob condi√ß√µes de separabilidade linear, as solu√ß√µes da regress√£o linear e do discriminante linear convergem para o mesmo hiperplano de decis√£o.  Isso indica que a regress√£o de indicadores pode ser utilizada para encontrar a fronteira de decis√£o, com a ressalva de que a estimativa das probabilidades pode ser inst√°vel, como descrito em [^7.2]

"Em alguns cen√°rios, conforme apontado em [^7.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1]."

"No entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^7.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear."

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

<imagem: Um mapa mental abrangente que conecta a sele√ß√£o de vari√°veis, regulariza√ß√£o, LDA, regress√£o log√≠stica e hiperplanos separadores, mostrando como esses conceitos se relacionam com o objetivo de construir um modelo de classifica√ß√£o robusto. O mapa mental deve incluir penalidades L1 e L2 e o impacto na complexidade do modelo>
```mermaid
graph TD
    subgraph "Regularization Techniques"
        direction TB
        A["Log-Likelihood Function: L(Œ≤)"]
        B["L1 Penalty Term: Œª‚àë|Œ≤_j|"]
        C["L2 Penalty Term: Œª‚àëŒ≤_j¬≤"]
        A --> B
        A --> C
        B --> D["Regularized Objective Function (L1)"]
        C --> E["Regularized Objective Function (L2)"]
        D --> F["Sparse Solution: Feature Selection"]
        E --> G["Stable Solution: Shrinkage"]
        F & G --> H["Model Complexity Control"]
    end
```
A sele√ß√£o de vari√°veis e regulariza√ß√£o s√£o t√©cnicas essenciais para controlar a complexidade do modelo e evitar o *overfitting*. A regulariza√ß√£o adiciona um termo de penalidade √† fun√ß√£o de custo, que pune modelos com coeficientes muito grandes [^7.4.4]. A penalidade L1 promove a esparsidade dos coeficientes, ou seja, alguns coeficientes s√£o reduzidos a zero, realizando a sele√ß√£o de vari√°veis de maneira impl√≠cita [^7.5]. A penalidade L2 reduz os coeficientes, mas n√£o os zera, tornando o modelo mais est√°vel [^7.5]. Em modelos log√≠sticos, a penalidade √© adicionada √† fun√ß√£o de log-verossimilhan√ßa [^7.4.4].

**Lemma 3:** Dada a fun√ß√£o de log-verossimilhan√ßa para regress√£o log√≠stica, $$ L(\beta) = \sum_{i=1}^N \left[ y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i)) \right] $$,  a penalidade L1 (lasso) adiciona um termo proporcional √† norma L1 dos coeficientes:
$$ L_{L1}(\beta) = L(\beta) - \lambda \sum_{j=1}^p |\beta_j| $$
Onde $\lambda$ √© o par√¢metro de regulariza√ß√£o que controla o n√≠vel de penaliza√ß√£o. A solu√ß√£o desse problema de otimiza√ß√£o tende a gerar coeficientes esparsos, pois a penalidade L1 for√ßa alguns coeficientes a serem exatamente zero [^7.4.4].

> üí° **Exemplo Num√©rico:** Suponha que temos uma regress√£o log√≠stica com duas vari√°veis preditoras ($x_1$ e $x_2$) e o vetor de coeficientes estimado por m√°xima verossimilhan√ßa √© $\beta = [2, -3]$.  Se aplicarmos a regulariza√ß√£o L1 com $\lambda = 1$, a nova fun√ß√£o a ser minimizada √© $L_{L1}(\beta) = L(\beta) - 1 \cdot (|2| + |-3|) = L(\beta) - 5$.  Para um valor maior de $\lambda$ como $\lambda=5$ a penaliza√ß√£o seria $L_{L1}(\beta) = L(\beta) - 5 \cdot (|2| + |-3|) = L(\beta) - 25$. A minimiza√ß√£o desta fun√ß√£o tender√° a levar os coeficientes para zero. Se $\lambda$ fosse grande o suficiente (e dependendo do valor de $L(\beta)$) algum dos coeficientes poderia ser exatamente zero, por exemplo se o coeficiente de $x_2$ fosse igual a zero ($\beta = [2, 0]$), a penaliza√ß√£o seria $L_{L1}(\beta) = L(\beta) - 1 \cdot (|2| + |0|) = L(\beta) - 2$ quando $\lambda = 1$. Isso representa a sele√ß√£o de vari√°veis, onde o modelo ignora a vari√°vel $x_2$.
>
> *Calculations:*
>
> $L_{L1}(\beta) = L(\beta) - \lambda \sum_{j=1}^p |\beta_j|$
>
> For $\lambda=1$, $L_{L1}(\beta) = L(\beta) - 1 \cdot (|2| + |-3|) = L(\beta) - 5$.
>
> For $\lambda=5$, $L_{L1}(\beta) = L(\beta) - 5 \cdot (|2| + |-3|) = L(\beta) - 25$.
>

**Prova do Lemma 3:** A penaliza√ß√£o L1 induz esparsidade porque seu contorno de n√≠vel tem v√©rtices em $\beta=0$. A otimiza√ß√£o da fun√ß√£o com penalidade L1 tende a encontrar solu√ß√µes nesses v√©rtices, zerando os coeficientes correspondentes. Em contraste, a penalidade L2 tem contornos suaves e tende a reduzir os coeficientes sem zer√°-los completamente [^7.4.4]  $\blacksquare$

**Corol√°rio 3:** A esparsidade dos coeficientes obtida pela regulariza√ß√£o L1 facilita a interpreta√ß√£o do modelo, pois destaca as vari√°veis mais relevantes para a classifica√ß√£o. Em outras palavras, a regulariza√ß√£o L1 faz uma sele√ß√£o impl√≠cita das vari√°veis mais importantes, levando a modelos mais simples e interpret√°veis [^7.4.5].

> ‚ö†Ô∏è **Ponto Crucial**:  A combina√ß√£o das penalidades L1 e L2, conhecida como Elastic Net, oferece um balanceamento entre a esparsidade e a estabilidade, sendo uma op√ß√£o flex√≠vel na constru√ß√£o de modelos classificat√≥rios [^7.5].

### Separating Hyperplanes e Perceptrons

A busca por um hiperplano √≥timo de separa√ß√£o entre classes leva ao conceito de margem m√°xima [^7.5.2]. O hiperplano √≥timo √© aquele que maximiza a dist√¢ncia entre as classes, medindo a margem de seguran√ßa na classifica√ß√£o. O problema da maximiza√ß√£o da margem pode ser formulado como um problema de otimiza√ß√£o quadr√°tica que pode ser resolvido usando o dual de Wolfe [^7.5.2]. A solu√ß√£o para esse problema define os pontos de suporte (support vectors), que s√£o os dados mais importantes para definir o hiperplano [^7.5.2]. O *Perceptron* de Rosenblatt √© um algoritmo que busca encontrar um hiperplano de decis√£o linear, atualizando os pesos iterativamente baseado na classifica√ß√£o incorreta dos dados de treinamento. A converg√™ncia do Perceptron √© garantida quando os dados s√£o linearmente separ√°veis [^7.5.1].

> üí° **Exemplo Num√©rico:** Suponha que temos um conjunto de dados bidimensional com duas classes, onde alguns pontos da classe A s√£o (1,1), (2,1), (1,2) e pontos da classe B s√£o (3,3), (4,2), (4,3). Inicializamos um hiperplano com pesos aleat√≥rios, por exemplo, $w = [0.1, 0.2]$ e bias $b = -0.5$. Aplicamos o Perceptron com uma taxa de aprendizagem de 0.1. Para o ponto (1,1) da classe A, o valor da fun√ß√£o linear √© $0.1*1 + 0.2*1 - 0.5 = -0.2$, o que indica que esse ponto √© classificado incorretamente, pois esper√°vamos um valor maior que 0. Atualizamos os pesos $w = w + \text{lr} * x_i = [0.1, 0.2] + 0.1*[1, 1] = [0.2, 0.3]$ e o bias $b = b + \text{lr} * 1 = -0.5 + 0.1 = -0.4$. Repetimos esse processo para todos os pontos e iteramos at√© que todos sejam classificados corretamente. A margem m√°xima seria dada pelo hiperplano que maximiza a dist√¢ncia entre os pontos de cada classe.
```mermaid
graph TD
    subgraph "Perceptron Algorithm"
        direction TB
        A["Initialize Weights: w and bias: b"]
        B["For each training sample: x_i"]
        B --> C["Calculate linear function: w^T x_i + b"]
        C --> D["Classify: if (w^T x_i + b) > 0 assign to class 1 else class 0"]
       D --> E["If classification is incorrect"]
        E --> F["Update weights: w = w + lr * x_i"]
          E --> G["Update bias: b = b + lr * y_i"]
        F --> B
        G --> B
    end
```

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**
A regra de decis√£o Bayesiana, sob o pressuposto de distribui√ß√µes Gaussianas, aloca uma observa√ß√£o √† classe que maximiza a probabilidade *a posteriori* da classe dado os dados, isto √©, $P(G = k | X = x)$.  Assumindo covari√¢ncias iguais para todas as classes, essa probabilidade pode ser expressa como: $$P(G = k | X = x) \propto \pi_k \exp \left( -\frac{1}{2}(x - \mu_k)^T \Sigma^{-1} (x - \mu_k) \right)$$, onde $\pi_k$ √© a probabilidade *a priori* da classe $k$, $\mu_k$ √© a m√©dia da classe $k$ e $\Sigma$ √© a matriz de covari√¢ncia comum a todas as classes [^7.3].
Por outro lado, o LDA constr√≥i uma fun√ß√£o discriminante linear para cada classe: $$ \delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log \pi_k $$. Ao compararmos as duas abordagens, vemos que ambas se baseiam na mesma estrutura de par√¢metros ($ \pi_k$, $\mu_k$ e $\Sigma$) e, quando o objetivo √© encontrar as regi√µes que maximizam a *a posteriori*, ambas convergem para o mesmo limite de decis√£o linear [^7.3]. A diferen√ßa fundamental est√° na forma como essa decis√£o √© tomada. Enquanto a regra Bayesiana compara diretamente as probabilidades *a posteriori*, o LDA usa uma fun√ß√£o discriminante linear que, por sua vez, leva √† mesma regi√£o de decis√£o. As suposi√ß√µes sobre a distribui√ß√£o dos dados e igualdade de covari√¢ncia s√£o importantes, pois definem o tipo de fronteira de decis√£o linear obtida em ambos os m√©todos [^7.3.1].

**Lemma 4:** Sob a hip√≥tese de distribui√ß√µes Gaussianas e covari√¢ncias iguais, a regra de decis√£o Bayesiana e o LDA levam √† mesma fronteira de decis√£o linear. A regra de decis√£o Bayesiana seleciona a classe $k$ que maximiza a probabilidade a posteriori, enquanto LDA seleciona a classe $k$ com maior discriminante linear [^7.3], [^7.3.3].  A condi√ß√£o necess√°ria para essa equival√™ncia √© que as fun√ß√µes discriminantes do LDA s√£o uma transforma√ß√£o mon√≥tona das probabilidades *a posteriori* bayesianas [^7.3.3].
```mermaid
graph TD
    subgraph "Bayesian Decision vs LDA"
        direction TB
        A["Bayesian Decision: P(G=k|X=x) ‚àù œÄ_k * exp(-(1/2)(x-Œº_k)^T Œ£^-1 (x-Œº_k))"]
          A --> B("Maximize Posterior Probability");
        C["LDA Discriminant: Œ¥_k(x) = x^T Œ£^-1 Œº_k - (1/2)Œº_k^T Œ£^-1 Œº_k + log(œÄ_k)"]
          C --> D("Select Class with Max Discriminant");
            B --> E("Same Decision Boundary under Gaussian and Equal Covariance Assumptions")
            D --> E
     end
```

**Corol√°rio 4:** Quando a hip√≥tese de igualdade de covari√¢ncias √© relaxada, a regra de decis√£o Bayesiana leva √† fronteira de decis√£o quadr√°tica (QDA), dada por:
$$ \delta_k(x) = -\frac{1}{2} \log|\Sigma_k| -\frac{1}{2}(x - \mu_k)^T \Sigma_k^{-1} (x - \mu_k) + \log \pi_k $$
onde $\Sigma_k$ √© a matriz de covari√¢ncia para a classe $k$ [^7.3]. QDA permite maior flexibilidade na modelagem da distribui√ß√£o das classes, mas tamb√©m maior n√∫mero de par√¢metros a serem estimados [^7.3].

> ‚ö†Ô∏è **Ponto Crucial**: A escolha da abordagem, seja LDA com fronteira linear ou QDA com fronteira quadr√°tica, depende de qu√£o apropriada √© a hip√≥tese de igualdade de covari√¢ncias para o problema em quest√£o [^7.3.1]. A escolha afeta diretamente a complexidade do modelo e sua capacidade de generaliza√ß√£o.

### Conclus√£o
Este cap√≠tulo abordou os conceitos fundamentais de avalia√ß√£o e sele√ß√£o de modelos, com foco na classifica√ß√£o, e a rela√ß√£o com a covari√¢ncia entre valores ajustados e verdadeiros. Exploramos as abordagens lineares, como LDA e regress√£o log√≠stica, a import√¢ncia da regulariza√ß√£o e sele√ß√£o de vari√°veis, bem como o conceito de *separating hyperplanes* e o algoritmo Perceptron. Examinamos as diferen√ßas entre abordagens frequentistas e bayesianas, com destaque para crit√©rios como AIC e BIC e exploramos a import√¢ncia da valida√ß√£o cruzada para estimativa da performance de modelos. Abordamos em detalhes como modelar e avaliar a performance de generaliza√ß√£o de modelos em diferentes situa√ß√µes pr√°ticas. As t√©cnicas aqui descritas fornecem um embasamento s√≥lido para a constru√ß√£o de modelos de classifica√ß√£o robustos e confi√°veis.
<!-- END DOCUMENT -->

### Footnotes
[^7.1]: "The generalization performance of a learning method relates to its prediction capability on independent test data. Assessment of this performance is extremely important in practice, since it guides the choice of learning method or model, and gives us a measure of the quality of the ultimately chosen model." *(Trecho de Model Assessment and Selection)*
[^7.2]: "Figure 7.1 illustrates the important issue in assessing the ability of a learning method to generalize. Consider first the case of a quantitative or interval scale response. We have a target variable Y, a vector of inputs X, and a prediction model f(X) that has been estimated from a training set T." *(Trecho de Model Assessment and Selection)*
[^7.3]:  "The story is similar for a qualitative or categorical response G taking one of K values in a set G, labeled for convenience as 1, 2, ..., K. Typically we model the probabilities pk(X) = Pr(G = k|X) (or some monotone transformations fr(X)), and then ƒú(X) = arg maxk √ék(X)." *(Trecho de Model Assessment and Selection)*
[^7.3.1]: "For a linear model family such as ridge regression, we can break down the bias more finely. Let Œ≤ denote the parameters of the best-fitting linear approximation to f:" *(Trecho de Model Assessment and Selection)*
[^7.3.2]: "If we are in a data-rich situation, the best approach for both problems is to randomly divide the dataset into three parts: a training set, a validation set, and a test set." *(Trecho de Model Assessment and Selection)*
[^7.3.3]: "In this chapter we describe a number of methods for estimating the expected test error for a model. Typically our model will have a tuning parameter or parameters a and so we can write our predictions as fa(x)." *(Trecho de Model Assessment and Selection)*
[^7.4]: "The log-likelihood can be used as a loss-function for general response densities, such as the Poisson, gamma, exponential, log-normal and others." *(Trecho de Model Assessment and Selection)*
[^7.4.1]: "Note that this expectation averages over everything that is random, including the randomness in the training set that produced f." *(Trecho de Model Assessment and Selection)*
[^7.4.2]: "The quantity -2 √ó the log-likelihood is sometimes referred to as the deviance." *(Trecho de Model Assessment and Selection)*
[^7.4.3]: "Training error is the sample analogue, for example, 
N
2
err
2=1
Œ£log pg; (Xi),
the sample log-likelihood for the model." *(Trecho de Model Assessment and Selection)*
[^7.4.4]: "The methods in this chapter are designed for situations where there is insufficient data to split it into three parts." *(Trecho de Model Assessment and Selection)*
[^7.4.5]: "Again it is too difficult to give a general rule on how much training data is enough; among