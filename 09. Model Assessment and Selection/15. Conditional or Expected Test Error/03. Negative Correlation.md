## Avalia√ß√£o e Sele√ß√£o de Modelos com Correla√ß√£o Negativa

```mermaid
graph TD
 subgraph "Model Evaluation Process"
    A["Data"] --> B["Model Training"]
    B --> C["Model Evaluation"]
    C --> D{"Model Selection"}
    D -->| "Best Model" | E["Final Model"]
    C -->| "Performance Metrics" | F["Bias, Variance, Complexity"]
    F --> D
 end
```

### Introdu√ß√£o

A avalia√ß√£o da performance de um m√©todo de aprendizado estat√≠stico √© crucial para determinar sua capacidade de generaliza√ß√£o, ou seja, sua habilidade em fazer previs√µes precisas em dados n√£o vistos [^7.1]. A pr√°tica de avaliar modelos √© essencial, pois direciona a escolha do m√©todo de aprendizado, do modelo e nos fornece uma medida da qualidade do modelo selecionado [^7.1]. Este cap√≠tulo aborda os m√©todos chave para avaliar o desempenho do modelo, mostrando como s√£o usados para selecionar modelos e discute a intera√ß√£o entre **bias**, **vari√¢ncia** e a **complexidade do modelo**.

### Conceitos Fundamentais

**Conceito 1:** O problema de classifica√ß√£o envolve a atribui√ß√£o de um objeto a uma categoria ou classe pr√©-definida. Modelos lineares, como a Regress√£o Log√≠stica e a An√°lise Discriminante Linear (LDA), s√£o usados para construir fronteiras de decis√£o linear que separam as classes. No entanto, existe um trade-off entre o vi√©s (*bias*) e a vari√¢ncia, onde modelos simples (com maior vi√©s) podem n√£o capturar padr√µes complexos nos dados, enquanto modelos complexos (com maior vari√¢ncia) podem se ajustar excessivamente ao ru√≠do, levando a uma m√° generaliza√ß√£o [^7.2]. O uso de m√©todos lineares pode levar a um vi√©s se a rela√ß√£o entre as vari√°veis preditoras e a resposta n√£o for linear. A complexidade do modelo √© ajustada para minimizar o erro de previs√£o em dados n√£o vistos.

> üí° **Exemplo Num√©rico:** Suponha que temos um conjunto de dados com uma rela√ß√£o n√£o-linear entre a vari√°vel preditora (X) e a vari√°vel de resposta (Y), onde Y = X¬≤ + Œµ, com Œµ representando um ru√≠do aleat√≥rio. Se tentarmos ajustar um modelo linear Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX, teremos um alto vi√©s porque o modelo linear n√£o consegue capturar a curvatura da rela√ß√£o. Por outro lado, um modelo muito complexo, como um polin√¥mio de grau 10, pode se ajustar perfeitamente aos dados de treinamento, incluindo o ru√≠do, e ter alta vari√¢ncia, levando a erros grandes em dados n√£o vistos. O ideal seria um modelo que capture a tend√™ncia principal sem ajustar demais o ru√≠do, como um polin√¥mio de grau 2.

**Lemma 1:** *A fun√ß√£o discriminante linear, que determina a fronteira de decis√£o em LDA, pode ser expressa como uma combina√ß√£o linear das caracter√≠sticas, ou seja, $f(x) = w^Tx + b$ , onde $w$ s√£o os pesos e $b$ o termo de vi√©s*. A demonstra√ß√£o deste lemma se baseia na formula√ß√£o de LDA, conforme descrito em [^7.3], onde a proje√ß√£o dos dados em um subespa√ßo de menor dimens√£o preserva a separabilidade das classes. Isso ocorre devido a LDA otimizar a separa√ß√£o das m√©dias das classes, minimizando a vari√¢ncia dentro de cada classe e maximizando a dist√¢ncia entre as m√©dias [^7.3.1].

```mermaid
graph LR
    subgraph "Linear Discriminant Analysis (LDA)"
        A["Data Points"] --> B["Projection to Subspace"]
        B --> C["Maximizing Class Separation"]
        C --> D["Linear Discriminant Function: f(x) = wTx + b"]
        C --> E["Minimizing Within-Class Variance"]
        C --> F["Maximizing Between-Class Mean Distance"]
    end
```

**Conceito 2:** A **Linear Discriminant Analysis (LDA)** √© uma t√©cnica de classifica√ß√£o que assume que as classes t√™m distribui√ß√µes gaussianas com a mesma matriz de covari√¢ncia [^7.3]. A LDA encontra uma combina√ß√£o linear das vari√°veis preditoras que maximiza a separa√ß√£o entre as m√©dias das classes, minimizando a vari√¢ncia dentro de cada classe [^7.3.2]. A fronteira de decis√£o linear √© definida pelo ponto onde as probabilidades posteriores das classes s√£o iguais, levando a uma classifica√ß√£o. No entanto, a LDA tem limita√ß√µes se as suposi√ß√µes de normalidade ou igualdade de covari√¢ncia forem violadas [^7.3.3].

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com duas classes, "A" e "B", e duas vari√°veis preditoras, x‚ÇÅ e x‚ÇÇ. Vamos supor que, ap√≥s aplicar LDA, obtivemos a fun√ß√£o discriminante $f(x) = 0.5x_1 + 1.2x_2 - 2$. Pontos para os quais $f(x) > 0$ s√£o classificados como classe "A", e pontos com $f(x) < 0$ s√£o classificados como classe "B". A fronteira de decis√£o √© dada por $0.5x_1 + 1.2x_2 - 2 = 0$. Se um novo ponto tem coordenadas (x‚ÇÅ, x‚ÇÇ) = (2, 1), ent√£o $f(2, 1) = 0.5*2 + 1.2*1 - 2 = -0.3$. Logo, este ponto seria classificado como classe "B".

**Corol√°rio 1:** *A fun√ß√£o discriminante linear na LDA, $\delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + log(\pi_k)$, pode ser reescrita em termos da proje√ß√£o de x no subespa√ßo definido por $\Sigma^{-1}(\mu_1 - \mu_k)$, demonstrando que a decis√£o de classe √© feita baseada na proximidade da proje√ß√£o do ponto nas proje√ß√µes das m√©dias das classes*, onde $\mu_k$ √© a m√©dia da classe k, $\Sigma$ √© a matriz de covari√¢ncia comum e $\pi_k$ √© a probabilidade a priori da classe k [^7.3.1].

```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        A["Input Data: x"]
        B["Class Mean: Œºk"]
        C["Covariance Matrix: Œ£"]
        D["Prior Probability: œÄk"]
        A --> E["Projection: xTŒ£‚Åª¬πŒºk"]
        B --> F["Term: -1/2ŒºkTŒ£‚Åª¬πŒºk"]
        D --> G["Term: log(œÄk)"]
        E & F & G --> H["Discriminant Score: Œ¥k(x)"]
        H --> I["Decision based on max(Œ¥k(x))"]
    end
```

**Conceito 3:** A **Regress√£o Log√≠stica** modela a probabilidade de um evento bin√°rio atrav√©s de uma fun√ß√£o log√≠stica (sigmoid) da combina√ß√£o linear das vari√°veis preditoras [^7.4]. O modelo log√≠stico transforma probabilidades usando o *logit* (log-odds), que √© ent√£o modelado por uma combina√ß√£o linear das vari√°veis preditoras [^7.4.1]. A estimativa dos par√¢metros √© realizada por meio da maximiza√ß√£o da verossimilhan√ßa, ou seja, ajustando os pesos de forma que os resultados preditos pelo modelo se aproximem ao m√°ximo dos dados observados [^7.4.2]. A regress√£o log√≠stica √© usada quando a vari√°vel de resposta √© bin√°ria ou categ√≥rica e n√£o exige as suposi√ß√µes de normalidade como a LDA [^7.4.3], [^7.4.4], [^7.4.5]. A regress√£o log√≠stica e a LDA t√™m conex√µes, especialmente em problemas de classifica√ß√£o com duas classes e dados com distribui√ß√µes gaussianas. Em muitos casos, a fronteira de decis√£o linear obtida por esses dois m√©todos pode ser semelhante [^7.5].

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo de regress√£o log√≠stica com uma vari√°vel preditora x e a probabilidade de sucesso (classe 1) modelada como $p(x) = \frac{1}{1 + e^{-(0.8 + 0.5x)}}$. Se $x=2$, ent√£o $p(2) = \frac{1}{1 + e^{-(0.8 + 0.5*2)}} \approx 0.769$. Isso significa que, para um valor de x igual a 2, a probabilidade estimada de o ponto pertencer √† classe 1 √© aproximadamente 77%. O *logit* neste caso √© $0.8 + 0.5x$.

> ‚ö†Ô∏è **Nota Importante**: A escolha entre LDA e Regress√£o Log√≠stica depende das suposi√ß√µes sobre a distribui√ß√£o dos dados e do objetivo do modelo. Enquanto LDA assume distribui√ß√µes gaussianas com covari√¢ncias iguais, a Regress√£o Log√≠stica √© mais flex√≠vel em rela√ß√£o a essas suposi√ß√µes [^7.4.1].

> ‚ùó **Ponto de Aten√ß√£o**: Em datasets com classes n√£o-balanceadas, a regress√£o log√≠stica pode ser mais robusta do que LDA, especialmente se h√° preocupa√ß√£o com o ajuste excessivo da classe majorit√°ria [^7.4.2].

> ‚úîÔ∏è **Destaque**: As estimativas dos par√¢metros nos modelos de LDA e regress√£o log√≠stica s√£o similares em certos cen√°rios, especialmente quando a diferen√ßa entre as m√©dias das classes √© grande em rela√ß√£o √† vari√¢ncia, o que pode levar a modelos com fronteiras de decis√£o semelhantes [^7.5].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
flowchart TD
  subgraph "Linear Regression for Classification"
    A["Encode Classes as Indicator Variables"] --> B["Fit Linear Model via Least Squares"]
    B --> C["Prediction based on Largest Output"]
    C --> D["Comparison with Probabilistic Methods (LDA, Logistic Regression)"]
  end
```

**Explica√ß√£o:** Este diagrama representa o fluxo do processo de regress√£o de indicadores e como ele se relaciona √† classifica√ß√£o, conforme descrito nos t√≥picos [^7.2].

A regress√£o linear aplicada a uma matriz de indicadores √© uma abordagem para classifica√ß√£o onde as classes s√£o codificadas como vari√°veis bin√°rias (0 ou 1) e ent√£o um modelo de regress√£o linear √© ajustado a essas vari√°veis de resposta [^7.2]. Embora essa abordagem seja simples, ela possui algumas limita√ß√µes, como a possibilidade de extrapola√ß√µes fora do intervalo de [0,1] e n√£o modelar diretamente as probabilidades das classes [^7.1], [^7.2]. Por exemplo, em um problema com tr√™s classes, cada classe seria representada por uma coluna na matriz de indicadores. Um modelo linear √© ajustado para cada coluna, e a classe predita √© aquela com a maior resposta linear.

> üí° **Exemplo Num√©rico:** Vamos supor que temos um problema de classifica√ß√£o com tr√™s classes, A, B e C, e duas vari√°veis preditoras x‚ÇÅ e x‚ÇÇ. Podemos criar uma matriz de indicadores com tr√™s colunas, uma para cada classe.  A matriz de indicadores para um √∫nico ponto $(x_1, x_2)$ que pertence √† classe B seria:
>
> ```
> | Classe A | Classe B | Classe C |
> |----------|----------|----------|
> |    0     |     1    |    0     |
> ```
> Ap√≥s aplicar regress√£o linear, teremos 3 modelos:
>
> $\hat{y}_A = \beta_{0A} + \beta_{1A}x_1 + \beta_{2A}x_2$
>
> $\hat{y}_B = \beta_{0B} + \beta_{1B}x_1 + \beta_{2B}x_2$
>
> $\hat{y}_C = \beta_{0C} + \beta_{1C}x_1 + \beta_{2C}x_2$
>
>  A classe predita para um novo ponto $(x_1, x_2)$ seria aquela que resulta no maior valor entre $\hat{y}_A, \hat{y}_B$ e $\hat{y}_C$.

No entanto, o problema de "masking", onde uma classe pode ser encoberta por outra devido a um erro de modelo ou a alta colinearidade entre os preditores, √© uma limita√ß√£o importante da regress√£o de indicadores, especialmente com m√∫ltiplas classes [^7.3]. Em LDA e outros m√©todos, a estrutura de covari√¢ncia entre as classes √© levada em conta explicitamente, o que ajuda a mitigar este problema.

**Lemma 2:** *Em certas condi√ß√µes, especialmente em problemas com duas classes, as proje√ß√µes nos hiperplanos de decis√£o geradas por regress√£o linear em uma matriz de indicadores s√£o equivalentes √† proje√ß√£o gerada por um classificador discriminante linear.* A prova desse lemma envolve mostrar que a regress√£o linear pode ser vista como uma proje√ß√£o de pontos em um espa√ßo de alta dimens√£o para um hiperplano, e que, sob certas condi√ß√µes (como igualdade de covari√¢ncia e normalidade dos dados), essa proje√ß√£o √© equivalente √† proje√ß√£o da LDA. [^7.2]

**Corol√°rio 2:** *Se a estrutura de covari√¢ncia das classes for id√™ntica, ent√£o a regress√£o linear para classifica√ß√£o se torna equivalente a um classificador discriminante linear, e a an√°lise da regress√£o linear pode ser simplificada usando os resultados da an√°lise discriminante* [^7.3]. Isso implica que em cen√°rios onde a suposi√ß√£o de covari√¢ncias iguais √© v√°lida, a regress√£o linear pode ser suficiente para definir as fronteiras de decis√£o linear.

Em alguns casos, como mencionado em [^7.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis ‚Äã‚Äãde probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora do intervalo [0,1]. No entanto, como indicado em [^7.2], a regress√£o de indicadores √© suficiente quando o foco √© na fronteira de decis√£o linear.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
 subgraph "Regularization in Logistic Regression"
    A["Logistic Regression Model"] --> B["Cost Function (Log-Likelihood)"]
    B --> C{"Add Regularization Term"}
    C -- "L1 (Lasso)" --> D["Cost Function + Œª‚àë|Œ≤|"]
    C -- "L2 (Ridge)" --> E["Cost Function + Œª‚àëŒ≤¬≤"]
    C -- "Elastic Net" --> F["Cost Function + Œª‚ÇÅ‚àë|Œ≤| + Œª‚ÇÇ‚àëŒ≤¬≤"]
    D --> G["Sparsity, Variable Selection"]
    E --> H["Coefficient Shrinkage, Stability"]
    F --> I["Combination of Sparsity and Stability"]
 end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o cruciais em problemas de classifica√ß√£o, principalmente quando o n√∫mero de vari√°veis preditoras √© alto, ou quando a colinearidade entre as vari√°veis pode levar √† instabilidade das estimativas [^7.5]. Em modelos log√≠sticos, a regulariza√ß√£o √© feita atrav√©s da adi√ß√£o de termos de penalidade √† fun√ß√£o de verossimilhan√ßa [^7.4.4]. As penalidades L1 (Lasso) e L2 (Ridge) s√£o as mais comuns [^7.5.1].

A penalidade L1 adiciona um termo proporcional √† soma dos valores absolutos dos coeficientes, o que leva a solu√ß√µes esparsas, onde muitos dos coeficientes s√£o zerados [^7.4.4]. Isso promove a sele√ß√£o de vari√°veis mais relevantes e simplifica o modelo [^7.5]. Por outro lado, a penalidade L2 adiciona um termo proporcional √† soma dos quadrados dos coeficientes, o que leva a um encolhimento dos coeficientes, reduzindo o impacto de vari√°veis colineares e melhorando a estabilidade das estimativas [^7.5.2].

> üí° **Exemplo Num√©rico:** Vamos considerar um modelo de regress√£o log√≠stica com tr√™s vari√°veis preditoras: $x_1$, $x_2$ e $x_3$.
>
> **Sem Regulariza√ß√£o:** A fun√ß√£o de custo a ser minimizada √© a log-verossimilhan√ßa negativa:
>
> $$ J(\beta) = -\sum_{i=1}^n [y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] $$
>
> Suponha que ap√≥s o ajuste, os coeficientes s√£o $\beta = [\beta_0, \beta_1, \beta_2, \beta_3] = [0.5, 1.2, -0.8, 0.3]$.
>
> **Com Regulariza√ß√£o L1 (Lasso):** A fun√ß√£o de custo com regulariza√ß√£o L1 √©:
>
> $$ J(\beta)_{L1} = J(\beta) + \lambda (|\beta_1| + |\beta_2| + |\beta_3|) $$
>
> Suponha que, com $\lambda=0.5$, ap√≥s ajuste, os coeficientes se tornem  $\beta_{L1} = [0.6, 0.9, 0, 0.1]$. Observe que $\beta_2$ foi zerado, indicando que a vari√°vel $x_2$ n√£o contribui significativamente para a predi√ß√£o.
>
> **Com Regulariza√ß√£o L2 (Ridge):** A fun√ß√£o de custo com regulariza√ß√£o L2 √©:
>
> $$ J(\beta)_{L2} = J(\beta) + \lambda (\beta_1^2 + \beta_2^2 + \beta_3^2) $$
>
> Suponha que, com $\lambda=0.5$, ap√≥s ajuste, os coeficientes se tornem $\beta_{L2} = [0.55, 1.0, -0.6, 0.2]$. Observe que os coeficientes s√£o menores em magnitude em compara√ß√£o com o modelo sem regulariza√ß√£o, mas nenhum deles foi zerado.
>
> A regulariza√ß√£o L1 promove a sele√ß√£o de vari√°veis, enquanto a L2 encolhe os coeficientes.

**Lemma 3:** *A penaliza√ß√£o L1 em classifica√ß√£o log√≠stica leva √† esparsidade dos coeficientes, ou seja, muitos coeficientes s√£o zerados, o que significa que as vari√°veis preditoras correspondentes n√£o contribuem para a predi√ß√£o*. A prova deste lemma envolve mostrar que o problema de otimiza√ß√£o com a penalidade L1 tende a ter solu√ß√µes nos v√©rtices do espa√ßo de par√¢metros, onde muitos coeficientes s√£o zero [^7.4.4].

**Prova do Lemma 3:**  O problema de otimiza√ß√£o da regress√£o log√≠stica com regulariza√ß√£o L1 √© dado por:
$$ \text{min}_\beta - \sum_{i=1}^n [y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda \sum_{j=1}^p |\beta_j| $$
Onde $p(x_i)$ √© a probabilidade de classe predita, $\beta_j$ s√£o os coeficientes, $n$ √© o n√∫mero de amostras, e $p$ √© o n√∫mero de preditores, e $\lambda$ √© o par√¢metro de regulariza√ß√£o que controla a intensidade da penaliza√ß√£o. Quando $\lambda > 0$, o termo de regulariza√ß√£o $|\beta_j|$ for√ßa alguns dos $\beta_j$ a serem exatamente zero. Ao derivar a fun√ß√£o objetivo e analisar as condi√ß√µes de otimalidade, percebe-se que a regulariza√ß√£o L1 leva a solu√ß√µes esparsas pois, diferentemente da L2, a penaliza√ß√£o em valor absoluto tem derivada descont√≠nua em zero, resultando em coeficientes iguais a zero com maior probabilidade. Essa propriedade de esparsidade √© essencial para a sele√ß√£o de vari√°veis. $\blacksquare$

**Corol√°rio 3:** *A esparsidade dos coeficientes resultante da regulariza√ß√£o L1 em modelos de classifica√ß√£o log√≠stica melhora a interpretabilidade do modelo, pois apenas as vari√°veis preditoras mais relevantes s√£o inclu√≠das no modelo final* [^7.4.5]. Ao selecionar um subconjunto de vari√°veis, √© mais f√°cil identificar quais preditores t√™m um impacto maior na classifica√ß√£o, o que facilita a compreens√£o do problema.

> ‚ö†Ô∏è **Ponto Crucial**: A combina√ß√£o de penalidades L1 e L2 (Elastic Net) permite aproveitar as vantagens de ambos os tipos de regulariza√ß√£o: a esparsidade da L1 e a estabilidade da L2 [^7.5].

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Perceptron Algorithm"
    A["Initialize weights"] --> B["Input data point"]
    B --> C{"Classified Correctly?"}
    C -- Yes --> D["Next Data Point"]
    C -- No --> E["Adjust weights based on error"]
    E --> B
    D --> F{"All Points Classified?"}
    F -- No --> B
    F -- Yes --> G["Converged"]
    end
```

A ideia de encontrar um **hiperplano separador** que maximize a margem entre as classes leva ao conceito de hiperplanos √≥timos. A margem de separa√ß√£o √© definida como a dist√¢ncia m√≠nima entre os pontos de dados e o hiperplano de decis√£o [^7.5.2]. O objetivo √© encontrar o hiperplano que maximize essa margem, levando a modelos com melhor capacidade de generaliza√ß√£o [^7.5.2]. Essa formula√ß√£o do problema de otimiza√ß√£o pode ser resolvida usando t√©cnicas de programa√ß√£o quadr√°tica, encontrando um dual de Wolfe [^7.5.2]. Os pontos de suporte (support vectors) s√£o os pontos mais pr√≥ximos da fronteira de decis√£o, e a solu√ß√£o √≥tima √© expressa em fun√ß√£o desses pontos. O perceptron, tamb√©m conhecido como o algoritmo de Rosenblatt, √© um algoritmo de aprendizado de m√°quina para classifica√ß√£o bin√°ria baseado em hiperplanos separadores [^7.5.1]. O algoritmo ajusta os pesos dos preditores iterativamente, convergindo para uma solu√ß√£o se os dados forem linearmente separ√°veis [^7.5.1].

> üí° **Exemplo Num√©rico:** Considere duas classes linearmente separ√°veis em um espa√ßo 2D, com pontos da classe 1 representados por c√≠rculos e pontos da classe 2 por cruzes. Um perceptron come√ßa com um hiperplano (neste caso, uma linha) aleat√≥rio.  A cada itera√ß√£o, o perceptron encontra um ponto classificado incorretamente e ajusta os pesos (ou seja, a inclina√ß√£o e o intercepto da linha) de modo a classificar corretamente aquele ponto. Este processo se repete at√© que todos os pontos estejam classificados corretamente, ou seja, o algoritmo converge. Visualmente, a linha vai se movendo gradativamente at√© separar os c√≠rculos das cruzes.

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**
A LDA, como discutido em [^7.3], assume que os dados de cada classe seguem uma distribui√ß√£o gaussiana com a mesma matriz de covari√¢ncia $\Sigma$. A regra de decis√£o Bayesiana, por outro lado, usa diretamente as probabilidades condicionais das classes, tamb√©m assumindo gaussianas com matrizes de covari√¢ncia id√™nticas. Sob essas condi√ß√µes, a fronteira de decis√£o da LDA, que se baseia em maximizar a separa√ß√£o das m√©dias das classes, torna-se equivalente √† regra de decis√£o Bayesiana, que minimiza o erro de classifica√ß√£o esperado [^7.3].
A diferen√ßa chave reside na maneira como os par√¢metros s√£o estimados e usados para formar a regra de classifica√ß√£o. Enquanto a LDA estima os par√¢metros (m√©dias e covari√¢ncia) usando os dados dispon√≠veis diretamente, a regra de decis√£o Bayesiana usa as densidades de probabilidade condicionais, que s√£o expressas em termos desses par√¢metros estimados. As fronteiras de decis√£o s√£o derivadas da compara√ß√£o das probabilidades posteriores das classes, onde essas probabilidades s√£o calculadas usando os par√¢metros estimados [^7.3], [^7.3.3], [^7.3.1]. As proje√ß√µes lineares na LDA s√£o consequ√™ncia da forma gaussiana e da covari√¢ncia comum, que tamb√©m est√° presente na decis√£o Bayesiana. A escolha da m√©dia e da covari√¢ncia influencia a forma da fronteira de decis√£o, mas ambos os m√©todos levam √† mesma fronteira linear quando as suposi√ß√µes s√£o satisfeitas [^7.3].

**Lemma 4:** *Sob a hip√≥tese de distribui√ß√µes gaussianas com covari√¢ncia id√™ntica, a fun√ß√£o discriminante linear da LDA pode ser derivada a partir da regra de decis√£o Bayesiana ao comparar as probabilidades posteriores logar√≠tmicas das classes, com a diferen√ßa sendo uma constante que n√£o altera a decis√£o*. A prova desse lemma demonstra que as fun√ß√µes discriminantes de LDA e as fun√ß√µes de decis√£o Bayesiana, quando expressas sob essas condi√ß√µes, diferem apenas por uma constante, o que significa que as superf√≠cies de decis√£o s√£o id√™nticas [^7.3], [^7.3.3], [^7.3.1].

**Corol√°rio 4:** *Se a hip√≥tese de covari√¢ncias iguais for relaxada, a fronteira de decis√£o resultante da regra de decis√£o Bayesiana torna-se quadr√°tica (QDA), em vez de linear, e n√£o mais equivalente ao LDA.* Isso mostra que a hip√≥tese de igualdade de covari√¢ncia √© fundamental para o LDA [^7.3].

> ‚ö†Ô∏è **Ponto Crucial:**  A escolha entre covari√¢ncias iguais (LDA) ou diferentes (QDA) impacta diretamente a forma da fronteira de decis√£o, resultando em fronteiras lineares ou quadr√°ticas, respectivamente, e isso precisa ser considerado quando se escolhe o m√©todo de classifica√ß√£o [^7.3.1], [^7.3].

```mermaid
graph LR
 subgraph "LDA vs. Bayesian Decision Rule"
    A["Gaussian Data Distribution"] --> B{"Equal Covariance Matrices?"}
    B -- Yes --> C["LDA Decision Boundary: Linear"]
    B -- No --> D["Bayesian Decision Rule (QDA): Quadratic"]
    C --> E["Discriminant function derived from posterior probabilities"]
    D --> F["Non-Linear decision boundary"]
 end
```

### Conclus√£o

Neste cap√≠tulo, exploramos m√©todos para avaliar o desempenho de modelos estat√≠sticos de classifica√ß√£o, discutindo em detalhes a rela√ß√£o entre bias, vari√¢ncia e complexidade do modelo, e revisamos o funcionamento dos m√©todos lineares como LDA e Regress√£o Log√≠stica, al√©m da import√¢ncia da regulariza√ß√£o e da sele√ß√£o de vari√°veis. Tamb√©m discutimos os conceitos de hiperplanos separadores e perceptrons, que s√£o fundamentais para a compreens√£o dos m√©todos de classifica√ß√£o linear. As complexidades te√≥ricas envolvidas na escolha de modelos e na avalia√ß√£o de sua performance exigem uma compreens√£o profunda dos conceitos abordados.

### Footnotes

[^7.1]: "The generalization performance of a learning method relates to its prediction capability on independent test data. Assessment of this performance is extremely important in practice, since it guides the choice of learning method or model, and gives us a measure of the quality of the ultimately chosen model." *(Trecho de <Model Assessment and Selection>)*
[^7.2]: "Figure 7.1 illustrates the important issue in assessing the ability of a learning method to generalize. Consider first the case of a quantitative or interval scale response. We have a target variable Y, a vector of inputs X, and a prediction model f(X) that has been estimated from a training set T." *(Trecho de <Model Assessment and Selection>)*
[^7.3]: "The story is similar for a qualitative or categorical response G taking one of K values in a set G, labeled for convenience as 1, 2, ..., K. Typically we model the probabilities pk(X) = Pr(G = k|X) (or some monotone transformations fr(X)), and then ƒú(X) = arg maxk pk (X)." *(Trecho de <Model Assessment and Selection>)*
[^7.3.1]: "Test error, also referred to as generalization error, is the prediction error over an independent test sample ErrT = E[L(Y, f(X))|T]." *(Trecho de <Model Assessment and Selection>)*
[^7.3.2]: "where both X and Y are drawn randomly from their joint distribution (population). Here the training set T is fixed, and test error refers to the error for this specific training set. A related quantity is the expected prediction error (or expected test error) Err = E[L(Y, f(X))] = E[ErrT]." *(Trecho de <Model Assessment and Selection>)*
[^7.3.3]: "Note that this expectation averages over everything that is random, including the randomness in the training set that produced f." *(Trecho de <Model Assessment and Selection>)*
[^7.4]: "Again, test error here is ErrT = E[L(G, ƒú(X))|T], the population misclassification error of the classifier trained on T, and Err is the expected misclassification error." *(Trecho de <Model Assessment and Selection>)*
[^7.4.1]: "Training error is the sample analogue, for example, err = (2/N) \sum \log(p_{g_i}(x_i)) the sample log-likelihood for the model." *(Trecho de <Model Assessment and Selection>)*
[^7.4.2]: "The log-likelihood can be used as a loss-function for general response densities, such as the Poisson, gamma, exponential, log-normal and others. If Pro(x) (Y) is the density of Y, indexed by a parameter Œ∏(X) that depends on the predictor X, then L(Y,Œ∏(X)) = ‚àí2 ¬∑ log PrŒ∏(x)(Y)." *(Trecho de <Model Assessment and Selection>)*
[^7.4.3]: "The ‚Äò‚àí2‚Äô in the definition makes the log-likelihood loss for the Gaussian distribution match squared-error loss." *(Trecho de <Model Assessment and Selection>)*
[^7.4.4]: "For ease of exposition, for the remainder of this chapter we will use Y and f(X) to represent all of the above situations, since we focus mainly on the quantitative response (squared-error loss) setting." *(Trecho de <Model Assessment and Selection>)*
[^7.4.5]: "For the other situations, the appropriate translations are obvious." *(Trecho de <Model Assessment and Selection>)*
[^7.5]: "In this chapter we describe a number of methods for estimating the expected test error for a model. Typically our model will have a tuning parameter or parameters Œ± and so we can write our predictions as fŒ±(x). The tuning parameter varies the complexity of our model, and we wish to find the value of Œ± that minimizes error, that is, produces the minimum of the average test error curve in Figure 7.1." *(Trecho de <Model Assessment and Selection>)*
[^7.5.1]: "Having said this, for brevity we will often suppress the dependence of f(x) on Œ±." *(Trecho de <Model Assessment and Selection>)*
[^7.5.2]: "It is important to note that there are in fact two separate goals that we might have in mind: Model selection: estimating the performance of different models in order to choose the best one. Model assessment: having chosen a final model, estimating its prediction error (generalization error) on new data." *(Trecho de <Model Assessment and Selection>)*
