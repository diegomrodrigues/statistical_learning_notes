## Data Splitting: Estrat√©gias para Avalia√ß√£o e Sele√ß√£o de Modelos

```mermaid
graph LR
    A["Data"] --> B["Training Set"]
    A --> C["Test Set"]
    B --> D["Model Training"]
    D --> E["Model Evaluation"]
    E --> F["Performance Metrics"]
    C --> E
    F --> G["Model Selection"]
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#ccf,stroke:#333,stroke-width:2px
    style C fill:#ccf,stroke:#333,stroke-width:2px
    style E fill:#ffc,stroke:#333,stroke-width:2px
```

### Introdu√ß√£o

A capacidade de um modelo de aprendizado de m√°quina de generalizar para dados n√£o vistos √© crucial. Este cap√≠tulo aborda a **generaliza√ß√£o** [^7.1], ou seja, a performance preditiva do modelo em dados independentes (test set). A avalia√ß√£o dessa performance √© essencial para orientar a escolha do melhor m√©todo de aprendizado ou modelo [^7.1]. Discutiremos m√©todos para avaliar e selecionar modelos, come√ßando com a an√°lise do *tradeoff* entre vi√©s (*bias*), vari√¢ncia e complexidade do modelo [^7.2].

### Conceitos Fundamentais

**Conceito 1: Generaliza√ß√£o e Erro de Predi√ß√£o**

A **generaliza√ß√£o** refere-se √† habilidade de um modelo de aprendizado de m√°quina em prever resultados corretamente em dados que n√£o foram usados para trein√°-lo [^7.1]. O erro de predi√ß√£o, por sua vez, quantifica o qu√£o distante as predi√ß√µes do modelo est√£o dos valores reais. Formalmente, um modelo $f(X)$ √© treinado utilizando um conjunto de dados $T$ para aproximar uma vari√°vel alvo $Y$. O erro pode ser medido atrav√©s de fun√ß√µes de perda, como o erro quadr√°tico m√©dio ou o erro absoluto [^7.2]:

$$ L(Y, f(X)) = \begin{cases}
(Y - f(X))^2 & \text{erro quadr√°tico} \\
|Y - f(X)| & \text{erro absoluto}
\end{cases} $$

```mermaid
graph LR
    subgraph "Loss Function Decomposition"
        direction TB
        A["L(Y, f(X))"]
        B["Squared Error: (Y - f(X))¬≤"]
        C["Absolute Error: |Y - f(X)|"]
        A --> B
        A --> C
    end
```

O objetivo √© minimizar este erro no conjunto de teste, um conjunto de dados n√£o visto durante o treinamento. M√©todos lineares, embora simples, podem sofrer de vi√©s alto (underfitting) quando a rela√ß√£o entre $X$ e $Y$ √© n√£o linear [^7.2]. A escolha do modelo impacta no equil√≠brio entre vi√©s e vari√¢ncia.

> üí° **Exemplo Num√©rico:**
>
> Imagine que estamos tentando prever o pre√ßo de casas ($Y$) com base no n√∫mero de quartos ($X$). Um modelo linear simples poderia ser $f(X) = 50000 + 75000X$. Se a rela√ß√£o verdadeira for, na verdade, n√£o linear, como $Y = 100000 + 50000X + 10000X^2$, o modelo linear ter√° um **vi√©s alto**. Ele n√£o consegue capturar a curvatura da rela√ß√£o. Para calcular o erro, podemos usar um conjunto de teste:
>
> | Casa | N√∫mero de Quartos ($X$) | Pre√ßo Real ($Y$) | Pre√ßo Predito ($f(X)$) | Erro Quadr√°tico $(Y - f(X))^2$ |
> |---|---|---|---|---|
> | 1  | 1 | 160000 | 125000 | 1225000000 |
> | 2  | 2 | 300000 | 200000 | 10000000000 |
> | 3  | 3 | 550000 | 275000 | 75625000000 |
>
> O erro quadr√°tico m√©dio neste pequeno conjunto de teste seria a m√©dia da coluna de erros quadr√°ticos. Se usarmos um modelo mais complexo (um polin√¥mio de grau 2, por exemplo), poder√≠amos obter um erro menor nesse mesmo conjunto de teste. No entanto, um modelo muito complexo (ex: um polin√¥mio de grau 10) poderia ajustar-se perfeitamente ao conjunto de treino, mas apresentar erros altos em dados n√£o vistos (vari√¢ncia alta).

**Lemma 1:** *A complexidade do modelo afeta o balan√ßo entre vi√©s e vari√¢ncia*. Um modelo com pouca complexidade (ex: modelo linear simples) pode ter um alto vi√©s (n√£o consegue capturar padr√µes complexos), enquanto modelos muito complexos podem ter alta vari√¢ncia (sens√≠veis a varia√ß√µes nos dados de treinamento e baixa generaliza√ß√£o). O objetivo √© encontrar um ponto √≥timo onde o erro de predi√ß√£o seja minimizado [^7.2]. Um modelo *linear*, por exemplo, apresenta uma *menor vari√¢ncia*, mas um *alto vi√©s* quando os dados s√£o n√£o lineares.

```mermaid
graph LR
    subgraph "Bias-Variance Tradeoff"
        direction TB
        A["Model Complexity"]
        B["High Bias, Low Variance (Underfitting)"]
        C["Optimal Complexity"]
        D["Low Bias, High Variance (Overfitting)"]
        A --> B
        A --> C
        A --> D
    end
```

**Conceito 2: Linear Discriminant Analysis (LDA)**

A *Linear Discriminant Analysis* (LDA) √© um m√©todo de classifica√ß√£o que busca projetar os dados em um subespa√ßo de dimens√£o menor, de forma que as classes fiquem o mais separadas poss√≠vel. Ele assume que os dados de cada classe s√£o normalmente distribu√≠dos e compartilham a mesma matriz de covari√¢ncia [^7.3]. A fun√ß√£o discriminante linear gerada pelo LDA pode ser expressa como:

$$ \delta_k(x) = x^T \Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log(\pi_k) $$

onde:

-   $x$ √© o vetor de features,
-   $\Sigma$ √© a matriz de covari√¢ncia conjunta,
-   $\mu_k$ √© a m√©dia da classe $k$,
-   $\pi_k$ √© a probabilidade a priori da classe $k$.

```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction TB
        A["Œ¥_k(x)"]
        B["x·µÄ Œ£‚Åª¬π Œº_k"]
        C["- 1/2 Œº_k·µÄ Œ£‚Åª¬π Œº_k"]
        D["log(œÄ_k)"]
        A --> B
        A --> C
        A --> D
    end
```
O LDA tem como objetivo projetar os dados em uma dire√ß√£o que maximize a separa√ß√£o entre as classes [^7.3.1], [^7.3.2].

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos duas classes de flores (classe 0 e classe 1) e duas features (comprimento e largura da s√©pala). Temos os seguintes dados:
>
> ```python
> import numpy as np
> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
>
> X = np.array([[5.1, 3.5], [4.9, 3.0], [6.2, 3.4], [7.2, 3.2], [4.6, 3.1], [5.0, 3.6], [6.7, 3.0], [7.7, 3.8]])
> y = np.array([0, 0, 1, 1, 0, 0, 1, 1])
>
> lda = LinearDiscriminantAnalysis()
> lda.fit(X, y)
>
> print("M√©dias das classes:", lda.means_)
> print("Matriz de covari√¢ncia conjunta:", lda.covariance_)
> print("Coeficientes da fun√ß√£o discriminante:", lda.scalings_)
>
> # Sa√≠da aproximada
# M√©dias das classes: [[4.9   3.24]  [7.2    3.35]]
# Matriz de covari√¢ncia conjunta: [[0.482  0.05  ] [0.05  0.09  ]]
# Coeficientes da fun√ß√£o discriminante: [[-0.9  0.5]]
> ```
>
> A sa√≠da mostra as m√©dias das classes, a matriz de covari√¢ncia conjunta estimada pelo LDA e os coeficientes da fun√ß√£o discriminante. O LDA encontrou uma combina√ß√£o linear das features que melhor separa as duas classes, o que pode ser usado para classificar novas flores. A fun√ß√£o discriminante $\delta_k(x)$ calcula um score, e a classe com maior score √© atribu√≠da ao novo dado.

**Corol√°rio 1:** A fronteira de decis√£o do LDA √© linear [^7.3.3], o que a torna uma escolha adequada para problemas onde as classes s√£o linearmente separ√°veis ou aproximadamente separ√°veis. Em outras palavras, o LDA busca encontrar a melhor combina√ß√£o linear das features que separe as classes, o que corresponde a encontrar a melhor proje√ß√£o dos dados em um subespa√ßo de dimens√£o menor [^7.3].

**Conceito 3: Logistic Regression**

A *Logistic Regression* √© outro m√©todo popular para classifica√ß√£o, modelando a probabilidade de pertencer a uma classe atrav√©s da fun√ß√£o log√≠stica (sigmoide). A regress√£o log√≠stica estima a probabilidade de um evento ocorrer utilizando uma fun√ß√£o log√≠stica sobre uma combina√ß√£o linear das vari√°veis preditoras [^7.4]. O log-odds (logit) √© dado por:

$$ \text{logit}(p(X)) = \ln\left(\frac{p(X)}{1 - p(X)}\right) = \beta_0 + \beta_1 X_1 + \ldots + \beta_p X_p $$

```mermaid
graph LR
    subgraph "Logistic Regression: Logit"
        direction TB
        A["logit(p(X))"]
        B["ln(p(X) / (1 - p(X)))"]
        C["Œ≤‚ÇÄ + Œ≤‚ÇÅX‚ÇÅ + ... + Œ≤‚ÇöX‚Çö"]
        A --> B
        A --> C
    end
```
A fun√ß√£o log√≠stica converte o resultado do modelo linear em uma probabilidade entre 0 e 1 [^7.4.1]. Os par√¢metros s√£o estimados maximizando a verossimilhan√ßa (likelihood) dos dados de treinamento [^7.4.3].

> üí° **Exemplo Num√©rico:**
>
> Vamos usar o mesmo conjunto de dados anterior e aplicar regress√£o log√≠stica:
>
> ```python
> from sklearn.linear_model import LogisticRegression
>
> logreg = LogisticRegression()
> logreg.fit(X, y)
>
> print("Intercepto:", logreg.intercept_)
> print("Coeficientes:", logreg.coef_)
>
> # Sa√≠da aproximada
# Intercepto: [-33.6]
# Coeficientes: [[5.1  -2.1]]
> ```
>
> Aqui, o `intercept_` √© o $\beta_0$ e `coef_` cont√©m os $\beta_i$ da equa√ß√£o log√≠stica. O modelo calcula a probabilidade de uma flor pertencer √† classe 1. Se essa probabilidade for maior que 0.5, a flor ser√° classificada como classe 1; caso contr√°rio, classe 0.

> ‚ö†Ô∏è **Nota Importante**: A *Logistic Regression* estima probabilidades, enquanto o LDA fornece fronteiras de decis√£o. A escolha entre eles depende da necessidade de estimar probabilidades ou apenas classificar [^7.4].
> ‚ùó **Ponto de Aten√ß√£o**: Classes n√£o balanceadas podem levar a resultados enviesados na *Logistic Regression*. √â importante tratar esse desbalanceamento, atrav√©s de t√©cnicas como *re-sampling* [^7.4.2].
> ‚úîÔ∏è **Destaque**: Em certos casos, quando as suposi√ß√µes do LDA s√£o v√°lidas, as estimativas de par√¢metros em LDA e em *Logistic Regression* podem apresentar comportamentos semelhantes [^7.5].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction TB
        A["Input Data (X, y)"]
        B["Encode Classes as Indicators"]
        C["Linear Regression: yÃÇ = XŒ≤"]
        D["Decision Rule: yÃÇ > threshold"]
        E["Classification Result"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

A regress√£o linear pode ser usada para classifica√ß√£o atrav√©s da cria√ß√£o de uma **matriz de indicadores**, onde cada coluna indica a perten√ßa de uma amostra a uma determinada classe. O objetivo √© minimizar o erro quadr√°tico da predi√ß√£o da perten√ßa √† classe [^7.2]. A regress√£o linear, neste caso, ajusta um modelo linear para prever a perten√ßa √† classe, e a classifica√ß√£o √© feita atrav√©s de uma regra de decis√£o baseada nas predi√ß√µes.

> üí° **Exemplo Num√©rico:**
>
> Para usar regress√£o linear para classifica√ß√£o com o mesmo exemplo anterior, transformamos as classes em uma representa√ß√£o num√©rica:
>
> | Casa | N√∫mero de Quartos ($X_1$) | Largura da S√©pala ($X_2$)| Classe (y) |
> |---|---|---|---|
> | 1 | 5.1 | 3.5 | 0 |
> | 2 | 4.9 | 3.0 | 0 |
> | 3 | 6.2 | 3.4 | 1 |
> | 4 | 7.2 | 3.2 | 1 |
> | 5 | 4.6 | 3.1 | 0 |
> | 6 | 5.0 | 3.6 | 0 |
> | 7 | 6.7 | 3.0 | 1 |
> | 8 | 7.7 | 3.8 | 1 |
>
> Agora, usamos regress√£o linear, onde o objetivo √© prever o valor de y (0 ou 1).
>
> ```python
> from sklearn.linear_model import LinearRegression
>
> linreg = LinearRegression()
> linreg.fit(X, y)
>
> print("Intercepto:", linreg.intercept_)
> print("Coeficientes:", linreg.coef_)
>
> # Sa√≠da aproximada
# Intercepto: -1.16
# Coeficientes: [0.23    0.12]
> ```
>
> A classifica√ß√£o √© feita usando o resultado da regress√£o linear. Se o resultado √© maior que 0.5, a classe predita √© 1, sen√£o, 0. Isso mostra como a regress√£o linear pode ser adaptada para tarefas de classifica√ß√£o.

No entanto, a regress√£o linear aplicada diretamente √† classifica√ß√£o pode apresentar algumas limita√ß√µes, como extrapola√ß√µes fora do intervalo \[0, 1], e n√£o modelar a probabilidade de cada classe [^7.4]. O uso de uma matriz de indicadores e a regress√£o linear podem levar a estimativas menos est√°veis e a extrapola√ß√µes err√¥neas [^7.2]. Quando o objetivo √© obter uma fronteira de decis√£o linear, e n√£o estimar a probabilidade de perten√ßa √† classe, a regress√£o linear pode ser suficiente [^7.2].

**Lemma 2**: *Sob certas condi√ß√µes, a proje√ß√£o nos hiperplanos de decis√£o obtidos via regress√£o linear em matriz de indicadores pode ser equivalente √†s proje√ß√µes obtidas por discriminantes lineares.* Em outras palavras, ao inv√©s de usar LDA, sob condi√ß√µes espec√≠ficas, a regress√£o linear pode produzir uma fronteira de decis√£o linear muito similar. Isso √© particularmente √∫til quando a proje√ß√£o linear √© o principal objetivo, e n√£o a estimativa da probabilidade de classes. [^7.2]

**Corol√°rio 2**: A equival√™ncia entre as proje√ß√µes via regress√£o linear e discriminantes lineares, sob certas condi√ß√µes [^7.3], pode simplificar a an√°lise do modelo, especialmente quando a separa√ß√£o linear das classes √© o principal objetivo. O uso de regress√£o linear em problemas de classifica√ß√£o pode ser uma alternativa interessante quando a complexidade e o custo computacional de outros m√©todos, como LDA, precisam ser considerados [^7.2].

> Em alguns cen√°rios, a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1]. [^7.4]
> No entanto, h√° situa√ß√µes em que a regress√£o de indicadores √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear [^7.2].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

A sele√ß√£o de vari√°veis √© crucial para construir modelos parcimoniosos, evitar *overfitting* e aumentar a interpretabilidade. Em modelos lineares como a regress√£o log√≠stica, a *regulariza√ß√£o* √© uma t√©cnica que adiciona um termo de penalidade na fun√ß√£o de custo, que controla a complexidade do modelo [^7.4.4]. As penalidades mais comuns s√£o a L1 (Lasso) e a L2 (Ridge), que tendem a encolher os coeficientes em dire√ß√£o a zero e diminuir a vari√¢ncia [^7.5].

```mermaid
graph LR
    subgraph "Regularization Techniques"
      direction TB
        A["Regularization"]
        B["L1 Penalty (Lasso)"]
        C["L2 Penalty (Ridge)"]
        A --> B
        A --> C
    end
```

A penaliza√ß√£o L1 leva a coeficientes esparsos, ou seja, muitos coeficientes s√£o zerados, realizando assim a sele√ß√£o de vari√°veis [^7.4.4]. A penaliza√ß√£o L2 encolhe os coeficientes, diminuindo a vari√¢ncia e a complexidade do modelo [^7.5]. Ambas as t√©cnicas, L1 e L2, ajudam a controlar o *overfitting* e melhorar a capacidade de generaliza√ß√£o do modelo.

> üí° **Exemplo Num√©rico:**
>
> Vamos aplicar a regulariza√ß√£o L1 (Lasso) √† regress√£o log√≠stica:
>
> ```python
> from sklearn.linear_model import LogisticRegression
>
> # Aumentando o n√∫mero de features
> X_extended = np.hstack((X, np.random.rand(X.shape[0], 5)))
>
> # Ajustando com L1 (Lasso)
> logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=0.1) # C √© o inverso de lambda
> logreg_l1.fit(X_extended, y)
> print("Coeficientes Lasso:", logreg_l1.coef_)
>
> # Ajustando com L2 (Ridge)
> logreg_l2 = LogisticRegression(penalty='l2', C=0.1) # C √© o inverso de lambda
> logreg_l2.fit(X_extended, y)
> print("Coeficientes Ridge:", logreg_l2.coef_)
>
> # Sa√≠da (vari√°vel devido √† aleatoriedade)
# Coeficientes Lasso: [[ 0.          0.         -0.4         0.         0.          0.         -0.        ]]
# Coeficientes Ridge: [[-0.23 -0.24 -0.14  -0.07 -0.12  -0.27 -0.08]]
> ```
>
> Observe que com a penalidade L1 (Lasso), alguns coeficientes s√£o exatamente zero, realizando sele√ß√£o de vari√°veis, enquanto que com L2 (Ridge), os coeficientes tendem a ficar pequenos. O par√¢metro C controla a intensidade da regulariza√ß√£o.

**Lemma 3**: *A penaliza√ß√£o L1 em modelos de classifica√ß√£o log√≠stica leva a coeficientes esparsos*, o que significa que muitos dos coeficientes s√£o for√ßados a serem exatamente zero, efetivamente realizando a sele√ß√£o de vari√°veis. Matematicamente, a penaliza√ß√£o L1 adiciona um termo proporcional √† soma dos valores absolutos dos coeficientes √† fun√ß√£o de perda. A otimiza√ß√£o dessa fun√ß√£o tende a levar √† esparsidade dos coeficientes, removendo os preditores menos relevantes [^7.4.4].

**Prova do Lemma 3**: A fun√ß√£o de custo com penaliza√ß√£o L1 para um modelo de regress√£o log√≠stica √© dada por:

$$ J(\beta) = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(p_i) + (1 - y_i) \log(1 - p_i) \right] + \lambda \sum_{j=1}^{p} |\beta_j| $$

Onde $p_i$ √© a probabilidade de perten√ßa √† classe, $\beta$ s√£o os coeficientes do modelo, e $\lambda$ √© o par√¢metro de regulariza√ß√£o. A derivada da penalidade L1 em rela√ß√£o a $\beta_j$ √© dada por $\lambda \cdot \text{sign}(\beta_j)$. Este termo n√£o √© diferenci√°vel em $\beta_j=0$, o que leva a coeficientes sendo exatamente zero durante o processo de otimiza√ß√£o, especialmente para valores suficientemente altos de $\lambda$. Este processo induz a esparsidade e realiza sele√ß√£o de vari√°veis [^7.4.3], [^7.4.5]. $\blacksquare$

```mermaid
graph LR
    subgraph "L1 Regularization Function"
        direction TB
        A["J(Œ≤)"]
        B["- 1/N ‚àë [y·µ¢ log(p·µ¢) + (1 - y·µ¢) log(1 - p·µ¢)]"]
        C["Œª ‚àë |Œ≤‚±º|"]
        A --> B
        A --> C
     end
```

**Corol√°rio 3**: A esparsidade dos coeficientes resultante da penaliza√ß√£o L1 aumenta a interpretabilidade do modelo, uma vez que apenas as vari√°veis mais importantes s√£o mantidas no modelo final [^7.4.5]. Isso facilita a compreens√£o da rela√ß√£o entre as vari√°veis preditoras e a vari√°vel alvo.

> ‚ö†Ô∏è **Ponto Crucial**: L1 e L2 podem ser combinadas (Elastic Net) para aproveitar vantagens de ambos os tipos de regulariza√ß√£o [^7.5]. Essa t√©cnica √© especialmente √∫til quando h√° alta correla√ß√£o entre as vari√°veis preditoras.

### Separating Hyperplanes e Perceptrons

A ideia de maximizar a margem de separa√ß√£o entre classes leva ao conceito de **hiperplanos** √≥timos. O objetivo √© encontrar um hiperplano que separe as classes com a maior dist√¢ncia poss√≠vel entre ele e os pontos mais pr√≥ximos de cada classe (os *support vectors*). A formula√ß√£o matem√°tica desse problema envolve a otimiza√ß√£o do dual de Wolfe, que permite encontrar os pontos de suporte e definir o hiperplano √≥timo [^7.5.2].

```mermaid
graph LR
    subgraph "Hyperplane Optimization"
        direction TB
        A["Data points (X, y)"]
        B["Find separating hyperplane"]
        C["Maximize margin between classes"]
        D["Support Vectors define margin"]
         A --> B
         B --> C
         C --> D
    end
```

O Perceptron de Rosenblatt √© um algoritmo de classifica√ß√£o que busca encontrar um hiperplano que separe linearmente os dados [^7.5.1]. O algoritmo itera sobre os dados, ajustando os pesos do hiperplano a cada erro de classifica√ß√£o. Sob a condi√ß√£o de separabilidade linear dos dados, o Perceptron converge para um hiperplano que separa as classes.

### Pergunta Te√≥rica Avan√ßada (Exemplo): Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**
O *Linear Discriminant Analysis* (LDA) e a Regra de Decis√£o Bayesiana s√£o m√©todos de classifica√ß√£o que, sob certas condi√ß√µes, podem apresentar resultados similares, especialmente quando assumimos que os dados seguem distribui√ß√µes Gaussianas com covari√¢ncias iguais [^7.3]. No entanto, as formula√ß√µes e objetivos de cada m√©todo s√£o distintos:

-   **Regra de Decis√£o Bayesiana:** O classificador Bayesiano busca minimizar a probabilidade de erro de classifica√ß√£o e, para isso, utiliza as probabilidades *a posteriori* das classes, dadas pelas seguintes express√µes:

    $$ P(G=k|X=x) = \frac{P(X=x|G=k)\pi_k}{\sum_{l=1}^K P(X=x|G=l)\pi_l} $$

    Onde $P(G=k|X=x)$ √© a probabilidade *a posteriori* da classe $k$, dado o vetor de features $x$; $P(X=x|G=k)$ √© a densidade de probabilidade dos dados da classe $k$; e $\pi_k$ √© a probabilidade *a priori* da classe $k$ [^7.3].
```mermaid
graph LR
    subgraph "Bayes Rule"
        direction TB
        A["P(G=k|X=x)"]
        B["P(X=x|G=k) * œÄ_k"]
        C["‚àë P(X=x|G=l) * œÄ_l"]
         A --> B
         B --> C
    end
```
-   **LDA:** O LDA, por sua vez, assume que os dados de cada classe seguem uma distribui√ß√£o Gaussiana com a mesma matriz de covari√¢ncia e utiliza uma fun√ß√£o discriminante linear para separar as classes, como expresso em [^7.3]. Matematicamente, o LDA busca encontrar um subespa√ßo de dimens√£o menor que maximize a separa√ß√£o entre as classes, projetando os dados nessa dire√ß√£o. Quando assumimos que as covari√¢ncias das classes s√£o iguais, a fronteira de decis√£o entre duas classes $k$ e $l$ √© expressa como:

    $$  x^T \Sigma^{-1}(\mu_k - \mu_l) - \frac{1}{2}(\mu_k^T\Sigma^{-1}\mu_k - \mu_l^T\Sigma^{-1}\mu_l) + \log\left(\frac{\pi_k}{\pi_l}\right) = 0 $$

    que define um hiperplano [^7.3.3].

**Lemma 4:** *Quando as distribui√ß√µes condicionais das classes s√£o Gaussianas com a mesma matriz de covari√¢ncia e quando usamos a Regra de Decis√£o Bayesiana, a fronteira de decis√£o resultante √© uma fun√ß√£o linear dos dados, equivalente √† fun√ß√£o discriminante do LDA* [^7.3], [^7.3.3]. Isso significa que, sob essas suposi√ß√µes espec√≠ficas, ambos os m√©todos levam ao mesmo hiperplano de decis√£o, embora utilizando abordagens diferentes.

**Corol√°rio 4:** *Ao relaxar a suposi√ß√£o de covari√¢ncias iguais, a Regra de Decis√£o Bayesiana leva a fronteiras quadr√°ticas* (Quadratic Discriminant Analysis ou QDA), enquanto o LDA continua utilizando fronteiras lineares [^7.3]. Essa √© uma diferen√ßa fundamental entre os dois m√©todos, e a escolha entre eles depende da natureza dos dados e da complexidade da fronteira de decis√£o necess√°ria.

```mermaid
graph LR
    subgraph "LDA vs. Bayesian Decision"
    direction TB
        A["Gaussian Data with Equal Covariance"]
        B["LDA: Linear Decision Boundary"]
        C["Bayes: Linear Decision Boundary"]
        D["Gaussian Data with Different Covariance"]
        E["LDA: Linear Decision Boundary"]
        F["Bayes: Quadratic Decision Boundary"]
        A --> B
        A --> C
        D --> E
        D --> F
    end
```

> ‚ö†Ô∏è **Ponto Crucial**: A ado√ß√£o ou n√£o de covari√¢ncias iguais impacta fortemente o tipo de fronteira de decis√£o (linear vs. quadr√°tica) [^7.3.1]. A escolha entre LDA e QDA (ou Regra de Decis√£o Bayesiana com covari√¢ncias diferentes) depender√° da adequa√ß√£o das hip√≥teses aos dados e da capacidade de cada modelo de capturar as complexidades do problema de classifica√ß√£o.

### Conclus√£o

Este cap√≠tulo forneceu uma vis√£o abrangente sobre a divis√£o de dados para avalia√ß√£o e sele√ß√£o de modelos. Discutimos o *tradeoff* entre *bias* e vari√¢ncia, a import√¢ncia de estimar o erro de generaliza√ß√£o e apresentamos diferentes m√©todos para divis√£o de dados e escolha do melhor modelo. M√©todos de regulariza√ß√£o, como L1 e L2, desempenham um papel crucial no controle da complexidade do modelo e na melhoria da sua capacidade de generaliza√ß√£o. Conclu√≠mos que o *data splitting* √© essencial para avaliar corretamente a performance de modelos de *machine learning* e guiar a escolha dos melhores modelos para problemas espec√≠ficos. <!-- END DOCUMENT -->

### Footnotes

[^7.1]: "The generalization performance of a learning method relates to its prediction capability on independent test data. Assessment of this performance is extremely important in practice, since it guides the choice of learning method or model, and gives us a measure of the quality of the ultimately chosen model."
[^7.2]: "Figure 7.1 illustrates the important issue in assessing the ability of a learning method to generalize. Consider first the case of a quantitative or interval scale response. We have a target variable Y, a vector of inputs X, and a prediction model f(X) that has been estimated from a training set T. The loss function for measuring errors between Y and f(X) is denoted by L(Y, f(X)). Typical choices are L(Y, f(X)) = (Y‚àíf(X))2 squared error or L(Y, f(X)) = |Y ‚àí f(X)| absolute error."
[^7.3]: "The story is similar for a qualitative or categorical response G taking one of K values in a set G, labeled for convenience as 1, 2, ..., K. Typically we model the probabilities pk(X) = Pr(G = k|X) (or some monotone transformations fk(X)), and then ƒú(X) = arg maxk fk(X). In some cases, such as 1-nearest neighbor classification (Chapters 2 and 13) we produce G(X) directly. Typical loss functions are L(G, ƒú(X)) = I(G ‚â† ƒú(X)) (0-1 loss) or L(G, P(X)) = ‚àí2 ‚àëk=1 K I(G = k) log pk(X) = ‚àí2 log pƒú(X)  (-2 √ó log-likelihood)."
[^7.3.1]: "Test error, also referred to as generalization error, is the prediction error over an independent test sample ErrT = E[L(Y, f(X))|T], where both X and Y are drawn randomly from their joint distribution (population). Here the training set T is fixed, and test error refers to the error for this specific training set."
[^7.3.2]: "A related quantity is the expected prediction error (or expected test error) Err = E[L(Y, f(X))] = E[ErrT]. Note that this expectation averages over everything that is random, including the randomness in the training set that produced f."
[^7.3.3]: "Estimation of Erry will be our goal, although we will see that Err is more amenable to statistical analysis, and most methods effectively estimate the expected error."
[^7.4]: "Training error is the average loss over the training sample err =  1/N * Œ£ L(Yi, f(xi))"
[^7.4.1]: "We would like to know the expected test error of our estimated model f. As the model becomes more and more complex, it uses the training data more and is able to adapt to more complicated underlying structures. Hence there is a decrease in bias but an increase in variance. There is some intermediate model complexity that gives minimum expected test error."
[^7.4.2]: "Unfortunately training error is not a good estimate of the test error, as seen in Figure 7.1. Training error consistently decreases with model complexity, typically dropping to zero if we increase the model complexity enough."
[^7.4.3]: "However, a model with zero training error is overfit to the training data and will typically generalize poorly."
[^7.4.4]: "The log-likelihood can be used as a loss-function for general response densities, such as the Poisson, gamma, exponential, log-normal and others."
[^7.4.5]: "If Pro(x) (Y) is the density of Y, indexed by a parameter Œ∏(X) that depends on the predictor X, then L(Y, Œ∏(X)) = ‚àí2 ¬∑ log Pro(x) (Y)."
[^7.5]: "The ‚Äú‚àí2‚Äù in the definition makes the log-likelihood loss for the Gaussian distribution match squared-error loss."
[^7.5.1]: "For ease of exposition, for the remainder of this chapter we will use Y and f(X) to represent all of the above situations, since we focus mainly on the quantitative response (squared-error loss) setting."
[^7.5.2]: "For the other situations, the appropriate translations are obvious."
