## Avalia√ß√£o e Sele√ß√£o de Modelos: Foco no Erro de Generaliza√ß√£o

<imagem: Um diagrama complexo mostrando o fluxo de avalia√ß√£o do modelo, desde a divis√£o dos dados em treinamento, valida√ß√£o e teste at√© a an√°lise de bias-vari√¢ncia e a sele√ß√£o final, conectando as diferentes m√©tricas de avalia√ß√£o de desempenho>

**Introdu√ß√£o**

A capacidade de um m√©todo de aprendizado predizer corretamente em dados n√£o vistos, conhecida como **generaliza√ß√£o**, √© crucial para sua aplicabilidade pr√°tica [^7.1]. A avalia√ß√£o do desempenho de um modelo, portanto, torna-se um passo essencial, orientando a escolha do m√©todo de aprendizado ou modelo e proporcionando uma medida da qualidade do modelo selecionado [^7.1]. Este cap√≠tulo aborda m√©todos para avalia√ß√£o de desempenho e como eles s√£o empregados na sele√ß√£o de modelos. O tema inicial √© a discuss√£o da rela√ß√£o entre **bias, vari√¢ncia e complexidade do modelo** [^7.1].

### Conceitos Fundamentais

**Conceito 1:** O problema de **classifica√ß√£o** visa categorizar dados em classes predefinidas com base em suas caracter√≠sticas. M√©todos lineares s√£o frequentemente empregados devido √† sua simplicidade e interpretabilidade, mesmo que possam introduzir um vi√©s ou uma vari√¢ncia maior em compara√ß√£o com m√©todos n√£o lineares [^7.2]. O equil√≠brio entre bias e vari√¢ncia √© crucial: modelos muito simples tendem a ter alto bias e baixa vari√¢ncia, enquanto modelos muito complexos apresentam o oposto [^7.2].

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um problema de classifica√ß√£o bin√°ria onde queremos prever se um cliente vai comprar um produto (classe 1) ou n√£o (classe 0) baseado em sua idade (feature x).
>
> *   **Modelo Simples (Alto Bias, Baixa Vari√¢ncia):** Um modelo que sempre prediz a classe majorit√°ria, independentemente da idade (ex: sempre prediz "n√£o vai comprar"), ter√° um alto vi√©s (bias) porque ignora a rela√ß√£o entre idade e compra. No entanto, a vari√¢ncia ser√° baixa porque a predi√ß√£o n√£o muda muito, independentemente do conjunto de treinamento.
> *   **Modelo Complexo (Baixo Bias, Alta Vari√¢ncia):** Um modelo que ajusta uma fun√ß√£o muito complexa (ex: um polin√¥mio de grau muito alto) aos dados de treinamento pode ter baixo vi√©s porque se adapta perfeitamente aos dados de treinamento. No entanto, essa alta complexidade levar√° a uma alta vari√¢ncia, ou seja, pequenas mudan√ßas nos dados de treinamento podem levar a grandes mudan√ßas na fun√ß√£o de predi√ß√£o.
>
> Para visualizar isso, imagine ajustar uma reta a um conjunto de dados. Se a reta for muito simples (ex: uma constante), ela ter√° alto bias (n√£o capturando a rela√ß√£o real). Se a reta for muito complexa (ex: um polin√¥mio de grau alto, cheio de curvas), ela ter√° baixa bias nos dados de treino, mas uma alta vari√¢ncia, se ajustando em excesso a ru√≠dos.
>
>  ```mermaid
>  graph LR
>      A["Modelo Simples"] --> B["Alto Bias"];
>      A --> C["Baixa Vari√¢ncia"];
>      D["Modelo Complexo"] --> E["Baixo Bias"];
>      D --> F["Alta Vari√¢ncia"];
>  ```
>

**Lemma 1:** Considere um modelo de classifica√ß√£o linear $f(x) = w^T x + b$, onde $w$ s√£o os pesos, $x$ s√£o as features, e $b$ √© o bias. Em um espa√ßo de caracter√≠sticas de alta dimensionalidade, a vari√¢ncia das estimativas de $w$ aumenta, enquanto o bias pode ser reduzido com a inclus√£o de mais features. A complexidade do modelo linear √© regulada, por exemplo, pela penaliza√ß√£o dos pesos (regulariza√ß√£o) [^7.2].

> üí° **Exemplo Num√©rico:**
> Suponha que tenhamos um modelo linear para prever o pre√ßo de uma casa (\\$y$) com base em duas features: n√∫mero de quartos ($x_1$) e tamanho em metros quadrados ($x_2$). O modelo seria $y = w_1x_1 + w_2x_2 + b$.
>
> *   **Poucas features:** Se tivermos apenas o n√∫mero de quartos, o modelo seria $y = w_1x_1 + b$. Isso pode levar a um alto bias, j√° que ignora o tamanho da casa, que tamb√©m √© relevante para o pre√ßo. No entanto, a vari√¢ncia de $w_1$ seria baixa porque h√° menos fatores que podem mudar seu valor.
> *   **Muitas features:** Se adicionarmos, digamos, 100 features (incluindo caracter√≠sticas como localiza√ß√£o, idade da casa, etc), podemos reduzir o bias, pois o modelo tem mais informa√ß√µes para trabalhar. No entanto, a vari√¢ncia dos pesos $w_1, w_2... w_{100}$ aumentar√°, pois cada peso ser√° mais sens√≠vel aos dados de treino.
>
> A regulariza√ß√£o, como a penaliza√ß√£o L2 (Ridge), ajuda a controlar a magnitude dos pesos, reduzindo a vari√¢ncia, mesmo com muitas features.
> ```mermaid
>  graph LR
>     subgraph "Model Complexity & Feature Space"
>       direction TB
>       A["Few Features"] --> B["High Bias"];
>       A --> C["Low Variance of Weights"];
>       D["Many Features"] --> E["Low Bias"];
>       D --> F["High Variance of Weights"];
>     end
>  ```

**Conceito 2:** A **Linear Discriminant Analysis (LDA)** √© um m√©todo de classifica√ß√£o que assume que os dados de cada classe seguem uma distribui√ß√£o normal com a mesma matriz de covari√¢ncia [^7.3]. A fun√ß√£o discriminante linear, dada por $\delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + log(\pi_k)$, onde $\Sigma$ √© a matriz de covari√¢ncia, $\mu_k$ √© a m√©dia da classe *$k$* e $\pi_k$ √© a probabilidade a priori da classe *$k$*,  gera uma fronteira de decis√£o linear entre as classes, que √© √≥tima quando as premissas do modelo s√£o atendidas [^7.3.1]. A LDA busca projetar os dados em um subespa√ßo que maximize a separa√ß√£o entre as classes e minimize a variabilidade dentro das classes [^7.3.2].  Para isso, busca o espa√ßo que maximize a raz√£o de vari√¢ncia inter-classes para vari√¢ncia intra-classes, formalmente expressa como $max_W \frac{W^T S_B W}{W^T S_W W}$, onde $S_B$ √© a matriz de vari√¢ncia inter-classes e $S_W$ √© a matriz de vari√¢ncia intra-classes [^7.3.3].

> üí° **Exemplo Num√©rico:**
>
> Suponha um problema de classifica√ß√£o com duas classes (A e B) e duas features ($x_1$ e $x_2$). Temos os seguintes dados de exemplo:
>
> *   **Classe A:** 
>     *   M√©dia: $\mu_A = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$
>     *   Dados:  $(1.2, 0.8), (0.9, 1.1), (0.8, 0.9), (1.1, 1.2)$
> *   **Classe B:**
>     *   M√©dia: $\mu_B = \begin{bmatrix} 3 \\ 3 \end{bmatrix}$
>     *   Dados: $(2.8, 3.2), (3.1, 2.9), (2.9, 3.1), (3.2, 2.8)$
>
> Assumindo que a matriz de covari√¢ncia comum ($\Sigma$) √© a matriz identidade $\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$ (para simplificar). Tamb√©m vamos considerar que as probabilidades a priori s√£o iguais, ou seja, $\pi_A = \pi_B = 0.5$.
>
> *   **C√°lculo da fun√ß√£o discriminante para a Classe A ($\delta_A(x)$):**
>     $\delta_A(x) = x^T \Sigma^{-1} \mu_A - \frac{1}{2} \mu_A^T \Sigma^{-1} \mu_A + log(\pi_A)$
>     $\delta_A(x) = x^T \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}^{-1} \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}^{-1} \begin{bmatrix} 1 \\ 1 \end{bmatrix} + log(0.5)$
>     $\delta_A(x) = \begin{bmatrix} x_1 & x_2 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} + log(0.5)$
>     $\delta_A(x) = x_1 + x_2 - 1 - 0.693 \approx x_1 + x_2 - 1.693$
>
> *   **C√°lculo da fun√ß√£o discriminante para a Classe B ($\delta_B(x)$):**
>     $\delta_B(x) = x^T \Sigma^{-1} \mu_B - \frac{1}{2} \mu_B^T \Sigma^{-1} \mu_B + log(\pi_B)$
>     $\delta_B(x) = x^T \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}^{-1} \begin{bmatrix} 3 \\ 3 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 3 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}^{-1} \begin{bmatrix} 3 \\ 3 \end{bmatrix} + log(0.5)$
>    $\delta_B(x) = \begin{bmatrix} x_1 & x_2 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 3 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} + log(0.5)$
>     $\delta_B(x) = 3x_1 + 3x_2 - 9 - 0.693 \approx 3x_1 + 3x_2 - 9.693$
>
> Um novo ponto $x=(2,2)$ seria classificado comparando $\delta_A(2,2) = 2 + 2 - 1.693 = 2.307$ com $\delta_B(2,2) = 3*2 + 3*2 - 9.693= 2.307$.
>
> Para visualizar a matriz de vari√¢ncia interclasses ($S_B$) e intraclasses ($S_W$):
> $S_B = (\mu_A - \mu_B)(\mu_A - \mu_B)^T = \begin{bmatrix} -2 \\ -2 \end{bmatrix} \begin{bmatrix} -2 & -2 \end{bmatrix} = \begin{bmatrix} 4 & 4 \\ 4 & 4 \end{bmatrix} $
> $S_W = \frac{1}{n_A+n_B -2} \left(\sum_{i\in \text{Classe A}}(x_i - \mu_A)(x_i - \mu_A)^T + \sum_{j\in \text{Classe B}}(x_j - \mu_B)(x_j - \mu_B)^T\right)$
>  $S_W \approx \begin{bmatrix} 0.13 & 0 \\ 0 & 0.13\end{bmatrix}$
>
> A LDA projetaria os dados em um espa√ßo onde $\frac{W^T S_B W}{W^T S_W W}$ √© maximizado, o que maximiza a separa√ß√£o entre as classes.
> ```mermaid
> graph LR
>     subgraph "LDA Discriminant Function"
>         direction TB
>        A["Discriminant Function Œ¥k(x)"]
>        B["Class Mean Term: x·µÄŒ£‚Åª¬πŒºk"]
>        C["Quadratic Term: -1/2 * Œºk·µÄŒ£‚Åª¬πŒºk"]
>        D["Prior Term: log(œÄk)"]
>        A --> B
>        A --> C
>        A --> D
>     end
>
>  ```

**Corol√°rio 1:** A fun√ß√£o discriminante linear da LDA pode ser reescrita como uma proje√ß√£o no espa√ßo definido pela matriz de autovetores de  $S_W^{-1}S_B$, simplificando a an√°lise e a interpreta√ß√£o do modelo. Cada autovetor corresponde a uma dire√ß√£o de m√°xima separa√ß√£o entre classes [^7.3.1].
```mermaid
graph LR
    subgraph "LDA Projection"
      direction LR
        A["Original Data Space"] --> B["Eigenvector Space of Sw‚Åª¬πSb"]
        B --> C["Projection for Optimal Separation"]
        C --> D["Decision Boundary"]
    end
```

**Conceito 3:** A **Logistic Regression** modela a probabilidade de um evento bin√°rio, usando a fun√ß√£o log√≠stica $p(x) = \frac{1}{1+e^{-(\beta_0 + \beta^T x)}}$, onde $x$ s√£o as features e $\beta$ s√£o os par√¢metros do modelo [^7.4]. O logit, definido como $ln(\frac{p(x)}{1-p(x)}) = \beta_0 + \beta^T x$, estabelece uma rela√ß√£o linear entre as features e o log-odds da probabilidade de ocorr√™ncia do evento [^7.4.1]. Os par√¢metros do modelo s√£o estimados por meio da maximiza√ß√£o da verossimilhan√ßa (likelihood) [^7.4.2]. A fun√ß√£o de verossimilhan√ßa, no contexto da regress√£o log√≠stica, √© dada por $L(\beta) = \prod_{i=1}^n p(x_i)^{y_i}(1-p(x_i))^{1-y_i}$, onde $y_i \in \{0, 1\}$ √© a classe observada para o i-√©simo dado. A maximiza√ß√£o de L √© equivalente √† maximiza√ß√£o de seu logaritmo [^7.4.3]. A escolha entre LDA e regress√£o log√≠stica depende das premissas sobre a distribui√ß√£o dos dados e da natureza do problema [^7.4.5]. Se os dados seguem uma distribui√ß√£o gaussiana e a vari√¢ncia √© compartilhada entre as classes, a LDA pode ser prefer√≠vel, enquanto a regress√£o log√≠stica √© mais robusta em rela√ß√£o a essas premissas [^7.4.4].

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um problema de prever se um estudante ser√° aprovado em um exame (y=1) ou n√£o (y=0) com base em suas horas de estudo (x).
>
> Suponha que ap√≥s ajustar o modelo de regress√£o log√≠stica, os par√¢metros estimados sejam: $\beta_0 = -4$ e $\beta_1 = 0.8$. Isso significa que o modelo √© dado por:
>
> $p(x) = \frac{1}{1+e^{-(-4 + 0.8x)}}$
>
> *   **Interpreta√ß√£o dos par√¢metros:**
>    *   $\beta_1 = 0.8$: Para cada hora adicional de estudo, o log-odds de aprova√ß√£o aumenta em 0.8. Isso indica que quanto mais o estudante estuda, maior a probabilidade de aprova√ß√£o.
>    *   $\beta_0 = -4$:  O log-odds de aprova√ß√£o para um estudante que n√£o estuda (x=0) √© -4, o que indica uma probabilidade de aprova√ß√£o muito baixa.
>
> *   **C√°lculo da Probabilidade:**
>    *   Para um estudante que estuda 5 horas (x=5), a probabilidade de aprova√ß√£o √©:
>        $p(5) = \frac{1}{1+e^{-(-4 + 0.8*5)}} = \frac{1}{1+e^{0}} = \frac{1}{1+1} = 0.5$
>    *  Para um estudante que estuda 10 horas (x=10), a probabilidade de aprova√ß√£o √©:
>       $p(10) = \frac{1}{1+e^{-(-4 + 0.8*10)}} = \frac{1}{1+e^{-4}} \approx 0.98$
>
> *   **Fun√ß√£o de Verossimilhan√ßa:**
>     Suponha que temos os dados:
>       * Estudante 1: x=5, y=0
>       * Estudante 2: x=10, y=1
>    A verossimilhan√ßa seria $L(\beta) = p(5)^0 * (1-p(5))^1 * p(10)^1 * (1-p(10))^0 = (1-0.5) * 0.98 = 0.49$
>    O objetivo √© maximizar essa verossimilhan√ßa.
>
> A regress√£o log√≠stica modela a probabilidade usando a fun√ß√£o log√≠stica, enquanto a LDA faz isso implicitamente atrav√©s da fun√ß√£o discriminante, baseada em distribui√ß√µes Gaussianas.
>
```mermaid
graph LR
    subgraph "Logistic Regression Model"
      direction TB
        A["Logistic Function p(x) = 1 / (1 + e^(-(Œ≤‚ÇÄ + Œ≤·µÄx)))"]
        B["Linear Component: Œ≤‚ÇÄ + Œ≤·µÄx"]
        C["Probability p(x)"]
        A --> B
        A --> C
        D["Logit: ln(p(x) / (1 - p(x))) = Œ≤‚ÇÄ + Œ≤·µÄx"]
        B --> D
        E["Likelihood Function L(Œ≤) = Œ† p(xi)^yi * (1 - p(xi))^(1 - yi)"]
        C --> E
    end
```
> ‚ö†Ô∏è **Nota Importante**: Em casos de classes n√£o balanceadas, √© essencial ajustar os pesos ou usar outras t√©cnicas para evitar que o modelo seja enviesado para a classe majorit√°ria [^7.4.1].
> ‚ùó **Ponto de Aten√ß√£o**: A regress√£o log√≠stica √© menos sens√≠vel a outliers em compara√ß√£o com a LDA, o que pode ser uma vantagem em conjuntos de dados ruidosos [^7.4.2].
> ‚úîÔ∏è **Destaque**: Em certas condi√ß√µes, as estimativas dos par√¢metros nos modelos LDA e regress√£o log√≠stica podem convergir para solu√ß√µes similares [^7.5].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

<imagem: Diagrama de fluxo mostrando o processo de aplica√ß√£o da regress√£o linear para classifica√ß√£o, desde a codifica√ß√£o das classes atrav√©s de uma matriz de indicadores at√© a aplica√ß√£o da regra de decis√£o e compara√ß√£o com m√©todos probabil√≠sticos.>
```mermaid
flowchart TD
  subgraph "Regress√£o de Indicadores"
    A["Codificar Classes"] --> B["Estimar Coeficientes via LS"]
    B --> C["Aplicar Regra de Decis√£o"]
    C --> D["Comparar com M√©todos Probabil√≠sticos"]
  end
```
A regress√£o linear pode ser aplicada √† classifica√ß√£o usando uma **matriz de indicadores** para codificar as classes, em que cada coluna indica a pertin√™ncia de um dado a uma classe espec√≠fica [^7.2]. A regress√£o linear busca ent√£o, ajustar os par√¢metros do modelo minimizando os erros quadr√°ticos [^7.1]. O modelo resultante permite classificar novos dados com base na classe com maior valor previsto pelo modelo [^7.2].
Entretanto, este m√©todo possui limita√ß√µes. Por exemplo, a estimativa da probabilidade de um evento atrav√©s da regress√£o linear pode resultar em valores fora do intervalo [0, 1], al√©m de ser mais sens√≠vel a outliers [^7.2]. A regress√£o de indicadores, apesar de sua simplicidade, pode n√£o ser ideal para problemas com grande n√∫mero de classes ou para obter estimativas probabil√≠sticas precisas. A influ√™ncia de covari√¢ncia entre classes √© outro aspecto a se considerar, que √© explicitamente abordado pela LDA [^7.3].

> üí° **Exemplo Num√©rico:**
> Suponha um problema de classifica√ß√£o bin√°ria com uma √∫nica feature (x) e duas classes (0 e 1). Temos os seguintes dados:
>
> | x | Classe |
> |---|--------|
> | 1 | 0      |
> | 2 | 0      |
> | 3 | 1      |
> | 4 | 1      |
>
>  1. **Matriz de Indicadores:** Criamos uma coluna indicadora para a classe 1.
>
> | x | Classe 1 (y) |
> |---|--------------|
> | 1 | 0            |
> | 2 | 0            |
> | 3 | 1            |
> | 4 | 1            |
>
>  2. **Regress√£o Linear:** Ajustamos o modelo linear $y = \beta_0 + \beta_1 x$ aos dados. Usando o m√©todo dos m√≠nimos quadrados, podemos estimar os par√¢metros:
>     $\beta = (X^TX)^{-1}X^Ty$, onde $X$ √© a matriz com valores de $x$ e um vetor de 1's para $\beta_0$, e $y$ √© o vetor de classes (0 ou 1).
>
> ```python
> import numpy as np
> from sklearn.linear_model import LinearRegression
>
> X = np.array([[1,1], [1,2], [1,3], [1,4]]) # Matriz com 1's para o intercepto e os valores de x
> y = np.array([0, 0, 1, 1])
>
> model = LinearRegression()
> model.fit(X, y)
> beta0 = model.intercept_
> beta1 = model.coef_[1]
>
> print(f"beta0: {beta0}, beta1: {beta1}")
> ```
>
> Executando o c√≥digo, obtemos $\beta_0 \approx -0.5$ e $\beta_1 \approx 0.5$.
>
> 3. **Regra de Decis√£o:** Para classificar um novo ponto, por exemplo, x = 2.5, calculamos:
>    $y = -0.5 + 0.5 * 2.5 = 0.75$. Como $y$ √© maior que 0.5, classificamos como classe 1.
>
> **Limita√ß√µes:** Se tiv√©ssemos um outlier na classe 0 com x=6, a regress√£o linear poderia ser muito influenciada por esse ponto, levando a resultados imprecisos. Al√©m disso, as previs√µes da regress√£o linear podem ser valores fora do intervalo \[0, 1], dificultando a interpreta√ß√£o como probabilidades.

**Lemma 2:** Sob certas condi√ß√µes, a proje√ß√£o de dados em um hiperplano de decis√£o, gerada por uma regress√£o linear aplicada a uma matriz de indicadores, √© equivalente √† proje√ß√£o obtida por um discriminante linear, especialmente quando as classes s√£o aproximadamente lineares e os erros seguem uma distribui√ß√£o gaussiana. Essa equival√™ncia surge da solu√ß√£o dos problemas de otimiza√ß√£o que resultam na regress√£o linear e na LDA, onde a proje√ß√£o √© definida por um vetor que maximiza a separa√ß√£o das m√©dias entre as classes e minimiza a vari√¢ncia dentro das classes [^7.2].
```mermaid
graph LR
    subgraph "Equivalence of Linear Regression and LDA"
      direction TB
        A["Linear Regression with Indicator Matrix"]
        B["LDA Discriminant"]
        C["Assumptions: Linearity, Gaussian Errors"]
        D["Converge to Similar Projection Hyperplane"]
        A --> C
        B --> C
        C --> D
    end
```

**Corol√°rio 2:** Em problemas de classifica√ß√£o com classes bem separadas e distribui√ß√µes gaussianas, a solu√ß√£o da regress√£o linear com matriz de indicadores pode fornecer uma aproxima√ß√£o adequada √† solu√ß√£o da LDA. Isso simplifica a implementa√ß√£o e a an√°lise do modelo, pois a regress√£o linear √© mais amplamente conhecida e compreendida do que o m√©todo LDA [^7.3].
> Em alguns cen√°rios, conforme apontado em [^7.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1].
> No entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^7.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

<imagem: Um mapa mental conectando as t√©cnicas de regulariza√ß√£o (L1, L2 e Elastic Net) com seus efeitos nos modelos de classifica√ß√£o (Logistic Regression, LDA e Hyperplanes) e seus impactos na esparsidade, estabilidade e interpretabilidade do modelo.>

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas fundamentais para lidar com a complexidade e o overfitting em modelos de classifica√ß√£o. A regulariza√ß√£o adiciona uma penalidade √† fun√ß√£o de custo que visa reduzir o impacto de vari√°veis menos relevantes e evitar que os modelos se adaptem excessivamente aos dados de treinamento [^7.4.4]. A **penaliza√ß√£o L1** (Lasso) adiciona √† fun√ß√£o de custo a soma dos valores absolutos dos coeficientes, promovendo a esparsidade, ou seja, reduzindo alguns coeficientes a zero, o que melhora a interpretabilidade e a sele√ß√£o de vari√°veis [^7.5]. Matematicamente, a fun√ß√£o de custo com penaliza√ß√£o L1 para regress√£o log√≠stica √© definida como $C(\beta) = - \sum_{i=1}^{n}[y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda \sum_{j=1}^p |\beta_j|$, onde $\lambda$ √© um par√¢metro de ajuste que controla a intensidade da regulariza√ß√£o [^7.4.4]. A **penaliza√ß√£o L2** (Ridge) adiciona o quadrado dos coeficientes, o que tende a encolher os coeficientes em dire√ß√£o a zero, reduzindo a vari√¢ncia e estabilizando o modelo [^7.5.1]. A fun√ß√£o de custo com penaliza√ß√£o L2 para regress√£o log√≠stica √© dada por $C(\beta) = - \sum_{i=1}^{n}[y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda \sum_{j=1}^p \beta_j^2$ [^7.4.4]. A penaliza√ß√£o **Elastic Net** combina as penalidades L1 e L2, proporcionando um equil√≠brio entre as vantagens de ambos os m√©todos [^7.5].

> üí° **Exemplo Num√©rico:**
>
> Vamos usar um exemplo de regress√£o log√≠stica para classifica√ß√£o bin√°ria com duas features ($x_1$ e $x_2$). Suponha que o modelo sem regulariza√ß√£o resulte em: $\beta_0 = 0.5$, $\beta_1 = 1.2$, $\beta_2 = -0.8$.
>
> *   **Penaliza√ß√£o L1 (Lasso):**
>     *   Suponha que $\lambda = 0.5$. A fun√ß√£o de custo a ser minimizada √©:
>         $C(\beta) = - \sum_{i=1}^{n}[y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + 0.5(|\beta_1| + |\beta_2|)$
>     *   Ap√≥s otimizar, podemos obter: $\beta_0 = 0.4$, $\beta_1 = 0.8$, $\beta_2 = 0$. Observe que $\beta_2$ foi zerado pela penaliza√ß√£o L1, o que significa que a feature $x_2$ foi exclu√≠da do modelo, promovendo esparsidade.
> *   **Penaliza√ß√£o L2 (Ridge):**
>     *   Suponha que $\lambda = 0.5$. A fun√ß√£o de custo a ser minimizada √©:
>           $C(\beta) = - \sum_{i=1}^{n}[y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + 0.5(\beta_1^2 + \beta_2^2)$
>     *   Ap√≥s otimizar, podemos obter: $\beta_0 = 0.45$, $\beta_1 = 0.9$, $\beta_2 = -0.6$. Observe que os coeficientes s√£o menores, mas nenhum foi zerado.
> *  **Penaliza√ß√£o Elastic Net:**
>     *   Combina√ß√£o de L1 e L2. Por exemplo $\lambda_1 = 0.25$ e $\lambda_2 = 0.25$.
>     *  $C(\beta) = - \sum_{i=1}^{n}[y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + 0.25(|\beta_1| + |\beta_2|) + 0.25(\beta_1^2 + \beta_2^2)$
>     *   Ap√≥s otimizar, podemos obter: $\beta_0 = 0.42$, $\beta_1 = 0.75$, $\beta_2 = -0.1$.  Neste caso, os coeficientes diminuem, mas sem zerar nenhum.
>
>
>  | M√©todo       | $\beta_0$ | $\beta_1$ | $\beta_2$ |
> |--------------|----------|----------|----------|
> | Sem Reg.      | 0.5      | 1.2      | -0.8     |
> | L1 (Lasso)   | 0.4      | 0.8      | 0        |
> | L2 (Ridge)   | 0.45     | 0.9      | -0.6     |
> | Elastic Net | 0.42     | 0.75     | -0.1    |
>
> A regulariza√ß√£o L1 promove a sele√ß√£o de vari√°veis (esparsidade), enquanto a L2 estabiliza os coeficientes. O Elastic Net combina as vantagens de ambas.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.preprocessing import StandardScaler
>
> # Dados de exemplo
> X = np.array([[1, 2], [2, 3], [3, 1], [4, 4], [5, 3], [6, 2]]) # Features
> y = np.array([0, 0, 1, 1, 1, 0])  # Classes
>
> # Padronizar as features
> scaler = StandardScaler()
> X_scaled = scaler.fit_transform(X)
>
> # Logistic Regression sem Regulariza√ß√£o
> model_no_reg = LogisticRegression(penalty=None)
> model_no_reg.fit(X_scaled, y)
> print("Sem regulariza√ß√£o:", model_no_reg.intercept_, model_no_reg.coef_)
>
> # Logistic Regression com Regulariza√ß√£o L1 (Lasso)
> model_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1)
> model_l1.fit(X_scaled, y)
> print("Regulariza√ß√£o L1:", model_l1.intercept_, model_l1.coef_)
>
> # Logistic Regression com Regulariza√ß√£o L2 (Ridge)
> model_l2 = LogisticRegression(penalty='l2', solver='liblinear', C=1)
> model_l2.fit(X_scaled, y)
> print("Regulariza√ß√£o L2:", model_l2.intercept_, model_l2.coef_)
>
> # Logistic Regression com Elastic Net
> model_elastic = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, C=1)
> model_elastic.fit(X_scaled, y)
> print("Elastic Net:", model_elastic.intercept_, model_elastic.coef_)
> ```
>

```mermaid
graph LR
   subgraph "Regularization Techniques in Logistic Regression"
      direction TB
      A["Cost Function C(Œ≤)"]
      B["Loss Term: - Œ£[yi log(p(xi)) + (1 - yi) log(1 - p(xi))]"]
      C["L1 Penalty: Œª Œ£|Œ≤j| (Lasso)"]
      D["L2 Penalty: Œª Œ£Œ≤j¬≤ (Ridge)"]
       E["Elastic Net Penalty: Œª1 Œ£|Œ≤j| + Œª2 Œ£Œ≤j¬≤"]
      A --> B
      A --> C
      A --> D
       A --> E
        C --> F["Promotes Sparsity"]
        D --> G["Reduces Variance"]
         E --> H["Combines Sparsity and Stability"]
    end
```

**Lemma 3:** A penaliza√ß√£o L1 em modelos log√≠sticos leva a coeficientes esparsos porque ela cria cantos na fun√ß√£o de custo, o que promove a converg√™ncia de alguns coeficientes exatamente para zero. A geometria da penalidade L1 for√ßa a otimiza√ß√£o a escolher solu√ß√µes onde o par√¢metro de peso de alguns atributos (features) seja zero, o que promove a sele√ß√£o de atributos [^7.4.4].

**Prova do Lemma 3:** O problema de otimiza√ß√£o com penaliza√ß√£o L1 √© n√£o-diferenci√°vel quando $\beta_j=0$. No entanto, a solu√ß√£o pode ser interpretada como um problema de programa√ß√£o linear com restri√ß√µes. A condi√ß√£o de KKT (Karush-Kuhn-Tucker) estabelece que a derivada da fun√ß√£o de custo em rela√ß√£o a $\beta_j$, menos o sinal da penalidade L1, deve ser igual a zero na solu√ß√£o √≥tima. Ou seja, $\frac{\partial}{\partial \beta_j} L(\beta) \pm \lambda = 0$.  Quando essa derivada √© nula para algum $\beta_j$, isso implica que $\beta_j = 0$, o que ocorre em um n√∫mero expressivo de casos, dada a penalidade L1 [^7.4.3]. $\blacksquare$
```mermaid
graph LR
    subgraph "L1 Regularization and Sparsity"
      direction TB
        A["Non-differentiable Cost Function at Œ≤j=0"]
        B["KKT Condition: ‚àÇL/‚àÇŒ≤j ¬± Œª = 0"]
        C["Forcing Œ≤j to Zero at Optimum"]
        A --> B
        B --> C
        C --> D["Promotes Sparsity"]
    end
```

**Corol√°rio 3:**  A esparsidade promovida pela regulariza√ß√£o L1 melhora a interpretabilidade dos modelos classificat√≥rios ao reduzir o n√∫mero de vari√°veis relevantes, facilitando a identifica√ß√£o dos fatores que mais influenciam a decis√£o [^7.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: A combina√ß√£o de L1 e L2, o Elastic Net, consegue balancear as vantagens de ambos os tipos de regulariza√ß√£o: a sele√ß√£o de vari√°veis da L1 e a estabilidade da L2 [^7.5].

### Separating Hyperplanes e Perceptrons

A ideia de maximizar a margem de