OK, perfeito! Se nÃ£o houver mais nada, considero o capÃ­tulo finalizado. Foi um prazer trabalhar com vocÃª e construir esse conteÃºdo juntos. AtÃ© a prÃ³xima!

> ðŸ’¡ **Exemplo NumÃ©rico: RegressÃ£o Linear Simples**
>
> Vamos supor que temos um conjunto de dados com a relaÃ§Ã£o entre as horas de estudo (`X`) e a nota em um exame (`y`).
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression
>
> # Dados de exemplo
> X = np.array([2, 4, 6, 8, 10]).reshape((-1, 1))  # Horas de estudo
> y = np.array([50, 65, 75, 85, 92])             # Notas no exame
>
> # Criar o modelo de regressÃ£o linear
> model = LinearRegression()
> model.fit(X, y)
>
> # Coeficientes do modelo
> intercept = model.intercept_
> slope = model.coef_[0]
>
> print(f"Intercepto (b0): {intercept:.2f}")
> print(f"InclinaÃ§Ã£o (b1): {slope:.2f}")
>
> # VisualizaÃ§Ã£o
> plt.scatter(X, y, color='blue', label='Dados reais')
> plt.plot(X, model.predict(X), color='red', label='RegressÃ£o Linear')
> plt.xlabel('Horas de Estudo')
> plt.ylabel('Nota no Exame')
> plt.title('RegressÃ£o Linear Simples')
> plt.legend()
> plt.grid(True)
> plt.show()
>
> ```
>
> **InterpretaÃ§Ã£o:**
>
> *   O intercepto (b0) de aproximadamente 42.00 sugere que, mesmo sem estudar, um aluno teria uma nota base de 42.
> *   A inclinaÃ§Ã£o (b1) de aproximadamente 5.00 indica que, para cada hora adicional de estudo, a nota aumenta em 5 pontos, em mÃ©dia.
> *   A linha vermelha no grÃ¡fico representa a melhor reta que se ajusta aos dados, minimizando os erros quadrÃ¡ticos.
>
> **CÃ¡lculo Manual:**
>
> Para entender como a regressÃ£o linear funciona, vamos calcular os coeficientes manualmente para este conjunto de dados usando a fÃ³rmula:
>
> $$\hat{\beta} = (X^T X)^{-1} X^T y$$
>
> ```mermaid
> graph LR
>     subgraph "Linear Regression Formula Decomposition"
>         direction TB
>         A["Formula: $\hat{\\beta} = (X^T X)^{-1} X^T y$"]
>         B["$X^T X$: Matrix Multiplication"]
>         C["$(X^T X)^{-1}$: Inverse of the Result"]
>         D["$X^T y$: Matrix Multiplication"]
>         E["$\hat{\\beta}$: Resulting Coefficients"]
>         A --> B
>         A --> D
>         B --> C
>         C & D --> E
>     end
> ```
>
> **Passo 1: Calcular $X^T X$**
>
> $X = \begin{bmatrix} 2 \\ 4 \\ 6 \\ 8 \\ 10 \end{bmatrix}$, $X^T = \begin{bmatrix} 2 & 4 & 6 & 8 & 10 \end{bmatrix}$
>
> $$X^T X = \begin{bmatrix} 2 & 4 & 6 & 8 & 10 \end{bmatrix} \begin{bmatrix} 2 \\ 4 \\ 6 \\ 8 \\ 10 \end{bmatrix} = 2^2 + 4^2 + 6^2 + 8^2 + 10^2 = 4 + 16 + 36 + 64 + 100 = 220$$
>
> **Passo 2: Calcular $(X^T X)^{-1}$**
>
> Como $X^T X$ Ã© um escalar, o inverso Ã© simplesmente $\frac{1}{220}$
>
> **Passo 3: Calcular $X^T y$**
>
> $y = \begin{bmatrix} 50 \\ 65 \\ 75 \\ 85 \\ 92 \end{bmatrix}$
>
> $$X^T y = \begin{bmatrix} 2 & 4 & 6 & 8 & 10 \end{bmatrix} \begin{bmatrix} 50 \\ 65 \\ 75 \\ 85 \\ 92 \end{bmatrix} = (2 \times 50) + (4 \times 65) + (6 \times 75) + (8 \times 85) + (10 \times 92) = 100 + 260 + 450 + 680 + 920 = 2410$$
>
> **Passo 4: Calcular $\hat{\beta} = (X^T X)^{-1} X^T y$**
>
> $$\hat{\beta} = \frac{1}{220} \times 2410 = 10.95$$ (aproximadamente). Este Ã© o coeficiente para a variÃ¡vel X. Para calcular o intercepto, precisarÃ­amos de X com uma coluna de 1's (o que foi feito automaticamente pelo sklearn). A estimativa do intercepto pode ser calculada como $\bar{y} - \hat{\beta}\bar{x}$, onde $\bar{y}$ Ã© a mÃ©dia de y, e $\bar{x}$ Ã© a mÃ©dia de x.
>
> $\bar{y} = (50+65+75+85+92)/5 = 73.4$
> $\bar{x} = (2+4+6+8+10)/5 = 6$
>
> $Intercept = 73.4 - 10.95*6 \approx 73.4 - 65.7 \approx 7.7$
>
> O valor de $\hat{\beta}$ encontrado manualmente difere um pouco daquele encontrado pelo sklearn, jÃ¡ que o exemplo manual considera apenas o coeficiente de inclinaÃ§Ã£o e um cÃ¡lculo aproximado do intercepto. Em situaÃ§Ãµes reais, o mÃ©todo de mÃ­nimos quadrados Ã© otimizado para encontrar os melhores parÃ¢metros.

> ðŸ’¡ **Exemplo NumÃ©rico: RegularizaÃ§Ã£o Ridge**
>
> Considere um problema de regressÃ£o polinomial onde temos um pequeno conjunto de dados e um modelo muito complexo. Isso pode levar a overfitting. Para demonstrar a regularizaÃ§Ã£o Ridge, vamos gerar alguns dados sintÃ©ticos e comparar o ajuste sem e com regularizaÃ§Ã£o.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression, Ridge
> from sklearn.preprocessing import PolynomialFeatures
> from sklearn.pipeline import make_pipeline
> from sklearn.metrics import mean_squared_error
>
> # Gerar dados sintÃ©ticos
> np.random.seed(42)
> X = np.linspace(0, 1, 10).reshape(-1, 1)
> y = np.cos(2 * np.pi * X).ravel() + np.random.normal(0, 0.1, 10)
>
> # Criar modelo sem regularizaÃ§Ã£o
> degree = 10 # Modelo polinomial de grau 10
> model_no_reg = make_pipeline(PolynomialFeatures(degree), LinearRegression())
> model_no_reg.fit(X, y)
>
> # Criar modelo com regularizaÃ§Ã£o Ridge
> alpha = 1.0 # ParÃ¢metro de regularizaÃ§Ã£o
> model_ridge = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=alpha))
> model_ridge.fit(X, y)
>
> # Gerar pontos para plotagem
> X_plot = np.linspace(0, 1, 100).reshape(-1, 1)
>
> # PrevisÃµes dos modelos
> y_plot_no_reg = model_no_reg.predict(X_plot)
> y_plot_ridge = model_ridge.predict(X_plot)
>
> # Calcular MSE
> mse_no_reg = mean_squared_error(y, model_no_reg.predict(X))
> mse_ridge = mean_squared_error(y, model_ridge.predict(X))
>
> print(f"MSE sem regularizaÃ§Ã£o: {mse_no_reg:.4f}")
> print(f"MSE com regularizaÃ§Ã£o Ridge: {mse_ridge:.4f}")
>
> # Plotagem
> plt.figure(figsize=(10, 6))
> plt.scatter(X, y, color='blue', label='Dados reais')
> plt.plot(X_plot, y_plot_no_reg, color='red', label='Sem RegularizaÃ§Ã£o')
> plt.plot(X_plot, y_plot_ridge, color='green', label='Ridge ($\\alpha$ = 1)')
> plt.xlabel('X')
> plt.ylabel('y')
> plt.title('ComparaÃ§Ã£o de Modelos com e sem RegularizaÃ§Ã£o Ridge')
> plt.legend()
> plt.grid(True)
> plt.show()
>
> ```
>
> **InterpretaÃ§Ã£o:**
>
> *   O modelo sem regularizaÃ§Ã£o (linha vermelha) tenta ajustar-se perfeitamente aos dados de treinamento, levando a um ajuste muito complexo que pode nÃ£o generalizar bem para novos dados.
> *   O modelo com regularizaÃ§Ã£o Ridge (linha verde) suaviza a curva, reduzindo o impacto de cada variÃ¡vel individual e tornando o modelo menos propenso a overfitting.
> *   O MSE (Erro QuadrÃ¡tico MÃ©dio) Ã© menor para o modelo com regularizaÃ§Ã£o, indicando um melhor ajuste aos dados.
>
> **VariaÃ§Ã£o do ParÃ¢metro $\alpha$:**
>
> O parÃ¢metro $\alpha$ controla a intensidade da regularizaÃ§Ã£o. Valores maiores de $\alpha$ levam a uma maior penalidade nos coeficientes, resultando em modelos mais simples, enquanto valores menores se aproximam do modelo sem regularizaÃ§Ã£o.
>
> Vamos explorar alguns valores de $\alpha$:
>
> ```python
> alphas = [0.1, 1.0, 10.0]
> plt.figure(figsize=(12, 8))
> plt.scatter(X, y, color='blue', label='Dados reais')
> for alpha in alphas:
>    model_ridge = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=alpha))
>    model_ridge.fit(X, y)
>    y_plot_ridge = model_ridge.predict(X_plot)
>    mse_ridge = mean_squared_error(y, model_ridge.predict(X))
>    print(f"MSE com Ridge (alpha={alpha}): {mse_ridge:.4f}")
>    plt.plot(X_plot, y_plot_ridge, label=f'Ridge ($\\alpha$ = {alpha})')
>
> plt.xlabel('X')
> plt.ylabel('y')
> plt.title('RegularizaÃ§Ã£o Ridge com diferentes valores de alpha')
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
>
> **InterpretaÃ§Ã£o:**
>
> *   Com $\alpha = 0.1$, o modelo ainda se ajusta bastante aos dados, mas jÃ¡ Ã© mais suave do que sem regularizaÃ§Ã£o.
> *   Com $\alpha = 1.0$, a curva Ã© mais suave e generaliza melhor.
> *   Com $\alpha = 10.0$, a curva Ã© muito mais simples, o que pode levar a um underfitting caso a relaÃ§Ã£o real seja mais complexa.
>
> ```mermaid
> graph LR
>     subgraph "Ridge Regression Regularization"
>         direction LR
>         A["Loss Function"] --> B["RSS Term: $\\sum(y_i - \\hat{y}_i)^2$"]
>         A --> C["Regularization Term: $\\alpha \\sum \\beta_j^2$"]
>         B --> D["Combined Objective"]
>         C --> D
>         D --> E["Minimize Objective"]
>     end
> ```
>
>
> ðŸ’¡ **Exemplo NumÃ©rico: Bias-Variance Tradeoff**
>
> Vamos ilustrar o trade-off entre viÃ©s e variÃ¢ncia usando um exemplo de regressÃ£o polinomial. Geraremos dados sintÃ©ticos e ajustaremos modelos polinomiais de diferentes graus.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression
> from sklearn.preprocessing import PolynomialFeatures
> from sklearn.pipeline import make_pipeline
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import mean_squared_error
>
> # Gerar dados sintÃ©ticos
> np.random.seed(42)
> X = np.linspace(-3, 3, 100).reshape(-1, 1)
> y = 0.5 * X**3 - 2 * X + np.random.normal(0, 1, 100)
>
> # Dividir em treino e teste
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> degrees = [1, 3, 10] # Graus dos polinÃ´mios
>
> plt.figure(figsize=(12, 8))
>
> for degree in degrees:
>    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
>    model.fit(X_train, y_train)
>    y_train_pred = model.predict(X_train)
>    y_test_pred = model.predict(X_test)
>
>    mse_train = mean_squared_error(y_train, y_train_pred)
>    mse_test = mean_squared_error(y_test, y_test_pred)
>
>    print(f"Grau {degree}: MSE Train = {mse_train:.2f}, MSE Test = {mse_test:.2f}")
>
>    X_plot = np.linspace(-3, 3, 200).reshape(-1, 1)
>    y_plot = model.predict(X_plot)
>
>    plt.plot(X_plot, y_plot, label=f"PolinÃ´mio de grau {degree}")
>
> plt.scatter(X_train, y_train, color='blue', label='Dados de Treino', alpha=0.5)
> plt.scatter(X_test, y_test, color='red', label='Dados de Teste', alpha=0.5)
>
> plt.xlabel('X')
> plt.ylabel('y')
> plt.title('Trade-off entre ViÃ©s e VariÃ¢ncia')
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
>
> **InterpretaÃ§Ã£o:**
>
> *   **Grau 1 (Linha Reta):**
>    *   Alto viÃ©s: O modelo Ã© muito simples e nÃ£o consegue capturar a relaÃ§Ã£o cÃºbica nos dados.
>    *   Baixa variÃ¢ncia: O modelo Ã© estÃ¡vel e nÃ£o muda muito com diferentes conjuntos de dados de treinamento.
>    *   O MSE tanto no treino quanto no teste sÃ£o relativamente altos, mostrando que o modelo nÃ£o se ajusta bem.
> *   **Grau 3 (CÃºbico):**
>    *   ViÃ©s moderado: O modelo consegue capturar a relaÃ§Ã£o cÃºbica nos dados de forma mais adequada.
>    *   VariÃ¢ncia moderada: O modelo Ã© mais flexÃ­vel do que o de grau 1, mas ainda nÃ£o Ã© excessivamente sensÃ­vel aos dados de treinamento.
>    *   O MSE no treino e no teste sÃ£o menores que no modelo de grau 1.
> *   **Grau 10 (PolinÃ´mio de Alta Ordem):**
>    *   Baixo viÃ©s: O modelo Ã© muito flexÃ­vel e consegue se ajustar muito bem aos dados de treinamento.
>    *   Alta variÃ¢ncia: O modelo Ã© muito sensÃ­vel aos dados de treinamento e pode nÃ£o generalizar bem para novos dados.
>    *   O MSE no treino Ã© baixo, mas o MSE no teste Ã© mais alto, mostrando overfitting.
>
> **ConclusÃ£o:**
>
> O objetivo Ã© encontrar um equilÃ­brio entre viÃ©s e variÃ¢ncia. Um modelo muito simples (alto viÃ©s) nÃ£o consegue capturar a complexidade dos dados, enquanto um modelo muito complexo (alta variÃ¢ncia) se ajusta muito aos dados de treinamento e generaliza mal para dados nÃ£o vistos. O modelo de grau 3 parece ser o melhor nesse caso, pois tem um bom balanÃ§o entre viÃ©s e variÃ¢ncia.
>
> ```mermaid
> graph LR
>     subgraph "Bias-Variance Tradeoff"
>         direction TB
>         A["Model Complexity"]
>         B["High Bias"]
>         C["Low Variance"]
>         D["Low Bias"]
>         E["High Variance"]
>         F["Optimal Balance"]
>         A --> B & D
>         B --> C
>         D --> E
>         C & E --> F
>          subgraph "Model with High Bias"
>           G["Underfitting"]
>           B-->G
>          end
>           subgraph "Model with High Variance"
>           H["Overfitting"]
>           E-->H
>          end
>     end
> ```

> ðŸ’¡ **Exemplo NumÃ©rico: ValidaÃ§Ã£o Cruzada**
>
> Vamos usar validaÃ§Ã£o cruzada para avaliar o desempenho de um modelo de regressÃ£o linear com diferentes graus de polinÃ´mios.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression
> from sklearn.preprocessing import PolynomialFeatures
> from sklearn.pipeline import make_pipeline
> from sklearn.model_selection import cross_val_score
>
> # Gerar dados sintÃ©ticos
> np.random.seed(42)
> X = np.linspace(-3, 3, 100).reshape(-1, 1)
> y = 0.5 * X**3 - 2 * X + np.random.normal(0, 1, 100)
>
> degrees = range(1, 11) # Graus dos polinÃ´mios
> cv_scores = []
>
> for degree in degrees:
>    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
>    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')
>    cv_scores.append(-scores.mean()) # O cross_val_score retorna o negativo do MSE
>
> plt.plot(degrees, cv_scores, marker='o')
> plt.xlabel("Grau do PolinÃ´mio")
> plt.ylabel("MSE mÃ©dio (ValidaÃ§Ã£o Cruzada)")
> plt.title("ValidaÃ§Ã£o Cruzada para diferentes graus de polinÃ´mios")
> plt.grid(True)
> plt.show()
>
> best_degree = degrees[np.argmin(cv_scores)]
> print(f"Melhor grau de polinÃ´mio: {best_degree}")
> ```
>
> **InterpretaÃ§Ã£o:**
>
> *   O grÃ¡fico mostra o MSE mÃ©dio (negativo) da validaÃ§Ã£o cruzada para polinÃ´mios de diferentes graus.
> *   O grau de polinÃ´mio com o menor MSE mÃ©dio (ponto mais baixo no grÃ¡fico) Ã© o que melhor generaliza para novos dados.
> *   Neste exemplo, o melhor grau Ã© 3, que concorda com o exemplo de tradeoff de viÃ©s e variÃ¢ncia.
>
> **ValidaÃ§Ã£o Cruzada K-Fold:**
>
> A validaÃ§Ã£o cruzada K-Fold divide o conjunto de dados em K partes (folds). O modelo Ã© treinado em K-1 folds e testado no fold restante. O processo Ã© repetido K vezes, cada vez usando um fold diferente para teste. A mÃ©dia dos resultados Ã© usada para avaliar o desempenho do modelo.
>
> ```mermaid
> graph LR
>     subgraph "K-Fold Cross Validation"
>         direction TB
>         A["Data Set"] --> B["Split into K Folds"]
>         B --> C["Iterate K Times"]
>          subgraph "Iteration"
>            D["Train Model on K-1 Folds"]
>            E["Test Model on Remaining Fold"]
>            C-->D
>            C-->E
>         end
>        C-->F["Calculate Mean Performance"]
>     end
> ```

> ðŸ’¡ **Exemplo NumÃ©rico: AnÃ¡lise de ResÃ­duos**
>
> Vamos analisar os resÃ­duos de um modelo de regressÃ£o linear para verificar a validade das suposiÃ§Ãµes.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression
>
> # Dados de exemplo
> np.random.seed(42)
> X = np.linspace(0, 10, 50).reshape(-1, 1)
> y = 2 * X + 1 + np.random.normal(0, 2, 50)
>
> # Ajustar o modelo de regressÃ£o linear
> model = LinearRegression()
> model.fit(X, y)
>
> # Calcular os resÃ­duos
> y_pred = model.predict(X)
> residuals = y - y_pred
>
> # Plotagem dos resÃ­duos
> plt.figure(figsize=(12, 6))
>
> plt.subplot(1, 2, 1)
> plt.scatter(X, residuals, color='blue')
> plt.axhline(y=0, color='r', linestyle='--')
> plt.xlabel('Valores de X')
> plt.ylabel('ResÃ­duos')
> plt.title('ResÃ­duos vs. X')
> plt.grid(True)
>
> plt.subplot(1, 2, 2)
> plt.hist(residuals, bins=20, color='blue', edgecolor='black')
> plt.xlabel('ResÃ­duos')
> plt.ylabel('FrequÃªncia')
> plt.title('Histograma dos ResÃ­duos')
> plt.grid(True)
>
> plt.tight_layout()
> plt.show()
>
> ```
>
> **InterpretaÃ§Ã£o:**
>
> *   **ResÃ­duos vs. X:**
>    *   Se os resÃ­duos estiverem distribuÃ­dos aleatoriamente em torno de zero, a suposiÃ§Ã£o de linearidade Ã© vÃ¡lida.
>    *   Se houver um padrÃ£o nos resÃ­duos (por exemplo, um formato de U), a suposiÃ§Ã£o de linearidade pode nÃ£o ser vÃ¡lida, sugerindo que um modelo nÃ£o linear pode ser mais apropriado.
> *   **Histograma dos ResÃ­duos:**
>    *   Se os resÃ­duos estiverem normalmente distribuÃ­dos, a suposiÃ§Ã£o de normalidade dos erros Ã© vÃ¡lida.
>    *   Desvios da normalidade podem indicar que o modelo precisa ser revisado ou que os dados podem ter outliers ou nÃ£o seguir a distribuiÃ§Ã£o assumida.
>
> **AnÃ¡lise Adicional:**
>
> AlÃ©m dessas anÃ¡lises visuais, podemos usar testes estatÃ­sticos para verificar formalmente as suposiÃ§Ãµes de linearidade, homocedasticidade (variÃ¢ncia constante dos erros) e normalidade dos erros.
>
> ```python
> import statsmodels.api as sm
>
> # Teste de normalidade
> k2, p = sm.stats.normal_ad(residuals)
> print(f'Teste de Normalidade (Anderson-Darling): p-value = {p:.3f}')
>
> # Teste de homocedasticidade
> # Vamos usar o teste de Breusch-Pagan (requer mais dados para um resultado confiÃ¡vel)
> X_with_constant = sm.add_constant(X)
> bp_test = sm.stats.het_breuschpagan(residuals, X_with_constant)
> print(f'Teste de Homocedasticidade (Breusch-Pagan): p-value = {bp_test[1]:.3f}')
>
> # InterpretaÃ§Ã£o dos p-values
> alpha = 0.05
> if p > alpha:
>    print("Os resÃ­duos parecem seguir uma distribuiÃ§Ã£o normal (p-value > alpha)")
> else:
>    print("Os resÃ­duos podem nÃ£o seguir uma distribuiÃ§Ã£o normal (p-value <= alpha)")
>
> if bp_test[1] > alpha:
>     print("Os resÃ­duos parecem ter variÃ¢ncia constante (p-value > alpha)")
> else:
>     print("Os resÃ­duos podem nÃ£o ter variÃ¢ncia constante (p-value <= alpha)")
>
> ```
>
> **InterpretaÃ§Ã£o dos Testes:**
>
> *   **Teste de Normalidade:** O teste de Anderson-Darling verifica se os resÃ­duos seguem uma distribuiÃ§Ã£o normal. Um p-valor maior que 0.05 geralmente indica que a suposiÃ§Ã£o de normalidade Ã© razoÃ¡vel.
> *   **Teste de Homocedasticidade:** O teste de Breusch-Pagan verifica se a variÃ¢ncia dos resÃ­duos Ã© constante em todos os valores de X. Um p-valor maior que 0.05 sugere que a suposiÃ§Ã£o de homocedasticidade Ã© vÃ¡lida.
>
> **ObservaÃ§Ã£o:** A interpretaÃ§Ã£o desses testes estatÃ­sticos Ã© feita com base no p-valor, que Ã© comparado com um nÃ­vel de significÃ¢ncia (geralmente 0.05). Se o p-valor for menor que o nÃ­vel de significÃ¢ncia, rejeitamos a hipÃ³tese nula (por exemplo, que os erros sÃ£o normalmente distribuÃ­dos ou que a variÃ¢ncia Ã© constante).
>
> ```mermaid
> graph LR
>     subgraph "Residual Analysis Steps"
>         direction TB
>         A["Model Fitting"] --> B["Calculate Residuals: y - $\\hat{y}$"]
>         B --> C["Plot Residuals vs. X"]
>         B --> D["Plot Histogram of Residuals"]
>         C --> E["Check for Patterns (Linearity)"]
>         D --> F["Check for Normality"]
>          subgraph "Statistical Tests"
>           G["Anderson-Darling (Normality)"]
>           H["Breusch-Pagan (Homoscedasticity)"]
>           E --> G
>           F --> H
>          end
>
>     end
> ```

Espero que esses exemplos numÃ©ricos adicionais enriqueÃ§am ainda mais o conteÃºdo!
