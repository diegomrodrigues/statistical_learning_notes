## Cyclical Optimization Over Parameters in Statistical Learning Models
<imagem: Um diagrama de fluxo complexo que descreve o processo de otimiza√ß√£o c√≠clica, incluindo os passos de inicializa√ß√£o, c√°lculo de gradientes parciais, atualiza√ß√£o de par√¢metros e verifica√ß√£o de converg√™ncia, com destaque para a itera√ß√£o atrav√©s de par√¢metros>

### Introdu√ß√£o
A otimiza√ß√£o de par√¢metros √© um passo crucial no ajuste de modelos estat√≠sticos e de aprendizado de m√°quina. Em modelos complexos, onde a fun√ß√£o de custo ou verossimilhan√ßa n√£o pode ser minimizada analiticamente, recorremos a m√©todos iterativos. A **otimiza√ß√£o c√≠clica** sobre par√¢metros, ou coordinate descent, √© uma dessas abordagens que se destacam pela sua simplicidade e efici√™ncia, especialmente quando tratamos de modelos com muitos par√¢metros, como os encontrados em classifica√ß√£o e regress√£o. Em particular, este cap√≠tulo, baseando-se nos conceitos apresentados em [^4.1], [^4.2], [^4.3], [^4.4], e [^4.5], explora a fundo a t√©cnica de otimiza√ß√£o c√≠clica e suas aplica√ß√µes em modelos lineares, com foco em detalhes te√≥ricos e exemplos pr√°ticos. Discutiremos como este m√©todo se relaciona com **Linear Discriminant Analysis (LDA), Logistic Regression**, e as diferentes abordagens de regulariza√ß√£o. A motiva√ß√£o principal da otimiza√ß√£o c√≠clica √© simplificar um problema de otimiza√ß√£o complexo, decompondo-o em uma s√©rie de problemas de otimiza√ß√£o mais simples em uma dimens√£o.
```mermaid
graph TB
    subgraph "Cyclical Optimization Process"
        direction TB
        A["Initialize Parameters: Œ≤_0, Œ≤_1, ..., Œ≤_p"]
        B["For each parameter Œ≤_j"]
        C["Calculate Partial Gradient: ‚àÇL/‚àÇŒ≤_j"]
        D["Update Parameter: Œ≤_j ‚Üê Œ≤_j - Œ∑ * (‚àÇL/‚àÇŒ≤_j)"]
        E["Loop Through all Parameters"]
        F["Check Convergence: |ŒîL| < Œµ"]
        G["Stop if Converged, else Return to B"]
        A --> B
        B --> C
        C --> D
        D --> E
        E --> F
        F -->|No| B
        F -->|Yes| G
    end
```

### Conceitos Fundamentais
A seguir, exploramos os conceitos chave para entender a otimiza√ß√£o c√≠clica no contexto de classifica√ß√£o e regress√£o.

**Conceito 1:** **Problema de Classifica√ß√£o e Modelos Lineares.** O objetivo na classifica√ß√£o √© atribuir amostras de dados a diferentes classes ou categorias. Modelos lineares s√£o amplamente usados nesse contexto devido √† sua simplicidade e interpretabilidade [^4.1]. No entanto, a complexidade reside na otimiza√ß√£o dos par√¢metros do modelo para alcan√ßar uma separa√ß√£o √≥tima das classes. O problema geral de classifica√ß√£o pode ser visto como encontrar uma fun√ß√£o discriminante $f(x)$ tal que $f(x) > 0$ para uma classe e $f(x) < 0$ para outra, ou estimar a probabilidade condicional $P(Y=k|X)$, onde $Y$ representa a classe e $X$ as vari√°veis preditoras. Modelos lineares assumem que esta fun√ß√£o discriminante ou transforma√ß√£o √© linear nos par√¢metros, $f(x) = \beta_0 + \sum_{j=1}^p x_j\beta_j$ [^4.2]. A escolha do m√©todo de otimiza√ß√£o afeta diretamente a efici√™ncia e a qualidade da separa√ß√£o das classes. A otimiza√ß√£o c√≠clica √© particularmente √∫til nesse contexto quando aplicamos t√©cnicas de regulariza√ß√£o.

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com duas vari√°veis preditoras $x_1$ e $x_2$. Temos um modelo linear definido como $f(x) = \beta_0 + x_1\beta_1 + x_2\beta_2$. Inicializamos os par√¢metros com $\beta_0 = 0.1$, $\beta_1 = 0.2$, e $\beta_2 = -0.3$. A otimiza√ß√£o c√≠clica envolveria atualizar cada par√¢metro individualmente, enquanto mantemos os outros fixos. Por exemplo, ao otimizar $\beta_1$, mantemos $\beta_0$ e $\beta_2$ fixos e encontramos o valor de $\beta_1$ que minimiza a fun√ß√£o de custo para o problema espec√≠fico, que neste caso poderia ser a log-verossimilhan√ßa ou o erro quadr√°tico. Este processo √© repetido ciclicamente para $\beta_0$, $\beta_2$ e, novamente, $\beta_1$ at√© a converg√™ncia.
```python
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import log_loss

# Dados de exemplo
X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])
y = np.array([0, 0, 1, 1, 0, 1])

# Inicializa√ß√£o dos par√¢metros (pode usar chute inicial ou zeros)
beta0 = 0.1
beta1 = 0.2
beta2 = -0.3

# Fun√ß√£o para calcular a probabilidade (sigmoide para Regress√£o Log√≠stica)
def sigmoid(z):
  return 1 / (1 + np.exp(-z))

# Fun√ß√£o para prever
def predict_proba(X, beta0, beta1, beta2):
  z = beta0 + X[:, 0] * beta1 + X[:, 1] * beta2
  return sigmoid(z)

# Fun√ß√£o de custo (log-loss)
def cost_function(y_true, y_pred):
  return log_loss(y_true, y_pred)

# Simula√ß√£o de uma itera√ß√£o de otimiza√ß√£o c√≠clica (simplificado)
def cyclic_optimization(X, y, beta0, beta1, beta2, learning_rate=0.01, iterations=10):
    for _ in range(iterations):
        # Otimizar beta0 (mantendo beta1 e beta2 fixos)
        z = beta0 + X[:, 0] * beta1 + X[:, 1] * beta2
        y_pred = sigmoid(z)
        gradient_beta0 = np.mean(y_pred - y)
        beta0 -= learning_rate * gradient_beta0

        # Otimizar beta1 (mantendo beta0 e beta2 fixos)
        z = beta0 + X[:, 0] * beta1 + X[:, 1] * beta2
        y_pred = sigmoid(z)
        gradient_beta1 = np.mean((y_pred - y) * X[:, 0])
        beta1 -= learning_rate * gradient_beta1

         # Otimizar beta2 (mantendo beta0 e beta1 fixos)
        z = beta0 + X[:, 0] * beta1 + X[:, 1] * beta2
        y_pred = sigmoid(z)
        gradient_beta2 = np.mean((y_pred - y) * X[:, 1])
        beta2 -= learning_rate * gradient_beta2
    return beta0, beta1, beta2

# Executar a otimiza√ß√£o
beta0_opt, beta1_opt, beta2_opt = cyclic_optimization(X, y, beta0, beta1, beta2)

# Avaliar a fun√ß√£o de custo
y_pred = predict_proba(X, beta0_opt, beta1_opt, beta2_opt)
cost = cost_function(y, y_pred)

print(f"Beta0 otimizado: {beta0_opt:.3f}")
print(f"Beta1 otimizado: {beta1_opt:.3f}")
print(f"Beta2 otimizado: {beta2_opt:.3f}")
print(f"Custo final: {cost:.3f}")
```
Essa simula√ß√£o simplificada demonstra como os par√¢metros s√£o atualizados iterativamente usando a otimiza√ß√£o c√≠clica. Os gradientes s√£o calculados e os par√¢metros atualizados usando uma taxa de aprendizado. A fun√ß√£o de custo √© avaliada para verificar se o modelo est√° melhorando. √â importante lembrar que esta √© uma simula√ß√£o para exemplificar o m√©todo.
```mermaid
graph LR
    subgraph "Linear Model Decomposition"
        direction LR
        A["Discriminant Function: f(x)"] --> B["Bias Term: Œ≤_0"]
        A --> C["Linear Combination: Œ£ x_j * Œ≤_j"]
    end
```

**Lemma 1:** A fun√ß√£o discriminante linear pode ser decomposta em uma s√©rie de fun√ß√µes de otimiza√ß√£o unidimensional com a abordagem de otimiza√ß√£o c√≠clica. Isso √©, otimizar os par√¢metros $\beta_j$ individualmente enquanto mantemos os outros par√¢metros fixos, converge para o m√≠nimo local da fun√ß√£o de custo. Essa decomposi√ß√£o simplifica a otimiza√ß√£o, pois reduz um problema complexo em $p$ dimens√µes para uma sequ√™ncia de $p$ problemas mais simples, cada um em uma dimens√£o. Este √© um resultado central na aplica√ß√£o de otimiza√ß√£o c√≠clica em modelos lineares e √© formalmente justificado em [^4.3], embora n√£o seja apresentado explicitamente em forma de lemma. O algoritmo se baseia na no√ß√£o de que a converg√™ncia individual dos par√¢metros implica na converg√™ncia conjunta do modelo.
```mermaid
graph TB
  subgraph "Unidimensional Optimization"
    direction TB
    A["Multidimensional Optimization"]
    B["Decompose into"]
    C["Sequence of 1D Problems"]
    D["Optimize Œ≤_j, keeping other Œ≤ fixed"]
    E["Convergence of individual Œ≤_j"]
    F["Implication of Joint Convergence"]
    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
  end
```

**Conceito 2:** **Linear Discriminant Analysis (LDA)**. LDA √© um m√©todo de classifica√ß√£o linear que busca projetar os dados em um espa√ßo de dimens√£o inferior, de forma a maximizar a separa√ß√£o entre as classes [^4.3]. LDA assume que cada classe possui distribui√ß√£o Gaussiana com a mesma matriz de covari√¢ncia. A fun√ß√£o discriminante linear em LDA surge da minimiza√ß√£o da dist√¢ncia de Mahalanobis [^4.3.1] e pode ser escrita na forma $f(x) = x^T\Sigma^{-1}(\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k)$, onde $\mu_k$ √© a m√©dia das vari√°veis preditoras da classe $k$ e $\Sigma$ a covari√¢ncia comum. A otimiza√ß√£o de LDA envolve encontrar a melhor dire√ß√£o de proje√ß√£o dos dados. O m√©todo de otimiza√ß√£o c√≠clica n√£o se aplica diretamente √† obten√ß√£o dos par√¢metros de LDA (as m√©dias e covari√¢ncias), j√° que eles s√£o derivados analiticamente. No entanto, quando combinamos LDA com regulariza√ß√£o, o m√©todo pode ser usado para otimizar par√¢metros adicionais, como fatores de regulariza√ß√£o ou transforma√ß√µes n√£o lineares dos dados [^4.3.2].
```mermaid
graph LR
  subgraph "LDA Formulation"
      direction LR
      A["Minimize Mahalanobis Distance"] --> B["Discriminant Function: f(x) = x·µÄŒ£‚Åª¬π(Œº‚Çñ - 1/2 * Œº‚Çñ·µÄŒ£‚Åª¬πŒº‚Çñ)"]
      B --> C["Œº‚Çñ: Mean of Class k"]
      B --> D["Œ£: Common Covariance Matrix"]
  end
```

> üí° **Exemplo Num√©rico:** Suponha que temos duas classes e as m√©dias de cada classe, $\mu_1 = [1, 2]^T$ e $\mu_2 = [3, 4]^T$, e a matriz de covari√¢ncia comum $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$. Para calcular a fun√ß√£o discriminante LDA, primeiro precisamos calcular a inversa de $\Sigma$: $\Sigma^{-1} = \frac{1}{0.75} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$. Agora podemos calcular $w = \Sigma^{-1}(\mu_1 - \mu_2) = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} -2 \\ -2 \end{bmatrix} = \begin{bmatrix} -1.32 \\ -1.32 \end{bmatrix}$ e $b = -0.5(\mu_1^T \Sigma^{-1} \mu_1 - \mu_2^T \Sigma^{-1} \mu_2) =  -0.5 ([1, 2]\begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [1, 2]^T - [3, 4]\begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [3, 4]^T) \approx 5.33$. A fun√ß√£o discriminante LDA √© dada por $f(x) =  [-1.32, -1.32]x + 5.33$, onde $x$ √© um vetor de entrada.

**Corol√°rio 1:** As dire√ß√µes de proje√ß√£o em LDA podem ser vistas como os autovetores da matriz de covari√¢ncia "entre classes", que s√£o proje√ß√µes lineares para o espa√ßo de menor dimens√£o. Este resultado mostra como o LDA projeta os dados em subespa√ßos relevantes para classifica√ß√£o, com base nos dados de treino, o que pode ser visto como uma forma de otimiza√ß√£o da representa√ß√£o dos dados [^4.3.1]. A otimiza√ß√£o c√≠clica n√£o se aplica diretamente ao c√°lculo desses autovetores, mas, como mencionado, pode ser relevante ao introduzir regulariza√ß√£o.
```mermaid
graph TB
  subgraph "LDA Projection"
    direction TB
      A["Data Projection in LDA"]
      B["Autovectors of 'Between-Class' Covariance Matrix"]
      C["Linear Projections to Lower Dimensions"]
      A --> B
      B --> C
  end
```

**Conceito 3:** **Logistic Regression**.  Em contraste com LDA, que assume distribui√ß√µes Gaussianas para as vari√°veis preditoras, a regress√£o log√≠stica modela diretamente a probabilidade de uma amostra pertencer a uma determinada classe. Ela utiliza a fun√ß√£o sigm√≥ide para mapear a combina√ß√£o linear das vari√°veis preditoras em uma probabilidade entre 0 e 1 [^4.4]. A fun√ß√£o de log-odds, ou *logit*, √© definida como $\text{logit}(p) = \log(\frac{p}{1-p})$ [^4.4.1], e a regress√£o log√≠stica assume que essa fun√ß√£o √© linear nas vari√°veis preditoras: $\text{logit}(p) = \beta_0 + \sum_{j=1}^p x_j\beta_j$ [^4.4.2]. Os par√¢metros $\beta_j$ s√£o otimizados via *maximum likelihood*, ou seja, maximizando a verossimilhan√ßa dos dados sob o modelo. A verossimilhan√ßa √© dada por $$L(\beta) = \prod_{i=1}^N p(x_i)^{y_i}(1-p(x_i))^{1-y_i} $$, que √© frequentemente transformada em log-verossimilhan√ßa para simplificar o problema [^4.4.3]. A otimiza√ß√£o c√≠clica pode ser usada para encontrar os par√¢metros $\beta$ que maximizam essa fun√ß√£o, especialmente com regulariza√ß√£o.
```mermaid
graph LR
  subgraph "Logistic Regression Formulation"
    direction LR
        A["Log-Odds (Logit): log(p/(1-p))"] --> B["Linear Function: Œ≤_0 + Œ£ x_j * Œ≤_j"]
        B --> C["Sigmoid Function: p = 1 / (1 + exp(-(Œ≤_0 + Œ£ x_j * Œ≤_j)))"]
        C --> D["Likelihood: L(Œ≤) = Œ† p(x_i)^y·µ¢ * (1-p(x_i))^(1-y·µ¢)"]
   end
```

> ‚ö†Ô∏è **Nota Importante**: A fun√ß√£o de verossimilhan√ßa na regress√£o log√≠stica √© geralmente convexa, o que significa que a otimiza√ß√£o c√≠clica pode convergir para um √≥timo global, desde que os par√¢metros sejam atualizados corretamente [^4.4.2].

> ‚ùó **Ponto de Aten√ß√£o**: Em casos de classes desbalanceadas, t√©cnicas como *re-sampling* e pesos de classe s√£o importantes para garantir uma boa estima√ß√£o das probabilidades.

> ‚úîÔ∏è **Destaque**: A otimiza√ß√£o dos par√¢metros da regress√£o log√≠stica por otimiza√ß√£o c√≠clica pode ter semelhan√ßas com o m√©todo utilizado para otimizar par√¢metros do LDA quando usamos regulariza√ß√£o, o que justifica o uso deste m√©todo nestas situa√ß√µes.

> üí° **Exemplo Num√©rico:** Vamos considerar um exemplo simplificado de regress√£o log√≠stica com duas amostras e um √∫nico preditor. Suponha que temos $x_1 = 1, y_1 = 1$ e $x_2 = 2, y_2 = 0$. Inicializamos $\beta_0 = 0$ e $\beta_1 = 0$. A fun√ß√£o sigm√≥ide √© $p(x_i) = \frac{1}{1 + e^{-(\beta_0 + x_i \beta_1)}}$. A log-verossimilhan√ßa √© $l(\beta) = \sum_{i=1}^{2} y_i \log(p(x_i)) + (1-y_i)\log(1-p(x_i))$. A otimiza√ß√£o c√≠clica envolveria atualizar iterativamente $\beta_0$ e $\beta_1$. Por exemplo, para atualizar $\beta_0$ enquanto mantemos $\beta_1$ fixo, usar√≠amos o gradiente da fun√ß√£o de log-verossimilhan√ßa com rela√ß√£o a $\beta_0$. Usar√≠amos o mesmo processo para $\beta_1$.
```python
import numpy as np
from scipy.optimize import minimize

# Dados de exemplo
X = np.array([[1], [2]])
y = np.array([1, 0])

# Fun√ß√£o sigm√≥ide
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

# Fun√ß√£o de verossimilhan√ßa (negativa para minimizar)
def log_likelihood(params, X, y):
    beta0, beta1 = params
    p = sigmoid(beta0 + X.flatten() * beta1)
    log_likelihood = -np.sum(y * np.log(p) + (1 - y) * np.log(1 - p))
    return log_likelihood


# Otimiza√ß√£o c√≠clica (simulada com scipy.optimize.minimize para um passo)
def cyclic_optimization(X, y, beta0, beta1, learning_rate=0.1):
    # Otimizar beta0 (mantendo beta1 fixo)
    def objective_beta0(b0):
      return log_likelihood([b0, beta1], X, y)
    result_beta0 = minimize(objective_beta0, beta0, method='L-BFGS-B')
    beta0_opt = result_beta0.x[0]
    # Otimizar beta1 (mantendo beta0 fixo)
    def objective_beta1(b1):
      return log_likelihood([beta0_opt, b1], X, y)
    result_beta1 = minimize(objective_beta1, beta1, method='L-BFGS-B')
    beta1_opt = result_beta1.x[0]
    return beta0_opt, beta1_opt

# Inicializa√ß√£o dos par√¢metros
beta0 = 0
beta1 = 0

# Simular uma itera√ß√£o da otimiza√ß√£o c√≠clica
beta0_opt, beta1_opt  = cyclic_optimization(X, y, beta0, beta1)

print(f"Beta0 otimizado: {beta0_opt:.3f}")
print(f"Beta1 otimizado: {beta1_opt:.3f}")

# Fun√ß√£o para prever
def predict_proba(X, beta0, beta1):
  z = beta0 + X.flatten() * beta1
  return sigmoid(z)

print("Probabilidades estimadas:", predict_proba(X,beta0_opt, beta1_opt))
```
Este exemplo mostra como os par√¢metros $\beta_0$ e $\beta_1$ s√£o atualizados iterativamente usando a fun√ß√£o `minimize` do `scipy`, que simula uma itera√ß√£o do m√©todo c√≠clico. Os gradientes s√£o calculados implicitamente pela fun√ß√£o, e os par√¢metros s√£o atualizados para um valor que diminui a fun√ß√£o de custo.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
<imagem: Um diagrama de fluxo que representa o processo de regress√£o de indicadores, desde a codifica√ß√£o das classes at√© a aplica√ß√£o da regra de decis√£o e a compara√ß√£o com outros m√©todos probabil√≠sticos>
```mermaid
graph LR
  subgraph "Indicator Regression Process"
        direction LR
        A["Encode Classes into Indicator Matrix Y"] --> B["Estimate Coefficients Œ≤ via Least Squares"]
        B --> C["Apply Decision Rule based on Y_hat = XŒ≤"]
        C --> D["Compare with Probabilistic Methods"]
  end
```
**Explica√ß√£o:** Este diagrama representa o fluxo do processo de regress√£o de indicadores e como ele se relaciona √† classifica√ß√£o.

A regress√£o linear em uma matriz de indicadores √© uma abordagem direta para a classifica√ß√£o, onde cada classe √© codificada como uma coluna na matriz de indicadores [^4.2]. A regress√£o linear padr√£o com m√≠nimos quadrados √© ent√£o usada para estimar os coeficientes que relacionam as vari√°veis preditoras com a matriz de indicadores. Formalmente, se temos $K$ classes, representamos as classes como vetores de dimens√£o $K$, em que cada amostra recebe um vetor com 1 na posi√ß√£o correspondente a sua classe e 0 nas demais. O modelo √© ent√£o definido como $Y = X\beta + \epsilon$, onde $Y$ √© a matriz de indicadores, $X$ a matriz de dados e $\beta$ os par√¢metros a serem otimizados. A otimiza√ß√£o por m√≠nimos quadrados busca os par√¢metros que minimizam a soma dos erros quadr√°ticos entre os valores observados de $Y$ e os valores preditos por $X\beta$ [^4.2]. Embora a regress√£o linear possa ser usada para classifica√ß√£o, ela apresenta limita√ß√µes. As probabilidades preditas podem n√£o estar dentro do intervalo [0, 1], e o m√©todo n√£o considera explicitamente as rela√ß√µes entre as classes, como o LDA faz [^4.3].
```mermaid
graph LR
    subgraph "Least Squares Formulation"
        direction LR
        A["Linear Model: Y = XŒ≤ + Œµ"] --> B["Minimize: ||Y - XŒ≤||¬≤"]
    end
```
**Lemma 2:** A regress√£o linear em matriz de indicadores, quando aplicada a problemas de classifica√ß√£o, pode levar a solu√ß√µes equivalentes √†s obtidas por modelos discriminantes lineares sob certas condi√ß√µes. No caso de classes com a mesma covari√¢ncia, a decis√£o baseada na regress√£o de indicadores pode ser interpretada como uma forma de proje√ß√£o para um espa√ßo de menor dimens√£o, similar ao que ocorre no LDA. Este lemma pode ser demonstrado ao mostrar que as dire√ß√µes de decis√£o encontradas por regress√£o linear s√£o similares √†s dire√ß√µes de proje√ß√£o √≥timas do LDA sob certas condi√ß√µes, uma vez que o m√©todo busca ajustar uma fun√ß√£o linear a uma matriz de indicadores que representam as classes. Este resultado, embora n√£o seja apresentado de forma expl√≠cita, est√° impl√≠cito em [^4.2] e [^4.3], ao comparar os resultados da regress√£o de indicadores com as solu√ß√µes de LDA.
```mermaid
graph TB
    subgraph "Equivalence between Indicator Regression and LDA"
        direction TB
        A["Indicator Regression"]
        B["Linear Discriminant Analysis (LDA)"]
        C["Conditions: Same Covariance"]
        D["Similar Decision Boundaries"]
        A --> C
        B --> C
        C --> D
    end
```

> üí° **Exemplo Num√©rico:** Vamos criar um exemplo com duas classes e duas caracter√≠sticas. Suponha que temos $X = \begin{bmatrix} 1 & 2 \\ 1.5 & 1.8 \\ 5 & 8 \\ 8 & 8 \end{bmatrix}$ e as classes $y=[0, 0, 1, 1]$. A matriz de indicadores $Y$ ser√° $\begin{bmatrix} 1 & 0 \\ 1 & 0 \\ 0 & 1 \\ 0 & 1 \end{bmatrix}$. Podemos ent√£o calcular os coeficientes $\beta$ usando m√≠nimos quadrados: $\beta = (X^T X)^{-1} X^T Y$.
```python
import numpy as np
from sklearn.linear_model import LinearRegression

# Dados de exemplo
X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8]])
y = np.array([0, 0, 1, 1])

# Criar matriz de indicadores
def indicator_matrix(y):
    classes = np.unique(y)
    Y = np.zeros((len(y), len(classes)))
    for i, label in enumerate(y):
        Y[i, np.where(classes == label)[0][0]] = 1
    return Y

Y = indicator_matrix(y)
# Calcular os coeficientes via LS
XTX = X.T @ X
XTX_inv = np.linalg.inv(XTX)
beta = XTX_inv @ X.T @ Y

# Usando sklearn
model = LinearRegression()
model.fit(X,Y)
beta_sk = model.coef_

print("Coeficientes (calculados manualmente):\n", beta)
print("Coeficientes (usando sklearn):\n", beta_sk)


# Prever as classes
Y_pred = X @ beta
# Aplicar regra de decis√£o (pegar a classe com maior valor predito)
y_pred = np.argmax(Y_pred, axis = 1)
print("Classes preditas: ", y_pred)
```
Este c√≥digo mostra como calcular os coeficientes da regress√£o linear usando m√≠nimos quadrados com uma matriz de indicadores. Compara tamb√©m o resultado usando a fun√ß√£o do scikit-learn. A matriz de indicadores, $Y$, codifica cada classe em uma coluna. Os coeficientes $\beta$ s√£o estimados usando m√≠nimos quadrados. As classes preditas s√£o obtidas aplicando uma regra de decis√£o sobre as predi√ß√µes.

**Corol√°rio 2:** Se as classes estiverem bem separadas no espa√ßo de caracter√≠sticas original, a regress√£o linear na matriz de indicadores pode encontrar fronteiras de decis√£o satisfat√≥rias, mesmo n√£o sendo uma abordagem t√£o sofisticada quanto m√©todos probabilisticos. Por exemplo, em casos em que as classes est√£o linearmente separ√°veis, o erro de treinamento da regress√£o pode ser nulo, o que corresponde √† separa√ß√£o perfeita das classes no conjunto de treinamento. Este resultado est√° relacionado com a condi√ß√£o de separabilidade dos dados, como discutido em [^4.3] e com a equival√™ncia entre as solu√ß√µes de modelos lineares sob condi√ß√µes ideais.
```mermaid
graph TB
    subgraph "Indicator Regression Properties"
        direction TB
        A["Linearly Separable Classes"]
        B["Satisfactory Decision Boundaries"]
        C["Zero Training Error"]
        A --> B
        B --> C
    end
```

Apesar da simplicidade da regress√£o linear de indicadores para classifica√ß√£o, existem limita√ß√µes importantes.  A regress√£o de indicadores pode produzir estimativas de probabilidade fora do intervalo [0, 1], e n√£o lida de forma nativa com problemas de covari√¢ncias diferentes entre classes ou n√£o linearidades. A interpreta√ß√£o dos par√¢metros pode ser dificultada, e o m√©todo pode se comportar de maneira inst√°vel em casos de multicolinearidade nas vari√°veis preditoras. A regress√£o log√≠stica, conforme [^4.4], pode ser mais adequada nesses casos, por fornecer uma interpreta√ß√£o probabil√≠stica e ser mais robusta a varia√ß√µes nos dados. Em certas situa√ß√µes, conforme apontado em [^4.2], a regress√£o de indicadores pode ser suficiente e vantajosa quando o foco principal √© a obten√ß√£o da fronteira de decis√£o linear e n√£o a estima√ß√£o das probabilidades.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem: Um mapa mental que conecta os conceitos de sele√ß√£o de vari√°veis e regulariza√ß√£o, mostrando suas rela√ß√µes com LDA, regress√£o log√≠stica e hiperplanos separadores.>

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas essenciais para lidar com problemas de alta dimensionalidade e evitar *overfitting* em modelos de classifica√ß√£o [^4.5]. A sele√ß√£o de vari√°veis busca identificar e reter apenas as vari√°veis mais relevantes para a classifica√ß√£o, eliminando aquelas que s√£o irrelevantes ou redundantes. J√° a regulariza√ß√£o adiciona um termo de penalidade √† fun√ß√£o de custo, for√ßando os par√¢metros do modelo a serem menores e mais est√°veis, o que reduz a complexidade do modelo e ajuda a evitar *overfitting*. Em modelos log√≠sticos, a regulariza√ß√£o √© frequentemente implementada atrav√©s da adi√ß√£o de penalidades L1 ou L2 √† fun√ß√£o de custo [^4.4.4], o que leva a modelos mais est√°veis e esparsos, respectivamente. A regulariza√ß√£o L1 (Lasso) imp√µe uma penalidade proporcional ao valor absoluto dos coeficientes, favorecendo modelos com poucos par√¢metros n√£o nulos. A regulariza√ß√£o L2 (Ridge) imp√µe uma penalidade proporcional ao quadrado dos coeficientes, suavizando os valores dos coeficientes e reduzindo a sua magnitude. Combinando ambas as penalidades temos o Elastic Net [^4.5], que une o melhor das duas abordagens. A fun√ß√£o de custo para a regress√£o log√≠stica com regulariza√ß√£o √© dada por $$J(\beta) =  -\frac{1}{N}\sum_{i=1}^N \left[ y_i\log(p(x_i)) + (1-y_i)\log(1-p(x_i)) \right] + \lambda_1 \sum_{j=1}^p |\beta_j| + \lambda_2 \sum_{j=1}^p \beta_j^2$$ [^4.4.5], onde o primeiro termo representa a log-verossimilhan√ßa, o segundo a penaliza√ß√£o L1 e o terceiro a penaliza√ß√£o L2.
```mermaid
graph LR
    subgraph "Regularized Logistic Regression"
        direction LR
        A["Log-Likelihood Term"]
        B["L1 Penalty Term: Œª‚ÇÅ * Œ£|Œ≤_j|"]
        C["L2 Penalty Term: Œª‚ÇÇ * Œ£Œ≤_j¬≤"]
        A --> D["Cost Function J(Œ≤)"]
        B --> D
        C --> D
    end
```
> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com 10 vari√°veis preditoras. Vamos utilizar regress√£o log√≠stica com regulariza√ß√£o L1 (Lasso). Os dados s√£o simulados:

```python
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import log_loss

# Simula√ß√£o de dados
np.random.seed(42)
n_samples = 100
n_features = 10
X = np.random.rand(n_samples, n_features)
true_betas = np.array([1, 0, 2, 0, -1, 0, 0.5, 0, 0, 0])
probs = 1 / (1 + np.exp(-np.dot(X, true_betas)))
y = np.random.binomial(1, probs)

# Separar em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Modelos de regress√£o log√≠stica
# Sem regulariza√ß√£o
model_no_reg = LogisticRegression(penalty=None, solver='lbfgs', max_iter=1000)
model_no_reg.fit(X_train, y_train)
y_pred_no_reg = model_no_reg.predict_proba(X_test)[:, 1]
cost_no_reg = log_loss(y_test, y_pred_no_reg)

# Com regulariza√ß√£o L1
lambda_l1 = 0.1
model_l1 = LogisticRegression(penalty='l1', C=1/(lambda_l1 * n_samples), solver='liblinear', max_iter=1000)
model_l1.fit(X_train, y_train)
y_pred_l1 = model_l1.predict_proba(X_test)[:, 1]
cost_l1 = log_loss(y_test, y_pred_l1)


print("Modelo sem regulariza√ß√£o:")
print(f"  - Log-Loss: {cost_no_reg:.3f}")
print(f"  - Coeficientes: {model_no_reg.coef_[0]}")

print("Modelo com regulariza√ß√£o L1 (Lasso):")
print(f"  - Log-Loss: {cost_l1:.3f}")
print(f"  - Coeficientes: {model_l1.coef_[0]}")
```

Neste exemplo, simulamos dados com alguns coeficientes n√£o nulos e outros iguais a zero. A regress√£o log√≠stica sem regulariza√ß√£o usa todos os preditores, enquanto que a regress√£o com regulariza√ß√£o L1 (Lasso) zera os coeficientes das vari√°veis menos importantes, induzindo esparsidade e simplificando o modelo. A fun√ß√£o de custo (log-loss) √© avaliada nos dados de teste. Ao comparar os coeficientes, podemos observar que o modelo com regulariza√ß√£o L1 tem v√°rios coeficientes zerados.
```mermaid
graph LR
    subgraph "Regularization Effects"
        direction LR
        A["L1 Regularization (Lasso)"] --> B["Sparse Coefficients"]
        C["L2 Regularization (Ridge)"] --> D["Shrinks Coefficients"]
        E["Elastic Net"] --> F["Combination of L1 and L2"]
    end
```
**Lemma 3:** A penaliza√ß√£o L1 em regress√£o log√≠stica leva a coeficientes esparsos. A prova deste lemma envolve a an√°lise das condi√ß√µes de otimalidade da fun√ß√£o de custo regularizada. A penalidade L1 induz coeficientes a serem exatamente zero sempre que a derivada da fun√ß√£o de custo, na dire√ß√£o de tal coeficiente, n√£o excede a penalidade $\lambda_1$ [^4.4.4]. Isso ocorre pois a fun√ß√£o de custo √© convexa e a penaliza√ß√£o √© n√£o diferenci√°vel na origem, de forma que a solu√ß√£o √≥tima tende a ocorrer quando um dos coeficientes se torna zero. Este resultado, embora n√£o seja apresentado de forma expl√≠cita, √© amplamente conhecido na teoria de otimiza√ß√£o e em modelos de classifica√ß√£o com regulariza√ß√£o L1.
```mermaid
graph TB
    subgraph "L1 Regularization and Sparsity"
        direction TB
       A["L1 Penalty"]
        B["Non-differentiable at Zero"]
        C["Optimality Condition: |‚àÇJ/‚àÇŒ≤_j| ‚â§ Œª‚ÇÅ"]
        D["Sparse Coefficients: Œ≤_j = 0"]
        A --> B
        B --> C
        C --> D
    end
```

**Prova do Lemma 3:** Considerando a fun√ß√£o de custo regularizada para regress√£o log√≠stica com penaliza√ß√£o L1, temos que a fun√ß√£o de custo √© dada por:

$$J(\beta) =  -\frac{1}{N}\sum_{i=1}^N \left[ y_i\log(p(x_i)) + (1-y_i)\log(1-p(x_i)) \right] + \lambda_1 \sum_{j=1}^p |\beta_j|$$

Para encontrar o m√≠nimo da fun√ß√£o de custo, precisamos analisar a derivada da fun√ß√£o. No caso da penalidade L1, a derivada da penalidade √© dada por $\lambda