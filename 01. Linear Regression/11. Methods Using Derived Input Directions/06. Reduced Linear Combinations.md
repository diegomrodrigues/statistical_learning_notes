## M√©todos Lineares para Regress√£o: Uma Vis√£o Geral da Redu√ß√£o da Dimensionalidade de Inputs

<imagem: Diagrama mostrando o fluxo de dados para modelos de regress√£o com redu√ß√£o de dimensionalidade, destacando as etapas de combina√ß√£o linear, sele√ß√£o de vari√°veis e regulariza√ß√£o>

### Introdu√ß√£o
Este cap√≠tulo explora m√©todos lineares de regress√£o, com um foco especial na redu√ß√£o da dimensionalidade dos inputs. Os modelos lineares, apesar de sua simplicidade, s√£o ferramentas poderosas e interpret√°veis para analisar como os inputs afetam os outputs [^3.1]. A complexidade de modelos com muitos inputs pode levar √† overfitting e dificultar a interpreta√ß√£o. Assim, estrat√©gias para reduzir o n√∫mero de inputs ou combin√°-los de maneira mais eficiente tornam-se essenciais. Modelos lineares s√£o frequentemente utilizados como base para o desenvolvimento de m√©todos mais complexos [^3.1]. Em cen√°rios de alta dimens√£o, onde o n√∫mero de inputs ($p$) se aproxima ou excede o n√∫mero de observa√ß√µes ($N$), m√©todos que reduzem a dimensionalidade dos inputs s√£o indispens√°veis para construir modelos mais robustos e com boa generaliza√ß√£o. A redu√ß√£o de dimensionalidade, conforme descrito neste cap√≠tulo, tamb√©m pode ser vista como uma forma de regulariza√ß√£o para controlar o trade-off entre bias e vari√¢ncia [^3.1].

### Conceitos Fundamentais

**Conceito 1: O Problema de Classifica√ß√£o e M√©todos Lineares**

O problema da classifica√ß√£o, em sua ess√™ncia, envolve a aloca√ß√£o de observa√ß√µes a classes predefinidas, o que se relaciona intrinsecamente com o problema da regress√£o atrav√©s da formula√ß√£o de fun√ß√µes discriminantes [^4.1]. M√©todos lineares abordam este problema assumindo que a fronteira de decis√£o entre classes pode ser representada por uma combina√ß√£o linear dos inputs. Em termos matem√°ticos, um modelo linear para classifica√ß√£o pode ser expresso como:

$$f(x) = \beta_0 + \sum_{j=1}^p x_j\beta_j$$

onde $x$ representa o vetor de inputs e $\beta$ os par√¢metros do modelo. O uso de m√©todos lineares na classifica√ß√£o tem como vantagem a simplicidade e a interpretabilidade, mas pode introduzir vi√©s se a rela√ß√£o entre inputs e classes for n√£o linear [^4.1]. A vari√¢ncia de um modelo linear, no entanto, √© geralmente menor, o que pode ser ben√©fico em casos onde temos poucos dados de treinamento, e √© um trade-off a ser considerado. Por exemplo, a regress√£o linear pode ser usada para criar uma fun√ß√£o discriminante, atribuindo uma classe baseada no sinal da fun√ß√£o linear [^4.2].

> üí° **Exemplo Num√©rico:** Vamos considerar um problema de classifica√ß√£o com duas classes (0 e 1) e dois inputs, $x_1$ e $x_2$.  Um modelo linear poderia ser $f(x) = -0.5 + 2x_1 + 1.5x_2$. Para um novo ponto, $x = (0.6, 0.8)$, calcular√≠amos $f(x) = -0.5 + 2(0.6) + 1.5(0.8) = -0.5 + 1.2 + 1.2 = 1.9$.  Como $f(x)$ √© positivo, o ponto seria classificado como classe 1. Se tiv√©ssemos um ponto $x = (0.1, 0.1)$, ent√£o $f(x) = -0.5 + 2(0.1) + 1.5(0.1) = -0.5 + 0.2 + 0.15 = -0.15$, e o ponto seria classificado como classe 0. Este exemplo ilustra a tomada de decis√£o baseada no sinal da fun√ß√£o linear.

**Lemma 1: Decomposi√ß√£o de Fun√ß√µes Discriminantes Lineares**

*Em um espa√ßo de caracter√≠sticas, qualquer fun√ß√£o discriminante linear pode ser decomposta em uma soma ponderada de proje√ß√µes sobre os eixos das caracter√≠sticas, refletindo a import√¢ncia relativa de cada input na decis√£o de classe.*

Formalmente, uma fun√ß√£o discriminante linear $f(x)$ pode ser escrita como:

$$f(x) = w^T x + b$$

onde $w$ √© o vetor de pesos e $b$ √© o bias. Podemos decompor $w$ como uma combina√ß√£o linear de vetores ortonormais $u_i$:

$$w = \sum_{i=1}^{p} \alpha_i u_i$$

onde $p$ √© a dimens√£o dos inputs. Substituindo na fun√ß√£o discriminante:

$$f(x) = \left(\sum_{i=1}^{p} \alpha_i u_i\right)^T x + b = \sum_{i=1}^{p} \alpha_i (u_i^T x) + b$$

Aqui, $u_i^T x$ representa a proje√ß√£o de $x$ sobre o vetor $u_i$, e o par√¢metro $\alpha_i$ quantifica a import√¢ncia dessa proje√ß√£o na decis√£o de classe. Esta decomposi√ß√£o explicita que a decis√£o √© uma soma ponderada das proje√ß√µes de $x$ sobre v√°rias dire√ß√µes no espa√ßo de inputs, mostrando a influ√™ncia de cada input na classifica√ß√£o. $\blacksquare$

```mermaid
graph TD
    subgraph "Linear Discriminant Function Decomposition"
        direction TB
        A["Discriminant Function: f(x) = w^T x + b"]
        B["Weight Vector Decomposition: w = Œ£ Œ±_i u_i"]
        C["Substitution: f(x) = (Œ£ Œ±_i u_i)^T x + b"]
        D["Final Form: f(x) = Œ£ Œ±_i (u_i^T x) + b"]
        A --> B
        B --> C
        C --> D
    end
```

> üí° **Exemplo Num√©rico:** Imagine um cen√°rio com dois inputs e dois vetores ortonormais, $u_1 = [1, 0]$ e $u_2 = [0, 1]$. Seja o vetor de pesos $w = [3, 2]$, que pode ser reescrito como $w = 3u_1 + 2u_2$, onde $\alpha_1 = 3$ e $\alpha_2 = 2$. A fun√ß√£o discriminante ent√£o √© $f(x) = w^Tx + b =  3(u_1^Tx) + 2(u_2^Tx) + b$. Se tivermos um input $x = [2, 4]$ e $b = -1$, ent√£o $f(x) = 3(1\cdot2+0\cdot4) + 2(0\cdot2+1\cdot4) - 1 = 3(2) + 2(4) - 1 = 6 + 8 - 1 = 13$. A decomposi√ß√£o mostra que o input $x$ √© projetado em $u_1$ e $u_2$, com pesos 3 e 2 respectivamente, e o resultado final √© a soma ponderada dessas proje√ß√µes mais o bias.

**Conceito 2: Linear Discriminant Analysis (LDA)**

A **Linear Discriminant Analysis (LDA)** √© um m√©todo de classifica√ß√£o linear que busca encontrar a combina√ß√£o linear de inputs que melhor separa as classes, assumindo que os dados em cada classe s√£o normalmente distribu√≠dos com a mesma matriz de covari√¢ncia [^4.3]. A **LDA** opera encontrando um subespa√ßo linear no qual a raz√£o entre a vari√¢ncia entre as classes e a vari√¢ncia dentro das classes √© maximizada. Matematicamente, a **LDA** busca um vetor de proje√ß√£o $w$ que maximize o crit√©rio:

$$J(w) = \frac{w^T S_B w}{w^T S_W w}$$

onde $S_B$ √© a matriz de covari√¢ncia entre as classes e $S_W$ √© a matriz de covari√¢ncia dentro das classes [^4.3]. A **LDA** faz uso dessas matrizes e das m√©dias de cada classe para definir as fronteiras de decis√£o lineares [^4.3.1], que podem ser formalizadas como:

$$\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T \Sigma^{-1} \mu_k + \ln \pi_k$$

onde $\mu_k$ √© a m√©dia da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum e $\pi_k$ √© a probabilidade a priori da classe $k$. A decis√£o √© tomada atribuindo a classe $k$ que maximiza $\delta_k(x)$. A premissa de covari√¢ncias iguais √© crucial para garantir fronteiras lineares; caso contr√°rio, as fronteiras seriam quadr√°ticas [^4.3.2], [^4.3.3].

> üí° **Exemplo Num√©rico:** Suponha um problema de classifica√ß√£o com duas classes e duas features. Temos as m√©dias das classes $\mu_1 = [1, 2]$ e $\mu_2 = [3, 1]$ e uma matriz de covari√¢ncia comum $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$.  Para um novo ponto $x = [2, 2]$, e assumindo $\pi_1 = \pi_2 = 0.5$ ($\ln(0.5) \approx -0.693$), podemos calcular os discriminantes para cada classe. Primeiro calculamos $\Sigma^{-1} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$. Temos, $\delta_1(x) = [2, 2]^T \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [1, 2] - \frac{1}{2}[1, 2]^T\begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [1, 2] -0.693 = -0.107 $ e  $\delta_2(x) = [2, 2]^T \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [3, 1] - \frac{1}{2}[3, 1]^T\begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [3, 1] -0.693 = 1.043 $. Como $\delta_2(x) > \delta_1(x)$, o ponto $x$ √© classificado como pertencente √† classe 2.

**Corol√°rio 1: Rela√ß√£o entre a Fun√ß√£o Discriminante e Proje√ß√£o em Subespa√ßos**

*A fun√ß√£o discriminante linear da LDA pode ser interpretada como uma proje√ß√£o dos inputs em um subespa√ßo de menor dimens√£o, seguida por uma decis√£o baseada na posi√ß√£o da proje√ß√£o nesse subespa√ßo.*

A fun√ß√£o discriminante LDA pode ser reescrita em termos da proje√ß√£o de $x$ no subespa√ßo determinado por $S_W^{-1} (\mu_k - \mu)$, onde $\mu$ √© a m√©dia geral, obtendo:

$$\delta_k(x) = w_k^T (x - \mu) + b_k$$

com $w_k$ sendo a dire√ß√£o de proje√ß√£o da classe $k$ e $b_k$ o bias. Essa formula√ß√£o mostra como a LDA reduz a dimensionalidade ao projetar os dados em subespa√ßos determinados pela estrutura das classes, permitindo a tomada de decis√£o em um espa√ßo de menor dimens√£o com base nas proje√ß√µes. Essa interpreta√ß√£o demonstra como a LDA reduz a dimensionalidade mantendo a informa√ß√£o discriminativa, que √© essencial para a classifica√ß√£o. [^4.3.1] $\blacksquare$

```mermaid
graph TD
    subgraph "LDA Discriminant Function as Projection"
        direction TB
        A["Original LDA Discriminant: Œ¥_k(x) = x^T Œ£^-1 Œº_k - 1/2 Œº_k^T Œ£^-1 Œº_k + ln œÄ_k"]
        B["Rewrite with Projection: Œ¥_k(x) = w_k^T(x - Œº) + b_k"]
        C["w_k Direction: w_k = Œ£^-1(Œº_k - Œº)"]
        D["Interpretation: Projection of x onto class-specific subspace"]
        A --> B
        B --> C
        C --> D
    end
```

> üí° **Exemplo Num√©rico:**  Continuando com o exemplo anterior, suponha que a m√©dia global seja $\mu = [2, 1.5]$.  Ent√£o $w_1 = \Sigma^{-1}(\mu_1 - \mu) = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} -1 \\ 0.5 \end{bmatrix} = \begin{bmatrix} -1.665 \\ 1.335 \end{bmatrix}$ e  $w_2 = \Sigma^{-1}(\mu_2 - \mu) = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ -0.5 \end{bmatrix} = \begin{bmatrix} 1.665 \\ -1.335 \end{bmatrix}$.  Podemos calcular $b_k =  -\frac{1}{2}\mu_k^T \Sigma^{-1} \mu_k + \ln \pi_k$.  A proje√ß√£o de $x=[2,2]$ na dire√ß√£o $w_1$ √© $w_1^T(x-\mu) = \begin{bmatrix} -1.665 & 1.335 \end{bmatrix}\begin{bmatrix} 0 \\ 0.5 \end{bmatrix} = 0.6675$. Assim, a classifica√ß√£o √© feita com base nas proje√ß√µes em $w_1$ e $w_2$.  Este exemplo ilustra a ideia de que o discriminante pode ser expresso como uma proje√ß√£o nos subespa√ßos relevantes.

**Conceito 3: Regress√£o Log√≠stica**

A **Logistic Regression** √© outro m√©todo de classifica√ß√£o linear, mas em vez de assumir normalidade, modela a probabilidade de uma observa√ß√£o pertencer a uma classe atrav√©s de uma fun√ß√£o sigmoidal (logit) [^4.4]. A fun√ß√£o logit transforma uma fun√ß√£o linear dos inputs em uma probabilidade, permitindo a classifica√ß√£o atrav√©s de um limiar. Formalmente, a probabilidade de pertencer √† classe 1 √© modelada como:

$$p(x) = \frac{1}{1 + e^{-(\beta_0 + \sum_{j=1}^p x_j\beta_j)}}$$

A regress√£o log√≠stica busca encontrar os par√¢metros $\beta$ que melhor se ajustam aos dados de treinamento atrav√©s da maximiza√ß√£o da verossimilhan√ßa (likelihood), conforme descrito em [^4.4.1], [^4.4.2], [^4.4.3]. A fun√ß√£o de verossimilhan√ßa $L(\beta)$ para um conjunto de dados com $n$ observa√ß√µes √© dada por:
$$L(\beta) = \prod_{i=1}^n p(x_i)^{y_i} (1-p(x_i))^{1-y_i}$$

onde $y_i$ √© 1 se a observa√ß√£o $i$ pertence √† classe 1 e 0 caso contr√°rio. A maximiza√ß√£o da log-verossimilhan√ßa √© utilizada para obter as estimativas dos par√¢metros $\beta$, utilizando m√©todos iterativos [^4.4.4], [^4.4.5].

> ‚ö†Ô∏è **Nota Importante**: A regress√£o log√≠stica, ao contr√°rio da regress√£o linear, modela a probabilidade de um evento e n√£o o valor do output diretamente [^4.4.1].

> ‚ùó **Ponto de Aten√ß√£o**:  Em datasets desbalanceados, t√©cnicas de rebalanceamento de classes ou ajuste de thresholds podem ser necess√°rias [^4.4.2].

> ‚úîÔ∏è **Destaque**: Tanto a LDA como a Regress√£o Log√≠stica podem gerar fronteiras de decis√£o lineares e, em certas situa√ß√µes, seus resultados s√£o similares, mas seus fundamentos probabil√≠sticos s√£o diferentes [^4.5].

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo de regress√£o log√≠stica com dois inputs:  $p(x) = \frac{1}{1 + e^{-(-1 + 2x_1 - 1.5x_2)}}$.  Para $x = [0.5, 0.5]$, temos o argumento da exponencial: $-1 + 2(0.5) - 1.5(0.5) = -1 + 1 - 0.75 = -0.75$. Ent√£o, $p(x) = \frac{1}{1 + e^{0.75}} \approx \frac{1}{1 + 2.117} \approx \frac{1}{3.117} \approx 0.32$.  Isso significa que a probabilidade de $x$ pertencer √† classe 1 √© de aproximadamente 32%. Para classificar, normalmente usamos um limiar (threshold) de 0.5, ent√£o esse ponto seria classificado como classe 0.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
flowchart TD
  subgraph Regress√£o de Indicadores
    A["Codificar Classes como Vari√°veis Indicadoras"] --> B["Estimar Coeficientes via LS em Matriz Indicadora"]
    B --> C["Aplicar Regra de Decis√£o Baseada nas Estimativas"]
    C --> D["Comparar com Modelos Probabil√≠sticos como LDA e Regress√£o Log√≠stica"]
  end
```

A regress√£o linear aplicada a uma matriz de indicadores (dummy coding) √© uma forma direta de estender modelos de regress√£o linear para problemas de classifica√ß√£o [^4.2]. Nessa abordagem, cada classe √© representada por uma coluna na matriz de indicadores, e o modelo de regress√£o linear √© ajustado para cada coluna [^4.2]. O modelo ent√£o prediz um valor cont√≠nuo para cada classe, e a classe com o maior valor predito √© selecionada. Matematicamente, o modelo √© expresso como:

$$Y = X \beta + \epsilon$$

onde $Y$ √© a matriz de indicadores, $X$ √© a matriz de inputs, $\beta$ √© a matriz de coeficientes, e $\epsilon$ s√£o os erros. Os par√¢metros $\beta$ s√£o estimados via m√≠nimos quadrados. A regra de decis√£o √© dada pela classe $k$ que maximiza a sa√≠da $f_k(x) = x^T \beta_k$, ou seja:

$$\text{Classe} = \arg \max_k f_k(x)$$

Apesar de sua simplicidade, essa abordagem tem limita√ß√µes, como a possibilidade de predi√ß√µes fora do intervalo [0,1] e problemas com classes n√£o balanceadas [^4.2]. Uma dessas limita√ß√µes est√° relacionada √† interpreta√ß√£o dos coeficientes, que n√£o correspondem diretamente a probabilidades, mas sim a valores que direcionam a aloca√ß√£o para uma determinada classe. Outro ponto √© o "masking problem" descrito em [^4.3], onde uma vari√°vel altamente correlacionada com outras, pode ter sua import√¢ncia mascarada no modelo, o que √© abordado pela an√°lise discriminante linear.

> üí° **Exemplo Num√©rico:**  Considere um problema com tr√™s classes. A matriz de indicadores $Y$ ter√° tr√™s colunas, onde a coluna $k$ tem 1 se a amostra pertence √† classe $k$ e 0 caso contr√°rio.  Se tivermos tr√™s amostras e duas features, a matriz de inputs pode ser $X = \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \end{bmatrix}$, e a matriz de indicadores pode ser $Y = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$.  A regress√£o linear tentar√° ajustar tr√™s modelos: $Y_{:,1} = X \beta_1 + \epsilon_1$, $Y_{:,2} = X \beta_2 + \epsilon_2$ e $Y_{:,3} = X \beta_3 + \epsilon_3$. Suponha que ap√≥s o ajuste, tenhamos $\beta_1 = [-0.5, 0.6]$, $\beta_2 = [0.2, -0.3]$ e $\beta_3 = [0.8, 0.1]$. Para um novo input $x = [2, 2]$,  as sa√≠das para cada classe s√£o: $f_1(x) = -0.5(2) + 0.6(2) = 0.2$, $f_2(x) = 0.2(2) - 0.3(2) = -0.2$ e $f_3(x) = 0.8(2) + 0.1(2) = 1.8$.  A classe predita seria a classe 3, pois ela tem o maior valor de $f_k(x)$.

**Lemma 2: Equival√™ncia de Proje√ß√µes em Cen√°rios Lineares**

*Em um cen√°rio onde as classes s√£o bem separadas por hiperplanos, a proje√ß√£o dos inputs nos hiperplanos de decis√£o derivados da regress√£o de indicadores √© equivalente (em termos de aloca√ß√£o de classes) √† proje√ß√£o obtida por discriminantes lineares.*

Em um contexto de classifica√ß√£o bin√°ria com classes bem separadas, a regress√£o linear em indicadores tenta aproximar uma fun√ß√£o indicadora para cada classe. Ao projetarmos um novo input $x$ no hiperplano de decis√£o obtido pela regress√£o de indicadores, estamos implicitamente calculando uma combina√ß√£o linear de $x$ que reflete o quanto $x$ est√° associado a cada classe. Esta combina√ß√£o linear, sob condi√ß√µes de separabilidade, √© equivalente, em termos da decis√£o final de classe, √† proje√ß√£o obtida atrav√©s de discriminantes lineares como na LDA. Formalmente, podemos mostrar que a proje√ß√£o sobre o hiperplano determinado pela regress√£o de indicadores:

$$proj(x) = \sum_{k=1}^{K} f_k(x) u_k$$

onde $f_k(x)$ s√£o as sa√≠das da regress√£o linear e $u_k$ s√£o os vetores de base, √© uma aproxima√ß√£o da proje√ß√£o em um subespa√ßo de menor dimens√£o que separa as classes. Esta equival√™ncia, no entanto, s√≥ √© v√°lida quando as classes podem ser bem separadas linearmente, e se as classes n√£o forem bem separadas, a equival√™ncia pode n√£o ser v√°lida. $\blacksquare$

```mermaid
graph TD
    subgraph "Equivalence of Projections"
        direction TB
        A["Regression on Indicators: Approximates indicator functions"]
        B["Projection onto Decision Hyperplane: Implicit linear combination"]
        C["Discriminant Function Projection: LDA-like subspace"]
        D["Equivalence Condition: Linearly Separable Classes"]
        A --> B
        B --> C
        C --> D
    end
```

**Corol√°rio 2: Simplifica√ß√£o da An√°lise de Modelo**

*A equival√™ncia entre proje√ß√µes em certas condi√ß√µes permite simplificar a an√°lise do modelo, utilizando as ferramentas de interpreta√ß√£o da an√°lise discriminante linear em conjunto com a regress√£o de indicadores.*

Se demonstrarmos a equival√™ncia entre os dois m√©todos, podemos utilizar o conhecimento sobre a estrutura das proje√ß√µes da an√°lise discriminante linear para interpretar os resultados da regress√£o em indicadores. Este resultado √© muito √∫til, pois permite utilizar t√©cnicas de redu√ß√£o de dimensionalidade em conjunto com a regress√£o em indicadores de uma forma mais coerente. Conforme mencionado em [^4.3], a an√°lise discriminante linear fornece uma estrutura te√≥rica para entender como os dados s√£o projetados em subespa√ßos que maximizam a separabilidade das classes. $\blacksquare$

"Em alguns cen√°rios, conforme apontado em [^4.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1]."

"No entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^4.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear."

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

Em cen√°rios com muitos inputs, a sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas cruciais para evitar overfitting e melhorar a interpretabilidade do modelo [^4.5]. A sele√ß√£o de vari√°veis identifica o subconjunto de inputs mais relevante para a classifica√ß√£o. J√° a regulariza√ß√£o penaliza modelos complexos, levando a solu√ß√µes mais est√°veis.
Uma abordagem √© utilizar a regulariza√ß√£o L1 e L2 [^4.4.4] na formula√ß√£o da regress√£o log√≠stica. A regulariza√ß√£o L1, adiciona um termo de penalidade proporcional ao valor absoluto dos coeficientes, induzindo sparsity, ou seja, coeficientes iguais a zero e sele√ß√£o autom√°tica de vari√°veis. A regulariza√ß√£o L2 adiciona um termo proporcional ao quadrado dos coeficientes, reduzindo a magnitude dos coeficientes e oferecendo maior estabilidade ao modelo. A combina√ß√£o de ambas as abordagens, Elastic Net, √© √∫til para obter resultados balanceados [^4.5]. Matematicamente, a fun√ß√£o de custo regularizada para a regress√£o log√≠stica pode ser definida como:

$$J(\beta) = - \frac{1}{n} \sum_{i=1}^n \left[y_i \log(p_i) + (1-y_i) \log(1-p_i)\right] + \lambda \left( \alpha \sum_{j=1}^p |\beta_j| + (1-\alpha) \sum_{j=1}^p \beta_j^2 \right)$$

onde $p_i$ √© a probabilidade predita para a observa√ß√£o $i$, $\lambda$ √© o par√¢metro de regulariza√ß√£o, e $\alpha$ controla o trade-off entre L1 e L2 [^4.5.1].

> üí° **Exemplo Num√©rico:** Considere a regress√£o log√≠stica com regulariza√ß√£o L1 e L2.  Suponha que a fun√ß√£o de custo seja: $J(\beta) =  -\frac{1}{n}\sum_{i=1}^{n} \left[y_i \log(p_i) + (1-y_i) \log(1-p_i)\right] + \lambda \left(\alpha \sum_{j=1}^{p} |\beta_j| + (1-\alpha) \sum_{j=1}^{p} \beta_j^2\right)$. Com $\lambda = 0.1$ e $\alpha = 0.5$ (Elastic Net), se ap√≥s a otimiza√ß√£o tivermos $\beta = [1.2, 0, -0.8, 0.1]$,  a penalidade para L1 seria $\lambda\alpha(1.2 + 0 + 0.8 + 0.1) = 0.1 * 0.5 * 2.1 = 0.105$, e a penalidade para L2 seria $\lambda(1-\alpha)(1.2^2 + 0 + (-0.8)^2 + 0.1^2) = 0.1 * 0.5 * (1.44 + 0.64 + 0.01) = 0.1 * 0.5 * 2.09 = 0.1045$.  O termo de penalidade total √© a soma das duas.  Observe que a regulariza√ß√£o L1 induziu um dos coeficientes a ser zero (sele√ß√£o de vari√°veis), e os demais foram reduzidos em magnitude pela regulariza√ß√£o L2.

**Lemma 3: Sparsity Induzida pela Penaliza√ß√£o L1**

*A penaliza√ß√£o L1 na regress√£o log√≠stica leva a coeficientes esparsos (isto √©, muitos coeficientes iguais a zero), o que efetivamente realiza a sele√ß√£o de vari√°veis.*

A penaliza√ß√£o L1 adiciona um termo proporcional √† soma dos valores absolutos dos coeficientes na fun√ß√£o de custo. Este termo, devido √† sua n√£o diferenciabilidade na origem, induz os coeficientes a se tornarem exatamente zero em vez de simplesmente se aproximarem de zero. Para a regress√£o log√≠stica, a fun√ß√£o de custo com penaliza√ß√£o L1 pode ser expressa como:

$$J(\beta) = -\frac{1}{N}\sum_{i=1}^{N} \left[ y_i \log(p_i) + (1-y_i) \log(1-p_i) \right] + \lambda \sum_{j=1}^p |\beta_j|$$

A presen√ßa do termo $\lambda \sum_{j=1}^p |\beta_j|$ na fun√ß√£o de custo faz com que o processo de otimiza√ß√£o empurre certos coeficientes para zero. Isso ocorre porque a n√£o-diferenciabilidade da fun√ß√£o no ponto zero leva √† forma√ß√£o de "cantos" no espa√ßo de par√¢metros, onde a otimiza√ß√£o tende a concentrar as solu√ß√µes, resultando em muitos coeficientes exatamente iguais a zero [^4.4.4]. A solu√ß√£o √≥tima encontra um balan√ßo entre a fun√ß√£o de verossimilhan√ßa (fitting) e a penalidade L1 (sparsity). $\blacksquare$

```mermaid
graph TD
    subgraph "L1 Regularization and Sparsity"
        direction TB
         A["Regularized Cost Function: J(Œ≤) = -1/N Œ£ [y_i log(p_i) + (1-y_i) log(1-p_i)] + Œª Œ£ |Œ≤_j|"]
        B["L1 Penalty: Œª Œ£ |Œ≤_j|"]
        C["Non-Differentiability at Zero: Induces exact zeros"]
        D["Sparsity: Many coefficients equal to zero"]
        A --> B
        B --> C
        C --> D
    end
```

**Prova do Lemma 3:**
A fun√ß√£o de custo com penaliza√ß√£o L1 na regress√£o log√≠stica √©:

$$ J(\beta) = L(\beta) + \lambda ||\beta||_1$$

onde $L(\beta)$ √© a fun√ß√£o log-verossimilhan√ßa e $||\beta||_1$ √© a norma L1 de $\beta$. A otimiza√ß√£o desta fun√ß√£o envolve encontrar o $\beta$ que minimiza $J(\beta)$. A derivada da norma L1 n√£o √© diferenci√°vel em zero, o que leva √† seguinte condi√ß√£o de otimalidade no ponto de m√≠nimo:

$$ \frac{\partial L(\beta)}{\partial \beta_j} + \lambda \text{sign}(\beta_j) = 0$$

Se o valor da derivada da fun√ß√£o log-verossimilhan√ßa no ponto zero for menor que $\lambda$ em m√≥dulo, isto √©, $\vert \frac{\partial L(\beta)}{\partial \beta_j} \vert < \lambda$, ent√£o o coeficiente $\beta_j$ ser√° exatamente zero [^4.4.3]. Isto acontece porque, para minimizar a fun√ß√£o de custo, o termo de penalidade L1 "empurra" o coeficiente para zero, criando sparsity. $\blacksquare$

**Corol√°rio 3: Interpretabilidade dos Modelos Classificat√≥rios**

*A esparsidade induzida pela penaliza√ß√£o L1 simplifica a interpreta√ß√£o do modelo, pois apenas os inputs com coeficientes n√£o nulos s√£o considerados relevantes para a classifica√ß√£o.*

A sele√ß√£o de vari√°veis atrav√©s da penaliza√ß√£o L1 leva a modelos mais interpret√°veis, pois apenas um subconjunto de inputs tem coeficientes diferentes de zero. Isso significa que apenas esses inputs t√™m influ√™ncia na decis√£o final da classe, simplificando a an√°lise e identificando os fatores mais relevantes para o problema da classifica√ß√£o [^4.4.5]. A interpretabilidade √© crucial em muitos contextos, onde o entendimento dos mecanismos de decis√£o √© t√£o importante quanto a precis√£o da classifica√ß√£o. $\blacksquare$

> ‚ö†Ô∏è **Ponto Crucial**: L1 e L2 podem ser combinadas (Elastic Net) para aproveitar vantagens de ambos os tipos de regulariza√ß√£o, conforme discutido em [^4.5].

### Separating Hyperplanes e Perceptrons

A ideia de maximizar a margem de separa√ß√£o entre classes leva √† formula√ß√£o do problema de encontrar um hiperplano √≥timo [^4.5.2]. Um hiperplano √© definido pela equa√ß√£o:

$$w^T x + b = 0$$

onde $w$ √© o vetor normal ao hiperplano, e $b$ √© o offset. O hiperplano √≥timo √© aquele que maximiza a dist√¢ncia (margem) entre ele e as observa√ß√µes mais pr√≥ximas de cada classe. Este problema pode ser resolvido atrav√©s de programa√ß√£o quadr√°tica, e uma solu√ß√£o dual √© obtida usando o dual de Wolfe [^4.5.2]. Esta solu√ß√£o dual permite expressar a solu√ß√£o do hiperplano em termos de uma combina√ß√£o linear dos pontos de suporte:

$$w = \sum_i \alpha_i y_i x_i$$

onde $y_i$ s√£o os r√≥tulos de classe e $x_i$ s√£o os pontos de suporte [^4.5.2].
O Perceptron de Rosenblatt √© um algoritmo de aprendizagem de hiperplanos que busca iterativamente encontrar um hiperplano que separa as classes [^4.5.1]. O algoritmo ajusta os par√¢metros do hiperplano ($w$ e $b$) com base em observa√ß√µes classificadas incorretamente. Sob condi√ß√µes de separabilidade linear, o Perceptron converge para um hiperplano separador, embora n√£o necessariamente o √≥timo. [^4.5.1].

> üí° **Exemplo Num√©rico:** Suponha que, ap√≥s v√°rias itera√ß√µes do algoritmo Perceptron, encontramos um hiperplano dado por $w = [2, -1]$ e $b = -1$.  Para um input $x = [1, 3]$, calcular√≠amos $w^Tx + b = 2(1) - 1(3) - 1 = 2 - 3 - 1 = -2$. Como o resultado √© negativo, o Perceptron classificaria $x$ como pertencente √† classe -1. Se a classifica√ß√£o correta fosse classe 1, o Perceptron ajustaria os par√¢metros $w$ e $b$ para corrigir esse erro, buscando um hiperplano que separe melhor as classes.

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**
A an√°lise discriminante linear (LDA) e a regra de decis√£o Bayesiana s√£o abordagens para classifica√ß√£o que, sob certas condi√ß√µes, podem levar a resultados semelhantes, mas com formula√ß√µes e motiva√ß√µes diferentes. Vamos analisar as diferen√ßas sob a premissa de distribui√ß√µes Gaussianas com covari√¢ncias iguais.

*   **Regra de Decis√£o Bayesiana:** Assume que as observa√ß√µes em cada classe s√£o geradas por uma distribui√ß√£o Gaussiana e busca a classe que maximiza a probabilidade posterior [^4.3]. Formalmente, dado um input $x$, a regra de decis√£o Bayesiana aloca $x$ para a classe $k$ que maximiza:
    $$P(C_k | x) = \frac{P(x | C_k)P(C_k)}{P(x)}$$

    onde $P(C_k | x)$ √© a probabilidade posterior da classe $k$ dado $x$, $P(x | C_k)$ √© a probabilidade de $x$ dado a classe $k$, e $P(C_k)$ √© a probabilidade a priori da classe $k$. Assumindo que $P(x | C_k)$ segue uma distribui√ß√£o Gaussiana com m√©dia $\mu_k$ e covari√¢ncia $\Sigma_k$, e assumindo que $P(x) $ √© constante, maximizar $P(C_k | x)$ se torna equivalente a maximizar o discriminante:

    $$\delta_k(x) = \ln(P(C_k)) - \frac{1}{2}(x - \mu_k)^T \Sigma_k^{-1}(x-\mu_k)$$

    Quando as matrizes de covari√¢ncia s√£o iguais, i.e., $\Sigma_k = \Sigma$ para todas as classes $k$, o discriminante se reduz a:
   $$\delta_k(x) = \ln(P(C_k)) + x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T \Sigma^{-1} \mu_k$$

*   **Linear