## M√©todos Lineares para Regress√£o e sua Conex√£o com Programa√ß√£o Linear

<imagem: Mapa mental que conecta os principais conceitos de regress√£o linear, m√©todos de sele√ß√£o de vari√°veis e programa√ß√£o linear, destacando as rela√ß√µes entre m√≠nimos quadrados, regulariza√ß√£o e otimiza√ß√£o.>

### Introdu√ß√£o

Este cap√≠tulo explora os m√©todos lineares para regress√£o, uma classe de modelos fundamentais no aprendizado estat√≠stico, que foram desenvolvidos em grande parte na era pr√©-computacional da estat√≠stica [^3.1]. Apesar disso, continuam sendo essenciais devido √† sua simplicidade, interpretabilidade e, em algumas situa√ß√µes, desempenho superior em compara√ß√£o com modelos n√£o lineares mais complexos, especialmente quando se lida com poucos dados de treinamento, baixa rela√ß√£o sinal-ru√≠do ou dados esparsos [^3.1]. Al√©m disso, os m√©todos lineares formam a base para muitas t√©cnicas n√£o lineares, que s√£o frequentemente generaliza√ß√µes diretas dos m√©todos lineares [^3.1].

Neste contexto, exploraremos a fundo o modelo de regress√£o linear, incluindo suas formula√ß√µes, otimiza√ß√µes e conex√µes com programa√ß√£o linear, bem como m√©todos para a sele√ß√£o de vari√°veis e regulariza√ß√£o. Nosso objetivo √© estabelecer uma compreens√£o robusta desses m√©todos como alicerce para estudos mais avan√ßados em aprendizado de m√°quina.

### Conceitos Fundamentais

**Conceito 1:** O problema de **regress√£o linear** busca modelar a rela√ß√£o entre uma vari√°vel de resposta (Y) e um conjunto de vari√°veis preditoras ($X_1, ..., X_p$), assumindo que a fun√ß√£o de regress√£o $E(Y|X)$ √© linear nos inputs [^3.1]. Isso pode ser expresso como:

$$
f(x) = \beta_0 + \sum_{j=1}^{p} X_j\beta_j
$$
```mermaid
graph LR
    subgraph "Linear Regression Model"
        direction TB
        A["f(x)"] --> B["Œ≤_0"]
        A --> C["Œ£(X_j * Œ≤_j)"]
        C --> D["j = 1 to p"]
    end
```

Onde $\beta_j$ s√£o os par√¢metros ou coeficientes desconhecidos que precisam ser estimados a partir dos dados. As vari√°veis $X_j$ podem ser quantitativas, transforma√ß√µes de entradas quantitativas (como log, raiz quadrada ou quadrado), expans√µes de base, codifica√ß√µes num√©ricas ou 'dummy' de n√≠veis de inputs qualitativos, ou intera√ß√µes entre vari√°veis [^3.2]. A linearidade no modelo refere-se aos par√¢metros e n√£o necessariamente √†s vari√°veis de entrada. Em termos de vi√©s e vari√¢ncia, modelos lineares geralmente exibem baixo vi√©s mas alta vari√¢ncia quando o n√∫mero de par√¢metros se aproxima do n√∫mero de dados [^3.1].

> üí° **Exemplo Num√©rico:** Imagine que estamos tentando prever o pre√ßo de uma casa (Y) com base em seu tamanho em metros quadrados ($X_1$) e n√∫mero de quartos ($X_2$). Nosso modelo de regress√£o linear poderia ser:
>
> $$
> \text{Pre√ßo} = \beta_0 + \beta_1 \cdot \text{Tamanho} + \beta_2 \cdot \text{Quartos}
> $$
>
> Ap√≥s ajustar o modelo aos dados de treinamento, obtemos: $\beta_0 = 50000$, $\beta_1 = 1500$, e $\beta_2 = 30000$. Isso significa que, para cada metro quadrado adicional, o pre√ßo aumenta em R\\$1500, e cada quarto adicional aumenta o pre√ßo em R\\$30000 (com um pre√ßo base de R\\$50000).
>  
>  Se uma casa tem 100 metros quadrados e 3 quartos, o pre√ßo previsto seria:
>  
> $$
> \text{Pre√ßo} = 50000 + 1500 \cdot 100 + 30000 \cdot 3 = 50000 + 150000 + 90000 = 290000
> $$

**Lemma 1:**  A regress√£o linear pode ser vista como uma proje√ß√£o ortogonal da vari√°vel de resposta Y no subespa√ßo gerado pelas vari√°veis preditoras $X_1, ..., X_p$ [^3.2].  Se as colunas da matriz de dados X forem ortogonais entre si, ent√£o a estimativa de cada coeficiente $\beta_j$ √© independente dos outros coeficientes, resultando em uma solu√ß√£o mais est√°vel [^3.2]. No entanto, em dados observacionais, ortogonalidade entre as vari√°veis de entrada √© incomum, e a regress√£o linear precisa lidar com a multicolinearidade [^3.2].

**Prova do Lemma 1:** Para provar este lemma, podemos demonstrar que a solu√ß√£o de m√≠nimos quadrados $\hat{\beta} = (X^TX)^{-1}X^Ty$ minimiza a soma dos quadrados dos res√≠duos $RSS = (y - X\beta)^T(y - X\beta)$. O vetor res√≠duo $(y-X\hat{\beta})$ √© ortogonal ao subespa√ßo gerado pelas colunas de X. Assim, $\hat{\beta}$ √© o vetor que gera a proje√ß√£o ortogonal de y nesse subespa√ßo. $\blacksquare$

```mermaid
graph LR
    subgraph "Orthogonal Projection in Linear Regression"
        direction TB
        A["Variable of Response 'y'"] --> B["Subspace of Predictors X"]
        B --> C["Orthogonal Projection 'XŒ≤ÃÇ'"]
         C --> D["Residue Vector 'y - XŒ≤ÃÇ' is orthogonal to subspace X"]
        B --> E["Œ≤ÃÇ = (X^T*X)^-1 * X^T*y"]
        E --> F["Minimizes RSS = ||y - XŒ≤||¬≤"]
    end
```

> üí° **Exemplo Num√©rico:** Suponha que temos apenas duas amostras com uma √∫nica vari√°vel preditora, onde $X = \begin{bmatrix} 1 \\ 2 \end{bmatrix}$ e $y = \begin{bmatrix} 3 \\ 5 \end{bmatrix}$. Para encontrar $\hat{\beta}$, primeiro calculamos $X^TX$:
>
> $$
> X^TX = \begin{bmatrix} 1 & 2 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} = 1^2 + 2^2 = 5
> $$
>
> Em seguida, calculamos $(X^TX)^{-1}$:
>
> $$
> (X^TX)^{-1} = \frac{1}{5}
> $$
>
> Agora, calculamos $X^Ty$:
>
> $$
> X^Ty = \begin{bmatrix} 1 & 2 \end{bmatrix} \begin{bmatrix} 3 \\ 5 \end{bmatrix} = (1 \cdot 3) + (2 \cdot 5) = 13
> $$
>
> Finalmente, encontramos $\hat{\beta}$:
>
> $$
> \hat{\beta} = (X^TX)^{-1} X^Ty = \frac{1}{5} \cdot 13 = 2.6
> $$
>
> O modelo de regress√£o √© ent√£o $f(x) = 2.6x$. O vetor res√≠duo √©:
>
> $$
> e = y - X\hat{\beta} = \begin{bmatrix} 3 \\ 5 \end{bmatrix} - \begin{bmatrix} 1 \\ 2 \end{bmatrix} 2.6 = \begin{bmatrix} 3 \\ 5 \end{bmatrix} - \begin{bmatrix} 2.6 \\ 5.2 \end{bmatrix} = \begin{bmatrix} 0.4 \\ -0.2 \end{bmatrix}
> $$
>
> Este vetor res√≠duo √© ortogonal a X,  $X^T e = (1 \cdot 0.4) + (2 \cdot -0.2) = 0$. A proje√ß√£o de y no espa√ßo gerado por X √© o vetor $X \hat{\beta} = \begin{bmatrix} 2.6 \\ 5.2 \end{bmatrix}$, que √© a melhor aproxima√ß√£o linear de y.

**Conceito 2:** **Linear Discriminant Analysis (LDA)**, embora seja um m√©todo de classifica√ß√£o, tamb√©m tem conex√µes com a regress√£o linear quando se analisa a regress√£o de matrizes indicadoras. LDA busca encontrar a melhor combina√ß√£o linear de vari√°veis preditoras que maximizam a separa√ß√£o entre classes, assumindo que as classes seguem distribui√ß√µes gaussianas com a mesma matriz de covari√¢ncia [^4.3]. A fronteira de decis√£o √© linear e constru√≠da utilizando as m√©dias de classe e uma matriz de covari√¢ncia comum [^4.3.1]. No LDA, as proje√ß√µes lineares s√£o otimizadas para maximizar a raz√£o entre a varia√ß√£o entre classes e a varia√ß√£o dentro da classe [^4.3.2].
```mermaid
graph LR
    subgraph "Linear Discriminant Analysis (LDA)"
        direction TB
        A["Maximize Separation Between Classes"] --> B["Assumes Gaussian Distributions"]
        B --> C["Common Covariance Matrix"]
        C --> D["Linear Decision Boundary"]
         D --> E["Optimizes Linear Projections"]
        E --> F["Maximize (Between Class Variance) / (Within Class Variance)"]
    end
```

**Corol√°rio 1:** O LDA pode ser visto como uma regress√£o linear da matriz indicadora da classe (codifica√ß√£o 1-de-K) com as vari√°veis preditoras. Quando as classes s√£o bem separadas e as suposi√ß√µes de normalidade s√£o atendidas, a regress√£o linear de matrizes indicadoras pode gerar resultados semelhantes a LDA [^4.2]. A matriz de covari√¢ncia comum no LDA pode ter um impacto significativo na fronteira de decis√£o, como discutido em [^4.3.1].

**Conceito 3:** **Logistic Regression** √© um modelo probabil√≠stico que modela a probabilidade de um evento bin√°rio usando a fun√ß√£o log√≠stica ou sigmoide. O logit, que √© o log da raz√£o de chances (log-odds), √© modelado como uma combina√ß√£o linear das vari√°veis preditoras [^4.4]. A fun√ß√£o log√≠stica √© definida como $p(x) = \frac{e^{\beta_0 + \beta^T x}}{1+e^{\beta_0 + \beta^T x}}$, onde $p(x)$ √© a probabilidade da classe 1. Os par√¢metros s√£o estimados por meio da maximiza√ß√£o da verossimilhan√ßa, e n√£o por m√≠nimos quadrados [^4.4.1]. A regress√£o log√≠stica √© particularmente √∫til em problemas de classifica√ß√£o bin√°ria, e, em certas condi√ß√µes, suas decis√µes de classe podem se aproximar das decis√µes geradas pelo LDA [^4.5].

```mermaid
graph LR
    subgraph "Logistic Regression"
        direction TB
        A["Model Probability of Binary Outcome"] --> B["Uses Logistic (Sigmoid) Function"]
        B --> C["p(x) =  e^(Œ≤_0 + Œ≤^T x) / (1 + e^(Œ≤_0 + Œ≤^T x))"]
        C --> D["Logit is linear: log(p(x)/(1-p(x)))"]
        D --> E["Parameters estimated by Maximum Likelihood (MLE)"]
          E --> F["Useful for Binary Classification"]
    end
```

> üí° **Exemplo Num√©rico:** Suponha que estamos modelando a probabilidade de um cliente comprar um produto (Y=1) com base em sua idade (X). O modelo de regress√£o log√≠stica poderia ser:
>
> $$
> p(x) = \frac{e^{\beta_0 + \beta_1 \cdot \text{Idade}}}{1+e^{\beta_0 + \beta_1 \cdot \text{Idade}}}
> $$
>
> Ap√≥s ajustar o modelo, obtemos $\beta_0 = -5$ e $\beta_1 = 0.1$. Para um cliente de 50 anos, a probabilidade de comprar o produto seria:
>
> $$
> p(50) = \frac{e^{-5 + 0.1 \cdot 50}}{1+e^{-5 + 0.1 \cdot 50}} = \frac{e^0}{1+e^0} = \frac{1}{1+1} = 0.5
> $$
>
> J√° para um cliente de 20 anos:
>
> $$
> p(20) = \frac{e^{-5 + 0.1 \cdot 20}}{1+e^{-5 + 0.1 \cdot 20}} = \frac{e^{-3}}{1+e^{-3}} \approx \frac{0.05}{1.05} \approx 0.047
> $$
>
> Assim, a probabilidade de compra aumenta com a idade neste modelo.

> ‚ö†Ô∏è **Nota Importante**: Regress√£o log√≠stica √© otimizada atrav√©s da maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa (likelihood function), ao inv√©s da minimiza√ß√£o da soma dos quadrados dos res√≠duos, como na regress√£o linear padr√£o [^4.4.1].

> ‚ùó **Ponto de Aten√ß√£o**: A regress√£o log√≠stica pode apresentar problemas quando lidamos com dados desbalanceados, ou seja, quando uma das classes √© muito mais frequente que as outras [^4.4.2]. T√©cnicas como reamostragem ou penaliza√ß√£o de classes podem ser usadas para contornar esse problema.

> ‚úîÔ∏è **Destaque**: Em certas situa√ß√µes, as estimativas dos par√¢metros em LDA e regress√£o log√≠stica podem apresentar correla√ß√µes, especialmente quando a distribui√ß√£o dos dados se aproxima de uma distribui√ß√£o normal multivariada [^4.5].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

<imagem: Diagrama de fluxo que mostra como a regress√£o linear √© usada para classifica√ß√£o, incluindo as etapas de codifica√ß√£o de classes, estima√ß√£o de coeficientes por m√≠nimos quadrados, e aplica√ß√£o da regra de decis√£o.>
```mermaid
flowchart TD
    A[Codifica√ß√£o de Classes] --> B[Estima√ß√£o de Coeficientes (LS)];
    B --> C[Regra de Decis√£o];
    C --> D[Previs√£o da Classe];
    D --> E[Avalia√ß√£o de Performance];
```

A regress√£o linear, quando aplicada a uma matriz de indicadores, representa uma abordagem interessante para problemas de classifica√ß√£o [^4.2]. A ideia √© codificar cada classe como uma vari√°vel bin√°ria (por exemplo, usando codifica√ß√£o 1-de-K para K classes) e aplicar a regress√£o linear a cada uma dessas classes, tratando-as como respostas separadas [^4.2]. Os coeficientes resultantes do modelo s√£o ent√£o usados para projetar novos dados em um espa√ßo de decis√£o, sendo o limiar de decis√£o geralmente determinado pela classe que tem a maior proje√ß√£o.

No entanto, esta abordagem tem algumas limita√ß√µes. Uma delas √© que os resultados da regress√£o linear podem gerar predi√ß√µes fora do intervalo [0, 1], o que dificulta a interpreta√ß√£o em termos de probabilidades de classe [^4.2]. Al√©m disso, essa abordagem ignora explicitamente as rela√ß√µes entre as vari√°veis indicadoras, que podem ser importantes na modelagem de decis√µes de classe. Outra limita√ß√£o surge quando as classes s√£o linearmente n√£o separ√°veis, pois a regress√£o linear de matrizes indicadoras tenta encontrar uma separa√ß√£o linear, o que pode resultar em mau desempenho [^4.1].

**Lemma 2:** A proje√ß√£o de dados para classifica√ß√£o usando regress√£o linear de matrizes indicadoras pode ser interpretada como a busca por um conjunto de hiperplanos que minimizam a soma dos quadrados dos erros na atribui√ß√£o de classes. Se as classes forem bem separadas, estes hiperplanos tendem a ser uma boa aproxima√ß√£o das fronteiras de decis√£o ideais, sob condi√ß√µes em que a regress√£o de indicadores pode fornecer uma aproxima√ß√£o da regra de decis√£o bayesiana [^4.2].

**Prova do Lemma 2:** Seja Y uma matriz de indicadores onde cada linha representa uma observa√ß√£o, e cada coluna representa uma classe. A regress√£o linear em Y pode ser escrita como: $\hat{Y} = X(X^TX)^{-1}X^TY$.  Os valores em $\hat{Y}$ representam as previs√µes de associa√ß√£o √† classe. Minimizar a soma dos quadrados dos res√≠duos significa encontrar as proje√ß√µes ortogonais de cada linha de Y no subespa√ßo definido pelas colunas de X. Assim, para uma nova observa√ß√£o $x_i$, a decis√£o de classe √© baseada na linha de $\hat{Y_i}$ que apresenta o maior valor. $\blacksquare$
```mermaid
graph LR
    subgraph "Regression of Indicator Matrices for Classification"
        direction TB
        A["Indicator Matrix 'Y' (1-of-K coding)"] --> B["Linear Regression '≈∂ = X(X^TX)^-1 * X^T * Y'"]
        B --> C["≈∂ represents class association predictions"]
          C --> D["Minimizes Sum of Squared Errors"]
        D --> E["Finds orthogonal projections of Y into subspace X"]
        E --> F["Decision Rule: assign x to the class with maximum value in ≈∂"]

    end
```

> üí° **Exemplo Num√©rico:** Suponha que temos tr√™s classes (A, B e C) e duas observa√ß√µes com uma √∫nica vari√°vel preditora. A matriz de indicadores $Y$ e a matriz de dados $X$ poderiam ser:
>
> $$
> Y = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \end{bmatrix}, \quad X = \begin{bmatrix} 1 \\ 2 \end{bmatrix}
> $$
>
> Aqui, a primeira observa√ß√£o pertence √† classe A e a segunda √† classe B. Para aplicar regress√£o linear para classifica√ß√£o, fazemos a regress√£o de $Y$ em $X$. Calculamos primeiro $X^T X = 5$, $(X^T X)^{-1} = 1/5$ e $X^T Y = \begin{bmatrix} 1 & 2 \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \end{bmatrix} = \begin{bmatrix} 1 & 2 & 0 \end{bmatrix}$.
>
> Ent√£o, $\hat{Y} = X(X^TX)^{-1}X^TY = \begin{bmatrix} 1 \\ 2 \end{bmatrix} \frac{1}{5} \begin{bmatrix} 1 & 2 & 0 \end{bmatrix} = \begin{bmatrix} 1/5 & 2/5 & 0 \\ 2/5 & 4/5 & 0 \end{bmatrix}$.
>
> Para classificar uma nova amostra com $x = 1.5$, calculamos $\hat{y}_{new} = 1.5 \cdot \begin{bmatrix} 1/5 \\ 2/5 \\ 0\end{bmatrix} = \begin{bmatrix} 0.3 \\ 0.6 \\ 0 \end{bmatrix}$. Escolhemos a classe com maior valor, que neste caso √© a classe B.

**Corol√°rio 2:** Em situa√ß√µes onde as classes s√£o bem separadas e o n√∫mero de amostras de treinamento por classe √© suficientemente alto, a regress√£o linear de matrizes indicadoras pode gerar fronteiras de decis√£o linear que se aproximam das fronteiras obtidas com LDA, especialmente quando as matrizes de covari√¢ncia dentro de cada classe s√£o aproximadamente iguais [^4.3]. A abordagem de regress√£o linear de indicadores busca um ajuste linear das probabilidades de pertin√™ncia √† classe, enquanto LDA busca maximizar a raz√£o da vari√¢ncia entre classes pela vari√¢ncia dentro da classe, ambas levando a fronteiras lineares em certas condi√ß√µes [^4.3].

‚ÄúEm alguns cen√°rios, conforme apontado em [^4.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1].‚Äù

‚ÄúNo entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^4.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear.‚Äù

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

<imagem: Mapa mental mostrando as conex√µes entre m√©todos de sele√ß√£o de vari√°veis, regulariza√ß√£o, e os m√©todos LDA, Regress√£o Log√≠stica e Hiperplanos Separadores.>
```mermaid
graph LR
    subgraph "Feature Selection & Regularization"
    direction TB
    A["Multicollinearity & Overfitting Issues"] --> B["Feature Selection Methods"]
    A --> C["Regularization Techniques"]
    B --> D["Selects subset of relevant predictors"]
    C --> E["Adds penalty to cost function"]
    E --> F["Reduces magnitude of coefficients"]
        F--> G["Controls model complexity"]
    end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o essenciais para o tratamento da multicolinearidade e do overfitting em modelos de classifica√ß√£o [^4.5]. A multicolinearidade ocorre quando duas ou mais vari√°veis preditoras s√£o altamente correlacionadas, causando instabilidade nos coeficientes do modelo e dificuldade na interpreta√ß√£o [^4.5]. Overfitting ocorre quando um modelo se ajusta muito bem aos dados de treinamento, mas tem mau desempenho em dados novos. Para combater esses problemas, m√©todos de sele√ß√£o de vari√°veis escolhem um subconjunto relevante de preditores, enquanto t√©cnicas de regulariza√ß√£o adicionam uma penalidade √† fun√ß√£o de custo para reduzir a magnitude dos coeficientes e a complexidade do modelo [^4.4.4].

A regulariza√ß√£o pode ser aplicada em modelos de regress√£o log√≠stica por meio da adi√ß√£o de termos de penaliza√ß√£o √† fun√ß√£o de verossimilhan√ßa [^4.4.4]. As penalidades L1 (Lasso) promovem a esparsidade, ou seja, levam a coeficientes que s√£o exatamente iguais a zero, efetivamente removendo vari√°veis do modelo. J√° as penalidades L2 (Ridge) reduzem a magnitude dos coeficientes, o que resulta em modelos mais est√°veis.

A fun√ß√£o de custo com penalidade L1, por exemplo, √© expressa como:
$$
L(\beta) = -\sum_{i=1}^N [y_i \log p(x_i) + (1-y_i) \log(1-p(x_i))] + \lambda \sum_{j=1}^p |\beta_j|
$$

Onde $\lambda$ √© um par√¢metro de ajuste que controla a intensidade da penaliza√ß√£o, e o primeiro termo corresponde √† verossimilhan√ßa logar√≠tmica [^4.4.4].
```mermaid
graph LR
    subgraph "L1 Regularization in Logistic Regression"
       direction TB
       A["Cost Function 'L(Œ≤)'"] --> B["Log-Likelihood Term: '-Œ£[y_i*log(p(x_i)) + (1-y_i)*log(1-p(x_i))]'"]
       A --> C["L1 Penalty Term: 'Œª*Œ£|Œ≤_j|'"]
       C --> D["Œª controls the intensity"]
       D --> E["Promotes sparsity by setting some coefficients to zero"]
    end
```

> üí° **Exemplo Num√©rico:** Suponha que estamos fazendo uma regress√£o log√≠stica com duas vari√°veis preditoras ($X_1$ e $X_2$). A fun√ß√£o de custo sem regulariza√ß√£o √© $L_0(\beta)$. Ap√≥s aplicar a regulariza√ß√£o L1 com $\lambda = 0.5$, a fun√ß√£o de custo passa a ser $L_1(\beta) = L_0(\beta) + 0.5(|\beta_1| + |\beta_2|)$. A regulariza√ß√£o penaliza os valores absolutos dos coeficientes. Se durante o processo de otimiza√ß√£o, $\beta_2$ tem um valor pequeno (pr√≥ximo a zero), a penaliza√ß√£o L1 vai for√ßar esse valor a ser exatamente zero, eliminando essa vari√°vel do modelo, se o ganho na fun√ß√£o de verossimilhan√ßa n√£o compensar a penalidade.
>
> Para demonstrar o efeito do $\lambda$, podemos comparar os resultados com diferentes valores de $\lambda$ em um conjunto de dados simulado. Abaixo est√° um exemplo simples com Python usando `sklearn`:

```python
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# Generate sample data
np.random.seed(42)
n_samples = 100
X = np.random.rand(n_samples, 5)
true_coefs = np.array([1, -2, 0.5, 0, 0])  # Only 3 features are relevant
y = np.random.binomial(1, 1 / (1 + np.exp(-np.dot(X, true_coefs))))

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train logistic regression with L1 regularization for different lambdas
lambdas = [0.01, 0.1, 1, 10]
results = []

for lam in lambdas:
    model = LogisticRegression(penalty='l1', C=1/lam, solver='liblinear', random_state=42)
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    coef = model.coef_[0]
    results.append({
        'lambda': lam,
        'accuracy': accuracy,
        'coefficients': coef,
    })
    
df_results = pd.DataFrame(results)
print(df_results)
```

> A tabela abaixo mostra os resultados com diferentes valores de $\lambda$. √â poss√≠vel observar que √† medida que $\lambda$ aumenta, o n√∫mero de coeficientes zero aumenta, indicando uma maior esparsidade.
>
> | lambda | accuracy | coefficients                              |
> |--------|----------|-------------------------------------------|
> | 0.01   |  0.93    | [0.66, -1.34,  0.38, -0.15,  -0.07] |
> | 0.1    |  0.90    | [0.53, -1.20,  0.21,   0,   -0.00]  |
> | 1      |  0.83    | [0.19, -0.67,  0.   ,   0.   ,  0. ]  |
> | 10     |  0.70    | [0.,   -0.0,  0.,  0., 0.]             |
>

**Lemma 3:** A penaliza√ß√£o L1 em classifica√ß√£o log√≠stica leva a coeficientes esparsos.

**Prova do Lemma 3:** A penaliza√ß√£o L1 adiciona um termo $\lambda \sum_{j=1}^p |\beta_j|$ na fun√ß√£o de custo. A derivada desse termo em rela√ß√£o a $\beta_j$ √© $\lambda$ se $\beta_j > 0$, $-\lambda$ se $\beta_j < 0$, e n√£o existe no ponto $\beta_j = 0$. O resultado √© que, durante a otimiza√ß√£o da fun√ß√£o de custo, alguns coeficientes podem ser for√ßados a zero, criando um modelo mais esparso [^4.4.4]. $\blacksquare$

**Corol√°rio 3:** A esparsidade promovida pela penaliza√ß√£o L1 resulta em modelos classificat√≥rios mais interpret√°veis, uma vez que um n√∫mero reduzido de vari√°veis preditoras est√° diretamente associado √†s decis√µes de classifica√ß√£o [^4.4.5]. Isso tamb√©m reduz o overfitting, pois o modelo se torna menos sens√≠vel √†s flutua√ß√µes nos dados de treinamento.

> ‚ö†Ô∏è **Ponto Crucial**: A combina√ß√£o de L1 e L2 (Elastic Net) pode ser adotada para aproveitar vantagens de ambos os tipos de regulariza√ß√£o [^4.5], resultando em modelos com um bom compromisso entre esparsidade e estabilidade.

### Separating Hyperplanes e Perceptrons

<imagem: Diagrama mostrando a busca por um hiperplano separador, incluindo a margem de separa√ß√£o e os pontos de suporte.>

Os **hiperplanos separadores** formam o conceito fundamental em muitos m√©todos de classifica√ß√£o linear, especialmente em *Support Vector Machines* (SVM) [^4.5.2]. Um hiperplano √© um subespa√ßo de dimens√£o n-1 em um espa√ßo de n dimens√µes, que pode ser usado para separar dados em diferentes classes. O conceito de margem de separa√ß√£o, a dist√¢ncia entre o hiperplano e os pontos de treinamento mais pr√≥ximos (pontos de suporte), √© crucial [^4.5.2]. A ideia √© maximizar esta margem, o que resulta em um hiperplano com melhor generaliza√ß√£o para novos dados.

Para encontrar o hiperplano ideal, o problema √© frequentemente reformulado como um problema de otimiza√ß√£o com restri√ß√µes [^4.5.2]. O problema dual de Wolfe pode ser usado para encontrar a solu√ß√£o, que muitas vezes pode ser expressa como uma combina√ß√£o linear dos pontos de suporte.
```mermaid
graph LR
 subgraph "Separating Hyperplanes in Linear Classification"
    direction TB
    A["Hyperplane (n-1 dimensional subspace)"] --> B["Separates data into different classes"]
    B --> C["Margin of separation (distance to closest training points)"]
    C --> D["Maximize margin for better generalization"]
    D --> E["Optimization problem with constraints"]
    E --> F["Solution often as a linear combination of support vectors"]
    end
```

O **Perceptron de Rosenblatt** √© um algoritmo para classifica√ß√£o linear que busca, iterativamente, um hiperplano separador [^4.5.1]. Come√ßando com um hiperplano aleat√≥rio, o algoritmo ajusta seus par√¢metros com base nos pontos de treinamento que s√£o classificados incorretamente [^4.5.1]. Quando os dados s√£o linearmente separ√°veis, o Perceptron converge para um hiperplano que separa as classes [^4.5.1].

A escolha do hiperplano que maximiza a margem, como feita em SVM, pode resultar em um classificador mais robusto do que o obtido com o Perceptron, uma vez que o Perceptron busca *qualquer* hiperplano separador, e n√£o necessariamente o √≥timo.
```mermaid
graph LR
    subgraph "Perceptron Algorithm"
        direction TB
        A["Start with random hyperplane"] --> B["Iteratively adjust hyperplane parameters"]
        B --> C["Based on misclassified training points"]
        C --> D["Converges to a separating hyperplane if data is linearly separable"]
       D --> E["SVM seeks the hyperplane with the largest margin"]
    end
```

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:** LDA e a regra de decis√£o Bayesiana, sob a suposi√ß√£o de distribui√ß√µes Gaussianas com covari√¢ncias iguais, compartilham muitas semelhan√ßas, mas possuem diferen√ßas sutis [^4.3]. LDA assume explicitamente que os dados dentro de cada classe s√£o amostrados de uma distribui√ß√£o Gaussiana, com a mesma matriz de covari√¢ncia para todas as classes, e que as classes possuem m√©dias diferentes. Formalmente, se tivermos K classes, ent√£o para a classe $k$, as observa√ß√µes $x$ seguem a distribui√ß√£o:

$$
x \sim N(\mu_k, \Sigma)
$$

Onde $\mu_k$ √© a m√©dia da classe k e $\Sigma$ √© a matriz de covari√¢ncia comum para todas as classes [^4.3]. O LDA busca um hiperplano que maximiza a raz√£o entre a varia√ß√£o entre classes e a varia√ß√£o dentro da classe, e isso leva a uma fronteira de decis√£o linear [^4.3.1].

A regra de decis√£o Bayesiana, por sua vez, busca classificar uma nova observa√ß√£o na classe que tem a maior probabilidade *a posteriori*, dada a observa√ß√£o. Com a mesma suposi√ß√£o gaussiana, e se as probabilidades *a priori* das classes s√£o as mesmas, a decis√£o Bayesiana equivale a classificar na classe $k$ que maximiza:

$$
\text{exp} \{-\frac{1}{2} (x-\mu_k)^T\Sigma^{-1}(x-\mu_k)\}
$$

A fun√ß√£o discriminante obtida pela regra bayesiana, sob estas condi√ß√µes, tem a forma:

$$
\delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2} \mu_k^T\Sigma^{-1}\mu_k
$$

Esta fun√ß√£o √© linear em $x$, portanto, leva a um hiperplano separador tamb√©m.
```mermaid
graph LR
    subgraph "LDA vs Bayesian Decision Rule"
    direction TB
    A["Both assume Gaussian distributions with equal covariance 'Œ£'"] --> B["LDA: Maximizes (between class variance) / (within class variance)"]
    A --> C["Bayesian: maximizes the posterior probability 'P(class|x)'"]
     C --> D["With equal prior probabilities, minimizes the distance using  'Œ£^-1'"]
        B & D--> E["Both lead to a linear discriminant function"]
   E-->F["Œ¥_k(x) = x^T*Œ£^-1*Œº_k - 1/2*Œº_k^T*Œ£^-1*Œº_k"]
    end
```

**Lemma 4:** Sob a suposi√ß√£o de distribui√ß√µes Gaussianas com covari√¢ncias iguais para todas as classes e probabilidades *a priori* iguais, a decis√£o de classifica√ß√£o feita pelo LDA √© id√™ntica √† decis√£o obtida pela regra de decis√£o Bayesiana [^4.3].

**Prova do Lemma 4:** O LDA utiliza a seguinte fun√ß√£o discriminante: $\delta_k^{LDA}(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1}\mu_k$. A regra de decis√£o bayesiana, sob condi√ß√µes gaussianas e probabilidades *a priori* iguais, tamb√©m leva √† mesma fun√ß√£o discriminante $\delta_k(x)$. Assim, ambos os m√©todos levam √† mesma fronteira de decis√£o e, portanto, a decis√µes de classe id√™nticas [^4.3.3]. $\blacksquare$

**Corol√°rio 4:** Se relaxarmos a hip√≥tese de covari√¢ncias iguais entre as classes, o discriminante da decis√£o bayesiana torna-se quadr√°tico em rela√ß√£o a x, levando a fronteiras de decis√£o quadr√°ticas (Quadratic Discriminant Analysis, ou QDA) [^4.3]. Nesse caso, LDA e QDA n√£o coincidem, e o QDA permite modelar fronteiras de decis√£o mais flex√≠veis.

> ‚ö†Ô∏è **Ponto Crucial**: A suposi√ß√£o de covari√¢ncias iguais (LDA) leva a decis√µes lineares, e, em muitos casos, √© uma boa aproxima√ß√£o. No entanto, a relaxa√ß√£o dessa hip√≥tese, como em QDA, pode ser necess√°ria para modelar fen√¥menos mais complexos [^4.3.1].

### Conclus√£o

Neste cap√≠tulo, exploramos os fundamentos dos m√©todos lineares para regress√£o e classifica√ß√£o, desde modelos de regress√£o linear e suas conex√µes com a programa√ß√£o linear at√© m√©todos de classifica√ß√£o como LDA, regress√£o log√≠stica, e hiperplanos separadores. Atrav√©s de exemplos, an√°lise te√≥rica, e algumas conex√µes com programa√ß√£o linear, buscamos fornecer um entendimento aprofundado desses m√©todos.

As se√ß√µes te√≥ricas avan√ßadas que exploramos visam consolidar o entendimento da base matem√°tica desses modelos, bem como suas nuances, incluindo seus pontos fortes e limita√ß√µes. Essa base √© crucial para a compreens√£o de modelos mais complexos e para a aplica√ß√£o eficaz desses m√©todos em problemas do mundo real. A aplica√ß√£o dos m√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o, bem como a compreens√£o de suas conex√µes com programa√ß√£o linear, desempenham um papel chave em modelos de classifica√ß√£o mais robustos e generaliz√°veis.

### Footnotes
[^3.1]: "A linear regression model assumes that the regression function E(Y|X) is linear in