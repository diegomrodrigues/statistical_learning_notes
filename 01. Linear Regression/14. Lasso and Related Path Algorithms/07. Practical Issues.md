## Classifica√ß√£o e An√°lise Discriminante: Quest√µes Pr√°ticas
<imagem: Um diagrama de fluxo complexo mostrando os diferentes passos para a sele√ß√£o e avalia√ß√£o de modelos de classifica√ß√£o, incluindo a prepara√ß√£o dos dados, sele√ß√£o de vari√°veis, ajuste do modelo e valida√ß√£o. Este diagrama incluiria todos os t√≥picos principais discutidos nas se√ß√µes 4.1 a 4.5.2, criando um guia visual abrangente.>

### Introdu√ß√£o
A classifica√ß√£o, como um dos pilares do aprendizado de m√°quina, aborda o desafio de atribuir r√≥tulos de classe a inst√¢ncias com base em um conjunto de caracter√≠sticas. Em contraste com a regress√£o, que se concentra na previs√£o de valores cont√≠nuos, a classifica√ß√£o lida com a previs√£o de categorias discretas [^4.1]. A an√°lise discriminante, especificamente, √© uma fam√≠lia de t√©cnicas que busca projetar dados em um espa√ßo de dimens√£o inferior, preservando o m√°ximo poss√≠vel a separa√ß√£o entre as classes [^4.3]. Este cap√≠tulo explora a fundo os aspectos pr√°ticos desses m√©todos lineares, abordando desde a modelagem inicial at√© a sele√ß√£o de vari√°veis e otimiza√ß√£o de modelos.

### Conceitos Fundamentais
A seguir, aprofundaremos os conceitos essenciais que sustentam as abordagens lineares para classifica√ß√£o, com foco em seus fundamentos estat√≠sticos e matem√°ticos.

**Conceito 1:** O problema de classifica√ß√£o envolve a aloca√ß√£o de uma observa√ß√£o $\mathbf{x}$ a uma das $K$ classes pr√©-definidas, $C_1, C_2, ..., C_K$. O objetivo √© aprender uma fun√ß√£o discriminante $f(\mathbf{x})$ que atribua a $\mathbf{x}$ a classe apropriada com a maior precis√£o poss√≠vel. M√©todos lineares buscam construir fronteiras de decis√£o lineares no espa√ßo de caracter√≠sticas [^4.1]. No entanto, a escolha de um modelo linear implica em um trade-off entre vi√©s e vari√¢ncia. Modelos simples t√™m um vi√©s maior, devido √† sua incapacidade de capturar rela√ß√µes complexas nos dados, mas sua vari√¢ncia √© menor, o que significa que eles s√£o menos sens√≠veis a pequenas altera√ß√µes nos dados de treinamento. A escolha adequada depende da natureza dos dados e do problema em quest√£o. Por exemplo, dados altamente n√£o-lineares exigir√£o, potencialmente, abordagens n√£o-lineares ou pr√©-processamento dos dados.

> üí° **Exemplo Num√©rico:** Imagine um cen√°rio onde estamos classificando imagens de frutas em "ma√ß√£s" e "laranjas" usando apenas duas caracter√≠sticas: "cor m√©dia" (em uma escala de 0 a 1, com 0 sendo vermelho e 1 sendo amarelo) e "formato" (uma medida de circularidade, com 0 sendo n√£o circular e 1 sendo perfeitamente circular). Um modelo linear simples pode definir uma linha de decis√£o:
> $f(\mathbf{x}) = w_1 \cdot \text{cor m√©dia} + w_2 \cdot \text{formato} + b$
> Se os pesos forem $w_1 = -2$, $w_2 = 1$ e $b=0.5$,  a linha de decis√£o seria $-2\cdot \text{cor m√©dia} + 1 \cdot \text{formato} + 0.5 = 0$.
>
> Uma ma√ß√£ com "cor m√©dia"=0.2 e "formato"=0.7 teria $f(\mathbf{x}) = -2 \cdot 0.2 + 1 \cdot 0.7 + 0.5 = 0.8$, sendo classificada como "laranja" (considerando que $f(x) > 0$). Uma laranja com "cor m√©dia"=0.8 e "formato"=0.9 teria $f(\mathbf{x}) = -2 \cdot 0.8 + 1 \cdot 0.9 + 0.5 = -0.2$, sendo classificada como "ma√ß√£" (considerando que $f(x) < 0$).
>
>  Um modelo linear pode ter dificuldades se ma√ß√£s e laranjas tivessem uma mistura mais complexa de cores e formatos, por exemplo, existissem ma√ß√£s amarelas e laranjas mais avermelhadas, o que ilustra o trade-off entre vi√©s (modelo simples) e vari√¢ncia (sensibilidade a varia√ß√µes nos dados).

**Lemma 1:** *Em um problema de classifica√ß√£o bin√°ria, um discriminante linear $f(\mathbf{x}) = \mathbf{w}^T\mathbf{x} + b$ define um hiperplano de decis√£o onde $f(\mathbf{x}) = 0$. Todas as observa√ß√µes com $f(\mathbf{x}) > 0$ s√£o classificadas em uma classe, e as observa√ß√µes com $f(\mathbf{x}) < 0$ s√£o classificadas na outra classe.* Essa representa√ß√£o geom√©trica facilita a compreens√£o da separa√ß√£o entre classes e da influ√™ncia dos par√¢metros $\mathbf{w}$ e $b$. Prova: Seja o espa√ßo de entrada de dimens√£o $p$. Um hiperplano no espa√ßo $p$-dimensional √© definido pela equa√ß√£o $ \mathbf{w}^T\mathbf{x} + b = 0$. Qualquer ponto $\mathbf{x}$ que satisfa√ßa essa equa√ß√£o est√° no hiperplano. Pontos com $f(\mathbf{x}) > 0$ est√£o em um lado do hiperplano e pontos com $f(\mathbf{x}) < 0$ est√£o do outro lado. Se $\mathbf{w}$ e $b$ s√£o definidos a partir de um modelo de classifica√ß√£o, os lados do hiperplano correspondem √†s classes previstas. $\blacksquare$
```mermaid
graph TB
    subgraph "Linear Discriminant Geometry"
        direction TB
        A["Decision Function: f(x) = w·µÄx + b"]
        B["Decision Boundary: f(x) = 0"]
        C["Class 1: f(x) > 0"]
        D["Class 2: f(x) < 0"]
        A --> B
        B --> C
        B --> D
    end
```

**Conceito 2:** A **Linear Discriminant Analysis (LDA)** √© uma t√©cnica cl√°ssica para classifica√ß√£o que faz uso das informa√ß√µes estat√≠sticas dos dados para construir fronteiras de decis√£o. A LDA assume que as classes possuem uma distribui√ß√£o normal multivariada com a mesma matriz de covari√¢ncia, ou seja, $\Sigma_1 = \Sigma_2 = ... = \Sigma_K = \Sigma$ [^4.3]. A fun√ß√£o discriminante para a classe $k$ √© dada por:

$$
\delta_k(\mathbf{x}) = \mathbf{x}^T \Sigma^{-1}\mathbf{\mu_k} - \frac{1}{2}\mathbf{\mu_k}^T \Sigma^{-1} \mathbf{\mu_k} + \log\pi_k
$$

onde $\mathbf{\mu_k}$ √© o vetor m√©dio da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum e $\pi_k$ √© a probabilidade *a priori* da classe $k$. A LDA busca projetar os dados em um espa√ßo de dimens√£o inferior maximizando a separa√ß√£o entre as classes. A fronteira de decis√£o entre duas classes $k$ e $l$ √© um hiperplano onde $\delta_k(\mathbf{x}) = \delta_l(\mathbf{x})$. A LDA requer o c√°lculo das m√©dias de cada classe, a matriz de covari√¢ncia comum e as probabilidades *a priori*, e os estimadores s√£o obtidos a partir dos dados de treinamento [^4.3.1], [^4.3.2], [^4.3.3].
```mermaid
graph LR
    subgraph "LDA Discriminant Function Components"
        direction LR
        A["Discriminant Function: Œ¥‚Çñ(x)"] --> B["Linear Term: x·µÄŒ£‚Åª¬πŒº‚Çñ"]
        A --> C["Quadratic Term: -¬ΩŒº‚Çñ·µÄŒ£‚Åª¬πŒº‚Çñ"]
        A --> D["Prior Probability Term: log(œÄ‚Çñ)"]
    end
```

> üí° **Exemplo Num√©rico:** Suponha que temos duas classes, $C_1$ e $C_2$, com as seguintes estat√≠sticas calculadas a partir dos dados de treinamento:
>
> - $\mathbf{\mu_1} = \begin{bmatrix} 1 \\ 2 \end{bmatrix}$ (m√©dia da classe 1)
> - $\mathbf{\mu_2} = \begin{bmatrix} 3 \\ 1 \end{bmatrix}$ (m√©dia da classe 2)
> - $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$ (matriz de covari√¢ncia comum)
> - $\pi_1 = 0.6$ (probabilidade *a priori* da classe 1)
> - $\pi_2 = 0.4$ (probabilidade *a priori* da classe 2)
>
> E um novo ponto a ser classificado: $\mathbf{x} = \begin{bmatrix} 2 \\ 2 \end{bmatrix}$
>
> Primeiro, calculamos a inversa da matriz de covari√¢ncia:
>
> $\Sigma^{-1} = \frac{1}{(1*1 - 0.5*0.5)} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix}$
>
> Agora, calculamos as fun√ß√µes discriminantes para cada classe:
>
> $\delta_1(\mathbf{x}) = \mathbf{x}^T \Sigma^{-1}\mathbf{\mu_1} - \frac{1}{2}\mathbf{\mu_1}^T \Sigma^{-1} \mathbf{\mu_1} + \log\pi_1$
>
> $\delta_1(\mathbf{x}) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix}  - \frac{1}{2}\begin{bmatrix} 1 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} + \log(0.6)$
>
> $\delta_1(\mathbf{x}) =  \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 0.67 \\ 2 \end{bmatrix} - \frac{1}{2}\begin{bmatrix} 1 & 2 \end{bmatrix} \begin{bmatrix} 0.67 \\ 2 \end{bmatrix} + \log(0.6)$
>
> $\delta_1(\mathbf{x}) = 5.34 - \frac{1}{2}(4.67) + (-0.51) \approx 2.5$
>
> Calculamos $\delta_2(\mathbf{x})$ da mesma forma:
>
> $\delta_2(\mathbf{x}) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 1 \end{bmatrix}  - \frac{1}{2}\begin{bmatrix} 3 & 1 \end{bmatrix} \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 1 \end{bmatrix} + \log(0.4)$
>
> $\delta_2(\mathbf{x}) \approx  \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 3.33 \\ -1.33 \end{bmatrix}  - \frac{1}{2}\begin{bmatrix} 3 & 1 \end{bmatrix} \begin{bmatrix} 3.33 \\ -1.33 \end{bmatrix} + (-0.92) = 4 - \frac{1}{2}(8.67) -0.92 \approx -1.25$
>
> Como $\delta_1(\mathbf{x}) > \delta_2(\mathbf{x})$, o ponto $\mathbf{x}$ √© classificado como pertencente √† classe $C_1$.

**Corol√°rio 1:** A fronteira de decis√£o na LDA √© um hiperplano. A prova decorre da igualdade de $\delta_k(\mathbf{x})$ e $\delta_l(\mathbf{x})$ para classes $k$ e $l$:
$$
\mathbf{x}^T \Sigma^{-1}\mathbf{\mu_k} - \frac{1}{2}\mathbf{\mu_k}^T \Sigma^{-1} \mathbf{\mu_k} + \log\pi_k = \mathbf{x}^T \Sigma^{-1}\mathbf{\mu_l} - \frac{1}{2}\mathbf{\mu_l}^T \Sigma^{-1} \mathbf{\mu_l} + \log\pi_l
$$
Reorganizando os termos, obtemos uma equa√ß√£o linear na forma $\mathbf{w}^T\mathbf{x} + b = 0$, onde $\mathbf{w} = \Sigma^{-1}(\mathbf{\mu_k} - \mathbf{\mu_l})$ e $b = -\frac{1}{2}(\mathbf{\mu_k}^T \Sigma^{-1} \mathbf{\mu_k} - \mathbf{\mu_l}^T \Sigma^{-1} \mathbf{\mu_l}) + \log(\pi_k/\pi_l)$, o que demonstra que a fronteira de decis√£o √© um hiperplano [^4.3.1].
```mermaid
graph TB
    subgraph "LDA Decision Boundary"
    direction TB
        A["Œ¥‚Çñ(x) = Œ¥‚Çó(x)"]
        B["x·µÄŒ£‚Åª¬πŒº‚Çñ - ¬ΩŒº‚Çñ·µÄŒ£‚Åª¬πŒº‚Çñ + log(œÄ‚Çñ) = x·µÄŒ£‚Åª¬πŒº‚Çó - ¬ΩŒº‚Çó·µÄŒ£‚Åª¬πŒº‚Çó + log(œÄ‚Çó)"]
        C["w·µÄx + b = 0 where w = Œ£‚Åª¬π(Œº‚Çñ - Œº‚Çó)"]
        A --> B
        B --> C
    end
```
**Conceito 3:** A **Regress√£o Log√≠stica** √© um m√©todo amplamente utilizado para problemas de classifica√ß√£o bin√°ria, que modela a probabilidade de uma observa√ß√£o pertencer a uma determinada classe usando uma fun√ß√£o log√≠stica [^4.4]. Ao contr√°rio da LDA, a regress√£o log√≠stica n√£o faz suposi√ß√µes sobre as distribui√ß√µes dos dados de entrada, mas sim modela a probabilidade de uma classe. A fun√ß√£o *logit* ou *log-odds*, $\text{logit}(p) = \log(\frac{p}{1-p})$, transforma a probabilidade $p$ para um espa√ßo que pode ser modelado linearmente:
$$
\text{logit}[P(C=1|\mathbf{x})] = \mathbf{w}^T\mathbf{x} + b
$$

onde $P(C=1|\mathbf{x})$ √© a probabilidade da observa√ß√£o $\mathbf{x}$ pertencer √† classe 1, $\mathbf{w}$ s√£o os coeficientes do modelo e $b$ √© o intercepto. A probabilidade √© ent√£o expressa como:

$$
P(C=1|\mathbf{x}) = \frac{1}{1+e^{-(\mathbf{w}^T\mathbf{x}+b)}}
$$

Os par√¢metros $\mathbf{w}$ e $b$ s√£o estimados atrav√©s da maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa (likelihood) [^4.4.1], [^4.4.2], [^4.4.3]. A regress√£o log√≠stica √© mais flex√≠vel que LDA, mas geralmente menos eficiente com classes bem separadas [^4.5].
```mermaid
graph TB
    subgraph "Logistic Regression Formulation"
        direction TB
        A["Logit Function: logit(p) = log(p/(1-p))"]
        B["Linear Model: logit(P(C=1|x)) = w·µÄx + b"]
        C["Probability: P(C=1|x) = 1 / (1 + e^-(w·µÄx + b))"]
        A --> B
        B --> C
    end
```

> üí° **Exemplo Num√©rico:** Suponha que ap√≥s treinar um modelo de regress√£o log√≠stica, obtivemos os seguintes par√¢metros: $\mathbf{w} = \begin{bmatrix} 0.5 \\ -1 \end{bmatrix}$ e $b = 0.2$. Considere um ponto de dados $\mathbf{x} = \begin{bmatrix} 2 \\ 1 \end{bmatrix}$.
>
> 1. Calculamos a pontua√ß√£o linear:
> $\mathbf{w}^T\mathbf{x} + b =  \begin{bmatrix} 0.5 & -1 \end{bmatrix} \begin{bmatrix} 2 \\ 1 \end{bmatrix} + 0.2 = 0.5 * 2 + (-1) * 1 + 0.2 = 1 - 1 + 0.2 = 0.2$
>
> 2. Calculamos a probabilidade usando a fun√ß√£o sigm√≥ide:
>
> $P(C=1|\mathbf{x}) = \frac{1}{1+e^{-0.2}} \approx \frac{1}{1+0.8187} \approx \frac{1}{1.8187} \approx 0.55$
>
>
> Isso significa que a probabilidade de $\mathbf{x}$ pertencer √† classe 1 √© de aproximadamente 55%. Se o limiar de decis√£o for 0.5, ent√£o o ponto $\mathbf{x}$ seria classificado na classe 1. Se o limiar fosse maior, digamos 0.6, o ponto seria classificado na classe 0.
>
> O log-odds seria:
>
> $\text{logit}(0.55) = \log(\frac{0.55}{1-0.55}) = \log(\frac{0.55}{0.45}) \approx \log(1.22) \approx 0.2$, que √© o resultado da pontua√ß√£o linear $\mathbf{w}^T\mathbf{x} + b$

> ‚ö†Ô∏è **Nota Importante**: Em problemas com classes n√£o-balanceadas, √© crucial ajustar a fun√ß√£o de perda na regress√£o log√≠stica ou usar t√©cnicas de reamostragem para evitar que o modelo seja tendencioso para a classe majorit√°ria [^4.4.2].

> ‚ùó **Ponto de Aten√ß√£o**: Tanto LDA quanto Regress√£o Log√≠stica s√£o m√©todos lineares, o que significa que as fronteiras de decis√£o s√£o hiperplanos no espa√ßo de caracter√≠sticas. Isso limita a capacidade desses modelos de classificar dados que possuem rela√ß√µes n√£o lineares entre as vari√°veis e a classe de sa√≠da.

> ‚úîÔ∏è **Destaque**: Ambos LDA e Regress√£o Log√≠stica est√£o intimamente relacionadas: LDA deriva as suas fronteiras de decis√£o das estat√≠sticas descritivas das classes (m√©dias e covari√¢ncias) enquanto a regress√£o log√≠stica modela a probabilidade diretamente usando a fun√ß√£o log√≠stica.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
<imagem: Diagrama que demonstra o processo de regress√£o de uma matriz de indicadores para classifica√ß√£o. O diagrama come√ßa com um conjunto de dados de entrada com m√∫ltiplas classes, mostra a transforma√ß√£o dessas classes em uma matriz de indicadores, depois aplica a regress√£o linear para obter coeficientes e, finalmente, usa os coeficientes para decidir a classe com base na pontua√ß√£o predita. As setas indicam o fluxo do processo, e os r√≥tulos explicam cada passo. Diagrama semelhante ao abaixo, mas com mais detalhes>
```mermaid
graph LR
    A[Dados de Entrada com Classes] --> B[Codifica√ß√£o de Classes em Matriz Indicadora]
    B --> C[Regress√£o Linear M√≠nimos Quadrados]
    C --> D[Estimativa dos Coeficientes de Regress√£o]
    D --> E[C√°lculo das Pontua√ß√µes de Classifica√ß√£o]
    E --> F[Decis√£o de Classe com base nas Pontua√ß√µes]
```
A regress√£o linear, apesar de ser originalmente concebida para problemas de regress√£o, tamb√©m pode ser aplicada para tarefas de classifica√ß√£o atrav√©s da codifica√ß√£o de classes usando uma matriz de indicadores [^4.2]. Em uma matriz de indicadores, cada coluna representa uma classe, com '1' indicando a perten√ßa √† classe e '0' caso contr√°rio. Este processo transforma um problema de classifica√ß√£o em um de regress√£o m√∫ltipla, onde cada resposta (coluna da matriz de indicadores) √© prevista. Dado um conjunto de dados com $N$ observa√ß√µes e $K$ classes, a matriz de indicadores $Y$ ter√° dimens√£o $N \times K$.

Seja $\mathbf{X}$ a matriz de design dos preditores ($N \times p$), e $\mathbf{Y}$ a matriz de indicadores ($N \times K$). O modelo de regress√£o linear √© expresso como:
$$
\mathbf{Y} = \mathbf{X} \mathbf{B} + \mathbf{E}
$$
Onde $\mathbf{B}$ √© a matriz de coeficientes ($p \times K$) e $\mathbf{E}$ √© a matriz de erros. A solu√ß√£o para $\mathbf{B}$ usando m√≠nimos quadrados √© dada por:
$$
\mathbf{B} = (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}
$$
Ap√≥s obter a matriz $\mathbf{B}$, a previs√£o de um novo ponto $\mathbf{x}$ √© feita calculando $\hat{\mathbf{y}} = \mathbf{x}^T \mathbf{B}$, e a classe atribu√≠da √© a que corresponde √† maior componente de $\hat{\mathbf{y}}$.

> üí° **Exemplo Num√©rico:**  Vamos criar um exemplo simples com 3 observa√ß√µes e 2 classes, onde cada observa√ß√£o tem duas caracter√≠sticas. Suponha que a matriz de design $\mathbf{X}$ e a matriz de indicadores $\mathbf{Y}$ s√£o:
>
> $\mathbf{X} = \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \end{bmatrix}$ , $\mathbf{Y} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix}$
>
> Adicionamos uma coluna de 1s para o termo independente da regress√£o,
> $\mathbf{X} = \begin{bmatrix} 1 & 1 & 2 \\ 1 & 2 & 1 \\ 1 & 3 & 3 \end{bmatrix}$
>
>
>
> 1.  Calculamos $\mathbf{X}^T\mathbf{X}$:
>
>  $\mathbf{X}^T\mathbf{X} = \begin{bmatrix} 1 & 1 & 1 \\ 1 & 2 & 3 \\ 2 & 1 & 3 \end{bmatrix} \begin{bmatrix} 1 & 1 & 2 \\ 1 & 2 & 1 \\ 1 & 3 & 3 \end{bmatrix} = \begin{bmatrix} 3 & 6 & 6 \\ 6 & 14 & 13 \\ 6 & 13 & 14 \end{bmatrix}$
>
> 2.  Calculamos a inversa de $\mathbf{X}^T\mathbf{X}$:
>
> $(\mathbf{X}^T\mathbf{X})^{-1} \approx \begin{bmatrix} 1.8 & -0.6 & -0.6 \\ -0.6 & 0.8 & 0.1 \\ -0.6 & 0.1 & 0.8 \end{bmatrix}$
>
> 3. Calculamos $\mathbf{X}^T\mathbf{Y}$:
>
> $\mathbf{X}^T\mathbf{Y} = \begin{bmatrix} 1 & 1 & 1 \\ 1 & 2 & 3 \\ 2 & 1 & 3 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix} = \begin{bmatrix} 2 & 1 \\ 4 & 2 \\ 5 & 1 \end{bmatrix}$
>
> 4.  Calculamos a matriz de coeficientes $\mathbf{B}$:
>
> $\mathbf{B} = (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y} \approx \begin{bmatrix} 1.8 & -0.6 & -0.6 \\ -0.6 & 0.8 & 0.1 \\ -0.6 & 0.1 & 0.8 \end{bmatrix} \begin{bmatrix} 2 & 1 \\ 4 & 2 \\ 5 & 1 \end{bmatrix} = \begin{bmatrix} 0.0 & 0.0 \\ 0.1 & 0.6 \\ 0.8 & -0.2 \end{bmatrix}$
>
> Para classificar um novo ponto, por exemplo $\mathbf{x} = \begin{bmatrix} 2 & 2 \end{bmatrix}$, adicionamos um 1 na primeira posi√ß√£o: $\mathbf{x} = \begin{bmatrix} 1 & 2 & 2 \end{bmatrix}$.
>  Calculamos $\hat{\mathbf{y}} = \mathbf{x}^T \mathbf{B}$:
>
> $\hat{\mathbf{y}} = \begin{bmatrix} 1 & 2 & 2 \end{bmatrix} \begin{bmatrix} 0.0 & 0.0 \\ 0.1 & 0.6 \\ 0.8 & -0.2 \end{bmatrix} = \begin{bmatrix} 1.8 & 0.8 \end{bmatrix}$
>
> A maior componente de $\hat{\mathbf{y}}$ √© 1.8, correspondendo √† classe 1, o que significa que o ponto $\mathbf{x}$ seria classificado na classe 1.
```mermaid
graph TB
    subgraph "Linear Regression for Classification"
        direction TB
        A["Indicator Matrix Y (N x K)"]
        B["Design Matrix X (N x p)"]
        C["Regression: Y = XB + E"]
        D["Coefficient Matrix: B = (X·µÄX)‚Åª¬πX·µÄY"]
        E["Prediction: ≈∑ = x·µÄB"]
        F["Class Assignment: argmax(≈∑)"]
        A & B --> C
        C --> D
        D --> E
        E --> F
    end
```

**Lemma 2:** *A solu√ß√£o para a regress√£o linear sobre uma matriz de indicadores √© equivalente √† proje√ß√£o de cada ponto no espa√ßo de classes.* Prova: Dada a solu√ß√£o $\mathbf{B} = (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}$, a previs√£o de um ponto $\mathbf{x}$ √© dada por $\hat{\mathbf{y}} = \mathbf{x}^T \mathbf{B} = \mathbf{x}^T (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}$. Seja $\mathbf{H} = \mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T$ a matriz de proje√ß√£o. Ent√£o $\hat{\mathbf{y}} = \mathbf{x}^T \mathbf{H} \mathbf{Y}$, que mostra que a previs√£o √© o resultado de uma proje√ß√£o de $\mathbf{x}$ em $\mathbf{H}$ seguida pela aplica√ß√£o da matriz de indicadores $\mathbf{Y}$. $\blacksquare$
```mermaid
graph TB
    subgraph "Projection in Linear Regression"
        direction TB
        A["Solution B = (X·µÄX)‚Åª¬πX·µÄY"]
        B["Prediction: ≈∑ = x·µÄB"]
        C["Projection Matrix H = X(X·µÄX)‚Åª¬πX·µÄ"]
        D["≈∑ = x·µÄH Y"]
        A --> B
        B --> C
        C --> D
    end
```

**Corol√°rio 2:** Se as classes s√£o perfeitamente separ√°veis por um hiperplano, a regress√£o linear com matriz de indicadores tamb√©m encontra os mesmos hiperplanos de separa√ß√£o que discriminantes lineares, sob certas condi√ß√µes (como quando as classes n√£o s√£o muito sobrepostas), e a solu√ß√£o do problema de regress√£o se torna uma solu√ß√£o do problema de classifica√ß√£o. Este corol√°rio liga a regress√£o linear ao problema de classifica√ß√£o quando condi√ß√µes de separabilidade s√£o satisfeitas [^4.3].

Apesar de sua simplicidade, a regress√£o linear para classifica√ß√£o apresenta algumas limita√ß√µes. Primeiro, as previs√µes n√£o s√£o probabilidades no intervalo [0,1], podendo levar a valores fora desse intervalo. Segundo, a regress√£o linear n√£o leva em conta a estrutura espec√≠fica dos dados de classifica√ß√£o e pode apresentar um desempenho inferior a outros m√©todos mais adequados, como a regress√£o log√≠stica ou LDA. Uma das principais limita√ß√µes √© o "masking problem", em que uma classe pode ser encoberta pela outra devido √† proje√ß√£o linear, especialmente em problemas com classes muito sobrepostas [^4.3]. No entanto, em casos onde as classes s√£o aproximadamente lineares e bem separadas, a regress√£o linear pode ser uma op√ß√£o r√°pida e razo√°vel.

"Em alguns cen√°rios, conforme apontado em [^4.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1]."

"No entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^4.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear."

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem: Um mapa mental que conecta os m√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o em modelos de classifica√ß√£o. No centro, h√° o t√≥pico central "Sele√ß√£o de Vari√°veis e Regulariza√ß√£o". A partir dele, surgem ramifica√ß√µes para "Regulariza√ß√£o L1 (Lasso)", "Regulariza√ß√£o L2 (Ridge)", "Regulariza√ß√£o Elastic Net", "Sele√ß√£o de Vari√°veis por Penaliza√ß√£o" e "Impacto na Interpretabilidade". Cada ramifica√ß√£o inclui explica√ß√µes concisas sobre cada m√©todo e seu impacto na classifica√ß√£o. As setas indicam a rela√ß√£o entre os conceitos.>

Na pr√°tica, muitos conjuntos de dados apresentam alta dimensionalidade, e muitas das vari√°veis podem n√£o contribuir para a classifica√ß√£o ou at√© mesmo levar a overfitting. A sele√ß√£o de vari√°veis e regulariza√ß√£o s√£o t√©cnicas essenciais para lidar com esse desafio, melhorando a interpretabilidade e o desempenho dos modelos [^4.5]. A **regulariza√ß√£o** adiciona um termo de penalidade √† fun√ß√£o de perda do modelo, que controla a complexidade do modelo, e a **sele√ß√£o de vari√°veis** seleciona as vari√°veis mais relevantes para um modelo de classifica√ß√£o, simplificando-o e melhorando a sua generaliza√ß√£o.

A **regulariza√ß√£o L1 (Lasso)** adiciona uma penalidade baseada na soma dos valores absolutos dos coeficientes, ou seja, $||w||_1 = \sum_{j=1}^{p}|w_j|$, na fun√ß√£o de custo [^4.4.4]. Essa penalidade tem a propriedade de promover coeficientes esparsos, ou seja, alguns coeficientes se tornam exatamente iguais a zero, levando √† sele√ß√£o autom√°tica de vari√°veis. O problema de otimiza√ß√£o √© expresso como:

$$
\text{minimize} \quad -\frac{1}{N} \sum_{i=1}^{N} [y_i(\mathbf{w}^T \mathbf{x_i}) - \log(1 + e^{\mathbf{w}^T \mathbf{x_i}})] + \lambda \sum_{j=1}^{p}|w_j|
$$

onde $\lambda$ √© um par√¢metro de ajuste que controla a intensidade da penalidade. Em contrapartida, a **regulariza√ß√£o L2 (Ridge)** adiciona uma penalidade baseada na soma dos quadrados dos coeficientes, ou seja, $||w||_2^2 = \sum_{j=1}^{p}w_j^2$ [^4.5]. Esta penalidade n√£o promove a esparsidade dos coeficientes, mas sim reduz seus valores, levando a modelos mais est√°veis. O problema de otimiza√ß√£o √© similar ao anterior, exceto que a penalidade √© dada por:

$$
 \text{minimize} \quad -\frac{1}{N} \sum_{i=1}^{N} [y_i(\mathbf{w}^T \mathbf{x_i}) - \log(1 + e^{\mathbf{w}^T \mathbf{x_i}})] + \lambda \sum_{j=1}^{p}w_j^2
$$
A **Regulariza√ß√£o Elastic Net** combina as penalidades L1 e L2 em um √∫nico modelo, visando aproveitar as propriedades de ambas [^4.5]:
$$
 \text{minimize} \quad -\frac{1}{N} \sum_{i=1}^{N} [y_i(\mathbf{w}^T \mathbf{x_i}) - \log(1 + e^{\mathbf{w}^T \mathbf{x_i}})] + \lambda_1 \sum_{j=1}^{p}|w_j| + \lambda_2 \sum_{j=1}^{p}w_j^2
$$

onde $\lambda_1$ e $\lambda_2$ s√£o par√¢metros que controlam as intensidades das penalidades L1 e L2.
```mermaid
graph TB
    subgraph "Regularization Techniques"
        direction TB
        A["L1 Regularization (Lasso): ||w||‚ÇÅ"]
        B["L2 Regularization (Ridge): ||w||‚ÇÇ¬≤"]
        C["Elastic Net: Œª‚ÇÅ||w||‚ÇÅ + Œª‚ÇÇ||w||‚ÇÇ¬≤"]
        D["Loss Function: -‚àë[y·µ¢(w·µÄx·µ¢) - log(1+e^(w·µÄx·µ¢))]"]
        D --> A
        D --> B
        D --> C
    end
```

> üí° **Exemplo Num√©rico:** Suponha que estamos usando regress√£o log√≠stica para classificar clientes como "churn" (1) ou "n√£o-churn" (0) com base em 5 caracter√≠sticas: "idade", "tempo de contrato", "n√∫mero de produtos", "total gasto" e "reclama√ß√µes". O modelo com regulariza√ß√£o L1 pode apresentar os seguintes coeficientes:
>
> - Modelo sem regulariza√ß√£o: $\mathbf{w} = [0.01, 0.2, 0.15, 0.005, -0.3]$
> - Modelo com regulariza√ß√£o L1 (Lasso) com $\lambda = 0.1$: $\mathbf{w} = [0, 0.15, 0, 0, -0.2]$
> - Modelo com regulariza√ß√£o L2 (Ridge) com $\lambda = 0.1$: $\mathbf{w} = [0.009, 0.18, 0.13, 0.004, -0.27]$
>
> A penaliza√ß√£o L1 zerou os coeficientes de "idade", "n√∫mero de produtos", e "total gasto", selecionando apenas "tempo de contrato" e "reclama√ß√µes" como preditores relevantes. O modelo L2 reduziu os coeficientes de todas as vari√°veis.
>
> Uma poss√≠vel interpreta√ß√£o √© que o tempo de contrato e as reclama√ß√µes s√£o os fatores mais preditivos para o churn, enquanto a idade, o n√∫mero de produtos e o total gasto t√™m um impacto menor na decis√£o de churn. Isto demonstra como a regulariza√ß√£o L1 pode simplificar o modelo, eliminando as vari√°veis de menor import√¢ncia.

**Lemma 3:** *A penalidade L1 em modelos de classifica√ß√£o log√≠stica leva a coeficientes esparsos*. Prova: Ao adicionar a penalidade L1 √† fun√ß√£o de custo, o modelo tende a minimizar a fun√ß√£o de custo e a norma L1 dos coeficientes simultaneamente. A penalidade L1 tem "cantos" em zero que levam alguns coeficientes a serem exatamente iguais a zero. Isso