## Estat√≠stica F: $F = (RSS_0 - RSS_1) / (p_1 - p_0) / (RSS_1 / (N - p_1 - 1))$ em Modelos de Regress√£o Linear

```mermaid
flowchart TD
    A["Modelo Reduzido"] -->|RSS0| B(Calcular Diferen√ßa do RSS)
    C["Modelo Completo"] -->|RSS1| B
    B -->|RSS0 - RSS1| D{Normalizar}
    D --> |$(RSS_0 - RSS_1) / (p_1 - p_0)$| E[Numerador da Estat√≠stica F]
    C -->|RSS1| F{Normalizar}
    F -->|$RSS_1 / (N - p_1 - 1)$| G[Denominador da Estat√≠stica F]
    E --> H[Estat√≠stica F = Numerador / Denominador]
    G --> H
    H --> I{Comparar com Distribui√ß√£o F}
    I --> J[Avalia√ß√£o da Signific√¢ncia]
```

### Introdu√ß√£o

A **estat√≠stica F**, definida pela f√≥rmula **$F = (RSS_0 - RSS_1) / (p_1 - p_0) / (RSS_1 / (N - p_1 - 1))$**, √© uma ferramenta essencial na an√°lise de modelos de regress√£o linear, utilizada para avaliar a signific√¢ncia estat√≠stica de um grupo de preditores [^48]. Ao comparar o ajuste de um modelo completo com um modelo reduzido (que exclui um grupo de preditores), o teste F determina se a inclus√£o desse grupo de preditores √© estatisticamente significativa para o modelo, quantificando a mudan√ßa na soma dos quadrados dos res√≠duos devido √† adi√ß√£o ou remo√ß√£o de preditores. Nesta se√ß√£o, vamos explorar a formula√ß√£o matem√°tica da estat√≠stica F, sua interpreta√ß√£o, e suas aplica√ß√µes na sele√ß√£o de modelos e na avalia√ß√£o da import√¢ncia de grupos de preditores em modelos de regress√£o linear.

### Formula√ß√£o Matem√°tica da Estat√≠stica F

A estat√≠stica F √© utilizada para comparar o ajuste de dois modelos de regress√£o linear: um modelo completo e um modelo reduzido [^48]. O modelo completo inclui todos os preditores relevantes, e o modelo reduzido exclui um subconjunto dos preditores. A estat√≠stica F √© definida como:

$$
F = \frac{(RSS_0 - RSS_1)/(p_1 - p_0)}{RSS_1/(N - p_1 - 1)}
$$

onde:

-   $RSS_0$ √© a soma dos quadrados dos res√≠duos para o modelo reduzido.
-   $RSS_1$ √© a soma dos quadrados dos res√≠duos para o modelo completo.
-   $p_1$ √© o n√∫mero de par√¢metros do modelo completo, incluindo o *intercept*.
-   $p_0$ √© o n√∫mero de par√¢metros do modelo reduzido, incluindo o *intercept*.
-   $N$ √© o n√∫mero de observa√ß√µes.
-   $N - p_1 - 1$ s√£o os graus de liberdade do modelo completo.
-  $p_1 - p_0$ √© a diferen√ßa de graus de liberdade entre o modelo completo e o reduzido.

O numerador da estat√≠stica $F$, $(RSS_0 - RSS_1)/(p_1 - p_0)$, representa a varia√ß√£o no RSS devido √† inclus√£o ou remo√ß√£o do grupo de preditores que est√° sendo testado, normalizado pelo n√∫mero de par√¢metros adicionais. O denominador, $RSS_1/(N - p_1 - 1)$, representa uma estimativa n√£o viesada da vari√¢ncia do erro do modelo completo, que √© usado como um termo de normaliza√ß√£o.
Se o grupo de preditores adicionados (ou removidos) tem pouca influ√™ncia no modelo, ent√£o a diferen√ßa $RSS_0 - RSS_1$ ser√° pequena, e a estat√≠stica $F$ tamb√©m ser√° pequena.

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um exemplo com dados simulados para ilustrar o c√°lculo da estat√≠stica F. Suponha que temos um conjunto de dados com $N = 100$ observa√ß√µes. O modelo completo inclui tr√™s preditores (incluindo o intercepto, $p_1 = 4$) e o modelo reduzido inclui apenas um preditor (o intercepto, $p_0 = 2$).
>
> Ap√≥s ajustar os modelos aos dados, obtemos os seguintes resultados:
>
> - $RSS_0$ (modelo reduzido) = 150
> - $RSS_1$ (modelo completo) = 100
>
> Usando a f√≥rmula da estat√≠stica F:
>
> $F = \frac{(150 - 100)/(4 - 2)}{100/(100 - 4 - 1)} = \frac{50/2}{100/95} = \frac{25}{1.053} \approx 23.74$
>
> Este valor de F = 23.74 ser√° comparado com a distribui√ß√£o F para determinar o p-valor.
>
> ```python
> import numpy as np
> from scipy.stats import f
>
> # Dados do exemplo
> rss_0 = 150
> rss_1 = 100
> p1 = 4
> p0 = 2
> N = 100
>
> # C√°lculo da estat√≠stica F
> F = ((rss_0 - rss_1) / (p1 - p0)) / (rss_1 / (N - p1 - 1))
> print(f"Estat√≠stica F: {F:.2f}")
>
> # C√°lculo do p-valor
> df1 = p1 - p0  # Graus de liberdade do numerador
> df2 = N - p1 - 1 # Graus de liberdade do denominador
> p_valor = 1 - f.cdf(F, df1, df2)
> print(f"P-valor: {p_valor:.4f}")
>
> ```
>
> Neste caso, o p-valor √© muito baixo, indicando que o modelo completo √© significativamente melhor que o modelo reduzido.

### Interpreta√ß√£o Estat√≠stica da Estat√≠stica F

A estat√≠stica F quantifica a melhoria relativa no ajuste de um modelo ao incluir ou excluir um grupo de preditores. Ela tem as seguintes interpreta√ß√µes estat√≠sticas:
    1. **Compara√ß√£o de Ajuste:**  A estat√≠stica $F$ compara o ajuste de dois modelos, onde $RSS_0$ e $RSS_1$ quantificam o erro nos modelos reduzido e completo, respectivamente.
   2. **Distribui√ß√£o F:** Se a hip√≥tese nula, ou seja, que o grupo de preditores n√£o contribui para o modelo, √© verdadeira, ent√£o a estat√≠stica $F$ segue uma distribui√ß√£o $F$ com $p_1 - p_0$ e $N - p_1 - 1$ graus de liberdade. A distribui√ß√£o F descreve o comportamento de uma raz√£o entre duas distribui√ß√µes qui-quadrado.
   3. **Teste de Hip√≥teses:** A estat√≠stica $F$ √© utilizada para realizar testes de hip√≥teses sobre a signific√¢ncia de grupos de preditores. O p-valor, calculado a partir da distribui√ß√£o F, quantifica a probabilidade de observar um valor da estat√≠stica $F$ t√£o ou mais extremo que o valor obtido, assumindo que a hip√≥tese nula √© verdadeira.
   4. **Rejei√ß√£o da Hip√≥tese Nula:** Se o p-valor for menor que um determinado n√≠vel de signific√¢ncia $\alpha$, por exemplo 0.05, ent√£o a hip√≥tese nula √© rejeitada e conclui-se que o grupo de preditores tem efeito na resposta. Um valor alto da estat√≠stica F, e um valor baixo do p-valor, indicam que o modelo com todos os preditores ajusta significativamente melhor os dados do que o modelo que exclui o grupo de preditores em teste.

> üí° **Exemplo Num√©rico:**
>
> Continuando com o exemplo anterior, onde calculamos F = 23.74, e temos $p_1 - p_0 = 2$ e $N - p_1 - 1 = 95$ graus de liberdade. Usando a distribui√ß√£o F, podemos calcular o p-valor para este teste.
>
>  O p-valor obtido (usando scipy.stats.f.cdf) √© muito pr√≥ximo de zero, o que nos leva a rejeitar a hip√≥tese nula de que os preditores adicionais n√£o contribuem para o modelo.
>
> ```python
> import numpy as np
> from scipy.stats import f
>
> # Estat√≠stica F calculada
> F = 23.74
>
> # Graus de liberdade
> df1 = 2  # p1 - p0
> df2 = 95 # N - p1 - 1
>
> # C√°lculo do p-valor
> p_valor = 1 - f.cdf(F, df1, df2)
>
> print(f"P-valor: {p_valor:.4f}")
>
> # Interpreta√ß√£o
> alpha = 0.05
> if p_valor < alpha:
>     print("Rejeitamos a hip√≥tese nula. Os preditores adicionais s√£o significativos.")
> else:
>     print("N√£o rejeitamos a hip√≥tese nula. Os preditores adicionais n√£o s√£o significativos.")
> ```
>
> Este exemplo mostra como a estat√≠stica F e o p-valor s√£o usados para tomar decis√µes sobre a inclus√£o de preditores em um modelo de regress√£o.

###  A Distribui√ß√£o F e seu Significado

A distribui√ß√£o *F* √© uma distribui√ß√£o de probabilidade cont√≠nua, definida por dois graus de liberdade, $d_1$ e $d_2$, e dada pela express√£o:

$$
f(x; d_1, d_2) = \frac{\Gamma\left(\frac{d_1+d_2}{2}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}\left(\frac{d_1}{d_2}\right)^{\frac{d_1}{2}}\frac{x^{\frac{d_1}{2}-1}}{(1+\frac{d_1 x}{d_2})^{\frac{d_1+d_2}{2}}}
$$
onde:
    - $\Gamma$ denota a fun√ß√£o gama.
    - $d_1$ corresponde ao grau de liberdade do numerador e $d_2$ ao grau de liberdade do denominador da estat√≠stica $F$.

A distribui√ß√£o *F* surge naturalmente ao analisar raz√µes de distribui√ß√µes qui-quadrado, e as suas propriedades s√£o utilizadas para avaliar a signific√¢ncia de grupos de preditores.
A distribui√ß√£o *F* √© n√£o negativa e tem uma forma assim√©trica √† direita. Os graus de liberdade $d_1$ e $d_2$ controlam a forma e dispers√£o da distribui√ß√£o, e valores maiores de graus de liberdade levam a distribui√ß√µes mais sim√©tricas. A estat√≠stica $F$ compara a variabilidade explicada pelo modelo completo com o modelo reduzido, e a distribui√ß√£o *F* permite concluir se essa diferen√ßa √© estatisticamente significativa.

**Lemma 29:** A Distribui√ß√£o da Estat√≠stica F

A estat√≠stica F, sob a hip√≥tese nula de que o grupo de preditores n√£o contribui para o modelo, segue uma distribui√ß√£o *$F$* com $p_1-p_0$ e $N-p_1-1$ graus de liberdade.
A liga√ß√£o da estat√≠stica $F$ com a distribui√ß√£o *$F$* √© uma consequ√™ncia direta das suposi√ß√µes do modelo linear e das propriedades das distribui√ß√µes qui-quadrado.

**Prova do Lemma 29:**
Se as suposi√ß√µes do modelo linear s√£o v√°lidas, a soma dos quadrados dos res√≠duos em cada modelo segue uma distribui√ß√£o proporcional a uma qui-quadrado. A estat√≠stica F √© a raz√£o de duas vari√°veis aleat√≥rias que seguem distribui√ß√µes qui-quadrado, e onde a estat√≠stica √© normalizada pelos graus de liberdade. Pela defini√ß√£o da distribui√ß√£o F como a raz√£o de duas qui-quadrados, a estat√≠stica F segue uma distribui√ß√£o F com graus de liberdade dados por $(p_1-p_0)$ e $(N-p_1-1)$.
A distribui√ß√£o do numerador √© a diferen√ßa dos RSS, que √© proporcional a uma distribui√ß√£o qui-quadrado com $p_1 - p_0$ graus de liberdade e o denominador √© a soma dos quadrados dos res√≠duos do modelo completo, dividida pelo seu grau de liberdade, o que resulta em uma distribui√ß√£o qui-quadrado com $N - p_1 -1$ graus de liberdade. $\blacksquare$

**Corol√°rio 29:** Teste F como Comparador de Modelos

A distribui√ß√£o F permite que a signific√¢ncia dos grupos de preditores seja avaliada, comparando a diferen√ßa no ajuste dos modelos com a sua complexidade. O teste F √© uma generaliza√ß√£o do teste t, j√° que o teste t pode ser visto como um teste F com um √∫nico preditor. O valor do p-valor permite que se decida se rejeitamos ou n√£o a hip√≥tese nula, de que o grupo de par√¢metros seja igual a zero.

### Aplica√ß√µes Pr√°ticas da Estat√≠stica F
```mermaid
flowchart TD
    A[Sele√ß√£o de Vari√°veis] --> B(Teste F)
    C[Compara√ß√£o de Modelos] --> B
    D[ANOVA] --> B
    E[Modelos Aninhados] --> B
    B --> F{Avaliar Signific√¢ncia}
    F --> G[Decis√£o/A√ß√£o]
```

A estat√≠stica F e o teste F t√™m diversas aplica√ß√µes pr√°ticas na modelagem de regress√£o linear:

1.  **Sele√ß√£o de Vari√°veis:**  O teste F √© utilizado na sele√ß√£o de vari√°veis para avaliar a signific√¢ncia de grupos de preditores. O teste √© usado para remover os preditores que n√£o contribuem significativamente para o modelo, e que podem estar relacionados com *overfitting*.
2. **Compara√ß√£o de Modelos:**  O teste F √© √∫til para comparar dois modelos com diferentes conjuntos de preditores. O teste permite decidir se um modelo com mais preditores captura mais informa√ß√£o dos dados, e se essa melhoria do ajuste justifica o aumento na complexidade do modelo.
3.  **An√°lise de Vari√¢ncia (ANOVA):**  O teste F √© a base da ANOVA, que avalia a signific√¢ncia de vari√°veis categ√≥ricas (que se transformam em grupos de vari√°veis *dummy*), e permite determinar se grupos de vari√°veis tem um efeito na vari√°vel resposta.
4. **Modelos Aninhados:** O teste F √© usado para comparar modelos aninhados, ou seja, modelos onde um modelo reduzido √© um caso particular de um modelo mais completo. Nesse caso, o teste F avalia se a adi√ß√£o de preditores no modelo completo leva a uma melhoria estatisticamente significativa no ajuste do modelo.

> üí° **Exemplo Num√©rico: Sele√ß√£o de Vari√°veis**
>
> Suponha que estamos modelando o pre√ßo de casas ($y$) com base em v√°rias caracter√≠sticas, como √°rea ($x_1$), n√∫mero de quartos ($x_2$) e dist√¢ncia do centro da cidade ($x_3$). Inicialmente, inclu√≠mos todos os preditores em um modelo completo. Em seguida, queremos testar se podemos remover $x_3$ (dist√¢ncia do centro) sem perda significativa de ajuste.
>
> Modelo Completo: $y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \epsilon$
> Modelo Reduzido: $y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon$
>
> Ap√≥s ajustar os modelos aos dados (simulados), obtemos os seguintes resultados:
>
> - $RSS_0$ (modelo reduzido, sem $x_3$) = 1200
> - $RSS_1$ (modelo completo, com $x_3$) = 1000
> - $N$ = 150 observa√ß√µes
> - $p_1$ (modelo completo) = 4
> - $p_0$ (modelo reduzido) = 3
>
> Calculamos a estat√≠stica F:
>
> $F = \frac{(1200 - 1000)/(4 - 3)}{1000/(150 - 4 - 1)} = \frac{200/1}{1000/145} = \frac{200}{6.896} \approx 28.99$
>
> O p-valor √© calculado usando a distribui√ß√£o F com graus de liberdade 1 e 145. Se o p-valor for inferior a 0.05, rejeitamos a hip√≥tese nula, indicando que $x_3$ √© um preditor significativo e deve ser mantido no modelo.
>
> ```python
> import numpy as np
> from scipy.stats import f
>
> # Dados do exemplo
> rss_0 = 1200
> rss_1 = 1000
> N = 150
> p1 = 4
> p0 = 3
>
> # C√°lculo da estat√≠stica F
> F = ((rss_0 - rss_1) / (p1 - p0)) / (rss_1 / (N - p1 - 1))
> print(f"Estat√≠stica F: {F:.2f}")
>
> # C√°lculo do p-valor
> df1 = p1 - p0
> df2 = N - p1 - 1
> p_valor = 1 - f.cdf(F, df1, df2)
> print(f"P-valor: {p_valor:.4f}")
>
> # Interpreta√ß√£o
> alpha = 0.05
> if p_valor < alpha:
>     print("Rejeitamos a hip√≥tese nula. A dist√¢ncia do centro (x3) √© um preditor significativo.")
> else:
>     print("N√£o rejeitamos a hip√≥tese nula. A dist√¢ncia do centro (x3) n√£o √© um preditor significativo.")
> ```
>
> Este exemplo ilustra como o teste F pode ser usado para decidir se um preditor deve ser inclu√≠do ou exclu√≠do de um modelo.

A utiliza√ß√£o da estat√≠stica F e do teste F √© um passo crucial na constru√ß√£o e valida√ß√£o de modelos de regress√£o linear. A capacidade de comparar e selecionar modelos atrav√©s de um teste estat√≠stico √© uma ferramenta valiosa no processo de modelagem.

> ‚ö†Ô∏è **Nota Importante**: A estat√≠stica F compara o ajuste de dois modelos de regress√£o linear, usando a diferen√ßa nos res√≠duos e os seus graus de liberdade.
> ‚ùó **Ponto de Aten√ß√£o**: A estat√≠stica F segue uma distribui√ß√£o F sob a hip√≥tese nula, permitindo o c√°lculo do p-valor e a tomada de decis√µes.

> ‚úîÔ∏è **Destaque**: O teste F, quando usado corretamente, avalia a signific√¢ncia de grupos de preditores e permite decidir quando modelos mais complexos s√£o necess√°rios.

### Conclus√£o
A estat√≠stica F, definida como $F = \frac{(RSS_0 - RSS_1)/(p_1 - p_0)}{RSS_1/(N - p_1 - 1)}$, √© uma ferramenta fundamental na modelagem de regress√£o linear, usada para avaliar a signific√¢ncia de grupos de preditores. Atrav√©s da compara√ß√£o do ajuste de diferentes modelos, o teste F auxilia a selecionar os melhores preditores e a construir modelos mais precisos e interpret√°veis. O entendimento da deriva√ß√£o, da interpreta√ß√£o e das propriedades da estat√≠stica F √© essencial para utilizar a regress√£o linear de forma eficaz, e para construir modelos que combinem ajuste aos dados com generaliza√ß√£o para novos dados.

### Refer√™ncias
[^48]: "Often we need to test for the significance of groups of coefficients simultaneously. For example, to test if a categorical variable with k levels can be excluded from a model, we need to test whether the coefficients of the dummy variables used to represent the levels can all be set to zero. Here we use the F statistic" *(Trecho de Linear Methods for Regression)*
[^1]:  "A linear regression model assumes that the regression function E(Y|X) is linear in the inputs X1,..., Xp." *(Trecho de Linear Methods for Regression)*
