## M√©todos Lineares para Regress√£o: Uma An√°lise Aprofundada com Foco em Conex√µes Bayesianas
```mermaid
graph LR
    A["Data Collection"] --> B["Linear Regression (OLS)"];
    B --> C["Regularization (Ridge/Lasso)"];
    B --> D["LDA"];
    B --> E["Logistic Regression"];
    C --> F["Bayesian Analysis (Gaussian Priors)"];
    D --> F
    E --> F
    F --> G["Posterior Estimation"];
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style G fill:#f9f,stroke:#333,stroke-width:2px
```

### Introdu√ß√£o
O cap√≠tulo anterior apresentou os modelos de regress√£o linear e seus m√©todos de estima√ß√£o, com √™nfase em abordagens cl√°ssicas como m√≠nimos quadrados e sele√ß√£o de vari√°veis [^4.1]. Neste cap√≠tulo, exploraremos a fundo esses conceitos, detalhando a conex√£o entre os m√©todos lineares e as abordagens Bayesianas. Particularmente, examinaremos como a imposi√ß√£o de priors Gaussianos sobre os par√¢metros do modelo leva a estimativas de posterior que se conectam aos conceitos de regulariza√ß√£o, como ridge regression e lasso. A regress√£o linear, conforme descrito em [^4.2], assume que a fun√ß√£o de regress√£o $E(Y|X)$ √© linear nas entradas $X_1, ..., X_p$. M√©todos lineares, embora desenvolvidos na era pr√©-computacional, continuam relevantes por sua simplicidade, interpretabilidade e, em alguns casos, por sua performance superior a modelos n√£o lineares, especialmente em cen√°rios com poucos dados de treino, baixa rela√ß√£o sinal-ru√≠do ou dados esparsos [^4.1]. As generaliza√ß√µes desses m√©todos, como as expans√µes de bases e transforma√ß√µes de entrada, expandem seu alcance e os tornam essenciais para a compreens√£o de t√©cnicas n√£o lineares.

### Conceitos Fundamentais

**Conceito 1:** **O Problema de Classifica√ß√£o e M√©todos Lineares**. O problema de classifica√ß√£o, em sua ess√™ncia, busca encontrar um limite de decis√£o que separa as classes de forma √≥tima [^4.1]. M√©todos lineares, embora possam parecer simplistas √† primeira vista, oferecem uma estrutura s√≥lida para abordar esse problema. A decis√£o de usar um m√©todo linear muitas vezes se relaciona com o trade-off entre **vi√©s** e **vari√¢ncia**: modelos lineares tendem a ter alto vi√©s, mas baixa vari√¢ncia, tornando-os adequados quando h√° poucos dados. Por exemplo, em uma an√°lise de sentimentos onde a entrada pode ser um vetor de contagens de palavras, um modelo linear simples pode atingir alta performance, mesmo com pouca complexidade. Um exemplo pr√°tico seria usar um modelo de regress√£o linear sobre uma matriz indicadora para classificar documentos em diferentes categorias, onde o output seria a categoria predita.  
> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com duas classes (0 e 1). Temos um conjunto de dados com 5 amostras e uma √∫nica feature. As features e labels s√£o: `X = np.array([[1], [2], [3], [4], [5]])` e `y = np.array([0, 0, 1, 1, 1])`. Podemos usar um modelo de regress√£o linear para classificar esses dados usando uma matriz indicadora. Primeiro, treinamos o modelo usando o sklearn:
```python
import numpy as np
from sklearn.linear_model import LinearRegression

X = np.array([[1], [2], [3], [4], [5]])
y = np.array([0, 0, 1, 1, 1])

model = LinearRegression()
model.fit(X, y)

# Predi√ß√£o para um novo ponto x = 3.5
x_new = np.array([[3.5]])
y_pred = model.predict(x_new)
print(f"Predicted value for x=3.5: {y_pred[0]}")

# O resultado ser√° um valor entre 0 e 1, e podemos classificar como 0 se < 0.5 e 1 se >= 0.5
if y_pred[0] >= 0.5:
    print("Classified as class 1")
else:
    print("Classified as class 0")
```
Este exemplo ilustra como uma regress√£o linear pode ser usada para classifica√ß√£o, embora seja importante notar que os resultados n√£o s√£o probabilidades e podem estar fora do intervalo [0,1].

**Lemma 1:** *Decomposi√ß√£o da Fun√ß√£o Discriminante Linear*. Uma fun√ß√£o discriminante linear pode ser decomposta em uma proje√ß√£o dos dados em um hiperplano e uma decis√£o com base na posi√ß√£o projetada. Matematicamente, dada uma fun√ß√£o discriminante $f(x) = w^T x + b$, onde $w$ √© o vetor de pesos e $b$ √© o bias, a proje√ß√£o em um hiperplano definido por $w$ √© dada por $\frac{w^T x}{||w||}$, e a decis√£o da classe √© baseada no sinal de $f(x)$.
```mermaid
graph LR
    subgraph "Linear Discriminant Function Decomposition"
        direction TB
        A["Discriminant Function: f(x) = w^Tx + b"]
        B["Projection onto Hyperplane: (w^Tx)/||w||"]
        C["Decision Based on Sign: sign(f(x))"]
        A --> B
        A --> C
    end
```
**Prova:** O hiperplano de decis√£o √© definido por $w^T x + b = 0$. O vetor $w$ √© ortogonal ao hiperplano. A proje√ß√£o de um ponto $x$ sobre o vetor $w$ (ou seja, a proje√ß√£o em dire√ß√£o ortogonal ao hiperplano) √© $\frac{w^T x}{||w||}$. A fun√ß√£o discriminante linear usa essa proje√ß√£o, adicionando um *bias* $b$. $\blacksquare$

**Conceito 2:** **Linear Discriminant Analysis (LDA)**. A LDA √© um m√©todo de classifica√ß√£o que assume que as classes seguem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia [^4.3]. A fun√ß√£o discriminante do LDA √© derivada da probabilidade posterior de cada classe, baseando-se na probabilidade de um ponto pertencer a cada classe. A fronteira de decis√£o, portanto, √© um hiperplano que maximiza a separa√ß√£o entre classes, considerando a vari√¢ncia dentro de cada classe. As suposi√ß√µes de normalidade e igualdade de covari√¢ncia s√£o cruciais para a deriva√ß√£o do LDA [^4.3.1]. Se essas suposi√ß√µes n√£o se sustentam, outros m√©todos podem ser mais adequados. Matematicamente, a fun√ß√£o discriminante da LDA para a classe $k$ √© dada por:

$$ \delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log(\pi_k) $$

Onde $\mu_k$ √© a m√©dia da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum a todas as classes e $\pi_k$ √© a probabilidade *a priori* da classe $k$ [^4.3.2]. A fun√ß√£o de decis√£o, em ess√™ncia, usa essa proje√ß√£o e classifica um novo ponto na classe com maior probabilidade posterior.
> üí° **Exemplo Num√©rico:**  Vamos considerar um exemplo simplificado com duas classes e duas features. Suponha que temos:
> - Classe 1: $\mu_1 = [1, 1]$,  $\pi_1 = 0.4$
> - Classe 2: $\mu_2 = [3, 3]$, $\pi_2 = 0.6$
> - Matriz de covari√¢ncia comum: $\Sigma = [[1, 0.5], [0.5, 1]]$
> Vamos calcular a fun√ß√£o discriminante para um novo ponto $x = [2, 2]$:
```python
import numpy as np
from numpy.linalg import inv

mu1 = np.array([1, 1])
mu2 = np.array([3, 3])
pi1 = 0.4
pi2 = 0.6
Sigma = np.array([[1, 0.5], [0.5, 1]])
x = np.array([2, 2])

Sigma_inv = inv(Sigma)

delta1 = x.T @ Sigma_inv @ mu1 - 0.5 * mu1.T @ Sigma_inv @ mu1 + np.log(pi1)
delta2 = x.T @ Sigma_inv @ mu2 - 0.5 * mu2.T @ Sigma_inv @ mu2 + np.log(pi2)
print(f"Discriminant function for class 1: {delta1}")
print(f"Discriminant function for class 2: {delta2}")

if delta1 > delta2:
    print("Classified as class 1")
else:
    print("Classified as class 2")
```
Este c√≥digo calcula as fun√ß√µes discriminantes da LDA para cada classe e classifica o ponto x na classe com maior valor discriminante.
```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction TB
        A["Discriminant Function: Œ¥k(x)"]
        B["Term 1: x^T Œ£^-1 Œºk"]
        C["Term 2: -1/2 * Œºk^T Œ£^-1 Œºk"]
        D["Term 3: log(œÄk)"]
        A --> B
        A --> C
        A --> D
        style A fill:#ccf,stroke:#333,stroke-width:2px
    end
```

**Corol√°rio 1:** A fun√ß√£o discriminante linear na LDA √© equivalente √† proje√ß√£o em um subespa√ßo de menor dimens√£o. Se a matriz de covari√¢ncia √© singular, a LDA pode ser adaptada para lidar com essa situa√ß√£o, encontrando proje√ß√µes em subespa√ßos onde a matriz √© invert√≠vel, de forma que essa proje√ß√£o capture a m√°xima separabilidade entre as classes [^4.3.1].

**Conceito 3:** **Regress√£o Log√≠stica**. A regress√£o log√≠stica √© um m√©todo de classifica√ß√£o probabil√≠stico que modela a probabilidade de um ponto pertencer a uma classe atrav√©s de uma fun√ß√£o log√≠stica [^4.4]. Diferentemente da LDA, a regress√£o log√≠stica n√£o imp√µe restri√ß√µes sobre as covari√¢ncias das classes, oferecendo mais flexibilidade, especialmente em problemas com dados n√£o Gaussianos. A regress√£o log√≠stica modela o log-odds (logit) como uma fun√ß√£o linear dos preditores:

$$ \log\left(\frac{p(x)}{1-p(x)}\right) = \beta_0 + \beta_1x_1 + \ldots + \beta_p x_p $$

Onde $p(x)$ √© a probabilidade de um ponto pertencer √† classe positiva [^4.4.1]. O objetivo √© estimar os par√¢metros $\beta$ que maximizam a verossimilhan√ßa dos dados, o que √© frequentemente realizado por m√©todos de otimiza√ß√£o num√©rica, como o gradiente descendente [^4.4.2].
> ‚ö†Ô∏è **Nota Importante**: Em regress√£o log√≠stica, o conceito do logit √© essencial para transformar a probabilidade, que est√° limitada entre 0 e 1, em um espa√ßo irrestrito, que pode ser modelado como uma fun√ß√£o linear dos preditores.
> ‚ùó **Ponto de Aten√ß√£o**: Classes n√£o balanceadas podem levar a estimativas de par√¢metros enviesadas na regress√£o log√≠stica, requerendo t√©cnicas de balanceamento ou ajuste de pesos.
> ‚úîÔ∏è **Destaque**: Existe uma forte correla√ß√£o entre as estimativas dos par√¢metros na LDA e na regress√£o log√≠stica, especialmente quando as classes seguem distribui√ß√µes Gaussianas com covari√¢ncias semelhantes. Essa conex√£o, como veremos, √© a base para v√°rias t√©cnicas que relacionam os dois m√©todos.
> üí° **Exemplo Num√©rico:** Suponha que temos um modelo de regress√£o log√≠stica com dois par√¢metros: $\beta_0 = -1$ e $\beta_1 = 0.5$. Dado um ponto com feature $x_1 = 2$, podemos calcular a probabilidade de pertencer √† classe positiva:
$$ \text{logit}(p(x)) = -1 + 0.5 \times 2 = 0 $$
$$ p(x) = \frac{1}{1 + e^{-\text{logit}(p(x))}} = \frac{1}{1 + e^0} = \frac{1}{2} = 0.5 $$
```python
import numpy as np

beta0 = -1
beta1 = 0.5
x1 = 2

logit = beta0 + beta1 * x1
p_x = 1 / (1 + np.exp(-logit))
print(f"Logit: {logit}")
print(f"Probability of belonging to the positive class: {p_x}")
```
Este exemplo mostra como, com os par√¢metros do modelo e o valor da feature, podemos calcular a probabilidade de pertencer √† classe positiva.
```mermaid
graph LR
    subgraph "Logistic Regression Formulation"
        direction TB
        A["Logit Function: log(p(x)/(1-p(x)))"]
        B["Linear Model: Œ≤0 + Œ≤1x1 + ... + Œ≤pxp"]
        C["Probability: p(x) = 1 / (1 + e^-logit(p(x)))"]
        A --> B
        B --> C
        style C fill:#ccf,stroke:#333,stroke-width:2px
    end
```

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
```mermaid
graph LR
    A["Classes"] --> B["Indicator Matrix"];
    B --> C["Linear Regression (OLS)"];
    C --> D["Coefficient Estimation"];
    D --> E["Decision Rule"];
    E --> F["Class Prediction"];
    F --> G["Comparison with Probabilistic Methods"];
    style A fill:#ccf,stroke:#333,stroke-width:2px
    style G fill:#ccf,stroke:#333,stroke-width:2px
```
A regress√£o linear pode ser adaptada para a classifica√ß√£o utilizando uma **matriz de indicadores** para representar as classes [^4.2]. Nesse enfoque, cada classe √© codificada como uma vari√°vel *dummy* e um modelo linear √© ajustado para prever o valor da vari√°vel de resposta, que nesse caso seria a vari√°vel indicadora da classe. Apesar de sua simplicidade, essa abordagem tem limita√ß√µes, como a possibilidade de previs√µes fora do intervalo [0,1] e a sensibilidade a classes n√£o balanceadas. No entanto, a regress√£o de indicadores, como descrito em [^4.2], pode ser √∫til em alguns casos, especialmente quando a fronteira de decis√£o linear √© suficiente para o problema e o foco principal √© a separa√ß√£o das classes e n√£o uma probabilidade precisa da pertin√™ncia √† classe. Matematicamente, se temos $K$ classes, criar√≠amos $K$ vari√°veis indicadoras, e o problema de regress√£o linear seria adaptado para cada uma dessas vari√°veis.

**Lemma 2:** A regress√£o linear de indicadores, em certas condi√ß√µes, √© equivalente a m√©todos discriminantes lineares. Em termos formais, se assumimos que os erros s√£o aditivos e Gaussianos, a fronteira de decis√£o entre classes pode ser aproximada por uma regress√£o linear sobre as vari√°veis indicadoras, e essa fronteira tem uma forma similar √† das fronteiras obtidas por LDA.
**Prova**: A regress√£o de indicadores ajusta uma fun√ß√£o linear para cada vari√°vel indicadora de classe, usando m√≠nimos quadrados. A decis√£o da classe √© feita com base na classe de maior valor predito. Em alguns casos, sob suposi√ß√µes adequadas dos dados, a fronteira linear resultante dessa abordagem se assemelha √† fronteira gerada por LDA, principalmente quando as matrizes de covari√¢ncia s√£o similares entre classes. Formalmente, a fun√ß√£o discriminante $x^T\beta$ pode ser derivada como aproxima√ß√£o da fun√ß√£o discriminante da LDA. $\blacksquare$

**Corol√°rio 2:** A proje√ß√£o de dados em hiperplanos de decis√£o gerados por regress√£o linear de indicadores pode ser usada para reduzir a dimensionalidade antes de aplicar classificadores mais complexos.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
```mermaid
graph LR
    A["Variable Selection"] --> B["LDA"];
    A --> C["Logistic Regression"];
    B --> D["Hyperplane"];
    C --> D
    E["Regularization"] --> B;
    E --> C;
     F["Model Complexity"] --> E;
    G["Overfitting"] --> E
    F --> G;
   style A fill:#ccf,stroke:#333,stroke-width:2px
   style E fill:#ccf,stroke:#333,stroke-width:2px
   style G fill:#ccf,stroke:#333,stroke-width:2px
```
M√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o s√£o cruciais em classifica√ß√£o para lidar com o problema de *overfitting*, especialmente quando o n√∫mero de preditores √© alto [^4.5]. A regulariza√ß√£o, em particular, adiciona termos de penaliza√ß√£o √† fun√ß√£o de custo, for√ßando os coeficientes do modelo a adotarem valores menores, o que reduz a vari√¢ncia do modelo [^4.4.4]. Penaliza√ß√µes L1 (Lasso) promovem a *sparsity* do modelo, enquanto penaliza√ß√µes L2 (Ridge) diminuem a magnitude dos coeficientes de forma mais suave. Em um modelo log√≠stico, por exemplo, podemos adicionar uma penaliza√ß√£o L1 (Lasso) como:

$$ J(\beta) = - \sum_{i=1}^n \left[ y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i)) \right] + \lambda \sum_{j=1}^p |\beta_j| $$

Onde $\lambda$ √© o par√¢metro de regulariza√ß√£o [^4.4.4]. A combina√ß√£o de penaliza√ß√µes L1 e L2 (Elastic Net) permite aproveitar as vantagens de ambos os tipos de regulariza√ß√£o.
> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o log√≠stica com penaliza√ß√£o L1. Vamos usar um exemplo simulado para ilustrar o efeito da regulariza√ß√£o.
```python
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Simula dados de exemplo
np.random.seed(42)
X = np.random.rand(100, 5) # 100 amostras, 5 features
y = np.random.randint(0, 2, 100)

# Divide dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Treina o modelo sem regulariza√ß√£o
model_no_reg = LogisticRegression(penalty=None, solver='lbfgs', max_iter=1000)
model_no_reg.fit(X_train, y_train)
y_pred_no_reg = model_no_reg.predict(X_test)

# Treina o modelo com regulariza√ß√£o L1 (Lasso)
model_lasso = LogisticRegression(penalty='l1', solver='liblinear', C=0.5, random_state=42, max_iter=1000) # C = 1/lambda
model_lasso.fit(X_train, y_train)
y_pred_lasso = model_lasso.predict(X_test)

# Imprime os resultados
print("Accuracy sem regulariza√ß√£o: ", accuracy_score(y_test, y_pred_no_reg))
print("Accuracy com regulariza√ß√£o L1: ", accuracy_score(y_test, y_pred_lasso))
print("Coeficientes sem regulariza√ß√£o:", model_no_reg.coef_)
print("Coeficientes com regulariza√ß√£o L1:", model_lasso.coef_)
```
Este exemplo mostra que a regulariza√ß√£o L1 (Lasso) pode levar a coeficientes esparsos (alguns exatamente zero), enquanto o modelo sem regulariza√ß√£o usa todos os coeficientes. A acur√°cia do modelo tamb√©m pode ser afetada pela regulariza√ß√£o. Este c√≥digo demonstra como usar o sklearn para criar modelos com e sem regulariza√ß√£o L1 e como os coeficientes mudam em consequ√™ncia.

**Lemma 3:** A penaliza√ß√£o L1 em classifica√ß√£o log√≠stica leva a coeficientes esparsos. A penaliza√ß√£o L1 tem como caracter√≠stica diminuir a magnitude dos coeficientes, for√ßando alguns a serem exatamente zero, resultando em um modelo mais simples e interpretabilidade.  
**Prova:** A penaliza√ß√£o L1, $|\beta_j|$, n√£o √© diferenci√°vel no ponto zero, o que causa a esparsidade. Ao minimizar a fun√ß√£o de custo, essa penaliza√ß√£o for√ßa alguns coeficientes $\beta_j$ a serem zero, especialmente quando a magnitude dos coeficientes √© pequena. Isso acontece porque a penaliza√ß√£o L1 adiciona uma fun√ß√£o com derivada descont√≠nua em zero, for√ßando os par√¢metros a zero para atingir o m√≠nimo da fun√ß√£o de custo. $\blacksquare$

**Corol√°rio 3:** A esparsidade induzida pela penaliza√ß√£o L1 em modelos classificat√≥rios melhora a interpretabilidade do modelo, identificando os preditores mais relevantes para a classifica√ß√£o.
```mermaid
graph LR
 subgraph "L1 Regularization (Lasso)"
    A["Cost Function J(Œ≤)"]
    B["Cross-Entropy Loss"]
    C["L1 Penalty: Œª * ‚àë|Œ≤j|"]
    A --> B
    A --> C
    C --> D["Sparse Coefficients"]
     style D fill:#ccf,stroke:#333,stroke-width:2px
  end
```

> ‚ö†Ô∏è **Ponto Crucial**: A combina√ß√£o de regulariza√ß√£o L1 e L2 (Elastic Net) permite controlar a esparsidade e a estabilidade do modelo, oferecendo uma abordagem mais robusta e flex√≠vel.

### Separating Hyperplanes e Perceptrons
A ideia de maximizar a margem de separa√ß√£o entre classes leva ao conceito de **hiperplanos √≥timos**. Os *separating hyperplanes* buscam o hiperplano que melhor separa as classes, maximizando a dist√¢ncia entre os pontos de dados e o hiperplano [^4.5.2]. Essa abordagem √© intimamente relacionada ao conceito de *Support Vector Machines* (SVMs), embora o contexto aqui seja mais focado em m√©todos lineares. O problema de otimiza√ß√£o para encontrar o hiperplano de m√°xima margem pode ser resolvido atrav√©s da formula√ß√£o dual de Wolfe, onde a solu√ß√£o surge como uma combina√ß√£o linear dos *support vectors*. Os *support vectors* s√£o os pontos de dados que se encontram mais pr√≥ximos do hiperplano de decis√£o. J√° o *perceptron* de Rosenblatt √© um algoritmo de aprendizagem iterativo que, sob condi√ß√µes de linear separabilidade, converge para uma solu√ß√£o que separa as classes, utilizando uma abordagem de ajuste de pesos baseada no feedback dos erros de classifica√ß√£o [^4.5.1].

### Pergunta Te√≥rica Avan√ßada: Diferen√ßas Fundamentais entre LDA e a Regra de Decis√£o Bayesiana com Covari√¢ncias Iguais
**Resposta:** A **regra de decis√£o Bayesiana** define que um ponto deve ser classificado na classe que maximiza a probabilidade posterior [^4.3]. Quando as distribui√ß√µes das classes s√£o gaussianas com a mesma matriz de covari√¢ncia, a regra de decis√£o Bayesiana leva a uma fronteira de decis√£o linear [^4.3]. Sob essas mesmas suposi√ß√µes, a LDA, como discutido em [^4.3.3], deriva sua regra de decis√£o de uma forma que √© equivalente a da regra de decis√£o Bayesiana. Contudo, LDA e regra bayesiana podem diferir sob outras suposi√ß√µes, especialmente quando as covari√¢ncias n√£o s√£o iguais, caso em que a fronteira de decis√£o √© quadr√°tica (QDA) e n√£o linear.
> üí° **Exemplo Num√©rico**: Para ilustrar a diferen√ßa entre LDA e a regra Bayesiana com covari√¢ncias diferentes, considere duas classes com as seguintes propriedades:
> *   Classe 1: $\mu_1 = [1, 1]$, $\Sigma_1 = [[1, 0], [0, 1]]$ , $\pi_1 = 0.5$
> *   Classe 2: $\mu_2 = [3, 3]$, $\Sigma_2 = [[2, 1], [1, 2]]$ , $\pi_2 = 0.5$
>
>   A LDA assume que $\Sigma_1 = \Sigma_2$, enquanto a regra Bayesiana com covari√¢ncias diferentes n√£o faz essa suposi√ß√£o. Se usarmos o classificador Bayesiano (QDA) com estas covari√¢ncias, a fronteira de decis√£o ser√° quadr√°tica, n√£o linear, diferentemente do LDA. O seguinte c√≥digo em Python demonstra como calcular as probabilidades posteriores para um ponto $x = [2,2]$ usando as fun√ß√µes de densidade multivariadas.
```python
import numpy as np
from numpy.linalg import inv
from scipy.stats import multivariate_normal

# Dados das classes
mu1 = np.array([1, 1])
Sigma1 = np.array([[1, 0], [0, 1]])
pi1 = 0.5
mu2 = np.array([3, 3])
Sigma2 = np.array([[2, 1], [1, 2]])
pi2 = 0.5

x = np.array([2, 2])

# Calcula as probabilidades de densidade
p_x_given_c1 = multivariate_normal.pdf(x, mean=mu1, cov=Sigma1)
p_x_given_c2 = multivariate_normal.pdf(x, mean=mu2, cov=Sigma2)

# Calcula as probabilidades posteriores
p_c1_given_x = (p_x_given_c1 * pi1) / (p_x_given_c1 * pi1 + p_x_given_c2 * pi2)
p_c2_given_x = (p_x_given_c2 * pi2) / (p_x_given_c1 * pi1 + p_x_given_c2 * pi2)
print(f"Probability of class 1 given x: {p_c1_given_x}")
print(f"Probability of class 2 given x: {p_c2_given_x}")

# Classifica o ponto x
if p_c1_given_x > p_c2_given_x:
  print("Classified as class 1")
else:
  print("Classified as class 2")
```
Este exemplo ilustra como, usando a regra Bayesiana com covari√¢ncias diferentes, obtemos probabilidades posteriores que, em geral, levam a uma decis√£o diferente do LDA, e a fronteira de decis√£o deixa de ser linear.
```mermaid
graph LR
    subgraph "LDA vs Bayesian Decision Rule"
        direction TB
        A["LDA: Assumes Equal Covariance Matrices"]
        B["Bayesian Rule: p(k|x) = max (p(x|k) * œÄk) / p(x)"]
        C["Equal Covariances: Linear Decision Boundary"]
        D["Unequal Covariances: Quadratic Decision Boundary (QDA)"]
        A --> C
        B --> C
        B --> D
        style A fill:#ccf,stroke:#333,stroke-width:2px
         style B fill:#ccf,stroke:#333,stroke-width:2px
    end
```

**Lemma 4:** Formalmente, em dados gaussianos com covari√¢ncias iguais, a regra de decis√£o Bayesiana e a LDA levam ao mesmo classificador linear.  
**Prova**: Sejam $p(x|k)$ a distribui√ß√£o condicional de $x$ dado a classe $k$ e $\pi_k$ a probabilidade a priori da classe $k$. A regra de decis√£o bayesiana classifica um novo ponto $x$ na classe que maximiza a probabilidade posterior: $p(k|x) = \frac{p(x|k)\pi_k}{p(x)}$. Ao assumirmos Gaussianas com covari√¢ncias iguais, $p(x|k) = \frac{1}{(2\pi)^{p/2} |\Sigma|^{1/2}}e^{-\frac{1}{2}(x-\mu_k)^T \Sigma^{-1}(x-\mu_k)}$. Substituindo, e tomando o logaritmo, obtemos uma fun√ß√£o que √© linear em $x$, que √© equivalente a da LDA. $\blacksquare$

**Corol√°rio 4:** Se a hip√≥tese de covari√¢ncias iguais √© relaxada, a fronteira de decis√£o Bayesiana torna-se quadr√°tica (QDA), que √© mais flex√≠vel que a fronteira linear do LDA, mas pode levar a maior complexidade e *overfitting*.
> ‚ö†Ô∏è **Ponto Crucial**:  A diferen√ßa crucial entre LDA e a regra de decis√£o Bayesiana, sob distribui√ß√µes gaussianas, reside na suposi√ß√£o sobre a matriz de covari√¢ncia. O uso de covari√¢ncias iguais leva √† LDA e a uma fronteira linear, enquanto covari√¢ncias distintas levam a QDA e fronteiras quadr√°ticas, impactando diretamente o modelo.

### Conclus√£o
Neste cap√≠tulo, aprofundamos o conhecimento sobre modelos lineares, focando nas conex√µes entre abordagens cl√°ssicas e bayesianas. Exploramos como a regress√£o linear pode ser adaptada para classifica√ß√£o, detalhamos o funcionamento do LDA e da regress√£o log√≠stica, e discutimos a import√¢ncia de m√©todos de sele√ß√£o e regulariza√ß√£o de vari√°veis. A conex√£o entre modelos lineares e a infer√™ncia Bayesiana ficou clara atrav√©s do estudo de priors Gaussianos e suas rela√ß√µes com t√©cnicas de regulariza√ß√£o como ridge e lasso. As perguntas te√≥ricas avan√ßadas e os *lemmas* e corol√°rios explorados permitiram uma compreens√£o mais profunda e formalizada desses conceitos.

### Footnotes
[^4.1]: "A linear regression model assumes that the regression function E(Y|X) is linear in the inputs X1,..., Xp. Linear models were largely developed in the precomputer age of statistics, but even in today's computer era there are still good reasons to study and use them." *(Trecho de Linear Methods for Regression)*
[^4.2]: "Typically we have a set of training data (x1, y1) ... (xn, yn) from which to estimate the parameters Œ≤. Each xi = (xi1, xi2,..., xip)T is a vector of feature measurements for the ith case. The most popular estimation method is least squares, in which we pick the coefficients Œ≤ = (Œ≤0, Œ≤1, ..., Œ≤p)T to minimize the residual sum of squares" *(Trecho de Linear Methods for Regression)*
[^4.3]: "The predicted values at an input vector xo are given by f(xo) = (1 : xo)TŒ≤; the fitted values at the training inputs are  yÃÇ = XŒ≤ÃÇ = X(XTX)-1XTy" *(Trecho de Linear Methods for Regression)*
[^4.3.1]: "It might happen that the columns of X are not linearly independent, so that X is not of full rank. This would occur, for example, if two of the inputs were perfectly correlated, (e.g., x2 = 3x1). Then XTX is singular and the least squares coefficients Œ≤ are not uniquely defined." *(Trecho de Linear Methods for Regression)*
[^4.3.2]: "Assuming (for the moment) that X has full column rank, and hence XTX is positive definite, we set the first derivative to zero" *(Trecho de Linear Methods for Regression)*
[^4.3.3]: "The variance-covariance matrix of the least squares parameter estimates is easily derived from (3.6) and is given by Var(Œ≤) = (XTX)-1œÉ2." *(Trecho de Linear Methods for Regression)*
[^4.4]: "The linear model either assumes that the regression function E(Y|X) is linear, or that the linear model is a reasonable approximation." *(Trecho de Linear Methods for Regression)*
[^4.4.1]: "numeric or "dummy" coding of the levels of qualitative inputs. For example, if G is a five-level factor input, we might create Xj, j = 1,...,5, such that Xj = I(G = j). Together this group of Xj represents the effect of G by a set of level-dependent constants, since in Œ£j=1XjŒ≤j, one of the Xis is one, and the others are zero." *(Trecho de Linear Methods for Regression)*
[^4.4.2]:  "From a statistical point of view, this criterion is reasonable if the training observations (xi, Yi) represent independent random draws from their population." *(Trecho de Linear Methods for Regression)*
[^4.4.3]: "Assuming (for the moment) that X has full column rank, and hence XTX is positive definite, we set the first derivative to zero XT (y ‚Äì XŒ≤) = 0 to obtain the unique solution Œ≤ = (XTX)-1XTy." *(Trecho de Linear Methods for Regression)*
[^4.4.4]: "Typically one estimates the variance œÉ¬≤ by œÉ^2 = 1/(N-p-1) Œ£(yi-yÃÇi)^2" *(Trecho de Linear Methods for Regression)*
[^4.4.5]: "To draw inferences about the parameters and the model, additional assumptions are needed. We now assume that (3.1) is the correct model for the mean; that is, the conditional expectation of Y is linear in X1,..., Xp." *(Trecho de Linear Methods for Regression)*
[^4.5]: "Up to now we have made minimal assumptions about the true distribution of the data. In order to pin down the sampling properties of Œ≤, we now assume that the observations yi are uncorrelated and have constant variance œÉ¬≤, and that the xi are fixed (non random). The variance-covariance matrix of the least squares parameter estimates is easily derived from (3.6) and is given by Var(Œ≤) = (XTX)-1œÉ2" *(Trecho de Linear Methods for Regression)*
[^4.5.1]: "The N -p-1 rather than N in the denominator makes œÉ^2 an unbiased estimate of œÉ¬≤: E(œÉ^2) = œÉ2." *(Trecho de Linear Methods for Regression)*
[^4.5.2]: "To test the hypothesis that a particular coefficient Œ≤j = 0, we form the standardized coefficient or Z-score Zj = Œ≤j/√¥j, where vj is the jth diagonal element of (XTX)‚àí1. Under the null hypothesis that Œ≤j = 0, zj is distributed as tN‚àíp‚àí1 (a t distribution with N ‚Äì p ‚àí1 degrees of freedom), and hence a large (absolute) value of zj will lead to rejection of this null hypothesis." *(Trecho de Linear Methods for Regression)*
<!-- END DOCUMENT -->
