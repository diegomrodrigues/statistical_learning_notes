## M√©todos Lineares para Classifica√ß√£o e An√°lise Discriminante: Uma Vis√£o Abrangente

<imagem: Mapa mental complexo mostrando a interconex√£o entre regress√£o de indicadores, LDA, regress√£o log√≠stica, m√©todos de regulariza√ß√£o e separating hyperplanes, com setas e fluxos indicando as rela√ß√µes te√≥ricas e pr√°ticas entre esses conceitos. Cada n√≥ do mapa deve conter conceitos matem√°ticos chave e refer√™ncias aos t√≥picos 4.1 a 4.5.2.>

### Introdu√ß√£o

Este cap√≠tulo explora m√©todos estat√≠sticos e de aprendizado de m√°quina para classifica√ß√£o, com foco em abordagens lineares [^4.1]. A classifica√ß√£o √© um problema fundamental no aprendizado de m√°quina, onde o objetivo √© atribuir uma amostra a uma categoria ou classe predefinida. M√©todos lineares, apesar de sua simplicidade, oferecem solu√ß√µes eficazes e interpret√°veis para muitos problemas de classifica√ß√£o [^4.1]. Eles servem como base para o entendimento de t√©cnicas n√£o lineares mais avan√ßadas. Discutiremos t√©cnicas como regress√£o linear aplicada a matrizes indicadoras, An√°lise Discriminante Linear (LDA), regress√£o log√≠stica, e o conceito de **separating hyperplanes**, juntamente com t√©cnicas de regulariza√ß√£o para lidar com a alta variabilidade. O objetivo √© fornecer uma vis√£o detalhada dos fundamentos te√≥ricos e matem√°ticos desses m√©todos, suas aplica√ß√µes e suas limita√ß√µes.

### Conceitos Fundamentais

**Conceito 1:** O problema de classifica√ß√£o envolve a atribui√ß√£o de um vetor de entrada **x** a uma das *K* classes poss√≠veis, denotadas por $C_1, C_2, \ldots, C_K$. Modelos lineares assumem que a fun√ß√£o de decis√£o √© linear em rela√ß√£o √†s entradas **x**, utilizando uma combina√ß√£o linear das vari√°veis de entrada para separar as classes. A decis√£o √© tomada com base em qual lado de uma fronteira de decis√£o linear o ponto **x** est√° situado. No entanto, usar apenas modelos lineares pode introduzir vi√©s, especialmente quando as classes n√£o s√£o linearmente separ√°veis, mas tamb√©m pode reduzir a vari√¢ncia das previs√µes, comparado com modelos mais flex√≠veis [^4.1], [^4.2]. Em cen√°rios com poucos dados de treino, um modelo linear mais simples pode generalizar melhor do que um modelo mais complexo, apesar do poss√≠vel vi√©s. Por exemplo, em tarefas de classifica√ß√£o de imagens, um classificador linear simples pode ser adequado para distinguir d√≠gitos manuscritos se as caracter√≠sticas (features) relevantes forem definidas de forma adequada.

**Lemma 1:** Dada uma matriz de design X e um vetor de classes **y**, onde $y_i \in \{1, 2, \ldots, K\}$, a regress√£o de uma matriz indicadora Y, onde $Y_{ij} = 1$ se $y_i = j$ e 0 caso contr√°rio, resulta em fun√ß√µes discriminantes lineares para cada classe *j* [^4.3]. Isto √©, a fun√ß√£o discriminante para a classe *j* pode ser expressa como:

$$f_j(\mathbf{x}) = \mathbf{x}^T\mathbf{\beta}_j$$

onde $\mathbf{\beta}_j$ s√£o os coeficientes obtidos da regress√£o por m√≠nimos quadrados. Este resultado pode ser demonstrado mostrando que a solu√ß√£o por m√≠nimos quadrados para a regress√£o da matriz indicadora √© equivalente √† minimiza√ß√£o da soma dos erros quadr√°ticos para cada classe. Os coeficientes $\mathbf{\beta}_j$ resultantes, quando combinados com um novo vetor de entrada **x**, indicam a proximidade de **x** √† classe *j*. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Suponha um problema de classifica√ß√£o com 3 classes e duas vari√°veis de entrada (features). Temos os seguintes dados de treinamento:
>
> ```python
> import numpy as np
> from sklearn.linear_model import LinearRegression
>
> # Dados de treinamento
> X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 1], [8, 0]])
> y = np.array([0, 0, 1, 1, 2, 2, 2]) # Classes: 0, 1, 2
>
> # Criar matriz indicadora Y
> Y = np.zeros((len(y), 3))
> for i, label in enumerate(y):
>     Y[i, label] = 1
>
> # Regress√£o linear para cada classe
> model = LinearRegression()
> model.fit(X, Y)
>
> # Coeficientes beta para cada classe
> betas = model.coef_
> print("Coeficientes Beta para cada classe:\n", betas)
>
> # Novo vetor de entrada
> x_new = np.array([3, 4])
>
> # Calcula as fun√ß√µes discriminantes
> discriminants = np.dot(x_new, betas.T)
> print("Fun√ß√µes discriminantes:\n", discriminants)
>
> # Predi√ß√£o da classe
> predicted_class = np.argmax(discriminants)
> print("Classe predita:", predicted_class)
> ```
>
> **Interpreta√ß√£o:** Os coeficientes `betas` representam os pesos que multiplicam as vari√°veis de entrada para cada classe. As `fun√ß√µes discriminantes` s√£o resultados dessas multiplica√ß√µes com um novo ponto `x_new`. A classe predita √© aquela com a maior fun√ß√£o discriminante.
>
> **C√°lculo dos coeficientes:**
>
> $\text{Step 1: Constru√ß√£o da Matriz Indicadora } Y:$
>
> $$ Y = \begin{bmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \end{bmatrix} $$
>
> $\text{Step 2: C√°lculo dos coeficientes } \beta \text{ para cada classe } k:$
>
> $\beta_k = (X^TX)^{-1}X^TY_k$, onde $Y_k$ √© a k-√©sima coluna da matriz indicadora.
>
> Ap√≥s o c√°lculo, os resultados obtidos foram:
>
> $\beta_0 = [-0.525, 0.250 ]$
>
> $\beta_1 = [0.051, 0.082]$
>
> $\beta_2 = [0.473, -0.332]$
>
> **Fun√ß√µes Discriminantes:** Para um novo ponto $x = [3, 4]$
>
> $f_0(x) = [3, 4] \cdot [-0.525, 0.250] = -0.575$
>
> $f_1(x) = [3, 4] \cdot [0.051, 0.082] = 0.481$
>
> $f_2(x) = [3, 4] \cdot [0.473, -0.332] = 0.180$
>
> A classe predita √© a classe 1, pois ela apresenta o maior valor para fun√ß√£o discriminante.
>
> ```mermaid
>   graph LR
>       A["Dados de Entrada X"] --> B("Regress√£o Linear");
>       C["Matriz Indicadora Y"] --> B;
>       B --> D["Coeficientes Beta"];
>       D --> E["Fun√ß√µes Discriminantes f(x)"];
>       E --> F["Classe Predita"];
> ```

**Conceito 2:** A An√°lise Discriminante Linear (LDA) assume que as classes t√™m distribui√ß√µes gaussianas com a mesma matriz de covari√¢ncia, mas diferentes m√©dias [^4.3]. O objetivo da LDA √© encontrar um subespa√ßo linear que maximize a separa√ß√£o entre as m√©dias das classes, minimizando simultaneamente a vari√¢ncia dentro de cada classe. Matematicamente, isto √© alcan√ßado atrav√©s da maximiza√ß√£o da raz√£o de dispers√£o inter-classes para a dispers√£o intra-classes. A fun√ß√£o discriminante linear obtida por LDA para cada classe *k* pode ser expressa como:

$$ \delta_k(\mathbf{x}) = \mathbf{x}^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \ln(\pi_k) $$

onde  $\mu_k$ √© a m√©dia da classe *k*,  $\Sigma$ √© a matriz de covari√¢ncia comum e $\pi_k$ √© a probabilidade a priori da classe *k*. A suposi√ß√£o de gaussianidade e igualdade de covari√¢ncias pode ser uma limita√ß√£o em algumas aplica√ß√µes.

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o bin√°ria com duas classes, onde temos duas vari√°veis de entrada. As m√©dias e a matriz de covari√¢ncia para cada classe s√£o dadas por:
>
> $\mu_1 = \begin{bmatrix} 2 \\ 2 \end{bmatrix}$, $\mu_2 = \begin{bmatrix} 4 \\ 4 \end{bmatrix}$, $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
>
> Assumimos que as probabilidades a priori s√£o iguais, $\pi_1 = \pi_2 = 0.5$.
>
> ```python
> import numpy as np
> from numpy.linalg import inv
>
> # M√©dias das classes
> mu1 = np.array([2, 2])
> mu2 = np.array([4, 4])
>
> # Matriz de covari√¢ncia comum
> Sigma = np.array([[1, 0.5], [0.5, 1]])
> Sigma_inv = inv(Sigma)
>
> # Probabilidades a priori
> pi1 = 0.5
> pi2 = 0.5
>
> # Novo vetor de entrada
> x_new = np.array([3, 3])
>
> # Calcula as fun√ß√µes discriminantes
> delta1 = np.dot(x_new, np.dot(Sigma_inv, mu1)) - 0.5 * np.dot(mu1, np.dot(Sigma_inv, mu1)) + np.log(pi1)
> delta2 = np.dot(x_new, np.dot(Sigma_inv, mu2)) - 0.5 * np.dot(mu2, np.dot(Sigma_inv, mu2)) + np.log(pi2)
> print("Fun√ß√£o discriminante para classe 1:", delta1)
> print("Fun√ß√£o discriminante para classe 2:", delta2)
>
> # Predi√ß√£o da classe
> predicted_class = 1 if delta1 > delta2 else 2
> print("Classe predita:", predicted_class)
> ```
>
> **Interpreta√ß√£o:** A fun√ß√£o discriminante √© calculada para cada classe. A classe com a maior fun√ß√£o discriminante √© predita como a classe do vetor de entrada.
>
> **C√°lculos intermedi√°rios:**
>
> $\text{Step 1: C√°lculo de } \Sigma^{-1}$
>
> $$ \Sigma^{-1} = \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} $$
>
> $\text{Step 2: C√°lculo das fun√ß√µes discriminantes para } x = [3, 3]:$
>
> $\delta_1(x) =  [3, 3] \cdot \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \cdot \begin{bmatrix} 2 \\ 2 \end{bmatrix} - \frac{1}{2} [2, 2] \cdot \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \cdot \begin{bmatrix} 2 \\ 2 \end{bmatrix} + \ln(0.5) = -0.69$
>
> $\delta_2(x) =  [3, 3] \cdot \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \cdot \begin{bmatrix} 4 \\ 4 \end{bmatrix} - \frac{1}{2} [4, 4] \cdot \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \cdot \begin{bmatrix} 4 \\ 4 \end{bmatrix} + \ln(0.5) = 1.31$
>
> A classe predita √© a classe 2, pois ela apresenta a maior fun√ß√£o discriminante.
>
> ```mermaid
>   graph LR
>       A["Dados de Entrada X"] --> B("C√°lculo das M√©dias e Covari√¢ncia");
>       B --> C["Fun√ß√µes Discriminantes LDA"];
>       C --> D["Classe Predita"];
> ```

**Corol√°rio 1:** A fun√ß√£o discriminante linear na LDA [^4.3.1] pode ser vista como uma proje√ß√£o do espa√ßo de entrada em um subespa√ßo de menor dimens√£o, onde as classes s√£o mais bem separadas. Esta proje√ß√£o √© dada por:

$$  \mathbf{w} = \Sigma^{-1} (\mu_1 - \mu_2) $$

No caso de duas classes, a fun√ß√£o discriminante se reduz a $f(\mathbf{x}) = \mathbf{w}^T\mathbf{x} + b$, onde *b* √© um termo constante. Este resultado pode ser derivado mostrando que a proje√ß√£o que maximiza a raz√£o de dispers√£o entre classes √© equivalente √† dire√ß√£o dada por $\mathbf{w}$. Ao projetar os dados em $\mathbf{w}$, a separabilidade das classes √© maximizada. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Usando os mesmos valores de $\mu_1$, $\mu_2$, e $\Sigma$ do exemplo anterior, calculamos o vetor de proje√ß√£o $\mathbf{w}$ e a fun√ß√£o discriminante simplificada.
>
> ```python
> import numpy as np
> from numpy.linalg import inv
>
> # M√©dias das classes
> mu1 = np.array([2, 2])
> mu2 = np.array([4, 4])
>
> # Matriz de covari√¢ncia comum
> Sigma = np.array([[1, 0.5], [0.5, 1]])
> Sigma_inv = inv(Sigma)
>
> # Vetor de proje√ß√£o
> w = np.dot(Sigma_inv, (mu1 - mu2))
> print("Vetor de proje√ß√£o w:", w)
>
> # Termo constante b (para simplifica√ß√£o, b ser√° considerado 0 neste exemplo)
> b = 0
>
> # Novo vetor de entrada
> x_new = np.array([3, 3])
>
> # Calcula a fun√ß√£o discriminante simplificada
> discriminant = np.dot(w, x_new) + b
> print("Fun√ß√£o discriminante simplificada:", discriminant)
> ```
>
> **Interpreta√ß√£o:** O vetor `w` indica a dire√ß√£o na qual os dados devem ser projetados para maximizar a separa√ß√£o entre classes. A fun√ß√£o discriminante simplificada, `w^T * x + b`, fornece um valor que pode ser usado para classifica√ß√£o.
>
> **C√°lculos Intermedi√°rios:**
>
> $\text{Step 1: C√°lculo de } \mathbf{w}:$
>
> $$ \mathbf{w} = \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \cdot (\begin{bmatrix} 2 \\ 2 \end{bmatrix} - \begin{bmatrix} 4 \\ 4 \end{bmatrix}) = \begin{bmatrix} 1.33 & -0.66 \\ -0.66 & 1.33 \end{bmatrix} \cdot \begin{bmatrix} -2 \\ -2 \end{bmatrix} = \begin{bmatrix} -1.33 \\ -1.33 \end{bmatrix} $$
>
> $\text{Step 2: C√°lculo da fun√ß√£o discriminante simplificada:}$
>
> $f(\mathbf{x}) =  \begin{bmatrix} -1.33 \\ -1.33 \end{bmatrix}^T \cdot \begin{bmatrix} 3 \\ 3 \end{bmatrix} + 0 = -7.98 $
>
> Um valor positivo indica a classe 1, enquanto um valor negativo indica a classe 2. Contudo, o ponto $x=[3,3]$ pertence a classe 2, e como essa fun√ß√£o simplificada n√£o considera o intercepto, esse valor deve ser comparado com a fun√ß√£o discriminante de outras classes.
>
> ```mermaid
>   graph LR
>       A["Dados de Entrada X"] --> B("Calculo de w e b");
>       B --> C["Fun√ß√£o Discriminante Simplificada"];
>       C --> D["Decis√£o de Classe"];
> ```

**Conceito 3:** A Regress√£o Log√≠stica modela a probabilidade de uma amostra pertencer a uma classe espec√≠fica usando a fun√ß√£o log√≠stica, tamb√©m conhecida como sigmoide [^4.4]. A fun√ß√£o log√≠stica transforma uma combina√ß√£o linear das vari√°veis de entrada em uma probabilidade entre 0 e 1, tornando-a apropriada para problemas de classifica√ß√£o bin√°ria.  A formula√ß√£o do modelo pode ser expressa como:

$$ P(Y=1 | \mathbf{x}) = \frac{1}{1 + e^{-(\mathbf{x}^T\mathbf{\beta})}} $$

onde $\mathbf{\beta}$ s√£o os coeficientes do modelo, que s√£o estimados por meio de um processo de maximiza√ß√£o da verossimilhan√ßa. A verossimilhan√ßa mede o qu√£o bem os par√¢metros do modelo se ajustam aos dados de treinamento.  A regress√£o log√≠stica √© uma alternativa √† LDA, especialmente quando as suposi√ß√µes gaussianas n√£o s√£o v√°lidas [^4.4], [^4.4.1], [^4.4.2], [^4.4.3], [^4.4.4], [^4.4.5]. A regress√£o log√≠stica √© uma forma de modelo de classifica√ß√£o linear com um foco probabil√≠stico, enquanto LDA tem um foco discriminante.

> ‚ö†Ô∏è **Nota Importante**: A fun√ß√£o logit, que √© o logaritmo da raz√£o de chances (odds ratio), √© linear no espa√ßo dos preditores na regress√£o log√≠stica, o que facilita a interpreta√ß√£o dos coeficientes e possibilita modelar a probabilidade de pertencimento a uma classe [^4.4.1].

> ‚ùó **Ponto de Aten√ß√£o**: A regress√£o log√≠stica pode ser sens√≠vel a classes desbalanceadas, onde uma classe √© muito mais prevalente que as outras. T√©cnicas como subamostragem da classe majorit√°ria ou sobreamostragem da classe minorit√°ria podem ser usadas para mitigar este problema [^4.4.2].

> ‚úîÔ∏è **Destaque**: Em certos casos, LDA e regress√£o log√≠stica podem gerar estimativas de par√¢metros semelhantes, especialmente se as classes forem bem separadas, por√©m a regress√£o log√≠stica oferece uma abordagem mais flex√≠vel quando as premissas de normalidade n√£o s√£o atendidas [^4.5].

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um conjunto de dados de treinamento com duas vari√°veis de entrada e uma vari√°vel de sa√≠da bin√°ria (0 ou 1). Ap√≥s o treinamento de um modelo de regress√£o log√≠stica, obtivemos os seguintes coeficientes:
>
> $\beta_0 = -2$, $\beta_1 = 1.5$, $\beta_2 = -0.5$.
>
> Para um novo vetor de entrada $\mathbf{x} = \begin{bmatrix} 1 \\ 2 \end{bmatrix}$, podemos calcular a probabilidade de pertencer √† classe 1:
>
> ```python
> import numpy as np
>
> # Coeficientes do modelo
> beta_0 = -2
> beta = np.array([1.5, -0.5])
>
> # Novo vetor de entrada
> x_new = np.array([1, 2])
>
> # Calcula a combina√ß√£o linear
> z = beta_0 + np.dot(x_new, beta)
>
> # Calcula a probabilidade usando a fun√ß√£o log√≠stica
> prob = 1 / (1 + np.exp(-z))
> print("Probabilidade de pertencer √† classe 1:", prob)
>
> # Predi√ß√£o da classe (usando um limiar de 0.5)
> predicted_class = 1 if prob >= 0.5 else 0
> print("Classe predita:", predicted_class)
> ```
>
> **Interpreta√ß√£o:** A probabilidade de pertencer √† classe 1 √© aproximadamente 0.269. Usando um limiar de 0.5, o ponto seria classificado como pertencente √† classe 0.
>
> **C√°lculo Intermedi√°rio:**
>
> $\text{Step 1: C√°lculo da combina√ß√£o linear } z:$
>
> $z = -2 + (1 \times 1.5) + (2 \times -0.5) = -2 + 1.5 - 1 = -1.5$
>
> $\text{Step 2: C√°lculo da probabilidade usando a fun√ß√£o log√≠stica:}$
>
> $P(Y=1 | x) = \frac{1}{1 + e^{-(-1.5)}} = \frac{1}{1 + 4.48} = 0.182$
>
> A probabilidade de pertencer √† classe 1 √© de aproximadamente 0.182, logo a classe predita √© 0.
>
> ```mermaid
>   graph LR
>       A["Dados de Entrada X"] --> B("Combina√ß√£o Linear");
>       B --> C("Fun√ß√£o Log√≠stica");
>       C --> D["Probabilidade"];
>       D --> E["Classe Predita"];
> ```

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
flowchart TD
  subgraph "Regress√£o de Indicadores para Classifica√ß√£o"
    A["Matriz de Design X, Vetor de Classes y"] --> B["Constru√ß√£o da Matriz Indicadora Y"]
    B --> C["Regress√£o Linear: Y = X * Beta"]
    C --> D["Obten√ß√£o dos Coeficientes Beta"]
    D --> E["Fun√ß√µes Discriminantes: f_j(x) = x^T * Beta_j"]
    E --> F["Atribui√ß√£o √† Classe com Maior f_j(x)"]
  end
```

**Explica√ß√£o:** Este diagrama representa o fluxo do processo de regress√£o de indicadores e como ele se relaciona √† classifica√ß√£o, **conforme descrito nos t√≥picos [1](4.2)**.

A regress√£o linear pode ser aplicada para classifica√ß√£o atrav√©s da cria√ß√£o de uma matriz de indicadores, em que cada coluna representa uma classe e cada linha representa uma amostra, com 1 indicando a classe a qual a amostra pertence e 0 caso contr√°rio [^4.2]. Por exemplo, em um problema de classifica√ß√£o com tr√™s classes, para cada amostra *i*, ter√≠amos um vetor $(y_{i1}, y_{i2}, y_{i3})$ onde um dos $y_{ij}$ seria 1 e o restante 0. A regress√£o linear √© aplicada usando este vetor como a vari√°vel dependente e as vari√°veis de entrada como independentes. Os coeficientes $\mathbf{\beta}$  obtidos s√£o usados para derivar fun√ß√µes discriminantes lineares. O classificador prediz a classe da amostra associando o output m√°ximo entre as classes.

No entanto, a regress√£o linear aplicada diretamente a problemas de classifica√ß√£o apresenta limita√ß√µes [^4.1], [^4.2]. A regress√£o linear n√£o se restringe ao intervalo [0, 1], necess√°rio para interpretar os resultados como probabilidades. As predi√ß√µes podem ter valores que n√£o fazem sentido no contexto de classifica√ß√£o, e o m√©todo de m√≠nimos quadrados pode levar a extrapola√ß√µes inadequadas.  Adicionalmente, a regress√£o linear para classifica√ß√£o pode sofrer do "masking problem", onde certas classes podem obscurecer a influ√™ncia de outras classes se houver fortes correla√ß√µes entre as classes e as vari√°veis de entrada [^4.3]. Por exemplo, em um problema de classifica√ß√£o de texto, a presen√ßa de uma palavra espec√≠fica em uma classe pode ofuscar a influ√™ncia de palavras que tamb√©m s√£o relevantes para outras classes, levando a um modelo de classifica√ß√£o menos preciso.

**Lemma 2:** Dada a matriz de design X e a matriz indicadora Y, a proje√ß√£o de um novo vetor de entrada x para a decis√£o de classe usando regress√£o linear √© equivalente √† proje√ß√£o sobre o hiperplano definido pelos coeficientes $\mathbf{\beta}$ obtidos via regress√£o linear. As estimativas por m√≠nimos quadrados dos coeficientes da regress√£o linear para cada classe resultam nas seguintes proje√ß√µes para cada classe *k*: $\hat{y}_{k} = x^T\hat{\mathbf{\beta}}_k$. A classe predita √© aquela com maior valor de proje√ß√£o. A equival√™ncia entre as proje√ß√µes e os hiperplanos de decis√£o pode ser demonstrada mostrando que, em condi√ß√µes espec√≠ficas, os termos lineares da proje√ß√£o e do hiperplano s√£o matematicamente similares. A decis√£o da classe baseia-se em qual das proje√ß√µes lineares para as diferentes classes √© maior. $\blacksquare$

**Corol√°rio 2:** Em certas situa√ß√µes, a proje√ß√£o do vetor de entrada sobre os hiperplanos de decis√£o gerados por regress√£o linear pode ser vista como uma forma de simplificar a an√°lise do modelo de classifica√ß√£o [^4.3]. Ao inv√©s de avaliar uma dist√¢ncia direta entre um ponto e todas as amostras, a decis√£o se baseia em avaliar qual proje√ß√£o linear √© maior. Este corol√°rio √© derivado diretamente do Lemma 2 e demonstra como a proje√ß√£o sobre hiperplanos de decis√£o simplifica o processo de classifica√ß√£o. $\blacksquare$

A regress√£o linear para classifica√ß√£o pode ser suficiente quando o objetivo principal √© encontrar uma fronteira de decis√£o linear e as probabilidades n√£o s√£o de grande import√¢ncia. Em situa√ß√µes onde a probabilidade √© crucial, como em an√°lise de risco, a regress√£o log√≠stica pode ser prefer√≠vel devido √† sua capacidade de gerar estimativas de probabilidades bem calibradas. No entanto, quando as classes s√£o linearmente separ√°veis, e o interesse principal √© a fronteira de decis√£o,  a regress√£o linear pode servir como uma alternativa eficaz, com menor complexidade e custo computacional.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph TD
    subgraph "Regulariza√ß√£o em Modelos de Classifica√ß√£o"
      direction TB
        A["Fun√ß√£o de Custo sem Regulariza√ß√£o"] --> B["Fun√ß√£o de Custo com Regulariza√ß√£o L1 (Lasso)"]
        A --> C["Fun√ß√£o de Custo com Regulariza√ß√£o L2 (Ridge)"]
        B --> D["Sparsity e Sele√ß√£o de Vari√°veis"]
        C --> E["Redu√ß√£o da Magnitude dos Coeficientes"]
        D --> F["Melhoria da Interpretabilidade"]
        E --> G["Estabilidade do Modelo"]
        A --> H["Fun√ß√£o de Custo com Regulariza√ß√£o Elastic Net"]
        H --> I["Combina√ß√£o de Sparsity e Estabilidade"]
     end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas essenciais para lidar com a alta variabilidade e a complexidade em problemas de classifica√ß√£o, especialmente quando o n√∫mero de vari√°veis (preditores) √© grande [^4.5]. O objetivo dessas t√©cnicas √© reduzir o risco de overfitting e melhorar a generaliza√ß√£o dos modelos de classifica√ß√£o. O overfitting ocorre quando o modelo se ajusta excessivamente aos dados de treinamento e n√£o generaliza bem para dados n√£o vistos.

A regulariza√ß√£o √© implementada adicionando um termo de penalidade √† fun√ß√£o de custo que o modelo busca otimizar [^4.4.4]. No contexto da regress√£o log√≠stica, por exemplo, a fun√ß√£o de verossimilhan√ßa negativa (usada como fun√ß√£o de custo) √© modificada para incluir termos de penaliza√ß√£o que restringem a magnitude dos coeficientes. As formas mais comuns de regulariza√ß√£o s√£o L1 (Lasso) e L2 (Ridge), al√©m da combina√ß√£o de ambas, Elastic Net [^4.4.4], [^4.5].

A penaliza√ß√£o L1, tamb√©m conhecida como *Lasso*, adiciona um termo de penaliza√ß√£o proporcional √† soma dos valores absolutos dos coeficientes:

$$ \text{Custo} = -\sum_{i=1}^N [y_i \log(p_i) + (1-y_i) \log(1-p_i)] + \lambda \sum_{j=1}^p |\beta_j| $$

onde $p_i$ √© a probabilidade estimada para a i-√©sima amostra, $\beta_j$ s√£o os coeficientes do modelo e $\lambda$ √© o par√¢metro de regulariza√ß√£o que controla a for√ßa da penalidade [^4.5], [^4.5.1], [^4.5.2]. A penaliza√ß√£o L1 tende a gerar solu√ß√µes esparsas, definindo alguns coeficientes como exatamente zero, o que efetivamente remove as vari√°veis correspondentes do modelo. Isso tamb√©m contribui para a interpretabilidade do modelo.

A penaliza√ß√£o L2, tamb√©m conhecida como *Ridge*, adiciona um termo de penaliza√ß√£o proporcional √† soma dos quadrados dos coeficientes:

$$ \text{Custo} = -\sum_{i=1}^N [y_i \log(p_i) + (1-y_i) \log(1-p_i)] + \lambda \sum_{j=1}^p \beta_j^2 $$

A penaliza√ß√£o L2 reduz a magnitude dos coeficientes, mas geralmente n√£o define coeficientes como exatamente zero. Ela tende a suavizar a influ√™ncia de vari√°veis altamente correlacionadas, resultando em um modelo mais est√°vel e generaliz√°vel.

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um problema de regress√£o log√≠stica bin√°ria com duas vari√°veis de entrada. Suponha que ap√≥s o ajuste de um modelo sem regulariza√ß√£o, os coeficientes sejam $\beta_1 = 2.5$ e $\beta_2 = -1.5$. Agora vamos aplicar a regulariza√ß√£o L1 (Lasso) e L2 (Ridge) com $\lambda = 0.1$.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
>
> # Dados de exemplo (apenas para demonstra√ß√£o, normalmente ter√≠amos um conjunto de treinamento maior)
> X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 1], [8, 0]])
> y = np.array([0, 0, 1, 1, 0, 1, 0])
>
> # Ajuste do modelo sem regulariza√ß√£o
> model_no_reg = LogisticRegression(penalty=None, solver='lbfgs') #solver necess√°rio para evitar warning
> model_no_reg.fit(X, y)
> beta_no_reg = model_no_reg.coef_[0]
> print("Coeficientes sem regulariza√ß√£o:", beta_no_reg)
>
> # Ajuste do modelo com regulariza√ß√£o L1 (Lasso)
> model_l1 = LogisticRegression(penalty='l1', C=1/0.1, solver='liblinear', random_state=42) # C = 1/lambda
> model_l1.fit(X, y)
> beta_l1 = model_l1.coef_[0]
> print("Coeficientes com regulariza√ß√£o L1:", beta_l1)
>
> # Ajuste do modelo com regulariza√ß√£o L2 (Ridge)
> model_l2 = LogisticRegression(penalty='l2', C=1/0.1, solver='lbfgs', random_state=42) # C = 1/lambda
> model_l2.fit(X, y)
> beta_l2 = model_l2.coef_[0]
> print("Coeficientes com regulariza√ß√£o L2:", beta_l2)
>
>
> # Compara√ß√£o em tabela
> print("\nCompara√ß√£o dos Coeficientes:\n")
> print("| M√©todo      | Beta 1 | Beta 2 |")
> print("|-------------|--------|--------|")
> print(f"| Sem Reg     | {beta_no_reg[0]:.3f}  | {beta_no_reg[1]:.3f}  |")
> print(f"| L1 (Lasso)  | {beta_l1[0]:.3f} | {beta_l1[1]:.3f} |")
> print(f"| L2 (Ridge)  | {beta_l2[0]:.3f} | {beta_l2[1]:.3f} |")
> ```
>
> **Interpreta√ß√£o:** Observe que a regulariza√ß√£o L1 (Lasso) leva um dos coeficientes a 0, indicando que essa vari√°vel pode ser menos importante. J√° a regulariza√ß√£o L2 (Ridge) diminui a magnitude de ambos os coeficientes, sem necessariamente zer√°-los.
>
> **An√°lise da Regulariza√ß√£o:**
>
> A penaliza√ß√£o L1 (Lasso) tende a induzir esparsidade, zerando coeficientes menos importantes, enquanto a penaliza√ß√£o L2 (Ridge) reduz a magnitude de todos os coeficientes, evitando overfitting e mantendo todas as vari√°veis.
>
> ```mermaid
>   graph LR
>       A["Dados de Entrada X, Classes y"] --> B("Regress√£o Log√≠stica");
>       B --> C["Sem Regulariza√ß√£o"];
>       B --> D["Regulariza√ß√£o L1 (Lasso)"];
>       B --> E["Regulariza√ß√£o L2 (Ridge)"];
>       C --> F["Coeficientes Œ≤ sem Regulariza√ß√£o"];
>       D --> G["Coeficientes Œ≤ com Penaliza√ß√£o L1"];
>       E --> H["Coeficientes Œ≤ com Penaliza√ß√£o L2"];
> ```

**Lemma 3:** A penaliza√ß√£o L1 na classifica√ß√£o log√≠stica leva a coeficientes esparsos devido √† sua propriedade de induzir esparsidade. Isso pode ser demonstrado considerando a minimiza√ß√£o da fun√ß√£o de custo com a penaliza√ß√£o L1 [^4.4.4]. Os coeficientes de regress√£o log√≠stica s√£o atualizados iterativamente, usando um m√©todo de otimiza√ß√£o. Ao adicionar a penaliza√ß√£o L1, a fun√ß√£o de custo se torna n√£o diferenci√°vel em $\beta_j = 0$. Na otimiza√ß√£o iterativa, os coeficientes s√£o iterativamente empurrados para zero pela penalidade L1, resultando em um modelo esparso, onde muitas vari√°veis t√™m coeficientes exatamente iguais a zero. Isso ocorre porque o contorno da fun√ß√£o de penaliza√ß√£o L1 tem "quinas" que levam √† esparsidade. $\blacksquare$

**Prova do Lemma 3:** A prova formal envolve a an√°lise das condi√ß√µes de otimalidade da fun√ß√£o de custo com a penaliza√ß√£o L1. Para mostrar que os coeficientes convergem para valores esparsos, considera-se a fun√ß√£o de custo da regress√£o log√≠stica com a penaliza√ß√£o L1 e analisa-se o gradiente da fun√ß√£o, mostrando que este favorece o zeramento dos coeficientes, levando a um modelo esparso. As derivadas da fun√ß√£o de custo com a penaliza√ß√£o L1 incluem um termo que pune a magnitude dos coeficientes, o que leva √† esparsidade [^4.4.3]. $\blacksquare$

**Corol√°rio 3:** Como resultado do Lemma 3, a penaliza√ß√£o L1 n√£o apenas controla a complexidade do modelo de classifica√ß√£o, mas tamb√©m aumenta a sua interpretabilidade [^4.4.5]. Ao remover as vari√°veis menos importantes, a penaliza√ß√£o L1 facilita a identifica√ß√£o das vari√°veis mais relevantes para a classifica√ß√£o, o que pode ajudar a compreender melhor a rela√ß√£o entre as vari√°veis de entrada e as classes. Este resultado pode ser √∫til em tarefas onde √© importante entender quais vari√°veis s√£o os principais preditores, como em diagn√≥sticos m√©dicos ou an√°lise de cr√©dito