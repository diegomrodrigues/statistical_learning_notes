## Linear Methods for Classification: A Deep Dive into Discriminant Analysis, Logistic Regression, and Regularization Techniques
<imagem: Mapa mental abrangente que conecta os subtemas 4.1 a 4.5.2, ilustrando as rela√ß√µes entre LDA, logistic regression e hyperplanes, com destaque para as t√©cnicas de regulariza√ß√£o>

### Introdu√ß√£o

A classifica√ß√£o, uma tarefa fundamental no aprendizado de m√°quina, envolve a atribui√ß√£o de dados a categorias predefinidas. Modelos lineares, apesar de sua simplicidade, oferecem solu√ß√µes robustas e interpret√°veis para este problema, especialmente quando usados em conjunto com t√©cnicas de regulariza√ß√£o e sele√ß√£o de vari√°veis. Este cap√≠tulo explora as bases te√≥ricas e matem√°ticas desses modelos, desde a **regress√£o linear de matrizes de indicadores** at√© a **an√°lise discriminante linear (LDA)**, passando pela **regress√£o log√≠stica** e m√©todos de **sele√ß√£o de vari√°veis e regulariza√ß√£o**, culminando com uma an√°lise dos **hiperplanos separadores** [^4.1].

### Conceitos Fundamentais

**Conceito 1:** O problema de classifica√ß√£o, em sua ess√™ncia, busca encontrar uma fun√ß√£o $f(x)$ que mapeie um vetor de entrada $x$ para uma classe $y$. Em m√©todos lineares, essa fun√ß√£o assume a forma $f(x) = w^T x + b$, onde $w$ s√£o os pesos do modelo e $b$ √© o bias. A escolha de modelos lineares pode ser justificada pela sua interpretabilidade e efici√™ncia computacional [^4.1]. No entanto, √© importante notar que modelos lineares podem introduzir vi√©s, especialmente se a verdadeira rela√ß√£o entre as entradas e as classes n√£o for linear, embora a vari√¢ncia, em geral, seja baixa, especialmente quando combinado com t√©cnicas de regulariza√ß√£o [^4.2]. Por exemplo, em um problema de classifica√ß√£o bin√°ria, a sa√≠da $f(x)$ pode ser interpretada como a pontua√ß√£o que determina a qual classe um dado $x$ pertence. Quanto maior o valor de $f(x)$, maior a probabilidade de $x$ pertencer a uma classe espec√≠fica.

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o bin√°ria com duas features, $x_1$ e $x_2$. Um modelo linear pode ser expresso como $f(x) = w_1x_1 + w_2x_2 + b$. Suponha que, ap√≥s treinamento, os pesos encontrados sejam $w_1 = 0.5$, $w_2 = -0.3$ e $b = 1$. Para um ponto de dados $x = [2, 3]$, temos $f(x) = 0.5 * 2 + (-0.3) * 3 + 1 = 1 - 0.9 + 1 = 1.1$. Se a regra de decis√£o for classificar como classe 1 se $f(x) > 0$, ent√£o este ponto seria classificado na classe 1.

**Lemma 1:** Em um problema de classifica√ß√£o bin√°ria com classes $\mathcal{C}_1$ e $\mathcal{C}_2$, uma fun√ß√£o discriminante linear pode ser expressa como $g(x) = w^T x + b$. Se definirmos uma matriz de indicadores $Y$ tal que $Y_{ij} = 1$ se a amostra $i$ pertence √† classe $j$ e $0$ caso contr√°rio, e aplicarmos regress√£o linear sobre esta matriz, podemos encontrar os coeficientes $w$ e $b$ que definem um hiperplano de decis√£o linear [^4.2]. Esse hiperplano, dado por $g(x)=0$, separa as classes no espa√ßo de entrada, e sua forma √© determinada pelos coeficientes da regress√£o linear. Isso significa que, sob certas condi√ß√µes, uma simples regress√£o linear em uma matriz de indicadores pode levar a uma solu√ß√£o de classifica√ß√£o linear.
```mermaid
graph LR
    subgraph "Linear Discriminant Function"
        direction TB
        A["Discriminant Function: g(x) = w^T x + b"]
        B["Input Vector: x"]
        C["Weight Vector: w"]
        D["Bias: b"]
        A --> B
        A --> C
        A --> D
    end
```
  **Prova:** Seja $X$ a matriz de dados, com cada linha representando uma amostra, e $Y$ a matriz de indicadores. A regress√£o linear busca minimizar $||Y - XW||^2$, onde $W$ √© a matriz de pesos. As colunas de $W$ correspondem aos pesos para cada classe. A fronteira de decis√£o para classifica√ß√£o bin√°ria √© dada por $w^T x + b = 0$. Os par√¢metros $w$ e $b$ s√£o obtidos minimizando o erro quadr√°tico m√©dio, levando √† mesma estrutura de separa√ß√£o linear obtida por uma fun√ß√£o discriminante linear. $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere um dataset com duas amostras e duas classes.
>
>  $X = \begin{bmatrix} 1 & 2 \\ 2 & 1 \end{bmatrix}$ (cada linha √© uma amostra, a primeira coluna √© para o bias e a segunda a feature $x_1$)
>
>  $Y = \begin{bmatrix} 1 \\ 0 \end{bmatrix}$ (a primeira amostra pertence √† classe 1, a segunda √† classe 0).
>
> Aplicamos regress√£o linear para encontrar $w$:
>
> $\text{Step 1: } W = (X^TX)^{-1}X^TY$
>
> $X^T = \begin{bmatrix} 1 & 2 \\ 2 & 1 \end{bmatrix}$
>
> $X^TX = \begin{bmatrix} 1 & 2 \\ 2 & 1 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 2 & 1 \end{bmatrix} = \begin{bmatrix} 5 & 4 \\ 4 & 5 \end{bmatrix}$
>
> $(X^TX)^{-1} = \frac{1}{9}\begin{bmatrix} 5 & -4 \\ -4 & 5 \end{bmatrix}$
>
> $X^TY = \begin{bmatrix} 1 & 2 \\ 2 & 1 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} = \begin{bmatrix} 1 \\ 2 \end{bmatrix}$
>
> $W = \frac{1}{9}\begin{bmatrix} 5 & -4 \\ -4 & 5 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} = \frac{1}{9}\begin{bmatrix} -3 \\ 6 \end{bmatrix} = \begin{bmatrix} -1/3 \\ 2/3 \end{bmatrix}$
>
> Assim, o modelo linear seria: $f(x) = -\frac{1}{3} + \frac{2}{3}x_1$. Se um novo ponto $x_1=1$ √© avaliado $f(x) = -\frac{1}{3} + \frac{2}{3} = \frac{1}{3}$. Classificamos este ponto como pertencente √† classe 1 se $f(x) > 0.5$.
>
> Este exemplo demonstra como uma regress√£o linear na matriz de indicadores pode ser utilizada para classifica√ß√£o bin√°ria.

**Conceito 2:** A **Linear Discriminant Analysis (LDA)**, uma t√©cnica cl√°ssica de classifica√ß√£o, assume que cada classe possui uma distribui√ß√£o gaussiana com a mesma matriz de covari√¢ncia [^4.3]. A LDA deriva a fronteira de decis√£o maximizando a separa√ß√£o entre as classes, projetando os dados em um subespa√ßo de dimens√£o inferior. A fun√ß√£o discriminante linear da LDA √© dada por $g_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + log(\pi_k)$, onde $\mu_k$ √© o vetor de m√©dias da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia compartilhada, e $\pi_k$ √© a probabilidade a priori da classe $k$. A LDA √© √≥tima quando as suposi√ß√µes de normalidade e igualdade de covari√¢ncia s√£o v√°lidas [^4.3.1], mas pode ter um desempenho sub-√≥timo quando estas suposi√ß√µes s√£o violadas [^4.3.2]. A LDA, como outros m√©todos lineares, se beneficia da sua efici√™ncia computacional e facilidade de interpreta√ß√£o [^4.3.3].
```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction TB
        A["Discriminant Function: g_k(x)"]
        B["Term 1: x^T Œ£‚Åª¬π Œº_k"]
        C["Term 2: -1/2 Œº_k^T Œ£‚Åª¬π Œº_k"]
        D["Term 3: log(œÄ_k)"]
        A --> B
        A --> C
        A --> D
    end
    subgraph "Parameters"
        direction LR
        E["x: Input Vector"]
        F["Œº_k: Mean Vector of class k"]
        G["Œ£: Shared Covariance Matrix"]
        H["œÄ_k: Prior Probability of class k"]
     end
     B --> E
     B --> F
     B --> G
     C --> F
     C --> G
     D --> H
```

> üí° **Exemplo Num√©rico:** Suponha que temos duas classes com as seguintes m√©dias e covari√¢ncia compartilhada:
>
> $\mu_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$, $\mu_2 = \begin{bmatrix} 3 \\ 2 \end{bmatrix}$, $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
>
> A probabilidade a priori √© $\pi_1 = \pi_2 = 0.5$. Para classificar um novo ponto $x = \begin{bmatrix} 2 \\ 1.5 \end{bmatrix}$, calculamos as fun√ß√µes discriminantes:
>
> $\text{Step 1: } \Sigma^{-1} = \frac{1}{0.75}\begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$
>
> $\text{Step 2: } g_1(x) = x^T \Sigma^{-1} \mu_1 - \frac{1}{2} \mu_1^T \Sigma^{-1} \mu_1 + log(\pi_1)$
>
> $g_1(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} + \log(0.5)$
>
> $g_1(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 0.66 \\ 0.66 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 0.66 \\ 0.66 \end{bmatrix} + \log(0.5)$
>
> $g_1(x) = 1.32 + 0.99 - \frac{1}{2}(1.32) + \log(0.5) = 2.31 - 0.66 - 0.69 = 0.96$
>
> $\text{Step 3: } g_2(x) = x^T \Sigma^{-1} \mu_2 - \frac{1}{2} \mu_2^T \Sigma^{-1} \mu_2 + log(\pi_2)$
>
> $g_2(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 2 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 2 \end{bmatrix} + \log(0.5)$
>
> $g_2(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 2.66 \\ 0.66 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 2 \end{bmatrix} \begin{bmatrix} 2.66 \\ 0.66 \end{bmatrix} + \log(0.5)$
>
> $g_2(x) = 5.32 + 0.99 - \frac{1}{2}(7.98 + 1.32) + \log(0.5) = 6.31 - 4.65 - 0.69 = 0.97$
>
> Como $g_2(x) > g_1(x)$, o ponto √© classificado na classe 2.

**Corol√°rio 1:** A fun√ß√£o discriminante linear da LDA, $g_k(x)$, pode ser reescrita como $g_k(x) = w_k^T x + b_k$, onde $w_k = \Sigma^{-1} \mu_k$ e $b_k = - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + log(\pi_k)$ [^4.3.1]. Isso demonstra explicitamente a natureza linear da fronteira de decis√£o gerada pela LDA. Este corol√°rio refor√ßa que a LDA, apesar de usar conceitos probabil√≠sticos para construir a fun√ß√£o discriminante, resulta em um classificador linear [^4.3]. Al√©m disso, √© poss√≠vel observar a rela√ß√£o entre a proje√ß√£o feita pela LDA em um subespa√ßo de menor dimens√£o e os pesos $w_k$, que direcionam essa proje√ß√£o para maximizar a separa√ß√£o entre as classes.

**Conceito 3:** A **regress√£o log√≠stica** modela a probabilidade de uma amostra pertencer a uma classe usando uma fun√ß√£o sigmoide aplicada a uma combina√ß√£o linear das entradas [^4.4]. O *logit* ou *log-odds* √© definido como $log(\frac{p(x)}{1-p(x)}) = w^T x + b$, onde $p(x)$ √© a probabilidade da classe 1. A fun√ß√£o sigmoide transforma esta combina√ß√£o linear para uma probabilidade entre 0 e 1 [^4.4.1]. Os par√¢metros $w$ e $b$ s√£o estimados maximizando a verossimilhan√ßa dos dados [^4.4.3], e a fronteira de decis√£o √© dada por $w^T x + b = 0$. A regress√£o log√≠stica n√£o assume normalidade nas entradas, e por isso, √© mais flex√≠vel do que a LDA, embora ambas produzam fronteiras de decis√£o lineares [^4.4.4]. A regress√£o log√≠stica √© particularmente √∫til para problemas de classifica√ß√£o com classes n√£o-balanceadas [^4.4.2] e oferece uma maneira natural de obter probabilidades de classe [^4.4.5].
```mermaid
graph LR
 subgraph "Logistic Regression Model"
  direction TB
  A["Input x"] --> B{"Linear Combination: w^T x + b"}
  B --> C["Sigmoid Function: œÉ(w^T x + b)"]
  C --> D["Probability: p(x)"]
  C --> E["Class Prediction"]
 end
 subgraph "Sigmoid Function"
  direction LR
  F["z = w^T x + b"] --> G["œÉ(z) = 1 / (1 + exp(-z))"]
  G --> H["Output: Probability (0 to 1)"]
 end
 D --> E
```

> üí° **Exemplo Num√©rico:** Considere que, ap√≥s treinamento de uma regress√£o log√≠stica com uma √∫nica feature, $x$, os par√¢metros sejam $w=2$ e $b=-1$. A probabilidade de um ponto $x$ pertencer √† classe 1 √© dada por $p(x) = \frac{1}{1 + e^{-(2x-1)}}$. Se $x=1$, ent√£o $p(1) = \frac{1}{1+e^{-1}} \approx 0.73$. Se $x=0$, ent√£o $p(0) = \frac{1}{1+e^{1}} \approx 0.27$. A fronteira de decis√£o, $w^Tx+b=0$ √© atingida em $x=0.5$, onde $p(0.5) = 0.5$.
>
> ```mermaid
>   graph LR
>      A[x=0] -->|p(0)=0.27| B(Classe 0)
>      C[x=1] -->|p(1)=0.73| D(Classe 1)
>      E[x=0.5] -->|p(0.5)=0.5| F(Fronteira)
> ```

> ‚ö†Ô∏è **Nota Importante**: A regress√£o log√≠stica usa a fun√ß√£o sigmoide para garantir que a sa√≠da esteja entre 0 e 1, representando probabilidades de classe. **Refer√™ncia ao t√≥pico [^4.4.1]**.

> ‚ùó **Ponto de Aten√ß√£o**: Em casos de classes n√£o-balanceadas, a regress√£o log√≠stica permite ajustar os pesos para compensar o desequil√≠brio, o que n√£o acontece diretamente na LDA. **Conforme indicado em [^4.4.2]**.

> ‚úîÔ∏è **Destaque**: Embora a formula√ß√£o seja diferente, as estimativas dos par√¢metros $w$ nas duas t√©cnicas tendem a ser similares, principalmente quando as classes s√£o bem separadas e as premissas da LDA s√£o respeitadas. **Baseado no t√≥pico [^4.5]**.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
<imagem: Diagrama de fluxo mostrando o processo de regress√£o de indicadores: Codifica√ß√£o das classes, estima√ß√£o de coeficientes via m√≠nimos quadrados, aplica√ß√£o da regra de decis√£o e compara√ß√£o com m√©todos probabil√≠sticos>

A regress√£o linear, quando aplicada diretamente a uma matriz de indicadores, pode ser utilizada para classifica√ß√£o [^4.2]. A ideia √© codificar cada classe com um vetor indicador (por exemplo, 1 para a classe pertencente e 0 para as outras), e usar regress√£o linear para prever esses indicadores. A classe atribu√≠da a uma amostra √© ent√£o dada pelo √≠ndice do indicador com maior valor previsto. Formalmente, seja $Y$ a matriz de indicadores (N x K), onde N √© o n√∫mero de amostras e K o n√∫mero de classes. A regress√£o linear busca minimizar $||Y - XW||^2$, onde $X$ √© a matriz de dados (N x (p+1)) e $W$ √© a matriz de pesos ((p+1) x K). As predi√ß√µes s√£o dadas por $\hat{Y} = XW$ e a classe predita para a amostra $i$ √© dada por $argmax_k \hat{Y}_{ik}$.

A regress√£o de indicadores √©, no entanto, limitada. Em particular, as predi√ß√µes podem n√£o ser bem calibradas em termos de probabilidades, podendo ter valores fora do intervalo [0, 1]. Al√©m disso, pode apresentar problemas quando a rela√ß√£o entre os atributos e as classes n√£o √© bem aproximada por fun√ß√µes lineares [^4.1]. M√©todos probabil√≠sticos como a regress√£o log√≠stica geralmente fornecem estimativas de probabilidade mais est√°veis [^4.4].

**Lemma 2:** Em um problema de classifica√ß√£o bin√°ria, a regress√£o linear em uma matriz de indicadores com apenas duas classes √© equivalente a uma fun√ß√£o discriminante linear, quando a fun√ß√£o de decis√£o √© dada por um limiar em 0.5, mesmo quando a matriz de indicadores n√£o possui posto completo [^4.2].
```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction TB
        A["Indicator Matrix: Y (N x K)"]
        B["Data Matrix: X (N x (p+1))"]
        C["Weight Matrix: W ((p+1) x K)"]
        D["Prediction: YÃÇ = XW"]
        E["Class Prediction: argmax_k(YÃÇ_ik)"]
        A & B & C --> D
        D --> E
    end
```
**Prova:** Seja $Y$ a matriz de indicadores para um problema de classifica√ß√£o bin√°ria, onde $y_i \in \{0, 1\}$. Se a previs√£o da regress√£o linear para uma dada observa√ß√£o $x_i$ √© dada por $\hat{y}_i = w^T x_i + b$, a regra de decis√£o √© que $x_i$ pertence √† classe 1 se $\hat{y}_i \ge 0.5$, e √† classe 0 caso contr√°rio. Essa regra √© equivalente a $\hat{y}_i - 0.5 \ge 0$ que tamb√©m pode ser escrita como um hiperplano de separa√ß√£o linear: $(w^T x_i + b - 0.5) \ge 0$. Logo, a regress√£o de indicadores gera uma fronteira de decis√£o linear, assim como a fun√ß√£o discriminante linear. $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere o mesmo dataset anterior, com $X = \begin{bmatrix} 1 & 2 \\ 2 & 1 \end{bmatrix}$ e $Y = \begin{bmatrix} 1 \\ 0 \end{bmatrix}$. O resultado da regress√£o linear √© $W = \begin{bmatrix} -1/3 \\ 2/3 \end{bmatrix}$. Para classificar um novo ponto $x = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$,  calculamos $\hat{y} =  -\frac{1}{3} + \frac{2}{3} * 1 = \frac{1}{3}$. Como $\hat{y} < 0.5$, o ponto √© classificado como classe 0. Se o ponto fosse $x=\begin{bmatrix} 1 \\ 2 \end{bmatrix}$, ent√£o $\hat{y} = -\frac{1}{3} + \frac{2}{3} * 2 = 1$, sendo classificado na classe 1.
>
> Note que este exemplo gera as mesmas conclus√µes do Exemplo Num√©rico do Lema 1, confirmando a equival√™ncia entre regress√£o de indicadores e fun√ß√£o discriminante linear em classifica√ß√£o bin√°ria, quando aplicada a regra de decis√£o apropriada.

**Corol√°rio 2:** A equival√™ncia entre as proje√ß√µes nos hiperplanos de decis√£o gerados por regress√£o linear e discriminantes lineares implica que, sob condi√ß√µes ideais (classes bem separadas e sem multicolinearidade), os m√©todos podem levar a resultados semelhantes, contudo, a regress√£o de indicadores, por n√£o possuir a natureza probabil√≠stica da LDA e da regress√£o log√≠stica, n√£o √© a mais adequada para a estima√ß√£o de probabilidades de classe, podendo gerar resultados fora do intervalo [0,1] [^4.3].

"Em alguns cen√°rios, conforme apontado em [^4.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1]."

"No entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^4.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear."

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem: Mapa mental conectando m√©todos de sele√ß√£o e regulariza√ß√£o em classifica√ß√£o, mostrando sua rela√ß√£o com LDA, logistic regression e hyperplanes>

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas essenciais para lidar com overfitting e multicolinearidade em modelos de classifica√ß√£o. A regulariza√ß√£o, em particular, adiciona uma penalidade √† fun√ß√£o de custo, for√ßando o modelo a ter pesos menores e, consequentemente, a evitar solu√ß√µes complexas que se ajustam ao ru√≠do dos dados.

Em modelos log√≠sticos, por exemplo, a fun√ß√£o de custo da regress√£o log√≠stica pode ser regularizada com penalidades L1 (lasso), L2 (ridge) ou uma combina√ß√£o de ambas (Elastic Net) [^4.5]. A penalidade L1, dada por $\lambda \sum_{j=1}^p |w_j|$, promove a esparsidade, for√ßando alguns pesos a serem exatamente zero [^4.4.4], e realizando a sele√ß√£o de vari√°veis. A penalidade L2, dada por $\lambda \sum_{j=1}^p w_j^2$, encolhe os pesos em dire√ß√£o a zero, reduzindo a vari√¢ncia [^4.5].
```mermaid
graph LR
 subgraph "Regularization Techniques"
  direction TB
  A["Cost Function (Logistic Regression)"]
  B["L1 Regularization: Œª Œ£|w_j|"]
  C["L2 Regularization: Œª Œ£w_j¬≤"]
  D["Elastic Net Regularization"]
  A --> B
  A --> C
  B & C --> D
 end
  subgraph "L1 Regularization"
    direction LR
   E["Penalty Term: Œª Œ£|w_j|"] --> F["Sparse Coefficients"]
    F--> G["Variable Selection"]
  end
  subgraph "L2 Regularization"
    direction LR
    H["Penalty Term: Œª Œ£w_j¬≤"] --> I["Shrinks Coefficients"]
        I--> J["Reduced Variance"]
 end
```

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo de regress√£o log√≠stica com dois preditores ($x_1$ e $x_2$). Sem regulariza√ß√£o, os pesos podem ser $w_1=3$ e $w_2=-2$. Com regulariza√ß√£o L1 e $\lambda=0.5$, a fun√ß√£o de custo a ser minimizada √© modificada: $-\text{loglikelihood} + 0.5(|w_1| + |w_2|)$. Ap√≥s re-treinamento, os pesos podem ter sido ajustados para $w_1=1.5$ e $w_2=0$ (ou um valor muito pr√≥ximo de zero), indicando que o preditor $x_2$ foi exclu√≠do do modelo. A regulariza√ß√£o L2, com $\lambda=0.5$, poderia ter levado a $w_1=2.2$ e $w_2=-1.5$, valores menores do que os iniciais, mas sem zerar nenhum dos pesos.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.datasets import make_classification
>
> # Generate synthetic data
> X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)
>
> # Train logistic regression without regularization
> model_no_reg = LogisticRegression(penalty=None)
> model_no_reg.fit(X, y)
> w_no_reg = model_no_reg.coef_[0]
>
> # Train logistic regression with L1 regularization
> model_l1 = LogisticRegression(penalty='l1', C=0.5, solver='liblinear')
> model_l1.fit(X, y)
> w_l1 = model_l1.coef_[0]
>
> # Train logistic regression with L2 regularization
> model_l2 = LogisticRegression(penalty='l2', C=0.5)
> model_l2.fit(X, y)
> w_l2 = model_l2.coef_[0]
>
> print(f"Weights without regularization: {w_no_reg}")
> print(f"Weights with L1 regularization: {w_l1}")
> print(f"Weights with L2 regularization: {w_l2}")
> ```
>
> Este exemplo demonstra como L1 tende a zerar alguns coeficientes, enquanto L2 reduz sua magnitude. O valor de C (inverso de lambda) afeta a for√ßa da regulariza√ß√£o.

**Lemma 3:** A penaliza√ß√£o L1 em classifica√ß√£o log√≠stica leva a coeficientes esparsos.

**Prova:** A fun√ß√£o de custo da regress√£o log√≠stica com penalidade L1 √© dada por:
$$ J(w) = -\sum_{i=1}^N [y_i \log(p(x_i)) + (1-y_i) \log(1 - p(x_i))] + \lambda \sum_{j=1}^p |w_j| $$
onde $p(x_i)$ √© a probabilidade da classe 1 para a amostra $x_i$. O termo de penaliza√ß√£o $\lambda \sum_{j=1}^p |w_j|$ √© n√£o diferenci√°vel em $w_j = 0$, e induz esparsidade ao for√ßar alguns coeficientes a serem exatamente zero. A otimiza√ß√£o de uma fun√ß√£o de custo com esta penalidade geralmente leva a solu√ß√µes esparsas onde alguns dos par√¢metros s√£o zero, indicando que algumas vari√°veis n√£o t√™m relev√¢ncia para a classifica√ß√£o. Este efeito √© devido ao fato de que a norma L1 imp√µe uma penalidade constante sobre cada coeficiente, independentemente de sua magnitude, diferente da penalidade L2 que imp√µe uma penalidade quadr√°tica. Este comportamento √© an√°logo ao que acontece no modelo linear de regress√£o com penalidade L1 [^4.4.4]. $\blacksquare$

**Corol√°rio 3:** A esparsidade induzida pela penaliza√ß√£o L1 aumenta a interpretabilidade dos modelos classificat√≥rios, pois ela efetivamente realiza a sele√ß√£o de vari√°veis, indicando quais atributos s√£o mais importantes para a classifica√ß√£o. Al√©m disso, o n√∫mero reduzido de vari√°veis no modelo esparso reduz a complexidade computacional e, em alguns casos, tamb√©m melhora a sua generaliza√ß√£o [^4.4.5].
```mermaid
graph LR
    subgraph "Impact of L1 Regularization"
        direction TB
        A["L1 Penalty Term: Œª Œ£|w_j|"]
        B["Induces Sparsity in Coefficients"]
        C["Variable Selection"]
        D["Increased Model Interpretability"]
        E["Reduced Computational Complexity"]
         F["Improved Generalization"]
        A --> B
        B --> C
         C --> D
        C --> E
         C --> F
    end
```

> ‚ö†Ô∏è **Ponto Crucial**: L1 e L2 podem ser combinadas (Elastic Net) para aproveitar vantagens de ambos os tipos de regulariza√ß√£o, proporcionando flexibilidade no ajuste do modelo, controlando tanto a esparsidade quanto a estabilidade dos par√¢metros. **Conforme discutido em [^4.5]**.

### Separating Hyperplanes e Perceptrons

A ideia de **hiperplanos separadores** (separating hyperplanes) surge da necessidade de encontrar uma fronteira linear √≥tima que divide as classes em um problema de classifica√ß√£o. Em um cen√°rio com dados linearmente separ√°veis, existem infinitos hiperplanos que podem realizar esta tarefa. O objetivo √© encontrar um hiperplano que maximize a margem de separa√ß√£o entre as classes [^4.5.2]. A margem √© definida como a dist√¢ncia m√≠nima entre o hiperplano e os pontos de dados mais pr√≥ximos, conhecidos como vetores de suporte.
```mermaid
graph LR
 subgraph "Separating Hyperplanes"
  direction TB
  A["Data points"]
  B["Separating Hyperplane"]
  C["Margin of Separation"]
  D["Support Vectors"]
  A --> B
  B --> C
  C --> D
 end
```
O **Perceptron** de Rosenblatt √© um algoritmo cl√°ssico que busca encontrar uma fronteira linear para separar dados linearmente separ√°veis [^4.5.1]. Ele itera sobre os dados, ajustando os pesos do hiperplano de forma a classificar corretamente as amostras. Em casos de dados linearmente separ√°veis, o Perceptron garante encontrar um hiperplano separador em um n√∫mero finito de itera√ß√µes. A fronteira resultante, no entanto, n√£o √© necessariamente a de maior margem.

O problema de encontrar o hiperplano com maior margem pode ser formulado como um problema de otimiza√ß√£o convexa, onde o objetivo √© maximizar a margem (equivalente a minimizar a norma dos pesos) sujeito a restri√ß√µes de que todas as amostras estejam corretamente classificadas. A solu√ß√£o deste problema geralmente envolve a resolu√ß√£o do seu dual (de Wolfe), o qual permite encontrar uma solu√ß√£o como uma combina√ß√£o linear dos pontos de suporte [^4.5.2].

### Pergunta Te√≥rica Avan√ßada (Exemplo): Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**

A LDA e a Regra de Decis√£o Bayesiana s√£o abordagens distintas para a classifica√ß√£o, mas sob certas suposi√ß√µes, tornam-se equivalentes, especialmente quando consideramos distribui√ß√µes Gaussianas com covari√¢ncias iguais.

A **Regra de Decis√£o Bayesiana** busca classificar uma amostra $x$ na classe $k$ que maximiza a probabilidade a posteriori $P(C_k | x)$, dada por:

$$P(C_k | x) = \frac{P(x | C_k) P(C_k)}{P(x)}$$

onde:
*   $P(C_k)$ √© a probabilidade a priori da classe $k$;
*   $P(x|C_k)$ √© a densidade de probabilidade de observar $x$ dado que pertence √† classe $k$.

Assumindo que $P(x|C_k)$ segue uma distribui√ß√£o gaussiana com m√©dia $\mu_k$ e matriz de covari√¢ncia $\Sigma$, temos:

$$P(x|C_k) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}} \exp\left(-\frac{1}{2}(x-\mu_k)^T \Sigma^{-1} (x-\mu_k)\right)$$

Ao calcular o logaritmo da probabilidade a posteriori e remover termos constantes, a regra de decis√£o se resume a:

$$\delta_k(x) = -\frac{1}{2}(x-\mu_k)^T \Sigma^{-1} (x-\mu_k) + \log(\pi_k)$$

Por outro lado, a **LDA** assume que todas as classes t√™m a mesma matriz de covari√¢ncia $\Sigma$ e busca o discriminante linear:

$$g_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log(\pi_k)$$

Ao comparar as express√µes, notamos que a Regra de Decis√£o Bayesiana e a LDA tornam-se equivalentes quando a matriz de covari√¢ncia $\Sigma$ √© compartilhada entre as classes. A fun√ß√£o discriminante $\delta_k(x)$ na regra Bayesiana, ao se expandir o termo quadr√°tico, tem um termo que se cancela (devido √† covari√¢ncia igual) restando um termo linear em $x$, assim como a fun√ß√£o $g_k(x)$ da LDA [^4.3]. Portanto, ambos os m√©todos, quando aplicados a distribui√ß√µes Gaussianas com mesma covari√¢ncia, levam √† mesma fronteira de decis√£o linear.
```mermaid
graph LR
    subgraph "Comparison of LDA and Bayesian Decision Rule"
        direction TB
        A["Bayesian Decision Rule: Œ¥_k(x)"]
        B["LDA Discriminant: g_k(x)"]
        C["Shared Covariance (Œ£)"]
        A -->|Gaussian Assumption| D
        B --> |Linear Assumption| E
        D -- "Reduces to Linear Term" -->