## Ridge Regression: Penalized Least Squares and Shrinkage
<imagem: Um diagrama ilustrando como a Ridge Regression adiciona um termo de penalidade √† fun√ß√£o de custo do m√©todo de m√≠nimos quadrados, com setas indicando a dire√ß√£o em que os coeficientes s√£o encolhidos em dire√ß√£o a zero.>
### Introdu√ß√£o
Este cap√≠tulo foca em **m√©todos lineares para regress√£o**, um tema fundamental em modelagem estat√≠stica e aprendizado de m√°quina. A regress√£o linear assume que a fun√ß√£o de regress√£o E(Y|X) √© linear nas entradas $X_1, \ldots, X_p$. Embora desenvolvidos na era pr√©-computacional da estat√≠stica, esses modelos permanecem relevantes devido √† sua simplicidade, interpretabilidade e desempenho adequado em diversas situa√ß√µes, especialmente quando o n√∫mero de casos de treinamento √© pequeno, a rela√ß√£o sinal-ru√≠do √© baixa ou quando h√° dados esparsos [^4.1].  Esses m√©todos lineares podem ser aplicados a transforma√ß√µes das entradas, o que expande seu escopo, dando origem aos m√©todos de fun√ß√µes de base, abordados no Cap√≠tulo 5. Embora o Cap√≠tulo 3 foque em regress√£o, o Cap√≠tulo 4 abordar√° os m√©todos lineares para classifica√ß√£o. O entendimento profundo de modelos lineares √© crucial para compreender modelos n√£o lineares, que frequentemente s√£o generaliza√ß√µes diretas dos lineares [^4.1].
### Conceitos Fundamentais

**Conceito 1: O Problema de Classifica√ß√£o e Modelos Lineares**

O problema de classifica√ß√£o busca atribuir uma observa√ß√£o a uma ou mais classes predefinidas, com base em um conjunto de *features* (vari√°veis preditoras). M√©todos lineares s√£o frequentemente utilizados em classifica√ß√£o devido √† sua simplicidade e interpretabilidade.  Em um modelo linear para regress√£o, assume-se que a fun√ß√£o de regress√£o E(Y|X) √© linear nas entradas $X_1,..., X_p$. Matematicamente, isso pode ser expresso como $f(x) = \beta_0 + \sum_{j=1}^p X_j \beta_j$, onde $\beta_j$ s√£o os coeficientes ou par√¢metros desconhecidos [^4.2]. O problema de classifica√ß√£o pode ser encarado como um problema de regress√£o em que a sa√≠da (vari√°vel dependente) assume valores discretos que representam as diferentes classes.  Ao utilizar m√©todos lineares para classifica√ß√£o, √© comum usar um *threshold* para transformar a sa√≠da cont√≠nua em uma decis√£o de classe. Essa abordagem introduz *vi√©s* (bias), uma vez que o modelo pode estar restringido a uma forma funcional inadequada para os dados. Em contrapartida, a simplicidade e a interpretabilidade do modelo linear resultam em menor *vari√¢ncia*, o que significa que as estimativas dos par√¢metros s√£o relativamente est√°veis e pouco sens√≠veis a pequenas altera√ß√µes nos dados de treinamento [^4.1]. No entanto, a baixa vari√¢ncia pode n√£o ser desej√°vel se a forma funcional for demasiadamente restritiva, como no caso de dados n√£o linearmente separ√°veis.
```mermaid
graph TB
    subgraph "Linear Model Trade-off"
        direction TB
        A["Linear Model"] --> B["Simplicity and Interpretability"]
        A --> C["Potential for Bias"]
        B --> D["Low Variance"]
        C --> E["Restriction on Functional Form"]
    end
```
> üí° **Exemplo Num√©rico:** Imagine um problema de classifica√ß√£o bin√°ria com duas features, $X_1$ e $X_2$, onde a classe 1 √© representada por $y=1$ e a classe 0 por $y=0$. Um modelo linear pode ser expresso como $f(x) = \beta_0 + \beta_1 X_1 + \beta_2 X_2$. Se $\beta_0 = -1$, $\beta_1 = 2$, e $\beta_2 = 1$, ent√£o a observa√ß√£o $x = [1, 1]$ ter√° uma pontua√ß√£o de $f(x) = -1 + 2(1) + 1(1) = 2$.  Usando um threshold de 0, a observa√ß√£o ser√° classificada como classe 1, pois $f(x) > 0$. J√° a observa√ß√£o $x = [0, 0]$ ter√° $f(x) = -1$, sendo classificada como classe 0. Este modelo simples ilustra o vi√©s introduzido por uma decis√£o linear. Se a verdadeira rela√ß√£o fosse n√£o linear, o modelo apresentaria baixa vari√¢ncia mas alto vi√©s, ou seja, seria consistente mas impreciso.

**Lemma 1:** *Em um problema de classifica√ß√£o com duas classes, a fun√ß√£o discriminante linear pode ser decomposta em uma fun√ß√£o que projeta as observa√ß√µes em um vetor normal ao hiperplano de separa√ß√£o e um valor de limiar.*

**Prova do Lemma 1:** Considere uma fun√ß√£o discriminante linear $f(x) = \beta_0 + \sum_{j=1}^p X_j \beta_j$. A fronteira de decis√£o √© definida por $f(x) = 0$. Podemos expressar $f(x)$ como um produto escalar entre um vetor de par√¢metros $\beta$ e um vetor de *features* aumentado $x$, isto √©, $f(x) = \beta^T x$, onde $x=[1,X_1, \ldots, X_p]^T$ e $\beta = [\beta_0, \beta_1, \ldots, \beta_p]^T$. A dire√ß√£o do vetor $\beta$ √© normal ao hiperplano $f(x) = 0$.  A decis√£o de classe √© dada por:
$$
    \begin{cases}
      \text{classe 1} & \text{se } f(x) \geq 0 \\
      \text{classe 0} & \text{se } f(x) < 0
    \end{cases}
$$
Onde $f(x)$ pode ser reescrito como:

$f(x) = \beta^T x = ||\beta|| \cdot ||x|| \cdot \cos(\theta)$.

Onde $\theta$ √© o √¢ngulo entre o vetor $\beta$ e o vetor $x$. Assim, a decis√£o depende da proje√ß√£o de $x$ em $\beta$  e de um valor de limiar $\beta_0$.
$\blacksquare$
```mermaid
graph TB
    subgraph "Linear Discriminant Decomposition"
        direction TB
        A["Discriminant Function: f(x) = Œ≤·µÄx"]
        B["Projection: ||Œ≤|| ||x|| cos(Œ∏)"]
        C["Decision Threshold: Œ≤‚ÇÄ"]
        A --> B
        A --> C
    end
```
**Conceito 2: Linear Discriminant Analysis (LDA)**

A **Linear Discriminant Analysis (LDA)** √© um m√©todo para classifica√ß√£o linear que busca encontrar a melhor proje√ß√£o dos dados de alta dimens√£o em um subespa√ßo de dimens√£o reduzida, maximizando a separa√ß√£o entre as classes e minimizando a vari√¢ncia dentro de cada classe [^4.3]. O LDA assume que os dados de cada classe s√£o normalmente distribu√≠dos com a mesma matriz de covari√¢ncia. O LDA estima a m√©dia e a matriz de covari√¢ncia para cada classe, e ent√£o encontra uma fun√ß√£o discriminante linear que maximiza a separa√ß√£o entre as classes, baseada na raz√£o entre a vari√¢ncia inter-classes e a vari√¢ncia intra-classes [^4.3.1]. A fun√ß√£o discriminante do LDA √© da forma:
$$ \delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T \Sigma^{-1}\mu_k + \log \pi_k $$
onde $\mu_k$ √© o vetor de m√©dias da classe k, $\Sigma$ √© a matriz de covari√¢ncia comum, e $\pi_k$ √© a probabilidade *a priori* da classe k [^4.3.2].  A fronteira de decis√£o entre duas classes √© linear e obtida atrav√©s da igualdade das fun√ß√µes discriminantes:  $\delta_i(x) = \delta_j(x)$. No entanto, o LDA pode apresentar limita√ß√µes quando as classes n√£o s√£o bem separadas ou quando as suposi√ß√µes de normalidade e covari√¢ncias iguais n√£o s√£o v√°lidas [^4.3.3].
```mermaid
graph LR
    subgraph "LDA Discriminant Function"
      direction LR
        A["Œ¥‚Çñ(x)"] --> B["Projection Term: x·µÄŒ£‚Åª¬πŒº‚Çñ"]
        A --> C["Bias Term: -1/2 Œº‚Çñ·µÄŒ£‚Åª¬πŒº‚Çñ"]
        A --> D["Prior Term: log(œÄ‚Çñ)"]
    end
```
> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com duas classes, com as seguintes m√©dias e matriz de covari√¢ncia comum: $\mu_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$, $\mu_2 = \begin{bmatrix} 3 \\ 3 \end{bmatrix}$, e $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$. Assumindo que as probabilidades a priori s√£o iguais, $\pi_1 = \pi_2 = 0.5$.  Para classificar um novo ponto $x = \begin{bmatrix} 2 \\ 2 \end{bmatrix}$, podemos calcular as fun√ß√µes discriminantes:
>
>  $\Sigma^{-1} = \frac{1}{0.75}\begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$
>
> $\delta_1(x) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} + \log(0.5)  = 2.66 - 0.66 + (-0.693) \approx 1.307$
>
> $\delta_2(x) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 3 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} + \log(0.5) = 8 - 6 + (-0.693) \approx 1.307$
>
> Como $\delta_1(x) = \delta_2(x)$, o ponto $x$ est√° na fronteira de decis√£o linear entre as duas classes. Se $\pi_1 \neq \pi_2$, o ponto de corte seria diferente, ilustrando o papel da probabilidade *a priori*.

**Corol√°rio 1:** *A fun√ß√£o discriminante linear do LDA pode ser expressa como uma proje√ß√£o das observa√ß√µes em um vetor dado pela diferen√ßa entre as m√©dias das classes, escalonada pela inversa da matriz de covari√¢ncia, seguida por um ajuste do limiar de decis√£o.*

**Prova do Corol√°rio 1:** A fun√ß√£o discriminante linear do LDA para a classe $k$ √©:
$$
    \delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T \Sigma^{-1}\mu_k + \log \pi_k
$$
Considere o caso de duas classes, $i$ e $j$. A fronteira de decis√£o √© definida quando $\delta_i(x) = \delta_j(x)$:
$$
    x^T \Sigma^{-1} \mu_i - \frac{1}{2}\mu_i^T \Sigma^{-1}\mu_i + \log \pi_i = x^T \Sigma^{-1} \mu_j - \frac{1}{2}\mu_j^T \Sigma^{-1}\mu_j + \log \pi_j
$$
Reorganizando:
$$
   x^T \Sigma^{-1}(\mu_i - \mu_j) =  \frac{1}{2} (\mu_i^T \Sigma^{-1}\mu_i  - \mu_j^T \Sigma^{-1}\mu_j) + \log\frac{\pi_j}{\pi_i}
$$
O termo $\Sigma^{-1}(\mu_i - \mu_j)$ representa a dire√ß√£o da proje√ß√£o, e o termo do lado direito da equa√ß√£o representa o limiar de decis√£o.  Assim, a fun√ß√£o discriminante do LDA √© equivalente a uma proje√ß√£o das observa√ß√µes na dire√ß√£o da diferen√ßa das m√©dias escalonada pela inversa da covari√¢ncia, e a compara√ß√£o dessa proje√ß√£o com um limiar adequado.
$\blacksquare$
```mermaid
graph TB
  subgraph "LDA Decision Boundary"
    direction TB
    A["Œ¥·µ¢(x) = Œ¥‚±º(x)"] --> B["Projection Vector: Œ£‚Åª¬π(Œº·µ¢ - Œº‚±º)"]
    B --> C["Decision Threshold: 1/2 (Œº·µ¢·µÄŒ£‚Åª¬πŒº·µ¢ - Œº‚±º·µÄŒ£‚Åª¬πŒº‚±º) + log(œÄ‚±º/œÄ·µ¢)"]
    end
```
**Conceito 3: Logistic Regression**

A **Logistic Regression** √© um modelo estat√≠stico para classifica√ß√£o bin√°ria, que modela a probabilidade de um evento (classe) ocorrer atrav√©s da fun√ß√£o log√≠stica [^4.4].  Ao inv√©s de modelar diretamente a classe, a regress√£o log√≠stica modela a probabilidade da classe atrav√©s de uma fun√ß√£o log√≠stica aplicada a uma combina√ß√£o linear das *features*. A fun√ß√£o log√≠stica (sigm√≥ide) √© dada por $\sigma(z) = \frac{1}{1 + e^{-z}}$. A probabilidade da classe 1, dado o vetor de *features* x, √© dada por $p(y=1|x) = \sigma(\beta_0 + \sum_{j=1}^p x_j \beta_j)$.  O *logit* (log-odds) √© dado por:
$$
   \text{logit}(p(y=1|x)) = \ln\left(\frac{p(y=1|x)}{1-p(y=1|x)}\right) = \beta_0 + \sum_{j=1}^p x_j \beta_j
$$
Os par√¢metros s√£o estimados atrav√©s da maximiza√ß√£o da verossimilhan√ßa, que consiste em encontrar os par√¢metros que maximizam a probabilidade dos dados observados [^4.4.1]. O modelo da regress√£o log√≠stica, ao contrario do LDA, n√£o imp√µe nenhuma suposi√ß√£o sobre a distribui√ß√£o das *features*.  A regress√£o log√≠stica pode ser utilizada para classificar dados com mais de duas classes atrav√©s de extens√µes como a regress√£o log√≠stica *multinomial* (softmax) e *one-vs-all*, onde a decis√£o entre duas classes √© similar a LDA com fronteiras de decis√£o lineares [^4.4.5]. Apesar das similaridades entre o LDA e a regress√£o log√≠stica, a escolha entre os modelos depende das suposi√ß√µes sobre a distribui√ß√£o dos dados, e da necessidade de estimativas de probabilidade.
```mermaid
graph LR
    subgraph "Logistic Regression"
        direction LR
        A["Linear Combination: z = Œ≤‚ÇÄ + Œ£(x‚±ºŒ≤‚±º)"] --> B["Logistic Function: œÉ(z) = 1 / (1 + e‚Åª·∂ª)"]
        B --> C["Probability: P(y=1|x)"]
         C-->D["Logit Function: log(P/(1-P))"]
         D-->A
    end
```
> üí° **Exemplo Num√©rico:**  Suponha um modelo de regress√£o log√≠stica com uma √∫nica feature $X$, onde $\beta_0 = -3$ e $\beta_1 = 2$. Para uma observa√ß√£o com $x = 2$, a probabilidade de pertencer √† classe 1 seria calculada como:
>
> $z = -3 + 2(2) = 1$
>
> $p(y=1|x) = \frac{1}{1 + e^{-1}} = \frac{1}{1 + 0.368} \approx 0.731$.
>
>  Isso significa que a probabilidade estimada de essa observa√ß√£o pertencer √† classe 1 √© de aproximadamente 73,1%. Se usarmos um threshold de 0.5, classificariamos essa observa√ß√£o como classe 1. Se $x = 1$, ent√£o $z = -3 + 2(1) = -1$, e $p(y=1|x) = \frac{1}{1 + e^{1}} = \frac{1}{1 + 2.718} \approx 0.269$. Portanto a observa√ß√£o seria classificada como classe 0.

> ‚ö†Ô∏è **Nota Importante**: O modelo de regress√£o log√≠stica estima diretamente a probabilidade da classe, enquanto o LDA estima uma fun√ß√£o discriminante que pode ser usada para classifica√ß√£o [^4.4.1].

> ‚ùó **Ponto de Aten√ß√£o**:  Em problemas de classifica√ß√£o com classes n√£o-balanceadas, pode ser necess√°rio ajustar os limiares de decis√£o na regress√£o log√≠stica para obter um melhor equil√≠brio entre precis√£o e revoca√ß√£o [^4.4.2].

> ‚úîÔ∏è **Destaque**:  Sob certas condi√ß√µes, como quando as classes s√£o normalmente distribu√≠das com a mesma covari√¢ncia, o LDA e a regress√£o log√≠stica levam a decis√µes classificat√≥rias similares, embora estimem os par√¢metros de maneira diferente [^4.5].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
```mermaid
flowchart TD
  subgraph "Regress√£o de Indicadores"
    A[Codificar Classes] --> B[Estimar Coeficientes via LS]
    B --> C[Aplicar Regra de Decis√£o]
    C --> D[Comparar com M√©todos Probabil√≠sticos]
  end
```
<imagem: Gr√°fico ilustrando as fronteiras de decis√£o resultantes da regress√£o de indicadores em um problema de classifica√ß√£o bin√°ria. As fronteiras s√£o retas que dividem o espa√ßo de *features*, mostrando a capacidade de separa√ß√£o linear da regress√£o de indicadores.>
A regress√£o linear, utilizando uma matriz de indicadores, pode ser aplicada a problemas de classifica√ß√£o. A ideia central √© criar uma representa√ß√£o num√©rica para cada classe, codificando-as com vetores de indicadores. Em um problema de classifica√ß√£o bin√°ria, uma classe √© codificada como 1 e outra como 0. Ao aplicar regress√£o linear a essa representa√ß√£o, busca-se encontrar uma fun√ß√£o linear que mapeie as *features* para esses valores de classe [^4.2]. O m√©todo de m√≠nimos quadrados √© empregado para estimar os coeficientes de regress√£o que minimizam a soma dos quadrados dos res√≠duos. Ap√≥s estimar os coeficientes, a regra de decis√£o transforma a sa√≠da cont√≠nua em uma classifica√ß√£o discreta, como atribuir √† classe 1 se a sa√≠da predita for maior ou igual a 0.5 e classe 0 caso contr√°rio. No entanto, essa abordagem possui algumas limita√ß√µes. A regress√£o linear de indicadores n√£o garante que as previs√µes ficar√£o entre 0 e 1, o que pode levar a resultados pouco intuitivos. Em situa√ß√µes com mais de duas classes, a regress√£o linear de indicadores pode apresentar problemas, como o *masking problem*, onde uma classe pode obscurecer outras na regress√£o, levando a um desempenho inadequado [^4.3]. A regress√£o log√≠stica √© geralmente prefer√≠vel pois ela estima as probabilidades da classe diretamente, o que √© fundamental em problemas de classifica√ß√£o [^4.4]. Al√©m disso, enquanto a regress√£o de indicadores foca em obter a melhor fronteira de decis√£o linear, a regress√£o log√≠stica estima as probabilidades da classe com base em um modelo probabil√≠stico.

> üí° **Exemplo Num√©rico:** Considere um conjunto de dados com duas classes (0 e 1) e duas features, onde as classes s√£o representadas por um vetor indicador $y$. Aplicamos a regress√£o linear $y = X\beta$. Suponha que ap√≥s o ajuste dos m√≠nimos quadrados obtivemos os seguintes coeficientes: $\beta_0 = 0.2$, $\beta_1 = 0.5$ e $\beta_2 = 0.3$. Uma nova observa√ß√£o $x = [1, 2]$ teria uma previs√£o de $≈∑ = 0.2 + 0.5(1) + 0.3(2) = 1.3$. Usando um limiar de 0.5, essa observa√ß√£o seria classificada como classe 1. No entanto, se $x = [-1, -1]$, ent√£o $≈∑ = 0.2 - 0.5 - 0.3 = -0.6$.  Apesar de o resultado ser menor que 0, o que intuitivamente seria classe 0, valores negativos n√£o fazem sentido como probabilidades.
```mermaid
graph TB
    subgraph "Linear Regression for Classification"
        direction TB
        A["Indicator Matrix Y"] --> B["Linear Regression: Y = XB"]
        B --> C["Prediction: ≈∑ = XŒ≤"]
        C --> D["Threshold:  ≈∑ ‚â• 0.5 ? Class 1 : Class 0"]
          D --> E["Potential Issues: Extrapolation Beyond [0,1]"]
    end
```
**Lemma 2:** *Sob certas condi√ß√µes, a proje√ß√£o dos dados nas dire√ß√µes definidas pela regress√£o linear de indicadores √© equivalente √† proje√ß√£o em um hiperplano de decis√£o gerado por um discriminante linear*.

**Prova do Lemma 2:** Considere um problema de classifica√ß√£o com *K* classes. Na regress√£o linear de indicadores, cada classe *k* √© representada por um vetor $y_k$ em que $y_{k,i} = 1$ se a observa√ß√£o $i$ pertence √† classe *k* e $y_{k,i}=0$ caso contr√°rio.  A matriz de indicadores $Y$ tem dimens√µes *N* x *K*, onde *N* √© o n√∫mero de observa√ß√µes.  Ao realizar a regress√£o linear $Y = XB$, obtemos a matriz de coeficientes $B$, que representa a proje√ß√£o dos dados originais nas classes. Sob a condi√ß√£o de que as vari√°veis preditoras s√£o independentes e com vari√¢ncia igual, a regress√£o linear de indicadores resulta em proje√ß√µes que maximizam a vari√¢ncia entre as classes, de maneira similar ao que ocorre no discriminante linear. A fronteira de decis√£o √© definida pelos pontos nos quais a proje√ß√£o em diferentes classes √© igual, o que resulta em um hiperplano, assim como no caso do discriminante linear. Assim, a dire√ß√£o da proje√ß√£o e o limiar de decis√£o da regress√£o linear de indicadores podem ser expressos como proje√ß√µes em um hiperplano gerado por um discriminante linear sob essas condi√ß√µes.
$\blacksquare$
```mermaid
graph TB
  subgraph "Equivalence with Linear Discriminants"
    direction TB
    A["Regression Projection"] --> B["Maximizes inter-class variance"]
    B --> C["Equivalent to Discriminant Projection"]
    C --> D["Hyperplane Decision Boundary"]
  end
```
**Corol√°rio 2:** *A equival√™ncia entre a proje√ß√£o nos hiperplanos de decis√£o da regress√£o linear e discriminantes lineares permite simplificar a an√°lise em casos espec√≠ficos, por exemplo, quando a separabilidade linear √© desejada*.

**Prova do Corol√°rio 2:** Como demonstrado no Lemma 2, sob certas condi√ß√µes, a regress√£o linear de indicadores e discriminantes lineares (como o LDA) levam a solu√ß√µes equivalentes. Isso simplifica a an√°lise em cen√°rios onde a separabilidade linear √© o objetivo prim√°rio. Em vez de derivar as equa√ß√µes para ambos os m√©todos separadamente, podemos utilizar a equival√™ncia para derivar resultados e analisar a efici√™ncia da classifica√ß√£o com base na proje√ß√£o nos hiperplanos de decis√£o, o que simplifica o processo de modelagem e an√°lise dos dados.
$\blacksquare$

Em alguns casos, a regress√£o log√≠stica fornece estimativas mais est√°veis da probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora do intervalo [0,1] [^4.4]. Entretanto, a regress√£o de indicadores pode ser suficiente e at√© mesmo vantajosa quando a fronteira de decis√£o linear √© o principal interesse [^4.2].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o
<imagem: Um mapa mental que conecta m√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o, mostrando L1, L2, Elastic Net e suas aplica√ß√µes em modelos de classifica√ß√£o como regress√£o log√≠stica, e sua rela√ß√£o com a interpretabilidade e desempenho do modelo.>
A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas cruciais para melhorar a generaliza√ß√£o e a interpretabilidade dos modelos de classifica√ß√£o, especialmente quando o n√∫mero de preditores √© alto ou quando h√° multicolinearidade. A sele√ß√£o de vari√°veis busca identificar o subconjunto mais relevante de preditores para o modelo, eliminando as vari√°veis redundantes ou irrelevantes. A regulariza√ß√£o, por sua vez, imp√µe restri√ß√µes aos coeficientes do modelo, penalizando os coeficientes que s√£o muito grandes, reduzindo o risco de sobreajuste e tornando o modelo mais est√°vel. A regress√£o log√≠stica, por exemplo, pode se beneficiar da regulariza√ß√£o, como as penaliza√ß√µes L1 e L2 [^4.4.4].

A **penaliza√ß√£o L1** imp√µe uma penalidade sobre a soma dos valores absolutos dos coeficientes, $\lambda \sum_{j=1}^p |\beta_j|$, onde $\lambda$ √© um par√¢metro de ajuste que controla a intensidade da penaliza√ß√£o. Essa penalidade tem a propriedade de levar muitos coeficientes a zero, resultando em modelos esparsos e interpret√°veis, pois apenas um subconjunto das *features* ser√° utilizado no modelo [^4.5.1]. A **penaliza√ß√£o L2** imp√µe uma penalidade sobre a soma dos quadrados dos coeficientes, $\lambda \sum_{j=1}^p \beta_j^2$.  Essa penalidade tende a reduzir a magnitude de todos os coeficientes, levando a modelos mais est√°veis e generaliz√°veis, mas n√£o leva a modelos esparsos como a L1. Uma combina√ß√£o das penalidades L1 e L2 √© utilizada na **Elastic Net** para tirar vantagem de ambos os tipos de regulariza√ß√£o [^4.5.2]. Essa t√©cnica penaliza o modelo com $\lambda_1 \sum_{j=1}^p |\beta_j| + \lambda_2 \sum_{j=1}^p \beta_j^2$ e combina a capacidade de selecionar vari√°veis do lasso com a estabilidade da ridge regression, promovendo modelos mais robustos.
```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction LR
        A["L1 Penalty: ŒªŒ£|Œ≤‚±º|"] --> B["Sparsity"]
        C["L2 Penalty: ŒªŒ£Œ≤‚±º¬≤"] --> D["Coefficient Shrinkage"]
        E["Elastic Net: Œª‚ÇÅŒ£|Œ≤‚±º| + Œª‚ÇÇŒ£Œ≤‚±º¬≤"] --> F["Sparsity + Stability"]
    end
```
> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o log√≠stica com 3 features, e coeficientes iniciais $\beta = [\beta_0, \beta_1, \beta_2, \beta_3] = [0.5, 2, -1.5, 0.8]$. Vamos aplicar as penalidades L1 e L2 com $\lambda=0.5$.
>
> **Penalidade L1:** $\lambda \sum_{j=1}^3 |\beta_j| = 0.5 * (|2| + |-1.5| + |0.8|) = 0.5 * (2 + 1.5 + 0.8) = 2.15$.
>
> **Penalidade L2:** $\lambda \sum_{j=1}^3 \beta_j^2 = 0.5 * (2^2 + (-1.5)^2 + 0.8^2) = 0.5 * (4 + 2.25 + 0.64) = 3.445$.
>
> A penalidade L1 tende a zerar alguns dos coeficientes, o que leva a um modelo mais esparso. A penalidade L2 encolhe todos os coeficientes, tornando o modelo mais est√°vel. Uma penalidade Elastic Net combinaria as duas penalidades. Variando $\lambda$, podemos controlar o grau de regulariza√ß√£o.

**Lemma 3:** *A penaliza√ß√£o L1 na classifica√ß√£o log√≠stica leva a coeficientes esparsos devido √† sua propriedade de concentrar a densidade de probabilidade nas regi√µes pr√≥ximas dos eixos*.

**Prova do Lemma 3:** A regress√£o log√≠stica com regulariza√ß√£o L1 tem como objetivo minimizar a fun√ß√£o de custo:
$$
    L(\beta) = -\sum_{i=1}^N [y_i \log(p_i) + (1-y_i)\log(1-p_i)] + \lambda \sum_{j=1}^p |\beta_j|
$$
onde $p_i$ √© a probabilidade da classe 1 para a observa√ß√£o *i*. A penaliza√ß√£o L1, $\lambda \sum_{j=1}^p |\beta_j|$, corresponde a um prior de Laplace nos coeficientes $\beta$. A fun√ß√£o de Laplace concentra sua densidade de probabilidade nas regi√µes pr√≥ximas aos eixos, ou seja, onde alguns coeficientes $\beta_j$ s√£o nulos.  Ao minimizar o custo total, a penaliza√ß√£o L1 tende a levar os coeficientes menos relevantes para zero, resultando em um modelo esparso, onde apenas um subconjunto de *features* √© utilizado. Portanto, a penaliza√ß√£o L1 induz esparsidade nos modelos de classifica√ß√£o log√≠stica.
$\blacksquare$
```mermaid
graph TB
    subgraph "L1 Regularization & Sparsity"
        direction TB
        A["L1 Cost Function: L(Œ≤) + ŒªŒ£|Œ≤‚±º|"] --> B["Laplace Prior on Coefficients"]
        B --> C["Probability Density Concentrated near Axes"]
        C --> D["Sparsity: Irrelevant Coefficients Driven to Zero"]
    end
```
**Corol√°rio 3:** *A esparsidade induzida pela penaliza√ß√£o L1 melhora a interpretabilidade do modelo classificador, pois apenas os preditores mais relevantes s√£o mantidos*.

**Prova do Corol√°rio 3:** Conforme o Lemma 3, a penaliza√ß√£o L1 leva a modelos esparsos, em que a maioria dos coeficientes $\beta_j$ s√£o iguais a zero.  Isso significa que as *features* correspondentes aos coeficientes zero n√£o contribuem para a predi√ß√£o.  Assim, o modelo final acaba por utilizar apenas um subconjunto dos preditores originais. Essa sele√ß√£o autom√°tica das *features* mais relevantes facilita a interpreta√ß√£o do modelo, permitindo identificar quais as vari√°veis mais importantes para a tarefa de classifica√ß√£o, promovendo um modelo mais compreens√≠vel e f√°cil de analisar.
$\blacksquare$

> ‚ö†Ô∏è **Ponto Crucial**: A Elastic Net combina as vantagens das regulariza√ß√µes L1 e L2, oferecendo um equil√≠brio entre esparsidade e estabilidade do modelo [^4.5].

### Separating Hyperplanes e Perceptrons
A ideia de maximizar a margem de separa√ß√£o entre as classes leva ao conceito de **hiperplanos separadores √≥timos**. Em um problema de classifica√ß√£o linear, um hiperplano separador √© uma superf√≠cie linear que divide o espa√ßo de *features* em regi√µes correspondentes a diferentes classes [^4.5.2]. O objetivo √© encontrar o hiperplano que maximiza a dist√¢ncia entre o hiperplano e as observa√ß√µes mais pr√≥ximas de cada classe, chamadas de vetores de suporte. A formula√ß√£o do problema de otimiza√ß√£o para encontrar o hiperplano separador envolve a maximiza√ß√£o da margem, que pode ser resolvida atrav√©s da solu√ß√£o do seu problema dual de Wolfe, resultando em coeficientes obtidos a partir de combina√ß√µes lineares dos pontos de suporte.
```mermaid
graph TB
    subgraph "Optimal Separating Hyperplane"
        direction TB
        A["Maximize Margin"] --> B["Find Hyperplane"]
        B --> C["Support Vectors"]
        C --> D["Dual Wolfe Problem"]
        D --> E["Coefficients from Support Vectors"]
    end
```
O **Perceptron** √© um algoritmo de aprendizado supervisionado que busca encontrar um hiperplano separador para dados linearmente separ√°veis [^4.5.1]. O algoritmo do Perceptron de Rosenblatt atualiza iterativamente os pesos da fun√ß√£o discriminante at√© encontrar um hiperplano que classifique corretamente os dados. A converg√™ncia do Perceptron √© garantida sob a condi√ß√£o de que os dados sejam linearmente separ√°veis. O algoritmo do Perceptron pode n√£o convergir ou convergir para uma solu√ß√£o sub√≥tima se os dados n√£o s√£o linearmente separ√°veis. No entanto, o Perceptron tem valor hist√≥rico e ainda √© utilizado como base para m√©todos mais avan√ßados de classifica√ß√£o linear.
```mermaid
graph TB
    subgraph "Perceptron Algorithm"
        direction TB
        A["Initialize Weights"] --> B["Iteratively Update Weights"]
        B --> C["Hyperplane Convergence"]
        C --> D["Linear Separability Requirement"]
        D --> E["Potential for Non-Convergence/Suboptimal Solutions"]

    end
```
> üí° **Exemplo Num√©rico:** Vamos ilustrar o Perceptron com um exemplo simples. Suponha que temos os seguintes dados linearmente separ√°veis: Classe 1: $[(1, 1), (2, 2)]$, e Classe 0: $[(1, -1), (2, -1)]$. Inicializamos os pesos com $\beta = [0, 0, 0]$. Para cada ponto $x_i$, atualizamos os pesos se a classifica√ß√£o estiver errada. Itera√ß√£o 1: $x_1 = [1, 1]$. Se $f(x) = 0$, a classifica√ß√£o seria errada. Como √© classe 1, atualizamos os pesos: $\beta = [1, 1, 1]$. Itera√ß√£o 2: $x_2 = [2, 2]$.  $f(x) = 1 * 1 + 2 * 1 + 2 * 1 = 5 > 0$, classifica√ß√£o correta. Itera√ß√£o 3: $x_3 = [1, -1]$. $f(x) = 1 * 1 + 1 * 1 -1 *1 = 1 > 0$, classifica√ß√£o errada. Como √© classe 0, $\beta = [1 - 1, 1 - 1, 1 -(-1)] = [0, 0, 2]$. Itera√ß√£o 4: $x_4 = [2, -1]$.  $f(x) = 0 * 1 + 0 * 2 + 2 * (-1) = -2 < 0$, classifica√ß√£o correta. Repetindo esse processo, o Perceptron eventualmente encontra pesos que separam as classes.

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**
Sob a suposi√ß√£o de que os dados de cada classe s√£o gerados por uma distribui√ß√£o Gaussiana com a mesma matriz de covari√¢ncia, a Linear Discriminant Analysis (LDA) e a Regra de Decis√£o Bayesiana levam a solu√ß√µes equivalentes [^4.3].

*   **Regra de Decis√£o Bayesiana:** A regra de decis√£o Bayesiana atribui uma observa√ß√£o $x$ √† classe $k$ que maximiza a probabilidade posterior $P(C_k|x)$, que pode ser expressa usando a regra de Bayes:
    $$
    P(C_k|x) = \frac{P(x|C_k)P(C_k)}{P(x)}
    $$
    Onde $P(x|C_k)$ √© a verossimilhan√ßa de $x$ dado a classe $C_k$, $P(C_k)$ √© a probabilidade a priori da classe $C_k$, e $P(x)$ √© a probabilidade marginal de $x$.  Sob a suposi√ß√£o de que $P(x|C_k)$ s√£o gaussianas com m√©dia $\mu_k$ e covari