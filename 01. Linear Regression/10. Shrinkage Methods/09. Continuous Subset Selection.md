Okay, I will add practical numerical examples to the text where appropriate, while preserving all existing content and following the guidelines you've provided.

## Continuous Subset Selection via Coefficient Shrinkage to Zero

<imagem: Um diagrama que ilustra a rela√ß√£o entre diferentes m√©todos de sele√ß√£o de vari√°veis (Subset Selection, Ridge, Lasso e Elastic Net), com flechas mostrando como cada um deles afeta os coeficientes do modelo, destacando a ideia de que eles convergem para zero de forma cont√≠nua.>

### Introdu√ß√£o

Este cap√≠tulo explora m√©todos de regress√£o linear que visam a sele√ß√£o de vari√°veis por meio do encolhimento cont√≠nuo de coeficientes para zero, abordando alternativas ao m√©todo de sele√ß√£o de subconjuntos. A regress√£o linear assume que a fun√ß√£o de regress√£o $E(Y|X)$ √© linear nas entradas $X_1, \dots, X_p$ [^3.1]. Embora modelos lineares tenham sido desenvolvidos principalmente na era pr√©-computacional, eles permanecem relevantes por sua simplicidade, interpretabilidade e desempenho em cen√°rios com poucos dados, baixo sinal-ru√≠do ou dados esparsos [^3.1]. M√©todos lineares tamb√©m podem ser aplicados a transforma√ß√µes das entradas, expandindo consideravelmente seu escopo [^3.1]. Este cap√≠tulo foca em m√©todos lineares para regress√£o, com m√©todos para classifica√ß√£o abordados no cap√≠tulo seguinte [^3.1].

### Conceitos Fundamentais

**Conceito 1:** O problema de classifica√ß√£o envolve determinar a qual classe um novo ponto de dados pertence. Em termos gerais, o objetivo da an√°lise discriminante √© construir um modelo capaz de predizer a classe de um novo objeto com base em um conjunto de dados de treinamento com r√≥tulos de classe pr√©-definidos. M√©todos lineares, como regress√£o linear em matrizes indicadoras, Linear Discriminant Analysis (LDA) e regress√£o log√≠stica, buscam construir fronteiras lineares entre classes. No contexto de modelos lineares, a decis√£o de usar um ou outro m√©todo de classifica√ß√£o pode ter implica√ß√µes no compromisso entre vi√©s e vari√¢ncia. Por exemplo, a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1] [^4.4], enquanto a LDA imp√µe hip√≥teses sobre a normalidade dos dados e igualdade de covari√¢ncias entre as classes [^4.3]. A escolha do m√©todo deve ser guiada pela natureza dos dados e pelo objetivo da an√°lise, incluindo a interpretabilidade do modelo final.
**Lemma 1:** *Em um cen√°rio de regress√£o linear com uma matriz de indicadores para classes, onde o objetivo √© prever a qual classe um objeto pertence, a decis√£o de atribuir um objeto √† classe $k$ pode ser baseada na maior sa√≠da linear entre todas as classes*. Formalmente, dadas as fun√ß√µes lineares $f_k(x) = x^T \beta_k$ para $k=1,\ldots,K$, onde $x$ √© o vetor de caracter√≠sticas do objeto e $\beta_k$ s√£o os coeficientes associados √† classe $k$, a classe predita $\hat{c}$ ser√° aquela que maximiza a sa√≠da linear: $\hat{c} = \arg \max_{k} f_k(x)$. Isso implica que, para cada classe $k$, existe um hiperplano definido pelos coeficientes $\beta_k$, e a escolha da classe √© feita pela proje√ß√£o do ponto $x$ na dire√ß√£o de cada $\beta_k$ [^4.2]. A atribui√ß√£o √† classe $k$ ocorrer√° se essa proje√ß√£o for a maior de todas as proje√ß√µes, o que corresponde a estar do lado correto do hiperplano definido pela classe $k$. $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Considere um problema de classifica√ß√£o com tr√™s classes (A, B, e C) e duas caracter√≠sticas ($x_1$ e $x_2$). Ap√≥s a regress√£o linear em uma matriz de indicadores, obtivemos os seguintes coeficientes para cada classe:
>
> - Classe A: $\beta_A = [0.5, -0.2]$
> - Classe B: $\beta_B = [-0.1, 0.4]$
> - Classe C: $\beta_C = [0.2, 0.1]$
>
> Para um novo ponto $x = [2, 1]$, as sa√≠das lineares seriam:
>
> - $f_A(x) = (2 * 0.5) + (1 * -0.2) = 0.8$
> - $f_B(x) = (2 * -0.1) + (1 * 0.4) = 0.2$
> - $f_C(x) = (2 * 0.2) + (1 * 0.1) = 0.5$
>
> Como $f_A(x)$ √© a maior sa√≠da, o ponto $x$ seria classificado como pertencente √† Classe A. Este exemplo ilustra como a decis√£o de classe √© tomada pela maximiza√ß√£o das sa√≠das lineares.

```mermaid
graph LR
    subgraph "Linear Classification Decision"
        direction TB
        A["Input Vector: x"]
        B["Class 1: f1(x) = x<sup>T</sup>Œ≤1"]
        C["Class 2: f2(x) = x<sup>T</sup>Œ≤2"]
        D["Class K: fK(x) = x<sup>T</sup>Œ≤K"]
        E["argmax<sub>k</sub> f<sub>k</sub>(x)"]
        A --> B
        A --> C
        A --> D
        B & C & D --> E
    end
```
**Conceito 2:** A Linear Discriminant Analysis (LDA) √© um m√©todo de classifica√ß√£o que assume que as classes possuem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia [^4.3]. A LDA busca projetar os dados em um subespa√ßo de menor dimens√£o de forma a maximizar a separa√ß√£o entre as classes. As suposi√ß√µes de normalidade e covari√¢ncia igual afetam a forma da fronteira de decis√£o, que ser√° linear. A fun√ß√£o discriminante linear para uma observa√ß√£o $x$ √© dada por
$$
\delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log\pi_k
$$
onde $\mu_k$ √© a m√©dia da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum, e $\pi_k$ √© a probabilidade a priori da classe $k$ [^4.3.1].  A decis√£o de classe √© feita com base na maior fun√ß√£o discriminante, que tamb√©m √© uma forma de proje√ß√£o linear [^4.3.2].

**Corol√°rio 1:** *A fun√ß√£o discriminante linear da LDA pode ser interpretada como uma proje√ß√£o dos dados no espa√ßo definido pelos centroides das classes, ponderada pela matriz de covari√¢ncia inversa*. Essa proje√ß√£o implica que os dados s√£o transformados de forma que a separa√ß√£o entre as classes √© maximizada no novo espa√ßo, ao mesmo tempo em que a variabilidade dentro das classes √© minimizada. A fronteira de decis√£o √©, portanto, uma superf√≠cie que separa as regi√µes do espa√ßo onde as fun√ß√µes discriminantes para diferentes classes s√£o m√°ximas.  Quando as classes s√£o linearmente separ√°veis, os centroides formam uma base no espa√ßo de proje√ß√£o [^4.3.2].$\blacksquare$

> üí° **Exemplo Num√©rico:**
> Suponha que temos duas classes com as seguintes m√©dias e matriz de covari√¢ncia comum:
>
> - Classe 1: $\mu_1 = [1, 1]$
> - Classe 2: $\mu_2 = [3, 2]$
> - $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
> - Probabilidades a priori: $\pi_1 = 0.6$, $\pi_2 = 0.4$.
>
> Primeiro calculamos a inversa da matriz de covari√¢ncia:
>
> $\Sigma^{-1} = \frac{1}{(1*1 - 0.5*0.5)}\begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$
>
> Para um novo ponto $x = [2, 1.5]$, as fun√ß√µes discriminantes s√£o:
>
> $\delta_1(x) = [2, 1.5]^T \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [1, 1] - \frac{1}{2} [1, 1]^T \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [1, 1] + \log(0.6) =  -0.26 $
> $\delta_2(x) = [2, 1.5]^T \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [3, 2] - \frac{1}{2} [3, 2]^T \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} [3, 2] + \log(0.4) = 0.12 $
>
> Como $\delta_2(x) > \delta_1(x)$, o ponto $x$ seria classificado como pertencente √† Classe 2. Este exemplo demonstra o c√°lculo das fun√ß√µes discriminantes da LDA.

```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction TB
        A["Input Vector: x"]
        B["Class k Mean: Œº<sub>k</sub>"]
        C["Common Covariance Matrix: Œ£"]
        D["Prior Probability: œÄ<sub>k</sub>"]
        E["Œ£<sup>-1</sup>"]
        F["x<sup>T</sup>Œ£<sup>-1</sup>Œº<sub>k</sub>"]
        G["Œº<sub>k</sub><sup>T</sup>Œ£<sup>-1</sup>Œº<sub>k</sub>"]
        H["Œ¥<sub>k</sub>(x) = x<sup>T</sup>Œ£<sup>-1</sup>Œº<sub>k</sub> - 1/2 Œº<sub>k</sub><sup>T</sup>Œ£<sup>-1</sup>Œº<sub>k</sub> + log(œÄ<sub>k</sub>)"]

        B --> E
        C --> E
        A & E & B --> F
        B & E --> G
        F & G & D --> H
    end
```

**Conceito 3:** A regress√£o log√≠stica √© um m√©todo de classifica√ß√£o que modela a probabilidade de um objeto pertencer a uma determinada classe atrav√©s da fun√ß√£o log√≠stica [^4.4]. A probabilidade de um objeto $x$ pertencer √† classe positiva √© modelada como:
$$
p(x) = \frac{1}{1+e^{-(\beta_0 + \beta^T x)}}
$$
onde $\beta_0$ √© o intercepto e $\beta$ s√£o os coeficientes. O logit, que √© o log-odds, √© linear nos coeficientes:
$$
\ln\left(\frac{p(x)}{1-p(x)}\right) = \beta_0 + \beta^T x
$$
Os coeficientes $\beta$ s√£o estimados maximizando a verossimilhan√ßa (likelihood) dos dados de treinamento [^4.4.1]. Enquanto LDA assume a normalidade das classes, a regress√£o log√≠stica n√£o faz essa suposi√ß√£o, tornando-a mais flex√≠vel [^4.4.2]. A regress√£o log√≠stica tamb√©m pode ser facilmente estendida para problemas de classifica√ß√£o multiclasse usando a fun√ß√£o softmax [^4.4.3]. As decis√µes podem ser feitas considerando qual classe tem a maior probabilidade ou usando um limiar de classifica√ß√£o [^4.4.5].

> ‚ö†Ô∏è **Nota Importante:** A regress√£o log√≠stica usa o conceito de *log-odds* para transformar uma probabilidade entre 0 e 1 em um n√∫mero que pode ser modelado linearmente, conforme descrito em [^4.4.1].

> ‚ùó **Ponto de Aten√ß√£o**:  Em cen√°rios onde as classes est√£o desbalanceadas, a regress√£o log√≠stica, assim como outros modelos de classifica√ß√£o, pode apresentar vi√©s em favor da classe majorit√°ria, o que deve ser tratado por meio de t√©cnicas como subamostragem, sobreamostragem ou pondera√ß√£o de classes, conforme indicado em [^4.4.2].

> ‚úîÔ∏è **Destaque**: Embora LDA e regress√£o log√≠stica sejam abordagens distintas, seus coeficientes podem estar correlacionados em muitos casos pr√°ticos, especialmente quando as classes s√£o aproximadamente normais e linearmente separ√°veis, conforme indicado em [^4.5].

> üí° **Exemplo Num√©rico:**
> Suponha que, ap√≥s ajustar um modelo de regress√£o log√≠stica, obtivemos os seguintes coeficientes:
>
> - $\beta_0 = -1.5$
> - $\beta = [0.8, 0.5]$ (para duas vari√°veis preditoras $x_1$ e $x_2$)
>
> Para um novo ponto $x = [2, 1]$, a probabilidade predita para a classe positiva seria:
>
> $p(x) = \frac{1}{1 + e^{-(-1.5 + 0.8 * 2 + 0.5 * 1)}} = \frac{1}{1 + e^{-0.6}} = 0.6456 $
>
> Se usarmos um limiar de classifica√ß√£o de 0.5, classificar√≠amos este ponto como pertencente √† classe positiva, pois $p(x) > 0.5$. Este exemplo ilustra o c√°lculo da probabilidade usando a fun√ß√£o log√≠stica.

```mermaid
graph LR
    subgraph "Logistic Regression Probability"
        direction TB
        A["Input Vector: x"]
        B["Coefficients: Œ≤"]
        C["Intercept: Œ≤<sub>0</sub>"]
        D["Linear Combination: Œ≤<sub>0</sub> + Œ≤<sup>T</sup>x"]
        E["exp(-D)"]
        F["1 + E"]
        G["p(x) = 1 / F"]
        A --> B
        A & B --> D
        C --> D
        D --> E
        E --> F
        F --> G
    end
```

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o
```mermaid
flowchart TD
  subgraph Regress√£o de Indicadores
    A[Codificar Classes] --> B[Estimar Coeficientes via LS]
    B --> C[Aplicar Regra de Decis√£o]
    C --> D[Comparar com M√©todos Probabil√≠sticos]
  end
```
A regress√£o linear pode ser utilizada para classifica√ß√£o por meio da regress√£o de uma matriz de indicadores. Inicialmente, codifica-se cada classe como um vetor de indicadores bin√°rios [^4.2]. Por exemplo, em um problema com tr√™s classes, um objeto pertencente √† classe 1 seria codificado como (1, 0, 0), √† classe 2 como (0, 1, 0) e √† classe 3 como (0, 0, 1). Em seguida, realiza-se a regress√£o linear dos vetores indicadores contra os preditores, resultando em um conjunto de coeficientes para cada classe.

A regra de decis√£o neste contexto seria classificar o objeto na classe com a maior sa√≠da linear. Formalmente, se $f_k(x) = x^T \beta_k$ representa a fun√ß√£o linear associada √† classe $k$, a classe predita $\hat{c}$ seria dada por $\hat{c} = argmax_k f_k(x)$. Essa abordagem pode ser vista como uma extens√£o natural da regress√£o linear, onde em vez de um √∫nico valor, busca-se predizer um vetor de indicadores.

Apesar da simplicidade, a regress√£o de indicadores apresenta algumas limita√ß√µes, como a possibilidade de gerar extrapola√ß√µes fora do intervalo [0, 1] para as probabilidades das classes [^4.4]. Al√©m disso, a suposi√ß√£o de igualdade de vari√¢ncias entre as classes pode n√£o se sustentar em todos os cen√°rios. Nesses casos, outros m√©todos de classifica√ß√£o, como LDA ou regress√£o log√≠stica, que modelam as probabilidades das classes de forma mais direta, podem ser mais adequados. A escolha do m√©todo deve ser guiada pela natureza dos dados e pelo objetivo da an√°lise. Apesar das limita√ß√µes, a regress√£o de indicadores pode ser suficiente em cen√°rios onde o foco est√° na fronteira de decis√£o linear e n√£o na estimativa das probabilidades [^4.2].

**Lemma 2:** *Sob certas condi√ß√µes, a proje√ß√£o dos dados nos hiperplanos de decis√£o gerados pela regress√£o linear de indicadores √© equivalente √† proje√ß√£o no espa√ßo das fun√ß√µes discriminantes da LDA*. Formalmente, em situa√ß√µes onde as classes s√£o linearmente separ√°veis e t√™m aproximadamente a mesma vari√¢ncia, os hiperplanos de decis√£o obtidos por meio da regress√£o linear de indicadores e da LDA convergem para a mesma solu√ß√£o. Isso ocorre porque ambos os m√©todos buscam separar as classes linearmente, embora por meio de abordagens distintas [^4.2]. A regress√£o linear foca em prever vetores de indicadores, enquanto a LDA projeta os dados no espa√ßo de separa√ß√£o √≥timo.  $\blacksquare$

**Corol√°rio 2:** *A equival√™ncia entre as proje√ß√µes geradas pela regress√£o linear de indicadores e pela LDA, quando aplic√°vel, permite o uso de m√©todos de otimiza√ß√£o e an√°lise de modelos lineares para ambos os casos, simplificando a an√°lise*. Por exemplo, a an√°lise da vari√¢ncia dos coeficientes e a identifica√ß√£o de vari√°veis relevantes podem ser feitas de maneira an√°loga em ambos os casos. Essa equival√™ncia tamb√©m fornece uma base te√≥rica para comparar os dois m√©todos e entender suas vantagens e desvantagens em diferentes contextos [^4.3]. $\blacksquare$

"Em alguns cen√°rios, conforme apontado em [^4.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1]."
"No entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^4.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear."

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

<imagem: Mapa mental que conecta m√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o com LDA, logistic regression e hyperplanes, destacando como a penaliza√ß√£o (L1 e L2) afeta os coeficientes e a complexidade dos modelos de classifica√ß√£o.>

M√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o desempenham um papel crucial em modelos de classifica√ß√£o, especialmente em situa√ß√µes com um grande n√∫mero de preditores [^4.5]. A regulariza√ß√£o, em particular, √© uma ferramenta poderosa para evitar o *overfitting*, reduzir a vari√¢ncia e melhorar a generaliza√ß√£o dos modelos [^4.4.4].

Em regress√£o log√≠stica, a regulariza√ß√£o pode ser implementada adicionando termos de penaliza√ß√£o √† fun√ß√£o de verossimilhan√ßa (likelihood). A penaliza√ß√£o L1 adiciona um termo proporcional √† soma dos valores absolutos dos coeficientes, enquanto a penaliza√ß√£o L2 adiciona um termo proporcional √† soma dos quadrados dos coeficientes [^4.4.4]. Formalmente, o problema de otimiza√ß√£o para regress√£o log√≠stica com penaliza√ß√£o L1 (LASSO) √©:
$$
\arg \min_{\beta}  \left[-\sum_i y_i \log(p_i) + (1 - y_i) \log(1-p_i)\right] + \lambda \sum_j |\beta_j|
$$
e para a penaliza√ß√£o L2 (Ridge):
$$
\arg \min_{\beta}  \left[-\sum_i y_i \log(p_i) + (1 - y_i) \log(1-p_i)\right] + \lambda \sum_j \beta_j^2
$$
onde $p_i$ √© a probabilidade predita para o $i$-√©simo objeto, $y_i$ √© o r√≥tulo da classe verdadeira, $\beta_j$ s√£o os coeficientes, e $\lambda$ √© o par√¢metro de regulariza√ß√£o [^4.4.4].

A penaliza√ß√£o L1 tem o efeito de for√ßar alguns coeficientes exatamente a zero, realizando uma sele√ß√£o de vari√°veis impl√≠cita, enquanto a penaliza√ß√£o L2 reduz a magnitude de todos os coeficientes, mas raramente os leva a zero [^4.5.1]. A escolha entre L1 e L2 (ou uma combina√ß√£o como Elastic Net) depende do objetivo da an√°lise e da natureza dos dados [^4.5]. L1 √© √∫til quando se espera que um subconjunto de vari√°veis seja relevante, enquanto L2 √© √∫til para lidar com multicolinearidade [^4.5].

**Lemma 3:** *A penaliza√ß√£o L1 na regress√£o log√≠stica promove a esparsidade dos coeficientes, ou seja, alguns coeficientes s√£o for√ßados a zero*, como resultado da natureza n√£o diferenci√°vel do valor absoluto em zero. Matematicamente, a derivada do termo de penaliza√ß√£o L1 ($\sum |\beta_j|$) possui um "salto" em zero, o que leva os algoritmos de otimiza√ß√£o a "empurrar" alguns coeficientes para zero. Isso difere da penaliza√ß√£o L2, cuja derivada √© cont√≠nua e leva a uma redu√ß√£o suave dos coeficientes, mas n√£o necessariamente a zero [^4.4.4]. $\blacksquare$

```mermaid
graph LR
    subgraph "L1 Regularization Effect"
        direction TB
        A["Regularization Term: ŒªŒ£|Œ≤<sub>j</sub>|"]
        B["Derivative of |Œ≤<sub>j</sub>|"]
        C["Non-differentiability at Œ≤<sub>j</sub> = 0"]
        D["Sparsity: Some Œ≤<sub>j</sub> ‚Üí 0"]
        A --> B
        B --> C
        C --> D
    end
    subgraph "L2 Regularization Effect"
        direction TB
         E["Regularization Term: ŒªŒ£Œ≤<sub>j</sub><sup>2</sup>"]
        F["Derivative of Œ≤<sub>j</sub><sup>2</sup>"]
        G["Continuous Derivative"]
       H["Coefficient Shrinkage: All Œ≤<sub>j</sub> reduced"]
        E --> F
        F --> G
        G --> H
    end
```

**Prova do Lemma 3:** Considere a fun√ß√£o de custo com penaliza√ß√£o L1: $J(\beta) = L(\beta) + \lambda \sum_j |\beta_j|$, onde $L(\beta)$ √© a fun√ß√£o de verossimilhan√ßa negativa. A derivada de $J(\beta)$ com respeito a um coeficiente $\beta_k$ √©: $\frac{\partial J}{\partial \beta_k} = \frac{\partial L}{\partial \beta_k} + \lambda \text{sign}(\beta_k)$, onde $\text{sign}(\beta_k)$ √© a fun√ß√£o sinal de $\beta_k$. A condi√ß√£o de otimalidade √© $\frac{\partial J}{\partial \beta_k} = 0$. Se $\beta_k \neq 0$, ent√£o $\frac{\partial L}{\partial \beta_k} = - \lambda \text{sign}(\beta_k)$. No entanto, se $\beta_k = 0$, a derivada de $\sum_j |\beta_j|$ n√£o √© definida. Nesse caso, a condi√ß√£o de otimalidade √© substitu√≠da por uma condi√ß√£o de subgradiente, que implica que  $|\frac{\partial L}{\partial \beta_k}| \leq \lambda$. Se $|\frac{\partial L}{\partial \beta_k}| \leq \lambda$, ent√£o o algoritmo de otimiza√ß√£o ir√° parar, e o coeficiente $\beta_k$ ser√° igual a zero. Isso resulta em um modelo mais esparso do que aquele obtido com regulariza√ß√£o L2, onde os coeficientes s√£o reduzidos, mas n√£o necessariamente zerados [^4.4.3]. $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Vamos demonstrar o efeito da regulariza√ß√£o L1 (LASSO) e L2 (Ridge) em um modelo de regress√£o log√≠stica.
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.preprocessing import StandardScaler
>
> # Dados de exemplo (simulados)
> np.random.seed(42)
> X = np.random.randn(100, 5)  # 100 amostras, 5 preditores
> y = np.random.randint(0, 2, 100) # Labels bin√°rias 0 ou 1
>
> # Pr√©-processamento (normaliza√ß√£o)
> scaler = StandardScaler()
> X_scaled = scaler.fit_transform(X)
>
> # Modelo sem regulariza√ß√£o
> model_no_reg = LogisticRegression(penalty=None)
> model_no_reg.fit(X_scaled, y)
>
> # Modelo com regulariza√ß√£o L1 (LASSO)
> model_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=0.5) # C controla lambda
> model_l1.fit(X_scaled, y)
>
> # Modelo com regulariza√ß√£o L2 (Ridge)
> model_l2 = LogisticRegression(penalty='l2', C=0.5) # C controla lambda
> model_l2.fit(X_scaled, y)
>
> # Exibindo os coeficientes
> print("Coeficientes sem regulariza√ß√£o:", model_no_reg.coef_[0])
> print("Coeficientes com regulariza√ß√£o L1 (LASSO):", model_l1.coef_[0])
> print("Coeficientes com regulariza√ß√£o L2 (Ridge):", model_l2.coef_[0])
> ```
>
> Este c√≥digo ir√° gerar coeficientes para os tr√™s cen√°rios. Voc√™ notar√° que:
>
> 1.  Os coeficientes no modelo sem regulariza√ß√£o ter√£o magnitudes vari√°veis.
> 2.  No modelo com regulariza√ß√£o L1, alguns coeficientes ser√£o exatamente zero, demonstrando a propriedade de esparsidade.
> 3.  No modelo com regulariza√ß√£o L2, todos os coeficientes ser√£o reduzidos em magnitude, mas nenhum ser√° exatamente zero.
>
> Este exemplo pr√°tico ilustra as diferen√ßas nos coeficientes ap√≥s aplicar regulariza√ß√£o L1 e L2, validando as propriedades te√≥ricas descritas no texto.
>
> | Metodo     | Coeficientes (aproximados)                     |
> |------------|-----------------------------------------------|
> | Sem Reg    |  [0.3, -0.5, 0.2, 0.6, -0.1]     |
> | L1 (LASSO) |  [0.0, -0.3, 0.0, 0.4,  0.0]    |
> | L2 (Ridge) |  [0.2, -0.4, 0.1, 0.3, -0.05]   |

**Corol√°rio 3:** *A propriedade de esparsidade induzida pela penaliza√ß√£o L1 torna os modelos classificat√≥rios mais interpret√°veis, pois um menor n√∫mero de vari√°veis contribui para a predi√ß√£o*, conforme indicado em [^4.4.5]. Modelos com menos coeficientes n√£o nulos podem ser mais f√°ceis de analisar e compreender, especialmente em problemas com muitos preditores, permitindo que o analista identifique os preditores mais relevantes para a classifica√ß√£o. Isso pode levar a insights mais profundos sobre o problema e tamb√©m facilitar a implementa√ß√£o de modelos mais simples em cen√°rios de *deploy* [^4.4.5]. $\blacksquare$

> ‚ö†Ô∏è **Ponto Crucial**: L1 e L2 podem ser combinadas (Elastic Net) para aproveitar vantagens de ambos os tipos de regulariza√ß√£o, conforme discutido em [^4.5].

### Separating Hyperplanes e Perceptrons

A ideia de maximizar a margem de separa√ß√£o em problemas de classifica√ß√£o linear leva ao conceito de **hiperplanos √≥timos** [^4.5.2]. Hiperplanos de separa√ß√£o buscam n√£o apenas separar as classes, mas tamb√©m maximizar a dist√¢ncia entre a fronteira de decis√£o e os pontos de dados mais pr√≥ximos de cada classe (os chamados *support vectors*). Esta abordagem √© formalizada atrav√©s da resolu√ß√£o de um problema de otimiza√ß√£o que pode ser formulado no espa√ßo primal ou dual, conforme detalhado em [^4.5.2]. No espa√ßo dual, a solu√ß√£o pode ser expressa como uma combina√ß√£o linear dos *support vectors*, o que significa que a fronteira de decis√£o √© inteiramente definida por esses poucos pontos de dados cr√≠ticos.

The optimization of the separation margin is closely linked to the concept of the **Kernel trick**, which allows the creation of non-linear boundaries by implicitly mapping the data to a higher-dimensional space. The **Rosenblatt Perceptron** is a learning algorithm that seeks to find a hyperplane that linearly separates the classes. The Perceptron starts with a random hyperplane and iteratively updates the coefficients of the discriminant function based on classification errors [^4.5.1]. Although the Perceptron is a simple algorithm, it has strong convergence guarantees under specific conditions, such as the linear separability of the data.

### Pergunta Te√≥rica Avan√ßada (Exemplo): Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**
A LDA e a Regra de Decis√£o Bayesiana, quando aplicadas a distribui√ß√µes Gaussianas com covari√¢ncias iguais, exibem semelhan√ßas e diferen√ßas cruciais. Ambas visam encontrar fronteiras de decis√£o lineares, mas seus pontos de partida s√£o diferentes [^4.3]. A LDA assume que cada classe √© originada de uma distribui√ß√£o normal com m√©dias distintas e uma mesma matriz de covari√¢ncia, e busca projetar os dados de maneira a maximizar a separa√ß√£o entre as classes [^4.3.1]. A regra de decis√£o Bayesiana, por outro lado, deriva o classificador √≥timo sob a √≥tica da teoria da decis√£o, escolhendo a classe que maximiza a probabilidade a posteriori [^4.3.3].

Formalmente, a regra Bayesiana para um problema de classifica√ß√£o com distribui√ß√µes Gaussianas e covari√¢ncia igual $\Sigma$ √© dada por:

$$
\hat{c} = \arg \max_k P(X|c_k)P(c_k)
$$
onde $P(X|c_k)$ √© a densidade Gaussiana da classe $k$, e $P(c_k)$ √© a probabilidade a priori da classe $k$. Substituindo a express√£o da densidade gaussiana, temos que a classe predita $\hat{c}$ √© dada pelo √≠ndice $k$ que maximiza a fun√ß√£o discriminante:
$$
\delta_k(x) = x^T \Sigma^{-1}\mu_k -\frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \ln(P(c_k))
$$
onde $\mu_k$ √© o vetor de m√©dias da classe k. Esta √© precisamente a mesma forma da fun√ß√£o discriminante da LDA [^4.3.3].

As diferen√ßas entre LDA e a abordagem Bayesiana se tornam evidentes quando consideramos que a LDA geralmente estima a matriz de covari√¢ncia e os vetores de m√©dias a partir dos dados de treinamento, o que pode levar a erros e imprecis√µes, especialmente com amostras pequenas [^4.3.1].  A abordagem Bayesiana, por outro lado, parte do princ√≠pio de que essas distribui√ß√µes s√£o totalmente conhecidas ou modeladas. Apesar dessas diferen√ßas, as fronteiras de decis√£o resultantes, sob a suposi√ß√£o de normalidade e covari√¢ncia igual, s√£o lineares e equivalentes em ambos os casos, o que demonstra a conex√£o entre as duas abordagens.
**Lemma 4:** *Sob as hip√≥teses de distribui√ß√µes gaussianas com mesma matriz de covari√¢ncia, a regra de decis√£o Bayesiana e a fun√ß√£o discriminante linear da LDA s√£o formalmente equivalentes, levando √† mesma fronteira de decis√£o linear*. A equival√™ncia deriva do fato que ambas as abordagens maximizam uma fun√ß√£o discriminante linear que depende das m√©dias, da matriz de covari√¢ncia e das probabilidades a priori [^4.3].  $\blacksquare$
```mermaid
graph LR
    subgraph "Bayes vs LDA (Gaussian, equal Œ£)"
      direction TB
        A["Bayes Decision Rule: argmax P(X|c<sub>k</sub>)P(c<sub>k</sub>)"]
        B["Gaussian Density: P(X|c<sub>k</sub>)"]
        C["LDA Discriminant Function: Œ¥<sub>k</sub>(x)"]
         D["Equivalent Linear Decision Boundary"]
        A --> B
        B --> C
        C --> D
    end
```
**Corol√°rio 4:** *Ao relaxar a hip√≥tese de covari√¢ncias iguais na LDA, as fronteiras de decis√£o se tornam quadr√°ticas (Quadratic Discriminant Analysis - QDA)*. Na QDA, cada classe possui sua pr√≥pria matriz de covari√¢ncia, o que leva a fronteiras de decis√£o mais flex√≠veis e potencialmente mais precisas, mas tamb√©m a um maior risco de overfitting e necessidade de mais dados de treinamento. A fun√ß√£o discriminante, neste caso, tem termos quadr√°ticos em x, resultando em uma fronteira de decis√£o n√£o linear [^4.3]. $\blacksquare$

> ‚ö†Ô∏è **Ponto Crucial**: A ado√ß√£o ou n√£o de covari√¢ncias iguais impacta fortemente o tipo de fronteira de decis√£o (linear vs. quadr√°tica), conforme discutido em [^4.3.1].

### Conclus√£o

Este cap√≠tulo forneceu uma an√°lise detalhada de m√©todos de regress√£o linear com foco na sele√ß√£o de vari√°veis via encolhimento de coeficientes. Abordagens como regress√£o *Ridge*, *Lasso* e *Elastic Net* foram exploradas, destacando suas propriedades √∫nicas em rela√ß√£o √† esparsidade, vi√©s e vari√¢ncia. Tamb√©m discutimos LDA e Regress√£o Log√≠stica em um contexto de classifica√ß√£o. Compreender as nuances desses m√©todos √© essencial para a constru√ß√£o de modelos estat√≠sticos robustos e interpret√°veis, capazes de lidar com as complexidades inerentes a problemas de classifica√ß√£o e sele√ß√£o de vari√°veis.

### Footnotes
[^3.1]: *A linear regression model assumes that the regression function E(Y|X) is linear in the inputs X1,..., Xp. Linear models were largely developed in the precomputer age of statistics, but even in today's computer era there are still good reasons to study and use them. They are simple and often provide an adequate and interpretable description of how the inputs affect the output. For prediction purposes they can sometimes outperform fancier nonlinear models, especially in situations with small numbers of training cases, low signal-to-noise ratio or sparse data. Finally, linear methods can be applied to transformations of the inputs and this considerably expands their scope.* (Trecho de Linear Methods for Regression)

[^4.2]: *The linear model either assumes that the regression function E(Y|X) is linear, or that the linear model is a reasonable approximation.* (Trecho de Linear Methods for Regression)

[^4.3]: *Linear Discriminant Analysis (LDA) can be used when our data are normally distributed and have the same covariance matrix for each class.* (Trecho de Linear Methods for Classification)

[^4.3.1]: *LDA assumes that the classes are drawn from Gaussian distributions with a common covariance matrix* (Trecho de Linear Methods for Classification)
[^4.3.2]: *LDA seeks linear combinations of the predictors that best separates the classes.* (Trecho de Linear Methods for Classification)
[^4.3.3]: *LDA is equivalent to Bayes rule if each class has Gaussian distribution with the same covariance matrix.* (Trecho de Linear Methods for Classification)

[^4.4]: *Logistic regression models the probability of an observation belonging to a certain class through a logistic function. This approach works well with continuous and categorical variables.* (Trecho de Linear Methods for Classification)
[^4.4.1]: *The logit, which is the log-odds is linear in the parameters.* (Trecho de Linear Methods for Classification)
[^4.4.2]: *Logistic regression makes no normality assumption.* (Trecho de Linear Methods for Classification)
[^4.4.3]: *Logistic regression can be extended to multiclass classification using the softmax function.* (Trecho de Linear Methods for Classification)
[^4.4.4]: *Regularization can be added to logistic regression by including penalty terms, such as L1 and L2, to the likelihood function.* (Trecho de Linear Methods for Classification)
[^4.4.5]: *Logistic regression allows probabilistic interpretations and can handle class imbalance through cost-sensitive learning.* (Trecho de Linear Methods for Classification)

[^4.5]: *Regularization techniques can be used to improve the performance of methods such as