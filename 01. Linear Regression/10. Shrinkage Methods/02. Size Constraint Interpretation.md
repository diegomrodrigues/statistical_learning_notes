## M√©todos Lineares para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Linear Classification Overview"
        direction TB
        A["Classification Problem"] --> B["Linear Models"]
        B --> C["Hyperplane Decision Boundary"]
        C --> D["Trade-off: Bias vs Variance"]
        D --> E["Interpretability and Performance"]
    end
```

### Introdu√ß√£o

Este cap√≠tulo aborda m√©todos lineares para classifica√ß√£o, explorando a sua relev√¢ncia no contexto da an√°lise discriminante. Os modelos lineares, apesar de sua simplicidade, oferecem uma base s√≥lida para a compreens√£o de t√©cnicas mais complexas [^4.1]. Eles permitem uma an√°lise interpret√°vel das rela√ß√µes entre os preditores e a vari√°vel de resposta, e, em muitos casos, podem apresentar um desempenho compar√°vel ou at√© superior a modelos n√£o lineares, especialmente quando se tem um n√∫mero limitado de dados, baixa rela√ß√£o sinal-ru√≠do ou dados esparsos [^4.1]. O estudo detalhado desses m√©todos lineares √© fundamental para o desenvolvimento de uma intui√ß√£o s√≥lida em aprendizado de m√°quina e para a compreens√£o de diversas generaliza√ß√µes n√£o lineares [^4.1].

### Conceitos Fundamentais

**Conceito 1:** O problema de classifica√ß√£o consiste em atribuir uma classe a cada observa√ß√£o com base em um conjunto de preditores. Em m√©todos lineares, assume-se que a fronteira de decis√£o entre classes pode ser definida por um hiperplano. A escolha por m√©todos lineares implica em um *trade-off* entre vi√©s e vari√¢ncia [^4.1]. Modelos lineares tendem a ter um vi√©s maior, pois imp√µem uma estrutura mais restrita, mas podem apresentar menor vari√¢ncia, o que √© desej√°vel em muitas situa√ß√µes. Por exemplo, se a rela√ß√£o entre as vari√°veis de entrada e a vari√°vel de sa√≠da for aproximadamente linear, um modelo linear pode ser suficiente e, em muitos casos, prefer√≠vel a um modelo n√£o linear complexo [^4.1].

> üí° **Exemplo Num√©rico:** Considere um conjunto de dados com duas classes, onde a classe 1 tem um centro em (2, 2) e a classe 2 tem um centro em (5, 5), ambas com uma pequena vari√¢ncia. Um modelo linear pode separar essas classes com um hiperplano. Um modelo n√£o linear poderia se ajustar perfeitamente aos dados de treinamento, mas generalizaria pior para dados novos. Este √© um exemplo do trade-off entre vi√©s e vari√¢ncia: um modelo linear pode ter um vi√©s maior (n√£o se ajusta perfeitamente aos dados de treinamento), mas tem uma vari√¢ncia menor (generaliza melhor para novos dados).

**Lemma 1:** Em problemas de classifica√ß√£o com duas classes, uma fun√ß√£o discriminante linear pode ser definida como uma proje√ß√£o dos dados em um vetor normal ao hiperplano de decis√£o. Esta proje√ß√£o maximiza a separabilidade entre as classes, desde que as classes sejam razoavelmente bem separadas por um hiperplano.

> $$f(x) = w^Tx + b$$

Onde:

-   $f(x)$ √© a fun√ß√£o discriminante linear.
-   $w$ √© o vetor de pesos, normal ao hiperplano.
-   $x$ √© o vetor de preditores.
-   $b$ √© o *bias* ou *intercept*.

A fun√ß√£o discriminante pode ser usada para decidir a qual classe pertence uma observa√ß√£o. Por exemplo, se $f(x) > 0$, a observa√ß√£o √© classificada como pertencente √† primeira classe e, caso contr√°rio, √† segunda classe [^4.3].

```mermaid
graph LR
    subgraph "Linear Discriminant Function"
        direction TB
        A["Input Vector x"] --> B["Weight Vector w"]
        A --> C["Bias term b"]
        B & C --> D["Linear Function f(x) = w^Tx + b"]
        D --> E["Classification: f(x) > 0 (Class 1), f(x) <= 0 (Class 2)"]
    end
```

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo linear com $w = [1, -1]$ e $b = -1$. Um ponto $x_1 = [2, 1]$ ter√° $f(x_1) = (1*2) + (-1*1) - 1 = 0$. Este ponto estaria exatamente na fronteira de decis√£o. J√° um ponto $x_2 = [3, 1]$ ter√° $f(x_2) = (1*3) + (-1*1) - 1 = 1 > 0$, sendo classificado como pertencente √† primeira classe. Por outro lado, o ponto $x_3 = [2, 3]$ ter√° $f(x_3) = (1*2) + (-1*3) - 1 = -2 < 0$, e seria classificado na segunda classe.

**Conceito 2:** A **Linear Discriminant Analysis (LDA)** √© um m√©todo cl√°ssico para classifica√ß√£o que assume que as classes seguem uma distribui√ß√£o normal multivariada com a mesma matriz de covari√¢ncia [^4.3]. O m√©todo busca encontrar a melhor combina√ß√£o linear de preditores que maximize a separa√ß√£o entre as m√©dias das classes, e minimiza a vari√¢ncia dentro de cada classe [^4.3.1]. Formalmente, a regra de decis√£o do LDA √© dada por:

> $$\delta_k(x) = x^T \Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T \Sigma^{-1}\mu_k + \log(\pi_k)$$

Onde:

-   $\delta_k(x)$ √© a fun√ß√£o discriminante para a classe $k$.
-   $x$ √© o vetor de preditores.
-   $\Sigma$ √© a matriz de covari√¢ncia comum das classes.
-   $\mu_k$ √© o vetor de m√©dias da classe $k$.
-   $\pi_k$ √© a probabilidade *a priori* da classe $k$.

Para classificar uma observa√ß√£o $x$, calculamos $\delta_k(x)$ para todas as classes $k$ e atribu√≠mos $x$ √† classe com o maior valor de $\delta_k(x)$ [^4.3.2].

```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction TB
        A["Input x"] --> B["Common Covariance Matrix Œ£"]
        A --> C["Mean Vector Œº_k"]
        C --> D["Prior Probability œÄ_k"]
        B & C & D --> E["Discriminant Function Œ¥_k(x) = x^TŒ£‚Åª¬πŒº_k - 1/2Œº_k^TŒ£‚Åª¬πŒº_k + log(œÄ_k)"]
    end
```

> üí° **Exemplo Num√©rico:** Vamos supor um caso simplificado com duas classes e dois preditores. Classe 1 tem $\mu_1 = [1, 1]$ e Classe 2 tem $\mu_2 = [3, 3]$. A matriz de covari√¢ncia comum √© $\Sigma = [[1, 0], [0, 1]]$ (uma matriz identidade para simplifica√ß√£o). As probabilidades a priori s√£o $\pi_1 = 0.6$ e $\pi_2 = 0.4$. Para classificar um novo ponto $x = [2, 2]$:

> $\Sigma^{-1} = [[1, 0], [0, 1]]$
> $\delta_1(x) = [2, 2]^T [[1, 0], [0, 1]] [1, 1] - \frac{1}{2}[1, 1]^T [[1, 0], [0, 1]] [1, 1] + \log(0.6) = 4 - 1 + \log(0.6) \approx 2.51$
> $\delta_2(x) = [2, 2]^T [[1, 0], [0, 1]] [3, 3] - \frac{1}{2}[3, 3]^T [[1, 0], [0, 1]] [3, 3] + \log(0.4) = 12 - 9 + \log(0.4) \approx 2.08$
>
> Como $\delta_1(x) > \delta_2(x)$, o ponto $x$ seria classificado como pertencente √† Classe 1.

**Corol√°rio 1:** Quando as classes compartilham a mesma matriz de covari√¢ncia, a fronteira de decis√£o entre duas classes no LDA √© um hiperplano linear, o que simplifica a an√°lise e a implementa√ß√£o do modelo. A linearidade da fronteira surge devido √† estrutura compartilhada da matriz de covari√¢ncia, permitindo que a decis√£o seja baseada na diferen√ßa entre as m√©dias das classes. A demonstra√ß√£o detalhada disso est√° em [^4.3.3].

**Conceito 3:** A **Logistic Regression** √© um modelo de classifica√ß√£o que estima a probabilidade de uma observa√ß√£o pertencer a uma classe por meio de uma transforma√ß√£o log√≠stica da combina√ß√£o linear dos preditores [^4.4]. A fun√ß√£o log√≠stica, ou logit, transforma qualquer valor real em um valor entre 0 e 1, que pode ser interpretado como uma probabilidade [^4.4.1]. O modelo log√≠stico √© definido como:

> $$p(x) = \frac{1}{1 + e^{-(\beta_0 + \beta^T x)}}$$

Onde:

-   $p(x)$ √© a probabilidade de $x$ pertencer a uma classe.
-   $\beta_0$ √© o *bias*.
-   $\beta$ √© o vetor de pesos.
-   $x$ √© o vetor de preditores.

A fun√ß√£o de verossimilhan√ßa para a regress√£o log√≠stica √© dada por:

> $$L(\beta) = \prod_{i=1}^N p(x_i)^{y_i}(1-p(x_i))^{1-y_i}$$

Onde $y_i$ √© a classe observada, que pode ser 0 ou 1. Os par√¢metros s√£o estimados maximizando a fun√ß√£o de verossimilhan√ßa ou sua vers√£o logar√≠tmica. O processo de otimiza√ß√£o normalmente envolve m√©todos iterativos como o gradiente descendente ou o m√©todo de Newton-Raphson [^4.4.3].

```mermaid
graph LR
 subgraph "Logistic Regression Model"
  direction TB
    A["Input Vector x"] --> B["Weight Vector Œ≤"]
    A --> C["Bias Œ≤_0"]
    B & C --> D["Linear Combination: Œ≤_0 + Œ≤^Tx"]
    D --> E["Logistic Function: p(x) = 1 / (1 + e^(-(Œ≤_0 + Œ≤^Tx)))"]
    E --> F["Probability p(x) of belonging to a class"]
 end
```

> üí° **Exemplo Num√©rico:** Suponha que um modelo de regress√£o log√≠stica foi treinado, resultando em $\beta_0 = -2$ e $\beta = [1, 0.5]$. Dado um ponto $x = [3, 2]$, a probabilidade de pertencer √† classe 1 seria:

> $p(x) = \frac{1}{1 + e^{-(-2 + (1*3) + (0.5*2))}} = \frac{1}{1 + e^{-( -2 + 3 + 1)}} = \frac{1}{1 + e^{-2}} \approx \frac{1}{1 + 0.135} \approx 0.88$

> Isso significa que o modelo prev√™ uma probabilidade de 88% do ponto x pertencer √† classe 1.

> ‚ö†Ô∏è **Nota Importante**: A regress√£o log√≠stica n√£o assume a mesma distribui√ß√£o normal dos dados como o LDA, o que a torna mais robusta em rela√ß√£o a desvios dessa premissa [^4.4.1].

> ‚ùó **Ponto de Aten√ß√£o**: Em problemas de classifica√ß√£o com classes desbalanceadas, √© importante ajustar os pesos das classes na regress√£o log√≠stica para evitar um modelo enviesado em dire√ß√£o √† classe majorit√°ria [^4.4.2].

> ‚úîÔ∏è **Destaque**: Em muitos casos, a regress√£o log√≠stica e o LDA fornecem resultados muito parecidos, especialmente quando a matriz de covari√¢ncia √© similar entre as classes, embora a interpreta√ß√£o dos coeficientes possa ser diferente [^4.5].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
 subgraph "Linear Regression for Classification"
    direction TB
    A["Input Data with Class Indicators"] --> B["Least Squares Estimation of Coefficients"]
    B --> C["Application of Decision Rule"]
    C --> D["Comparison with Probabilistic Methods"]
 end
```

A regress√£o linear pode ser aplicada para classifica√ß√£o utilizando uma matriz de indicadores, onde cada coluna corresponde a uma classe e as entradas s√£o 1 para a classe a qual a observa√ß√£o pertence e 0 caso contr√°rio. O problema de classifica√ß√£o √© ent√£o transformado em um problema de regress√£o, onde cada classe √© tratada como uma vari√°vel dependente [^4.2]. Os par√¢metros s√£o estimados por meio do m√©todo de m√≠nimos quadrados, minimizando a soma dos quadrados dos res√≠duos [^4.2]:

> $$RSS(\beta) = \sum_{i=1}^N (y_i - x_i^T\beta)^2$$

onde:

-   $RSS(\beta)$ √© a soma dos quadrados dos res√≠duos.
-   $y_i$ √© o vetor indicador da classe da observa√ß√£o $i$.
-   $x_i$ √© o vetor de preditores da observa√ß√£o $i$.
-   $\beta$ √© a matriz de coeficientes a ser estimada.

As predi√ß√µes s√£o ent√£o obtidas usando a regress√£o linear para cada classe. A classe de uma dada observa√ß√£o √© determinada pela maior predi√ß√£o entre as classes. A principal limita√ß√£o desse m√©todo √© que as predi√ß√µes da regress√£o linear n√£o s√£o limitadas entre 0 e 1, o que dificulta a interpreta√ß√£o como probabilidades [^4.2]. Al√©m disso, quando a classe √© representada por um indicador "dummy" (1 e 0), pode haver problemas na interpreta√ß√£o dos par√¢metros, pois as classes podem ser consideradas ordenadas (o que n√£o √© o caso, por exemplo, quando as classes s√£o "vermelho", "verde" e "azul").

> üí° **Exemplo Num√©rico:** Considere um conjunto de dados com 3 observa√ß√µes e 2 classes. Os dados e as classes s√£o:
> - $x_1 = [1, 2]$, $y_1 = [1, 0]$ (Classe 1)
> - $x_2 = [2, 1]$, $y_2 = [0, 1]$ (Classe 2)
> - $x_3 = [3, 3]$, $y_3 = [1, 0]$ (Classe 1)
>  Podemos criar matrizes $X$ e $Y$:
> $$ X = \begin{bmatrix} 1 & 1 & 2 \\ 1 & 2 & 1 \\ 1 & 3 & 3 \end{bmatrix}, \quad Y = \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix} $$
>  Aqui, a primeira coluna de X s√£o os interceptos. Os coeficientes $\beta$ s√£o estimados minimizando o RSS. Usando numpy para os c√°lculos:
> ```python
> import numpy as np
> from sklearn.linear_model import LinearRegression
>
> X = np.array([[1, 1, 2], [1, 2, 1], [1, 3, 3]])
> Y = np.array([[1, 0], [0, 1], [1, 0]])
>
> model = LinearRegression()
> model.fit(X, Y)
> beta = model.coef_
> intercept = model.intercept_
> print("Coefficients (beta):\n", beta)
> print("Intercept:", intercept)
> ```
> Isso resultar√° em coeficientes $\beta$ que, quando multiplicados por um novo vetor de preditores, dariam uma predi√ß√£o para cada classe.  Por exemplo, para um novo ponto $x_4 = [2, 2]$ (incluindo o intercepto), as predi√ß√µes seriam:
>
> $y_{pred} = \begin{bmatrix} 1 & 2 & 2 \end{bmatrix} \begin{bmatrix} 0.833 & -0.167 \\ -0.167 & 0.5 \\  -0.167 & -0.167 \end{bmatrix} + intercept  \approx \begin{bmatrix} 0.5 & 0.5 \end{bmatrix} + \begin{bmatrix} 0.167 & 0.333 \end{bmatrix} = \begin{bmatrix} 0.667 & 0.833 \end{bmatrix}$
>
> Como a segunda predi√ß√£o √© maior (0.833 > 0.667), o modelo classificaria o ponto como pertencente √† classe 2.

**Lemma 2:** Em um problema de classifica√ß√£o com duas classes, se a fronteira de decis√£o resultante da regress√£o linear com matriz de indicadores for um hiperplano, ela √© equivalente √† fronteira de decis√£o obtida por um discriminante linear em certas condi√ß√µes de distribui√ß√£o dos dados (por exemplo, dados gaussianos com mesma covari√¢ncia entre as classes) [^4.2], [^4.3].

**Prova:** A prova envolve mostrar que a solu√ß√£o de m√≠nimos quadrados para o modelo de regress√£o de indicadores pode ser escrita em termos das m√©dias das classes e da matriz de covari√¢ncia, que s√£o tamb√©m os componentes fundamentais da fun√ß√£o discriminante linear do LDA.

**Corol√°rio 2:** O Lemma 2 implica que, em algumas condi√ß√µes espec√≠ficas, a regress√£o linear e o LDA (Linear Discriminant Analysis) produzem resultados similares em termos da fronteira de decis√£o, embora suas interpreta√ß√µes e pressupostos possam ser diferentes. A regress√£o de indicadores pode ser uma forma de obter uma aproxima√ß√£o da fronteira de decis√£o em cen√°rios menos ideais [^4.3].

√â importante notar que, em situa√ß√µes com muitas classes ou quando as classes n√£o s√£o linearmente separ√°veis, a regress√£o linear de matriz de indicadores pode apresentar limita√ß√µes significativas. Em alguns cen√°rios, a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora do intervalo [0,1]. No entanto, h√° situa√ß√µes em que a regress√£o de indicadores pode ser suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Methods"
        direction TB
        A["L1 Regularization (Lasso)"]
        B["L2 Regularization (Ridge)"]
        C["Elastic Net"]
        A --> D["Feature Selection, Sparsity"]
        B --> E["Stability, Variance Reduction"]
        C --> F["Combination of L1 and L2"]
        D & E & F --> G["Application in Logistic Regression and LDA"]
    end
```

A sele√ß√£o de vari√°veis √© crucial em problemas de classifica√ß√£o com muitos preditores, visando identificar um subconjunto de vari√°veis relevantes que contribuam significativamente para a capacidade preditiva do modelo e para a interpreta√ß√£o dos resultados [^4.5]. A regulariza√ß√£o, em contrapartida, √© uma t√©cnica que adiciona uma penalidade √† fun√ß√£o de custo para controlar a complexidade do modelo e evitar *overfitting*.

Em particular, em modelos log√≠sticos, a regulariza√ß√£o pode ser implementada adicionando termos de penaliza√ß√£o √† fun√ß√£o de verossimilhan√ßa. A regulariza√ß√£o L1 (Lasso) adiciona uma penalidade proporcional √† soma dos valores absolutos dos coeficientes, enquanto a regulariza√ß√£o L2 (Ridge) adiciona uma penalidade proporcional √† soma dos quadrados dos coeficientes [^4.4.4]. A penaliza√ß√£o L1 tem a propriedade de levar alguns coeficientes a serem exatamente zero, realizando uma sele√ß√£o de vari√°veis impl√≠cita e produzindo modelos mais esparsos [^4.4.4]:

> $$ J(\beta) = - \sum_{i=1}^N (y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))) + \lambda \sum_{j=1}^p |\beta_j|$$

Enquanto a regulariza√ß√£o L2 tende a reduzir os valores dos coeficientes, mas raramente os leva a zero, o que resulta em modelos mais est√°veis e com menor vari√¢ncia [^4.4.4].

> $$J(\beta) = - \sum_{i=1}^N (y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))) + \lambda \sum_{j=1}^p \beta_j^2$$

A escolha entre regulariza√ß√£o L1 e L2 depende do problema espec√≠fico e dos objetivos do modelo. Em geral, L1 √© prefer√≠vel quando h√° muitas vari√°veis irrelevantes e busca-se *sparsity*, enquanto L2 √© mais adequada quando se deseja estabilidade e redu√ß√£o da vari√¢ncia.

> üí° **Exemplo Num√©rico:** Considere um modelo de regress√£o log√≠stica com dois preditores, onde os coeficientes estimados sem regulariza√ß√£o s√£o $\beta = [5, -3]$. Com regulariza√ß√£o L1, usando $\lambda = 1$, o custo para um modelo com $\beta = [4, -2]$  seria $-LogLikelihood + 1*(|4|+|-2|) = -LogLikelihood + 6 $.  Com um modelo com $\beta = [2, 0]$ o custo seria  $-LogLikelihood + 1*(|2|+|0|) = -LogLikelihood + 2 $. Note que a regulariza√ß√£o L1 pode levar alguns coeficientes a serem exatamente zero, como o segundo coeficiente neste exemplo. Com regulariza√ß√£o L2, usando $\lambda = 1$, o custo para um modelo com $\beta = [4, -2]$  seria $-LogLikelihood + 1*(4^2+(-2)^2) = -LogLikelihood + 20 $.  Com um modelo com $\beta = [2, 1]$ o custo seria $-LogLikelihood + 1*(2^2+1^2) = -LogLikelihood + 5 $. A regulariza√ß√£o L2 reduz os valores dos coeficientes, mas normalmente n√£o os leva a zero.

**Lemma 3:** Em um modelo de regress√£o log√≠stica regularizado com L1, a penalidade L1 na fun√ß√£o de custo pode levar a coeficientes esparsos, pois ela incentiva alguns coeficientes a serem exatamente zero [^4.4.4].

**Prova do Lemma 3:** A prova envolve analisar as condi√ß√µes de otimalidade da fun√ß√£o de custo com penalidade L1. A derivada da penalidade L1 √© uma fun√ß√£o sinal, o que implica que, para que a derivada total da fun√ß√£o de custo seja zero, alguns coeficientes devem ser iguais a zero, o que leva a um modelo esparso. Essa demonstra√ß√£o √© feita atrav√©s do estudo das condi√ß√µes de Karush-Kuhn-Tucker (KKT) [^4.4.3]. $\blacksquare$

**Corol√°rio 3:** A *sparsity* induzida pela regulariza√ß√£o L1 leva a modelos mais interpret√°veis, pois apenas as vari√°veis relevantes permanecem no modelo [^4.4.5]. Isso facilita a identifica√ß√£o dos preditores mais importantes e a compreens√£o das rela√ß√µes entre as vari√°veis de entrada e a vari√°vel de resposta.

A regulariza√ß√£o L1 e L2 podem ser combinadas usando o m√©todo Elastic Net, que adiciona ambas as penalidades, resultando em modelos que combinam as vantagens de ambas as abordagens [^4.5]:

> $$J(\beta) = - \sum_{i=1}^N (y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))) + \lambda (\alpha \sum_{j=1}^p |\beta_j| + (1-\alpha) \sum_{j=1}^p \beta_j^2)$$

> ‚ö†Ô∏è **Ponto Crucial**: L1 e L2 podem ser combinadas (Elastic Net) para aproveitar vantagens de ambos os tipos de regulariza√ß√£o [^4.5]. O par√¢metro Œ± controla a propor√ß√£o de L1 e L2 na penalidade.

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Optimal Separating Hyperplane"
        direction TB
        A["Maximize Margin"] --> B["Support Vectors"]
        B --> C["Objective Function: Minimize 1/2 ||Œ≤||¬≤"]
        C --> D["Constraints: y_i(Œ≤^Tx_i + b) >= 1"]
        D --> E["Solution via Convex Optimization"]
    end
```

A ideia de maximizar a margem de separa√ß√£o entre as classes leva ao conceito de **hiperplanos √≥timos**. Em vez de apenas encontrar um hiperplano que separa as classes, o objetivo √© encontrar o hiperplano que maximiza a dist√¢ncia entre as classes mais pr√≥ximas, tamb√©m conhecidos como **pontos de suporte** [^4.5.2]. Formalmente, o problema pode ser formulado como:

> $$\min_{\beta, b} \frac{1}{2} ||\beta||^2$$

> sujeito a:
> $$y_i(\beta^Tx_i + b) \geq 1 \ \forall i$$

Onde:

-   $\beta$ √© o vetor normal ao hiperplano.
-   $b$ √© o *bias*.
-   $x_i$ s√£o os preditores da observa√ß√£o $i$.
-   $y_i$ √© a classe da observa√ß√£o $i$, que assume valores de +1 e -1.

Este problema pode ser resolvido utilizando t√©cnicas de otimiza√ß√£o convexa, como o m√©todo do dual de Wolfe [^4.5.2]. O resultado √© que o hiperplano de decis√£o √© expresso como uma combina√ß√£o linear dos pontos de suporte.

```mermaid
graph LR
    subgraph "Perceptron Learning Algorithm"
        direction TB
        A["Initialize Weights Œ≤"] --> B["Iterate through Training Data"]
        B --> C{"Classify Observation"}
        C -- "Incorrect" --> D["Update Weights: Œ≤_(t+1) = Œ≤_t + Œ∑y_ix_i"]
        C -- "Correct" --> B
        D --> B
        B --> E["Convergence: Linear Separability"]
    end
```

O **Perceptron** de Rosenblatt √© um algoritmo de aprendizado de m√°quina simples que busca encontrar um hiperplano separador atrav√©s de um processo iterativo. Inicialmente, os pesos s√£o atribu√≠dos aleatoriamente. Em cada itera√ß√£o, o algoritmo verifica se as observa√ß√µes est√£o corretamente classificadas; se houver classifica√ß√£o incorreta, os pesos s√£o atualizados de acordo com a regra:

> $$\beta_{t+1} = \beta_t + \eta y_i x_i$$

Onde:

-   $\beta_t$ s√£o os pesos na itera√ß√£o $t$.
-   $\eta$ √© a taxa de aprendizagem.
-   $y_i$ √© a classe da observa√ß√£o $i$.
-   $x_i$ s√£o os preditores da observa√ß√£o $i$.

O perceptron garante converg√™ncia para um hiperplano separador se os dados forem linearmente separ√°veis e a taxa de aprendizagem for suficientemente pequena [^4.5.1]. Em caso de dados n√£o linearmente separ√°veis, o perceptron pode n√£o convergir.

> üí° **Exemplo Num√©rico:** Considere um problema com dois preditores e duas classes, com $x_1 = [1, 1]$, $y_1 = 1$ e $x_2 = [2, 3]$, $y_2 = -1$.  Inicializando $\beta = [0.1, -0.1]$ e $b=0$.
> Itera√ß√£o 1:
> - $y_1(\beta^Tx_1+b) = 1*(0.1*1 -0.1*1 + 0) = 0 < 1$.  Classifica√ß√£o incorreta.  Atualiza $\beta = [0.1, -0.1] + 0.1 * 1 * [1, 1] = [0.2, 0]$.
> - $y_2(\beta^Tx_2+b) = -1*(0.2*2 +0*3 +0) = -0.4 < 1 $.  Classifica√ß√£o incorreta.  Atualiza $\beta = [0.2, 0] + 0.1 * -1 * [2, 3] = [0, -0.3]$
>
> Itera√ß√£o 2:
> - $y_1(\beta^Tx_1+b) = 1*(0*1 -0.3*1 + 0) = -0.3 < 1$. Classifica√ß√£o incorreta. Atualiza $\beta = [0, -0.3] + 0.1 * 1 * [1, 1] = [0.1, -0.2]$.
>  - $y_2(\beta^Tx_2+b) = -1*(0.1*2 -0.2*3 +0) = -1*(-0.4) = 0.4 < 1 $. Classifica√ß√£o incorreta. Atualiza $\beta = [0.1, -0.2] + 0.1 * -1 * [2, 3] = [-0.1, -0.5]$.
>
> O perceptron continua atualizando os pesos at√© que os pontos estejam corretamente classificados, ou atinja um n√∫mero m√°ximo de itera√ß√µes.  Em situa√ß√µes com dados linearmente separ√°veis, o Perceptron convergir√° para um hiperplano que separa as classes.

### Pergunta Te√≥rica Avan√ßada (Exemplo): Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**

O **LDA (Linear Discriminant Analysis)** e a Regra de Decis√£o Bayesiana s√£o ambos m√©todos de classifica√ß√£o que, quando aplicados a distribui√ß√µes Gaussianas com covari√¢ncias iguais, levam a fronteiras de decis√£o lineares, mas s√£o derivados de abordagens distintas.

```mermaid
graph LR
 subgraph "Bayesian Decision Rule"
    direction TB
    A["Posterior Probability: P(Y=k|X=x)"] --> B["Bayes' Rule: P(X=x|Y=k)P(Y=k)/P(X=x)"]
    B --> C["Gaussian Assumption with Same Covariance"]
    C --> D["Maximizing Log-Probability"]
    D --> E["Discriminant Function (same as LDA)"]
 end
```

A **Regra de Decis√£o Bayesiana** busca a classe que maximiza a probabilidade *a posteriori* $P(Y=k|X=x)$, isto √©, a probabilidade da classe $k$ dado um vetor de preditores $x$. Pela regra de Bayes, essa probabilidade √© dada por:

> $$P(Y=k|X=x) = \frac{P(X=x|Y=k)P(Y=k)}{P(X=x)}$$

Quando as classes s√£o Gaussianas com m√©dias $\mu_k$ e a mesma matriz de covari√¢ncia $\Sigma$, a probabilidade condicional $P(X=x|Y=k)$ √© dada por:

> $$P(X=x|Y=k) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}} \exp(-\frac{1}{2}(x-\mu_k)^T\Sigma^{-1}(x-\mu_k))$$

Onde $p$ √© o n√∫mero de preditores. A regra de decis√£o Bayesiana atribui uma observa√ß√£o $x$ √† classe $k$ que maximiza $P(Y=k|X=x)$ ou, equivalentemente, que maximiza $P(X=x|Y=k)P(Y=k)$ (j√° que $P(X=x)$ √© comum a todas as classes). Ao tomarmos o logaritmo da probabilidade e omitindo termos constantes, a regra de decis√£o Bayesiana se reduz a atribuir a observa√ß√£o $x$ √† classe que maximiza:

> $$\delta_k(x) = -\frac{1}{2}(x-\mu_k)^T\Sigma^{-1}(x-\mu_k) + \log(\pi_k)$$

onde $\pi_k = P(Y=k)$ √© a probabilidade a priori da classe $k$. Expandindo o termo quadr√°tico e omitindo termos que s√£o comuns a todas as classes, obtemos:

> $$\delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log(\pi_k)$$

Que √© exatamente a fun√ß√£o discriminante do LDA [^4.3].

```mermaid
graph LR
    subgraph "LDA Derivation"
        direction TB
        A["Maximize Between-Class Variance"] --> B["Minimize Within-Class Variance"]
        B --> C["Optimization of Discriminant Function"]
        C --> D["Resulting Discriminant Function (same as Bayesian)"]
    end
```

O **LDA**, por sua vez, √© derivado da an√°lise discriminante, com o objetivo de encontrar as combina√ß√µes lineares das vari√°veis que melhor discriminam as classes. O LDA maximiza a raz√£o entre a vari√¢ncia entre classes e a vari√¢ncia dentro das classes, resultando em uma fun√ß√£o discriminante linear semelhante √† regra de decis√£o Bayesiana, como mostrado acima [^4.3].

**Lemma 4:** Sob a premissa de que as classes seguem uma distribui√ß√£o Gaussiana multivariada com a mesma matriz de covari√¢ncia, a regra de decis√£o Bayesiana e o LDA levam exatamente √† mesma fun√ß√£o discriminante linear, e, portanto, √† mesma decis√£o de classifica√ß√£o [^4.3], [^4.3.3].

**Corol√°rio 4:** A relaxa√ß√£o da premissa de igualdade das matrizes de covari√¢ncia entre as classes leva ao **Quadratic Discriminant Analysis (QDA)**, onde a fronteira de decis√£o √© uma fun√ß√£o quadr√°tica e n√£o mais linear [^4.3]. Isso ocorre porque os termos quadr√°ticos das m√©dias das classes ($\mu_k^T\Sigma_k^{-1}\mu_k$) n√£o se cancelam quando as covari√¢ncias s√£o distintas, resultando em uma fun√ß√£o discriminante com termos quadr√°ticos [^4.3].

> ‚ö†Ô∏è **Ponto Crucial**: A escolha de covari√¢ncias iguais ou diferentes impacta fortemente o tipo de fronteira de decis√£o (linear vs. quadr√°tica), alterando a complexidade e a flexibilidade do modelo. A escolha deve ser guiada pelos dados e pelo balan√ßo desejado entre vi√©s e vari√¢ncia.

As perguntas devem ser altamente relevantes, **avaliar a compreens√£o profunda de conceitos te√≥ricos-chave**, podem envolver deriva√ß√µes matem√°ticas e provas, e focar em an√°lises te√≥ricas.

### Conclus√£o

Este cap√≠tulo explorou os fundamentos e as nuances dos m√©todos lineares para classifica√ß√£o. Iniciamos com a apresenta√ß√£o dos conceitos b√°sicos de classifica√ß√£o e suas implica√ß√µes em vi√©s e vari√¢ncia. Em seguida, detalhamos o funcionamento e as formula√ß√µes matem√°ticas do LDA e da regress√£o log√≠stica, ressaltando suas premissas e seus pontos fortes e fracos. A regress√£o linear com matriz de indicadores foi abordada como uma alternativa para classifica√ß√£o, destacando suas limita√ß√µes. A import√¢ncia da sele√ß√£o de vari√°veis e da regulariza√ß√£o foi discutida, com √™nfase em como essas t√©cnicas afetam a complexidade do modelo e sua capacidade preditiva. Al√©m disso, foram introduzidos os conceitos de hiperplanos separadores e o algoritmo do perceptron, bem como as diferen√ßas te√≥ricas entre LDA e a Regra de Decis√£o Bayesiana. O cap√≠tulo tamb√©m abordou problemas de classifica√ß√£o multivariada, explorando como m√©todos como a an√°lise de correla√ß√£o can√¥nica podem ajudar a reduzir a dimensionalidade. As se√ß√µes te√≥ricas avan√ßadas visaram consolidar a compreens√£o te√≥rica e aprofundar a capacidade anal√≠tica do leitor.

<!-- END DOCUMENT -->

### Footnotes

[^4.1]: "A linear regression model assumes that the regression function E(Y|X) is linear in the inputs X1,..., Xp. Linear models were largely developed in the precomputer age of statistics, but even in today's computer era there are still good reasons to study and use them. They are simple and often provide an adequate and interpretable description of how the inputs affect the output. For prediction purposes they can sometimes outperform fancier nonlinear models, especially in situations