## An√°lise Comparativa de M√©todos Lineares para Classifica√ß√£o no Caso Ortogonal e Via Solu√ß√£o Expl√≠cita

```mermaid
graph LR
    subgraph "Comparative Analysis of Linear Methods"
      direction LR
        A["Linear Methods for Classification"] --> B("Linear Discriminant Analysis (LDA)")
        A --> C("Logistic Regression")
        A --> D("Indicator Matrix Regression")
        B --> E("Assumptions: Gaussian Distributions, Equal Covariance")
        C --> F("Model: Sigmoid function for class probabilities")
        D --> G("Linear regression of dummy variables")
        E & F & G --> H("Focus: orthogonal case and explicit solutions")
    end
```

### Introdu√ß√£o

A busca por modelos de classifica√ß√£o precisos e interpret√°veis √© um desafio constante em estat√≠stica e aprendizado de m√°quina. Modelos lineares, apesar de sua simplicidade, continuam sendo ferramentas poderosas e fundamentais, oferecendo um bom ponto de partida para problemas de classifica√ß√£o, al√©m de servirem como base para o entendimento de modelos mais complexos [^4.1]. Este cap√≠tulo explora em profundidade a aplica√ß√£o de m√©todos lineares para classifica√ß√£o, com foco nas suas caracter√≠sticas, fundamentos te√≥ricos e matem√°ticos, e nas suas limita√ß√µes. Em particular, vamos nos concentrar na an√°lise comparativa entre esses m√©todos no caso ortogonal, onde as propriedades dos modelos se tornam mais claras, e na obten√ß√£o de solu√ß√µes expl√≠citas, sempre que poss√≠vel.

### Conceitos Fundamentais

√â essencial come√ßar com uma compreens√£o clara dos conceitos fundamentais que sustentam a classifica√ß√£o linear, e como esses conceitos se relacionam com o trade-off entre vi√©s e vari√¢ncia.

**Conceito 1:** O **problema de classifica√ß√£o** envolve a atribui√ß√£o de um conjunto de observa√ß√µes a um n√∫mero discreto de classes. Modelos lineares buscam encontrar uma **fronteira de decis√£o** linear que separe as classes no espa√ßo de atributos. Essa fronteira √© definida por uma fun√ß√£o linear dos atributos, ou seja, $f(x) = \beta_0 + \sum_{j=1}^p x_j\beta_j$, onde $x$ representa o vetor de atributos e $\beta$ s√£o os coeficientes do modelo. O vi√©s de um modelo se refere √† sua capacidade de capturar a complexidade real dos dados, enquanto a vari√¢ncia reflete o quanto o modelo √© sens√≠vel a pequenas mudan√ßas nos dados de treinamento. Modelos lineares, por sua natureza, tendem a ter um alto vi√©s, j√° que n√£o capturam rela√ß√µes n√£o lineares, e baixa vari√¢ncia, porque s√£o relativamente est√°veis a mudan√ßas nos dados de treinamento [^4.1]. Por exemplo, em dados de alta dimens√£o e baixa amostragem, um modelo linear pode generalizar melhor que um modelo n√£o linear, j√° que este √∫ltimo pode ser mais suscet√≠vel a overfitting.

> üí° **Exemplo Num√©rico:** Considere um conjunto de dados bidimensional com duas classes, onde os pontos da classe 1 est√£o concentrados em torno de $(1, 1)$ e os pontos da classe 0 em torno de $(3, 3)$. Um modelo linear tentar√° tra√ßar uma linha reta que separe as duas classes. Se os dados forem distribu√≠dos de forma que uma linha reta n√£o consiga separ√°-los perfeitamente, o modelo ter√° um vi√©s. Por outro lado, se os pontos das classes forem dispersos, o modelo ser√° menos sens√≠vel a varia√ß√µes no conjunto de treinamento, indicando baixa vari√¢ncia. Um modelo linear, como uma regress√£o log√≠stica, pode fornecer uma fronteira de decis√£o razo√°vel mesmo em dados onde os pontos n√£o est√£o bem separados, mas ele falhar√° se as classes forem separadas por uma fronteira n√£o linear, como um c√≠rculo.

**Lemma 1:** A fun√ß√£o discriminante linear $f(x) = \beta_0 + \sum_{j=1}^p x_j\beta_j$ pode ser decomposta em uma soma de proje√ß√µes em eixos ortogonais. Suponha que temos um conjunto de eixos ortogonais $v_1, v_2, \ldots, v_p$ que formam uma base para o espa√ßo de atributos. Ent√£o, podemos escrever qualquer vetor de atributos $x$ como uma combina√ß√£o linear desses eixos, ou seja, $x = \sum_{j=1}^p \alpha_jv_j$. A fun√ß√£o discriminante linear pode ent√£o ser escrita como $f(x) = \beta_0 + \sum_{j=1}^p \alpha_j\beta'v_j$, onde $\beta'$ √© o vetor de coeficientes projetado nos eixos ortogonais, e $\alpha_j$ √© a proje√ß√£o de $x$ sobre o eixo $v_j$. Essa decomposi√ß√£o √© √∫til porque permite analisar o impacto de cada componente ortogonal individualmente na decis√£o de classifica√ß√£o [^4.3]. A proje√ß√£o de um vetor $x$ sobre um vetor $v_j$ √© dada por $\alpha_j = \frac{x \cdot v_j}{\|v_j\|^2}$. Em particular, quando os eixos $v_j$ formam uma base ortonormal, ent√£o $\alpha_j = x \cdot v_j$.
$\blacksquare$

```mermaid
graph TB
    subgraph "Orthogonal Decomposition of Linear Discriminant Function"
        direction TB
        A["Linear Discriminant Function: f(x) = Œ≤‚ÇÄ + ‚àë x‚±ºŒ≤‚±º"]
        B["Orthogonal Basis: v‚ÇÅ, v‚ÇÇ, ..., v‚Çö"]
        C["Attribute Vector: x = ‚àë Œ±‚±ºv‚±º"]
        D["Decomposed Function: f(x) = Œ≤‚ÇÄ + ‚àë Œ±‚±ºŒ≤'v‚±º"]
        E["Projection Coefficient: Œ±‚±º = x ‚ãÖ v‚±º / ||v‚±º||¬≤"]
        F["Orthonormal Case: Œ±‚±º = x ‚ãÖ v‚±º"]
        A --> B
        B --> C
        C --> D
        D --> E
        E --> F
    end
```

> üí° **Exemplo Num√©rico:** Suponha que temos dois atributos ortogonais, $v_1 = [1, 0]$ e $v_2 = [0, 1]$, e um ponto de dados $x = [3, 4]$. Os coeficientes do modelo s√£o $\beta = [0.5, -0.2]$. Podemos projetar $x$ nos eixos: $\alpha_1 = x \cdot v_1 = [3, 4] \cdot [1, 0] = 3$ e $\alpha_2 = x \cdot v_2 = [3, 4] \cdot [0, 1] = 4$. A fun√ß√£o discriminante √© $f(x) = \beta_0 + \alpha_1\beta'_1 + \alpha_2\beta'_2$. Se $\beta_0 = 1$, $\beta'_1 = 0.5$ e $\beta'_2 = -0.2$, ent√£o $f(x) = 1 + 3*0.5 + 4*(-0.2) = 1 + 1.5 - 0.8 = 1.7$. A decomposi√ß√£o nos permite ver que o atributo $v_1$ (projetado em $\alpha_1$) contribui positivamente para a classifica√ß√£o, enquanto o atributo $v_2$ (projetado em $\alpha_2$) contribui negativamente.

**Conceito 2:** A **Linear Discriminant Analysis (LDA)** √© um m√©todo de classifica√ß√£o que assume que as classes possuem distribui√ß√µes Gaussianas com a mesma matriz de covari√¢ncia. A LDA busca encontrar uma combina√ß√£o linear dos atributos que maximiza a separa√ß√£o entre as m√©dias das classes e minimiza a vari√¢ncia dentro de cada classe [^4.3]. A **fun√ß√£o discriminante linear** da LDA √© dada por:
$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T \Sigma^{-1} \mu_k + \log \pi_k,
$$
onde $\mu_k$ √© o vetor m√©dio da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum a todas as classes, e $\pi_k$ √© a probabilidade a priori da classe $k$. A decis√£o de classe √© tomada atribuindo a observa√ß√£o √† classe $k$ que maximiza $\delta_k(x)$. A suposi√ß√£o de normalidade e de covari√¢ncias iguais, apesar de restritivas, conduzem a solu√ß√µes anal√≠ticas e eficientes. No caso de classes com diferentes matrizes de covari√¢ncia, a LDA d√° lugar √† An√°lise Discriminante Quadr√°tica (QDA), que tem fronteiras de decis√£o quadr√°ticas [^4.3.1]. A **estimativa da matriz de covari√¢ncia** em LDA √© dada por:
$$
\hat{\Sigma} = \frac{1}{N-K} \sum_{k=1}^K \sum_{i \in C_k} (x_i - \hat{\mu}_k)(x_i - \hat{\mu}_k)^T
$$
onde $N$ √© o n√∫mero total de amostras, $K$ √© o n√∫mero de classes, $C_k$ √© o conjunto de amostras pertencentes √† classe $k$, e $\hat{\mu}_k$ √© a m√©dia amostral da classe $k$.

```mermaid
graph TB
    subgraph "Linear Discriminant Analysis (LDA) Framework"
        direction TB
        A["LDA Discriminant Function: Œ¥‚Çñ(x) = x·µÄŒ£‚Åª¬πŒº‚Çñ - (1/2)Œº‚Çñ·µÄŒ£‚Åª¬πŒº‚Çñ + log(œÄ‚Çñ)"]
        B["Œº‚Çñ: Mean vector of class k"]
        C["Œ£: Pooled covariance matrix"]
        D["œÄ‚Çñ: Prior probability of class k"]
        E["Covariance Matrix Estimation: Œ£ÃÇ = (1/(N-K)) ‚àë‚Çñ ‚àë·µ¢‚ààC‚Çñ (x·µ¢ - ŒºÃÇ‚Çñ)(x·µ¢ - ŒºÃÇ‚Çñ)·µÄ"]
        F["N: Total number of samples"]
        G["K: Number of classes"]
        H["C‚Çñ: Set of samples belonging to class k"]
         I["ŒºÃÇ‚Çñ: Sample mean of class k"]
         A --> B
        A --> C
        A --> D
        C --> E
        E --> F
        E --> G
         E --> H
         E --> I
    end
```

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com duas classes e dois atributos. As m√©dias das classes s√£o $\mu_1 = [1, 1]$ e $\mu_2 = [3, 3]$, e a matriz de covari√¢ncia estimada √© $\Sigma = [[1, 0.5], [0.5, 1]]$. As probabilidades a priori s√£o $\pi_1 = 0.4$ e $\pi_2 = 0.6$. Para classificar um novo ponto $x = [2, 2]$, calculamos $\delta_1(x)$ e $\delta_2(x)$.

> $\text{Passo 1: Calcular } \Sigma^{-1}$:
```python
import numpy as np
from numpy.linalg import inv

Sigma = np.array([[1, 0.5], [0.5, 1]])
Sigma_inv = inv(Sigma)
print("Sigma_inv:", Sigma_inv)
```
> $\text{Passo 2: Calcular } \delta_1(x) \text{ e } \delta_2(x)$:
```python
mu1 = np.array([1, 1])
mu2 = np.array([3, 3])
x = np.array([2, 2])
pi1 = 0.4
pi2 = 0.6

delta1_x = x.T @ Sigma_inv @ mu1 - 0.5 * mu1.T @ Sigma_inv @ mu1 + np.log(pi1)
delta2_x = x.T @ Sigma_inv @ mu2 - 0.5 * mu2.T @ Sigma_inv @ mu2 + np.log(pi2)

print("delta1_x:", delta1_x)
print("delta2_x:", delta2_x)

if delta1_x > delta2_x:
    print("Classe Predita: 1")
else:
    print("Classe Predita: 2")

```
> $\text{Output: }$
```
Sigma_inv: [[ 1.333 -0.667]
 [-0.667  1.333]]
delta1_x: -1.448
delta2_x: -0.453
Classe Predita: 2
```
> Como $\delta_2(x) > \delta_1(x)$, a LDA classifica o ponto $x$ como pertencente √† classe 2.

**Corol√°rio 1:** No caso em que as classes s√£o bem separadas no espa√ßo de atributos, a fun√ß√£o discriminante linear da LDA pode ser vista como uma proje√ß√£o dos dados em um subespa√ßo de menor dimens√£o que preserva a separabilidade entre as classes. Se considerarmos apenas o termo $x^T \Sigma^{-1} \mu_k$, a fun√ß√£o discriminante da LDA projeta os dados no espa√ßo das diferen√ßas entre as m√©dias das classes, ponderadas pela inversa da matriz de covari√¢ncia, o que faz com que a separabilidade seja maximizada nessa proje√ß√£o. Em situa√ß√µes onde o n√∫mero de atributos $p$ √© muito grande, realizar essa proje√ß√£o em subespa√ßos de menor dimens√£o pode simplificar o problema sem perda significativa de informa√ß√£o [^4.3.1].

> üí° **Exemplo Num√©rico:** Em um cen√°rio com 10 atributos, onde 8 deles s√£o altamente correlacionados e apenas 2 s√£o realmente informativos para a separa√ß√£o entre as classes, a LDA, ao utilizar a matriz de covari√¢ncia, efetivamente pondera os atributos e projeta os dados em um subespa√ßo de menor dimens√£o (aproximadamente 2 dimens√µes) que maximiza a separabilidade. Isso reduz o ru√≠do dos atributos irrelevantes e melhora o desempenho do classificador.

**Conceito 3:** A **Regress√£o Log√≠stica** √© um m√©todo de classifica√ß√£o que modela a probabilidade de uma observa√ß√£o pertencer a uma classe usando a fun√ß√£o log√≠stica. A fun√ß√£o log√≠stica √© dada por $\sigma(z) = \frac{1}{1 + e^{-z}}$, onde $z$ √© uma combina√ß√£o linear dos atributos, $z = \beta_0 + \sum_{j=1}^p x_j\beta_j$. O modelo de regress√£o log√≠stica estima os par√¢metros $\beta$ usando o m√©todo da m√°xima verossimilhan√ßa [^4.4]. A probabilidade de uma observa√ß√£o $x$ pertencer √† classe 1 √© dada por $P(Y=1|x) = \sigma(\beta_0 + \sum_{j=1}^p x_j\beta_j)$ e a probabilidade de pertencer √† classe 0 √© $P(Y=0|x) = 1 - \sigma(\beta_0 + \sum_{j=1}^p x_j\beta_j)$. A regress√£o log√≠stica, portanto, modela o logaritmo das chances (log-odds) como uma fun√ß√£o linear dos atributos:
$$
\log\left(\frac{P(Y=1|x)}{1-P(Y=1|x)}\right) = \beta_0 + \sum_{j=1}^p x_j\beta_j
$$
A escolha da fun√ß√£o log√≠stica garante que a probabilidade estimada esteja sempre entre 0 e 1. A regress√£o log√≠stica √© um modelo probabil√≠stico e oferece informa√ß√µes sobre a incerteza da classifica√ß√£o, diferente da LDA que oferece uma classifica√ß√£o direta. A **verossimilhan√ßa** (likelihood) para a regress√£o log√≠stica, para um conjunto de $N$ observa√ß√µes, √© dada por:
$$
L(\beta) = \prod_{i=1}^N p(x_i)^{y_i}(1-p(x_i))^{1-y_i}
$$
onde $y_i$ √© o r√≥tulo da classe (0 ou 1) para a observa√ß√£o $x_i$, e $p(x_i)$ √© a probabilidade de que $y_i = 1$ dado $x_i$. O objetivo √© maximizar essa verossimilhan√ßa para encontrar os melhores par√¢metros $\beta$.

```mermaid
graph TB
    subgraph "Logistic Regression Framework"
        direction TB
        A["Logistic Function: œÉ(z) = 1 / (1 + e‚Åª·∂ª)"]
        B["Linear Combination: z = Œ≤‚ÇÄ + ‚àë x‚±ºŒ≤‚±º"]
        C["Probability Model: P(Y=1|x) = œÉ(z)"]
        D["Log-odds: log(P(Y=1|x)/(1-P(Y=1|x))) = Œ≤‚ÇÄ + ‚àë x‚±ºŒ≤‚±º"]
        E["Likelihood Function: L(Œ≤) = ‚àè·µ¢ p(x·µ¢) ∏·µ¢(1-p(x·µ¢))‚ÅΩ¬π‚Åª ∏·µ¢‚Åæ"]
        A --> B
        B --> C
        C --> D
        C --> E
    end
```

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo de regress√£o log√≠stica com dois atributos, com os coeficientes $\beta_0 = -2$, $\beta_1 = 1$ e $\beta_2 = 0.5$. Para um ponto $x = [3, 2]$, temos $z = -2 + 1*3 + 0.5*2 = 2$. A probabilidade de pertencer √† classe 1 √© $\sigma(2) = \frac{1}{1 + e^{-2}} \approx 0.88$. Portanto, este ponto tem uma probabilidade alta de pertencer √† classe 1. A verossimilhan√ßa seria calculada para todos os pontos do conjunto de treinamento para maximizar os coeficientes $\beta$.

> üí° **Exemplo Num√©rico de C√°lculo da Verossimilhan√ßa:** Considere um conjunto de treinamento com dois exemplos: $x_1 = [1, 2]$, $y_1 = 1$ e $x_2 = [2, 1]$, $y_2 = 0$. Usando os mesmos par√¢metros $\beta_0 = -2$, $\beta_1 = 1$ e $\beta_2 = 0.5$, temos:
$z_1 = -2 + 1*1 + 0.5*2 = -1$, e $p(x_1) = \sigma(-1) = \frac{1}{1 + e^1} \approx 0.27$
$z_2 = -2 + 1*2 + 0.5*1 = 0.5$, e $p(x_2) = \sigma(0.5) = \frac{1}{1 + e^{-0.5}} \approx 0.62$
A verossimilhan√ßa √© $L(\beta) = p(x_1)^{y_1}(1-p(x_1))^{1-y_1} * p(x_2)^{y_2}(1-p(x_2))^{1-y_2} = 0.27^1 * (1-0.27)^0 * 0.62^0 * (1-0.62)^1 = 0.27 * 0.38 \approx 0.1026$. O objetivo da regress√£o log√≠stica √© encontrar os par√¢metros que maximizam esta verossimilhan√ßa.

> ‚ö†Ô∏è **Nota Importante**: Tanto LDA quanto regress√£o log√≠stica se baseiam na ideia de uma fronteira de decis√£o linear, mas diferem em suas suposi√ß√µes e objetivos. LDA assume normalidade e covari√¢ncias iguais e foca na separa√ß√£o das classes, enquanto regress√£o log√≠stica modela probabilidades e n√£o requer tais suposi√ß√µes. A escolha entre esses dois m√©todos depende das caracter√≠sticas espec√≠ficas do problema [^4.4.1].

> ‚ùó **Ponto de Aten√ß√£o**: Em situa√ß√µes com classes n√£o balanceadas, a regress√£o log√≠stica pode ser mais robusta do que a LDA devido √† sua natureza probabil√≠stica e √† capacidade de ajustar os pesos para compensar a disparidade entre as classes [^4.4.2].

> ‚úîÔ∏è **Destaque**: Em certos casos, a LDA pode ser vista como uma forma de regress√£o linear, que pode, por sua vez, ser utilizada como base para a regress√£o log√≠stica. Em casos onde o n√∫mero de classes √© dois, a LDA se torna um caso particular da regress√£o log√≠stica [^4.5].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Indicator Matrix Regression for Classification"
      direction LR
        A["Input Data: X (attributes)"] --> B("Create Indicator Variables: Y‚Çñ")
        B --> C("Perform Linear Regression: Y‚Çñ = XŒ≤‚Çñ + Œµ‚Çñ")
        C --> D("Coefficient Estimation via Least Squares: Œ≤ÃÇ‚Çñ = (X·µÄX)‚Åª¬πX·µÄY‚Çñ")
        D --> E("Prediction: argmax‚Çñ(XŒ≤ÃÇ‚Çñ)")
        E --> F("Class Prediction")
    end
```

A regress√£o linear, tradicionalmente usada para problemas de regress√£o, pode ser adaptada para problemas de classifica√ß√£o atrav√©s da **regress√£o de matriz indicadora**. Nessa abordagem, cada classe √© representada por uma vari√°vel indicadora (dummy variable) que assume o valor 1 se a observa√ß√£o pertence √† classe e 0 caso contr√°rio. Podemos realizar a regress√£o linear com essas vari√°veis como *outputs* e os atributos como *inputs*. Se tivermos $K$ classes, criamos $K$ vari√°veis indicadoras $Y_k$, e realizamos $K$ regress√µes lineares separadamente:
$$
Y_k = X\beta_k + \epsilon_k
$$
onde $X$ √© a matriz de atributos, $\beta_k$ √© o vetor de coeficientes para a classe $k$ e $\epsilon_k$ √© o erro. A predi√ß√£o de classe para uma nova observa√ß√£o √© ent√£o baseada na classe que apresenta o maior valor da fun√ß√£o de regress√£o:
$$
\text{classe} = \text{argmax}_k (X\beta_k)
$$
Essa abordagem transforma um problema de classifica√ß√£o em um problema de otimiza√ß√£o de m√≠nimos quadrados, onde o objetivo √© minimizar a soma dos quadrados dos erros residuais [^4.2]. As limita√ß√µes da regress√£o de matriz indicadora s√£o diversas. Principalmente quando se tem mais de duas classes, os resultados da regress√£o linear podem n√£o corresponder a probabilidades bem definidas, e a classifica√ß√£o pode apresentar resultados inconsistentes. Al√©m disso, o m√©todo √© sens√≠vel a classes desbalanceadas e outliers [^4.1], e a escolha do n√∫mero de classes afeta a estimativa dos par√¢metros. A estima√ß√£o de par√¢metros via m√≠nimos quadrados √© feita com a seguinte f√≥rmula:
$$
\hat{\beta} = (X^T X)^{-1} X^T Y
$$

> üí° **Exemplo Num√©rico:** Considere um problema de classifica√ß√£o com duas classes e dois atributos. Temos tr√™s observa√ß√µes com os seguintes dados:
> $x_1 = [1, 2]$, $y_1 = 1$ (classe 1)
> $x_2 = [2, 1]$, $y_2 = 0$ (classe 0)
> $x_3 = [3, 3]$, $y_3 = 1$ (classe 1)
> Primeiro, constru√≠mos a matriz de atributos $X$ e a matriz de vari√°veis indicadoras $Y$:
```python
import numpy as np

X = np.array([[1, 1, 2],
              [1, 2, 1],
              [1, 3, 3]])  # Adicionamos uma coluna de 1s para o intercepto

Y = np.array([[1, 0, 1]]).T  # Y √© uma matriz com colunas representando cada classe. Neste caso, s√≥ temos uma coluna para indicar a classe 1. A classe 0 ser√° implicitamente inferida.

print("X:\n", X)
print("Y:\n", Y)
```
> $\text{Output:}$
```
X:
 [[1 1 2]
 [1 2 1]
 [1 3 3]]
Y:
 [[1]
 [0]
 [1]]
```
>  $\text{Passo 1: Calcular } (X^T X)^{-1}$:
```python
XTX = X.T @ X
XTX_inv = np.linalg.inv(XTX)
print("(XTX)^-1:\n", XTX_inv)
```
> $\text{Passo 2: Calcular } (X^T X)^{-1} X^T Y$:
```python
beta_hat = XTX_inv @ X.T @ Y
print("beta_hat:\n", beta_hat)
```
> $\text{Output:}$
```
(XTX)^-1:
 [[ 1.166 -0.5    -0.166]
 [-0.5      0.5    0.   ]
 [-0.166    0.    0.166]]
beta_hat:
 [[-0.666]
 [ 0.333]
 [ 0.5]]
```
> $\text{Passo 3: Classificar um novo ponto } x_{new} = [2, 2]$:
```python
x_new = np.array([1, 2, 2])  # Adicionamos o 1 para o intercepto
y_new_pred = x_new @ beta_hat
print("y_new_pred:", y_new_pred)

if y_new_pred > 0.5:
  print("Classe Predita: 1")
else:
  print("Classe Predita: 0")
```
> $\text{Output:}$
```
y_new_pred: [0.666]
Classe Predita: 1
```
> Assim, a regress√£o de matriz indicadora classifica $x_{new}$ como pertencente √† classe 1. Note que como se trata de um classificador linear, o resultado n√£o √© uma probabilidade no intervalo [0,1] e a escolha de 0.5 como *threshold* √© arbitr√°ria.

**Lemma 2:** A regra de decis√£o baseada na regress√£o linear de matriz indicadora com duas classes, sob certas condi√ß√µes de covari√¢ncia, √© equivalente a um classificador linear obtido por LDA. Suponha que temos duas classes com m√©dias $\mu_1$ e $\mu_2$ e a mesma matriz de covari√¢ncia $\Sigma$. A regra de decis√£o de LDA atribui uma observa√ß√£o √† classe 1 se $x^T \Sigma^{-1} (\mu_1 - \mu_2) > c$, onde $c$ √© uma constante relacionada √† probabilidade a priori. Na regress√£o de matriz indicadora, as fun√ß√µes de regress√£o s√£o $Y_1 = X\beta_1$ e $Y_2 = X\beta_2$, e a classifica√ß√£o √© feita comparando $X\beta_1$ com $X\beta_2$. Se assumirmos que os coeficientes $\beta_1$ e $\beta_2$ s√£o estimados de forma que $\beta_1 - \beta_2$ √© proporcional a $\Sigma^{-1}(\mu_1 - \mu_2)$, ent√£o a regra de decis√£o da regress√£o linear se torna equivalente √† regra da LDA [^4.2].
$\blacksquare$

```mermaid
graph LR
    subgraph "Equivalence of Indicator Regression and LDA"
        direction LR
        A["LDA Decision Rule: x·µÄŒ£‚Åª¬π(Œº‚ÇÅ - Œº‚ÇÇ) > c"]
        B["Indicator Regression: Compare XŒ≤‚ÇÅ and XŒ≤‚ÇÇ"]
        C["If Œ≤‚ÇÅ - Œ≤‚ÇÇ ‚àù Œ£‚Åª¬π(Œº‚ÇÅ - Œº‚ÇÇ): Decision rules equivalent"]
        A --> C
        B --> C
    end
```

> üí° **Exemplo Num√©rico:** Considere o exemplo anterior com duas classes e atributos, onde se assumirmos que a diferen√ßa dos coeficientes obtidos pela regress√£o indicadora ($\beta_1 - \beta_2$) √© proporcional a $\Sigma^{-1} (\mu_1 - \mu_2)$, ent√£o a classifica√ß√£o de um ponto pelo m√©todo da matriz indicadora, seria equivalente a decis√£o da LDA.

**Corol√°rio 2:** Quando o n√∫mero de classes √© pequeno e os atributos s√£o linearmente separ√°veis, a regress√£o de matriz indicadora pode fornecer resultados compar√°veis a outros m√©todos lineares, e a an√°lise do modelo √© simplificada pela sua natureza direta. No entanto, na pr√°tica, o m√©todo pode ser inst√°vel e propenso a gerar probabilidades fora do intervalo [0,1]. Uma das raz√µes da instabilidade √© a tend√™ncia √† extrapola√ß√£o, ou seja, a gerar valores fora dos limites em casos onde h√° observa√ß√µes que ficam fora da regi√£o central dos dados de treinamento [^4.3].

> üí° **Exemplo Num√©rico:** Num caso de regress√£o de matriz indicadora com duas classes, onde os pontos de cada classe est√£o bem separados, o m√©todo pode funcionar bem. No entanto, se o ponto a ser classificado √© uma combina√ß√£o de atributos fora da regi√£o de dados de treinamento, a regress√£o pode gerar valores acima de 1 ou abaixo de 0. Por exemplo, se os pontos de uma classe s√£o concentrados em torno de $x = [1, 1]$ e os da outra classe em torno de $x = [3, 3]$, o ponto $x = [5, 5]$ poderia ser classificado com um valor muito maior que 1, indicando uma extrapola√ß√£o.

Em alguns cen√°rios, conforme apontado em [^4.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1].

No entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^4.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear.

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Methods for Linear Classification"
        direction TB
       A["Regularization Techniques"] --> B("L1 Regularization (Lasso)")
        A --> C("L2 Regularization (Ridge)")
        A --> D("Elastic Net Regularization")
        B --> E("Promotes sparsity, feature selection")
        C --> F("Reduces coefficient magnitude, improves stability")
        D --> G("Combines L1 and L2 for sparsity and stability")
         E & F & G --> H("Apply to LDA, Logistic Regression, Indicator Matrix Regression")
    end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas importantes para controlar a complexidade dos modelos de classifica√ß√£o, reduzir a vari√¢ncia e melhorar a generaliza√ß√£o. Modelos lineares com muitos atributos podem sofrer de overfitting, especialmente em situa√ß√µes de dados de alta dimens√£o e baixa amostragem. A **regulariza√ß√£o** adiciona uma penalidade √† fun√ß√£o de custo do modelo, o que leva a estimativas de par√¢metros menores ou iguais a zero, o que √© desej√°vel quando se busca esparsidade. Na regress√£o log√≠stica, por exemplo, a fun√ß√£o de custo, que busca maximizar a verossimilhan√ßa dos dados, √© modificada adicionando um termo de penaliza√ß√£o que restringe a magnitude dos coeficientes [^4.4.4].
A **penaliza√ß√£o L1** adiciona a soma do valor absoluto dos coeficientes ao custo (ou sua vers√£o log-likelihood), ou seja:
$$
\text{Custo} = - \log L(\beta) + \lambda\sum_{j=1}^p |\beta_j|
$$
Essa penaliza√ß√£o tende a gerar **coeficientes esparsos**, ou seja, muitos coeficientes s√£o reduzidos exatamente a zero, o que efetivamente seleciona um subconjunto de atributos relevantes [^4.5].
A **penaliza√ß√£o L2**, por sua vez, adiciona a soma do quadrado dos coeficientes ao custo:
$$
\text{Custo} = - \log L(\beta) + \lambda\sum_{j=1}^p \beta_j^2
$$
Essa penaliza√ß√£o tende a reduzir a magnitude de todos os coeficientes, sem necessariamente lev√°-los a zero. A penaliza√ß√£o L2 √© geralmente utilizada para controlar a vari√¢ncia do modelo e aumentar sua estabilidade.
O **Elastic Net** combina as penalidades L1 e L2, oferecendo flexibilidade para controlar tanto a esparsidade quanto a estabilidade do modelo [^4.5.1]. A fun√ß√£o de custo para o elastic net √© dada por:
$$
\text{Custo} = - \log L(\beta) + \lambda_1\sum_{j=1}^p |\beta_j| + \lambda_2\sum_{j=1}^p \beta_j^2
$$
onde $\lambda_1$ e $\lambda_2$ s√£o par√¢metros de regulariza√ß√£o que controlam a import√¢ncia relativa de cada penaliza√ß√£o.
A **regulariza√ß√£o** n√£o √© aplicada apenas na regress√£o log√≠stica; ela pode ser aplicada em todos os m√©todos lineares, incluindo a LDA e a regress√£o de matriz indicadora. No entanto, ela √© mais comumente utilizada na regress√£o log√≠stica, devido √† sua flexibilidade e capacidade de lidar com dados de alta dimens√£o.

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo de regress√£o log√≠stica com 5 atributos e coeficientes iniciais $\beta = [2, -1, 3, 0.5, -0.2]$. Se aplicarmos regulariza√ß√£o L1 com $\lambda = 1$, alguns coeficientes como o 0.5 e o -0.2 seriam reduzidos a zero. Se aplicarmos regulariza√ß√£o L2 com o mesmo $\lambda$, os coeficientes seriam todos reduzidos em magnitude, mas nenhum chegaria a zero. O elastic net com $\lambda_1 = 0.5$ e $\lambda_2 = 0.5$ combinaria ambos os efeitos.

**Lemma 3:** A penaliza√ß√£o L1 na regress√£o log√≠stica induz a esparsidade dos coeficientes, o que significa que alguns coeficientes s√£o reduzidos exatamente a zero. A prova da esparsidade se baseia na otimiza√ß√£o da fun√ß√£o de custo regularizada. As condi√ß√µes de otimalidade da fun√ß√£o de custo envolvem a derivada da fun√ß√£o de verossimilhan√ßa (likelihood) e a penalidade L1. Quando um coeficiente √© diferente de zero, a derivada da fun√ß√£o de verossimilhan√ßa deve compensar o termo da penalidade L1. No entanto, quando a derivada da fun√ß√£o de verossimilhan√ßa √© pequena e o par√¢metro de regulariza√ß√£o $\lambda$ √© suficientemente grande, o coeficiente pode ser reduzido a zero, o que leva √† esparsidade [^4.4.4].
$\blacksquare$

```mermaid
graph TB
    subgraph "L1 Regularization and Sparsity"
        direction TB
       A["Cost Function with L1 Penalty: Cost = -log L(Œ≤) + Œª‚àë|Œ≤‚±º|"]
       B["Optimality Condition: ‚àÇCost/‚àÇŒ≤‚±º = 0"]
       C["Non-zero Œ≤‚±º: ‚àÇ(-log L(Œ≤))/‚àÇŒ≤‚±º compensates L1 penalty"]
       D["If ‚àÇ(-log L(Œ≤))/‚àÇŒ≤‚±º is small & Œª is large enough then: Œ≤‚±º = 0"]
        A --> B
        B --> C
         B --> D
     end
```

**Prova do Lemma 3:** Formalmente, na regress√£o log√≠stica com penaliza√ß√£o L1, a fun√ß√£o de custo √© dada por:
$$ J(\beta) = -\frac{1}{N}\sum_{i=1}^N \left[y_i\log(\sigma(\beta^T x_i)) + (1-y_i)\log(1-\sigma(\beta^T x_i))\right] + \lambda \sum_{j=1}^p |\beta_j| $$
Para mostrar que esta fun√ß√£o promove a esparsidade, consideramos a condi√ß√£o de otimalidade para o $j$-√©simo coeficiente. Supondo que a fun√ß√£o log√≠stica $\sigma(\beta^T x_i)$ √© suficientemente suave, podemos aproximar a derivada da fun√ß√£o de verossimilhan√ßa e derivar a fun√ß√£o de custo com respeito ao coeficiente $\beta_j$:
$$ \frac{\partial J}{\partial \beta_j} = \frac{1}{N}\sum_{i=1}^N x_{ij}(y_i - \sigma(\beta^T x_i)) + \lambda \text{sign}(\beta_j) $$
onde $\text{sign}(\beta_j)$ √© o sinal de $\beta_j$. Na