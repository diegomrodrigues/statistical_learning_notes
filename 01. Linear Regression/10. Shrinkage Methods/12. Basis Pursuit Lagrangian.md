## M√©todos Lineares para Regress√£o e Classifica√ß√£o

```mermaid
graph LR
    A["Dados de Entrada"] --> B["Linear Discriminant Analysis (LDA)"]
    A --> C["Logistic Regression"]
    A --> D["Separating Hyperplanes"]
    B --> E["Classifica√ß√£o"]
    C --> E
    D --> E
```

### Introdu√ß√£o
O estudo de m√©todos lineares em aprendizado estat√≠stico √© fundamental devido √† sua simplicidade, interpretabilidade e capacidade de servir como base para t√©cnicas mais complexas [^4.1]. Modelos lineares, apesar de sua simplicidade, s√£o ferramentas poderosas para entender as rela√ß√µes entre vari√°veis de entrada e sa√≠da, al√©m de serem eficientes em cen√°rios com poucos dados de treinamento ou alta dimensionalidade [^4.1]. Este cap√≠tulo explora esses m√©todos tanto para regress√£o quanto para classifica√ß√£o, com foco em suas formula√ß√µes te√≥ricas e matem√°ticas. Em particular, vamos aprofundar as t√©cnicas de **Linear Discriminant Analysis (LDA)**, **Logistic Regression**, e a constru√ß√£o de **hiperplanos separadores**. A compreens√£o desses m√©todos lineares √© crucial para o desenvolvimento e compreens√£o de abordagens mais sofisticadas em aprendizado de m√°quina e an√°lise de dados.

### Conceitos Fundamentais

**Conceito 1: Problema de Classifica√ß√£o**
O problema de classifica√ß√£o, no contexto de aprendizado de m√°quina, refere-se √† tarefa de atribuir uma observa√ß√£o a uma de v√°rias categorias predefinidas [^4.1]. Modelos lineares podem ser aplicados a este problema buscando encontrar uma fronteira de decis√£o linear que separe as diferentes classes. No entanto, essa abordagem tem suas limita√ß√µes. *Modelos lineares imp√µem uma suposi√ß√£o forte de linearidade na rela√ß√£o entre as vari√°veis de entrada e as classes, o que pode levar a um alto vi√©s se a fronteira de decis√£o real for n√£o-linear*. Por outro lado, a simplicidade de modelos lineares pode resultar em uma menor vari√¢ncia, o que pode ser ben√©fico em situa√ß√µes com poucos dados. Por exemplo, ao classificar imagens de animais, modelos lineares podem n√£o ser adequados se as classes (gato, cachorro, etc.) n√£o podem ser separadas por uma linha reta no espa√ßo de caracter√≠sticas.

**Lemma 1:**
Em um cen√°rio de classifica√ß√£o bin√°ria com duas classes, onde $y_i \in \{-1, 1\}$, a fun√ß√£o discriminante linear pode ser definida como:
$$f(x) = \beta_0 + \sum_{j=1}^{p} x_j\beta_j = \beta^T x$$
onde $x$ √© o vetor de caracter√≠sticas, $\beta$ s√£o os coeficientes e $\beta_0$ o intercepto [^4.3]. Uma observa√ß√£o √© atribu√≠da √† classe +1 se $f(x) > 0$ e √† classe -1 caso contr√°rio. Este lemma demonstra que a decis√£o de classifica√ß√£o √© baseada no sinal de uma combina√ß√£o linear das features. O hiperplano de decis√£o √© dado por $f(x)=0$, que √© uma equa√ß√£o linear em $x$.

> üí° **Exemplo Num√©rico:**
> Suponha que temos duas caracter√≠sticas, $x_1$ e $x_2$, e os coeficientes estimados s√£o $\beta_0 = -1$, $\beta_1 = 2$ e $\beta_2 = 1$. A fun√ß√£o discriminante √© ent√£o $f(x) = -1 + 2x_1 + x_2$. Se tivermos uma observa√ß√£o com $x = [1, 1]$, ent√£o $f(x) = -1 + 2*1 + 1 = 2$. Como $f(x) > 0$, a observa√ß√£o seria classificada como +1. Por outro lado, se $x = [0, 0]$, ent√£o $f(x) = -1 + 2*0 + 0 = -1$, e a observa√ß√£o seria classificada como -1. O hiperplano de decis√£o √© dado por $-1 + 2x_1 + x_2 = 0$, que √© uma reta no espa√ßo 2D.
>
> ```mermaid
>  graph LR
>      A["x=(1,1)"] -->|f(x) = 2| B["Class +1"]
>      C["x=(0,0)"] -->|f(x) = -1| D["Class -1"]
>      E["Hiperplano"] -- "-1 + 2x1 + x2 = 0" --> F["Separa√ß√£o"]
> ```

**Conceito 2: Linear Discriminant Analysis (LDA)**
A **Linear Discriminant Analysis (LDA)** √© um m√©todo estat√≠stico para classifica√ß√£o que assume que os dados de cada classe seguem uma distribui√ß√£o normal com m√©dias diferentes, mas com a mesma matriz de covari√¢ncia [^4.3]. O objetivo da LDA √© encontrar uma combina√ß√£o linear das vari√°veis que maximiza a separa√ß√£o entre as m√©dias das classes e minimiza a varia√ß√£o dentro de cada classe.

```mermaid
graph LR
    subgraph "LDA Framework"
        direction TB
        A["Assumir Distribui√ß√£o Normal"]
        B["Maximizar Separa√ß√£o Inter-classe"]
        C["Minimizar Varia√ß√£o Intra-classe"]
        D["Fun√ß√£o Discriminante: Œ¥k(x)"]
        A --> B
        A --> C
        B & C --> D
    end
```

A fun√ß√£o discriminante da LDA para duas classes pode ser expressa como [^4.3.1]:
$$ \delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log \pi_k $$
onde $\mu_k$ √© a m√©dia da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum e $\pi_k$ √© a probabilidade *a priori* da classe $k$. A classifica√ß√£o √© realizada atribuindo a observa√ß√£o √† classe $k$ que maximiza $\delta_k(x)$.

**Corol√°rio 1:**
A fun√ß√£o discriminante linear na LDA pode ser vista como uma proje√ß√£o das observa√ß√µes em um subespa√ßo de dimens√£o reduzida. Especificamente, a fronteira de decis√£o na LDA √© uma linha reta (ou hiperplano em dimens√µes maiores) que divide o espa√ßo de caracter√≠sticas de forma a otimizar a separa√ß√£o entre as classes, ap√≥s uma proje√ß√£o linear [^4.3.1]. Para duas classes, esta proje√ß√£o corresponde ao vetor que maximiza a dist√¢ncia entre as m√©dias das classes, normalizada pela vari√¢ncia conjunta. Em termos matem√°ticos, essa proje√ß√£o $w$ √© dada por:
$$ w = \Sigma^{-1} (\mu_1 - \mu_2) $$
onde $\mu_1$ e $\mu_2$ s√£o as m√©dias das classes e $\Sigma$ √© a matriz de covari√¢ncia comum. Ao projetar os dados neste vetor, podemos separar as classes com um limiar.

> üí° **Exemplo Num√©rico:**
> Suponha que temos duas classes com m√©dias $\mu_1 = [1, 2]^T$ e $\mu_2 = [3, 1]^T$ e uma matriz de covari√¢ncia comum $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$.
>
> **Step 1:** Calcular a diferen√ßa das m√©dias: $\mu_1 - \mu_2 = [1-3, 2-1]^T = [-2, 1]^T$.
> **Step 2:** Calcular a inversa da matriz de covari√¢ncia: $\Sigma^{-1} = \frac{1}{1*1 - 0.5*0.5} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \frac{4}{3} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix}$.
> **Step 3:** Calcular o vetor de proje√ß√£o $w$: $w = \Sigma^{-1} (\mu_1 - \mu_2) = \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix} [-2, 1]^T =  [-10/3, 8/3]^T$.
>
> Este vetor $w$ define a dire√ß√£o na qual os dados devem ser projetados para maximizar a separa√ß√£o entre as classes. Ao projetar os dados neste vetor e definir um limiar, conseguimos classificar as observa√ß√µes em cada uma das classes.

**Conceito 3: Logistic Regression**
A **Logistic Regression** √© um m√©todo probabil√≠stico que modela a probabilidade de uma observa√ß√£o pertencer a uma determinada classe usando uma fun√ß√£o log√≠stica (sigm√≥ide) [^4.4]. Ao contr√°rio da LDA, a regress√£o log√≠stica n√£o assume que os dados seguem uma distribui√ß√£o normal, mas sim que a probabilidade de uma observa√ß√£o pertencer √† classe 1 dado o vetor de caracter√≠sticas *x* pode ser modelada como:

```mermaid
graph LR
    subgraph "Logistic Regression"
        A["Input x"] --> B["Linear Combination: Œ≤‚ÇÄ + Œ£x‚±ºŒ≤‚±º"]
        B --> C["Logistic Function: 1/(1+e^(-linear))"]
        C --> D["Probability P(y=1|x)"]
    end
```

$$ p(y=1|x) = \frac{1}{1+e^{-(\beta_0 + \sum_{j=1}^{p} x_j\beta_j)}} $$

Onde $\beta_0$ √© o intercepto e $\beta_j$ s√£o os coeficientes associados √†s vari√°veis preditoras $x_j$. A fun√ß√£o log√≠stica transforma uma combina√ß√£o linear de entradas em uma probabilidade entre 0 e 1. Os coeficientes $\beta$ s√£o estimados por meio da maximiza√ß√£o da verossimilhan√ßa.

> ‚ö†Ô∏è **Nota Importante**: Na Logistic Regression, a fun√ß√£o de verossimilhan√ßa $L(\beta)$ √© definida como o produto das probabilidades observadas, assumindo que as observa√ß√µes s√£o independentes [^4.4.1]. O objetivo √© encontrar os par√¢metros $\beta$ que maximizam essa fun√ß√£o, geralmente resolvido usando m√©todos iterativos como o gradient descent.
> ‚ùó **Ponto de Aten√ß√£o**: A regress√£o log√≠stica pode apresentar problemas em situa√ß√µes com classes n√£o balanceadas, onde uma classe predomina sobre a outra. √â necess√°rio ajustar os pesos das classes ou utilizar outras t√©cnicas de balanceamento para mitigar esse problema [^4.4.2].
> ‚úîÔ∏è **Destaque**: Uma importante conex√£o entre LDA e regress√£o log√≠stica reside no fato de que, sob a suposi√ß√£o de que as covari√¢ncias s√£o iguais, o limite de decis√£o da LDA pode ser expresso como uma fun√ß√£o linear de *x*, similar √† forma funcional utilizada na regress√£o log√≠stica. Entretanto, a forma como os par√¢metros s√£o estimados difere em cada m√©todo [^4.5].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
flowchart TD
  subgraph "Regress√£o de Indicadores"
    A["Codifica√ß√£o de Classes em Matriz Y"] --> B["Estimar Coeficientes Œ≤ via M√≠nimos Quadrados"]
    B --> C["Regra de Decis√£o: Classe com Maior Valor Predito"]
    C --> D["Compara√ß√£o com M√©todos Probabil√≠sticos"]
  end
```
**Explica√ß√£o:** Este diagrama representa o fluxo do processo de regress√£o de indicadores e como ele se relaciona √† classifica√ß√£o, **conforme descrito nos t√≥picos [1](4.2)**.

A regress√£o linear pode ser utilizada para fins de classifica√ß√£o atrav√©s da codifica√ß√£o das classes em uma matriz indicadora e, posteriormente, ajustando um modelo linear a essa matriz usando o m√©todo de m√≠nimos quadrados [^4.2]. Se temos $K$ classes, para cada observa√ß√£o criamos um vetor de *K* elementos, onde o elemento $k$ √© 1 se a observa√ß√£o pertence √† classe *k* e 0 caso contr√°rio. O modelo de regress√£o linear ajusta um vetor de par√¢metros $\beta$ para cada classe, e a classifica√ß√£o da observa√ß√£o se d√° pela classe com maior valor predito.
A abordagem de regress√£o linear para classifica√ß√£o tamb√©m tem suas limita√ß√µes. Uma delas √© a possibilidade de previs√µes fora do intervalo [0,1], o que √© problem√°tico para interpreta√ß√£o como probabilidade. Al√©m disso, a distribui√ß√£o dos res√≠duos n√£o √© necessariamente normal, que √© uma suposi√ß√£o do m√©todo de m√≠nimos quadrados, e pode levar a resultados sub√≥timos [^4.2].

**Lemma 2:** Em um cen√°rio de regress√£o linear para classifica√ß√£o, a solu√ß√£o para os coeficientes $\beta$ usando m√≠nimos quadrados √© dada por:
$$ \hat{\beta} = (X^T X)^{-1} X^T Y $$
onde $X$ √© a matriz de vari√°veis preditoras e $Y$ √© a matriz indicadora de classes. Este lemma mostra como a solu√ß√£o da regress√£o linear para classifica√ß√£o √© obtida atrav√©s de um procedimento an√°logo ao da regress√£o tradicional [^4.2]. Em situa√ß√µes onde os dados s√£o bem separados por uma fronteira linear, essa solu√ß√£o de m√≠nimos quadrados pode convergir para uma fronteira de decis√£o similar aos m√©todos de discriminante linear.

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos 3 observa√ß√µes e 2 classes. As vari√°veis preditoras s√£o $x_1$ e $x_2$. As observa√ß√µes e suas respectivas classes s√£o:
> - Observa√ß√£o 1: $x = [1, 2]$, Classe 1
> - Observa√ß√£o 2: $x = [2, 1]$, Classe 2
> - Observa√ß√£o 3: $x = [3, 3]$, Classe 1
>
> Primeiro, criamos a matriz de vari√°veis preditoras $X$ e a matriz indicadora de classes $Y$:
>
> $X = \begin{bmatrix} 1 & 1 & 2 \\ 1 & 2 & 1 \\ 1 & 3 & 3 \end{bmatrix}$, (primeira coluna de '1' para o intercepto)
> $Y = \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix}$
>
> **Step 1:** Calcular $X^T X$:
> $X^T X = \begin{bmatrix} 1 & 1 & 1 \\ 1 & 2 & 3 \\ 2 & 1 & 3 \end{bmatrix} \begin{bmatrix} 1 & 1 & 2 \\ 1 & 2 & 1 \\ 1 & 3 & 3 \end{bmatrix} = \begin{bmatrix} 3 & 6 & 6 \\ 6 & 14 & 13 \\ 6 & 13 & 14 \end{bmatrix} $
>
> **Step 2:** Calcular a inversa de $X^T X$, denotada como $(X^T X)^{-1}$:
> $(X^T X)^{-1} \approx \begin{bmatrix} 5.667 & -1.333 & -1.333 \\ -1.333 & 0.667 & 0 \\ -1.333 & 0 & 0.667 \end{bmatrix}$
>
> **Step 3:** Calcular $X^T Y$:
> $X^T Y = \begin{bmatrix} 1 & 1 & 1 \\ 1 & 2 & 3 \\ 2 & 1 & 3 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix} = \begin{bmatrix} 2 & 1 \\ 4 & 2 \\ 5 & 1 \end{bmatrix}$
>
> **Step 4:** Calcular $\hat{\beta} = (X^T X)^{-1} X^T Y$:
> $\hat{\beta} = \begin{bmatrix} 5.667 & -1.333 & -1.333 \\ -1.333 & 0.667 & 0 \\ -1.333 & 0 & 0.667 \end{bmatrix} \begin{bmatrix} 2 & 1 \\ 4 & 2 \\ 5 & 1 \end{bmatrix} \approx \begin{bmatrix} 1.33 & 1.00 \\ -0.66 & 0 \\ -0.66 & 0 \end{bmatrix}$
>
> As duas colunas de $\hat{\beta}$ correspondem aos coeficientes para cada classe. Para classificar uma nova observa√ß√£o, multiplicamos seu vetor de caracter√≠sticas pela matriz de coeficientes, adicionando o intercepto, e a classe com maior valor predito √© atribu√≠da.

**Corol√°rio 2:** A solu√ß√£o por m√≠nimos quadrados, dada no Lemma 2, se equipara √† solu√ß√£o de LDA sob certas condi√ß√µes restritivas. Especificamente, se as matrizes de covari√¢ncia para cada classe forem id√™nticas e se as classes forem bem separadas, a regress√£o linear de indicadores pode fornecer uma fronteira de decis√£o muito semelhante √† LDA. Isso pode ser demonstrado quando as classes s√£o igualmente distribu√≠das e separ√°veis, a proje√ß√£o no espa√ßo de decis√£o em ambas abordagens tende a ser muito similar [^4.3].

"Em alguns cen√°rios, conforme apontado em [^4.4], a regress√£o log√≠stica pode fornecer estimativas mais est√°veis de probabilidade, enquanto a regress√£o de indicadores pode levar a extrapola√ß√µes fora de [0,1]."

"No entanto, h√° situa√ß√µes em que a regress√£o de indicadores, de acordo com [^4.2], √© suficiente e at√© mesmo vantajosa quando o objetivo principal √© a fronteira de decis√£o linear."

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["Penaliza√ß√£o L1 (Lasso)"]
        B["Penaliza√ß√£o L2 (Ridge)"]
        C["Elastic Net (L1 + L2)"]
        D["Controle da Complexidade do Modelo"]
        E["Evitar Overfitting"]
        A --> D
        B --> D
        C --> D
        D --> E
    end
```

Na classifica√ß√£o, m√©todos de sele√ß√£o de vari√°veis e regulariza√ß√£o s√£o utilizados para controlar a complexidade do modelo e evitar *overfitting*, especialmente quando o n√∫mero de vari√°veis preditoras √© alto [^4.5]. Isso √© crucial para a estabilidade e interpretabilidade do modelo. A **penaliza√ß√£o L1** (Lasso) adiciona um termo na fun√ß√£o de custo que √© proporcional √† soma dos valores absolutos dos coeficientes. Isso leva √† esparsidade, ou seja, muitos coeficientes s√£o levados a zero, resultando em uma sele√ß√£o de vari√°veis. A **penaliza√ß√£o L2** (Ridge), por sua vez, adiciona um termo proporcional √† soma dos quadrados dos coeficientes, o que reduz a magnitude dos coeficientes e melhora a estabilidade do modelo [^4.4.4]. A combina√ß√£o das duas penaliza√ß√µes, conhecida como **Elastic Net**, busca aproveitar os benef√≠cios de ambas: esparsidade e estabilidade [^4.5].

**Lemma 3:** Em regress√£o log√≠stica com penaliza√ß√£o L1, a fun√ß√£o de custo a ser minimizada √©:
$$ J(\beta) = - \frac{1}{N} \sum_{i=1}^N \left[ y_i \log(p(x_i)) + (1-y_i)\log(1-p(x_i)) \right] + \lambda \sum_{j=1}^p |\beta_j| $$
onde $p(x_i)$ √© a probabilidade estimada, $N$ √© o n√∫mero de amostras, $\lambda$ √© o par√¢metro de regulariza√ß√£o e $\sum_{j=1}^p |\beta_j|$ √© a penaliza√ß√£o L1. A penaliza√ß√£o L1 favorece solu√ß√µes esparsas, onde muitos $\beta_j$ s√£o exatamente zero, o que automaticamente realiza sele√ß√£o de vari√°veis [^4.4.4].

**Prova do Lemma 3:** A prova do Lemma 3 envolve analisar a natureza da penaliza√ß√£o L1 e como ela interage com o processo de otimiza√ß√£o da fun√ß√£o de custo. Em uma abordagem de otimiza√ß√£o, os par√¢metros s√£o atualizados iterativamente, e o termo de penaliza√ß√£o L1 introduz um ponto de n√£o diferenciabilidade na origem. Isso implica que, em cada itera√ß√£o, quando um $\beta_j$ tem um valor pr√≥ximo de zero, o processo de otimiza√ß√£o tender√° a lev√°-lo exatamente a zero ao inv√©s de apenas reduzir sua magnitude, o que leva √† esparsidade [^4.4.3], [^4.4.4]. $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Suponha que estamos ajustando uma regress√£o log√≠stica com duas vari√°veis preditoras e temos uma fun√ß√£o de custo com penaliza√ß√£o L1. Para ilustrar a import√¢ncia da regulariza√ß√£o L1, considere os par√¢metros estimados sem regulariza√ß√£o como $\beta_1 = 1.5$ e $\beta_2 = -0.8$. Agora, com uma penaliza√ß√£o L1 ($\lambda = 0.5$), o modelo ajusta esses coeficientes para minimizar a fun√ß√£o de custo incluindo o termo $\lambda \sum_{j=1}^p |\beta_j|$. Se $\beta_1$ e $\beta_2$ s√£o ajustados para $\beta_1' = 1$ e $\beta_2' = 0$, a soma dos valores absolutos dos coeficientes seria $|1| + |0| = 1$, enquanto antes era $|1.5| + |-0.8| = 2.3$.
>
> O efeito da regulariza√ß√£o L1 √© levar o coeficiente $\beta_2$ a zero, efetivamente removendo a vari√°vel preditora $x_2$ do modelo. Isso demonstra como a penaliza√ß√£o L1 induz esparsidade. Abaixo, uma tabela comparando os resultados com diferentes $\lambda$ valores:
>
> |  Œª  | Œ≤_1 | Œ≤_2 | Œ£|Œ≤_j| |  Interpreta√ß√£o       |
> |-----|-----|-----|-------|----------------------|
> | 0.0 | 1.5 | -0.8| 2.3   |  Nenhuma Regulariza√ß√£o       |
> | 0.5 | 1.0 |  0.0| 1.0   |  Œ≤_2 √© removido do modelo   |
> | 1.0 | 0.5 | 0.0 | 0.5   |  Œ≤_2 √© removido do modelo, Œ≤_1 reduzido |
>
> Isso demonstra como o aumento de Œª leva a uma maior penaliza√ß√£o e esparsidade no modelo.
>
> ```python
> import numpy as np
>
> def logistic_cost_l1(y, p, beta, l):
>     n = len(y)
>     cost = -np.sum(y*np.log(p) + (1-y)*np.log(1-p))/n + l * np.sum(np.abs(beta))
>     return cost
>
> y = np.array([1, 0, 1, 0])
> p = np.array([0.8, 0.2, 0.9, 0.1])
> beta_initial = np.array([1.5, -0.8])
>
> lambda_values = [0, 0.5, 1]
> for l in lambda_values:
>     beta_optimized = np.array([1, 0]) if l == 0.5 else np.array([0.5, 0]) if l == 1 else beta_initial
>     cost_l1 = logistic_cost_l1(y, p, beta_optimized, l)
>     print(f"Custo para lambda={l}: {cost_l1}")
> ```

**Corol√°rio 3:** A propriedade de esparsidade induzida pela penaliza√ß√£o L1 em modelos de classifica√ß√£o log√≠stica oferece uma vantagem significativa na interpretabilidade dos modelos. Ao selecionar um subconjunto de vari√°veis, o modelo torna-se mais f√°cil de entender e comunicar [^4.4.5]. Isso √© particularmente importante em dom√≠nios onde a interpretabilidade √© t√£o crucial quanto a acur√°cia preditiva.

> ‚ö†Ô∏è **Ponto Crucial**: L1 e L2 podem ser combinadas (Elastic Net) para aproveitar vantagens de ambos os tipos de regulariza√ß√£o, **conforme discutido em [^4.5]**.

### Separating Hyperplanes e Perceptrons

A ideia de encontrar o melhor hiperplano para separar classes de dados levou ao desenvolvimento de modelos como o Perceptron e as **Support Vector Machines (SVM)**, este √∫ltimo baseado na maximiza√ß√£o da margem de separa√ß√£o entre as classes. Um **hiperplano** √© um espa√ßo linear que divide os dados em duas partes e √© definido por uma equa√ß√£o da forma $\beta^T x + \beta_0 = 0$ [^4.5.2]. O conceito de margem de separa√ß√£o representa a dist√¢ncia entre o hiperplano e os pontos de dados mais pr√≥ximos (pontos de suporte).

```mermaid
graph LR
  subgraph "Separating Hyperplane"
    A["Input Data (x)"] --> B["Weighted Sum: Œ≤^T x + Œ≤‚ÇÄ"]
    B --> C{"Decision:  Sign(Œ≤^T x + Œ≤‚ÇÄ) "}
    C --> D["Class Label (+1 or -1)"]
  end
  style C fill:#f9f,stroke:#333,stroke-width:2px
```

O **Perceptron de Rosenblatt** √© um algoritmo de classifica√ß√£o linear que ajusta um hiperplano iterativamente com base nos erros de classifica√ß√£o, utilizando o conceito de *gradient descent* [^4.5.1]. Ele recebe um vetor de *features*, aplica um peso a cada um, e calcula a soma ponderada adicionando um valor constante, que corresponde ao bias. A classe predita corresponde ao sinal da fun√ß√£o discriminante e, em caso de erro, o modelo √© ajustado at√© que os erros sejam minimizados. No entanto, se os dados n√£o forem linearmente separ√°veis, o Perceptron pode n√£o convergir, o que pode ser um limitador no uso de abordagens lineares para problemas mais complexos.

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**
A LDA e a Regra de Decis√£o Bayesiana, sob a suposi√ß√£o de distribui√ß√µes Gaussianas com covari√¢ncias iguais, s√£o intimamente relacionadas, mas diferem em sua abordagem e deriva√ß√£o [^4.3]. A Regra de Decis√£o Bayesiana busca a classe que maximiza a probabilidade *a posteriori*:
$$P(C_k|x) = \frac{P(x|C_k)P(C_k)}{P(x)}$$
onde $P(x|C_k)$ √© a densidade de probabilidade da classe $C_k$, $P(C_k)$ √© a probabilidade a priori e $P(x)$ √© a probabilidade da observa√ß√£o *x*. Quando as classes seguem distribui√ß√µes Gaussianas com mesma matriz de covari√¢ncia $\Sigma$ e m√©dias $\mu_k$, a regra de decis√£o se transforma em uma fun√ß√£o discriminante linear:
$$ \delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log \pi_k $$
Essa fun√ß√£o √© equivalente √† fun√ß√£o discriminante da LDA [^4.3]. A principal diferen√ßa √© que a LDA estima os par√¢metros $\mu_k$ e $\Sigma$ a partir dos dados, enquanto a Regra Bayesiana assume que essas distribui√ß√µes s√£o conhecidas. Sob a suposi√ß√£o de distribui√ß√µes Gaussianas com covari√¢ncias iguais, LDA busca uma proje√ß√£o linear √≥tima para separar as classes, enquanto a Regra Bayesiana encontra uma probabilidade *a posteriori* √≥tima. Quando a suposi√ß√£o de normalidade √© v√°lida, a LDA oferece uma aproxima√ß√£o da Regra Bayesiana [^4.3].

**Lemma 4:**
Se as distribui√ß√µes condicionais das vari√°veis de entrada *x* dadas as classes $C_k$ s√£o Gaussianas com a mesma matriz de covari√¢ncia $\Sigma$ e m√©dias $\mu_k$, a Regra de Decis√£o Bayesiana se torna equivalente √† LDA. Formalmente:
$$ P(x|C_k) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}} e^{-\frac{1}{2}(x-\mu_k)^T\Sigma^{-1}(x-\mu_k)} $$
Substituindo na regra Bayesiana e considerando as probabilidades *a priori* $\pi_k$, a fun√ß√£o discriminante resultante ser√°:
$$ \delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log \pi_k $$
que √© id√™ntica √† fun√ß√£o discriminante da LDA [^4.3], [^4.3.3]. $\blacksquare$

```mermaid
graph LR
    subgraph "LDA vs Bayesian Decision Rule"
        direction TB
        A["Gaussian Distributions with Equal Covariance"]
        B["Bayesian Rule: Maximize P(Ck|x)"]
        C["LDA: Maximize Separation"]
        D["Resulting Discriminant Function (Equivalent)"]
         A --> B
         A --> C
         B & C --> D
    end
```

**Corol√°rio 4:** Ao relaxarmos a suposi√ß√£o de que as matrizes de covari√¢ncia s√£o iguais para todas as classes, as fronteiras de decis√£o na Regra de Decis√£o Bayesiana tornam-se quadr√°ticas, originando o **Quadratic Discriminant Analysis (QDA)** [^4.3]. Cada classe ter√° sua pr√≥pria matriz de covari√¢ncia $\Sigma_k$, e a fun√ß√£o discriminante resultante ser√°:
$$ \delta_k(x) = -\frac{1}{2}\log|\Sigma_k| - \frac{1}{2}(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k) + \log \pi_k $$
Essa fun√ß√£o √© quadr√°tica em *x* devido √† presen√ßa do termo $(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k)$, resultando em fronteiras de decis√£o curvas, ao contr√°rio das fronteiras lineares da LDA.

> ‚ö†Ô∏è **Ponto Crucial**: A ado√ß√£o ou n√£o de covari√¢ncias iguais impacta fortemente o tipo de fronteira de decis√£o (linear vs. quadr√°tica), **conforme discutido em [^4.3.1]**.

### Conclus√£o
Este cap√≠tulo abordou os fundamentos e as aplica√ß√µes de m√©todos lineares para regress√£o e classifica√ß√£o, incluindo LDA, regress√£o log√≠stica, regress√£o linear de indicadores e m√©todos de regulariza√ß√£o. Cada um desses m√©todos oferece uma perspectiva diferente sobre como abordar problemas de classifica√ß√£o, seja atrav√©s de proje√ß√µes lineares otimizadas, modelos probabil√≠sticos ou penalidades para evitar overfitting. A rela√ß√£o entre esses m√©todos e suas limita√ß√µes foram exploradas, enfatizando que a escolha do m√©todo depende da natureza dos dados e do problema em quest√£o. O estudo detalhado de cada m√©todo, aliado a exerc√≠cios e an√°lises, visa aprimorar a compreens√£o dos profissionais em estat√≠stica e aprendizado de m√°quina.

### Footnotes
[^4.1]: "A linear regression model assumes that the regression function E(Y|X) is linear in the inputs X1,..., Xp. Linear models were largely developed in the precomputer age of statistics, but even in today's computer era there are still good reasons to study and use them." *(Trecho de Linear Methods for Regression)*
[^4.2]: "As introduced in Chapter 2, we have an input vector XT = (X1, X2, ..., Xp), and want to predict a real-valued output Y. The linear regression model has the form ... The linear model either assumes that the regression function E(Y|X) is linear, or that the linear model is a reasonable approximation." *(Trecho de Linear Methods for Regression)*
[^4.3]: "In this chapter we describe linear methods for regression, while in the next chapter we discuss linear methods for classification." *(Trecho de Linear Methods for Regression)*
[^4.3.1]: "These generalizations are sometimes called basis-function methods, and are discussed in Chapter 5." *(Trecho de Linear Methods for Regression)*
[^4.3.2]: "On some topics we go into considerable detail, as it is our firm belief that an understanding of linear methods is essential for understanding nonlinear ones." *(Trecho de Linear Methods for Regression)*
[^4.3.3]: "In fact, many nonlinear techniques are direct generalizations of the linear methods discussed here." *(Trecho de Linear Methods for Regression)*
[^4.4]: "The linear model either assumes that the regression function E(Y|X) is linear, or that the linear model is a reasonable approximation." *(Trecho de Linear Methods for Regression)*
[^4.4.1]: "Here the Bj's are unknown parameters or coefficients, and the variables X; can come from different sources:" *(Trecho de Linear Methods for Regression)*
[^4.4.2]: "quantitative inputs; transformations of quantitative inputs, such as log, square-root or square;" *(Trecho de Linear Methods for Regression)*
[^4.4.3]: "basis expansions, such as X2 = X1, X3 = X3, leading to a polynomial representation;" *(Trecho de Linear Methods for Regression)*
[^4.4.4]: "numeric or "dummy" coding of the levels of qualitative inputs. For example, if G is a five-level factor input, we might create Xj, j = 1,...,5, such that Xj = I(G = j)." *(Trecho de Linear Methods for Regression)*
[^4.4.5]: "interacctions between variables, for example, X3 = X1 X2." *(Trecho de Linear Methods for Regression)*
[^4.5]: "No matter the source of the Xj, the model is linear in the parameters." *(Trecho de Linear Methods for Regression)*
[^4.5.1]: "Typically we have a set of training data (X1,Y1) ... (xn, yn) from which to estimate the parameters Œ≤." *(Trecho de Linear Methods for Regression)*
[^4.5.2]: "Each xi = (Xi1, Xi2,...,xip)T is a vector of feature measurements for the ith case." *(Trecho de Linear Methods for Regression)*
