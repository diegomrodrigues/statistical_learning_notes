## MÃ©todos Lineares para RegressÃ£o: Algoritmos Iterativos e Ajuste de Coeficientes

```mermaid
graph TB
    subgraph "Iterative Variable Selection"
        direction TB
        A["Initialize: Start with no predictors"]
        B["Identify Best Predictor: Evaluate all"]
        C["Adjust Coefficients: Update model"]
        D["Check Convergence: Has model stabilized?"]
        E["Repeat: If not converged"]
        F["Final Model: Converged"]
        A --> B
        B --> C
        C --> D
        D -- "No" --> E
        D -- "Yes" --> F
        E --> B
        style B fill:#f9f,stroke:#333,stroke-width:2px
        style D fill:#ccf,stroke:#333,stroke-width:2px
        linkStyle 0,1,2,3,4 stroke:#333,stroke-width:2px;
    end
    subgraph "Regularization"
        direction LR
        G["L1 Regularization: Shrinks coeffs to zero"]
        H["L2 Regularization: Reduces coeff magnitude"]
        I["Evaluation Metrics: R2, RMSE, etc."]
        G --> I
        H --> I
        linkStyle 5,6 stroke:#00f,stroke-width:2px;
    end
    A --> G
    A --> H
    linkStyle 7 stroke:#00f,stroke-width:2px;
```

### IntroduÃ§Ã£o
O campo dos modelos de regressÃ£o linear, apesar de suas raÃ­zes histÃ³ricas, continua sendo um pilar fundamental na anÃ¡lise estatÃ­stica e aprendizado de mÃ¡quina [^4.1]. A simplicidade, interpretabilidade e, em muitos casos, a eficÃ¡cia preditiva desses modelos os tornam ferramentas indispensÃ¡veis [^4.1]. Em particular, quando se trabalha com dados escassos, de baixa razÃ£o sinal-ruÃ­do ou com um nÃºmero limitado de amostras, os mÃ©todos lineares frequentemente superam modelos nÃ£o-lineares mais complexos [^4.1]. Este capÃ­tulo aprofunda a compreensÃ£o dos mÃ©todos lineares para regressÃ£o, com Ãªnfase nos processos iterativos para ajuste de coeficientes e seleÃ§Ã£o de variÃ¡veis, cruciais para a construÃ§Ã£o de modelos robustos e precisos. AlÃ©m disso, exploraremos como esses mÃ©todos sÃ£o a base para tÃ©cnicas mais avanÃ§adas em anÃ¡lise de dados.

### Conceitos Fundamentais

**Conceito 1: O Problema de ClassificaÃ§Ã£o e MÃ©todos Lineares**

O problema de classificaÃ§Ã£o busca alocar instÃ¢ncias a uma ou mais classes predefinidas. A abordagem linear, assume que uma combinaÃ§Ã£o linear dos inputs pode criar um limite de decisÃ£o eficiente [^4.1]. Essa linearidade, no entanto, traz consigo um trade-off entre viÃ©s e variÃ¢ncia. Um modelo muito simples pode sofrer de alto viÃ©s (subajuste), enquanto um modelo linear muito complexo pode levar a alta variÃ¢ncia (sobreajuste) [^4.1]. A escolha de usar ou nÃ£o mÃ©todos lineares em classificaÃ§Ã£o deve ser sempre guiada pela avaliaÃ§Ã£o desses fatores. Por exemplo, em cenÃ¡rios com uma clara separaÃ§Ã£o linear entre as classes, um modelo linear pode ser suficiente e vantajoso, enquanto em situaÃ§Ãµes mais complexas, abordagens nÃ£o-lineares ou mÃ©todos de regularizaÃ§Ã£o podem ser mais apropriadas.

**Lemma 1:** Dada uma funÃ§Ã£o discriminante linear $f(x) = w^T x + b$, onde $w$ Ã© o vetor de pesos e $b$ Ã© o bias, a decisÃ£o de classe Ã© baseada no sinal de $f(x)$. Para um problema de classificaÃ§Ã£o binÃ¡ria, a decisÃ£o pode ser formalizada como:

$$
\text{Classe}(x) = 
\begin{cases}
    1 & \text{se } f(x) > 0 \\
    0 & \text{se } f(x) \leq 0
\end{cases}
$$

Essa representaÃ§Ã£o linear Ã© a base da Linear Discriminant Analysis (LDA) [^4.3].

> ðŸ’¡ **Exemplo NumÃ©rico:** Considere um exemplo bidimensional simples com dois pontos, um da classe 1 em $x_1 = [2, 3]$ e outro da classe 0 em $x_2 = [1, 1]$. Vamos supor que, apÃ³s o treinamento, o modelo linear encontre $w = [1, -1]$ e $b = 0.5$. Para o ponto $x_1$, temos $f(x_1) = [1, -1]^T [2, 3] + 0.5 = 2 - 3 + 0.5 = -0.5$. Como $f(x_1) < 0$, ele seria classificado como classe 0, o que estÃ¡ errado. Para o ponto $x_2$, temos $f(x_2) = [1, -1]^T [1, 1] + 0.5 = 1 - 1 + 0.5 = 0.5$. Como $f(x_2) > 0$, ele seria classificado como classe 1, o que tambÃ©m estÃ¡ errado. Isso ilustra que uma funÃ§Ã£o discriminante linear simples pode levar a erros, especialmente se os dados nÃ£o forem linearmente separÃ¡veis. Um ajuste mais preciso dos parÃ¢metros $w$ e $b$ seria necessÃ¡rio para uma correta classificaÃ§Ã£o.

**Conceito 2: Linear Discriminant Analysis (LDA)**

A LDA Ã© um mÃ©todo clÃ¡ssico de classificaÃ§Ã£o que busca projetar dados em um espaÃ§o de dimensÃ£o inferior, maximizando a separaÃ§Ã£o entre as classes [^4.3]. A LDA assume que os dados dentro de cada classe seguem uma distribuiÃ§Ã£o normal com a mesma matriz de covariÃ¢ncia [^4.3.1], [^4.3.2]. A funÃ§Ã£o discriminante linear na LDA Ã© derivada da aplicaÃ§Ã£o da regra de decisÃ£o Bayesiana sob estas suposiÃ§Ãµes, resultando em fronteiras lineares entre as classes.
A funÃ§Ã£o discriminante para cada classe $k$ Ã© dada por:

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + log(\pi_k)
$$

onde $\mu_k$ Ã© a mÃ©dia da classe $k$, $\Sigma$ Ã© a matriz de covariÃ¢ncia comum, e $\pi_k$ Ã© a probabilidade a priori da classe $k$ [^4.3.3].
A decisÃ£o de classe Ã© feita atribuindo a instÃ¢ncia $x$ Ã  classe $k$ para a qual $\delta_k(x)$ Ã© mÃ¡xima. A LDA tem uma forte ligaÃ§Ã£o com a anÃ¡lise de variÃ¢ncia (ANOVA) [^4.3.1].

```mermaid
graph TB
    subgraph "LDA Discriminant Function"
        direction TB
        A["Discriminant Function: Î´_k(x)"]
        B["Term 1: xáµ€Î£â»Â¹Î¼â‚–"]
        C["Term 2: -1/2 Î¼â‚–áµ€Î£â»Â¹Î¼â‚–"]
        D["Term 3: log(Ï€â‚–)"]
        A --> B
        A --> C
        A --> D
        linkStyle 0,1,2 stroke:#00f,stroke-width:2px;
    end
    subgraph "LDA Components"
        direction LR
        E["Î¼â‚–: Class Mean Vector"]
        F["Î£: Shared Covariance Matrix"]
        G["Ï€â‚–: Prior Class Probability"]
        E --> B
        F --> B
        E --> C
        F --> C
        G --> D
        linkStyle 3,4,5 stroke:#00f,stroke-width:2px;
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:** Considere um problema de classificaÃ§Ã£o com duas classes. Suponha que a classe 1 tenha mÃ©dia $\mu_1 = [2, 2]^T$ e a classe 2 tenha mÃ©dia $\mu_2 = [4, 4]^T$. A matriz de covariÃ¢ncia comum Ã© $\Sigma = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$.  As probabilidades a priori sÃ£o $\pi_1 = \pi_2 = 0.5$.  Vamos calcular a funÃ§Ã£o discriminante para um ponto $x=[3,3]^T$.

> $\Sigma^{-1} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$

> $\delta_1(x) = [3, 3] \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} [2, 2]^T - \frac{1}{2} [2, 2] \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} [2, 2]^T + \log(0.5)$
> $\delta_1(x) = (3*2 + 3*2) - \frac{1}{2} (2*2 + 2*2) + \log(0.5) = 12 - 4 - 0.693 = 7.307$

> $\delta_2(x) = [3, 3] \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} [4, 4]^T - \frac{1}{2} [4, 4] \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} [4, 4]^T + \log(0.5)$
> $\delta_2(x) = (3*4 + 3*4) - \frac{1}{2} (4*4 + 4*4) + \log(0.5) = 24 - 16 - 0.693 = 7.307$

> Como $\delta_1(x)$ e $\delta_2(x)$ sÃ£o iguais, a decisÃ£o seria que o ponto $x$ estÃ¡ no limiar de decisÃ£o.

**CorolÃ¡rio 1:** A funÃ§Ã£o discriminante linear da LDA pode ser vista como uma projeÃ§Ã£o dos dados em um subespaÃ§o de dimensÃ£o inferior, onde a separaÃ§Ã£o entre classes Ã© maximizada. A projeÃ§Ã£o Ã© dada pela matriz de projeÃ§Ã£o:

$$
W = S_W^{-1}(M_1-M_2)
$$

onde $S_W$ Ã© a matriz de covariÃ¢ncia dentro das classes, e $M_1$ e $M_2$ sÃ£o os vetores mÃ©dios das classes. Essa projeÃ§Ã£o linear garante que as classes sejam o mais separadas possÃ­veis dentro desse novo espaÃ§o [^4.3.1].

```mermaid
graph TB
    subgraph "LDA Projection"
      direction TB
      A["Projection Matrix: W"]
      B["S_Wâ»Â¹: Inverse Within-class Covariance"]
      C["Mâ‚-Mâ‚‚: Class Mean Difference"]
      A --> B
      A --> C
     linkStyle 0,1 stroke:#00f,stroke-width:2px;
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:** Usando os dados do exemplo anterior, suponha que temos duas classes com as seguintes amostras: Classe 1: $[[1,1], [2,2], [3,1]]$, Classe 2: $[[3,3], [4,4], [5,3]]$. Calculamos as mÃ©dias: $M_1 = [2, 1.33]$ e $M_2 = [4, 3.33]$. Primeiro, calculamos a matriz de covariÃ¢ncia dentro das classes ($S_W$):

> Calculando as matrizes de covariancia para cada classe e somando elas temos uma matriz $S_w =  \begin{bmatrix} 0.66 & 0.16 \\ 0.16 & 0.89 \end{bmatrix}$

> Agora,  calculamos $S_W^{-1}$:

> $S_W^{-1} \approx \begin{bmatrix} 1.55 & -0.28 \\ -0.28 & 1.15 \end{bmatrix}$
>
> Em seguida, calculamos a matriz de projeÃ§Ã£o:
> $W = S_W^{-1}(M_1-M_2) = \begin{bmatrix} 1.55 & -0.28 \\ -0.28 & 1.15 \end{bmatrix} \begin{bmatrix} -2 \\ -2 \end{bmatrix} = \begin{bmatrix} -2.54 \\ -2.84 \end{bmatrix}$

> Esta matriz de projeÃ§Ã£o $W$ pode ser usada para projetar novas amostras em um novo espaÃ§o unidimensional, onde as classes sÃ£o mais separÃ¡veis.

**Conceito 3: RegressÃ£o LogÃ­stica**

A RegressÃ£o LogÃ­stica, embora classificada como um mÃ©todo de classificaÃ§Ã£o, utiliza a funÃ§Ã£o logÃ­stica para modelar a probabilidade de uma instÃ¢ncia pertencer a uma classe [^4.4]. Diferentemente da LDA, ela nÃ£o assume normalidade dos dados e nÃ£o Ã© restrita a distribuiÃ§Ãµes gaussianas. O modelo da RegressÃ£o LogÃ­stica transforma a probabilidade usando a funÃ§Ã£o *logit*:

$$
\text{logit}(p(x)) = \ln\left(\frac{p(x)}{1-p(x)}\right) = \beta_0 + \beta^T x
$$

onde $p(x)$ Ã© a probabilidade de $x$ pertencer a uma classe. Os parÃ¢metros $\beta_0$ e $\beta$ sÃ£o estimados maximizando a funÃ§Ã£o de verossimilhanÃ§a [^4.4.1], [^4.4.2], [^4.4.3], [^4.4.4], [^4.4.5]. A regressÃ£o logÃ­stica tambÃ©m pode ser vista como um caso especial de modelos lineares generalizados (GLMs) [^4.4].

```mermaid
graph TB
    subgraph "Logistic Regression"
        direction TB
        A["logit(p(x))"]
        B["ln(p(x) / (1-p(x)))"]
        C["Î²â‚€ + Î²áµ€x"]
        A --> B
        A --> C
        linkStyle 0,1 stroke:#00f,stroke-width:2px;
    end
    subgraph "Logistic Function"
        direction LR
        D["p(x) = 1 / (1 + exp(-logit(p(x))))"]
       D --> A
        linkStyle 2 stroke:#00f,stroke-width:2px;
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:** Suponha que temos um modelo de regressÃ£o logÃ­stica com $\beta_0 = -3$ e $\beta = [1, 2]^T$. Para um ponto $x = [2, 1]^T$, calculamos o logit:

> $\text{logit}(p(x)) = -3 + 1*2 + 2*1 = 1$

> Para calcular a probabilidade, usamos a funÃ§Ã£o logÃ­stica inversa:

> $p(x) = \frac{1}{1 + e^{-\text{logit}(p(x))}} = \frac{1}{1 + e^{-1}} \approx \frac{1}{1 + 0.368} \approx 0.731$

> Isso indica que a probabilidade de $x$ pertencer Ã  classe 1 Ã© aproximadamente 0.731.

> âš ï¸ **Nota Importante**: Em casos de classes nÃ£o-balanceadas, a RegressÃ£o LogÃ­stica pode ser sensÃ­vel, necessitando ajustes nas probabilidades preditas ou no uso de tÃ©cnicas de reamostragem para evitar viÃ©s [^4.4.2].

> â— **Ponto de AtenÃ§Ã£o**: Embora ambos LDA e RegressÃ£o LogÃ­stica produzam fronteiras de decisÃ£o lineares, o mÃ©todo de estimaÃ§Ã£o dos parÃ¢metros Ã© diferente. A RegressÃ£o LogÃ­stica estima parÃ¢metros com base na maximizaÃ§Ã£o da verossimilhanÃ§a, enquanto a LDA utiliza a anÃ¡lise discriminante e as estatÃ­sticas de grupo [^4.5].

> âœ”ï¸ **Destaque**: Em algumas condiÃ§Ãµes, LDA e regressÃ£o logÃ­stica tendem a resultados muito similares, principalmente quando as classes sÃ£o bem separadas e as suposiÃ§Ãµes de normalidade sÃ£o aproximadamente satisfeitas [^4.5].

### RegressÃ£o Linear e MÃ­nimos Quadrados para ClassificaÃ§Ã£o
```mermaid
graph TB
    subgraph "Indicator Matrix Regression"
        direction TB
        A["Y = XÎ² + Îµ"]
        B["Y: Indicator Matrix"]
        C["X: Predictor Matrix"]
        D["Î²: Coefficients"]
        E["Îµ: Error Term"]
        A --> B
        A --> C
        A --> D
        A --> E
       linkStyle 0,1,2,3 stroke:#00f,stroke-width:2px;
    end
    subgraph "Class Prediction"
        direction LR
         F["Predicted Class = argmax_k (XÎ²)_k"]
         F --> A
         linkStyle 4 stroke:#00f,stroke-width:2px;
    end
```

A regressÃ£o linear pode ser adaptada para classificaÃ§Ã£o usando uma matriz de indicadores. Em vez de prever um valor contÃ­nuo, a regressÃ£o linear prediz um vetor de probabilidades de classe [^4.2]. Cada coluna da matriz de resposta representa uma classe, e a regressÃ£o linear Ã© aplicada a cada coluna separadamente. Os coeficientes de regressÃ£o obtidos podem entÃ£o ser usados para construir uma funÃ§Ã£o discriminante linear.
A regressÃ£o de uma matriz de indicadores pode ser formalizada como:

$$
Y = X \beta + \epsilon
$$

onde $Y$ Ã© a matriz de indicadores, $X$ Ã© a matriz de inputs, $\beta$ sÃ£o os coeficientes e $\epsilon$ Ã© o erro.
ApÃ³s o ajuste, a classe predita para uma nova amostra $x$ Ã© a que maximiza a saÃ­da do modelo linear. Embora simples, esta abordagem apresenta certas limitaÃ§Ãµes:

**Lemma 2:** A regressÃ£o linear de uma matriz de indicadores pode ser expressa como uma combinaÃ§Ã£o linear de hiperplanos. Seja $Y$ a matriz de indicadores de $n$ observaÃ§Ãµes e $k$ classes, $X$ a matriz de preditores, $\beta$ a matriz de coeficientes. O vetor de prediÃ§Ãµes de classes, $y_i$, para cada observaÃ§Ã£o $i$ serÃ¡ dado por $y_i = X_i \beta$.  A classe $c_i$ predita serÃ¡ dada por:

$$
c_i = argmax_k (y_i)_k
$$

Cada $(y_i)_k$ representa a projeÃ§Ã£o linear de $x_i$ no espaÃ§o da classe $k$. Essa projeÃ§Ã£o define um hiperplano para cada classe. A decisÃ£o final Ã© baseada em qual hiperplano tem a maior projeÃ§Ã£o [^4.2].

> ðŸ’¡ **Exemplo NumÃ©rico:** Considere um problema de classificaÃ§Ã£o com 3 classes e 2 preditores. Temos 5 observaÃ§Ãµes com a seguinte matriz de indicadores $Y$:
```
Y = [[1, 0, 0],  # Classe 1
     [0, 1, 0],  # Classe 2
     [0, 0, 1],  # Classe 3
     [1, 0, 0],  # Classe 1
     [0, 1, 0]]  # Classe 2
```
> E a seguinte matriz de preditores $X$:

```
X = [[1, 2],
     [2, 1],
     [3, 3],
     [1.5, 2.5],
     [2.5, 1.5]]
```
> ApÃ³s aplicar a regressÃ£o linear, obtemos os seguintes coeficientes $\beta$:

```
beta = [[ 0.9, -0.2,  0.1],
        [-0.1,  0.8, -0.2]]
```
> Para uma nova amostra $x=[2, 2]$, calculamos as projeÃ§Ãµes para cada classe:
>
> $y = x \beta = [2, 2] \begin{bmatrix} 0.9 & -0.2 & 0.1 \\ -0.1 & 0.8 & -0.2 \end{bmatrix} = [1.6, 1.2, -0.2]$
>
>  A classe predita para x Ã© a classe 1, porque tem o maior valor (1.6).

**CorolÃ¡rio 2:** Em problemas de classificaÃ§Ã£o com duas classes, a decisÃ£o de classe atravÃ©s da regressÃ£o linear de uma matriz indicadora Ã© equivalente a determinar de qual lado de um Ãºnico hiperplano de decisÃ£o uma amostra se encontra. Esse hiperplano Ã© dado por:

$$
H = \{x : (w_1 - w_2)^T x + (b_1 - b_2) = 0 \}
$$

onde $w_1, w_2$ e $b_1, b_2$ sÃ£o os pesos e bias para cada uma das classes, estimados via regressÃ£o. Em essÃªncia, a diferenÃ§a entre as projeÃ§Ãµes de cada classe determina o lado do hiperplano [^4.2], [^4.3].

> ðŸ’¡ **Exemplo NumÃ©rico:** Para um problema binÃ¡rio, suponha que apÃ³s a regressÃ£o linear, encontramos $w_1 = [1, 1]$ e $b_1 = 1$ para a classe 1, e $w_2 = [-1, 1]$ e $b_2 = -1$ para a classe 2. O hiperplano de decisÃ£o Ã©:

> $H = \{x : ([1, 1] - [-1, 1])^T x + (1 - (-1)) = 0 \}$
> $H = \{x : [2, 0]^T x + 2 = 0 \}$
> $H = \{x : 2x_1 + 2 = 0 \}$
> $H = \{x : x_1 = -1 \}$
> Este Ã© um hiperplano vertical em $x_1=-1$.

A regressÃ£o linear para classificaÃ§Ã£o pode sofrer do chamado "masking problem" [^4.3]. O masking ocorre quando algumas classes sÃ£o "mascaradas" por outras em termos de suas variÃ¡veis preditoras, levando a modelos que nÃ£o conseguem distinguir eficazmente certas classes. A covariÃ¢ncia entre as classes tambÃ©m afeta o desempenho do mÃ©todo [^4.3].

â€œEm alguns cenÃ¡rios, a regressÃ£o logÃ­stica pode fornecer estimativas mais estÃ¡veis de probabilidade, enquanto a regressÃ£o de indicadores pode levar a extrapolaÃ§Ãµes fora de [0,1]â€ [^4.4].
â€œNo entanto, hÃ¡ situaÃ§Ãµes em que a regressÃ£o de indicadores Ã© suficiente e atÃ© mesmo vantajosa quando o objetivo principal Ã© a fronteira de decisÃ£o linearâ€ [^4.2].

### MÃ©todos de SeleÃ§Ã£o de VariÃ¡veis e RegularizaÃ§Ã£o em ClassificaÃ§Ã£o
```mermaid
graph TB
    subgraph "Variable Selection"
        direction TB
        A["Feature Set"]
        B["Feature Subset"]
        C["Selection Method"]
        A --> C
        C --> B
        linkStyle 0,1 stroke:#00f,stroke-width:2px;
    end
        subgraph "Regularization"
        direction LR
        D["L1: Lasso"]
        E["L2: Ridge"]
        F["Elastic Net: L1 + L2"]
        B --> D
        B --> E
        B --> F
        linkStyle 2,3,4 stroke:#00f,stroke-width:2px;
    end
    subgraph "Classification Model"
        direction TB
         G["LDA"]
         H["Logistic Regression"]
         B --> G
         B --> H
       linkStyle 5,6 stroke:#00f,stroke-width:2px;
    end
```

A seleÃ§Ã£o de variÃ¡veis Ã© essencial em modelos de classificaÃ§Ã£o, especialmente quando se trabalha com um grande nÃºmero de preditores, pois busca identificar o subconjunto de variÃ¡veis mais relevante para o modelo e tambÃ©m para mitigar o problema de sobreajuste. A regularizaÃ§Ã£o, como a penalizaÃ§Ã£o L1 e L2, desempenha um papel fundamental nesse processo, controlando a complexidade do modelo e melhorando sua capacidade de generalizaÃ§Ã£o.

A regularizaÃ§Ã£o L1 (Lasso) adiciona uma penalidade ao valor absoluto dos coeficientes, favorecendo soluÃ§Ãµes esparsas, onde muitos coeficientes sÃ£o exatamente zero [^4.4.4]. Matematicamente, a funÃ§Ã£o custo a ser minimizada Ã©:

$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^{N}  [y_i \log(p(x_i)) + (1 - y_i) \log(1 - p(x_i))]  + \lambda \sum_{j=1}^{p} |\beta_j|
$$

onde $\lambda$ Ã© um parÃ¢metro de ajuste que controla a forÃ§a da penalizaÃ§Ã£o. A regularizaÃ§Ã£o L2 (Ridge) adiciona uma penalidade ao quadrado dos coeficientes, reduzindo a magnitude dos coeficientes sem necessariamente levÃ¡-los a zero [^4.5], [^4.5.1]. A funÃ§Ã£o custo, nesse caso, Ã©:

$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^{N}  [y_i \log(p(x_i)) + (1 - y_i) \log(1 - p(x_i))]  + \lambda \sum_{j=1}^{p} \beta_j^2
$$
> ðŸ’¡ **Exemplo NumÃ©rico:**
> Vamos considerar um cenÃ¡rio de regressÃ£o logÃ­stica com duas classes. Temos um conjunto de dados com duas features (X1 e X2) e uma variÃ¡vel de resposta binÃ¡ria (Y). Usaremos um pequeno conjunto de dados para demonstraÃ§Ã£o:
>
> ```python
> import numpy as np
> from sklearn.linear_model import LogisticRegression
> from sklearn.model_selection import train_test_split
> from sklearn.metrics import accuracy_score
>
> # Dados de exemplo
> X = np.array([[1, 1], [1, 2], [2, 1], [2, 3], [3, 2], [3, 3], [4, 1], [4, 2], [5, 1], [5,3]])
> y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])
>
> # Dividir os dados em treinamento e teste
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
>
> # Modelo de RegressÃ£o LogÃ­stica sem regularizaÃ§Ã£o
> model_no_reg = LogisticRegression(penalty=None)
> model_no_reg.fit(X_train, y_train)
> y_pred_no_reg = model_no_reg.predict(X_test)
> acc_no_reg = accuracy_score(y_test, y_pred_no_reg)
>
> # Modelo de RegressÃ£o LogÃ­stica com regularizaÃ§Ã£o L1 (Lasso)
> model_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=0.5)
> model_l1.fit(X_train, y_train)
> y_pred_l1 = model_l1.predict(X_test)
> acc_l1 = accuracy_score(y_test, y_pred_l1)
>
> # Modelo de RegressÃ£o LogÃ­stica com regularizaÃ§Ã£o L2 (Ridge)
> model_l2 = LogisticRegression(penalty='l2', C=0.5)
> model_l2.fit(X_train, y_train)
> y_pred_l2 = model_l2.predict(X_test)
> acc_l2 = accuracy_score(y_test, y_pred_l2)
>
> print(f"AcurÃ¡cia sem RegularizaÃ§Ã£o: {acc_no_reg:.3f}")
> print(f"AcurÃ¡cia com RegularizaÃ§Ã£o L1: {acc_l1:.3f}")
> print(f"AcurÃ¡cia com RegularizaÃ§Ã£o L2: {acc_l2:.3f}")
> print(f"Coeficientes sem regularizaÃ§Ã£o: {model_no_reg.coef_}")
> print(f"Coeficientes com regularizaÃ§Ã£o L1: {model_l1.coef_}")
> print(f"Coeficientes com regularizaÃ§Ã£o L2: {model_l2.coef_}")
> ```
>
> Resultados do exemplo:
>
> ```
> AcurÃ¡cia sem RegularizaÃ§Ã£o: 0.667
> AcurÃ¡cia com RegularizaÃ§Ã£o L1: 0.667
> AcurÃ¡cia com RegularizaÃ§Ã£o L2: 0.667
> Coeficientes sem regularizaÃ§Ã£o: [[-0.1667955  ,  0.24799327]]
> Coeficientes com regularizaÃ§Ã£o L1: [[0.  , 0.64240374]]
> Coeficientes com regularizaÃ§Ã£o L2: [[-0.03914371,  0.17511165]]
> ```
> Observamos que L1 leva um coeficiente a zero, enquanto o L2 reduz ambos os coeficientes. A acurÃ¡cia nos trÃªs modelos Ã© a mesma neste exemplo, mas em conjuntos de dados maiores e mais complexos a regularizaÃ§Ã£o pode levar a resultados significativamente diferentes.

**Lemma 3:** A penalizaÃ§Ã£o L1 em classificaÃ§Ã£o logÃ­stica promove coeficientes esparsos, ou seja, muitos coeficientes sÃ£o zero, levando a modelos mais simples e interpretÃ¡veis [^4.4.4].

**Prova do Lemma 3:** A penalizaÃ§Ã£o L1 adiciona um termo $\lambda \sum_{j=1}^{p} |\beta_j|$ Ã  funÃ§Ã£o de custo.  Quando se minimiza essa funÃ§Ã£o, os coeficientes $\beta_j$ tendem a ser levados a zero para minimizar a penalidade, especialmente quando $\lambda$ Ã© grande. A sub-diferenciabilidade da norma L1 na origem $\beta=0$ forÃ§a que alguns coeficientes se tornem exatamente zero, o que nÃ£o ocorre com a norma L2 [^4.4.3]. $\blacksquare$

**CorolÃ¡rio 3:** A esparsidade obtida com a penalizaÃ§Ã£o L1 simplifica o modelo e facilita a identificaÃ§Ã£o dos preditores mais relevantes para a classificaÃ§Ã£o [^4.4.5]. Modelos com muitos coeficientes nÃ£o-nulos podem ser mais difÃ­ceis de interpretar.

> âš ï¸ **Ponto Crucial**:  As penalidades L1 e L2 podem ser combinadas em um Ãºnico termo de regularizaÃ§Ã£o, conhecido como Elastic Net. A penalidade Elastic Net Ã© definida como:

$$
\lambda_1 \sum_{j=1}^{p} |\beta_j| + \lambda_2 \sum_{j=1}^{p} \beta_j^2
$$

Essa combinaÃ§Ã£o busca aproveitar os benefÃ­cios de ambas as tÃ©cnicas [^4.5].

### Separating Hyperplanes e Perceptrons
```mermaid
graph TB
    subgraph "Perceptron Algorithm"
        direction TB
        A["Initialize Weights: w, b"]
        B["For Each Sample x_i:"]
        C["Calculate Discriminant Function: f(x_i) = wáµ€x_i + b"]
        D["Predict Class: yÌ‚_i = step(f(x_i))"]
        E["Update Weights: w = w + Î·(y_i - yÌ‚_i)x_i"]
        F["Update Bias: b = b + Î·(y_i - yÌ‚_i)"]
        G["Check Convergence: All samples classified correctly?"]
        H["If Not Converged: Repeat from B"]
        I["Final Hyperplane: Converged"]
        A --> B
        B --> C
        C --> D
        D --> E
        E --> F
        F --> G
        G -- "No" --> H
        G -- "Yes" --> I
        H --> B
        style G fill:#ccf,stroke:#333,stroke-width:2px
        linkStyle 0,1,2,3,4,5,6,7 stroke:#333,stroke-width:2px;
    end
```

A ideia de maximizar a margem de separaÃ§Ã£o em problemas de classificaÃ§Ã£o Ã© central para entender a construÃ§Ã£o de hiperplanos separadores Ã³timos [^4.5.2]. Dado um conjunto de dados linearmente separÃ¡vel, o objetivo Ã© encontrar o hiperplano que maximize a distÃ¢ncia entre as classes. Esse hiperplano Ã© definido como:
$$
w^T x + b = 0
$$
onde $w$ Ã© o vetor normal ao hiperplano, e $b$ Ã© o termo de *bias*.

O problema de otimizaÃ§Ã£o para encontrar o hiperplano de margem mÃ¡xima envolve maximizar a margem (distÃ¢ncia entre o hiperplano e as instÃ¢ncias mais prÃ³ximas) sob a restriÃ§Ã£o de que todas as instÃ¢ncias sejam classificadas corretamente [^4.5.2]. Formalmente, pode ser definido como:

$$
\text{maximizar}_w \frac{2}{\|w\|}
$$
sujeito a $y_i (w^T x_i + b) \geq 1$, onde $y_i$ sÃ£o os rÃ³tulos das classes. Este problema pode ser reformulado usando o dual de Wolfe e resolvido usando programaÃ§Ã£o quadrÃ¡tica [^4.5.2]. Os pontos que estÃ£o na margem de decisÃ£o sÃ£o conhecidos como pontos de suporte e o hiperplano Ã© definido como uma combinaÃ§Ã£o linear desses pontos.

O Perceptron de Rosenblatt Ã© um algoritmo de aprendizagem que busca encontrar um hiperplano separador atravÃ©s de um processo iterativo [^4.5.1]. O Perceptron atualiza seus pesos $w$ a cada iteraÃ§Ã£o, levando em consideraÃ§Ã£o as instÃ¢ncias classificadas incorretamente [^4.5.1]. A atualizaÃ§Ã£o dos pesos Ã© feita conforme a regra:

$$
w = w + \eta (y_i - \hat{y_i})x_i
$$

onde $\eta$ Ã© a taxa de aprendizagem, $y_i$ Ã© o rÃ³tulo verdadeiro, e $\hat{y_i}$ Ã© o rÃ³tulo predito. Se os dados sÃ£o linearmente separÃ¡veis, o Perceptron garante convergir para um hiperplano separador.

> ðŸ’¡ **Exemplo NumÃ©rico:** Vamos demonstrar o funcionamento do Perceptron com um exemplo simples. Inicializamos os pesos com $w=[0.1, 0.1]$ e o bias $b=0.1$ e $\eta=0.1$. Temos um conjunto de dados com 4 pontos: Classe 1: $x_1 = [1, 2]$, $y_1 = 1$,  $x_2 = [2, 1]$, $y_2 = 1$. Classe 2: $x_3 = [3, 3]$, $y_3 = 0$, $x_4 = [4, 2]$, $y_4 = 0$.

> **IteraÃ§Ã£o 1:**
>
> *   **Ponto** $x_1 = [1, 2]$:  $\hat{y_1} = \text{step}(w^T x_1 + b) = \text{step}(0.1*1 + 0.1*2 + 0.1) = \text{step}(0.4) = 1$. PrediÃ§Ã£o correta.
> *   **Ponto** $x_2 = [2, 1]$: $\hat{y_2} = \text{step}(w^T x_2 + b) = \text{step}(0.1*2 + 0.1*1 + 0.1) = \text{step}(0.4) = 1$. PrediÃ§Ã£o correta.
> *   **Ponto** $x_3 = [3, 3]$: $\hat{y_3} = \text{step}(w^T x_3 + b) = \text{step}(0.1*3 + 0.1*3 + 0.1) = \text{step}(0.7) = 1$. PrediÃ§Ã£o incorreta.
>
>