## Caso Univariado Sem Intercepto: Y = XŒ≤ + Œµ em Regress√£o Linear

```mermaid
flowchart LR
    A[Vari√°vel Preditiva X] --> B(Modelo Linear: Y = XŒ≤ + Œµ)
    B --> C[Vari√°vel Resposta Y]
    C --> D[Erro Œµ]
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#ccf,stroke:#333,stroke-width:2px
    style C fill:#f9f,stroke:#333,stroke-width:2px
    style D fill:#aaf,stroke:#333,stroke-width:2px
```

### Introdu√ß√£o

Em modelos de regress√£o linear, a inclus√£o do *intercepto* permite que a reta de regress√£o tenha uma ordenada na origem diferente de zero. No entanto, em alguns casos, pode ser apropriado utilizar um modelo de regress√£o linear sem *intercepto*. O modelo univariado de regress√£o sem intercepto √© expresso pela f√≥rmula **Y = XŒ≤ + Œµ**, onde a vari√°vel resposta $Y$ √© modelada como um produto da vari√°vel preditora $X$ por um par√¢metro $\beta$ mais um erro aleat√≥rio $\epsilon$. Este cap√≠tulo explorar√° a formula√ß√£o matem√°tica do modelo, sua interpreta√ß√£o geom√©trica, os m√©todos para a sua resolu√ß√£o por m√≠nimos quadrados, e as implica√ß√µes pr√°ticas dessa simplifica√ß√£o.

### Formula√ß√£o Matem√°tica do Modelo Univariado sem Intercepto
Um modelo de regress√£o linear univariado sem *intercepto* assume que a vari√°vel dependente $Y$ √© uma fun√ß√£o linear de uma √∫nica vari√°vel preditora $X$,  e que essa rela√ß√£o passa pela origem, com o termo constante (o *intercepto*) sendo igual a zero. Este modelo √© definido por:

$$
Y = X \beta + \epsilon
$$

onde:

-   $Y \in \mathbb{R}^{N}$ √© o vetor de respostas, contendo os valores observados da vari√°vel dependente para cada observa√ß√£o.
-   $X \in \mathbb{R}^{N}$ √© o vetor de preditores, com um √∫nico preditor para cada observa√ß√£o.
-  $\beta$ √© o par√¢metro (coeficiente) do modelo a ser estimado.
- $\epsilon \in \mathbb{R}^N$ √© o vetor de erros aleat√≥rios, que representam a diferen√ßa entre os valores observados e os valores preditos pelo modelo.

O modelo n√£o tem intercepto, e, portanto, a reta de regress√£o passa pela origem. Este tipo de modelo pode ser √∫til em situa√ß√µes onde √© razo√°vel supor que, quando o preditor for igual a zero, a vari√°vel resposta tamb√©m seja igual a zero, como por exemplo, na modelagem da resposta de um sistema a um est√≠mulo, ou na modelagem da rela√ß√£o entre duas medidas que tenham uma origem em comum.

> üí° **Exemplo Num√©rico:**
> Imagine que estamos modelando a rela√ß√£o entre a quantidade de fertilizante utilizada ($X$) e o crescimento de uma planta ($Y$). Em teoria, se n√£o usarmos fertilizante, n√£o haver√° crescimento adicional. Portanto, um modelo sem intercepto pode ser apropriado. Suponha que temos os seguintes dados:
>
> | Observa√ß√£o | Fertilizante ($x_i$) | Crescimento ($y_i$) |
> |------------|-----------------------|--------------------|
> | 1          | 1                    | 2.1                |
> | 2          | 2                    | 3.9                |
> | 3          | 3                    | 6.1                |
> | 4          | 4                    | 7.8                |
> | 5          | 5                    | 10.2               |
>
> Aqui, $X = [1, 2, 3, 4, 5]$ e $Y = [2.1, 3.9, 6.1, 7.8, 10.2]$.
> O modelo √© $Y = X\beta + \epsilon$.

###  Interpreta√ß√£o Geom√©trica do Modelo Univariado sem Intercepto

A interpreta√ß√£o geom√©trica do modelo de regress√£o linear univariado sem intercepto √© mais simples que o caso geral, onde um intercepto √© inclu√≠do.

1.  **Espa√ßo dos Dados:** Tanto o vetor de respostas $y$ como o vetor de preditores $x$ residem no espa√ßo dos dados, $\mathbb{R}^N$, onde cada componente corresponde a uma observa√ß√£o.
2.  **Reta de Regress√£o:** O modelo linear, que relaciona $y$ e $x$, √© uma reta que passa pela origem.
3.  **Proje√ß√£o Ortogonal:** O objetivo da regress√£o √© encontrar o valor de $\beta$ tal que a proje√ß√£o ortogonal do vetor resposta $y$ sobre o subespa√ßo gerado pelo preditor $x$ seja o mais pr√≥xima poss√≠vel de y. Este subespa√ßo √© uma linha que passa pela origem.
4.  **Res√≠duos:** O vetor de res√≠duos $r=y-x\beta$ representa a diferen√ßa entre o valor observado e o valor predito para cada observa√ß√£o, e √© perpendicular √† linha de regress√£o.

Neste modelo, a aus√™ncia do *intercepto* implica que o espa√ßo gerado pelo preditor $x$ seja uma linha que passa pela origem.

> üí° **Exemplo Num√©rico (Continua√ß√£o):**
> Geometricamente, estamos procurando a reta que passa pela origem que melhor se ajusta aos pontos $(x_i, y_i)$. Os res√≠duos s√£o as dist√¢ncias verticais entre os pontos e a reta.
>
> ```mermaid
>  graph LR
>      A(0,0) -- Reta de Regress√£o --> B(5,10)
>      C(1,2.1) -- Res√≠duo 1 --> D
>      E(2,3.9) -- Res√≠duo 2 --> F
>      G(3,6.1) -- Res√≠duo 3 --> H
>      I(4,7.8) -- Res√≠duo 4 --> J
>      K(5,10.2) -- Res√≠duo 5 --> L
>      style A fill:#f9f,stroke:#333,stroke-width:2px
>      style B fill:#f9f,stroke:#333,stroke-width:2px
> ```
> Os pontos C, E, G, I e K representam os dados observados, e a reta A-B representa a reta de regress√£o que minimiza a soma dos quadrados dos res√≠duos (Res√≠duo 1, Res√≠duo 2, etc.).

### Estima√ß√£o de M√≠nimos Quadrados no Modelo Sem Intercepto

O m√©todo de m√≠nimos quadrados busca encontrar o valor de $\beta$ que minimize a soma dos quadrados dos res√≠duos (RSS):

$$
RSS(\beta) = ||y - x\beta||^2 = \sum_{i=1}^N (y_i - x_i\beta)^2
$$
onde:
    -   $y_i$ √© o valor observado da resposta na i-√©sima observa√ß√£o, e $x_i$ √© o valor do preditor na i-√©sima observa√ß√£o.

Para encontrar o valor de $\beta$ que minimiza o RSS, derivamos a fun√ß√£o RSS com rela√ß√£o a $\beta$ e igualamos a zero:

$$
\frac{\partial RSS}{\partial \beta} = -2 \sum_{i=1}^N x_i (y_i - x_i\beta) = 0
$$
Resolvendo para $\beta$:

$$
\sum_{i=1}^N x_i y_i - \sum_{i=1}^N x_i^2\beta = 0
$$
$$
\beta \sum_{i=1}^N x_i^2 =  \sum_{i=1}^N x_i y_i
$$
$$
\hat{\beta} = \frac{\sum_{i=1}^N x_i y_i}{\sum_{i=1}^N x_i^2} = \frac{x^Ty}{x^Tx}
$$

Em nota√ß√£o matricial, a solu√ß√£o por m√≠nimos quadrados para o modelo linear sem intercepto √© dada por:

$$
\hat{\beta} = (x^T x)^{-1} x^T y = \frac{x^T y}{x^T x}
$$

Esta f√≥rmula expressa a estimativa do par√¢metro $\beta$ em fun√ß√£o do produto interno dos vetores $x$ e $y$, normalizado pelo produto interno do vetor $x$ com si mesmo.

> üí° **Exemplo Num√©rico (Continua√ß√£o):**
> Vamos calcular $\hat{\beta}$ usando os dados do exemplo anterior:
>
> $x = [1, 2, 3, 4, 5]$
> $y = [2.1, 3.9, 6.1, 7.8, 10.2]$
>
> **Step 1:** Calcular $x^Ty = \sum_{i=1}^N x_i y_i$
>
> $x^Ty = (1*2.1) + (2*3.9) + (3*6.1) + (4*7.8) + (5*10.2) = 2.1 + 7.8 + 18.3 + 31.2 + 51 = 110.4$
>
> **Step 2:** Calcular $x^Tx = \sum_{i=1}^N x_i^2$
>
> $x^Tx = (1^2) + (2^2) + (3^2) + (4^2) + (5^2) = 1 + 4 + 9 + 16 + 25 = 55$
>
> **Step 3:** Calcular $\hat{\beta}$
>
> $\hat{\beta} = \frac{x^Ty}{x^Tx} = \frac{110.4}{55} = 2.00727$
>
> Portanto, o modelo estimado √© $Y = 2.00727X$. Isso significa que, para cada unidade de fertilizante adicional, esperamos um aumento de aproximadamente 2.007 unidades no crescimento da planta.

**Lemma 20:**  Unicidade da Solu√ß√£o do Modelo Sem Intercepto
A solu√ß√£o de m√≠nimos quadrados para o modelo univariado sem intercepto √© √∫nica, desde que o vetor de preditores $x$ n√£o seja o vetor zero.

**Prova do Lemma 20:**

O denominador da solu√ß√£o,  $\frac{x^T y}{x^T x}$, √© uma soma de quadrados, e portanto √© zero somente quando todos os seus componentes s√£o zero, o que implica que o vetor $x$ √© zero. Se o vetor $x$ for zero, o modelo n√£o tem um preditor, e o problema de regress√£o linear n√£o tem sentido. Se o vetor $x$ √© diferente de zero, o denominador √© diferente de zero, e a solu√ß√£o $\hat{\beta}$ √© √∫nica. $\blacksquare$

**Corol√°rio 20:**  Interpreta√ß√£o do Coeficiente

O coeficiente estimado $\hat{\beta}$ representa a inclina√ß√£o da reta que passa pela origem. √â importante notar que, nesse caso, n√£o existe um *intercept* e a reta de regress√£o √© for√ßada a passar pela origem.

> üí° **Exemplo Num√©rico (Continua√ß√£o):**
> O coeficiente $\hat{\beta} = 2.00727$  indica que, para cada unidade de aumento no fertilizante, o crescimento da planta aumenta em aproximadamente 2.007 unidades, assumindo que a rela√ß√£o √© linear e passa pela origem.

### Implica√ß√µes da Aus√™ncia do Intercepto

A aus√™ncia do *intercept* no modelo linear implica em:
1. **Reta de Regress√£o:** A reta de regress√£o passa pela origem, ou seja, a predi√ß√£o do modelo √© zero quando o preditor √© igual a zero, o que pode ser apropriado em alguns casos.
2. **Interpreta√ß√£o do Par√¢metro:** O par√¢metro $\beta$ quantifica a rela√ß√£o linear entre o preditor e a resposta, dado que a reta de regress√£o passa pela origem, e portanto o par√¢metro $\beta$ representa a taxa de varia√ß√£o da resposta a um aumento unit√°rio do preditor.
3. **Interpreta√ß√£o dos Res√≠duos:** Os res√≠duos s√£o a dist√¢ncia do ponto em rela√ß√£o a reta de regress√£o. Em modelos sem intercepto, os res√≠duos s√£o ortogonais ao preditor.
4. **Perda de Flexibilidade:** Ao remover o *intercepto*, o modelo se torna menos flex√≠vel, e pode apresentar maior vi√©s se a verdadeira rela√ß√£o n√£o passa pela origem.
5. **Restri√ß√µes do Modelo:** O modelo de regress√£o sem intercepto √© uma boa escolha quando h√° raz√µes te√≥ricas para crer que a resposta √© zero quando o preditor √© zero, ou tamb√©m quando desejamos um modelo com menos par√¢metros e menos complexo.

> üí° **Exemplo Num√©rico (Continua√ß√£o):**
> Vamos calcular os res√≠duos para o nosso exemplo:
>
> | Observa√ß√£o | Fertilizante ($x_i$) | Crescimento ($y_i$) | Predito ($\hat{y_i} = \hat{\beta}x_i$) | Res√≠duo ($r_i = y_i - \hat{y_i}$) |
> |------------|-----------------------|--------------------|-------------------------------------|-----------------------------------|
> | 1          | 1                    | 2.1                | 2.00727                              | 0.09273                            |
> | 2          | 2                    | 3.9                | 4.01454                              | -0.11454                           |
> | 3          | 3                    | 6.1                | 6.02181                              | 0.07819                            |
> | 4          | 4                    | 7.8                | 8.02908                              | -0.22908                           |
> | 5          | 5                    | 10.2               | 10.03635                             | 0.16365                            |
>
> A soma dos quadrados dos res√≠duos (RSS) √©:
>
> $RSS = (0.09273^2) + (-0.11454^2) + (0.07819^2) + (-0.22908^2) + (0.16365^2) = 0.0992$
>
> Os res√≠duos s√£o as diferen√ßas entre os valores observados e os valores preditos pelo modelo, e o RSS √© a medida da qualidade do ajuste do modelo.

### Regulariza√ß√£o e a Aus√™ncia do Intercepto
√â importante notar que em modelos regulares, a penaliza√ß√£o √© aplicada aos coeficientes dos preditores, e o *intercept* n√£o √© penalizado, e portanto o *intercept* pode ser entendido como um par√¢metro que n√£o deve ter a sua estimativa reduzida a zero.
Em modelos sem intercepto, o par√¢metro $\beta$ √© penalizado como qualquer outro, e portanto pode ser levado a zero por penaliza√ß√µes como a L1, o que leva a um modelo onde o preditor √© completamente ignorado.

> üí° **Exemplo Num√©rico (Regulariza√ß√£o):**
> Se aplicarmos uma regulariza√ß√£o L1 (Lasso) a este modelo, a estimativa de $\beta$ ser√° afetada pela penalidade.  Se a penalidade for suficientemente alta, o valor de $\beta$ pode ser reduzido a zero, efetivamente eliminando o preditor do modelo.  
>
> Por exemplo, se a fun√ß√£o de custo for $RSS(\beta) + \lambda |\beta|$, um valor grande de $\lambda$ levar√° a um $\hat{\beta}$ menor. No caso extremo, se $\lambda$ for grande o suficiente, $\hat{\beta}$ ir√° a zero.
```mermaid
sequenceDiagram
    participant Dados
    participant Modelo
    participant Regulariza√ß√£o
    Dados ->> Modelo: Ajustar Modelo Y=XŒ≤
    Modelo ->> Regulariza√ß√£o: Aplicar Penalidade L1
    Regulariza√ß√£o -->> Modelo: Atualizar Œ≤
    Modelo ->> Dados: Avaliar Res√≠duos
```

> ‚ö†Ô∏è **Nota Importante**: O modelo de regress√£o linear univariado sem intercepto √© expresso por Y = XŒ≤ + Œµ, onde a reta de regress√£o √© for√ßada a passar pela origem.

> ‚ùó **Ponto de Aten√ß√£o**: A estimativa do par√¢metro Œ≤ √© dada por $\hat{\beta} = \frac{\sum_{i=1}^N x_i y_i}{\sum_{i=1}^N x_i^2} = \frac{x^T y}{x^T x}$, que corresponde ao m√≠nimo da soma do quadrado dos res√≠duos.
 
> ‚úîÔ∏è **Destaque**: Em modelos sem intercepto, o par√¢metro $\beta$ quantifica a rela√ß√£o linear entre o preditor e a resposta, dado que a reta de regress√£o passa pela origem.

### Conclus√£o

O modelo de regress√£o linear univariado sem intercepto, definido por $Y = X\beta + \epsilon$, representa uma simplifica√ß√£o do modelo geral, onde a reta de regress√£o passa obrigatoriamente pela origem. Este modelo √© √∫til em cen√°rios onde o conhecimento pr√©vio ou caracter√≠sticas dos dados justificam sua utiliza√ß√£o. A sua interpreta√ß√£o geom√©trica, bem como o seu m√©todo de resolu√ß√£o, fornecem uma vis√£o clara da estima√ß√£o do par√¢metro $\beta$ atrav√©s do m√©todo dos m√≠nimos quadrados.

### Refer√™ncias
[^11]: "The linear model either assumes that the regression function E(Y|X) is linear, or that the linear model is a reasonable approximation." *(Trecho de Linear Methods for Regression)*
[^10]: "The most popular estimation method is least squares, in which we pick the coefficients Œ≤ = (Œ≤0, Œ≤1, ..., Œ≤p)T to minimize the residual sum of squares" *(Trecho de Linear Methods for Regression)*
