## T√≠tulo: Modelos Aditivos, √Årvores e M√©todos Relacionados: Utiliza√ß√£o do Erro de Classifica√ß√£o no Poda por Complexidade de Custo

```mermaid
flowchart TB
    subgraph "Cost-Complexity Pruning"
        A["Initial Complex Tree"] --> B{"Cost-Complexity Pruning Process"}
        B --> C["Simplified Tree"]
        C --> D["Evaluation on Validation Set"]
        D --> E{"Optimal Tree"}
        E --> F["Final Model"]
    end
```

### Introdu√ß√£o

Este cap√≠tulo explora a t√©cnica de poda por complexidade de custo (cost-complexity pruning), com foco em como o erro de classifica√ß√£o √© utilizado para guiar o processo de poda em √°rvores de decis√£o, e como esta estrat√©gia busca um bom balanceamento entre o ajuste aos dados de treino e a capacidade de generaliza√ß√£o [^9.1]. A poda por complexidade de custo √© uma abordagem para simplificar as √°rvores de decis√£o, reduzindo o *overfitting* e melhorando a sua capacidade de generaliza√ß√£o. O cap√≠tulo detalha como o erro de classifica√ß√£o √© utilizado para avaliar a qualidade da poda, como o par√¢metro de complexidade controla o tamanho da √°rvore e como a poda por complexidade de custo √© utilizada na constru√ß√£o de modelos mais robustos e interpret√°veis. O objetivo principal √© apresentar uma vis√£o aprofundada da aplica√ß√£o do erro de classifica√ß√£o para guiar a poda de √°rvores de decis√£o e suas implica√ß√µes no desempenho final do modelo.

### Conceitos Fundamentais

**Conceito 1: O Erro de Classifica√ß√£o em √Årvores de Decis√£o**

O erro de classifica√ß√£o em √°rvores de decis√£o √© uma m√©trica que mede a propor√ß√£o de observa√ß√µes que s√£o classificadas incorretamente pelo modelo, e pode ser utilizado para avaliar a qualidade de um n√≥ ou de toda a √°rvore. O erro de classifica√ß√£o para um n√≥ $m$ √© dado por:

$$
\text{Erro de Classifica√ß√£o}_m = 1 - \hat{p}_{mk(m)}
$$

onde $\hat{p}_{mk(m)}$ √© a propor√ß√£o da classe majorit√°ria $k(m)$ no n√≥ $m$. O erro de classifica√ß√£o mede a propor√ß√£o de observa√ß√µes que n√£o pertencem √† classe majorit√°ria, e o erro de classifica√ß√£o da √°rvore √© a soma ponderada do erro de classifica√ß√£o de cada n√≥ folha. Embora o erro de classifica√ß√£o seja uma m√©trica simples e intuitiva, ele n√£o √© t√£o sens√≠vel a mudan√ßas nos n√≥s como a entropia ou o √≠ndice de Gini, e o uso de outras m√©tricas √© mais comum durante o processo de constru√ß√£o da √°rvore, mas o erro de classifica√ß√£o √© importante no processo de poda, pois ele representa diretamente a taxa de classifica√ß√£o errada do modelo.

> üí° **Exemplo Num√©rico:**
> Considere um n√≥ $m$ em uma √°rvore de decis√£o onde temos 100 observa√ß√µes. Dessas, 60 pertencem √† classe A (a classe majorit√°ria) e 40 pertencem √† classe B. A propor√ß√£o da classe majorit√°ria $\hat{p}_{mA}$ √© 60/100 = 0.6. Portanto, o erro de classifica√ß√£o para este n√≥ √©:
> $$
> \text{Erro de Classifica√ß√£o}_m = 1 - 0.6 = 0.4
> $$
> Isso significa que 40% das observa√ß√µes neste n√≥ s√£o classificadas incorretamente se usarmos a classe majorit√°ria como previs√£o para todas as observa√ß√µes nesse n√≥.

**Lemma 1:** *O erro de classifica√ß√£o quantifica a propor√ß√£o de observa√ß√µes classificadas incorretamente por um modelo de classifica√ß√£o. O erro de classifica√ß√£o √© uma m√©trica intuitiva e f√°cil de interpretar, e √© utilizado para avaliar o desempenho da classifica√ß√£o do modelo.* O erro de classifica√ß√£o √© uma m√©trica essencial na avalia√ß√£o de modelos de classifica√ß√£o [^4.5].

**Conceito 2: Poda por Complexidade de Custo (Cost-Complexity Pruning)**

A poda por complexidade de custo (cost-complexity pruning) √© um m√©todo utilizado para simplificar as √°rvores de decis√£o e evitar o *overfitting*. O m√©todo envolve a poda de n√≥s da √°rvore que n√£o contribuem significativamente para a redu√ß√£o do erro de classifica√ß√£o, utilizando um par√¢metro de complexidade que controla o *trade-off* entre o tamanho da √°rvore e o ajuste aos dados. O processo de poda come√ßa com a √°rvore completa, e utiliza um crit√©rio de custo para definir qual n√≥ deve ser removido.  Em cada passo da poda, a √°rvore com menor custo √© escolhida. O custo de cada sub√°rvore $T$ √© dado por:
```mermaid
graph TB
    subgraph "Cost Function Decomposition"
      direction TB
      A["Cost Function: C<sub>Œ±</sub>(T)"]
      B["Impurity Term: ‚àë<sub>m=1</sub><sup>|T|</sup> N<sub>m</sub> Q<sub>m</sub>(T)"]
      C["Complexity Term: Œ±|T|"]
      A --> B
      A --> C
    end
```
$$
C_\alpha(T) = \sum_{m=1}^{|T|} N_m Q_m(T) + \alpha |T|
$$
onde $N_m$ √© o n√∫mero de observa√ß√µes no n√≥ $m$, $Q_m(T)$ √© a impureza do n√≥, $|T|$ √© o n√∫mero de n√≥s terminais, e $\alpha$ √© o par√¢metro de complexidade, onde, quanto maior, maior ser√° o custo por n√≥. O objetivo do m√©todo √© escolher o valor de $\alpha$ que minimize o custo do modelo.

> üí° **Exemplo Num√©rico:**
> Considere uma sub√°rvore $T$ com tr√™s n√≥s terminais.
> - N√≥ 1: $N_1 = 50$, $Q_1(T) = 0.2$
> - N√≥ 2: $N_2 = 30$, $Q_2(T) = 0.3$
> - N√≥ 3: $N_3 = 20$, $Q_3(T) = 0.1$
>
> O n√∫mero de n√≥s terminais √© $|T| = 3$. Se o par√¢metro de complexidade $\alpha = 0.05$, o custo da sub√°rvore $T$ √©:
>
> $$
> C_{0.05}(T) = (50 \times 0.2) + (30 \times 0.3) + (20 \times 0.1) + 0.05 \times 3
> $$
> $$
> C_{0.05}(T) = 10 + 9 + 2 + 0.15 = 21.15
> $$
> Se o $\alpha$ fosse 0.1, o custo seria:
> $$
> C_{0.1}(T) = 10 + 9 + 2 + 0.1 \times 3 = 21.3
> $$
> Este exemplo demonstra como o par√¢metro $\alpha$ afeta o custo da √°rvore. Um $\alpha$ maior aumenta o custo, incentivando a poda de n√≥s, enquanto um $\alpha$ menor permite √°rvores mais complexas.

**Corol√°rio 1:** *A poda por complexidade de custo busca simplificar a √°rvore de decis√£o, e o par√¢metro de complexidade controla o balan√ßo entre o ajuste e a complexidade da √°rvore*. O par√¢metro de complexidade √© crucial para controlar a capacidade de generaliza√ß√£o da √°rvore de decis√£o [^4.5.2].

**Conceito 3: Utiliza√ß√£o do Erro de Classifica√ß√£o na Poda por Complexidade de Custo**

O erro de classifica√ß√£o √© utilizado como crit√©rio para escolher qual n√≥ deve ser removido na poda por complexidade de custo. Em cada passo, o algoritmo de poda avalia o aumento do erro de classifica√ß√£o causado pela remo√ß√£o de um determinado n√≥, e o n√≥ que causa o menor aumento no erro de classifica√ß√£o, juntamente com o termo de penaliza√ß√£o, √© removido. O par√¢metro de complexidade $\alpha$ controla o *trade-off* entre a diminui√ß√£o do erro de classifica√ß√£o e a complexidade da √°rvore. A escolha adequada do par√¢metro de complexidade, que pode ser feita utilizando valida√ß√£o cruzada, resulta em um modelo com boa capacidade de generaliza√ß√£o. A valida√ß√£o cruzada √© utilizada para avaliar o desempenho da √°rvore podada e o n√≠vel de complexidade, que √© utilizado para escolher a melhor √°rvore final.

> ‚ö†Ô∏è **Nota Importante:** O erro de classifica√ß√£o √© utilizado para guiar o processo de poda por complexidade de custo, e a avalia√ß√£o do impacto de cada poda no erro de classifica√ß√£o √© essencial para evitar o overfitting do modelo e melhorar a sua capacidade de generaliza√ß√£o [^4.5].

> ‚ùó **Ponto de Aten√ß√£o:** O par√¢metro de complexidade $\alpha$ controla o *trade-off* entre o tamanho da √°rvore e o erro de classifica√ß√£o, e a sua escolha deve ser feita utilizando valida√ß√£o cruzada ou m√©todos similares. Valores pequenos do par√¢metro de complexidade levam a √°rvores muito complexas com risco de overfitting e valores muito altos do par√¢metro de complexidade levam a modelos muito simples e com pouco ajuste aos dados [^4.5.1].

> ‚úîÔ∏è **Destaque:** A poda por complexidade de custo utiliza o erro de classifica√ß√£o, juntamente com o par√¢metro de complexidade, para balancear o ajuste e a complexidade da √°rvore de decis√£o, o que resulta em modelos mais robustos e com melhor capacidade preditiva [^4.5.2].

### Processo de Poda por Complexidade de Custo: Utiliza√ß√£o do Erro de Classifica√ß√£o e do Par√¢metro de Complexidade

```mermaid
flowchart TD
    subgraph "Pruning Process"
      direction TB
      A["Initial Tree: T_0"]
      B["Calculate Cost: C<sub>Œ±</sub>(T) for Subtrees"]
      C["Identify Node to Prune"]
      D["Prune Node: Create T_i"]
      E{"Is Tree Reduced to Root?"}
      F["Select Best Subtree"]
      A --> B
      B --> C
      C --> D
      D --> E
      E -- "No" --> B
      E -- "Yes" --> F
    end
```

**Explica√ß√£o:** Este diagrama ilustra o processo de poda por complexidade de custo, mostrando como o erro de classifica√ß√£o e o par√¢metro de complexidade s√£o utilizados para simplificar a √°rvore de decis√£o. O processo iterativo busca o melhor *trade-off* entre ajuste aos dados e complexidade do modelo [^4.5.2].

O algoritmo de poda por complexidade de custo come√ßa com a √°rvore completa $T_0$ (a √°rvore que se ajusta perfeitamente aos dados de treino).  Em seguida, o algoritmo itera sobre as sub-√°rvores, removendo um n√≥ a cada passo, de acordo com o seguinte procedimento:

1.  **C√°lculo do Custo:** Para cada n√≥ interno da √°rvore, calcula o custo de remover o n√≥. O custo √© dado pela soma ponderada do erro de classifica√ß√£o nos n√≥s terminais da sub√°rvore $T$ e o termo de penaliza√ß√£o com o par√¢metro de complexidade $\alpha$:
   $$
C_\alpha(T) = \sum_{m=1}^{|T|} N_m Q_m(T) + \alpha |T|
$$
     onde $N_m$ √© o n√∫mero de observa√ß√µes no n√≥ $m$, $Q_m(T)$ √© uma medida de impureza do n√≥ (como o erro de classifica√ß√£o), e $|T|$ √© o n√∫mero de n√≥s terminais da sub√°rvore $T$.
2.  **Remo√ß√£o do N√≥:** O n√≥ interno que resulta na menor mudan√ßa no custo √© removido da √°rvore, gerando uma nova √°rvore podada $T_i$. A escolha do n√≥ a ser removido √© baseada no valor do par√¢metro de complexidade, onde, um valor maior de $\alpha$ leva a √°rvores menores.
3.  **Itera√ß√£o:** O processo de c√°lculo do custo e remo√ß√£o de n√≥s √© repetido at√© que a √°rvore se reduza a um √∫nico n√≥. Em cada passo, a √°rvore com menor custo √© escolhida.

A avalia√ß√£o do desempenho de cada √°rvore podada √© feita atrav√©s da valida√ß√£o cruzada, onde o erro de classifica√ß√£o √© utilizado como crit√©rio de escolha. A sequ√™ncia de √°rvores obtidas no processo de poda representa um conjunto de modelos de diferentes complexidades.

> üí° **Exemplo Num√©rico:**
> Suponha que temos uma √°rvore com um n√≥ interno que, quando removido, resulta em duas sub√°rvores.
> - Sub√°rvore 1: $|T_1| = 3$,  $\sum_{m=1}^{3} N_m Q_m(T_1) = 15$
> - Sub√°rvore 2: $|T_2| = 2$, $\sum_{m=1}^{2} N_m Q_m(T_2) = 10$
>
> Se removermos o n√≥ interno, obtemos uma nova √°rvore com $|T'| = 5$ e um custo total de impureza de $15+10=25$.
>
> Se $\alpha = 1$, o custo da √°rvore original √© $C_\alpha(T_1 \cup T_2) = 15 + 10 + 1 * 5 = 30$.
>
> Se n√£o removermos, o custo da √°rvore anterior (com o n√≥ interno) √© $C_\alpha(T) = \sum_{m=1}^{|T|} N_m Q_m(T) + \alpha |T|$. Suponha que $\sum_{m=1}^{|T|} N_m Q_m(T) = 20$ e $|T| = 4$, ent√£o $C_\alpha(T) = 20+1*4 = 24$.
>
> Portanto, se $\alpha = 1$, √© mais vantajoso manter o n√≥ interno (custo 24) do que remov√™-lo (custo 30).
>
> Se $\alpha = 5$, o custo da √°rvore sem remover o n√≥ interno seria $C_\alpha(T) = 20 + 5*4 = 40$. O custo da √°rvore com o n√≥ removido seria $C_\alpha(T_1 \cup T_2) = 15 + 10 + 5 * 5 = 50$. Portanto, √© mais vantajoso n√£o remover o n√≥ interno.
>
> Se aumentarmos $\alpha$ para 10, o custo da √°rvore sem remover o n√≥ interno seria $C_\alpha(T) = 20 + 10 * 4 = 60$. O custo da √°rvore com o n√≥ removido seria $C_\alpha(T_1 \cup T_2) = 15 + 10 + 10 * 5 = 75$. √â mais vantajoso manter o n√≥ interno.
>
> O ponto crucial √© que a remo√ß√£o do n√≥ interno, s√≥ ser√° vantajosa se o custo da √°rvore com o n√≥ interno for maior do que o custo da √°rvore sem o n√≥ interno.
>
> Este exemplo mostra como o par√¢metro $\alpha$ influencia a decis√£o de remover ou n√£o um n√≥ interno durante a poda.

**Lemma 3:** *O algoritmo de poda por complexidade de custo busca um balanceamento entre ajuste aos dados e complexidade da √°rvore, e a escolha do par√¢metro de complexidade √© fundamental para obter um modelo com boa capacidade de generaliza√ß√£o. O erro de classifica√ß√£o √© utilizado como crit√©rio para guiar a poda e a avalia√ß√£o do desempenho da √°rvore podada.*  O uso do par√¢metro de complexidade e do erro de classifica√ß√£o √© fundamental para evitar o overfitting e obter uma boa capacidade de generaliza√ß√£o [^4.5.2].

### A Escolha do Par√¢metro de Complexidade e a Avalia√ß√£o do Desempenho da √Årvore

```mermaid
graph TB
    subgraph "Model Selection with Œ±"
    A["Range of Œ± values"]
    B["Cross-Validation for each Œ±"]
    C["Evaluation Metric (Error Rate)"]
    D["Select Œ± with lowest Validation Error"]
     A --> B
    B --> C
    C --> D
    end
```

A escolha do par√¢metro de complexidade $\alpha$ √© feita utilizando valida√ß√£o cruzada ou outros m√©todos de escolha de modelos. O valor de $\alpha$ que resulta em um menor erro de classifica√ß√£o em um conjunto de valida√ß√£o √© escolhido para a poda final da √°rvore.  A utiliza√ß√£o de m√©tricas como sensibilidade e especificidade tamb√©m podem ser consideradas para a escolha do valor de $\alpha$.  A avalia√ß√£o do desempenho de cada √°rvore podada permite escolher o modelo mais adequado para o problema em quest√£o.  A escolha do par√¢metro $\alpha$ representa um equil√≠brio entre a complexidade e o ajuste do modelo e permite controlar a capacidade de generaliza√ß√£o da √°rvore.

> üí° **Exemplo Num√©rico:**
> Suponha que realizamos uma valida√ß√£o cruzada com 5 folds para avaliar o desempenho de diferentes valores de $\alpha$. Obtemos os seguintes resultados de erro de classifica√ß√£o m√©dio:
>
> | Œ±     | Erro de Classifica√ß√£o (Valida√ß√£o Cruzada) |
> |-------|----------------------------------------|
> | 0.001 | 0.18                                    |
> | 0.01  | 0.15                                    |
> | 0.05  | 0.12                                    |
> | 0.1   | 0.13                                    |
> | 0.2   | 0.16                                    |
> | 0.5   | 0.20                                    |
>
> Baseado nesses resultados, o valor de $\alpha$ que minimiza o erro de classifica√ß√£o na valida√ß√£o cruzada √© 0.05. Este valor seria escolhido para a poda final da √°rvore. Note que $\alpha = 0.001$ leva a um erro maior, o que sugere *overfitting*. Da mesma forma, $\alpha = 0.5$ leva a um erro maior, o que sugere *underfitting*.

###  A Rela√ß√£o da Poda com a Minimiza√ß√£o da Impureza

A poda por complexidade de custo √© uma abordagem alternativa para o processo de divis√£o gulosa da √°rvore. Enquanto a constru√ß√£o da √°rvore busca reduzir a impureza localmente, a poda busca remover as divis√µes que n√£o contribuem para a capacidade de generaliza√ß√£o. Ambos os processos s√£o gulosos, mas o primeiro busca o m√°ximo da redu√ß√£o da impureza, enquanto que o segundo busca um modelo que maximize a capacidade de generaliza√ß√£o. A escolha entre essas abordagens √© baseada no objetivo da modelagem.

### Perguntas Te√≥ricas Avan√ßadas: Como diferentes abordagens para a escolha do par√¢metro de complexidade Œ± (valida√ß√£o cruzada, m√©todos baseados em informa√ß√£o) afetam a capacidade de generaliza√ß√£o e a estabilidade dos modelos de √°rvores de decis√£o?

**Resposta:**

Diferentes abordagens para a escolha do par√¢metro de complexidade Œ± na poda por complexidade de custo, como valida√ß√£o cruzada e m√©todos baseados em informa√ß√£o, t√™m um impacto significativo na capacidade de generaliza√ß√£o e na estabilidade dos modelos de √°rvores de decis√£o.

```mermaid
graph TB
 subgraph "Model Selection Methods"
 direction TB
    A["Validation Cross-Validation"]
    B["Information-Based Criteria (AIC, BIC)"]
    C{"Generalization Capacity Assessment"}
    D{"Model Stability Assessment"}
    A --> C
    A --> D
    B --> C
    B --> D
 end
```

A valida√ß√£o cruzada √© um m√©todo emp√≠rico que estima o desempenho do modelo em dados n√£o vistos, atrav√©s da divis√£o dos dados em diferentes partes (folds) e a utiliza√ß√£o de uma parte para treino e outra para valida√ß√£o. O par√¢metro de complexidade Œ± que resulta no menor erro de classifica√ß√£o m√©dio sobre as diferentes partes √© selecionado. A valida√ß√£o cruzada √© uma abordagem geral, que pode ser aplicada a diferentes tipos de dados e modelos, e gera uma avalia√ß√£o mais precisa do desempenho do modelo em dados n√£o vistos.

M√©todos baseados em informa√ß√£o, como o crit√©rio de informa√ß√£o de Akaike (AIC) e o crit√©rio de informa√ß√£o Bayesiano (BIC), utilizam uma penalidade baseada no n√∫mero de par√¢metros do modelo, e utilizam a fun√ß√£o de *log-likelihood* como base para a avalia√ß√£o do modelo. Esses crit√©rios buscam selecionar um modelo que minimize o vi√©s e a vari√¢ncia, e oferecem uma avalia√ß√£o mais te√≥rica do desempenho do modelo. Os m√©todos baseados em informa√ß√£o utilizam um balan√ßo entre a qualidade do ajuste e a complexidade do modelo, com a inclus√£o de penalidades para modelos mais complexos.

Em geral, a escolha do par√¢metro de complexidade Œ± utilizando valida√ß√£o cruzada leva a modelos com boa capacidade de generaliza√ß√£o, pois a avalia√ß√£o √© feita diretamente no poder preditivo do modelo.  M√©todos baseados em informa√ß√£o podem levar a modelos mais simples, que t√™m maior interpretabilidade, mas, em alguns casos, podem sacrificar um pouco da capacidade de predi√ß√£o. A escolha do m√©todo depende dos objetivos da modelagem e da natureza dos dados, e ambos os m√©todos s√£o utilizados na pr√°tica.

A estabilidade dos modelos tamb√©m √© afetada pela escolha do par√¢metro Œ±. Modelos muito complexos (com Œ± baixo) tendem a ser inst√°veis e sens√≠veis aos dados de treino. Modelos mais simples (com Œ± alto) tendem a ser mais est√°veis e menos sens√≠veis aos dados de treino, mas podem perder a capacidade de capturar padr√µes importantes nos dados. A escolha de Œ± que equilibre a capacidade preditiva e a estabilidade do modelo √© fundamental para a modelagem estat√≠stica.

**Lemma 5:** *A escolha do par√¢metro de complexidade Œ± √© fundamental para a capacidade de generaliza√ß√£o de √°rvores de decis√£o. M√©todos baseados em valida√ß√£o cruzada estimam o desempenho do modelo em dados n√£o vistos, enquanto m√©todos baseados em informa√ß√£o oferecem uma avalia√ß√£o mais te√≥rica do ajuste do modelo, e uma penaliza√ß√£o para a complexidade. A estabilidade do modelo tamb√©m depende da escolha do par√¢metro Œ±*. A escolha do par√¢metro de complexidade √© um componente fundamental do processo de poda e da constru√ß√£o de modelos com √°rvores de decis√£o [^4.5.1], [^4.5.2].

**Corol√°rio 5:** *A utiliza√ß√£o de valida√ß√£o cruzada e m√©todos baseados em informa√ß√£o para a escolha do par√¢metro de complexidade Œ± permite obter modelos com boa capacidade de generaliza√ß√£o e com estabilidade das estimativas. A combina√ß√£o dos dois m√©todos pode ser utilizada para obter o melhor balan√ßo entre precis√£o, estabilidade e interpretabilidade do modelo*.  A escolha do m√©todo adequado depende das propriedades dos dados e do objetivo do modelo [^4.3.3].

> ‚ö†Ô∏è **Ponto Crucial**: A escolha do par√¢metro de complexidade Œ± √© um componente chave na constru√ß√£o de modelos baseados em √°rvores de decis√£o, e a escolha apropriada do m√©todo (valida√ß√£o cruzada ou m√©todos baseados em informa√ß√£o) garante que os modelos tenham uma boa capacidade de generaliza√ß√£o, o que √© crucial para o bom desempenho em dados n√£o vistos.  O balanceamento entre a capacidade de ajuste aos dados de treino e a capacidade de generaliza√ß√£o √© controlado por meio do par√¢metro de complexidade [^4.4.2].

### Conclus√£o

Este cap√≠tulo explorou a utiliza√ß√£o do erro de classifica√ß√£o para guiar a poda por complexidade de custo em √°rvores de decis√£o, detalhando os passos da poda, o impacto do par√¢metro de complexidade e como essas abordagens impactam a qualidade e capacidade preditiva dos modelos.  A compreens√£o da rela√ß√£o entre o erro de classifica√ß√£o e o par√¢metro de complexidade √© fundamental para a constru√ß√£o de modelos robustos e com boa capacidade de generaliza√ß√£o.

### Footnotes

[^4.1]: "In this chapter we begin our discussion of some specific methods for super-vised learning. These techniques each assume a (different) structured form for the unknown regression function, and by doing so they finesse the curse of dimensionality. Of course, they pay the possible price of misspecifying the model, and so in each case there is a tradeoff that has to be made." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.2]: "Regression models play an important role in many data analyses, providing prediction and classification rules, and data analytic tools for understand-ing the importance of different inputs." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.3]: "In this section we describe a modular algorithm for fitting additive models and their generalizations. The building block is the scatterplot smoother for fitting nonlinear effects in a flexible way. For concreteness we use as our scatterplot smoother the cubic smoothing spline described in Chapter 5." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.3.1]:  "The additive model has the form $Y = \alpha + \sum_{j=1}^p f_j(X_j) + \varepsilon$, where the error term $\varepsilon$ has mean zero." * (Trecho de "Additive Models, Trees, and Related Methods")*

[^4.3.2]:   "Given observations $x_i, y_i$, a criterion like the penalized sum of squares (5.9) of Section 5.4 can be specified for this problem, $PRSS(\alpha, f_1, f_2,..., f_p) = \sum_i^N (y_i - \alpha - \sum_j^p f_j(x_{ij}))^2 + \sum_j^p \lambda_j \int(f_j''(t_j))^2 dt_j$" * (Trecho de "Additive Models, Trees, and Related Methods")*

[^4.3.3]: "where the $\lambda_j > 0$ are tuning parameters. It can be shown that the minimizer of (9.7) is an additive cubic spline model; each of the functions $f_j$ is a cubic spline in the component $X_j$, with knots at each of the unique values of $x_{ij}$, $i = 1,..., N$." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.4]: "For two-class classification, recall the logistic regression model for binary data discussed in Section 4.4. We relate the mean of the binary response $\mu(X) = Pr(Y = 1|X)$ to the predictors via a linear regression model and the logit link function:  $log(\mu(X)/(1 ‚Äì \mu(X)) = \alpha + \beta_1 X_1 + \ldots + \beta_pX_p$." * (Trecho de "Additive Models, Trees, and Related Methods")*

[^4.4.1]: "The additive logistic regression model replaces each linear term by a more general functional form: $log(\mu(X)/(1 ‚Äì \mu(X))) = \alpha + f_1(X_1) + \ldots + f_p(X_p)$, where again each $f_j$ is an unspecified smooth function." * (Trecho de "Additive Models, Trees, and Related Methods")*

[^4.4.2]: "While the non-parametric form for the functions $f_j$ makes the model more flexible, the additivity is retained and allows us to interpret the model in much the same way as before. The additive logistic regression model is an example of a generalized additive model." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.4.3]: "In general, the conditional mean $\mu(X)$ of a response $Y$ is related to an additive function of the predictors via a link function $g$:  $g[\mu(X)] = \alpha + f_1(X_1) + \ldots + f_p(X_p)$." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.4.4]:  "Examples of classical link functions are the following: $g(\mu) = \mu$ is the identity link, used for linear and additive models for Gaussian response data." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.4.5]: "$g(\mu) = logit(\mu)$ as above, or $g(\mu) = probit(\mu)$, the probit link function, for modeling binomial probabilities. The probit function is the inverse Gaussian cumulative distribution function: $probit(\mu) = \Phi^{-1}(\mu)$." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.5]: "All three of these arise from exponential family sampling models, which in addition include the gamma and negative-binomial distributions. These families generate the well-known class of generalized linear models, which are all extended in the same way to generalized additive models." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.5.1]: "The functions $f_j$ are estimated in a flexible manner, using an algorithm whose basic building block is a scatterplot smoother. The estimated func-tion $f_j$ can then reveal possible nonlinearities in the effect of $X_j$. Not all of the functions $f_j$ need to be nonlinear." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.5.2]: "We can easily mix in linear and other parametric forms with the nonlinear terms, a necessity when some of the inputs are qualitative variables (factors)." *(Trecho de "Additive Models, Trees, and Related Methods")*
