## T√≠tulo: Modelos Aditivos Generalizados, √Årvores e M√©todos Relacionados para Classifica√ß√£o

```mermaid
graph LR
    A["X1"] --> B("f1(X1)");
    C["X2"] --> D("f2(X2)");
    E["Xp"] --> F("fp(Xp)");

    B --> G;
    D --> G;
    F --> G;

    G["$\sum f_j(X_j)$"] --> H("g(.)");

    H --> I["Y"];
    
    subgraph "Link Functions"
    J["Identidade"]
    K["Logit"]
    L["Probit"]
    M["Log"]
    end
    
    H --> J
    H --> K
    H --> L
    H --> M
```

### Introdu√ß√£o

Este cap√≠tulo explora m√©todos espec√≠ficos para **aprendizado supervisionado**, cada um assumindo uma forma estruturada diferente para a fun√ß√£o de regress√£o desconhecida, oferecendo solu√ß√µes para a **maldi√ß√£o da dimensionalidade** [^9.1]. √â fundamental entender que existe um *trade-off* entre a complexidade do modelo e o risco de misspecifica√ß√£o. Os m√©todos abordados s√£o extens√µes dos temas apresentados nos cap√≠tulos 3 a 6, incluindo **modelos aditivos generalizados**, **√°rvores de decis√£o**, **splines de regress√£o adaptativa multivariada (MARS)**, o m√©todo de indu√ß√£o de regras do paciente (PRIM) e misturas hier√°rquicas de especialistas (HME). O foco √© entender como esses modelos podem ser aplicados em problemas de classifica√ß√£o e regress√£o, especialmente em situa√ß√µes onde a rela√ß√£o entre as vari√°veis preditoras e a vari√°vel de resposta n√£o √© linear.

### Conceitos Fundamentais

**Conceito 1:** O **problema de classifica√ß√£o** busca atribuir uma classe ou categoria a uma dada observa√ß√£o com base em suas caracter√≠sticas. M√©todos lineares, embora simples, podem ser inadequados para modelar rela√ß√µes complexas e n√£o lineares presentes em dados reais [^9.1]. A escolha de um m√©todo linear implica um *trade-off* entre vi√©s e vari√¢ncia. Modelos com muitos par√¢metros podem se ajustar bem aos dados de treinamento, mas podem n√£o generalizar bem para novos dados, um exemplo claro de alta vari√¢ncia. J√° modelos com menos par√¢metros podem apresentar alto vi√©s, n√£o capturando adequadamente a complexidade dos dados. √â crucial entender como a estrutura linear afeta esse balan√ßo, pois pode simplificar demais o problema, levando a solu√ß√µes sub√≥timas, ou o oposto, levando a overfitting.

> üí° **Exemplo Num√©rico:**
> Considere um problema de classifica√ß√£o bin√°ria com duas vari√°veis preditoras ($X_1$ e $X_2$) e uma vari√°vel resposta ($Y$ com classes 0 e 1). Em um cen√°rio onde as classes s√£o separadas por uma fronteira circular, um modelo linear (como uma regress√£o log√≠stica simples) n√£o conseguiria capturar essa rela√ß√£o, resultando em um modelo com alto vi√©s e desempenho ruim. Por outro lado, um modelo complexo, como uma √°rvore de decis√£o profunda, poderia se ajustar perfeitamente aos dados de treino, mas poderia ter um desempenho ruim em dados novos (alta vari√¢ncia). Um GAM, por exemplo, poderia modelar cada preditor com fun√ß√µes n√£o lineares, capturando a separa√ß√£o das classes, equilibrando vi√©s e vari√¢ncia.

**Lemma 1:** Dado um conjunto de dados de classifica√ß√£o, a **regress√£o linear da matriz indicadora** pode ser vista como uma aproxima√ß√£o para a constru√ß√£o de **fun√ß√µes discriminantes lineares**, com coeficientes estimados por m√≠nimos quadrados. Em cen√°rios onde as classes s√£o bem separadas, esta aproxima√ß√£o pode gerar resultados compar√°veis ao LDA.

Seja $X$ a matriz de preditores de dimens√µes $N \times p$, onde $N$ √© o n√∫mero de observa√ß√µes e $p$ o n√∫mero de preditores. A matriz de indicadores $Y$ possui dimens√µes $N \times K$, onde $K$ √© o n√∫mero de classes, com cada linha da forma $[0, \ldots, 1, \ldots, 0]$, com o '1' na coluna que corresponde √† classe da observa√ß√£o. O modelo de regress√£o linear para a matriz indicadora √©:

$$
\hat{Y} = XB
$$

Onde $\hat{Y}$ √© a matriz de indicadores de classe estimada, $X$ √© a matriz de preditores, e $B$ s√£o os coeficientes estimados por m√≠nimos quadrados. A solu√ß√£o para $B$ √© dada por:

$$
\hat{B} = (X^T X)^{-1} X^T Y
$$
```mermaid
graph LR
    subgraph "Matrix Regression"
        direction LR
        A["X (Predictors): N x p"] --> B["Y (Indicators): N x K"]
        B --> C["B (Coefficients): p x K"]
    end
    D["$\\hat{Y} = XB$"] --> E["$\\hat{B} = (X^T X)^{-1} X^T Y$"]
    C --> E
```

Ao projetar os dados no espa√ßo gerado pelas colunas de $B$, os pontos de diferentes classes se agrupam linearmente. A matriz $B$ pode ser utilizada para definir os **hiperplanos de decis√£o**. A previs√£o para uma nova observa√ß√£o $x$ √© feita calculando $x^T \hat{B}$ e atribuindo a observa√ß√£o √† classe com a maior entrada neste vetor. A fun√ß√£o discriminante para cada classe $k$ √© dada por $\delta_k(x) = x^T \hat{B}_k$, onde $\hat{B}_k$ √© a $k$-√©sima coluna de $\hat{B}$.

> üí° **Exemplo Num√©rico:**
> Suponha um problema de classifica√ß√£o com $N=4$ amostras, $p=2$ preditores e $K=2$ classes. As matrizes $X$ e $Y$ s√£o:
>
> $X = \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \\ 4 & 2 \end{bmatrix}$
>
> $Y = \begin{bmatrix} 1 & 0 \\ 1 & 0 \\ 0 & 1 \\ 0 & 1 \end{bmatrix}$
>
> Primeiro, calculamos $X^T X$:
>
> $X^T X = \begin{bmatrix} 1 & 2 & 3 & 4 \\ 2 & 1 & 3 & 2 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \\ 4 & 2 \end{bmatrix} = \begin{bmatrix} 30 & 25 \\ 25 & 18 \end{bmatrix}$
>
> Em seguida, calculamos $(X^T X)^{-1}$:
>
> $(X^T X)^{-1} = \frac{1}{(30)(18)-(25)(25)} \begin{bmatrix} 18 & -25 \\ -25 & 30 \end{bmatrix} = \begin{bmatrix} 0.346 & -0.480 \\ -0.480 & 0.577 \end{bmatrix}$
>
> Agora, calculamos $X^T Y$:
>
> $X^T Y = \begin{bmatrix} 1 & 2 & 3 & 4 \\ 2 & 1 & 3 & 2 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 1 & 0 \\ 0 & 1 \\ 0 & 1 \end{bmatrix} = \begin{bmatrix} 3 & 7 \\ 3 & 5 \end{bmatrix}$
>
> Finalmente, calculamos $\hat{B}$:
>
> $\hat{B} = (X^T X)^{-1} X^T Y = \begin{bmatrix} 0.346 & -0.480 \\ -0.480 & 0.577 \end{bmatrix} \begin{bmatrix} 3 & 7 \\ 3 & 5 \end{bmatrix} = \begin{bmatrix} -0.402 & 0.022 \\ 0.291 & -0.461 \end{bmatrix}$
>
> Para classificar uma nova amostra, por exemplo $x = \begin{bmatrix} 2 \\ 2 \end{bmatrix}$, calculamos $x^T \hat{B}$:
>
> $x^T \hat{B} = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} -0.402 & 0.022 \\ 0.291 & -0.461 \end{bmatrix} = \begin{bmatrix} -0.222 & -0.878 \end{bmatrix}$
>
> A amostra seria classificada na classe 0, pois o primeiro valor √© maior.

**Conceito 2:** A **Linear Discriminant Analysis (LDA)**, como abordado em cap√≠tulos anteriores, assume que os dados para cada classe seguem uma distribui√ß√£o normal multivariada com a mesma matriz de covari√¢ncia [^4.3]. A **fronteira de decis√£o** entre duas classes, na LDA, √© linear e definida com base nas m√©dias e covari√¢ncias das classes [^4.3.1]. O LDA busca encontrar a combina√ß√£o linear das vari√°veis que melhor separe as classes, maximizando a separa√ß√£o entre as m√©dias das classes e minimizando a variabilidade dentro de cada classe [^4.3.2]. A formula√ß√£o da fun√ß√£o discriminante na LDA √© dada por:

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log \pi_k
$$

Onde $\mu_k$ √© o vetor de m√©dia da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum e $\pi_k$ √© a probabilidade *a priori* da classe $k$ [^4.3.3]. A classe predita para uma nova observa√ß√£o $x$ √© aquela que maximiza $\delta_k(x)$. O LDA pode ser interpretado como uma aplica√ß√£o da regra Bayesiana para o caso particular de distribui√ß√µes Gaussianas com covari√¢ncias iguais, e a fun√ß√£o discriminante $\delta_k(x)$ fornece um crit√©rio linear de decis√£o.
```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction TB
        A["$\\delta_k(x)$"] --> B["$x^T \\Sigma^{-1} \\mu_k$"]
        A --> C["$-\\frac{1}{2}\\mu_k^T\\Sigma^{-1}\\mu_k$"]
        A --> D["$\\log \\pi_k$"]
    end
```

> üí° **Exemplo Num√©rico:**
> Suponha duas classes com as seguintes m√©dias e matriz de covari√¢ncia comum:
>
> $\mu_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$, $\mu_2 = \begin{bmatrix} 3 \\ 3 \end{bmatrix}$, $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
>
> E as probabilidades *a priori*  s√£o: $\pi_1 = 0.6$ e $\pi_2 = 0.4$. Calculamos $\Sigma^{-1}$:
>
> $\Sigma^{-1} = \frac{1}{(1)(1)-(0.5)(0.5)} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix}$
>
> Para classificar uma nova observa√ß√£o $x = \begin{bmatrix} 2 \\ 2 \end{bmatrix}$, calculamos as fun√ß√µes discriminantes:
>
> $\delta_1(x) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} + \log(0.6) = 1.33 - 0.67 + \log(0.6) = 0.66 - 0.51 = 0.15$
>
> $\delta_2(x) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 3 \end{bmatrix} \begin{bmatrix} 1.33 & -0.67 \\ -0.67 & 1.33 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} + \log(0.4) = 7.98 - 6.00 + \log(0.4) = 1.98 - 0.92 = 1.06$
>
> Como $\delta_2(x) > \delta_1(x)$, a amostra seria classificada na classe 2.

**Corol√°rio 1:** Se as classes seguem uma distribui√ß√£o normal com covari√¢ncias iguais, a fun√ß√£o discriminante do LDA pode ser interpretada como uma proje√ß√£o dos dados em um subespa√ßo de dimens√£o menor, onde a separa√ß√£o entre as classes √© maximizada. Este resultado surge da minimiza√ß√£o da dist√¢ncia de Mahalanobis entre as observa√ß√µes e as m√©dias de cada classe [^4.3.1]. A dist√¢ncia de Mahalanobis entre um ponto $x$ e a m√©dia da classe $k$, $\mu_k$, √© dada por $\sqrt{(x - \mu_k)^T \Sigma^{-1} (x - \mu_k)}$. O LDA assume que a covari√¢ncia √© a mesma para todas as classes, $\Sigma$, e ent√£o a dist√¢ncia se reduz a uma forma linear em $x$.

**Conceito 3:** A **Regress√£o Log√≠stica** modela a probabilidade de uma observa√ß√£o pertencer a uma classe usando uma fun√ß√£o log√≠stica da combina√ß√£o linear dos preditores [^4.4]. O modelo log√≠stico para a probabilidade da classe 1 √© dado por:

$$
p(x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_1 + \ldots + \beta_px_p)}}
$$

Ou, equivalentemente, o log-odds (logit) √© modelado como:

$$
\log\left(\frac{p(x)}{1-p(x)}\right) = \beta_0 + \beta_1x_1 + \ldots + \beta_px_p
$$

Onde $p(x)$ √© a probabilidade da classe 1, e os $\beta_i$ s√£o os coeficientes do modelo [^4.4.1]. Os par√¢metros s√£o estimados maximizando a verossimilhan√ßa, dada por:

$$
L(\beta) = \prod_{i=1}^{N} p(x_i)^{y_i} (1-p(x_i))^{(1-y_i)}
$$

Onde $y_i \in \{0, 1\}$ √© o r√≥tulo de classe da observa√ß√£o $i$ [^4.4.3]. Diferentemente do LDA, a regress√£o log√≠stica n√£o assume normalidade dos preditores [^4.4.2]. Ambos os m√©todos, LDA e regress√£o log√≠stica, buscam encontrar separa√ß√µes lineares, mas a regress√£o log√≠stica estima probabilidades condicionais e pode ser mais apropriada quando o interesse est√° em probabilidades, e n√£o em fun√ß√µes discriminantes. Em casos onde as classes s√£o separ√°veis, os resultados podem ser semelhantes, mas a log√≠stica tende a ser mais robusta a desvios da normalidade [^4.4.5].
```mermaid
graph LR
    subgraph "Logistic Regression"
    A["Linear Predictor:  $\\beta_0 + \\beta_1x_1 + ... + \\beta_px_p$"]
    B["Logistic Function:  $\\frac{1}{1 + e^{-(\\beta_0 + \\beta_1x_1 + ... + \\beta_px_p)}}$"]
    A --> B
    end
```

> üí° **Exemplo Num√©rico:**
> Considere um modelo de regress√£o log√≠stica com dois preditores, $x_1$ e $x_2$, e os seguintes coeficientes: $\beta_0 = -1$, $\beta_1 = 0.5$, $\beta_2 = 0.8$. Para uma amostra com $x = \begin{bmatrix} 2 \\ 1 \end{bmatrix}$, a probabilidade de pertencer √† classe 1 √©:
>
> $p(x) = \frac{1}{1 + e^{-(-1 + 0.5*2 + 0.8*1)}} = \frac{1}{1 + e^{-0.8}} = \frac{1}{1 + 0.45} = \frac{1}{1.45} \approx 0.69$
>
> A probabilidade de pertencer √† classe 0 seria $1 - 0.69 = 0.31$. A amostra seria classificada na classe 1, pois a probabilidade √© maior.

A forma geral de um **Modelo Aditivo Generalizado (GAM)** √© dada por:

$$
g[E(Y|X_1, X_2, \ldots, X_p)] = \alpha + f_1(X_1) + f_2(X_2) + \ldots + f_p(X_p)
$$

Onde $g$ √© uma fun√ß√£o de liga√ß√£o (link function), $E(Y|X_1, X_2, \ldots, X_p)$ √© a esperan√ßa condicional da resposta $Y$ dado os preditores $X_1, X_2, \ldots, X_p$, $\alpha$ √© o intercepto e $f_j$ s√£o fun√ß√µes n√£o param√©tricas desconhecidas.

> ‚ö†Ô∏è **Nota Importante**: Modelos de classifica√ß√£o linear podem n√£o ser adequados quando as rela√ß√µes entre as vari√°veis e as classes s√£o n√£o lineares. A escolha do modelo deve considerar a natureza dos dados e o objetivo da an√°lise. **Refer√™ncia ao t√≥pico [^4.4.1]**. A flexibilidade dos GAMs permite que cada preditor tenha sua pr√≥pria fun√ß√£o, n√£o limitada a uma forma linear.

> ‚ùó **Ponto de Aten√ß√£o**: Classes desbalanceadas podem influenciar a performance dos modelos lineares, especialmente na regress√£o log√≠stica. T√©cnicas de balanceamento ou uso de pesos podem ser necess√°rias. **Conforme indicado em [^4.4.2]**. A aplica√ß√£o da regress√£o log√≠stica dentro de um GAM, como mostrado acima, tamb√©m pode ser afetada.

> ‚úîÔ∏è **Destaque**: H√° uma correla√ß√£o entre as estimativas de par√¢metros em LDA e em regress√£o log√≠stica em casos onde as classes s√£o separ√°veis linearmente. **Baseado no t√≥pico [^4.5]**. √â importante notar que modelos como o GAM, que s√£o mais flex√≠veis, podem superar as limita√ß√µes dos modelos lineares quando o problema n√£o √© linear.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
flowchart TD
  subgraph "Indicator Regression"
    A["Encode Classes (Indicator Matrix Y)"] --> B["Estimate Coefficients (B) via LS"]
    B --> C["Apply Decision Rule (max $x^T\\hat{B}$)"]
    C --> D["Compare with Probabilistic Methods"]
    D --> E["Limitations (Masking Problem, Extrapolation)"]
  end
```

A **regress√£o linear de uma matriz indicadora** √© uma abordagem para classifica√ß√£o onde cada classe √© representada por um vetor de indicadores bin√°rios, e a regress√£o linear √© aplicada a cada um desses indicadores [^4.2]. Essa abordagem busca modelar a probabilidade de pertencimento a uma classe, por meio de uma combina√ß√£o linear das vari√°veis preditoras. No entanto, esta abordagem possui limita√ß√µes, como o ‚Äúmasking problem‚Äù, onde a influ√™ncia de vari√°veis preditoras pode ser encoberta pela depend√™ncia entre classes [^4.3].

Em problemas de classifica√ß√£o com $K$ classes, a matriz de resposta $Y$ pode ser representada por uma matriz $N \times K$, onde $N$ √© o n√∫mero de amostras. Cada linha $i$ possui um valor 1 na coluna correspondente √† classe da amostra $i$, e 0 nas demais colunas. O modelo de regress√£o linear para essa matriz √© dado por:

$$
Y = XB + E
$$

onde $X$ √© a matriz de preditores $N \times p$, $B$ √© a matriz de coeficientes $p \times K$ a ser estimada por m√≠nimos quadrados, e $E$ √© a matriz de erros $N \times K$. A solu√ß√£o para $B$ √© dada por:

$$
\hat{B} = (X^TX)^{-1}X^TY
$$

Ap√≥s estimar os coeficientes, a classe predita para uma nova amostra $x$ √© aquela com maior valor em $x^T\hat{B}$. Embora essa abordagem possa gerar boas solu√ß√µes, ela n√£o garante que as probabilidades estimadas estejam entre 0 e 1. A decis√£o final da classe √© tomada atrav√©s de um *argmax*. Este m√©todo busca encontrar o melhor hiperplano de decis√£o atrav√©s de proje√ß√µes lineares.

**Lemma 2:** Se as classes s√£o linearmente separ√°veis e a matriz de covari√¢ncia para cada classe √© igual ($\Sigma_k = \Sigma, \forall k$), a solu√ß√£o obtida via regress√£o linear da matriz indicadora √© equivalente √† solu√ß√£o do LDA, no sentido de que ambos os m√©todos levam √† mesma fronteira de decis√£o.

**Prova do Lemma 2:** A solu√ß√£o de m√≠nimos quadrados $\hat{B} = (X^TX)^{-1}X^TY$ √© uma transforma√ß√£o linear das respostas $Y$. Sob as hip√≥teses de classes gaussianas com covari√¢ncias iguais, os coeficientes $\hat{B}$ s√£o proporcionais aos coeficientes da fun√ß√£o discriminante do LDA. Se a regra de decis√£o em ambos os casos √© tomar a classe com maior valor de fun√ß√£o, ent√£o as fronteiras de decis√£o ser√£o equivalentes. A fun√ß√£o discriminante do LDA,

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log \pi_k
$$

leva √† mesma separa√ß√£o entre as classes, pois, neste caso especial, ambas as abordagens encontram a mesma dire√ß√£o de separa√ß√£o. $\blacksquare$

**Corol√°rio 2:** A equival√™ncia entre regress√£o linear e LDA em casos especiais simplifica a an√°lise, pois a matriz de indicadores permite obter as proje√ß√µes dos dados nas classes atrav√©s de uma regress√£o linear, e as decis√µes de classe s√£o tomadas com base nas proje√ß√µes. Conforme indicado em [^4.3], esta equival√™ncia √© v√°lida sob as condi√ß√µes de covari√¢ncias iguais e classes separ√°veis. O m√©todo de regress√£o linear √© n√£o-probabil√≠stico e n√£o oferece estimativas diretas de probabilidades de classe.

Em alguns casos, a **regress√£o log√≠stica** pode fornecer estimativas mais est√°veis das probabilidades, enquanto a **regress√£o de indicadores** pode levar a extrapola√ß√µes fora do intervalo [0,1] [^4.4]. No entanto, a regress√£o de indicadores pode ser suficiente e at√© vantajosa quando o objetivo principal √© a fronteira de decis√£o linear [^4.2].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Techniques"
    direction TB
    A["L1 Regularization (Lasso)"] --> B["Sparse Coefficients"]
    C["L2 Regularization (Ridge)"] --> D["Shrinks Coefficients"]
    E["Elastic Net"] --> F["Combines L1 and L2"]
    B --> G["Better Generalization"]
    D --> G
    F --> G
     end
     H["Regularization Parameter ($\\lambda$)"] --> G
```

A **sele√ß√£o de vari√°veis** √© crucial para modelos de classifica√ß√£o, principalmente quando se trabalha com dados de alta dimens√£o. T√©cnicas como a regulariza√ß√£o podem ser usadas para selecionar vari√°veis importantes e melhorar a generaliza√ß√£o do modelo. A **regulariza√ß√£o L1** (Lasso) adiciona a norma L1 dos coeficientes √† fun√ß√£o de custo, induzindo esparsidade no modelo, ou seja, fazendo com que alguns coeficientes sejam exatamente zero [^4.4.4]. Isso seleciona implicitamente as vari√°veis mais relevantes. A regulariza√ß√£o L2 (Ridge), por outro lado, adiciona a norma L2 dos coeficientes √† fun√ß√£o de custo, encolhendo os coeficientes para zero, mas n√£o necessariamente tornando-os exatamente zero [^4.5]. Essa t√©cnica estabiliza os modelos, reduzindo o problema do *overfitting*. Ambas podem ser combinadas em uma abordagem chamada **Elastic Net** para equilibrar sele√ß√£o de vari√°veis e estabilidade [^4.5].

Na regress√£o log√≠stica, por exemplo, a fun√ß√£o de custo com regulariza√ß√£o L1 √© dada por:

$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda \sum_{j=1}^{p} |\beta_j|
$$

onde $\lambda$ √© um hiperpar√¢metro que controla a intensidade da regulariza√ß√£o [^4.4.4]. O primeiro termo √© a verossimilhan√ßa negativa do modelo, e o segundo termo √© a penalidade L1, que induz a esparsidade. Na regulariza√ß√£o L2, o termo $\lambda \sum_{j=1}^{p} |\beta_j|$ √© substitu√≠do por $\lambda \sum_{j=1}^{p} \beta_j^2$:

$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda \sum_{j=1}^{p} \beta_j^2
$$
A penalidade L2 encolhe os coeficientes, levando a um modelo mais est√°vel.
E no caso do Elastic Net, a fun√ß√£o de custo inclui ambas as penalidades:

$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda_1 \sum_{j=1}^{p} |\beta_j| + \lambda_2 \sum_{j=1}^{p} \beta_j^2
$$
onde $\lambda_1$ e $\lambda_2$ controlam a intensidade das penalidades L1 e L2, respectivamente. O Elastic Net combina a esparsidade da regulariza√ß√£o L1 com a estabilidade da regulariza√ß√£o L2.

> üí° **Exemplo Num√©rico:**
> Vamos usar um exemplo para ilustrar o efeito da regulariza√ß√£o L1 (Lasso) e L2 (Ridge) em um modelo de regress√£o log√≠stica. Suponha que temos um modelo com dois preditores e os seguintes par√¢metros sem regulariza√ß√£o: $\beta_0 = 0.5$, $\beta_1 = 2.0$, $\beta_2 = -1.5$.
>
> **Lasso (L1):** Ao aplicar a regulariza√ß√£o L1 com $\lambda = 0.5$, o modelo ajustaria os coeficientes, possivelmente reduzindo alguns a zero. Por exemplo, $\beta_1$ poderia ser reduzido para 1.2, e $\beta_2$ poderia ser reduzido para 0, resultando em um modelo mais esparso.
>
> **Ridge (L2):** Ao aplicar a regulariza√ß√£o L2 com $\lambda = 0.5$, o modelo encolheria os coeficientes em dire√ß√£o a zero, mas n√£o necessariamente a zero. Por exemplo, $\beta_1$ poderia ser reduzido para 1.5, e $\beta_2$ poderia ser reduzido para -1.0.
>
> **Elastic Net:** Com $\lambda_1 = 0.3$ e $\lambda_2 = 0.2$, o Elastic Net combinaria os efeitos do Lasso e do Ridge, resultando em coeficientes encolhidos, com alguns possivelmente pr√≥ximos de zero. Por exemplo, $\beta_1$ poderia ser reduzido para 1.3 e $\beta_2$ para -0.5.
>
> A escolha do valor de $\lambda$ √© crucial e geralmente √© feita usando valida√ß√£o cruzada.

**Lemma 3:** A penaliza√ß√£o L1 na regress√£o log√≠stica leva a coeficientes esparsos devido ao formato da fun√ß√£o de penalidade. A norma L1 imp√µe uma penalidade que n√£o √© diferenci√°vel em zero, levando a solu√ß√µes onde alguns coeficientes s√£o exatamente zero [^4.4.4].

**Prova do Lemma 3:** A otimiza√ß√£o da fun√ß√£o de custo com penaliza√ß√£o L1 envolve a minimiza√ß√£o da soma da verossimilhan√ßa negativa com o termo de penalidade. Geometricamente, a penaliza√ß√£o L1 for√ßa os coeficientes a se concentrarem nos eixos coordenados, resultando em coeficientes nulos para algumas vari√°veis. Este comportamento resulta da n√£o-diferenciabilidade da norma L1 em zero, que for√ßa a solu√ß√£o a se concentrar em pontos onde alguns dos coeficientes s√£o zero. A norma L2, por outro lado, possui derivadas cont√≠nuas e encolhe os coeficientes, mas raramente os torna exatamente zero. $\blacksquare$

**Corol√°rio 3:** A esparsidade induzida pela regulariza√ß√£o L1 facilita a interpreta√ß√£o do modelo, pois as vari√°veis com coeficientes zero s√£o consideradas irrelevantes para o problema de classifica√ß√£o, selecionando automaticamente as vari√°veis mais importantes para a constru√ß√£o da fronteira de decis√£o [^4.4.5]. A regulariza√ß√£o L1 realiza a sele√ß√£o de vari√°veis de forma impl√≠cita, reduzindo a complexidade do modelo.

> ‚ö†Ô∏è **Ponto Crucial**: A escolha entre L1 e L2 (ou Elastic Net) depende do problema. L1 √© prefer√≠vel para sele√ß√£o de vari√°veis, enquanto L2 ajuda na estabilidade e redu√ß√£o do overfitting. A combina√ß√£o Elastic Net pode aproveitar vantagens de ambos os tipos de regulariza√ß√£o [^4.5]. Elastic Net √© prefer√≠vel a Lasso quando o n√∫mero de preditores √© muito alto e h√° multicolinearidade, pois ele distribui os pesos entre vari√°veis correlacionadas. A escolha de $\lambda$ √© um hiperpar√¢metro que deve ser ajustado via valida√ß√£o cruzada.

### Separating Hyperplanes e Perceptrons

Uma **separating hyperplane** √© uma superf√≠cie linear que divide o espa√ßo de caracter√≠sticas em regi√µes correspondentes a diferentes classes. O objetivo √© encontrar um hiperplano que maximize a dist√¢ncia entre as classes, conhecida como margem. Seja um conjunto de dados $(x_i, y_i)$, onde $x_i \in \mathbb{R}^p$ s√£o os preditores e $y_i \in \{-1, 1\}$ s√£o os r√≥tulos das classes. O hiperplano √© definido pela equa√ß√£o:

$$
w^T x + b = 0
$$

Onde $w \in \mathbb{R}^p$ √© o vetor normal ao hiperplano e $b \in \mathbb{R}$ √© o vi√©s. Para uma classifica√ß√£o bin√°ria, o objetivo √© encontrar $w$ e $b$ de forma que:

$$
y_i(w^T x_i + b) > 0, \forall i
$$
```mermaid
graph LR
    subgraph "Hyperplane Definition"
    A["Hyperplane Equation: $w^T x + b = 0$"] --> B["Vector Normal to Hyperplane: $w$"]
    A --> C["Bias: $b$"]
    D["Classification Condition: $y_i(w^T x_i + b) > 0$"]
    B --> D
    C --> D
    end
```
O hiperplano √≥timo √© aquele que maximiza a dist√¢ncia entre o hiperplano e as observa√ß√µes mais pr√≥ximas, conhecidas como pontos de suporte. A margem √© definida como $\frac{2}{||w||}$. A maximiza√ß√£o da margem √© equivalente a minimizar $\frac{1}{2} ||w||^2$, sujeito √†s restri√ß√µes de classifica√ß√£o correta:

$$
\begin{aligned}
    & \text{minimizar}  \quad \frac{1}{2}||w||^2 \\
    & \text{sujeito a} \quad y_i(w^T x_i + b) \geq 1, \forall i
\end{aligned}
$$

A solu√ß√£o para este problema de otimiza√ß√£o √© dada por:

$$
w = \sum_{i=1}^{N} \alpha_i y_i x_i
$$

onde $\alpha_i$ s√£o os multiplicadores de Lagrange, obtidos atrav√©s da solu√ß√£o do problema dual de Wolfe [^4.5.2]. Os pontos de suporte s√£o os $x_i$ para os quais $\alpha_i > 0$.

> üí° **Exemplo Num√©rico:**
> Suponha que temos duas classes linearmente separ√°veis com as seguintes amostras:
>
> Classe 1 (y = -1): $x_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$, $x_2 = \begin{bmatrix} 2 \\ 1 \end{bmatrix}$
>
> Classe 2 (y = 1): $x_3 = \begin{bmatrix} 2 \\ 3 \end{bmatrix}$, $x_4 = \begin{bmatrix} 3 \\ 3 \end{bmatrix}$
>
> O objetivo √© encontrar um hiperplano $w^T x + b = 0$ que separe essas classes. Atrav√©s de m√©todos de otimiza√ß√£o (que n√£o ser√£o detalhados aqui), podemos encontrar, por exemplo, $w = \begin{bmatrix} -1 \\ 1 \end{bmatrix}$ e $b = 0$. O hiperplano resultante √© $-x_1 + x_2 = 0$, ou seja, $x_1 = x_2$. A margem seria maximizada por este hiperplano, e as amostras mais pr√≥ximas a ele seriam os pontos de suporte.

O **Perceptron de Rosenblatt** √© um algoritmo de aprendizado de m√°quina para classifica√ß√£o linear, cujo objetivo √© encontrar um hiperplano que separe os dados em diferentes classes [^4.5.1]. O algoritmo ajusta iterativamente os pesos do hiperplano com base em classifica√ß√µes err√¥neas. Seja um conjunto de dados $(x_i, y_i)$, onde $x_i \in \mathbb{R}^p$ s√£o os preditores e $y_i \in \{-1, 1\}$ s√£o os r√≥tulos das classes. A predi√ß√£o do perceptron √©:

$$
\hat{y} = \text{sign}(w^T x + b)
$$

Inicializando com valores arbitr√°rios para $w$ e $b$, o algoritmo do Perceptron atualiza os par√¢metros da seguinte forma:
1.  Se $y_i(w^T x_i + b) \leq 0$ (classifica√ß√£o errada):
$$
w_{t+1} = w_t + \eta y_i x_i
$$
$$
b_{t+1} = b_t + \eta y_i
$$
onde $\eta$ √© a taxa de aprendizado e $t$ √© o n√∫mero da itera√ß√£o.
2. Se a classifica√ß√£o estiver correta, os par√¢metros n√£o s√£o atualizados. A atualiza√ß√£o de $w$ e $b$ √© uma corre√ß√£o baseada no erro de classifica√ß√£o.
```mermaid
graph LR
    subgraph "Perceptron Algorithm"
    A["Prediction: $\\hat{y} = sign