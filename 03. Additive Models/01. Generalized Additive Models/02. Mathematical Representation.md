## TÃ­tulo: Modelos Aditivos Generalizados, Ãrvores e MÃ©todos Relacionados para ClassificaÃ§Ã£o

```mermaid
graph LR
    A["Dados de Entrada"] --> B{"LDA"};
    A --> C{"RegressÃ£o LogÃ­stica"};
    A --> D{"Ãrvores de DecisÃ£o"};

    B --> E["RegularizaÃ§Ã£o (L1, L2, Elastic Net)"];
    C --> F["RegularizaÃ§Ã£o (L1, L2, Elastic Net)"];
    D --> G["SeleÃ§Ã£o de VariÃ¡veis"];
    
    E --> H{"AvaliaÃ§Ã£o LDA"};
    F --> I{"AvaliaÃ§Ã£o Reg. LogÃ­stica"};
    G --> J{"AvaliaÃ§Ã£o Ãrvores DecisÃ£o"};
    
    H --> K{"Melhor Modelo"};
    I --> K;
    J --> K;
```

### IntroduÃ§Ã£o

Este capÃ­tulo explora mÃ©todos especÃ­ficos para **aprendizado supervisionado**, cada um assumindo uma forma estruturada diferente para a funÃ§Ã£o de regressÃ£o desconhecida, oferecendo soluÃ§Ãµes para a **maldiÃ§Ã£o da dimensionalidade** [^9.1]. Ã‰ fundamental entender que existe um *trade-off* entre a complexidade do modelo e o risco de misspecificaÃ§Ã£o. Os mÃ©todos abordados sÃ£o extensÃµes dos temas apresentados nos capÃ­tulos 3 a 6, incluindo **modelos aditivos generalizados**, **Ã¡rvores de decisÃ£o**, **splines de regressÃ£o adaptativa multivariada (MARS)**, o mÃ©todo de induÃ§Ã£o de regras do paciente (PRIM) e misturas hierÃ¡rquicas de especialistas (HME). O foco Ã© entender como esses modelos podem ser aplicados em problemas de classificaÃ§Ã£o.

### Conceitos Fundamentais

**Conceito 1:** O **problema de classificaÃ§Ã£o** busca atribuir uma classe ou categoria a uma dada observaÃ§Ã£o com base em suas caracterÃ­sticas. MÃ©todos lineares, embora simples, podem ser inadequados para modelar relaÃ§Ãµes complexas e nÃ£o lineares presentes em dados reais [^9.1]. A escolha de um mÃ©todo linear implica um *trade-off* entre viÃ©s e variÃ¢ncia. Modelos com muitos parÃ¢metros podem se ajustar bem aos dados de treinamento, mas podem nÃ£o generalizar bem para novos dados, um exemplo claro de alta variÃ¢ncia. JÃ¡ modelos com menos parÃ¢metros podem apresentar alto viÃ©s, nÃ£o capturando adequadamente a complexidade dos dados. Ã‰ crucial entender como a estrutura linear afeta esse balanÃ§o, pois pode simplificar demais o problema, levando a soluÃ§Ãµes subÃ³timas, ou o oposto, levando a overfitting.

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Suponha que temos um conjunto de dados com duas classes (0 e 1) e duas variÃ¡veis preditoras ($x_1$ e $x_2$). Se usarmos um modelo linear simples, como um classificador linear, podemos obter uma fronteira de decisÃ£o que separa as classes razoavelmente bem. No entanto, se a relaÃ§Ã£o entre as variÃ¡veis e a classe for nÃ£o linear (por exemplo, as classes se distribuem como cÃ­rculos concÃªntricos), o classificador linear terÃ¡ um alto viÃ©s, pois nÃ£o conseguirÃ¡ capturar essa relaÃ§Ã£o.
>
> Por outro lado, um modelo muito complexo, como uma Ã¡rvore de decisÃ£o profunda, pode se ajustar perfeitamente aos dados de treinamento, incluindo o ruÃ­do, resultando em baixa variÃ¢ncia nos dados de treinamento, mas alta variÃ¢ncia em novos dados. Isso significa que o modelo se ajustarÃ¡ bem aos dados de treinamento, mas terÃ¡ um desempenho ruim em dados nÃ£o vistos. A escolha do mÃ©todo correto envolve encontrar o equilÃ­brio certo entre viÃ©s e variÃ¢ncia.

**Lemma 1:** Dado um conjunto de dados de classificaÃ§Ã£o, a **regressÃ£o linear da matriz indicadora** pode ser vista como uma aproximaÃ§Ã£o para a construÃ§Ã£o de **funÃ§Ãµes discriminantes lineares**, com coeficientes estimados por mÃ­nimos quadrados. Em cenÃ¡rios onde as classes sÃ£o bem separadas, esta aproximaÃ§Ã£o pode gerar resultados comparÃ¡veis ao LDA.

Seja $X$ a matriz de preditores de dimensÃµes $N \times p$, onde $N$ Ã© o nÃºmero de observaÃ§Ãµes e $p$ o nÃºmero de preditores. A matriz de indicadores $Y$ possui dimensÃµes $N \times K$, onde $K$ Ã© o nÃºmero de classes, com cada linha da forma $[0, \ldots, 1, \ldots, 0]$, com o '1' na coluna que corresponde Ã  classe da observaÃ§Ã£o. O modelo de regressÃ£o linear para a matriz indicadora Ã©:

$$
\hat{Y} = XB
$$

Onde $\hat{Y}$ Ã© a matriz de indicadores de classe estimada, $X$ Ã© a matriz de preditores, e $B$ sÃ£o os coeficientes estimados por mÃ­nimos quadrados. A soluÃ§Ã£o para $B$ Ã© dada por:

$$
\hat{B} = (X^T X)^{-1} X^T Y
$$
```mermaid
graph LR
    subgraph "RegressÃ£o Linear da Matriz Indicadora"
    direction TB
        A["Matriz de Preditores X (N x p)"]
        B["Matriz de Indicadores Y (N x K)"]
        C["Coeficientes Estimados B (p x K)"]
        D["RegressÃ£o Linear:  YÌ‚ = XB"]
        E["SoluÃ§Ã£o via MÃ­nimos Quadrados: BÌ‚ = (Xáµ€X)â»Â¹Xáµ€Y"]
        A --> D
        B --> D
        D --> E
    end
```

Ao projetar os dados no espaÃ§o gerado pelas colunas de $B$, os pontos de diferentes classes se agrupam linearmente. A matriz $B$ pode ser utilizada para definir os **hiperplanos de decisÃ£o**. A previsÃ£o para uma nova observaÃ§Ã£o $x$ Ã© feita calculando $x^T \hat{B}$ e atribuindo a observaÃ§Ã£o Ã  classe com a maior entrada neste vetor.

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Suponha que temos 3 observaÃ§Ãµes e 2 classes, com os seguintes dados:
>
> $X = \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \end{bmatrix}$ e $Y = \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix}$.
>
> **Passo 1: Calcular $X^T X$**
>
> $X^T X = \begin{bmatrix} 1 & 2 & 3 \\ 2 & 1 & 3 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \end{bmatrix} = \begin{bmatrix} 14 & 13 \\ 13 & 14 \end{bmatrix}$
>
> **Passo 2: Calcular $(X^T X)^{-1}$**
>
> $(X^T X)^{-1} = \frac{1}{14^2 - 13^2} \begin{bmatrix} 14 & -13 \\ -13 & 14 \end{bmatrix} = \frac{1}{27} \begin{bmatrix} 14 & -13 \\ -13 & 14 \end{bmatrix} \approx \begin{bmatrix} 0.518 & -0.481 \\ -0.481 & 0.518 \end{bmatrix}$
>
> **Passo 3: Calcular $X^T Y$**
>
> $X^T Y = \begin{bmatrix} 1 & 2 & 3 \\ 2 & 1 & 3 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix} = \begin{bmatrix} 4 & 2 \\ 5 & 1 \end{bmatrix}$
>
> **Passo 4: Calcular $\hat{B}$**
>
> $\hat{B} = (X^T X)^{-1} X^T Y = \begin{bmatrix} 0.518 & -0.481 \\ -0.481 & 0.518 \end{bmatrix} \begin{bmatrix} 4 & 2 \\ 5 & 1 \end{bmatrix} = \begin{bmatrix} -0.333 & 0.555 \\ 0.667 & -0.444 \end{bmatrix}$
>
> Para uma nova observaÃ§Ã£o $x = \begin{bmatrix} 2 & 2 \end{bmatrix}$, calculamos $x^T \hat{B} = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} -0.333 & 0.555 \\ 0.667 & -0.444 \end{bmatrix} = \begin{bmatrix} 0.668 & 0.222 \end{bmatrix}$. Como o primeiro valor Ã© maior, a observaÃ§Ã£o seria classificada como classe 1.

**Conceito 2:** A **Linear Discriminant Analysis (LDA)**, como abordado em capÃ­tulos anteriores, assume que os dados para cada classe seguem uma distribuiÃ§Ã£o normal multivariada com a mesma matriz de covariÃ¢ncia [^4.3]. A **fronteira de decisÃ£o** entre duas classes, na LDA, Ã© linear e definida com base nas mÃ©dias e covariÃ¢ncias das classes [^4.3.1]. O LDA busca encontrar a combinaÃ§Ã£o linear das variÃ¡veis que melhor separe as classes, maximizando a separaÃ§Ã£o entre as mÃ©dias das classes e minimizando a variabilidade dentro de cada classe [^4.3.2]. A formulaÃ§Ã£o da funÃ§Ã£o discriminante na LDA Ã© dada por:

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log \pi_k
$$

Onde $\mu_k$ Ã© o vetor de mÃ©dia da classe $k$, $\Sigma$ Ã© a matriz de covariÃ¢ncia comum e $\pi_k$ Ã© a probabilidade *a priori* da classe $k$ [^4.3.3]. A classe predita para uma nova observaÃ§Ã£o $x$ Ã© aquela que maximiza $\delta_k(x)$.

```mermaid
graph LR
    subgraph "FunÃ§Ã£o Discriminante LDA"
        direction TB
        A["x: Vetor de ObservaÃ§Ã£o"]
        B["Î¼â‚–: MÃ©dia da Classe k"]
        C["Î£: Matriz de CovariÃ¢ncia Comum"]
        D["Ï€â‚–: Probabilidade a Priori da Classe k"]
        E["Î´â‚–(x) = xáµ€Î£â»Â¹Î¼â‚– - 1/2 Î¼â‚–áµ€Î£â»Â¹Î¼â‚– + log(Ï€â‚–)"]
        A --> E
        B --> E
        C --> E
        D --> E
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Considere um problema de classificaÃ§Ã£o binÃ¡ria com duas classes, onde:
>
> - Classe 1: $\mu_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$
> - Classe 2: $\mu_2 = \begin{bmatrix} 3 \\ 3 \end{bmatrix}$
> - Matriz de covariÃ¢ncia comum: $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
> - Probabilidades a priori: $\pi_1 = 0.6$, $\pi_2 = 0.4$
>
> **Passo 1: Calcular $\Sigma^{-1}$**
>
> $\Sigma^{-1} = \frac{1}{1 - 0.5^2} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \frac{4}{3} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.333 & -0.666 \\ -0.666 & 1.333 \end{bmatrix}$
>
> **Passo 2: Calcular as funÃ§Ãµes discriminantes para uma nova observaÃ§Ã£o $x = \begin{bmatrix} 2 \\ 2 \end{bmatrix}$**
>
> $\delta_1(x) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 1.333 & -0.666 \\ -0.666 & 1.333 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 1.333 & -0.666 \\ -0.666 & 1.333 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} + \log(0.6) \approx  0.000 - 0.666 -0.510 \approx -1.176$
>
> $\delta_2(x) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 1.333 & -0.666 \\ -0.666 & 1.333 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 3 \end{bmatrix} \begin{bmatrix} 1.333 & -0.666 \\ -0.666 & 1.333 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} + \log(0.4) \approx  0.000 - 6.000 -0.916 \approx -6.916$
>
> Como $\delta_1(x) > \delta_2(x)$, a observaÃ§Ã£o $x$ Ã© classificada como pertencente Ã  classe 1.

**CorolÃ¡rio 1:** Se as classes seguem uma distribuiÃ§Ã£o normal com covariÃ¢ncias iguais, a funÃ§Ã£o discriminante do LDA pode ser interpretada como uma projeÃ§Ã£o dos dados em um subespaÃ§o de dimensÃ£o menor, onde a separaÃ§Ã£o entre as classes Ã© maximizada. Este resultado surge da minimizaÃ§Ã£o da distÃ¢ncia de Mahalanobis entre as observaÃ§Ãµes e as mÃ©dias de cada classe [^4.3.1]. A distÃ¢ncia de Mahalanobis entre um ponto $x$ e a mÃ©dia da classe $k$, $\mu_k$, Ã© dada por $\sqrt{(x - \mu_k)^T \Sigma^{-1} (x - \mu_k)}$.  O LDA assume que a covariÃ¢ncia Ã© a mesma para todas as classes, $\Sigma$, e entÃ£o a distÃ¢ncia se reduz a uma forma linear em $x$.

**Conceito 3:** A **RegressÃ£o LogÃ­stica** modela a probabilidade de uma observaÃ§Ã£o pertencer a uma classe usando uma funÃ§Ã£o logÃ­stica da combinaÃ§Ã£o linear dos preditores [^4.4]. O modelo logÃ­stico para a probabilidade da classe 1 Ã© dado por:

$$
p(x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_1 + \ldots + \beta_px_p)}}
$$

Ou, equivalentemente, o log-odds (logit) Ã© modelado como:

$$
\log\left(\frac{p(x)}{1-p(x)}\right) = \beta_0 + \beta_1x_1 + \ldots + \beta_px_p
$$

Onde $p(x)$ Ã© a probabilidade da classe 1, e os $\beta_i$ sÃ£o os coeficientes do modelo [^4.4.1]. Os parÃ¢metros sÃ£o estimados maximizando a verossimilhanÃ§a, dada por:

$$
L(\beta) = \prod_{i=1}^{N} p(x_i)^{y_i} (1-p(x_i))^{(1-y_i)}
$$

Onde $y_i \in \{0, 1\}$ Ã© o rÃ³tulo de classe da observaÃ§Ã£o $i$ [^4.4.3]. Diferentemente do LDA, a regressÃ£o logÃ­stica nÃ£o assume normalidade dos preditores [^4.4.2]. Ambos os mÃ©todos, LDA e regressÃ£o logÃ­stica, buscam encontrar separaÃ§Ãµes lineares, mas a regressÃ£o logÃ­stica estima probabilidades condicionais e pode ser mais apropriada quando o interesse estÃ¡ em probabilidades, e nÃ£o em funÃ§Ãµes discriminantes. Em casos onde as classes sÃ£o separÃ¡veis, os resultados podem ser semelhantes, mas a logÃ­stica tende a ser mais robusta a desvios da normalidade [^4.4.5].

```mermaid
graph LR
    subgraph "RegressÃ£o LogÃ­stica"
    direction TB
        A["FunÃ§Ã£o LogÃ­stica:  p(x) = 1 / (1 + e^(-(Î²â‚€ + Î²â‚xâ‚ + ... + Î²â‚šxâ‚š)))"]
        B["Log-Odds (Logit): log(p(x)/(1-p(x))) = Î²â‚€ + Î²â‚xâ‚ + ... + Î²â‚šxâ‚š"]
        C["VerossimilhanÃ§a: L(Î²) = Î  p(xáµ¢)^yáµ¢ (1-p(xáµ¢))^(1-yáµ¢)"]
        A --> B
        B --> C
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Suponha que temos um modelo de regressÃ£o logÃ­stica com dois preditores:
>
> $$ \log\left(\frac{p(x)}{1-p(x)}\right) = -1 + 0.5x_1 - 0.2x_2 $$
>
> Para uma nova observaÃ§Ã£o $x = \begin{bmatrix} 2 \\ 3 \end{bmatrix}$, temos:
>
> $$ \log\left(\frac{p(x)}{1-p(x)}\right) = -1 + 0.5(2) - 0.2(3) = -1 + 1 - 0.6 = -0.6 $$
>
> Para encontrar a probabilidade $p(x)$:
>
> $$ \frac{p(x)}{1-p(x)} = e^{-0.6} \approx 0.5488 $$
>
> $$ p(x) = 0.5488(1 - p(x)) $$
>
> $$ p(x) = 0.5488 - 0.5488p(x) $$
>
> $$ 1.5488p(x) = 0.5488 $$
>
> $$ p(x) = \frac{0.5488}{1.5488} \approx 0.354 $$
>
> Isso significa que a probabilidade da observaÃ§Ã£o pertencer Ã  classe 1 Ã© aproximadamente 0.354. Se o limiar de classificaÃ§Ã£o for 0.5, a observaÃ§Ã£o seria classificada como classe 0.

> âš ï¸ **Nota Importante**: Modelos de classificaÃ§Ã£o linear podem nÃ£o ser adequados quando as relaÃ§Ãµes entre as variÃ¡veis e as classes sÃ£o nÃ£o lineares. A escolha do modelo deve considerar a natureza dos dados e o objetivo da anÃ¡lise. **ReferÃªncia ao tÃ³pico [^4.4.1]**.

> â— **Ponto de AtenÃ§Ã£o**: Classes desbalanceadas podem influenciar a performance dos modelos lineares, especialmente na regressÃ£o logÃ­stica. TÃ©cnicas de balanceamento ou uso de pesos podem ser necessÃ¡rias. **Conforme indicado em [^4.4.2]**.

> âœ”ï¸ **Destaque**: HÃ¡ uma correlaÃ§Ã£o entre as estimativas de parÃ¢metros em LDA e em regressÃ£o logÃ­stica em casos onde as classes sÃ£o separÃ¡veis linearmente. **Baseado no tÃ³pico [^4.5]**.

### RegressÃ£o Linear e MÃ­nimos Quadrados para ClassificaÃ§Ã£o

```mermaid
flowchart TD
  subgraph "RegressÃ£o de Indicadores"
    A["Codificar Classes (Matriz Indicadora Y)"] --> B["Estimar Coeficientes (B) via LS"]
    B --> C["Aplicar Regra de DecisÃ£o (max xáµ€BÌ‚)"]
    C --> D["Comparar com MÃ©todos ProbabilÃ­sticos"]
  end
```

A **regressÃ£o linear de uma matriz indicadora** Ã© uma abordagem para classificaÃ§Ã£o onde cada classe Ã© representada por um vetor de indicadores binÃ¡rios, e a regressÃ£o linear Ã© aplicada a cada um desses indicadores [^4.2]. Essa abordagem busca modelar a probabilidade de pertencimento a uma classe, por meio de uma combinaÃ§Ã£o linear das variÃ¡veis preditoras. No entanto, esta abordagem possui limitaÃ§Ãµes, como o â€œmasking problemâ€, onde a influÃªncia de variÃ¡veis preditoras pode ser encoberta pela dependÃªncia entre classes [^4.3].

Em problemas de classificaÃ§Ã£o com $K$ classes, a matriz de resposta $Y$ pode ser representada por uma matriz $N \times K$, onde $N$ Ã© o nÃºmero de amostras. Cada linha $i$  possui um valor 1 na coluna correspondente Ã  classe da amostra $i$, e 0 nas demais colunas. O modelo de regressÃ£o linear para essa matriz Ã© dado por:

$$
Y = XB + E
$$

onde $X$ Ã© a matriz de preditores $N \times p$, $B$ Ã© a matriz de coeficientes $p \times K$ a ser estimada por mÃ­nimos quadrados, e $E$ Ã© a matriz de erros $N \times K$. A soluÃ§Ã£o para $B$ Ã© dada por:

$$
\hat{B} = (X^TX)^{-1}X^TY
$$

ApÃ³s estimar os coeficientes, a classe predita para uma nova amostra $x$ Ã© aquela com maior valor em $x^T\hat{B}$. Embora essa abordagem possa gerar boas soluÃ§Ãµes, ela nÃ£o garante que as probabilidades estimadas estejam entre 0 e 1. A decisÃ£o final da classe Ã© tomada atravÃ©s de um *argmax*.

**Lemma 2:** Se as classes sÃ£o linearmente separÃ¡veis e a matriz de covariÃ¢ncia para cada classe Ã© igual ($\Sigma_k = \Sigma, \forall k$), a soluÃ§Ã£o obtida via regressÃ£o linear da matriz indicadora Ã© equivalente Ã  soluÃ§Ã£o do LDA, no sentido de que ambos os mÃ©todos levam Ã  mesma fronteira de decisÃ£o.

**Prova do Lemma 2:** A soluÃ§Ã£o de mÃ­nimos quadrados $\hat{B} = (X^TX)^{-1}X^TY$ Ã© uma transformaÃ§Ã£o linear das respostas $Y$. Sob as hipÃ³teses de classes gaussianas com covariÃ¢ncias iguais, os coeficientes $\hat{B}$ sÃ£o proporcionais aos coeficientes da funÃ§Ã£o discriminante do LDA.  Se a regra de decisÃ£o em ambos os casos Ã© tomar a classe com maior valor de funÃ§Ã£o, entÃ£o as fronteiras de decisÃ£o serÃ£o equivalentes. A funÃ§Ã£o discriminante do LDA,

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log \pi_k
$$

leva Ã  mesma separaÃ§Ã£o entre as classes, pois, neste caso especial, ambas as abordagens encontram a mesma direÃ§Ã£o de separaÃ§Ã£o.  $\blacksquare$

**CorolÃ¡rio 2:** A equivalÃªncia entre regressÃ£o linear e LDA em casos especiais simplifica a anÃ¡lise, pois a matriz de indicadores permite obter as projeÃ§Ãµes dos dados nas classes atravÃ©s de uma regressÃ£o linear, e as decisÃµes de classe sÃ£o tomadas com base nas projeÃ§Ãµes. Conforme indicado em [^4.3], esta equivalÃªncia Ã© vÃ¡lida sob as condiÃ§Ãµes de covariÃ¢ncias iguais e classes separÃ¡veis.

Em alguns casos, a **regressÃ£o logÃ­stica** pode fornecer estimativas mais estÃ¡veis das probabilidades, enquanto a **regressÃ£o de indicadores** pode levar a extrapolaÃ§Ãµes fora do intervalo [0,1] [^4.4]. No entanto, a regressÃ£o de indicadores pode ser suficiente e atÃ© vantajosa quando o objetivo principal Ã© a fronteira de decisÃ£o linear [^4.2]. A regressÃ£o linear nÃ£o Ã© um mÃ©todo probabilÃ­stico, e nÃ£o calcula probabilidades. A decisÃ£o de classe vem atravÃ©s de um "argmax".

### MÃ©todos de SeleÃ§Ã£o de VariÃ¡veis e RegularizaÃ§Ã£o em ClassificaÃ§Ã£o

```mermaid
graph LR
    subgraph "RegularizaÃ§Ã£o"
    direction TB
    A["FunÃ§Ã£o de Custo Original"]
    B["RegularizaÃ§Ã£o L1: + Î»âˆ‘|Î²â±¼|"]
    C["RegularizaÃ§Ã£o L2: + Î»âˆ‘Î²â±¼Â²"]
    D["Elastic Net: + Î»â‚âˆ‘|Î²â±¼| + Î»â‚‚âˆ‘Î²â±¼Â²"]
    A --> B
    A --> C
    A --> D
    end
```

A **seleÃ§Ã£o de variÃ¡veis** Ã© crucial para modelos de classificaÃ§Ã£o, principalmente quando se trabalha com dados de alta dimensÃ£o. TÃ©cnicas como a regularizaÃ§Ã£o podem ser usadas para selecionar variÃ¡veis importantes e melhorar a generalizaÃ§Ã£o do modelo. A **regularizaÃ§Ã£o L1** (Lasso) adiciona a norma L1 dos coeficientes Ã  funÃ§Ã£o de custo, induzindo esparsidade no modelo, ou seja, fazendo com que alguns coeficientes sejam exatamente zero [^4.4.4]. Isso seleciona implicitamente as variÃ¡veis mais relevantes. A regularizaÃ§Ã£o L2 (Ridge), por outro lado, adiciona a norma L2 dos coeficientes Ã  funÃ§Ã£o de custo, encolhendo os coeficientes para zero, mas nÃ£o necessariamente tornando-os exatamente zero [^4.5]. Essa tÃ©cnica estabiliza os modelos, reduzindo o problema do *overfitting*. Ambas podem ser combinadas em uma abordagem chamada **Elastic Net** para equilibrar seleÃ§Ã£o de variÃ¡veis e estabilidade [^4.5].

Na regressÃ£o logÃ­stica, por exemplo, a funÃ§Ã£o de custo com regularizaÃ§Ã£o L1 Ã© dada por:

$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda \sum_{j=1}^{p} |\beta_j|
$$

onde $\lambda$ Ã© um hiperparÃ¢metro que controla a intensidade da regularizaÃ§Ã£o [^4.4.4]. O primeiro termo Ã© a verossimilhanÃ§a negativa do modelo, e o segundo termo Ã© a penalidade L1. Na regularizaÃ§Ã£o L2, o termo $\lambda \sum_{j=1}^{p} |\beta_j|$ Ã© substituÃ­do por $\lambda \sum_{j=1}^{p} \beta_j^2$:

$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda \sum_{j=1}^{p} \beta_j^2
$$

E no caso do Elastic Net, a funÃ§Ã£o de custo inclui ambas as penalidades:

$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda_1 \sum_{j=1}^{p} |\beta_j| + \lambda_2 \sum_{j=1}^{p} \beta_j^2
$$

onde $\lambda_1$ e $\lambda_2$ controlam a intensidade das penalidades L1 e L2, respectivamente.

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Vamos considerar um exemplo com regressÃ£o logÃ­stica com 3 preditores ($x_1$, $x_2$, $x_3$), com os seguintes coeficientes estimados sem regularizaÃ§Ã£o:
>
> $\beta = \begin{bmatrix} -0.5 \\ 1.2 \\ -0.8 \end{bmatrix}$
>
> Agora, vamos aplicar regularizaÃ§Ã£o L1 (Lasso) com $\lambda = 0.5$. A funÃ§Ã£o de custo se torna:
>
> $J(\beta) = \text{VerossimilhanÃ§a Negativa} + 0.5(|\beta_1| + |\beta_2| + |\beta_3|)$
>
> ApÃ³s otimizaÃ§Ã£o, os coeficientes podem mudar, por exemplo:
>
> $\beta_{\text{Lasso}} = \begin{bmatrix} 0 \\ 0.9 \\ -0.2 \end{bmatrix}$
>
> Observe que o coeficiente de $x_1$ foi zerado, o que significa que a variÃ¡vel $x_1$ foi removida do modelo. Isso Ã© uma caracterÃ­stica da regularizaÃ§Ã£o L1.
>
> Agora, vamos aplicar regularizaÃ§Ã£o L2 (Ridge) com $\lambda = 0.5$. A funÃ§Ã£o de custo se torna:
>
> $J(\beta) = \text{VerossimilhanÃ§a Negativa} + 0.5(\beta_1^2 + \beta_2^2 + \beta_3^2)$
>
> ApÃ³s otimizaÃ§Ã£o, os coeficientes podem mudar, por exemplo:
>
> $\beta_{\text{Ridge}} = \begin{bmatrix} -0.3 \\ 0.8 \\ -0.5 \end{bmatrix}$
>
> Observe que os coeficientes foram encolhidos em direÃ§Ã£o a zero, mas nenhum se tornou exatamente zero.
>
> Finalmente, vamos aplicar Elastic Net com $\lambda_1 = 0.3$ e $\lambda_2 = 0.2$. A funÃ§Ã£o de custo se torna:
>
> $J(\beta) = \text{VerossimilhanÃ§a Negativa} + 0.3(|\beta_1| + |\beta_2| + |\beta_3|) + 0.2(\beta_1^2 + \beta_2^2 + \beta_3^2)$
>
> ApÃ³s otimizaÃ§Ã£o, os coeficientes podem mudar, por exemplo:
>
> $\beta_{\text{Elastic Net}} = \begin{bmatrix} 0 \\ 0.7 \\ -0.3 \end{bmatrix}$
>
> Aqui, Elastic Net combinou a seleÃ§Ã£o de variÃ¡veis (zerando o coeficiente de $x_1$) com o encolhimento dos coeficientes restantes.

**Lemma 3:** A penalizaÃ§Ã£o L1 na regressÃ£o logÃ­stica leva a coeficientes esparsos devido ao formato da funÃ§Ã£o de penalidade. A norma L1 impÃµe uma penalidade que nÃ£o Ã© diferenciÃ¡vel em zero, levando a soluÃ§Ãµes onde alguns coeficientes sÃ£o exatamente zero [^4.4.4].

**Prova do Lemma 3:** A otimizaÃ§Ã£o da funÃ§Ã£o de custo com penalizaÃ§Ã£o L1 envolve a minimizaÃ§Ã£o da soma da verossimilhanÃ§a negativa com o termo de penalidade. Geometricamente, a penalizaÃ§Ã£o L1 forÃ§a os coeficientes a se concentrarem nos eixos coordenados, resultando em coeficientes nulos para algumas variÃ¡veis. Este comportamento resulta da nÃ£o-diferenciabilidade da norma L1 em zero. Ou seja, a norma L1 possui um "canto" no ponto zero, induzindo a esparsidade nos coeficientes.  $\blacksquare$

**CorolÃ¡rio 3:** A esparsidade induzida pela regularizaÃ§Ã£o L1 facilita a interpretaÃ§Ã£o do modelo, pois as variÃ¡veis com coeficientes zero sÃ£o consideradas irrelevantes para o problema de classificaÃ§Ã£o, selecionando automaticamente as variÃ¡veis mais importantes para a construÃ§Ã£o da fronteira de decisÃ£o [^4.4.5].

> âš ï¸ **Ponto Crucial**: A escolha entre L1 e L2 (ou Elastic Net) depende do problema. L1 Ã© preferÃ­vel para seleÃ§Ã£o de variÃ¡veis, enquanto L2 ajuda na estabilidade e reduÃ§Ã£o do overfitting. A combinaÃ§Ã£o Elastic Net pode aproveitar vantagens de ambos os tipos de regularizaÃ§Ã£o [^4.5]. Elastic Net Ã© preferÃ­vel a Lasso quando o nÃºmero de preditores Ã© muito alto e hÃ¡ multicolinearidade.

### Separating Hyperplanes e Perceptrons

A **separating hyperplane** Ã© uma superfÃ­cie linear que divide o espaÃ§o de caracterÃ­sticas em regiÃµes correspondentes a diferentes classes. O objetivo Ã© encontrar um hiperplano que maximize a distÃ¢ncia entre as classes, conhecida como margem. Seja um conjunto de dados $(x_i, y_i)$, onde $x_i \in \mathbb{R}^p$ sÃ£o os preditores e $y_i \in \{-1, 1\}$ sÃ£o os rÃ³tulos das classes. O hiperplano Ã© definido pela equaÃ§Ã£o:

$$
w^T x + b = 0
$$

Onde $w \in \mathbb{R}^p$ Ã© o vetor normal ao hiperplano e $b \in \mathbb{R}$ Ã© o viÃ©s.  Para uma classificaÃ§Ã£o binÃ¡ria, o objetivo Ã© encontrar $w$ e $b$ de forma que:

$$
w^T x_i + b > 0 \text{, se } y_i = 1
$$
$$
w^T x_i + b < 0 \text{, se } y_i = -1
$$

O hiperplano Ã³timo Ã© aquele que maximiza a distÃ¢ncia entre o hiperplano e as observaÃ§Ãµes mais prÃ³ximas, conhecidas como pontos de suporte. A distÃ¢ncia (margem) Ã© dada por $\frac{2}{||w||}$. O problema de otimizaÃ§Ã£o pode ser formulado como:

$$
\text{minimizar} \frac{1}{2}||w||^2 \\
\text{sujeito a } y_i(w^T x_i + b) \geq 1, \forall i
$$

A soluÃ§Ã£o para este problema Ã© dada por:

$$
w = \sum_{i=1}^{N} \alpha_i y_i x_i
$$

onde $\alpha_i$ sÃ£o os multiplicadores de Lagrange. Os pontos de suporte sÃ£o os $x_i$ para os quais $\alpha_i > 0$. A soluÃ§Ã£o emerge a partir de combinaÃ§Ãµes lineares dos pontos de suporte, conforme discutido em [^4.5.2].

```mermaid
graph LR
    subgraph "Hiperplano Separador"
        direction TB
        A["Hiperplano: wáµ€x + b = 0"]
        B["ClassificaÃ§Ã£o: wáµ€xáµ¢ + b > 0 se yáµ¢ = 1, wáµ€xáµ¢ + b < 0 se yáµ¢ = -1"]
        C["DistÃ¢ncia (Margem): 2/||w||"]
        D["OtimizaÃ§Ã£o: Minimizar ||w||Â²/2 sujeito a yáµ¢(wáµ€xáµ¢ + b) â‰¥ 1"]
        E["SoluÃ§Ã£o: w = âˆ‘Î±áµ¢yáµ¢xáµ¢"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

O **Perceptron de Rosenblatt** Ã© um algoritmo de aprendizado de mÃ¡quina para classificaÃ§Ã£o linear, cujo objetivo Ã© encontrar um hiperplano que separe os dados em diferentes classes [^4.5.1]. O algoritmo ajusta iterativamente os pesos do hiperplano com base em classificaÃ§Ãµes errÃ´neas. Seja um conjunto de dados $(x_i, y_i)$, onde $x_i \in \mathbb{R}^p$ sÃ£o os preditores e $y_i \in \{-1, 1\}$ sÃ£o os rÃ³tulos das classes.  A prediÃ§Ã£o do perceptron Ã©:

$$
\hat{y} = \text{sign}(w^T x + b)
$$
Inicializando com valores arbitrÃ¡rios para $w$ e $b$, o algoritmo do Perceptron atualiza os parÃ¢metros da seguinte forma:
1.  Se $y_i(w^T x_i + b) \leq 0$ (classificaÃ§Ã£o errada):
   $$
   w_{t+1} = w_t + \eta y_i x_i
   $$
   $$
   b_{t+1} = b_t + \eta y_i
   $$
    onde $\eta$ Ã© a taxa de aprendizado e $t$ Ã© o nÃºmero da iteraÃ§Ã£o.
2. Se a classificaÃ§Ã£o estiver correta, os parÃ¢metros nÃ£o sÃ£o atualizados.

A convergÃªncia do Perceptron depende da **separabilidade linear** dos dados. Se as classes sÃ£o linearmente separÃ¡veis, o algoritmo converge em um nÃºmero finito de iteraÃ§Ãµes para uma soluÃ§Ã£o que separa as classes [^4.5.1]. No entanto, se os dados nÃ£o sÃ£o linearmente separÃ¡veis, o algoritmo pode nÃ£o convergir.

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Vamos considerar um conjunto de dados com 3 observaÃ§Ãµes e 2 preditores, com rÃ³tulos $y_i \in \{-1, 1\}$:
>
> - $x_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$, $y_1 = 1$
> - $x_2 = \begin{bmatrix} 2 \\ 0 \