## T√≠tulo: Modelos Aditivos Generalizados, √Årvores e M√©todos Relacionados

```mermaid
flowchart TD
    subgraph "Supervised Learning Methods"
        A["Data Complexity"] --> B["Generalized Additive Models (GAMs)"]
        A --> C["Decision Trees"]
        A --> D["Multivariate Adaptive Regression Splines (MARS)"]
        A --> E["Patient Rule Induction Method (PRIM)"]
        A --> F["Hierarchical Mixture of Experts (HME)"]
    end
```

### Introdu√ß√£o

Este cap√≠tulo explora m√©todos espec√≠ficos de aprendizado supervisionado que modelam a fun√ß√£o de regress√£o subjacente de forma estruturada para mitigar a maldi√ß√£o da dimensionalidade [^9.1]. Cada t√©cnica oferece uma abordagem distinta para lidar com a complexidade dos dados e suas poss√≠veis n√£o linearidades, apresentando um *trade-off* entre flexibilidade e risco de erro de especifica√ß√£o [^9.1]. Iniciando a discuss√£o a partir do ponto onde os cap√≠tulos 3-6 finalizaram, examinamos cinco m√©todos fundamentais: Modelos Aditivos Generalizados (GAMs), √°rvores de decis√£o, Multivariate Adaptive Regression Splines (MARS), o m√©todo de indu√ß√£o de regras de pacientes (PRIM), e Misturas Hier√°rquicas de Especialistas (HME) [^9.1]. O objetivo principal √© fornecer uma compreens√£o aprofundada das abordagens estat√≠sticas e de aprendizado de m√°quina que s√£o utilizadas para modelar e analisar dados complexos, com foco em sua formula√ß√£o matem√°tica e fundamentos te√≥ricos.

### Conceitos Fundamentais

**Conceito 1: O Problema de Classifica√ß√£o e Modelos Lineares**

O problema de classifica√ß√£o consiste em atribuir uma observa√ß√£o a uma de v√°rias classes com base em suas caracter√≠sticas. Em sua forma mais b√°sica, um modelo linear busca modelar a rela√ß√£o entre as vari√°veis preditoras ($X$) e a resposta ($Y$) como:

$$
Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \ldots + \beta_pX_p + \epsilon
$$

onde $\beta_i$ s√£o os coeficientes que quantificam a influ√™ncia de cada preditor $X_i$ na resposta, e $\epsilon$ √© o termo de erro, geralmente assumido como tendo uma distribui√ß√£o normal com m√©dia zero. No contexto de classifica√ß√£o, podemos usar a matriz de indicadores para modelar a vari√°vel resposta, onde cada coluna representa uma classe e cada linha representa uma observa√ß√£o com um "1" na coluna da classe correta e "0" nas outras. A aplica√ß√£o de modelos lineares, como a regress√£o linear com matrizes de indicadores [^4.2], imp√µe uma rela√ß√£o linear entre os preditores e a resposta, o que pode levar a um *bias* significativo se a rela√ß√£o verdadeira for n√£o-linear.

> üí° **Exemplo Num√©rico:**
> Suponha que temos um problema de classifica√ß√£o bin√°ria com dois preditores ($X_1$ e $X_2$) e uma vari√°vel de resposta $Y$ (0 ou 1). Usando um modelo linear, podemos ter a seguinte equa√ß√£o:
>
> $Y = 0.5 + 0.8X_1 - 0.3X_2 + \epsilon$
>
>  Aqui, $\beta_0 = 0.5$, $\beta_1 = 0.8$, e $\beta_2 = -0.3$. Se tivermos uma observa√ß√£o com $X_1 = 1$ e $X_2 = 2$, a previs√£o seria:
>
>  $Y = 0.5 + 0.8(1) - 0.3(2) = 0.5 + 0.8 - 0.6 = 0.7$.
>
>  Se usarmos um limiar de 0.5, classificar√≠amos essa observa√ß√£o como pertencente √† classe 1. Este modelo assume que o efeito de $X_1$ e $X_2$ em $Y$ √© linear, o que pode n√£o ser verdade na realidade.

**Lemma 1:** *Seja $f(x)$ a fun√ß√£o de classifica√ß√£o verdadeira, uma aproxima√ß√£o linear $g(x) = w^Tx + b$ pode ser vista como uma proje√ß√£o de $x$ em um espa√ßo de menor dimens√£o definido pelo vetor $w$, onde a decis√£o de classe √© determinada pelo sinal de $g(x)$. Em condi√ß√µes espec√≠ficas, essa proje√ß√£o √© equivalente √†quela encontrada em LDA.* Este lemma enfatiza que, apesar de sua simplicidade, a modelagem linear pode ser vista como uma proje√ß√£o de dados em um espa√ßo adequado, onde as decis√µes de classe s√£o tomadas, conforme demonstrado em [^4.3].

**Conceito 2: Linear Discriminant Analysis (LDA)**

LDA busca encontrar a melhor combina√ß√£o linear de preditores para separar diferentes classes [^4.3]. Para duas classes, a fun√ß√£o discriminante linear da LDA √© dada por:

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log(\pi_k)
$$

onde $x$ √© o vetor de preditores, $\mu_k$ √© a m√©dia da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum, e $\pi_k$ √© a probabilidade a priori da classe $k$.  As decis√µes de classe s√£o tomadas baseadas no maior valor da fun√ß√£o discriminante $\delta_k(x)$. LDA assume que as classes seguem distribui√ß√µes normais multivariadas com covari√¢ncias iguais [^4.3.1], ou seja, $\Sigma_k = \Sigma$, o que simplifica o c√°lculo da fronteira de decis√£o. O classificador LDA busca projetar os dados em um subespa√ßo de menor dimens√£o que maximize a separabilidade entre classes.

```mermaid
graph LR
    subgraph "LDA Discriminant Function"
        direction LR
        A["Input Vector: x"]
        B["Class Mean: Œº_k"]
        C["Covariance Matrix: Œ£"]
        D["Prior Probability: œÄ_k"]
        E["Inverse of Œ£: Œ£‚Åª¬π"]
        F["x·µÄŒ£‚Åª¬πŒº_k"]
        G["¬ΩŒº_k·µÄŒ£‚Åª¬πŒº_k"]
        H["log(œÄ_k)"]
        I["Œ¥_k(x) = x·µÄŒ£‚Åª¬πŒº_k - ¬ΩŒº_k·µÄŒ£‚Åª¬πŒº_k + log(œÄ_k)"]
        A --> F
        B --> G
        C --> E
        E --> F
        E --> G
        D --> H
        F & G & H --> I
    end
```

> üí° **Exemplo Num√©rico:**
> Vamos considerar duas classes com as seguintes caracter√≠sticas:
>
> Classe 1: $\mu_1 = \begin{bmatrix} 1 \\ 2 \end{bmatrix}$, $\pi_1 = 0.6$
> Classe 2: $\mu_2 = \begin{bmatrix} 3 \\ 1 \end{bmatrix}$, $\pi_2 = 0.4$
> Matriz de covari√¢ncia comum: $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
>
> Um ponto de dados $x = \begin{bmatrix} 2 \\ 1.5 \end{bmatrix}$.
>
> **C√°lculo de $\Sigma^{-1}$:**
> $\Sigma^{-1} = \frac{1}{1*1 - 0.5*0.5} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \frac{1}{0.75} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix}$
>
> **C√°lculo de $\delta_1(x)$:**
>
> $\delta_1(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 2 \end{bmatrix} \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} + \log(0.6)$
>
> $\delta_1(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 0 \\ 2 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 2 \end{bmatrix} \begin{bmatrix} -4/3 \\ 2 \end{bmatrix} + \log(0.6)$
>
> $\delta_1(x) = 3  - \frac{1}{2} (8/3) + \log(0.6) = 3 - 4/3 -0.51 = 1.82$
>
> **C√°lculo de $\delta_2(x)$:**
>
> $\delta_2(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix} \begin{bmatrix} 3 \\ 1 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 1 \end{bmatrix} \begin{bmatrix} 4/3 & -2/3 \\ -2/3 & 4/3 \end{bmatrix} \begin{bmatrix} 3 \\ 1 \end{bmatrix} + \log(0.4)$
>
> $\delta_2(x) = \begin{bmatrix} 2 & 1.5 \end{bmatrix} \begin{bmatrix} 10/3 \\ -2/3 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 1 \end{bmatrix} \begin{bmatrix} 10/3 \\ -2/3 \end{bmatrix} + \log(0.4)$
>
> $\delta_2(x) = 17/3 - \frac{1}{2} (28/3) + \log(0.4) = 17/3 - 14/3 -0.92 = -0.92$
>
> Como $\delta_1(x) > \delta_2(x)$, o ponto $x$ seria classificado como pertencente √† Classe 1.

**Corol√°rio 1:** *A fun√ß√£o discriminante linear da LDA, quando as covari√¢ncias das classes s√£o iguais, pode ser interpretada como uma proje√ß√£o dos dados em uma dire√ß√£o que maximiza a dist√¢ncia entre as m√©dias das classes, ou seja, a proje√ß√£o √© realizada na dire√ß√£o $w = \Sigma^{-1}(\mu_1 - \mu_2)$, onde $1$ e $2$ representam as duas classes.* [^4.3.1]

**Conceito 3: Regress√£o Log√≠stica**

A regress√£o log√≠stica modela a probabilidade de uma vari√°vel bin√°ria $Y$ como uma fun√ß√£o linear dos preditores $X$. Utiliza a fun√ß√£o *logit* para transformar probabilidades em um intervalo de $-\infty$ a $+\infty$, o que permite modelar a probabilidade usando uma combina√ß√£o linear dos preditores:

$$
\text{logit}(p(X)) = \log \left( \frac{p(X)}{1-p(X)} \right) = \beta_0 + \beta_1 X_1 + \ldots + \beta_p X_p
$$

onde $p(X) = P(Y=1|X)$. A probabilidade √© dada por:

$$
p(X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \ldots + \beta_p X_p)}}
$$

Os coeficientes $\beta_i$ s√£o estimados maximizando a verossimilhan√ßa dos dados. O processo de otimiza√ß√£o geralmente envolve o m√©todo de Newton-Raphson [^4.4.2] ou outras t√©cnicas de otimiza√ß√£o num√©rica. A fun√ß√£o de verossimilhan√ßa para regress√£o log√≠stica √© dada por:

$$
L(\beta) = \prod_{i=1}^N p(x_i)^{y_i}(1-p(x_i))^{1-y_i}
$$

e a *log-likelihood* correspondente √©:

$$
\log(L(\beta)) = \sum_{i=1}^N [y_i\log(p(x_i)) + (1-y_i)\log(1-p(x_i))]
$$

```mermaid
graph LR
    subgraph "Logistic Regression Components"
        direction LR
        A["Predictors: X"]
        B["Coefficients: Œ≤"]
        C["Linear Combination: Œ≤‚ÇÄ + Œ≤‚ÇÅX‚ÇÅ + ... + Œ≤‚ÇöX‚Çö"]
        D["Logit Function: log(p(X) / (1-p(X)))"]
        E["Probability p(X) = 1 / (1 + exp(-C))"]
        F["Log-Likelihood: ‚àë [y·µ¢log(p(x·µ¢)) + (1-y·µ¢)log(1-p(x·µ¢))]"]
        A --> C
        B --> C
        C --> D
        D --> E
        E --> F
    end
```

> üí° **Exemplo Num√©rico:**
> Suponha que temos um modelo de regress√£o log√≠stica com um √∫nico preditor $X$:
>
> $\text{logit}(p(X)) = -2 + 1.5X$
>
>  Se $X = 1$, ent√£o:
>
>  $\text{logit}(p(X)) = -2 + 1.5(1) = -0.5$
>
>  Para obter a probabilidade $p(X)$, usamos a fun√ß√£o log√≠stica inversa:
>
>  $p(X) = \frac{1}{1 + e^{-(-0.5)}} = \frac{1}{1 + e^{0.5}} \approx \frac{1}{1 + 1.6487} \approx 0.378$
>
>  Isso significa que para $X = 1$, a probabilidade de $Y=1$ √© aproximadamente 0.378.
>
>  Se $X = 2$, ent√£o:
>
> $\text{logit}(p(X)) = -2 + 1.5(2) = 1$
>
> $p(X) = \frac{1}{1 + e^{-1}} \approx \frac{1}{1 + 0.3679} \approx 0.731$
>
>  A probabilidade de $Y=1$ aumenta para aproximadamente 0.731 quando $X=2$.

> ‚ö†Ô∏è **Nota Importante**: A fun√ß√£o *logit* transforma a probabilidade em log-odds, o que permite modelar a probabilidade usando uma fun√ß√£o linear. [^4.4.1]

> ‚ùó **Ponto de Aten√ß√£o**: A regress√£o log√≠stica, assim como outros modelos, pode ser afetada por classes n√£o balanceadas. A corre√ß√£o desse problema envolve o ajuste dos pesos da fun√ß√£o de custo ou o rebalanceamento dos dados [^4.4.2].

> ‚úîÔ∏è **Destaque**: Em cen√°rios onde a separa√ß√£o entre as classes √© clara, os par√¢metros estimados na regress√£o log√≠stica podem se aproximar daqueles obtidos pela LDA, embora ambos os modelos sejam derivados de princ√≠pios diferentes [^4.5].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
flowchart TD
  subgraph "Indicator Regression for Classification"
    A["Classes encoded in indicator matrix Y (NxK)"] --> B["Estimate coefficients Œ≤ÃÇ = (X·µÄX)‚Åª¬πX·µÄY via Least Squares"]
    B --> C["Obtain predictions YÃÇ = XŒ≤ÃÇ"]
    C --> D["Decision Rule: Classify x·µ¢ in class argmax‚Çñ YÃÇ·µ¢‚Çñ"]
    D --> E["Comparison with Probabilistic Models (LDA, Logistic)"]
  end
```

**Explica√ß√£o:** Este diagrama representa o fluxo do processo de regress√£o de indicadores e como ele se relaciona √† classifica√ß√£o, conforme descrito nos t√≥picos [^4.2] e [^4.1].

A regress√£o linear pode ser usada para classifica√ß√£o codificando as classes em uma matriz de indicadores. A matriz de indicadores $Y$ √© uma matriz $N \times K$, onde $N$ √© o n√∫mero de observa√ß√µes e $K$ √© o n√∫mero de classes, com $y_{ik} = 1$ se a i-√©sima observa√ß√£o pertence √† classe $k$, e $y_{ik} = 0$ caso contr√°rio. O objetivo √© encontrar os coeficientes $\beta$ que minimizam a soma dos erros quadr√°ticos:

$$
\min_\beta ||Y - X\beta||^2
$$

A solu√ß√£o para este problema √© dada por:

$$
\hat{\beta} = (X^T X)^{-1} X^T Y
$$

As previs√µes de classe s√£o obtidas calculando $\hat{Y} = X\hat{\beta}$, e cada observa√ß√£o $x_i$ √© classificada na classe $k$ que maximiza o valor predito $\hat{y}_{ik}$.  As limita√ß√µes dessa abordagem incluem a incapacidade de modelar n√£o-linearidades, bem como a possibilidade de produzir valores preditos fora do intervalo [0,1], uma vez que a regress√£o linear n√£o imp√µe restri√ß√µes aos valores preditos. O "masking problem" surge quando a covari√¢ncia entre as classes leva a uma classifica√ß√£o sub√≥tima, pois a regress√£o linear n√£o leva em considera√ß√£o as rela√ß√µes entre as classes.

> üí° **Exemplo Num√©rico:**
> Suponha que temos 3 observa√ß√µes e 2 classes. A matriz de indicadores $Y$ e a matriz de preditores $X$ s√£o:
>
> $Y = \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix}$
>
> $X = \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \end{bmatrix}$
>
> Primeiro, calculamos $X^T X$:
>
> $X^T X = \begin{bmatrix} 1 & 2 & 3 \\ 2 & 1 & 3 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \end{bmatrix} = \begin{bmatrix} 14 & 13 \\ 13 & 14 \end{bmatrix}$
>
> Calculamos o inverso de $X^T X$:
>
> $(X^T X)^{-1} = \frac{1}{14*14 - 13*13} \begin{bmatrix} 14 & -13 \\ -13 & 14 \end{bmatrix} = \begin{bmatrix} 14/27 & -13/27 \\ -13/27 & 14/27 \end{bmatrix}$
>
> Calculamos $X^T Y$:
>
> $X^T Y = \begin{bmatrix} 1 & 2 & 3 \\ 2 & 1 & 3 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix} = \begin{bmatrix} 4 & 2 \\ 5 & 1 \end{bmatrix}$
>
> Calculamos $\hat{\beta}$:
>
> $\hat{\beta} = (X^T X)^{-1} X^T Y = \begin{bmatrix} 14/27 & -13/27 \\ -13/27 & 14/27 \end{bmatrix} \begin{bmatrix} 4 & 2 \\ 5 & 1 \end{bmatrix} = \begin{bmatrix} -9/27 & 15/27 \\ 18/27 & -12/27 \end{bmatrix} = \begin{bmatrix} -1/3 & 5/9 \\ 2/3 & -4/9 \end{bmatrix}$
>
> Agora podemos calcular as previs√µes $\hat{Y}$:
>
> $\hat{Y} = X\hat{\beta} = \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \end{bmatrix} \begin{bmatrix} -1/3 & 5/9 \\ 2/3 & -4/9 \end{bmatrix} = \begin{bmatrix} 1 & -1/3 \\ 0 & 6/9 \\ 1 & 1/9 \end{bmatrix}$
>
> Classificamos a observa√ß√£o $i$ na classe $k$ que maximiza $\hat{y}_{ik}$. Por exemplo, a primeira observa√ß√£o √© classificada na classe 1 porque $\hat{y}_{11} = 1 > \hat{y}_{12} = -1/3$.

**Lemma 2:** *Em um cen√°rio linearmente separ√°vel, onde as classes podem ser separadas por hiperplanos, as proje√ß√µes nos hiperplanos de decis√£o gerados pela regress√£o linear podem ser, em certas condi√ß√µes, equivalentes √†s proje√ß√µes geradas por outros m√©todos lineares, como discriminantes lineares. O problema de "masking" pode ocorrer quando as covari√¢ncias entre as classes causam confus√£o nas proje√ß√µes* [^4.2].

**Corol√°rio 2:** *A equival√™ncia entre regress√£o linear de indicadores e discriminantes lineares implica que, em problemas com alta separabilidade, a regress√£o linear pode ser utilizada como alternativa computacionalmente mais eficiente, desde que os efeitos do "masking" sejam pequenos.* [^4.3]

Comparando com a regress√£o log√≠stica [^4.4], a regress√£o linear de indicadores pode ser menos adequada para gerar estimativas precisas de probabilidade. No entanto, sua simplicidade e efici√™ncia podem ser vantajosas quando o objetivo principal √© obter uma fronteira de decis√£o linear. A regress√£o log√≠stica utiliza a fun√ß√£o sigmoide para for√ßar os valores preditos a ficarem no intervalo [0,1], ao passo que a regress√£o de indicadores n√£o imp√µe essa restri√ß√£o [^4.4].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["Log-Likelihood: log(L(Œ≤))"]
        subgraph "L1 (LASSO) Penalty"
           B["Œª‚àë|Œ≤‚±º|"]
        end
        subgraph "L2 (Ridge) Penalty"
           C["Œª‚àëŒ≤‚±º¬≤"]
        end
        subgraph "Elastic Net Penalty"
          D["Œª‚ÇÅ‚àë|Œ≤‚±º| + Œª‚ÇÇ‚àëŒ≤‚±º¬≤"]
        end
        A --> B
        A --> C
        A --> D
    end
```

A sele√ß√£o de vari√°veis e regulariza√ß√£o s√£o t√©cnicas cruciais para evitar overfitting, melhorar a generaliza√ß√£o e a interpretabilidade dos modelos de classifica√ß√£o [^4.5]. Em regress√£o log√≠stica, a regulariza√ß√£o pode ser aplicada atrav√©s da adi√ß√£o de termos de penaliza√ß√£o √† fun√ß√£o de custo. A penaliza√ß√£o L1 (LASSO) adiciona um termo proporcional ao valor absoluto dos coeficientes:

$$
\log(L(\beta))  - \lambda \sum_{j=1}^p |\beta_j|
$$

onde $\lambda$ √© o par√¢metro de regulariza√ß√£o e $\beta_j$ s√£o os coeficientes dos preditores. Esta penaliza√ß√£o tende a zerar alguns coeficientes, promovendo a esparsidade do modelo [^4.5.1]. A penaliza√ß√£o L2 (Ridge) adiciona um termo proporcional ao quadrado dos coeficientes:

$$
\log(L(\beta))  - \lambda \sum_{j=1}^p \beta_j^2
$$

Esta penaliza√ß√£o reduz a magnitude dos coeficientes, melhorando a estabilidade do modelo [^4.5.2]. A regulariza√ß√£o Elastic Net combina ambas as penaliza√ß√µes L1 e L2:

$$
\log(L(\beta))  - \lambda_1 \sum_{j=1}^p |\beta_j| - \lambda_2 \sum_{j=1}^p \beta_j^2
$$

onde $\lambda_1$ e $\lambda_2$ controlam a intensidade das penalidades L1 e L2, respectivamente [^4.5].

> üí° **Exemplo Num√©rico:**
> Vamos considerar um modelo de regress√£o log√≠stica com dois preditores $X_1$ e $X_2$. A fun√ß√£o de log-verossimilhan√ßa sem regulariza√ß√£o √© $\log(L(\beta))$.
>
> **Penaliza√ß√£o L1 (LASSO):**
>
> Suponha que $\lambda = 0.5$ e os coeficientes estimados s√£o $\beta_1 = 1.2$ e $\beta_2 = -0.8$. A fun√ß√£o de custo com penaliza√ß√£o L1 seria:
>
> $\log(L(\beta)) - 0.5(|1.2| + |-0.8|) = \log(L(\beta)) - 0.5(1.2 + 0.8) = \log(L(\beta)) - 1$.
>
> A penalidade reduz o valor da fun√ß√£o de log-verossimilhan√ßa.
>
> **Penaliza√ß√£o L2 (Ridge):**
>
> Suponha que $\lambda = 0.5$ e os mesmos coeficientes estimados. A fun√ß√£o de custo com penaliza√ß√£o L2 seria:
>
> $\log(L(\beta)) - 0.5(1.2^2 + (-0.8)^2) = \log(L(\beta)) - 0.5(1.44 + 0.64) = \log(L(\beta)) - 1.04$.
>
> A penalidade L2 tamb√©m reduz o valor da fun√ß√£o de log-verossimilhan√ßa, mas de maneira diferente.
>
> **Penaliza√ß√£o Elastic Net:**
>
> Suponha que $\lambda_1 = 0.3$, $\lambda_2 = 0.2$ e os mesmos coeficientes. A fun√ß√£o de custo com Elastic Net seria:
>
> $\log(L(\beta)) - 0.3(|1.2| + |-0.8|) - 0.2(1.2^2 + (-0.8)^2) = \log(L(\beta)) - 0.3(2) - 0.2(2.08) = \log(L(\beta)) - 0.6 - 0.416 = \log(L(\beta)) - 1.016$.
>
>  O Elastic Net combina as duas penalidades, proporcionando um efeito combinado.

**Lemma 3:** *A penaliza√ß√£o L1 na regress√£o log√≠stica leva a coeficientes esparsos devido √† sua natureza que promove a sele√ß√£o de um subconjunto de vari√°veis preditoras mais importantes. A fun√ß√£o de valor absoluto n√£o √© diferenci√°vel na origem, o que leva alguns coeficientes a serem exatamente zero quando a fun√ß√£o de custo √© minimizada. A regulariza√ß√£o L1 √© usada para a sele√ß√£o de vari√°veis.* [^4.4.4]

**Prova do Lemma 3:** Ao minimizar a fun√ß√£o de custo com a penaliza√ß√£o L1, a adi√ß√£o do termo $\lambda \sum_{j=1}^p |\beta_j|$ faz com que os coeficientes menos relevantes sejam levados a zero, j√° que a derivada da fun√ß√£o de valor absoluto n√£o est√° definida na origem e causa uma for√ßa que leva alguns coeficientes a serem exatamente zero quando a fun√ß√£o de custo √© minimizada. $\blacksquare$

**Corol√°rio 3:** *A esparsidade induzida pela penaliza√ß√£o L1, al√©m de simplificar o modelo e evitar overfitting, auxilia na interpreta√ß√£o dos resultados, uma vez que apenas os preditores mais relevantes s√£o considerados. Esta caracter√≠stica √© vantajosa em problemas com muitos preditores onde se busca identificar as vari√°veis mais influentes* [^4.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: A penaliza√ß√£o L1 (LASSO) √© mais adequada para a sele√ß√£o de vari√°veis, enquanto a penaliza√ß√£o L2 (Ridge) √© mais adequada para aumentar a estabilidade do modelo. A combina√ß√£o das duas, como no Elastic Net, permite um ajuste fino da regulariza√ß√£o [^4.5].

### Separating Hyperplanes e Perceptrons

```mermaid
graph LR
    subgraph "Separating Hyperplanes"
        direction LR
        A["Feature Space"]
        B["Hyperplane: w·µÄx + b = 0"]
        C["Class 1"]
        D["Class 2"]
        E["Margin"]
        A --> B
        B --> C
        B --> D
       B --> E
        style B fill:#f9f,stroke:#333,stroke-width:2px
    end
```

A ideia de hiperplanos separadores busca encontrar um hiperplano que divide o espa√ßo de caracter√≠sticas em regi√µes distintas, de modo que cada regi√£o corresponda a uma classe. A separa√ß√£o √≥tima √© alcan√ßada quando o hiperplano maximiza a margem entre as classes, o que leva a um classificador mais robusto. O hiperplano √© definido pela equa√ß√£o:

$$
w^Tx + b = 0
$$

onde $w$ √© o vetor normal ao hiperplano, $x$ √© o vetor de preditores, e $b$ √© o vi√©s (bias). A margem de separa√ß√£o √© dada pela dist√¢ncia entre os pontos mais pr√≥ximos de cada classe ao hiperplano.  A formula√ß√£o matem√°tica deste problema de otimiza√ß√£o pode ser expressa como:

$$
\max_{w, b} \frac{1}{||w||}  \text{ sujeito a: } y_i(w^Tx_i + b) \geq 1 \text{ para todos } i
$$

onde $y_i \in \{-1, 1\}$ s√£o os r√≥tulos de classe. Essa otimiza√ß√£o pode ser resolvida atrav√©s do dual de Wolfe, com solu√ß√µes dependentes dos pontos de suporte [^4.5.2].

> üí° **Exemplo Num√©rico:**
> Imagine um problema de classifica√ß√£o bin√°ria em duas dimens√µes, com os pontos de uma classe localizados na regi√£o $x_2 > x_1$ e os da outra classe em $x_2 < x_1$.
>
> Um poss√≠vel hiperplano separador seria dado por $w = \begin{bmatrix} -1 \\ 1 \end{bmatrix}$ e $b = 0$, ou seja, $-x_1 + x_2 = 0$.
>
> Para um ponto $x = \begin{bmatrix} 1 \\ 2 \end{bmatrix}$, temos $-1 + 2 = 1 > 0$, que seria classificado como da primeira classe.
>
> Para um ponto $x = \begin{bmatrix} 2 \\ 1 \end{bmatrix}$, temos $-2 + 1 = -1 < 0$, que seria classificado como da segunda classe.
>
> A margem de separa√ß√£o √© a dist√¢ncia entre os pontos mais pr√≥ximos ao hiperplano, que √© maximizada por uma solu√ß√£o √≥tima.

O Perceptron √© um algoritmo iterativo que busca encontrar um hiperplano separador para dados linearmente separ√°veis. O algoritmo come√ßa com um hiperplano inicial e atualiza os pesos $w$ e o vi√©s $b$ baseando-se nas classifica√ß√µes incorretas:

$$
w \leftarrow w + \eta y_i x_i
$$
$$
b \leftarrow b + \eta y_i
$$

onde $\eta$ √© a taxa de aprendizado. Sob a hip√≥tese de dados linearmente separ√°veis, o Perceptron converge para uma solu√ß√£o que separa as classes corretamente, como descrito em [^4.5.1].

```mermaid
graph TD
  subgraph "Perceptron Algorithm"
    A["Initialize weights w and bias b"] --> B{"For each misclassified data point (x·µ¢, y·µ¢)"}
    B --> C["Update weights w ‚Üê w + Œ∑y·µ¢x·µ¢"]
    B --> D["Update bias b ‚Üê b + Œ∑y·µ¢"]
    C & D --> E{"Iterate until convergence"}
  end
```

> üí° **Exemplo Num√©rico:**
> Suponha que temos um conjunto de dados com duas classes, onde $y_i \in \{-1, 1\}$. Inicializamos $w = \begin{bmatrix} 0 \\ 0 \end{bmatrix}$ e $b = 0$, e a taxa de aprendizado $\eta = 0.1$.
>
> 1.  Primeira observa√ß√£o: $x_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$, $y_1 = 1$.  A previs√£o inicial √© $w^Tx_1 + b = 0$.  Como a previs√£o √© incorreta $(0 < 1)$, atualizamos os pesos:
>
> $w \leftarrow \begin{bmatrix} 0 \\ 0 \end{bmatrix} + 0.1 * 1 * \begin{bmatrix} 1 \\ 1 \end{bmatrix} = \begin{bmatrix} 0.1 \\ 0.1 \end{bmatrix}$
>
> $b \leftarrow 0 + 0.1 * 1 = 0.1$
>
> 2.  Segunda observa√ß√£o: $x_2 = \begin{bmatrix} 2 \\ -1 \end{bmatrix}$, $y_2 = -1$. A previs√£o √© $w^Tx_2 + b = 0.1 * 2 + 0.1 * -1 + 0.1 = 0.2$. Como a previs√£o √© incorreta $(0.2 > -1)$, atualizamos os pesos:
>
> $w \leftarrow \begin{bmatrix} 0.1 \\ 0.1 \end{bmatrix} + 0.1 * -1 * \begin{bmatrix} 2 \\ -1 \end{bmatrix} = \begin{bmatrix} -0.1 \\ 0.2 \end{bmatrix}$
>
> $b \leftarrow 0.1 + 0.1 * -1 = 0$
>
> Este processo √© repetido at√© que o algoritmo encontre um hiperplano que separe as classes corretamente.

### Pergunta Te√≥rica Avan√ßada: Quais as diferen√ßas fundamentais entre a formula√ß√£o de LDA e a Regra de Decis√£o Bayesiana considerando distribui√ß√µes Gaussianas com covari√¢ncias iguais?

**Resposta:**

Embora a LDA e a Regra de Decis√£o Bayesiana, sob distribui√ß√µes gaussianas com covari√¢ncias iguais, levem a classificadores lineares com fronteiras de decis√£o similares, existem diferen√ßas sutis em suas formula√ß√µes e fundamentos te√≥ricos.

A LDA √© um m√©todo discriminativo que busca projetar os dados em um subespa√ßo de menor dimens√£o que maximize a separabilidade entre as classes. A fun√ß√£o discriminante linear √© dada por:

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log(\pi_k)
$$

onde $\mu_k$ √© a m√©dia da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum e $\pi_k$ √© a probabilidade a priori da classe $k$.  A classifica√ß√£o √© feita atribuindo a observa√ß√£o $x$ √† classe que maximiza a fun√ß√£o discriminante $\delta_k(x)$ [^4.3], [^4.3.2], [^4.3.3].

A Regra de Decis√£o Bayesiana, por outro lado, √© uma abordagem generativa que busca maximizar a probabilidade a posteriori da classe dada a observa√ß√£o:

$$
P(Y = k|x) = \frac{P(x|Y=k) P(Y=k)}{P(x)}
$$

Para distribui√ß√µes