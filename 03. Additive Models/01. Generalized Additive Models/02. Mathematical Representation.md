## T√≠tulo: Modelos Aditivos Generalizados, √Årvores e M√©todos Relacionados para Classifica√ß√£o

```mermaid
graph LR
    A["Dados de Entrada"] --> B{"LDA"};
    A --> C{"Regress√£o Log√≠stica"};
    A --> D{"√Årvores de Decis√£o"};

    B --> E["Regulariza√ß√£o (L1, L2, Elastic Net)"];
    C --> F["Regulariza√ß√£o (L1, L2, Elastic Net)"];
    D --> G["Sele√ß√£o de Vari√°veis"];
    
    E --> H{"Avalia√ß√£o LDA"};
    F --> I{"Avalia√ß√£o Reg. Log√≠stica"};
    G --> J{"Avalia√ß√£o √Årvores Decis√£o"};
    
    H --> K{"Melhor Modelo"};
    I --> K;
    J --> K;
```

### Introdu√ß√£o

Este cap√≠tulo explora m√©todos espec√≠ficos para **aprendizado supervisionado**, cada um assumindo uma forma estruturada diferente para a fun√ß√£o de regress√£o desconhecida, oferecendo solu√ß√µes para a **maldi√ß√£o da dimensionalidade** [^9.1]. √â fundamental entender que existe um *trade-off* entre a complexidade do modelo e o risco de misspecifica√ß√£o. Os m√©todos abordados s√£o extens√µes dos temas apresentados nos cap√≠tulos 3 a 6, incluindo **modelos aditivos generalizados**, **√°rvores de decis√£o**, **splines de regress√£o adaptativa multivariada (MARS)**, o m√©todo de indu√ß√£o de regras do paciente (PRIM) e misturas hier√°rquicas de especialistas (HME). O foco √© entender como esses modelos podem ser aplicados em problemas de classifica√ß√£o.

### Conceitos Fundamentais

**Conceito 1:** O **problema de classifica√ß√£o** busca atribuir uma classe ou categoria a uma dada observa√ß√£o com base em suas caracter√≠sticas. M√©todos lineares, embora simples, podem ser inadequados para modelar rela√ß√µes complexas e n√£o lineares presentes em dados reais [^9.1]. A escolha de um m√©todo linear implica um *trade-off* entre vi√©s e vari√¢ncia. Modelos com muitos par√¢metros podem se ajustar bem aos dados de treinamento, mas podem n√£o generalizar bem para novos dados, um exemplo claro de alta vari√¢ncia. J√° modelos com menos par√¢metros podem apresentar alto vi√©s, n√£o capturando adequadamente a complexidade dos dados. √â crucial entender como a estrutura linear afeta esse balan√ßo, pois pode simplificar demais o problema, levando a solu√ß√µes sub√≥timas, ou o oposto, levando a overfitting.

> üí° **Exemplo Num√©rico:**
> Suponha que temos um conjunto de dados com duas classes (0 e 1) e duas vari√°veis preditoras ($x_1$ e $x_2$). Se usarmos um modelo linear simples, como um classificador linear, podemos obter uma fronteira de decis√£o que separa as classes razoavelmente bem. No entanto, se a rela√ß√£o entre as vari√°veis e a classe for n√£o linear (por exemplo, as classes se distribuem como c√≠rculos conc√™ntricos), o classificador linear ter√° um alto vi√©s, pois n√£o conseguir√° capturar essa rela√ß√£o.
>
> Por outro lado, um modelo muito complexo, como uma √°rvore de decis√£o profunda, pode se ajustar perfeitamente aos dados de treinamento, incluindo o ru√≠do, resultando em baixa vari√¢ncia nos dados de treinamento, mas alta vari√¢ncia em novos dados. Isso significa que o modelo se ajustar√° bem aos dados de treinamento, mas ter√° um desempenho ruim em dados n√£o vistos. A escolha do m√©todo correto envolve encontrar o equil√≠brio certo entre vi√©s e vari√¢ncia.

**Lemma 1:** Dado um conjunto de dados de classifica√ß√£o, a **regress√£o linear da matriz indicadora** pode ser vista como uma aproxima√ß√£o para a constru√ß√£o de **fun√ß√µes discriminantes lineares**, com coeficientes estimados por m√≠nimos quadrados. Em cen√°rios onde as classes s√£o bem separadas, esta aproxima√ß√£o pode gerar resultados compar√°veis ao LDA.

Seja $X$ a matriz de preditores de dimens√µes $N \times p$, onde $N$ √© o n√∫mero de observa√ß√µes e $p$ o n√∫mero de preditores. A matriz de indicadores $Y$ possui dimens√µes $N \times K$, onde $K$ √© o n√∫mero de classes, com cada linha da forma $[0, \ldots, 1, \ldots, 0]$, com o '1' na coluna que corresponde √† classe da observa√ß√£o. O modelo de regress√£o linear para a matriz indicadora √©:

$$
\hat{Y} = XB
$$

Onde $\hat{Y}$ √© a matriz de indicadores de classe estimada, $X$ √© a matriz de preditores, e $B$ s√£o os coeficientes estimados por m√≠nimos quadrados. A solu√ß√£o para $B$ √© dada por:

$$
\hat{B} = (X^T X)^{-1} X^T Y
$$
```mermaid
graph LR
    subgraph "Regress√£o Linear da Matriz Indicadora"
    direction TB
        A["Matriz de Preditores X (N x p)"]
        B["Matriz de Indicadores Y (N x K)"]
        C["Coeficientes Estimados B (p x K)"]
        D["Regress√£o Linear:  YÃÇ = XB"]
        E["Solu√ß√£o via M√≠nimos Quadrados: BÃÇ = (X·µÄX)‚Åª¬πX·µÄY"]
        A --> D
        B --> D
        D --> E
    end
```

Ao projetar os dados no espa√ßo gerado pelas colunas de $B$, os pontos de diferentes classes se agrupam linearmente. A matriz $B$ pode ser utilizada para definir os **hiperplanos de decis√£o**. A previs√£o para uma nova observa√ß√£o $x$ √© feita calculando $x^T \hat{B}$ e atribuindo a observa√ß√£o √† classe com a maior entrada neste vetor.

> üí° **Exemplo Num√©rico:**
> Suponha que temos 3 observa√ß√µes e 2 classes, com os seguintes dados:
>
> $X = \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \end{bmatrix}$ e $Y = \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix}$.
>
> **Passo 1: Calcular $X^T X$**
>
> $X^T X = \begin{bmatrix} 1 & 2 & 3 \\ 2 & 1 & 3 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 2 & 1 \\ 3 & 3 \end{bmatrix} = \begin{bmatrix} 14 & 13 \\ 13 & 14 \end{bmatrix}$
>
> **Passo 2: Calcular $(X^T X)^{-1}$**
>
> $(X^T X)^{-1} = \frac{1}{14^2 - 13^2} \begin{bmatrix} 14 & -13 \\ -13 & 14 \end{bmatrix} = \frac{1}{27} \begin{bmatrix} 14 & -13 \\ -13 & 14 \end{bmatrix} \approx \begin{bmatrix} 0.518 & -0.481 \\ -0.481 & 0.518 \end{bmatrix}$
>
> **Passo 3: Calcular $X^T Y$**
>
> $X^T Y = \begin{bmatrix} 1 & 2 & 3 \\ 2 & 1 & 3 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 0 \end{bmatrix} = \begin{bmatrix} 4 & 2 \\ 5 & 1 \end{bmatrix}$
>
> **Passo 4: Calcular $\hat{B}$**
>
> $\hat{B} = (X^T X)^{-1} X^T Y = \begin{bmatrix} 0.518 & -0.481 \\ -0.481 & 0.518 \end{bmatrix} \begin{bmatrix} 4 & 2 \\ 5 & 1 \end{bmatrix} = \begin{bmatrix} -0.333 & 0.555 \\ 0.667 & -0.444 \end{bmatrix}$
>
> Para uma nova observa√ß√£o $x = \begin{bmatrix} 2 & 2 \end{bmatrix}$, calculamos $x^T \hat{B} = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} -0.333 & 0.555 \\ 0.667 & -0.444 \end{bmatrix} = \begin{bmatrix} 0.668 & 0.222 \end{bmatrix}$. Como o primeiro valor √© maior, a observa√ß√£o seria classificada como classe 1.

**Conceito 2:** A **Linear Discriminant Analysis (LDA)**, como abordado em cap√≠tulos anteriores, assume que os dados para cada classe seguem uma distribui√ß√£o normal multivariada com a mesma matriz de covari√¢ncia [^4.3]. A **fronteira de decis√£o** entre duas classes, na LDA, √© linear e definida com base nas m√©dias e covari√¢ncias das classes [^4.3.1]. O LDA busca encontrar a combina√ß√£o linear das vari√°veis que melhor separe as classes, maximizando a separa√ß√£o entre as m√©dias das classes e minimizando a variabilidade dentro de cada classe [^4.3.2]. A formula√ß√£o da fun√ß√£o discriminante na LDA √© dada por:

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log \pi_k
$$

Onde $\mu_k$ √© o vetor de m√©dia da classe $k$, $\Sigma$ √© a matriz de covari√¢ncia comum e $\pi_k$ √© a probabilidade *a priori* da classe $k$ [^4.3.3]. A classe predita para uma nova observa√ß√£o $x$ √© aquela que maximiza $\delta_k(x)$.

```mermaid
graph LR
    subgraph "Fun√ß√£o Discriminante LDA"
        direction TB
        A["x: Vetor de Observa√ß√£o"]
        B["Œº‚Çñ: M√©dia da Classe k"]
        C["Œ£: Matriz de Covari√¢ncia Comum"]
        D["œÄ‚Çñ: Probabilidade a Priori da Classe k"]
        E["Œ¥‚Çñ(x) = x·µÄŒ£‚Åª¬πŒº‚Çñ - 1/2 Œº‚Çñ·µÄŒ£‚Åª¬πŒº‚Çñ + log(œÄ‚Çñ)"]
        A --> E
        B --> E
        C --> E
        D --> E
    end
```

> üí° **Exemplo Num√©rico:**
> Considere um problema de classifica√ß√£o bin√°ria com duas classes, onde:
>
> - Classe 1: $\mu_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$
> - Classe 2: $\mu_2 = \begin{bmatrix} 3 \\ 3 \end{bmatrix}$
> - Matriz de covari√¢ncia comum: $\Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$
> - Probabilidades a priori: $\pi_1 = 0.6$, $\pi_2 = 0.4$
>
> **Passo 1: Calcular $\Sigma^{-1}$**
>
> $\Sigma^{-1} = \frac{1}{1 - 0.5^2} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \frac{4}{3} \begin{bmatrix} 1 & -0.5 \\ -0.5 & 1 \end{bmatrix} = \begin{bmatrix} 1.333 & -0.666 \\ -0.666 & 1.333 \end{bmatrix}$
>
> **Passo 2: Calcular as fun√ß√µes discriminantes para uma nova observa√ß√£o $x = \begin{bmatrix} 2 \\ 2 \end{bmatrix}$**
>
> $\delta_1(x) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 1.333 & -0.666 \\ -0.666 & 1.333 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 1 & 1 \end{bmatrix} \begin{bmatrix} 1.333 & -0.666 \\ -0.666 & 1.333 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} + \log(0.6) \approx  0.000 - 0.666 -0.510 \approx -1.176$
>
> $\delta_2(x) = \begin{bmatrix} 2 & 2 \end{bmatrix} \begin{bmatrix} 1.333 & -0.666 \\ -0.666 & 1.333 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} - \frac{1}{2} \begin{bmatrix} 3 & 3 \end{bmatrix} \begin{bmatrix} 1.333 & -0.666 \\ -0.666 & 1.333 \end{bmatrix} \begin{bmatrix} 3 \\ 3 \end{bmatrix} + \log(0.4) \approx  0.000 - 6.000 -0.916 \approx -6.916$
>
> Como $\delta_1(x) > \delta_2(x)$, a observa√ß√£o $x$ √© classificada como pertencente √† classe 1.

**Corol√°rio 1:** Se as classes seguem uma distribui√ß√£o normal com covari√¢ncias iguais, a fun√ß√£o discriminante do LDA pode ser interpretada como uma proje√ß√£o dos dados em um subespa√ßo de dimens√£o menor, onde a separa√ß√£o entre as classes √© maximizada. Este resultado surge da minimiza√ß√£o da dist√¢ncia de Mahalanobis entre as observa√ß√µes e as m√©dias de cada classe [^4.3.1]. A dist√¢ncia de Mahalanobis entre um ponto $x$ e a m√©dia da classe $k$, $\mu_k$, √© dada por $\sqrt{(x - \mu_k)^T \Sigma^{-1} (x - \mu_k)}$.  O LDA assume que a covari√¢ncia √© a mesma para todas as classes, $\Sigma$, e ent√£o a dist√¢ncia se reduz a uma forma linear em $x$.

**Conceito 3:** A **Regress√£o Log√≠stica** modela a probabilidade de uma observa√ß√£o pertencer a uma classe usando uma fun√ß√£o log√≠stica da combina√ß√£o linear dos preditores [^4.4]. O modelo log√≠stico para a probabilidade da classe 1 √© dado por:

$$
p(x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_1 + \ldots + \beta_px_p)}}
$$

Ou, equivalentemente, o log-odds (logit) √© modelado como:

$$
\log\left(\frac{p(x)}{1-p(x)}\right) = \beta_0 + \beta_1x_1 + \ldots + \beta_px_p
$$

Onde $p(x)$ √© a probabilidade da classe 1, e os $\beta_i$ s√£o os coeficientes do modelo [^4.4.1]. Os par√¢metros s√£o estimados maximizando a verossimilhan√ßa, dada por:

$$
L(\beta) = \prod_{i=1}^{N} p(x_i)^{y_i} (1-p(x_i))^{(1-y_i)}
$$

Onde $y_i \in \{0, 1\}$ √© o r√≥tulo de classe da observa√ß√£o $i$ [^4.4.3]. Diferentemente do LDA, a regress√£o log√≠stica n√£o assume normalidade dos preditores [^4.4.2]. Ambos os m√©todos, LDA e regress√£o log√≠stica, buscam encontrar separa√ß√µes lineares, mas a regress√£o log√≠stica estima probabilidades condicionais e pode ser mais apropriada quando o interesse est√° em probabilidades, e n√£o em fun√ß√µes discriminantes. Em casos onde as classes s√£o separ√°veis, os resultados podem ser semelhantes, mas a log√≠stica tende a ser mais robusta a desvios da normalidade [^4.4.5].

```mermaid
graph LR
    subgraph "Regress√£o Log√≠stica"
    direction TB
        A["Fun√ß√£o Log√≠stica:  p(x) = 1 / (1 + e^(-(Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + ... + Œ≤‚Çöx‚Çö)))"]
        B["Log-Odds (Logit): log(p(x)/(1-p(x))) = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + ... + Œ≤‚Çöx‚Çö"]
        C["Verossimilhan√ßa: L(Œ≤) = Œ† p(x·µ¢)^y·µ¢ (1-p(x·µ¢))^(1-y·µ¢)"]
        A --> B
        B --> C
    end
```

> üí° **Exemplo Num√©rico:**
> Suponha que temos um modelo de regress√£o log√≠stica com dois preditores:
>
> $$ \log\left(\frac{p(x)}{1-p(x)}\right) = -1 + 0.5x_1 - 0.2x_2 $$
>
> Para uma nova observa√ß√£o $x = \begin{bmatrix} 2 \\ 3 \end{bmatrix}$, temos:
>
> $$ \log\left(\frac{p(x)}{1-p(x)}\right) = -1 + 0.5(2) - 0.2(3) = -1 + 1 - 0.6 = -0.6 $$
>
> Para encontrar a probabilidade $p(x)$:
>
> $$ \frac{p(x)}{1-p(x)} = e^{-0.6} \approx 0.5488 $$
>
> $$ p(x) = 0.5488(1 - p(x)) $$
>
> $$ p(x) = 0.5488 - 0.5488p(x) $$
>
> $$ 1.5488p(x) = 0.5488 $$
>
> $$ p(x) = \frac{0.5488}{1.5488} \approx 0.354 $$
>
> Isso significa que a probabilidade da observa√ß√£o pertencer √† classe 1 √© aproximadamente 0.354. Se o limiar de classifica√ß√£o for 0.5, a observa√ß√£o seria classificada como classe 0.

> ‚ö†Ô∏è **Nota Importante**: Modelos de classifica√ß√£o linear podem n√£o ser adequados quando as rela√ß√µes entre as vari√°veis e as classes s√£o n√£o lineares. A escolha do modelo deve considerar a natureza dos dados e o objetivo da an√°lise. **Refer√™ncia ao t√≥pico [^4.4.1]**.

> ‚ùó **Ponto de Aten√ß√£o**: Classes desbalanceadas podem influenciar a performance dos modelos lineares, especialmente na regress√£o log√≠stica. T√©cnicas de balanceamento ou uso de pesos podem ser necess√°rias. **Conforme indicado em [^4.4.2]**.

> ‚úîÔ∏è **Destaque**: H√° uma correla√ß√£o entre as estimativas de par√¢metros em LDA e em regress√£o log√≠stica em casos onde as classes s√£o separ√°veis linearmente. **Baseado no t√≥pico [^4.5]**.

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
flowchart TD
  subgraph "Regress√£o de Indicadores"
    A["Codificar Classes (Matriz Indicadora Y)"] --> B["Estimar Coeficientes (B) via LS"]
    B --> C["Aplicar Regra de Decis√£o (max x·µÄBÃÇ)"]
    C --> D["Comparar com M√©todos Probabil√≠sticos"]
  end
```

A **regress√£o linear de uma matriz indicadora** √© uma abordagem para classifica√ß√£o onde cada classe √© representada por um vetor de indicadores bin√°rios, e a regress√£o linear √© aplicada a cada um desses indicadores [^4.2]. Essa abordagem busca modelar a probabilidade de pertencimento a uma classe, por meio de uma combina√ß√£o linear das vari√°veis preditoras. No entanto, esta abordagem possui limita√ß√µes, como o ‚Äúmasking problem‚Äù, onde a influ√™ncia de vari√°veis preditoras pode ser encoberta pela depend√™ncia entre classes [^4.3].

Em problemas de classifica√ß√£o com $K$ classes, a matriz de resposta $Y$ pode ser representada por uma matriz $N \times K$, onde $N$ √© o n√∫mero de amostras. Cada linha $i$  possui um valor 1 na coluna correspondente √† classe da amostra $i$, e 0 nas demais colunas. O modelo de regress√£o linear para essa matriz √© dado por:

$$
Y = XB + E
$$

onde $X$ √© a matriz de preditores $N \times p$, $B$ √© a matriz de coeficientes $p \times K$ a ser estimada por m√≠nimos quadrados, e $E$ √© a matriz de erros $N \times K$. A solu√ß√£o para $B$ √© dada por:

$$
\hat{B} = (X^TX)^{-1}X^TY
$$

Ap√≥s estimar os coeficientes, a classe predita para uma nova amostra $x$ √© aquela com maior valor em $x^T\hat{B}$. Embora essa abordagem possa gerar boas solu√ß√µes, ela n√£o garante que as probabilidades estimadas estejam entre 0 e 1. A decis√£o final da classe √© tomada atrav√©s de um *argmax*.

**Lemma 2:** Se as classes s√£o linearmente separ√°veis e a matriz de covari√¢ncia para cada classe √© igual ($\Sigma_k = \Sigma, \forall k$), a solu√ß√£o obtida via regress√£o linear da matriz indicadora √© equivalente √† solu√ß√£o do LDA, no sentido de que ambos os m√©todos levam √† mesma fronteira de decis√£o.

**Prova do Lemma 2:** A solu√ß√£o de m√≠nimos quadrados $\hat{B} = (X^TX)^{-1}X^TY$ √© uma transforma√ß√£o linear das respostas $Y$. Sob as hip√≥teses de classes gaussianas com covari√¢ncias iguais, os coeficientes $\hat{B}$ s√£o proporcionais aos coeficientes da fun√ß√£o discriminante do LDA.  Se a regra de decis√£o em ambos os casos √© tomar a classe com maior valor de fun√ß√£o, ent√£o as fronteiras de decis√£o ser√£o equivalentes. A fun√ß√£o discriminante do LDA,

$$
\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log \pi_k
$$

leva √† mesma separa√ß√£o entre as classes, pois, neste caso especial, ambas as abordagens encontram a mesma dire√ß√£o de separa√ß√£o.  $\blacksquare$

**Corol√°rio 2:** A equival√™ncia entre regress√£o linear e LDA em casos especiais simplifica a an√°lise, pois a matriz de indicadores permite obter as proje√ß√µes dos dados nas classes atrav√©s de uma regress√£o linear, e as decis√µes de classe s√£o tomadas com base nas proje√ß√µes. Conforme indicado em [^4.3], esta equival√™ncia √© v√°lida sob as condi√ß√µes de covari√¢ncias iguais e classes separ√°veis.

Em alguns casos, a **regress√£o log√≠stica** pode fornecer estimativas mais est√°veis das probabilidades, enquanto a **regress√£o de indicadores** pode levar a extrapola√ß√µes fora do intervalo [0,1] [^4.4]. No entanto, a regress√£o de indicadores pode ser suficiente e at√© vantajosa quando o objetivo principal √© a fronteira de decis√£o linear [^4.2]. A regress√£o linear n√£o √© um m√©todo probabil√≠stico, e n√£o calcula probabilidades. A decis√£o de classe vem atrav√©s de um "argmax".

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regulariza√ß√£o"
    direction TB
    A["Fun√ß√£o de Custo Original"]
    B["Regulariza√ß√£o L1: + Œª‚àë|Œ≤‚±º|"]
    C["Regulariza√ß√£o L2: + Œª‚àëŒ≤‚±º¬≤"]
    D["Elastic Net: + Œª‚ÇÅ‚àë|Œ≤‚±º| + Œª‚ÇÇ‚àëŒ≤‚±º¬≤"]
    A --> B
    A --> C
    A --> D
    end
```

A **sele√ß√£o de vari√°veis** √© crucial para modelos de classifica√ß√£o, principalmente quando se trabalha com dados de alta dimens√£o. T√©cnicas como a regulariza√ß√£o podem ser usadas para selecionar vari√°veis importantes e melhorar a generaliza√ß√£o do modelo. A **regulariza√ß√£o L1** (Lasso) adiciona a norma L1 dos coeficientes √† fun√ß√£o de custo, induzindo esparsidade no modelo, ou seja, fazendo com que alguns coeficientes sejam exatamente zero [^4.4.4]. Isso seleciona implicitamente as vari√°veis mais relevantes. A regulariza√ß√£o L2 (Ridge), por outro lado, adiciona a norma L2 dos coeficientes √† fun√ß√£o de custo, encolhendo os coeficientes para zero, mas n√£o necessariamente tornando-os exatamente zero [^4.5]. Essa t√©cnica estabiliza os modelos, reduzindo o problema do *overfitting*. Ambas podem ser combinadas em uma abordagem chamada **Elastic Net** para equilibrar sele√ß√£o de vari√°veis e estabilidade [^4.5].

Na regress√£o log√≠stica, por exemplo, a fun√ß√£o de custo com regulariza√ß√£o L1 √© dada por:

$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda \sum_{j=1}^{p} |\beta_j|
$$

onde $\lambda$ √© um hiperpar√¢metro que controla a intensidade da regulariza√ß√£o [^4.4.4]. O primeiro termo √© a verossimilhan√ßa negativa do modelo, e o segundo termo √© a penalidade L1. Na regulariza√ß√£o L2, o termo $\lambda \sum_{j=1}^{p} |\beta_j|$ √© substitu√≠do por $\lambda \sum_{j=1}^{p} \beta_j^2$:

$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda \sum_{j=1}^{p} \beta_j^2
$$

E no caso do Elastic Net, a fun√ß√£o de custo inclui ambas as penalidades:

$$
J(\beta) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(p(x_i)) + (1-y_i) \log(1-p(x_i))] + \lambda_1 \sum_{j=1}^{p} |\beta_j| + \lambda_2 \sum_{j=1}^{p} \beta_j^2
$$

onde $\lambda_1$ e $\lambda_2$ controlam a intensidade das penalidades L1 e L2, respectivamente.

> üí° **Exemplo Num√©rico:**
> Vamos considerar um exemplo com regress√£o log√≠stica com 3 preditores ($x_1$, $x_2$, $x_3$), com os seguintes coeficientes estimados sem regulariza√ß√£o:
>
> $\beta = \begin{bmatrix} -0.5 \\ 1.2 \\ -0.8 \end{bmatrix}$
>
> Agora, vamos aplicar regulariza√ß√£o L1 (Lasso) com $\lambda = 0.5$. A fun√ß√£o de custo se torna:
>
> $J(\beta) = \text{Verossimilhan√ßa Negativa} + 0.5(|\beta_1| + |\beta_2| + |\beta_3|)$
>
> Ap√≥s otimiza√ß√£o, os coeficientes podem mudar, por exemplo:
>
> $\beta_{\text{Lasso}} = \begin{bmatrix} 0 \\ 0.9 \\ -0.2 \end{bmatrix}$
>
> Observe que o coeficiente de $x_1$ foi zerado, o que significa que a vari√°vel $x_1$ foi removida do modelo. Isso √© uma caracter√≠stica da regulariza√ß√£o L1.
>
> Agora, vamos aplicar regulariza√ß√£o L2 (Ridge) com $\lambda = 0.5$. A fun√ß√£o de custo se torna:
>
> $J(\beta) = \text{Verossimilhan√ßa Negativa} + 0.5(\beta_1^2 + \beta_2^2 + \beta_3^2)$
>
> Ap√≥s otimiza√ß√£o, os coeficientes podem mudar, por exemplo:
>
> $\beta_{\text{Ridge}} = \begin{bmatrix} -0.3 \\ 0.8 \\ -0.5 \end{bmatrix}$
>
> Observe que os coeficientes foram encolhidos em dire√ß√£o a zero, mas nenhum se tornou exatamente zero.
>
> Finalmente, vamos aplicar Elastic Net com $\lambda_1 = 0.3$ e $\lambda_2 = 0.2$. A fun√ß√£o de custo se torna:
>
> $J(\beta) = \text{Verossimilhan√ßa Negativa} + 0.3(|\beta_1| + |\beta_2| + |\beta_3|) + 0.2(\beta_1^2 + \beta_2^2 + \beta_3^2)$
>
> Ap√≥s otimiza√ß√£o, os coeficientes podem mudar, por exemplo:
>
> $\beta_{\text{Elastic Net}} = \begin{bmatrix} 0 \\ 0.7 \\ -0.3 \end{bmatrix}$
>
> Aqui, Elastic Net combinou a sele√ß√£o de vari√°veis (zerando o coeficiente de $x_1$) com o encolhimento dos coeficientes restantes.

**Lemma 3:** A penaliza√ß√£o L1 na regress√£o log√≠stica leva a coeficientes esparsos devido ao formato da fun√ß√£o de penalidade. A norma L1 imp√µe uma penalidade que n√£o √© diferenci√°vel em zero, levando a solu√ß√µes onde alguns coeficientes s√£o exatamente zero [^4.4.4].

**Prova do Lemma 3:** A otimiza√ß√£o da fun√ß√£o de custo com penaliza√ß√£o L1 envolve a minimiza√ß√£o da soma da verossimilhan√ßa negativa com o termo de penalidade. Geometricamente, a penaliza√ß√£o L1 for√ßa os coeficientes a se concentrarem nos eixos coordenados, resultando em coeficientes nulos para algumas vari√°veis. Este comportamento resulta da n√£o-diferenciabilidade da norma L1 em zero. Ou seja, a norma L1 possui um "canto" no ponto zero, induzindo a esparsidade nos coeficientes.  $\blacksquare$

**Corol√°rio 3:** A esparsidade induzida pela regulariza√ß√£o L1 facilita a interpreta√ß√£o do modelo, pois as vari√°veis com coeficientes zero s√£o consideradas irrelevantes para o problema de classifica√ß√£o, selecionando automaticamente as vari√°veis mais importantes para a constru√ß√£o da fronteira de decis√£o [^4.4.5].

> ‚ö†Ô∏è **Ponto Crucial**: A escolha entre L1 e L2 (ou Elastic Net) depende do problema. L1 √© prefer√≠vel para sele√ß√£o de vari√°veis, enquanto L2 ajuda na estabilidade e redu√ß√£o do overfitting. A combina√ß√£o Elastic Net pode aproveitar vantagens de ambos os tipos de regulariza√ß√£o [^4.5]. Elastic Net √© prefer√≠vel a Lasso quando o n√∫mero de preditores √© muito alto e h√° multicolinearidade.

### Separating Hyperplanes e Perceptrons

A **separating hyperplane** √© uma superf√≠cie linear que divide o espa√ßo de caracter√≠sticas em regi√µes correspondentes a diferentes classes. O objetivo √© encontrar um hiperplano que maximize a dist√¢ncia entre as classes, conhecida como margem. Seja um conjunto de dados $(x_i, y_i)$, onde $x_i \in \mathbb{R}^p$ s√£o os preditores e $y_i \in \{-1, 1\}$ s√£o os r√≥tulos das classes. O hiperplano √© definido pela equa√ß√£o:

$$
w^T x + b = 0
$$

Onde $w \in \mathbb{R}^p$ √© o vetor normal ao hiperplano e $b \in \mathbb{R}$ √© o vi√©s.  Para uma classifica√ß√£o bin√°ria, o objetivo √© encontrar $w$ e $b$ de forma que:

$$
w^T x_i + b > 0 \text{, se } y_i = 1
$$
$$
w^T x_i + b < 0 \text{, se } y_i = -1
$$

O hiperplano √≥timo √© aquele que maximiza a dist√¢ncia entre o hiperplano e as observa√ß√µes mais pr√≥ximas, conhecidas como pontos de suporte. A dist√¢ncia (margem) √© dada por $\frac{2}{||w||}$. O problema de otimiza√ß√£o pode ser formulado como:

$$
\text{minimizar} \frac{1}{2}||w||^2 \\
\text{sujeito a } y_i(w^T x_i + b) \geq 1, \forall i
$$

A solu√ß√£o para este problema √© dada por:

$$
w = \sum_{i=1}^{N} \alpha_i y_i x_i
$$

onde $\alpha_i$ s√£o os multiplicadores de Lagrange. Os pontos de suporte s√£o os $x_i$ para os quais $\alpha_i > 0$. A solu√ß√£o emerge a partir de combina√ß√µes lineares dos pontos de suporte, conforme discutido em [^4.5.2].

```mermaid
graph LR
    subgraph "Hiperplano Separador"
        direction TB
        A["Hiperplano: w·µÄx + b = 0"]
        B["Classifica√ß√£o: w·µÄx·µ¢ + b > 0 se y·µ¢ = 1, w·µÄx·µ¢ + b < 0 se y·µ¢ = -1"]
        C["Dist√¢ncia (Margem): 2/||w||"]
        D["Otimiza√ß√£o: Minimizar ||w||¬≤/2 sujeito a y·µ¢(w·µÄx·µ¢ + b) ‚â• 1"]
        E["Solu√ß√£o: w = ‚àëŒ±·µ¢y·µ¢x·µ¢"]
        A --> B
        B --> C
        C --> D
        D --> E
    end
```

O **Perceptron de Rosenblatt** √© um algoritmo de aprendizado de m√°quina para classifica√ß√£o linear, cujo objetivo √© encontrar um hiperplano que separe os dados em diferentes classes [^4.5.1]. O algoritmo ajusta iterativamente os pesos do hiperplano com base em classifica√ß√µes err√¥neas. Seja um conjunto de dados $(x_i, y_i)$, onde $x_i \in \mathbb{R}^p$ s√£o os preditores e $y_i \in \{-1, 1\}$ s√£o os r√≥tulos das classes.  A predi√ß√£o do perceptron √©:

$$
\hat{y} = \text{sign}(w^T x + b)
$$
Inicializando com valores arbitr√°rios para $w$ e $b$, o algoritmo do Perceptron atualiza os par√¢metros da seguinte forma:
1.  Se $y_i(w^T x_i + b) \leq 0$ (classifica√ß√£o errada):
   $$
   w_{t+1} = w_t + \eta y_i x_i
   $$
   $$
   b_{t+1} = b_t + \eta y_i
   $$
    onde $\eta$ √© a taxa de aprendizado e $t$ √© o n√∫mero da itera√ß√£o.
2. Se a classifica√ß√£o estiver correta, os par√¢metros n√£o s√£o atualizados.

A converg√™ncia do Perceptron depende da **separabilidade linear** dos dados. Se as classes s√£o linearmente separ√°veis, o algoritmo converge em um n√∫mero finito de itera√ß√µes para uma solu√ß√£o que separa as classes [^4.5.1]. No entanto, se os dados n√£o s√£o linearmente separ√°veis, o algoritmo pode n√£o convergir.

> üí° **Exemplo Num√©rico:**
> Vamos considerar um conjunto de dados com 3 observa√ß√µes e 2 preditores, com r√≥tulos $y_i \in \{-1, 1\}$:
>
> - $x_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$, $y_1 = 1$
> - $x_2 = \begin{bmatrix} 2 \\ 0 \