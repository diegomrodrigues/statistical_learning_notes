## Modelos Aditivos e Suavização de Scatterplots

### Introdução
Este capítulo aprofunda o estudo dos **Modelos Aditivos** (Additive Models), explorando como eles utilizam a suavização de scatterplots para ajustar cada função, revelando potenciais não linearidades no efeito de cada preditor [^2]. Os modelos aditivos oferecem uma alternativa flexível ao modelo linear tradicional, permitindo a modelagem de efeitos não lineares e acomodando variáveis qualitativas e interações entre variáveis [^1]. Este capítulo complementa os conceitos de regressão abordados em capítulos anteriores, explorando técnicas que permitem identificar e caracterizar efeitos de regressão não lineares de forma mais automática e flexível [^1].

### Conceitos Fundamentais
Um **modelo aditivo generalizado** assume a forma [^1]:

$$E(Y|X_1, X_2, ..., X_p) = \alpha + f_1(X_1) + f_2(X_2) + ... + f_p(X_p),$$

onde $X_1, X_2, ..., X_p$ representam os preditores e $Y$ é o resultado. As funções $f_j$ são funções *suaves* e *não especificadas* ("não paramétricas") [^2]. A flexibilidade do modelo aditivo reside na capacidade de modelar cada função $f_j$ de forma independente, permitindo que o modelo capture relações complexas entre cada preditor e a variável resposta [^2].

Em vez de usar uma expansão de funções de base predefinidas, como discutido em capítulos anteriores, os modelos aditivos empregam *suavizadores de scatterplots* para ajustar cada função $f_j$ [^2]. Um suavizador de scatterplot, como um *spline de suavização cúbica* ou um *suavizador de kernel*, estima a relação entre um preditor e a variável resposta, permitindo que a função $f_j$ assuma uma forma não linear [^2].

Um aspecto crucial dos modelos aditivos é o algoritmo para estimar simultaneamente todas as funções $f_j$. O *algoritmo de backfitting* é uma técnica iterativa que estima cada função $f_j$ enquanto mantém as outras funções fixas [^2]. O algoritmo funciona da seguinte forma [^4]:

1.  Inicialização: $\alpha = \frac{1}{N} \sum_{i=1}^N y_i$, $f_j = 0, \forall i, j$.

2.  Ciclo: Para $j = 1, 2, ..., p, ..., 1, 2, ..., p, ...$:

    $$f_j \leftarrow S_j \left[ y_i - \alpha - \sum_{k \neq j} f_k(x_{ik}) \right]$$

    $$f_j \leftarrow f_j - \frac{1}{N} \sum_{i=1}^N f_j(x_{ij}).$$

    Repetir até que as funções $f_j$ mudem menos que um limiar predefinido.

O algoritmo de backfitting itera através de cada preditor, atualizando a estimativa da função $f_j$ com base nos resíduos parciais (os resíduos após remover os efeitos dos outros preditores) [^4]. Este processo é repetido até que as funções $f_j$ converjam, resultando em uma estimativa do modelo aditivo [^4].

Os modelos aditivos também podem ser estendidos para problemas de classificação binária usando a regressão logística aditiva. Neste caso, a função de ligação logit relaciona a média da resposta binária $\mu(X) = Pr(Y = 1|X)$ aos preditores através de uma forma funcional mais geral [^2]:

$$log \left( \frac{\mu(X)}{1 - \mu(X)} \right) = \alpha + f_1(X_1) + ... + f_p(X_p),$$

onde cada $f_j$ é uma função suave não especificada [^2].

Além disso, os modelos aditivos não se limitam a componentes não lineares. É possível *misturar formas lineares e outros formatos paramétricos com termos não lineares*, o que é particularmente útil quando algumas das entradas são variáveis qualitativas (fatores) [^3].  Por exemplo [^3]:

*   $g(\mu) = X^T\beta + \alpha_k + f(Z)$ — um modelo semiparamétrico, onde $X$ é um vetor de preditores a serem modelados linearmente, $\alpha_k$ é o efeito para o *k*-ésimo nível de uma entrada qualitativa $V$, e o efeito do preditor $Z$ é modelado não parametricamente.

*   $g(\mu) = f(X) + g_k(Z)$ — novamente *k* indexa os níveis de uma entrada qualitativa $V$, e assim cria um termo de interação $g(V, Z) = g_k(Z)$ para o efeito de $V$ e $Z$.

### Conclusão
Os modelos aditivos oferecem uma abordagem flexível e interpretável para modelar relações complexas entre preditores e variáveis de resposta [^3]. Ao empregar suavizadores de scatterplots e o algoritmo de backfitting, os modelos aditivos podem capturar efeitos não lineares e acomodar diferentes tipos de preditores [^2]. A capacidade de misturar termos lineares e não lineares torna os modelos aditivos uma ferramenta poderosa para uma ampla gama de aplicações [^3]. Embora os modelos aditivos apresentem desafios computacionais para conjuntos de dados muito grandes, eles oferecem uma alternativa valiosa aos modelos lineares tradicionais, proporcionando maior flexibilidade e insights sobre a natureza das relações entre variáveis [^3].

### Referências
[^1]: Page 295
[^2]: Page 296
[^3]: Page 297
[^4]: Page 298
<!-- END -->