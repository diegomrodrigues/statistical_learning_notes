## TÃ­tulo: Modelos Aditivos, Ãrvores e MÃ©todos Relacionados: Mecanismos de Dados Faltantes, MCAR, ImplicaÃ§Ãµes e AvaliaÃ§Ã£o

```mermaid
graph LR
    subgraph "Missing Data Mechanisms"
        direction TB
        A["Observed Data"]
        B["Missing Completely at Random (MCAR)"]
        C["Missing at Random (MAR)"]
        D["Missing Not at Random (MNAR)"]
        A --> B
        A --> C
        A --> D
        B --> E["Independent of all data"]
        C --> F["Dependent on observed data"]
        D --> G["Dependent on missing data"]
    end
```

### IntroduÃ§Ã£o

Este capÃ­tulo explora os mecanismos de dados faltantes, focando nas definiÃ§Ãµes de Missing Completely at Random (MCAR), Missing at Random (MAR) e Missing Not at Random (MNAR), e como cada mecanismo afeta as abordagens de modelagem e imputaÃ§Ã£o, com foco na aplicaÃ§Ã£o em Modelos Aditivos Generalizados (GAMs), Ã¡rvores de decisÃ£o e outras abordagens relacionadas [^9.1]. O capÃ­tulo detalha a definiÃ§Ã£o de cada mecanismo, as suas implicaÃ§Ãµes para a validade das estimativas dos modelos e como diferentes mÃ©todos de imputaÃ§Ã£o e modelagem podem ser utilizados para lidar com dados faltantes sob diferentes hipÃ³teses. O objetivo principal Ã© apresentar uma visÃ£o aprofundada sobre como o mecanismo de dados faltantes influencia a modelagem estatÃ­stica e como a utilizaÃ§Ã£o de mÃ©todos de imputaÃ§Ã£o e avaliaÃ§Ã£o dos dados ausentes Ã© fundamental para a construÃ§Ã£o de modelos robustos e confiÃ¡veis.

### Conceitos Fundamentais

**Conceito 1: Tipos de Mecanismos de Dados Faltantes**

A presenÃ§a de dados faltantes em modelos de aprendizado supervisionado Ã© comum em aplicaÃ§Ãµes reais, e a sua modelagem depende de qual Ã© o mecanismo que gera esses dados faltantes, que pode ser classificado em trÃªs tipos principais:

*   **Missing Completely at Random (MCAR):** Os dados sÃ£o considerados MCAR quando a probabilidade de um valor ser ausente Ã© completamente independente dos valores observados e dos valores que estÃ£o ausentes. O mecanismo de dados faltantes, portanto, Ã© aleatÃ³rio e nÃ£o correlacionado com os dados, e nÃ£o hÃ¡ padrÃ£o especÃ­fico nos dados ausentes.
*   **Missing at Random (MAR):** Os dados sÃ£o considerados MAR quando a probabilidade de um valor ser ausente depende dos valores observados, mas nÃ£o depende dos valores que estÃ£o ausentes.  O mecanismo de dados faltantes Ã© aleatÃ³rio, mas condicionado aos dados observados, e as observaÃ§Ãµes que apresentam informaÃ§Ãµes podem conter informaÃ§Ãµes sobre os dados faltantes, e essa informaÃ§Ã£o pode ser utilizada na modelagem.
*   **Missing Not at Random (MNAR):** Os dados sÃ£o considerados MNAR quando a probabilidade de um valor ser ausente depende do valor que estÃ¡ ausente.  Neste cenÃ¡rio, os dados ausentes podem conter informaÃ§Ã£o relevante, e o mecanismo que levou Ã  ausÃªncia de dados deve ser modelado. O modelo de inferÃªncia, neste caso, deve considerar como os dados ausentes se relacionam com as variÃ¡veis utilizadas na modelagem.

A escolha da abordagem apropriada para lidar com dados ausentes depende do mecanismo que gera os dados faltantes.  O conhecimento sobre o tipo de dados faltantes Ã© fundamental para a escolha dos modelos e dos mÃ©todos de imputaÃ§Ã£o mais adequados. A avaliaÃ§Ã£o das implicaÃ§Ãµes de cada mecanismo Ã© importante na anÃ¡lise estatÃ­stica.

**Lemma 1:** *Os dados faltantes podem ser classificados como MCAR, MAR ou MNAR, e a escolha do mecanismo apropriado Ã© fundamental para a modelagem e imputaÃ§Ã£o de valores ausentes. A hipÃ³tese sobre qual tipo de dado faltante Ã© presente no problema Ã© uma parte importante na modelagem estatÃ­stica*. A escolha do mÃ©todo de modelagem e de imputaÃ§Ã£o depende do mecanismo que gera a ausÃªncia dos dados [^9.6].

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Imagine um conjunto de dados com informaÃ§Ãµes sobre pacientes, incluindo idade, gÃªnero e nÃ­veis de colesterol.
>
> *   **MCAR:** Se a ausÃªncia do nÃ­vel de colesterol em alguns pacientes ocorre devido a um erro aleatÃ³rio no laboratÃ³rio, sem qualquer relaÃ§Ã£o com a idade ou o gÃªnero desses pacientes, entÃ£o os dados sÃ£o MCAR.
> *   **MAR:** Se a ausÃªncia do nÃ­vel de colesterol Ã© mais frequente em pacientes mais velhos (uma informaÃ§Ã£o observada), mas nÃ£o depende do valor real do nÃ­vel de colesterol (o dado faltante), entÃ£o os dados sÃ£o MAR.
> *   **MNAR:** Se a ausÃªncia do nÃ­vel de colesterol ocorre porque pacientes com nÃ­veis muito altos de colesterol se recusam a fazer o exame, entÃ£o os dados sÃ£o MNAR, pois a ausÃªncia depende do prÃ³prio valor que estÃ¡ faltando.
>
> A escolha do mÃ©todo de imputaÃ§Ã£o dependerÃ¡ de qual desses mecanismos Ã© mais plausÃ­vel.

**Conceito 2: Missing Completely at Random (MCAR) e suas ImplicaÃ§Ãµes**

Dados que sÃ£o considerados Missing Completely at Random (MCAR) sÃ£o o tipo mais simples de dados faltantes, pois a probabilidade de um valor ser ausente Ã© completamente aleatÃ³ria e independente dos dados observados e dos dados ausentes.  Em outras palavras, nÃ£o existe nenhuma informaÃ§Ã£o nos dados que explique a sua ausÃªncia.  A implicaÃ§Ã£o da hipÃ³tese MCAR Ã© que o conjunto de dados observados Ã© uma amostra aleatÃ³ria do conjunto de dados completo.  Quando a hipÃ³tese MCAR Ã© satisfeita, a remoÃ§Ã£o de observaÃ§Ãµes com dados faltantes nÃ£o induz *bias* no modelo. MÃ©todos de imputaÃ§Ã£o simples como mÃ©dia ou mediana podem ser utilizados, mas o uso de modelos mais complexos nÃ£o adiciona informaÃ§Ã£o relevante.  No entanto, na prÃ¡tica, o mecanismo MCAR Ã© pouco comum, e geralmente a ausÃªncia de dados tem alguma razÃ£o, que pode ser modelada com os outros tipos de dados faltantes.

**CorolÃ¡rio 1:** *Sob a hipÃ³tese MCAR, os dados faltantes sÃ£o aleatÃ³rios e nÃ£o enviesam as estimativas dos parÃ¢metros do modelo.  O uso de mÃ©todos de imputaÃ§Ã£o simples Ã© apropriado para dados MCAR, e modelos complexos para tratar dados ausentes nÃ£o acrescentam informaÃ§Ã£o relevante*.  A hipÃ³tese MCAR simplifica a modelagem, mas Ã© raramente encontrada na prÃ¡tica [^9.6].

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Considere um conjunto de dados com 100 observaÃ§Ãµes, onde cada observaÃ§Ã£o tem duas variÃ¡veis: X e Y. Suponha que 10 valores de Y estÃ£o faltando. Se esses 10 valores estÃ£o faltando devido a um erro aleatÃ³rio na coleta de dados (por exemplo, o equipamento de mediÃ§Ã£o falhou aleatoriamente), e a probabilidade de um valor faltar Ã© igual para todos os valores de Y, entÃ£o os dados sÃ£o MCAR.
>
> Neste caso, imputar os valores ausentes de Y com a mÃ©dia dos valores observados de Y nÃ£o introduziria viÃ©s significativo no modelo, pois a ausÃªncia dos dados nÃ£o estÃ¡ relacionada com os valores de X ou de Y.

**Conceito 3: ImplicaÃ§Ãµes de Modelagem para Dados MAR e MNAR**

*   **Missing at Random (MAR):** Dados que sÃ£o considerados MAR sÃ£o faltantes de forma aleatÃ³ria, mas dependendo de variÃ¡veis observadas.  Por exemplo, se a probabilidade de uma pessoa nÃ£o responder a um questionÃ¡rio sobre renda depende do seu nÃ­vel de escolaridade (que Ã© uma informaÃ§Ã£o observada), mas nÃ£o depende da sua renda (que Ã© o dado ausente), entÃ£o os dados sÃ£o MAR.  A imputaÃ§Ã£o dos valores ausentes deve levar em consideraÃ§Ã£o a informaÃ§Ã£o presente nas variÃ¡veis observadas.  A utilizaÃ§Ã£o de modelos de imputaÃ§Ã£o que levem em consideraÃ§Ã£o a dependÃªncia entre os dados ausentes e as variÃ¡veis observadas pode reduzir o *bias*. A modelagem de dados ausentes MAR deve considerar a sua dependÃªncia com as variÃ¡veis observadas.
*   **Missing Not at Random (MNAR):** Dados que sÃ£o considerados MNAR sÃ£o faltantes quando a probabilidade de um valor ser ausente depende do prÃ³prio valor que estÃ¡ faltando.  Por exemplo, uma pessoa que tem problemas financeiros pode ter maior probabilidade de omitir informaÃ§Ãµes sobre seus ganhos.  A modelagem de dados MNAR Ã© um grande desafio, e envolve considerar o mecanismo que gerou os dados ausentes. Abordagens como modelagem de seleÃ§Ã£o e modelos de *pattern-mixture* podem ser utilizados para lidar com esse tipo de dados, mas requerem um conhecimento sobre como os dados estÃ£o faltando e as suas propriedades, e sÃ£o modelos muito complexos.

```mermaid
graph LR
    subgraph "MAR vs MNAR"
        direction TB
        A["Missing at Random (MAR)"]
        B["Missing Not at Random (MNAR)"]
        A --> C["P(Missing | Observed Data)"]
        B --> D["P(Missing | Missing Data)"]
        C --> E["Imputation using observed data"]
        D --> F["Modeling missingness mechanism"]
    end
```

> âš ï¸ **Nota Importante:** A modelagem de dados MAR e MNAR requer abordagens mais complexas do que dados MCAR.  A escolha do mÃ©todo de imputaÃ§Ã£o e modelagem deve levar em consideraÃ§Ã£o o mecanismo que gera a ausÃªncia dos dados. A modelagem de dados com valores ausentes deve ser feita com cuidado para evitar o *bias* e perda de informaÃ§Ã£o [^9.6].

> â— **Ponto de AtenÃ§Ã£o:** Modelos de imputaÃ§Ã£o que nÃ£o consideram o mecanismo de dados faltantes podem levar a resultados viesados e com um menor poder preditivo. A identificaÃ§Ã£o e modelagem da dependÃªncia entre dados ausentes e outras variÃ¡veis Ã© fundamental em cenÃ¡rios com dados MAR e MNAR [^9.6].

> âœ”ï¸ **Destaque:**  A escolha da abordagem para lidar com valores ausentes, incluindo a imputaÃ§Ã£o, a modelagem da probabilidade de dados ausentes e a utilizaÃ§Ã£o de modelos que incorporem o mecanismo de dados ausentes, deve considerar a natureza dos dados e o tipo de modelo utilizado. A modelagem de dados faltantes Ã© importante para a construÃ§Ã£o de modelos mais robustos [^9.6].

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Considere um estudo sobre o consumo de Ã¡lcool, onde se coleta informaÃ§Ãµes sobre a idade, gÃªnero e quantidade de Ã¡lcool consumida por cada participante.
>
> *   **MAR:** Se a probabilidade de um participante nÃ£o informar a quantidade de Ã¡lcool consumida depende da sua idade (participantes mais jovens sÃ£o menos propensos a relatar), mas nÃ£o depende da quantidade real de Ã¡lcool que consomem, entÃ£o os dados sÃ£o MAR. Nesse caso, ao imputar a quantidade de Ã¡lcool consumida, um modelo de imputaÃ§Ã£o condicional que leve em conta a idade do participante pode ser usado para reduzir o *bias*.
> *   **MNAR:** Se a probabilidade de um participante nÃ£o informar a quantidade de Ã¡lcool consumida depende da quantidade real de Ã¡lcool que consomem (pessoas que bebem muito sÃ£o mais propensas a nÃ£o relatar), entÃ£o os dados sÃ£o MNAR. Nesse caso, a modelagem deve considerar essa relaÃ§Ã£o entre a quantidade real de Ã¡lcool e a probabilidade de nÃ£o relatar. Modelos mais avanÃ§ados, como modelos de seleÃ§Ã£o, podem ser necessÃ¡rios para lidar com essa situaÃ§Ã£o.

### Abordagens para Lidar com Dados Faltantes: ImputaÃ§Ã£o, CriaÃ§Ã£o de Categorias e *Surrogate Splits*

```mermaid
graph LR
    subgraph "Handling Missing Data"
    direction TB
        A["Missing Data"]
        B["Imputation"]
        C["Create 'Missing' Category"]
        D["Surrogate Splits"]
        A --> B
        A --> C
        A --> D
        B --> E["Mean/Median Imputation"]
        B --> F["Conditional Imputation"]
        B --> G["Multiple Imputation"]
    end
```

A modelagem estatÃ­stica com dados faltantes requer a escolha de abordagens apropriadas para lidar com esses valores ausentes, e as abordagens mais comuns sÃ£o:

1.  **ImputaÃ§Ã£o:** ImputaÃ§Ã£o envolve a substituiÃ§Ã£o dos valores ausentes por valores estimados, de acordo com um dado mÃ©todo.
    *   **ImputaÃ§Ã£o com MÃ©dia ou Mediana:** Os valores ausentes sÃ£o substituÃ­dos pela mÃ©dia ou mediana das observaÃ§Ãµes nÃ£o ausentes. Ã‰ um mÃ©todo simples e rÃ¡pido, mas pode introduzir *bias* nos modelos, especialmente quando os dados nÃ£o sÃ£o MCAR.
    *   **ImputaÃ§Ã£o Condicional:** Os valores ausentes sÃ£o imputados com base em um modelo construÃ­do usando os outros preditores. Por exemplo, um modelo de regressÃ£o pode ser utilizado para estimar um valor de acordo com os dados observados. Modelos condicionais podem levar em consideraÃ§Ã£o relaÃ§Ãµes entre os preditores.
    *   **ImputaÃ§Ã£o MÃºltipla:** A imputaÃ§Ã£o mÃºltipla cria diversos conjuntos de dados com imputaÃ§Ãµes diferentes, e cada modelo Ã© utilizado para ajustar os parÃ¢metros de acordo com os diferentes conjuntos de dados. A combinaÃ§Ã£o das estimativas, leva em consideraÃ§Ã£o a incerteza da imputaÃ§Ã£o, e permite estimativas mais robustas e com menor viÃ©s.
2. **CriaÃ§Ã£o de uma Categoria â€œAusenteâ€:** Para preditores categÃ³ricos, Ã© criada uma categoria adicional "ausente", que representa as observaÃ§Ãµes onde o valor do preditor nÃ£o foi observado. Esta abordagem Ã© apropriada para preditores categÃ³ricos quando o fato da informaÃ§Ã£o nÃ£o estar disponÃ­vel Ã© relevante e pode influenciar na modelagem. A criaÃ§Ã£o de uma categoria "ausente" permite que o modelo aprenda a modelar a ausÃªncia da informaÃ§Ã£o.
3.  ***Surrogate Splits* em Ãrvores de DecisÃ£o:** Em Ã¡rvores de decisÃ£o, quando um preditor tem um valor ausente, um *surrogate split* Ã© utilizado para avaliar qual o melhor preditor substituto para a divisÃ£o do nÃ³. O *surrogate split* Ã© escolhido como aquele que melhor aproxima a divisÃ£o que seria feita pelo preditor original, com base na impureza.  Os *surrogate splits* permitem que o modelo utilize informaÃ§Ã£o de outros preditores mesmo quando a informaÃ§Ã£o do preditor principal esteja ausente.

A escolha de uma abordagem para lidar com dados ausentes depende do tipo de dados, da quantidade de dados ausentes, do mecanismo gerador dos dados ausentes e da necessidade de manter o *bias* e a variÃ¢ncia do modelo controladas.

**Lemma 4:** *A escolha da abordagem de imputaÃ§Ã£o de dados ausentes influencia diretamente os resultados do modelo, e a escolha entre imputaÃ§Ã£o, a criaÃ§Ã£o da categoria ausente, ou surrogate splits depende da natureza dos dados e do modelo utilizado. Abordagens mais sofisticadas podem ser utilizadas para dados nÃ£o MCAR, onde as imputaÃ§Ãµes dependem das outras variÃ¡veis, e onde o mecanismo dos dados ausentes deve ser considerado*. A escolha da melhor abordagem deve ser feita levando em consideraÃ§Ã£o as suas limitaÃ§Ãµes [^4.5.1], [^4.5.2].

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Considere um conjunto de dados com as variÃ¡veis `idade`, `renda`, e `nivel_educacional`. Suponha que hÃ¡ dados faltantes na variÃ¡vel `renda`.
>
> 1.  **ImputaÃ§Ã£o com MÃ©dia/Mediana:** Se imputarmos os valores faltantes de `renda` com a mÃ©dia das rendas observadas, teremos:
>
>     ```python
>     import numpy as np
>     import pandas as pd
>
>     data = {'idade': [25, 30, 35, 40, 45, 50],
>             'renda': [2000, 3000, np.nan, 4000, np.nan, 5000],
>             'nivel_educacional': ['Ensino MÃ©dio', 'Superior', 'Superior', 'Ensino MÃ©dio', 'Superior', 'PÃ³s-graduaÃ§Ã£o']}
>     df = pd.DataFrame(data)
>
>     media_renda = df['renda'].mean()
>     df_imputed_mean = df.fillna({'renda': media_renda})
>     print("ImputaÃ§Ã£o com a MÃ©dia:\n", df_imputed_mean)
>     ```
>
>     Essa abordagem Ã© simples, mas nÃ£o considera a relaÃ§Ã£o entre renda e outras variÃ¡veis.
>
> 2.  **ImputaÃ§Ã£o Condicional:** Podemos usar a idade para prever a renda usando um modelo de regressÃ£o linear:
>
>     ```python
>     from sklearn.linear_model import LinearRegression
>
>     df_not_na = df.dropna(subset=['renda'])
>     model = LinearRegression()
>     model.fit(df_not_na[['idade']], df_not_na['renda'])
>
>     missing_indices = df['renda'].isna()
>     imputed_values = model.predict(df[missing_indices][['idade']])
>     df_imputed_conditional = df.copy()
>     df_imputed_conditional.loc[missing_indices, 'renda'] = imputed_values
>     print("\nImputaÃ§Ã£o Condicional:\n", df_imputed_conditional)
>     ```
>     Essa abordagem leva em consideraÃ§Ã£o a relaÃ§Ã£o entre idade e renda.
>
> 3.  **CriaÃ§Ã£o de Categoria "Ausente":** Se `nivel_educacional` for um preditor categÃ³rico, podemos criar uma categoria "ausente":
>
>     ```python
>     df_category = df.copy()
>     df_category['nivel_educacional'] = df_category['nivel_educacional'].fillna('Ausente')
>     print("\nCategoria Ausente:\n", df_category)
>     ```
>     Essa abordagem Ã© Ãºtil se a ausÃªncia de informaÃ§Ã£o de nÃ­vel educacional tiver um significado.
>
> A escolha entre esses mÃ©todos dependerÃ¡ da natureza dos dados e do problema.

### Impacto da Escolha do Tratamento de Valores Ausentes na Interpretabilidade e GeneralizaÃ§Ã£o do Modelo

A escolha do tratamento dos dados faltantes influencia a interpretabilidade e a capacidade de generalizaÃ§Ã£o dos modelos.

*   **ImputaÃ§Ã£o Simples (MÃ©dia/Mediana):** A imputaÃ§Ã£o com a mÃ©dia ou mediana, embora seja simples, pode distorcer as relaÃ§Ãµes nos dados, e levar a modelos com menor qualidade preditiva. A imputaÃ§Ã£o simples tambÃ©m introduz *bias* nos modelos, principalmente quando os dados nÃ£o sÃ£o MCAR. A sua interpretaÃ§Ã£o tambÃ©m pode ser mais difÃ­cil, pois os valores imputados sÃ£o valores que nÃ£o foram medidos diretamente, e a informaÃ§Ã£o utilizada para a imputaÃ§Ã£o nÃ£o estÃ¡ claramente relacionada ao modelo final.
*  **ImputaÃ§Ã£o Condicional e MÃºltipla:** Modelos de imputaÃ§Ã£o condicional ou a imputaÃ§Ã£o mÃºltipla buscam levar em consideraÃ§Ã£o a incerteza relacionada aos dados faltantes e as relaÃ§Ãµes entre as variÃ¡veis.  O uso de imputaÃ§Ã£o mais complexas pode aumentar a capacidade do modelo de lidar com dados faltantes, e tambÃ©m modelar relaÃ§Ãµes mais complexas.
*   **Categoria "Ausente":**  A utilizaÃ§Ã£o da categoria "ausente" permite que o modelo aprenda o efeito da ausÃªncia de informaÃ§Ã£o sobre a resposta.  A sua utilizaÃ§Ã£o Ã© Ãºtil quando a ausÃªncia dos dados tem algum significado, e pode contribuir para uma modelagem mais completa do problema.
*   ***Surrogate Splits*:** A utilizaÃ§Ã£o de *surrogate splits* permite lidar com dados ausentes de forma implÃ­cita, o que evita a necessidade de imputaÃ§Ã£o. A utilizaÃ§Ã£o de *surrogate splits* Ã© mais apropriada quando hÃ¡ correlaÃ§Ã£o entre preditores, e a sua escolha depende do critÃ©rio de impureza da Ã¡rvore, e dos preditores que foram definidos como mais relevantes.

A escolha da forma de lidar com dados faltantes deve ser feita de forma cuidadosa, considerando a natureza dos dados e do modelo, o *trade-off* entre *bias* e variÃ¢ncia e tambÃ©m o seu impacto na interpretabilidade do modelo. O tratamento de dados faltantes Ã© um componente importante na modelagem estatÃ­stica, e a escolha apropriada de cada tÃ©cnica pode melhorar o desempenho do modelo e a sua capacidade de generalizaÃ§Ã£o para dados nÃ£o vistos.

###  A RelaÃ§Ã£o com MÃ©todos de RegularizaÃ§Ã£o e SeleÃ§Ã£o de VariÃ¡veis

A escolha do mÃ©todo para lidar com dados faltantes se relaciona diretamente com as tÃ©cnicas de regularizaÃ§Ã£o e seleÃ§Ã£o de variÃ¡veis. MÃ©todos de imputaÃ§Ã£o que introduzem *bias* podem ser combinados com regularizaÃ§Ã£o para evitar o *overfitting*.  MÃ©todos de seleÃ§Ã£o de variÃ¡veis podem ser utilizados para diminuir o impacto de valores ausentes em dados com alta dimensionalidade. A utilizaÃ§Ã£o de uma metodologia adequada para lidar com dados ausentes garante que os resultados sejam mais robustos e que a modelagem seja feita de forma apropriada aos dados.

### Perguntas TeÃ³ricas AvanÃ§adas: Como os mecanismos de Missing Not At Random (MNAR) afetam as propriedades assintÃ³ticas dos estimadores, e como os modelos de seleÃ§Ã£o (selection models) e *pattern mixture* tentam modelar a distribuiÃ§Ã£o dos dados sob essas hipÃ³teses, e como essa modelagem se relaciona com o conceito de *identifiability*?

**Resposta:**

Os mecanismos de Missing Not At Random (MNAR) afetam as propriedades assintÃ³ticas dos estimadores, como a consistÃªncia e a ausÃªncia de *bias*, e os modelos de seleÃ§Ã£o (*selection models*) e *pattern mixture* sÃ£o abordagens para modelar dados sob estas hipÃ³teses. A modelagem de dados MNAR Ã© complexa e desafiadora, e a capacidade de identificar e modelar a sua influÃªncia nos resultados Ã© fundamental para a modelagem estatÃ­stica.

Dados sÃ£o considerados MNAR quando a probabilidade de um valor ser ausente depende do valor que estÃ¡ faltando e de informaÃ§Ãµes observadas, e podem ser expressos como:

$$
P(R|Z) = P(R|Z_{obs}, Z_{mis})
$$
onde $R$ Ã© uma variÃ¡vel indicadora que representa a ausÃªncia de informaÃ§Ã£o, $Z$ Ã© o conjunto de dados (observados e ausentes), $Z_{obs}$ sÃ£o as observaÃ§Ãµes e $Z_{mis}$ os dados faltantes.  Sob este cenÃ¡rio, os dados ausentes nÃ£o sÃ£o aleatÃ³rios e devem ser modelados.

Modelos de seleÃ§Ã£o (*selection models*) buscam modelar a distribuiÃ§Ã£o dos dados observados e a distribuiÃ§Ã£o da ausÃªncia dos dados simultaneamente. Esses modelos utilizam um processo que divide a probabilidade conjunta dos dados observados e o mecanismo de ausÃªncia:

$$
P(Z, R) = P(Z|R) P(R)
$$

Modelos de seleÃ§Ã£o buscam modelar como a probabilidade de o dado estar ausente estÃ¡ relacionada aos valores que estÃ£o faltando e aos valores que foram observados. Em geral, para a modelagem de dados MNAR com mÃ©todos de seleÃ§Ã£o, deve haver informaÃ§Ã£o disponÃ­vel sobre a estrutura dos dados ausentes.

Modelos de *pattern mixture* modelam a distribuiÃ§Ã£o dos dados condicionando ao padrÃ£o de valores ausentes:

$$
P(Z,R) = P(Z|R) P(R)
$$

onde a probabilidade $P(Z|R)$ Ã© modelada de forma diferente para cada padrÃ£o de dados faltantes, o que permite avaliar como a distribuiÃ§Ã£o de dados Ã© afetada pela presenÃ§a de valores ausentes.  A sua implementaÃ§Ã£o Ã© mais difÃ­cil em modelos com muitos preditores e com muitos padrÃµes de dados faltantes.  Modelos *pattern-mixture* buscam modelos que capturem a natureza do mecanismo de dados faltantes, e se os dados seguem distribuiÃ§Ãµes diferentes de acordo com os padrÃµes de dados faltantes.

Sob a hipÃ³tese MNAR, os estimadores obtidos com modelos que nÃ£o levam em consideraÃ§Ã£o o mecanismo de dados faltantes sÃ£o viesados e inconsistentes. As propriedades assintÃ³ticas dos estimadores sÃ£o afetadas, e os resultados da modelagem podem nÃ£o ser confiÃ¡veis. Modelos de seleÃ§Ã£o e *pattern mixture* buscam mitigar esse viÃ©s, mas requerem um entendimento detalhado sobre o mecanismo gerador dos dados faltantes, e suas propriedades. A identificabilidade do modelo, a sua capacidade de estimar os parÃ¢metros, Ã© um componente importante na escolha do modelo adequado para dados MNAR. Modelos com um grande nÃºmero de parÃ¢metros podem nÃ£o ser identificÃ¡veis sem restriÃ§Ãµes adicionais.

```mermaid
graph LR
    subgraph "MNAR Modeling"
        direction TB
        A["Missing Not at Random (MNAR)"]
        B["Selection Models"]
        C["Pattern Mixture Models"]
        A --> B
        A --> C
        B --> D["P(Z, R) = P(Z|R) P(R)"]
        C --> E["P(Z,R) = P(Z|R) P(R)  (different for each R pattern)"]
        D --> F["Model both data and missingness"]
        E --> G["Model data distribution by missing pattern"]
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Considere um estudo sobre a relaÃ§Ã£o entre depressÃ£o e renda. Suponha que pessoas com depressÃ£o severa sÃ£o menos propensas a relatar sua renda, e a probabilidade de nÃ£o relatar a renda depende da prÃ³pria renda (pessoas com baixa renda e depressÃ£o severa sÃ£o mais propensas a nÃ£o relatar).
>
> Nesse caso, temos dados MNAR. Modelos de seleÃ§Ã£o ou *pattern mixture* seriam necessÃ¡rios.
>
> Um modelo de seleÃ§Ã£o poderia modelar a probabilidade de nÃ£o relatar a renda como uma funÃ§Ã£o da renda real e da severidade da depressÃ£o. Por exemplo:
>
> $P(R = 1 | Z) = \text{logit}^{-1}(\alpha + \beta_1 \text{renda} + \beta_2 \text{depressao})$
>
> Onde R Ã© 1 se a renda nÃ£o Ã© relatada e 0 caso contrÃ¡rio.
>
> Um modelo *pattern mixture* poderia modelar a distribuiÃ§Ã£o da renda separadamente para os grupos onde a renda foi relatada e onde a renda nÃ£o foi relatada, e o modelo pode estimar distribuiÃ§Ãµes diferentes para cada padrÃ£o de dados.
>
> A nÃ£o utilizaÃ§Ã£o desses mÃ©todos levaria a estimativas viesadas da relaÃ§Ã£o entre depressÃ£o e renda, pois a ausÃªncia da informaÃ§Ã£o Ã© relacionada com a prÃ³pria renda.

**Lemma 5:** *A hipÃ³tese de dados faltantes que nÃ£o sÃ£o aleatÃ³rios (MNAR) afeta as propriedades estatÃ­sticas dos estimadores, como a sua consistÃªncia e *bias*. Modelos de seleÃ§Ã£o e modelos *pattern mixture* buscam modelar a distribuiÃ§Ã£o dos dados sob a hipÃ³tese de dados faltantes MNAR, e sÃ£o importantes para que os parÃ¢metros sejam estimados de forma mais precisa e adequada*.  A utilizaÃ§Ã£o de modelos adequados para dados MNAR requer um cuidado maior na modelagem [^9.6].

**CorolÃ¡rio 5:** *A modelagem de dados MNAR Ã© um desafio na modelagem estatÃ­stica e requer modelos mais complexos que modelem o mecanismo que gera os dados ausentes e, tambÃ©m, a distribuiÃ§Ã£o dos dados observados.  As abordagens para lidar com dados MNAR devem ser consideradas na anÃ¡lise e construÃ§Ã£o de modelos estatÃ­sticos robustos e com boa capacidade preditiva. A escolha inadequada dos modelos para dados MNAR pode levar a resultados viesados e pouco confiÃ¡veis*. A escolha do modelo para dados MNAR Ã© importante para a validade dos resultados [^4.3.3].

> âš ï¸ **Ponto Crucial**: A escolha da abordagem para lidar com dados MNAR (Missing Not At Random) afeta a consistÃªncia, o *bias* e as propriedades assintÃ³ticas dos estimadores, e a escolha de um modelo deve levar em consideraÃ§Ã£o o mecanismo gerador dos dados ausentes. MÃ©todos que nÃ£o consideram o mecanismo de dados ausentes podem levar a resultados viesados e modelos com baixa capacidade preditiva. A escolha adequada de modelos e abordagens de imputaÃ§Ã£o para dados faltantes Ã© um aspecto importante da modelagem estatÃ­stica [^4.3.2].

### ConclusÃ£o

Este capÃ­tulo apresentou um resumo das principais abordagens para modelagem estatÃ­stica, com foco na escolha de modelos, mÃ©todos de otimizaÃ§Ã£o, funÃ§Ãµes de ligaÃ§Ã£o, mÃ©tricas de avaliaÃ§Ã£o e tratamento de valores ausentes, com foco nas propriedades de cada abordagem, e como ela se relaciona com os modelos de aprendizado supervisionado.  A integraÃ§Ã£o de diferentes ferramentas e tÃ©cnicas de modelagem oferece um conjunto poderoso de ferramentas para a modelagem de dados complexos e com diferentes tipos de relaÃ§Ãµes. O conhecimento das diferentes abordagens e a capacidade de analisar os *trade-offs* entre flexibilidade, interpretabilidade, estabilidade e generalizaÃ§Ã£o Ã© fundamental para a modelagem estatÃ­stica avanÃ§ada.

### Footnotes

[^4.1]: "In this chapter we begin our discussion of some specific methods for super-vised learning. These techniques each assume a (different) structured form for the unknown regression function, and by doing so they finesse the curse of dimensionality. Of course, they pay the possible price of misspecifying the model, and so in each case there is a tradeoff that has to be made." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.2]: "Regression models play an important role in many data analyses, providing prediction and classification rules, and data analytic tools for understand-ing the importance of different inputs." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.3]: "In this section we describe a modular algorithm for fitting additive models and their generalizations. The building block is the scatterplot smoother for fitting nonlinear effects in a flexible way. For concreteness we use as our scatterplot smoother the cubic smoothing spline described in Chapter 5." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.3.1]:  "The additive model has the form $Y = \alpha + \sum_{j=1}^p f_j(X_j) + \varepsilon$, where the error term $\varepsilon$ has mean zero." * (Trecho de "Additive Models, Trees, and Related Methods")*

[^4.3.2]:   "Given observations $x_i, y_i$, a criterion like the penalized sum of squares (5.9) of Section 5.4 can be specified for this problem, $PRSS(\alpha, f_1, f_2,\ldots, f_p) = \sum_i^N (y_i - \alpha - \sum_j^p f_j(x_{ij}))^2 + \sum_j^p \lambda_j \int (f_j''(t_j))^2 dt_j$" * (Trecho de "Additive Models, Trees, and Related Methods")*

[^4.3.3]: "where the $\lambda_j > 0$ are tuning parameters. It can be shown that the minimizer of (9.7) is an additive cubic spline model; each of the functions $f_j$ is a cubic spline in the component $X_j$, with knots at each of the unique values of $x_{ij}$, $i = 1,\ldots, N$." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.4]: "For two-class classification, recall the logistic regression model for binary data discussed in Section 4.4. We relate the mean of the binary response $\mu(X) = Pr(Y = 1|X)$ to the predictors via a linear regression model and the logit link function:  $\log(\mu(X)/(1 â€“ \mu(X)) = \alpha + \beta_1 X_1 + \ldots + \beta_pX_p$." * (Trecho de "Additive Models, Trees, and Related Methods")*

[^4.4.1]: "The additive logistic regression model replaces each linear term by a more general functional form: $\log(\mu(X)/(1 â€“ \mu(X))) = \alpha + f_1(X_1) + \cdots + f_p(X_p)$, where again each $f_j$ is an unspecified smooth function." * (Trecho de "Additive Models, Trees, and Related Methods")*

[^4.4.2]: "While the non-parametric form for the functions $f_j$ makes the model more flexible, the additivity is retained and allows us to interpret the model in much the same way as before. The additive logistic regression model is an example of a generalized additive model." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.4.3]: "In general, the conditional mean $\mu(X)$ of a response $Y$ is related to an additive function of the predictors via a link function $g$:  $g[\mu(X)] = \alpha + f_1(X_1) + \cdots + f_p(X_p)$." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.4.4]:  "Examples of classical link functions are the following: $g(\mu) = \mu$ is the identity link, used for linear and additive models for Gaussian response data." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.4.5]: "$g(\mu) = \text{logit}(\mu)$ as above, or $g(\mu) = \text{probit}(\mu)$, the probit link function, for modeling binomial probabilities. The probit function is the inverse Gaussian cumulative distribution function: $\text{probit}(\mu) = \Phi^{-1}(\mu)$." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.5]: "All three of these arise from exponential family sampling models, which in addition include the gamma and negative-binomial distributions. These families generate the well-known class of generalized linear models, which are all extended in the same way to generalized additive models." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.5.1]: "The functions $f_j$ are estimated in a flexible manner, using an algorithm whose basic building block is a scatterplot smoother. The estimated func-tion $f_j$ can then reveal possible nonlinearities in the effect of $X_j$. Not all of the functions $f_j$ need to be nonlinear." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^4.5.2]: "We can easily mix in linear and other parametric forms with the nonlinear terms, a necessity when some of the inputs are qualitative variables (factors)." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^9.1]: "In this chapter we begin our discussion of some specific methods for super-vised learning. These techniques each assume a (different) structured form for the unknown regression function, and by doing so they finesse the curse of dimensionality. Of course, they pay the possible price of misspecifying the model, and so in each case there is a tradeoff that has to be made. We describe five related techniques: generalized additive models, trees, multivariate adaptive regression splines, the patient rule induction method, and hierarchical mixtures of experts." *(Trecho de "Additive Models, Trees, and Related Methods")*

[^9.6]:  "Suppose our data has some missing predictor values in some or all of the variables. We might discard any observation with some missing values, but this could lead to serious depletion of the training set. Alternatively we might try to fill in (impute) the missing values, with say the mean of that predictor over the nonmissing observations." *(Trecho de "Additive Models, Trees, and Related Methods")*
