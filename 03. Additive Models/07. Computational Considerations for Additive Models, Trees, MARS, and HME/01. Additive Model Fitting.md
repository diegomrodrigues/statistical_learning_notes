## Computational Cost of Additive Model Fitting

### Introdução
Este capítulo explora as considerações computacionais envolvidas no ajuste de modelos aditivos, árvores, MARS (Multivariate Adaptive Regression Splines) e HME (Hierarchical Mixtures of Experts). O foco principal deste capítulo é detalhar a complexidade computacional associada ao ajuste de modelos aditivos, um aspecto crucial para a aplicação eficiente desses modelos em análise de dados e aprendizado de máquina. Em continuidade ao que foi discutido nos capítulos anteriores [^9], onde foram introduzidas técnicas que utilizam funções de base predefinidas para alcançar não linearidades, este capítulo se aprofunda em métodos estatísticos flexíveis e automáticos para identificar e caracterizar efeitos de regressão não lineares.

### Conceitos Fundamentais
O ajuste de modelos aditivos envolve a aplicação repetida de métodos de suavização ou regressão unidimensional [^334]. A complexidade computacional é influenciada pelo número de ciclos do algoritmo de *backfitting* ($m$) e pelo número de preditores ($p$). Assim, o número total de operações é dado por $m \cdot p$, onde $m$ geralmente é menor que 20 [^334].

Para *cubic smoothing splines*, são necessárias $N \log N$ operações para uma ordenação inicial e $N$ operações para o ajuste da spline [^334]. Portanto, o custo total para o ajuste de um modelo aditivo com *cubic smoothing splines* é da ordem de $pN \log N + mpN$, onde o termo $pN \log N$ domina o custo computacional [^334].

**Algoritmo de Backfitting**: O algoritmo de *backfitting* é uma técnica iterativa usada para estimar as funções $f_j$ em um modelo aditivo. O algoritmo funciona atualizando cada função $f_j$ enquanto mantém as outras funções fixas, repetindo este processo até que as estimativas das funções $f_j$ converjam [^298].

**Complexidade Computacional do Algoritmo de Backfitting**: Cada iteração do algoritmo de *backfitting* requer a aplicação de um *scatterplot smoother* para cada preditor [^296]. Se utilizarmos *cubic smoothing splines* como *scatterplot smoother*, o custo computacional para cada iteração será $O(pN \log N)$, onde $p$ é o número de preditores e $N$ é o número de observações [^334]. Como o algoritmo de *backfitting* geralmente converge em um número pequeno de iterações ($m < 20$), o custo total do algoritmo é aproximadamente $O(mpN \log N)$ [^334].

**Otimização e Ajuste de Parâmetros**: O ajuste de modelos aditivos, conforme descrito na seção 9.1.1 [^297], envolve a minimização de uma soma penalizada de quadrados (PRSS), dada por:

$$
PRSS(a, f_1, f_2, ..., f_p) = \sum_{i=1}^{N} \left(Y_i - a - \sum_{j=1}^{p} f_j(X_{ij})\right)^2 + \sum_{j=1}^{p} \lambda_j \int [f_j''(t_j)]^2 dt_j,
$$

onde $\lambda_j > 0$ são os parâmetros de ajuste. Minimizar esta expressão leva a um modelo spline cúbico aditivo, onde cada função $f_j$ é uma spline cúbica [^297]. A complexidade computacional desta minimização é influenciada pela escolha dos parâmetros $\lambda_j$.

### Conclusão
Em resumo, o ajuste de modelos aditivos requer um número considerável de operações computacionais, especialmente quando se utilizam *cubic smoothing splines*. A complexidade total é da ordem de $pN \log N + mpN$, onde o termo $pN \log N$ domina o custo. A escolha de métodos de suavização mais eficientes e a otimização do número de ciclos do algoritmo de *backfitting* podem reduzir o custo computacional. A compreensão dessas considerações computacionais é fundamental para a aplicação eficaz de modelos aditivos em problemas de análise de dados e aprendizado de máquina, permitindo a seleção de modelos e parâmetros que equilibrem precisão e eficiência computacional.

### Referências
[^334]: Página 334 do documento original.
[^9]: Páginas 295-304 do documento original.
[^296]: Página 296 do documento original.
[^297]: Página 297 do documento original.
[^298]: Página 298 do documento original.
<!-- END -->