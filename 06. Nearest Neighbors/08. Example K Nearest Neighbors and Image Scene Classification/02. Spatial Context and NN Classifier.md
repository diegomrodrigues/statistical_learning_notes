## Utiliza√ß√£o do Contexto Espacial com 8-Vizinhos e um Classificador 5-NN: Alta Performance na Classifica√ß√£o de Imagens de Sat√©lite

```mermaid
graph LR
    subgraph "Feature Extraction"
        direction TB
        A["Central Pixel"]
        B["8 Neighbors"]
        C["Combine Spectral Data"]
        A & B --> C
    end
    subgraph "Classification"
        direction TB
        D["Feature Vector (36 Dimensions)"]
        E["5-NN Classifier"]
        C --> D
        D --> E
    end
    E --> F["Classification Output"]
```

### Introdu√ß√£o

Este cap√≠tulo explora a utiliza√ß√£o do **contexto espacial**, por meio da informa√ß√£o dos 8 vizinhos imediatos de um pixel, e sua aplica√ß√£o em conjunto com um classificador **5-vizinhos mais pr√≥ximos (5-NN)** para obter alta performance na classifica√ß√£o de imagens de sat√©lite [^13.3.2]. O uso do contexto espacial, ou seja, a inclus√£o de informa√ß√µes dos pixels vizinhos no processo de classifica√ß√£o, busca agregar informa√ß√µes contextuais para aumentar a capacidade de discrimina√ß√£o e tornar a classifica√ß√£o mais robusta. Analisaremos como a extra√ß√£o de *features* a partir do pixel central e seus 8 vizinhos resulta em um espa√ßo de *features* de alta dimens√£o, e como o 5-NN √© aplicado nesse espa√ßo para obter resultados satisfat√≥rios na classifica√ß√£o. Discutiremos tamb√©m a import√¢ncia de combinar a informa√ß√£o espectral e espacial no processo de classifica√ß√£o de imagens de sat√©lite.

### O Contexto Espacial: Import√¢ncia das Informa√ß√µes da Vizinhan√ßa

A utiliza√ß√£o do **contexto espacial** na classifica√ß√£o de imagens de sat√©lite √© uma abordagem que se baseia na ideia de que a informa√ß√£o dos pixels vizinhos de um dado pixel pode auxiliar a determinar sua classe com maior precis√£o [^13.3.2]. Em vez de utilizar apenas a informa√ß√£o espectral do pixel central, a inclus√£o de informa√ß√µes de seus vizinhos permite agregar conhecimento sobre a regi√£o local, o que melhora a capacidade de discrimina√ß√£o entre as classes.

A import√¢ncia do contexto espacial reside no fato de que pixels vizinhos de uma imagem de sat√©lite tendem a pertencer √† mesma classe ou a classes que est√£o espacialmente relacionadas. Por exemplo, em uma imagem de cenas agr√≠colas, a presen√ßa de vegeta√ß√£o em um pixel pode indicar que seus vizinhos tamb√©m t√™m uma probabilidade maior de pertencer a categorias relacionadas √† vegeta√ß√£o.

A inclus√£o do contexto espacial pode ser feita por meio de diversas t√©cnicas, como a extra√ß√£o de *features* de vizinhan√ßa (m√©dia, desvio padr√£o, histogramas, etc.) ou a utiliza√ß√£o de modelos que explicitamente modelam as rela√ß√µes espaciais entre os pixels, como as redes neurais convolucionais (CNN). No caso do m√©todo descrito no contexto, as *features* s√£o extra√≠das dos 8 vizinhos mais pr√≥ximos de cada pixel, al√©m do pr√≥prio pixel.

**Lemma 109:** A informa√ß√£o contextual, obtida da vizinhan√ßa de um pixel em uma imagem de sat√©lite, permite melhorar a capacidade de classifica√ß√£o por meio da incorpora√ß√£o de informa√ß√µes sobre a estrutura espacial das classes.
*Prova*:  A informa√ß√£o sobre as classes dos vizinhos fornece uma pista sobre a regi√£o local e o padr√£o dos dados que n√£o pode ser capturada apenas pela informa√ß√£o de um √∫nico pixel. $\blacksquare$

**Corol√°rio 109:** A combina√ß√£o das informa√ß√µes espectrais e espaciais aumenta a capacidade de discrimina√ß√£o do modelo, o que leva a uma classifica√ß√£o mais precisa e robusta.

> ‚ö†Ô∏è **Nota Importante**: A utiliza√ß√£o do contexto espacial, por meio das informa√ß√µes da vizinhan√ßa de um pixel, √© uma forma eficaz de agregar conhecimento para a classifica√ß√£o de imagens de sat√©lite.

> ‚ùó **Ponto de Aten√ß√£o**:  A escolha do tamanho da vizinhan√ßa e das *features* extra√≠das da vizinhan√ßa influencia o desempenho do modelo, e a escolha adequada desses par√¢metros √© um passo importante no desenvolvimento de sistemas de classifica√ß√£o de imagens de sat√©lite.

### Extra√ß√£o de *Features* com Vizinhos: Um Espa√ßo de 36 Dimens√µes

A extra√ß√£o de *features* utilizando o contexto espacial, que considera um pixel central e seus 8 vizinhos imediatos, resulta em um espa√ßo de *features* com 36 dimens√µes [^13.3.2]. Essa alta dimensionalidade surge da combina√ß√£o das informa√ß√µes espectrais de cada um desses pixels.

```mermaid
graph LR
    subgraph "Feature Vector Calculation"
        direction TB
        A["Pixel (1 central)"]
        B["8 Neighbors"]
        C["4 Spectral Channels per Pixel"]
        D["Feature Vector: 9 Pixels * 4 Channels = 36 Features"]
        A & B --> C
        C --> D
    end
```

Em um problema simulado onde cada pixel possui 4 canais espectrais (duas bandas no espectro vis√≠vel e duas no infravermelho), ao extrair as informa√ß√µes dos 9 pixels (1 central + 8 vizinhos), e de cada um dos 4 canais, obtemos um vetor de *features* com 36 componentes:

$$9 \text{ pixels} \times 4 \text{ canais espectrais} = 36 \text{ features}$$

O pixel central, e seus 8 vizinhos, cont√™m informa√ß√µes sobre a regi√£o local, que podem ser relevantes para a identifica√ß√£o da classe do pixel central. A combina√ß√£o de informa√ß√µes espectrais e espaciais em um vetor de *features* de alta dimens√£o oferece uma representa√ß√£o mais completa da estrutura dos dados na imagem de sat√©lite. Essa representa√ß√£o captura as rela√ß√µes entre pixels vizinhos, o que pode ser fundamental para a modelagem da complexidade das cenas do mundo real.

> üí° **Exemplo Num√©rico:**
> Imagine que temos um pixel central com valores espectrais nos 4 canais como [0.2, 0.5, 0.7, 0.1]. Seu vizinho da direita tem valores [0.3, 0.6, 0.8, 0.2], o vizinho de baixo [0.1, 0.4, 0.6, 0.3], e assim por diante para todos os 8 vizinhos. Para extrair as *features*, concatenamos todos esses valores em um √∫nico vetor. Isso resultaria em um vetor de 36 dimens√µes:
>
>  $[0.2, 0.5, 0.7, 0.1, 0.3, 0.6, 0.8, 0.2, 0.1, 0.4, 0.6, 0.3, ..., \text{valores dos outros vizinhos}]$
>
> Cada bloco de 4 valores representa as informa√ß√µes espectrais de um pixel. Esse vetor de 36 dimens√µes ser√° usado para classificar o pixel central.

**Lemma 110:** A extra√ß√£o de *features* com um pixel central e seus 8 vizinhos imediatos, com 4 canais espectrais, resulta em um espa√ßo de *features* de alta dimens√£o (36 dimens√µes), que permite representar as rela√ß√µes espaciais e espectrais da imagem de sat√©lite.
*Prova*: A combina√ß√£o das informa√ß√µes espectrais de cada um dos 9 pixels em 4 diferentes canais leva a um vetor com 36 dimens√µes. $\blacksquare$

**Corol√°rio 110:** O uso de informa√ß√µes contextuais aumenta a dimensionalidade do espa√ßo de *features*, o que exige que o modelo seja capaz de lidar com problemas de alta dimens√£o.

> ‚ö†Ô∏è **Nota Importante**:  A extra√ß√£o de *features* utilizando um pixel central e seus 8 vizinhos imediatos resulta em um espa√ßo de *features* de alta dimens√£o (36 dimens√µes), que combina informa√ß√µes espectrais e espaciais da imagem de sat√©lite.

> ‚ùó **Ponto de Aten√ß√£o**: Embora o uso de *features* de vizinhan√ßa aumente a capacidade de discrimina√ß√£o do modelo, ele tamb√©m aumenta a complexidade computacional e pode gerar problemas relacionados √† maldi√ß√£o da dimensionalidade.

### Classifica√ß√£o com 5-NN: Alta Performance em Espa√ßo de 36 Dimens√µes

No espa√ßo de *features* de 36 dimens√µes, o **classificador 5-vizinhos mais pr√≥ximos (5-NN)** demonstrou um desempenho not√°vel na classifica√ß√£o de imagens de sat√©lite [^13.3.2]. A escolha do valor de $k=5$ foi feita experimentalmente, e diferentes valores podem levar a resultados diferentes, conforme discutido em se√ß√µes anteriores.

```mermaid
graph LR
    subgraph "5-NN Classification"
        direction TB
        A["Query Point: Feature Vector (36 Dimensions)"]
        B["Training Data: Feature Vectors with Class Labels"]
        C["Calculate Distances"]
        D["Find 5 Nearest Neighbors"]
        E["Majority Vote of 5 Neighbors"]
        F["Class Label Assigned"]
        A & B --> C
        C --> D
        D --> E
        E --> F
    end
```

Ao utilizar o 5-NN nesse espa√ßo de alta dimens√£o, o modelo busca os 5 pontos de treinamento mais pr√≥ximos no espa√ßo de *features* de 36 dimens√µes e atribui o ponto de consulta √† classe mais frequente entre esses vizinhos. A capacidade do 5-NN de obter bom desempenho nesse espa√ßo de alta dimens√£o se deve, principalmente, a sua capacidade de explorar a informa√ß√£o local dos vizinhos para realizar a classifica√ß√£o. A extra√ß√£o da informa√ß√£o de vizinhan√ßa, e de diferentes canais espectrais, permite que o algoritmo capture de forma mais eficaz as regi√µes relevantes para a classifica√ß√£o.

A escolha do valor $k=5$ permite equilibrar o vi√©s e a vari√¢ncia do modelo. Um valor muito pequeno de $k$ tornaria o modelo muito sens√≠vel ao ru√≠do e √† variabilidade local dos dados, enquanto um valor muito grande de $k$ tornaria o modelo mais enviesado e com dificuldade em capturar detalhes espec√≠ficos da regi√£o de decis√£o.

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um pixel para classificar (o "ponto de consulta") e seu vetor de *features* de 36 dimens√µes √© $x_q$. Nosso conjunto de treinamento consiste em v√°rios pixels com seus respectivos vetores de *features* de 36 dimens√µes e suas classes. O algoritmo 5-NN calcula a dist√¢ncia (por exemplo, dist√¢ncia euclidiana) entre $x_q$ e todos os vetores de *features* do conjunto de treinamento.
>
> Digamos que os 5 vetores mais pr√≥ximos a $x_q$ s√£o:
>
> - $x_1$: Classe 'Vegeta√ß√£o'
> - $x_2$: Classe 'Vegeta√ß√£o'
> - $x_3$: Classe 'Solo'
> - $x_4$: Classe 'Constru√ß√£o'
> - $x_5$: Classe 'Vegeta√ß√£o'
>
> O classificador 5-NN atribui o pixel de consulta √† classe 'Vegeta√ß√£o', pois √© a classe mais frequente entre seus 5 vizinhos mais pr√≥ximos.

**Lemma 111:** O classificador 5-NN no espa√ßo de 36 dimens√µes, gerado pela extra√ß√£o de *features* do pixel central e seus vizinhos, resulta em alta performance na classifica√ß√£o de imagens de sat√©lite.
*Prova*: O uso do contexto espacial, combinado com a abordagem do k-NN, permite capturar rela√ß√µes espaciais nos dados que melhoram a qualidade da classifica√ß√£o. $\blacksquare$

**Corol√°rio 111:** A escolha de k=5 √© um valor razo√°vel para balancear a vari√¢ncia e vi√©s do modelo, considerando que valores menores podem aumentar a vari√¢ncia e valores muito altos o vi√©s.

> ‚ö†Ô∏è **Nota Importante**: O classificador 5-NN no espa√ßo de 36 dimens√µes permite utilizar o contexto espacial para melhorar o desempenho da classifica√ß√£o de imagens de sat√©lite.

> ‚ùó **Ponto de Aten√ß√£o**:  A escolha do valor $k=5$ foi obtida de forma emp√≠rica, e a otimiza√ß√£o desse par√¢metro utilizando t√©cnicas de valida√ß√£o cruzada pode melhorar o desempenho do modelo.

### Compara√ß√£o com Outros M√©todos: k-NN como Ferramenta Base

No estudo de caso descrito, o k-NN com a utiliza√ß√£o do contexto espacial e a escolha de um n√∫mero de vizinhos adequado apresentou um desempenho superior em compara√ß√£o com outros m√©todos de classifica√ß√£o, como o LVQ, CART (Classification and Regression Tree) e redes neurais [^13.3.2]. Isso demonstra que o k-NN, apesar de sua simplicidade conceitual, √© uma ferramenta poderosa para lidar com problemas complexos de classifica√ß√£o de imagens de sat√©lite.

A utiliza√ß√£o da informa√ß√£o da vizinhan√ßa de cada pixel, atrav√©s da escolha de *features* do pixel central e seus vizinhos, aumenta a capacidade de discriminabilidade do modelo e permite que ele capture padr√µes locais importantes para a classifica√ß√£o. Essa abordagem, combinada com a classifica√ß√£o por vota√ß√£o majorit√°ria entre os $k$ vizinhos mais pr√≥ximos, resulta em um classificador robusto e eficiente.

O sucesso do k-NN nesse contexto ilustra que a simplicidade e a flexibilidade dos m√©todos *model-free* podem ser uma vantagem em problemas onde a complexidade dos dados e as caracter√≠sticas locais das distribui√ß√µes s√£o os fatores mais importantes para a qualidade da classifica√ß√£o.

> üí° **Exemplo Num√©rico:**
>
> Para ilustrar a compara√ß√£o com outros m√©todos, vamos considerar um cen√°rio simplificado com um conjunto de teste de 100 pixels de uma imagem de sat√©lite e duas classes: 'Floresta' e 'N√£o-Floresta'. Ap√≥s treinar diferentes modelos, obtivemos as seguintes taxas de acerto (acur√°cia):
>
> | M√©todo              | Acur√°cia (%) |
> |----------------------|-------------|
> | 5-NN com contexto espacial | 92          |
> | LVQ                 | 85          |
> | CART                | 88          |
> | Rede Neural         | 90          |
>
> Neste exemplo, o 5-NN com contexto espacial teve a maior acur√°cia, indicando que ele classificou corretamente mais pixels do que os outros m√©todos. Este √© um resultado similar ao encontrado no estudo de caso original, onde o k-NN se destacou em rela√ß√£o a outros m√©todos.

**Lemma 112:** A utiliza√ß√£o de k-NN com dados de vizinhan√ßa para classifica√ß√£o de imagens de sat√©lite apresenta alta performance devido √† capacidade de adapta√ß√£o do modelo e √† sua natureza *model-free*.
*Prova*: O k-NN √© capaz de modelar fronteiras de decis√£o complexas devido a sua abordagem baseada nas informa√ß√µes locais e de cada ponto da regi√£o, e sem a necessidade de um ajuste pr√©vio a um modelo param√©trico. $\blacksquare$

**Corol√°rio 112:** O k-NN, embora simples, √© um modelo robusto e eficaz que pode ser utilizado como base para a cria√ß√£o de m√©todos mais avan√ßados para classifica√ß√£o de imagens de sat√©lite.

> ‚ö†Ô∏è **Nota Importante**: O k-NN demonstrou bom desempenho na classifica√ß√£o de imagens de sat√©lite, superando outros m√©todos testados, o que evidencia a efic√°cia dessa abordagem em problemas complexos e com alta dimensionalidade.

> ‚ùó **Ponto de Aten√ß√£o**:  A combina√ß√£o da informa√ß√£o espectral com informa√ß√µes da vizinhan√ßa e a escolha cuidadosa do valor de $k$ s√£o fatores cruciais para o bom desempenho do k-NN na classifica√ß√£o de imagens de sat√©lite.

### Conclus√£o

A aplica√ß√£o do k-NN para classifica√ß√£o de imagens de sat√©lite, combinando a informa√ß√£o espectral e espacial por meio da extra√ß√£o de *features* de vizinhan√ßa, e a utiliza√ß√£o de um classificador 5-NN em um espa√ßo de 36 dimens√µes, demonstrou que essa abordagem √© capaz de obter alta performance em problemas reais de classifica√ß√£o. A flexibilidade e adaptabilidade do k-NN, aliadas a uma escolha adequada dos hiperpar√¢metros e √† utiliza√ß√£o de informa√ß√µes contextuais, tornam essa abordagem uma alternativa eficaz para o processamento e classifica√ß√£o de dados de sensoriamento remoto.

### Footnotes

[^13.3.2]: "The STATLOG project (Michie et al., 1994) used part of a LANDSAT image as a benchmark for classification (82 √ó 100 pixels). Figure 13.6 shows four heat-map images, two in the visible spectrum and two in the infrared, for an area of agricultural land in Australia...For each pixel we extracted an 8-neighbor feature map-the pixel itself and its 8 immediate neighbors (see Figure 13.7)...Then five-nearest-neighbors classification was carried out in this 36-dimensional feature space...Of all the methods used in the STATLOG project, including LVQ, CART, neural networks, linear discriminant analysis and many others, k-nearest-neighbors performed best on this task." *(Trecho de "13. Prototype Methods and Nearest-Neighbors")*

[^13.3]: "These classifiers are memory-based, and require no model to be fit. Given a query point xo, we find the k training points x(r), r = 1,..., k closest in distance to xo, and then classify using majority vote among the k neighbors." *(Trecho de "13. Prototype Methods and Nearest-Neighbors")*
