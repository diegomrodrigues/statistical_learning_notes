## Model Free Methods for Classification and Pattern Recognition

```mermaid
graph LR
    subgraph "Model-Free Classification Methods"
        direction TB
        A["Input Data: 'Feature Space'"]
        B["Prototype Methods: 'K-means', 'LVQ', 'Gaussian Mixtures'"]
        C["K-Nearest Neighbors: 'k-NN'"]
        D["Classification Output: 'Class Labels'"]
        A --> B
        A --> C
        B --> D
        C --> D
        style A fill:#f9f,stroke:#333,stroke-width:2px
        style D fill:#f9f,stroke:#333,stroke-width:2px
    end
```

### Introdu√ß√£o

Este cap√≠tulo explora m√©todos simples e essencialmente **model-free** para classifica√ß√£o e reconhecimento de padr√µes [^13.1]. Estas t√©cnicas, devido √† sua natureza n√£o estruturada, n√£o se prestam √† interpreta√ß√£o da rela√ß√£o entre as *features* e os resultados das classes, mas s√£o muito eficazes como motores de predi√ß√£o ‚Äú*black-box*‚Äù, frequentemente com desempenho superior em problemas de dados reais. Abordaremos tanto os m√©todos de prot√≥tipos quanto os de k-vizinhos mais pr√≥ximos, explorando suas caracter√≠sticas, vantagens e limita√ß√µes [^13.1]. Embora a t√©cnica do vizinho mais pr√≥ximo tamb√©m possa ser usada em regress√£o, seu desempenho n√£o √© t√£o favor√°vel em altas dimens√µes como na classifica√ß√£o, devido ao compromisso entre vi√©s e vari√¢ncia [^13.1].

### Conceitos Fundamentais

**Conceito 1: Problema de Classifica√ß√£o**

O problema de classifica√ß√£o, em geral, consiste em atribuir uma classe a um dado ponto de *feature space* com base em um conjunto de dados de treino. Os m√©todos lineares, como discutido anteriormente, buscam hiperplanos que separam as classes, o que pode introduzir vi√©s quando as fronteiras de decis√£o n√£o s√£o lineares [^4.1]. Abordagens *model-free*, por outro lado, utilizam a proximidade entre amostras ou a representa√ß√£o da distribui√ß√£o das classes atrav√©s de prot√≥tipos para realizar a classifica√ß√£o. No contexto de prot√≥tipos, dados de treino s√£o representados por um conjunto de pontos no espa√ßo de *features*. Estes prot√≥tipos, muitas vezes, n√£o s√£o exemplos diretos dos dados de treino, exceto no caso da classifica√ß√£o de 1-vizinho mais pr√≥ximo [^13.2]. Cada prot√≥tipo possui uma classe associada e a classifica√ß√£o de um novo ponto √© feita atribuindo-o √† classe do prot√≥tipo mais pr√≥ximo, onde a proximidade √© medida geralmente pela dist√¢ncia Euclidiana [^13.2].

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o com duas classes (A e B) e duas *features* (x1 e x2). Suponha que temos tr√™s prot√≥tipos:
> - Prot√≥tipo 1: (1, 1), Classe A
> - Prot√≥tipo 2: (2, 3), Classe B
> - Prot√≥tipo 3: (4, 2), Classe A
>
> Um novo ponto a ser classificado √© (2.5, 2). Para classific√°-lo, calculamos a dist√¢ncia Euclidiana entre este ponto e cada prot√≥tipo:
>
> - Dist√¢ncia ao Prot√≥tipo 1: $\sqrt{(2.5-1)^2 + (2-1)^2} = \sqrt{1.5^2 + 1^2} = \sqrt{2.25 + 1} = \sqrt{3.25} \approx 1.80$
> - Dist√¢ncia ao Prot√≥tipo 2: $\sqrt{(2.5-2)^2 + (2-3)^2} = \sqrt{0.5^2 + (-1)^2} = \sqrt{0.25 + 1} = \sqrt{1.25} \approx 1.12$
> - Dist√¢ncia ao Prot√≥tipo 3: $\sqrt{(2.5-4)^2 + (2-2)^2} = \sqrt{(-1.5)^2 + 0^2} = \sqrt{2.25} = 1.50$
>
> O ponto (2.5, 2) √© mais pr√≥ximo do Prot√≥tipo 2, que pertence √† Classe B. Portanto, o ponto √© classificado como Classe B.

**Lemma 1:** Em um espa√ßo de *features* normalizado (m√©dia zero e vari√¢ncia um), a dist√¢ncia Euclidiana √© uma medida apropriada para quantificar a proximidade entre os pontos, desde que os *features* sejam quantitativos.
*Prova*: A normaliza√ß√£o garante que *features* com diferentes escalas n√£o dominem a medida de dist√¢ncia. A dist√¢ncia Euclidiana √© definida como $d(x,y) = \sqrt{\sum_{i=1}^p (x_i - y_i)^2}$, onde $p$ √© o n√∫mero de *features*. Em um espa√ßo normalizado, cada *feature* contribui de maneira uniforme para a dist√¢ncia [^13.2]. $\blacksquare$

```mermaid
graph LR
    subgraph "Euclidean Distance Calculation"
        direction LR
        A["Input: 'Points x, y'"]
        B["Normalization: 'Mean 0, Variance 1'"]
         C["Distance: 'd(x,y) = sqrt(Œ£(xi - yi)¬≤) '"]
         B --> C
         A --> B
        D["Output: 'Distance Measure'"]
        C --> D
    end
```

**Conceito 2: Linear Discriminant Analysis (LDA) vs. M√©todos de Prot√≥tipos**

Enquanto o LDA busca uma transforma√ß√£o linear para projetar os dados em um subespa√ßo onde as classes s√£o mais separ√°veis, os m√©todos de prot√≥tipos aproximam as distribui√ß√µes das classes por um conjunto de pontos representativos [^4.3]. Em contraste com o LDA, os m√©todos de prot√≥tipos s√£o mais adequados para representar fronteiras de decis√£o irregulares, posicionando prot√≥tipos em locais estrat√©gicos no espa√ßo de *features* [^13.2]. A principal dificuldade desses m√©todos √© determinar quantos prot√≥tipos usar e onde posicion√°-los, o que varia conforme a t√©cnica utilizada [^13.2].

**Corol√°rio 1:** Uma vez que a dist√¢ncia Euclidiana √© invariante sob transla√ß√µes e rota√ß√µes no espa√ßo de *features*, o uso de dados normalizados n√£o altera as rela√ß√µes de proximidade entre os prot√≥tipos e os pontos de consulta.

**Conceito 3: Regress√£o Log√≠stica vs. M√©todos de k-vizinhos mais pr√≥ximos**

A regress√£o log√≠stica, como visto anteriormente, estima a probabilidade de um ponto pertencer a uma classe atrav√©s de uma fun√ß√£o log√≠stica sobre uma combina√ß√£o linear dos *features*, enquanto que os m√©todos de k-vizinhos mais pr√≥ximos classificam um ponto atrav√©s da vota√ß√£o majorit√°ria dos k vizinhos mais pr√≥ximos no espa√ßo de *features* [^4.4]. Os m√©todos de k-vizinhos s√£o *memory-based*, pois n√£o requerem um modelo a ser ajustado, utilizando todos os dados de treino durante a classifica√ß√£o. A principal desvantagem desses m√©todos √© sua alta complexidade computacional para grandes conjuntos de dados, visto que cada classifica√ß√£o requer o c√°lculo da dist√¢ncia para todos os pontos de treino [^13.3].

> üí° **Exemplo Num√©rico:**
>
> Considere um conjunto de dados de treino com 5 pontos e duas classes (A e B):
> - Ponto 1: (1, 1), Classe A
> - Ponto 2: (1, 2), Classe A
> - Ponto 3: (3, 2), Classe B
> - Ponto 4: (4, 1), Classe B
> - Ponto 5: (4, 3), Classe B
>
> Queremos classificar um novo ponto (2, 1.5) usando k-NN com k=3. Calculamos a dist√¢ncia Euclidiana para cada ponto de treino:
>
> - Dist√¢ncia ao Ponto 1: $\sqrt{(2-1)^2 + (1.5-1)^2} = \sqrt{1^2 + 0.5^2} = \sqrt{1.25} \approx 1.12$
> - Dist√¢ncia ao Ponto 2: $\sqrt{(2-1)^2 + (1.5-2)^2} = \sqrt{1^2 + (-0.5)^2} = \sqrt{1.25} \approx 1.12$
> - Dist√¢ncia ao Ponto 3: $\sqrt{(2-3)^2 + (1.5-2)^2} = \sqrt{(-1)^2 + (-0.5)^2} = \sqrt{1.25} \approx 1.12$
> - Dist√¢ncia ao Ponto 4: $\sqrt{(2-4)^2 + (1.5-1)^2} = \sqrt{(-2)^2 + 0.5^2} = \sqrt{4.25} \approx 2.06$
> - Dist√¢ncia ao Ponto 5: $\sqrt{(2-4)^2 + (1.5-3)^2} = \sqrt{(-2)^2 + (-1.5)^2} = \sqrt{6.25} = 2.5$
>
> Os 3 vizinhos mais pr√≥ximos s√£o os pontos 1, 2 e 3. Os pontos 1 e 2 s√£o da classe A e o ponto 3 √© da classe B. Por vota√ß√£o majorit√°ria (2 votos para A e 1 voto para B), o novo ponto (2, 1.5) √© classificado como Classe A.

> ‚ö†Ô∏è **Nota Importante**: M√©todos de prot√≥tipos s√£o mais flex√≠veis em modelar fronteiras de decis√£o complexas, enquanto m√©todos lineares podem sofrer com vi√©s quando tais fronteiras s√£o n√£o lineares [^13.2].

> ‚ùó **Ponto de Aten√ß√£o**: M√©todos baseados em *memory* (k-NN) podem ser computacionalmente caros para grandes conjuntos de dados, devido √† necessidade de calcular a dist√¢ncia para todos os pontos de treino [^13.3].

> ‚úîÔ∏è **Destaque**: A dist√¢ncia Euclidiana, embora popular, pode n√£o ser adequada para todos os tipos de dados (ex: dados categ√≥ricos). M√©todos mais avan√ßados utilizam m√©tricas adaptativas para melhorar o desempenho [^13.1], [^13.4].

### Regress√£o Linear e M√≠nimos Quadrados para Classifica√ß√£o

```mermaid
graph LR
    subgraph "Linear Regression for Classification"
        direction TB
        A["Input: 'Training Data with Class Labels'"]
        B["Encode Classes: 'Indicator Matrix Y'"]
        C["Estimate Coefficients: 'Œ≤ = (X·µÄX)‚Åª¬πX·µÄY'"]
        D["New Point Input: 'x_new'"]
        E["Predict Class: '≈∑ = x_new·µÄŒ≤'"]
        F["Output: 'Class Assignment'"]
        A --> B
        B --> C
        C --> E
        D --> E
        E --> F
    end
```

A regress√£o linear pode ser usada para classifica√ß√£o usando uma matriz indicadora para as classes, onde cada coluna representa uma classe. Os coeficientes da regress√£o linear s√£o estimados por m√≠nimos quadrados, buscando minimizar a soma dos erros quadr√°ticos. Para classificar um novo ponto, usa-se a coluna que produz o maior valor na regress√£o [^4.2].

**Lemma 2:** A solu√ß√£o de m√≠nimos quadrados para a regress√£o linear de uma matriz indicadora, na forma de $\hat{\mathbf{B}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}$, onde $\mathbf{Y}$ √© a matriz indicadora, busca otimizar a proje√ß√£o de cada ponto de treino nos hiperplanos definidos pelas classes, com o objetivo de minimizar a dist√¢ncia entre as predi√ß√µes e os indicadores de classe.
*Prova*: A deriva√ß√£o padr√£o da solu√ß√£o de m√≠nimos quadrados envolve a minimiza√ß√£o da fun√ß√£o de custo $L(\mathbf{B}) = ||\mathbf{Y} - \mathbf{X}\mathbf{B}||_F^2$, onde $||\cdot||_F$ denota a norma de Frobenius. Derivando e igualando a zero, encontramos $\hat{\mathbf{B}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}$ [^4.2]. $\blacksquare$

```mermaid
graph LR
    subgraph "Least Squares Derivation"
        direction LR
        A["Cost Function: 'L(B) = ||Y - XB||¬≤_F'"]
        B["Minimize: '‚àÇL/‚àÇB = 0'"]
        C["Solution: 'BÃÇ = (X·µÄX)‚Åª¬πX·µÄY'"]
        A --> B
        B --> C
    end
```

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o com 2 classes e 2 *features*. Temos os seguintes dados de treino:
>
> | x1 | x2 | Classe |
> |----|----|--------|
> | 1  | 1  | 0      |
> | 2  | 1  | 0      |
> | 1  | 2  | 1      |
> | 2  | 2  | 1      |
>
> Codificamos a classe como 0 e 1, sendo 0 para a primeira classe e 1 para a segunda classe. A matriz de desenho (X) e a matriz indicadora (Y) ser√£o:
>
> $$X = \begin{bmatrix} 1 & 1 & 1 \\ 1 & 2 & 1 \\ 1 & 1 & 2 \\ 1 & 2 & 2 \end{bmatrix}, \quad Y = \begin{bmatrix} 0 \\ 0 \\ 1 \\ 1 \end{bmatrix}$$
>
> Calculando $\hat{\mathbf{B}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}$:
>
> $$X^TX = \begin{bmatrix} 4 & 6 & 6 \\ 6 & 10 & 10 \\ 6 & 10 & 10 \end{bmatrix}, \quad (X^TX)^{-1} = \begin{bmatrix}  2.5 & -1.5 & -1.5 \\ -1.5 & 1.0 & 0.5 \\ -1.5 & 0.5 & 1.0 \end{bmatrix}$$
>
> $$X^TY = \begin{bmatrix} 2 \\ 3 \\ 3 \end{bmatrix}$$
>
> $$\hat{B} = \begin{bmatrix}  2.5 & -1.5 & -1.5 \\ -1.5 & 1.0 & 0.5 \\ -1.5 & 0.5 & 1.0 \end{bmatrix} \begin{bmatrix} 2 \\ 3 \\ 3 \end{bmatrix} = \begin{bmatrix} -2 \\ 1 \\ 1 \end{bmatrix}$$
>
> Para classificar um novo ponto, digamos (1.5, 1.5), calculamos $\hat{y} = X_{new} \hat{B}$, onde $X_{new} = \begin{bmatrix} 1 & 1.5 & 1.5 \end{bmatrix}$:
>
> $$\hat{y} = \begin{bmatrix} 1 & 1.5 & 1.5 \end{bmatrix} \begin{bmatrix} -2 \\ 1 \\ 1 \end{bmatrix} = -2 + 1.5 + 1.5 = 1$$
>
> Como o valor obtido √© 1, o ponto seria classificado como pertencente √† classe 1.

**Corol√°rio 2:** No caso de um problema de duas classes, a regra de decis√£o linear resultante da regress√£o linear da matriz indicadora √© equivalente √† regra de decis√£o do discriminante linear de Fisher, onde o ponto √© classificado na classe que maximiza a proje√ß√£o ortogonal. Isso ocorre quando as covari√¢ncias intra-classe s√£o iguais e a matriz indicadora possui apenas duas colunas [^4.3].

No entanto, a regress√£o linear pode apresentar algumas limita√ß√µes em problemas de classifica√ß√£o. Uma delas √© que, em alguns casos, a previs√£o pode resultar em valores fora do intervalo [0,1], o que √© um problema quando se est√° estimando probabilidades [^4.2]. Al√©m disso, o problema de *masking*, em que a regress√£o linear tende a favorecer classes com maior vari√¢ncia, pode afetar negativamente o desempenho da classifica√ß√£o. No entanto, a regress√£o linear pode ser adequada em cen√°rios onde a principal preocupa√ß√£o √© obter uma fronteira de decis√£o linear [^4.2]. Em compara√ß√£o com a regress√£o log√≠stica, a regress√£o linear pode n√£o oferecer estimativas t√£o robustas de probabilidade, principalmente quando a linearidade n√£o √© uma boa aproxima√ß√£o para o problema [^4.4].

### M√©todos de Sele√ß√£o de Vari√°veis e Regulariza√ß√£o em Classifica√ß√£o

```mermaid
graph LR
    subgraph "Regularization Techniques"
        direction TB
        A["Input: 'Classification Problem'"]
        B["L1 Regularization: 'LASSO, Sparsity'"]
        C["L2 Regularization: 'Ridge Regression, Stability'"]
        D["Elastic Net: 'L1 + L2, Stability & Sparsity'"]
        E["Output: 'Improved Model Performance'"]
        A --> B
        A --> C
        A --> D
        B --> E
        C --> E
         D --> E
        style E fill:#f9f,stroke:#333,stroke-width:2px
    end
```

A sele√ß√£o de vari√°veis e a regulariza√ß√£o s√£o t√©cnicas importantes para melhorar o desempenho de modelos de classifica√ß√£o, principalmente em situa√ß√µes com muitas vari√°veis (alta dimensionalidade). A regulariza√ß√£o adiciona termos de penalidade √† fun√ß√£o de custo do modelo, com o objetivo de reduzir a complexidade e evitar o *overfitting*. As penalidades L1 e L2 s√£o as mais utilizadas, com a penalidade L1 induzindo solu√ß√µes esparsas, isto √©, for√ßando alguns coeficientes a serem zero [^4.5].

A regulariza√ß√£o L1, tamb√©m conhecida como LASSO, adiciona √† fun√ß√£o de custo um termo proporcional √† norma L1 dos coeficientes $\sum_{j=1}^p |\beta_j|$, onde $p$ √© o n√∫mero de *features*. A regulariza√ß√£o L2, tamb√©m conhecida como *Ridge Regression*, adiciona um termo proporcional √† norma L2 dos coeficientes, dado por $\sum_{j=1}^p \beta_j^2$ [^4.4.4].

**Lemma 3:** A penaliza√ß√£o L1 na regress√£o log√≠stica leva a coeficientes esparsos devido √† sua natureza de "bico" na origem, o que faz com que a otimiza√ß√£o tenda a "empurrar" alguns coeficientes para zero.
*Prova*: A fun√ß√£o objetivo da regress√£o log√≠stica com penaliza√ß√£o L1 √© dada por:
$$L(\beta) = -\sum_{i=1}^N [y_i \log(\sigma(\mathbf{x}_i^T\beta)) + (1-y_i) \log(1-\sigma(\mathbf{x}_i^T\beta))] + \lambda \sum_{j=1}^p |\beta_j|$$
O termo $\lambda \sum_{j=1}^p |\beta_j|$ n√£o √© diferenci√°vel em $\beta_j=0$, o que leva a uma solu√ß√£o esparsa, pois a otimiza√ß√£o tende a colocar muitos coeficientes em zero para minimizar a fun√ß√£o objetivo [^4.4.4]. $\blacksquare$

```mermaid
graph LR
    subgraph "L1 Regularization Proof"
         direction LR
        A["Logistic Loss: 'L(Œ≤)'"]
        B["L1 Penalty Term: 'Œª‚àë|Œ≤j|'"]
        C["Non-differentiability at 'Œ≤j = 0'"]
         D["Sparse Solution"]
          A --> B
          B --> C
          C --> D
     end
```

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um modelo de regress√£o log√≠stica com duas features (x1 e x2), e queremos aplicar regulariza√ß√£o L1 (LASSO). A fun√ß√£o de custo com regulariza√ß√£o L1 √©:
>
> $$L(\beta) = -\sum_{i=1}^N [y_i \log(\sigma(\mathbf{x}_i^T\beta)) + (1-y_i) \log(1-\sigma(\mathbf{x}_i^T\beta))] + \lambda (|\beta_1| + |\beta_2|)$$
>
> Sem regulariza√ß√£o ($\lambda = 0$), o modelo pode ter coeficientes $\beta_1 = 2.5$ e $\beta_2 = -1.8$.
>
> Com regulariza√ß√£o L1, digamos $\lambda = 0.5$, a otimiza√ß√£o ir√° tentar minimizar a fun√ß√£o de custo incluindo a penalidade. Isso pode levar a um resultado com $\beta_1 = 1.2$ e $\beta_2 = 0$.
>
> Com $\lambda = 1$, a penalidade aumenta, e a solu√ß√£o pode ser $\beta_1 = 0.5$ e $\beta_2 = 0$.
>
> Observe que a regulariza√ß√£o L1 for√ßou $\beta_2$ a ser zero, eliminando a feature x2 do modelo, tornando a solu√ß√£o mais esparsa.

**Corol√°rio 3:** A esparsidade induzida pela regulariza√ß√£o L1 aumenta a interpretabilidade do modelo, pois identifica quais *features* s√£o mais relevantes para a classifica√ß√£o, o que pode ser valioso para a compreens√£o do fen√¥meno estudado [^4.4.5].

A regulariza√ß√£o L2, por outro lado, n√£o gera solu√ß√µes esparsas, mas penaliza coeficientes grandes, tornando o modelo mais est√°vel e menos sens√≠vel a pequenas varia√ß√µes nos dados de treino [^4.4.4]. A combina√ß√£o das penalidades L1 e L2, conhecida como *Elastic Net*, pode aproveitar as vantagens de ambas, induzindo esparsidade e estabilidade [^4.5].

> ‚ö†Ô∏è **Ponto Crucial**: A escolha do par√¢metro de regulariza√ß√£o $\lambda$ √© crucial para o desempenho do modelo. Valores muito altos de $\lambda$ levam a um modelo muito simplificado (subajustado), enquanto valores muito baixos podem levar ao *overfitting* [^4.4.4].

### Separating Hyperplanes e Perceptrons

O conceito de **separating hyperplanes** (hiperplanos de separa√ß√£o) busca determinar um hiperplano que divide o espa√ßo de *features* de forma a separar as diferentes classes, buscando a m√°xima margem de separa√ß√£o. Formalmente, isso se traduz em encontrar um hiperplano $w^Tx + b = 0$ tal que os pontos de uma classe estejam de um lado e os da outra classe estejam do lado oposto, com a m√°xima dist√¢ncia poss√≠vel em rela√ß√£o aos pontos mais pr√≥ximos [^4.5.2].

O problema de otimiza√ß√£o associado envolve a maximiza√ß√£o da margem, geralmente atrav√©s da formula√ß√£o do problema dual de Wolfe. A solu√ß√£o deste problema resulta em uma combina√ß√£o linear dos pontos de suporte, ou seja, os pontos que est√£o mais pr√≥ximos do hiperplano [^4.5.2].

O **Perceptron** de Rosenblatt √© um algoritmo de classifica√ß√£o que busca iterativamente encontrar um hiperplano de separa√ß√£o. O algoritmo inicia com um hiperplano aleat√≥rio e ajusta seus par√¢metros (pesos e bias) com base nos pontos que s√£o classificados incorretamente, buscando convergir para um hiperplano que separa as classes [^4.5.1]. A converg√™ncia do Perceptron √© garantida sob certas condi√ß√µes, especialmente quando os dados s√£o linearmente separ√°veis [^4.5.1].

```mermaid
graph LR
    subgraph "Perceptron Algorithm"
        direction TB
        A["Initialize 'w' and 'b'"]
         B["Iterate through data"]
        C["Misclassified Point: 'y(wTx + b) ‚â§ 0'"]
        D["Update 'w = w + Œ∑yx', 'b = b + Œ∑y'"]
         E["Convergence Check"]
        A --> B
        B --> C
        C --> D
          D --> B
        B --> E
        style E fill:#f9f,stroke:#333,stroke-width:2px
    end
```

> üí° **Exemplo Num√©rico:**
>
> Considere um problema de classifica√ß√£o bin√°ria com dois *features* e os seguintes dados:
>
> - Classe 1: (1, 1), (2, 1)
> - Classe 2: (1, 2), (2, 2)
>
> Inicializamos o Perceptron com pesos $w = [0, 0]$ e bias $b = 0$. A taxa de aprendizagem $\eta$ √© 1.
>
> Itera√ß√£o 1:
> - Ponto (1, 1) (Classe 1): $w^Tx + b = 0$. Classificado incorretamente. Atualizamos $w = w + \eta y x = [1, 1]$, $b = b + \eta y = 1$.
>
> Itera√ß√£o 2:
> - Ponto (2, 1) (Classe 1): $w^Tx + b = 1*2 + 1*1 + 1 = 4$. Classificado corretamente.
> - Ponto (1, 2) (Classe 2): $w^Tx + b = 1*1 + 1*2 + 1 = 4$. Classificado incorretamente. Atualizamos $w = w + \eta y x = [0, -1]$, $b = b + \eta y = 0$.
>
> Itera√ß√£o 3:
> - Ponto (2, 2) (Classe 2): $w^Tx + b = 0*2 - 1*2 + 0 = -2$. Classificado corretamente.
>
> O algoritmo continuaria ajustando os pesos at√© que todos os pontos fossem classificados corretamente. Em cada itera√ß√£o, o Perceptron ajusta o hiperplano (neste caso uma reta) baseado em pontos classificados incorretamente. Este exemplo ilustra como o Perceptron busca um hiperplano separador, atualizando iterativamente seus pesos e bias.

### Pergunta Te√≥rica Avan√ßada: Deriva√ß√£o da condi√ß√£o de converg√™ncia do Perceptron para dados linearmente separ√°veis
**Resposta:**
A condi√ß√£o de converg√™ncia do Perceptron para dados linearmente separ√°veis √© um resultado cl√°ssico em aprendizado de m√°quina. Para demonstr√°-la, assumimos que existe um hiperplano √≥timo que separa as classes, isto √©, existe um vetor $w^*$ e um escalar $b^*$ tal que $y_i(w^{*T}x_i+b^*)>0$ para todo $i$, onde $y_i \in \{-1,1\}$ representa a classe.

**Lemma 4:** Dado um conjunto de dados linearmente separ√°vel, existe uma solu√ß√£o $w^*$ tal que $\rho = \min_{i} y_i(w^{*T}x_i+b^*)>0$ e $||w^*||=1$.

O Perceptron itera os seguintes passos:
 1.  Inicializa $w=0$, $b=0$.
 2.  Para cada ponto $x_i$ :
    - Se $y_i(w^T x_i+b) \leq 0$, atualiza $w = w+\eta y_i x_i$ e $b = b + \eta y_i$, onde $\eta$ √© a taxa de aprendizagem.

Seja $w_t$ e $b_t$ os par√¢metros no passo $t$ e $\rho = \min_{i} y_i(w^{*T}x_i+b^*) > 0$. Denotamos $R = \max_i ||x_i||$. A cada itera√ß√£o, o produto interno com a solu√ß√£o √≥tima pode ser expresso como:
$$w_t^T w^* = (w_{t-1} + \eta y_i x_i)^T w^* = w_{t-1}^T w^* + \eta y_i w^{*T}x_i \geq w_{t-1}^T w^* + \eta \rho $$
Seja $w_{0} = 0$, ap√≥s $t$ itera√ß√µes, $w_t^T w^* \geq t \eta \rho$. Por outro lado:
$$||w_t||^2 = ||w_{t-1} + \eta y_i x_i||^2 = ||w_{t-1}||^2 + 2\eta y_i w_{t-1}^Tx_i + \eta^2 ||x_i||^2$$
$$||w_t||^2 \leq ||w_{t-1}||^2 + \eta^2 R^2 \implies ||w_t||^2 \leq t\eta^2 R^2 $$
Assim:
$$ \frac{w_t^T w^*}{||w_t|| ||w^*||} \geq \frac{t \eta \rho}{\sqrt{t}\eta R} = \sqrt{t}\frac{\rho}{R} $$
Como $\frac{w_t^T w^*}{||w_t|| ||w^*||} \leq 1$, obtemos $t \leq \left(\frac{R}{\rho}\right)^2$. Logo, o algoritmo do Perceptron converge em um n√∫mero finito de itera√ß√µes para um conjunto de dados linearmente separ√°vel. $\blacksquare$
A taxa de aprendizagem $\eta$ afeta a rapidez da converg√™ncia e os ajustes s√£o necess√°rios em casos com ru√≠do ou n√£o-linearmente separ√°vel.

```mermaid
graph LR
    subgraph "Perceptron Convergence Proof"
        direction TB
         A["Assume Linear Separability: '‚àÉ w*, b* : yi(w*Txi + b*) > 0'"]
        B["Iteration Step: 'wt = wt-1 + Œ∑yixi'"]
        C["Inner Product Growth: 'wtTw* ‚â• tŒ∑œÅ'"]
        D["Norm Bound: '||wt||¬≤ ‚â§ tŒ∑¬≤R¬≤'"]
        E["Convergence Condition: 't ‚â§ (R/œÅ)¬≤'"]
         A --> B
        B --> C
        B --> D
         C & D --> E
        style E fill:#f9f,stroke:#333,stroke-width:2px
    end
```

> ‚ö†Ô∏è **Ponto Crucial**: A condi√ß√£o de linear separabilidade √© uma premissa fundamental para a converg√™ncia do Perceptron. Quando os dados n√£o s√£o linearmente separ√°veis, o algoritmo pode n√£o convergir, necessitando de outras abordagens como o uso de *kernels* [^4.5.1].

### Conclus√£o

Este cap√≠tulo explorou m√©todos de classifica√ß√£o e reconhecimento de padr√µes que s√£o essencialmente *model-free*, focando em sua capacidade de realizar previs√µes precisas em vez de interpretar a rela√ß√£o entre os *features* e os resultados das classes. Os m√©todos de prot√≥tipos, como o K-means e o LVQ, oferecem uma forma flex√≠vel de aproximar a distribui√ß√£o das classes e representar fronteiras de decis√£o complexas. J√° os m√©todos de k-vizinhos mais pr√≥ximos, apesar de sua simplicidade, s√£o eficazes em diversas aplica√ß√µes, mas podem ser computacionalmente caros para grandes conjuntos de dados. M√©todos mais avan√ßados, como os m√©todos adaptativos e as dist√¢ncias invariantes, representam melhorias importantes para o desempenho e podem se adaptar √†s caracter√≠sticas dos dados, levando a modelos de classifica√ß√£o mais robustos.

### Footnotes

[^13.1]: "In this chapter we discuss some simple and essentially model-free methods for classification and pattern recognition. Because they are highly unstructured, they typically are not useful for understanding the nature of the relationship between the features and class outcome. However, as black box prediction engines, they can be very effective, and are often among the best performers in real data problems."

[^13.2]: "Throughout this chapter, our training data consists of the N pairs (x1,91),...,(xn, 9N) where gi is a class label taking values in {1, 2, . . ., K}. Prototype methods represent the training data by a set of points in feature space. These prototypes are typically not examples from the training sample, except in the case of 1-nearest-neighbor classification discussed later. Each prototype has an associated class label, and classification of a query point x is made to the class of the closest prototype. "Closest" is usually defined by Euclidean distance in the feature space, after each feature has been standardized to have overall mean 0 and variance 1 in the training sample."

[^4.1]:  "This chapter focuses on linear methods for classification, which are linear in the parameters and lead to linear decision boundaries."

[^4.3]:  "Linear Discriminant Analysis (LDA) is a classical method for classification. It assumes that the classes are normally distributed and that their covariance matrices are the same."

[^4.4]: "Logistic Regression models the log-odds of belonging to a particular class using a linear function of the features, making it a powerful and flexible tool for classification."

[^4.2]: "Linear regression can also be used for classification by fitting a linear model to an indicator matrix. However, the resulting decision boundaries are not always ideal for classification purposes due to the lack of constraints on predicted values and the masking effect."

[^4.5]: "Regularization and feature selection techniques are essential in classification to deal with high-dimensional data and to improve the generalization ability of models. Both L1 and L2 regularization, along with Elastic Net, are widely used."

[^4.4.4]: "Regularization is a technique that helps prevent overfitting by adding a penalty term to the loss function. The L1 penalty leads to sparse solutions, while L2 penalty does not."

[^4.4.5]: "By adding a penalty term to the likelihood, regularization helps shrink parameters towards zero, resulting in simpler models that are less prone to overfitting."

[^4.5.1]: "The perceptron algorithm iteratively updates the separating hyperplane until all training points are correctly classified. The convergence of this algorithm is guaranteed only if the training data is linearly separable."

[^4.5.2]: "The method of separating hyperplanes finds the hyperplane that maximizes the margin between the two classes. This is a key concept in support vector machines and related methods."

[^13.3]: "These classifiers are memory-based, and require no model to be fit. Given a query point xo, we find the k training points x(r), r = 1,..., k closest in distance to xo, and then classify using majority vote among the k neighbors."

[^13.4]: "When nearest-neighbor classification is carried out in a high-dimensional feature space, the nearest neighbors of a point can be very far away, causing bias and degrading the performance of the rule. In general, this calls for adapting the metric used in nearest-neighbor classification, so that the resulting neighborhoods stretch out in directions for which the class probabilities don't change much."
