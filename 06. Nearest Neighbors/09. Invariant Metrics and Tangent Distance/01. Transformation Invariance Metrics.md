## M√©tricas Invariantes: Incorporando a Invari√¢ncia a Transforma√ß√µes na Medida de Proximidade

```mermaid
graph LR
    A["Data with Transformations"] --> B("Traditional Distance Metric\n(e.g., Euclidean)")
    B --> C("Biased Similarity Measurement")
    A --> D("Invariant Metric")
    D --> E("Accurate Similarity Measurement")
    E --> F("Improved k-NN Generalization")
    C --> G("Reduced k-NN Generalization")
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style D fill:#ccf,stroke:#333,stroke-width:2px
```

### Introdu√ß√£o

Este cap√≠tulo explora o conceito de **m√©tricas invariantes**, que s√£o projetadas para medir a similaridade entre objetos que s√£o transforma√ß√µes uns dos outros [^13.3.3]. Em muitos problemas de aprendizado de m√°quina, os dados podem apresentar transforma√ß√µes naturais, como rota√ß√µes, transla√ß√µes, mudan√ßas de escala ou outras distor√ß√µes. M√©tricas de dist√¢ncia tradicionais, como a dist√¢ncia Euclidiana, podem ser sens√≠veis a essas transforma√ß√µes, levando a resultados enviesados na classifica√ß√£o ou reconhecimento de padr√µes. Analisaremos como as m√©tricas invariantes s√£o constru√≠das para lidar com esse problema, e como elas permitem que o k-NN generalize melhor em cen√°rios onde os dados apresentam essas transforma√ß√µes. Discutiremos tamb√©m o conceito de dist√¢ncia tangente como uma forma de construir m√©tricas invariantes e como elas s√£o aplicadas em reconhecimento de padr√µes.

### A Necessidade de M√©tricas Invariantes: Lidando com Transforma√ß√µes nos Dados

Em muitos problemas de classifica√ß√£o e reconhecimento de padr√µes, os dados apresentam transforma√ß√µes que podem afetar a forma como a similaridade entre os objetos √© medida [^13.3.3]. Essas transforma√ß√µes podem ser:

1.  **Transforma√ß√µes Geom√©tricas:** Rota√ß√µes, transla√ß√µes, mudan√ßas de escala, deforma√ß√µes, e outras transforma√ß√µes que afetam a posi√ß√£o, orienta√ß√£o e forma dos objetos.
2.  **Transforma√ß√µes de Intensidade:** Mudan√ßas no brilho, contraste, cor, e outras transforma√ß√µes que afetam os valores das *features*.
3.  **Transforma√ß√µes Temporais:** Mudan√ßas na ordem de sequ√™ncia, deslocamentos ou outras transforma√ß√µes que afetam dados temporais.

```mermaid
graph LR
    subgraph "Data Transformations"
        direction TB
        A["Original Data"]
        B["Geometric Transformations:\nRotation, Translation, Scaling, etc."]
        C["Intensity Transformations:\nBrightness, Contrast, Color Changes"]
        D["Temporal Transformations:\nSequence Shifts, Order Changes"]
        A --> B
        A --> C
        A --> D
    end
```

As m√©tricas de dist√¢ncia tradicionais, como a dist√¢ncia Euclidiana, s√£o sens√≠veis a essas transforma√ß√µes. Por exemplo, ao calcular a dist√¢ncia entre duas imagens de um mesmo objeto, a dist√¢ncia Euclidiana pode ser alta se uma das imagens for rotacionada ou transladada, mesmo que o objeto seja essencialmente o mesmo nas duas imagens.

Para lidar com esse problema, s√£o utilizadas **m√©tricas invariantes**, que s√£o projetadas para medir a similaridade entre objetos que s√£o transforma√ß√µes uns dos outros. A invari√¢ncia √© uma propriedade desej√°vel das m√©tricas de dist√¢ncia, que permite que o modelo de aprendizado ignore as transforma√ß√µes que n√£o s√£o relevantes para a classifica√ß√£o ou reconhecimento do padr√£o.

**Lemma 116:** M√©tricas invariantes permitem medir a similaridade entre objetos que s√£o transforma√ß√µes uns dos outros, o que aumenta a capacidade de generaliza√ß√£o do modelo e reduz a influ√™ncia de varia√ß√µes nos dados que n√£o s√£o relevantes para a classifica√ß√£o.
*Prova*: Uma m√©trica invariante resulta no mesmo valor de dist√¢ncia quando aplicada entre pontos e suas transforma√ß√µes, representando apenas similaridade estrutural entre as inst√¢ncias e n√£o sua posi√ß√£o no espa√ßo. $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Imagine que temos duas representa√ß√µes de um mesmo objeto, representadas por vetores de caracter√≠sticas (features). O objeto original √© representado por $x_1 = [1, 2]$, e uma vers√£o rotacionada do mesmo objeto √© $x_2 = [2, -1]$. Usando a dist√¢ncia euclidiana, temos:
>
> $d(x_1, x_2) = \sqrt{(2-1)^2 + (-1-2)^2} = \sqrt{1^2 + (-3)^2} = \sqrt{10} \approx 3.16$
>
> Agora, suponha que a rota√ß√£o n√£o seja relevante para a classifica√ß√£o. Uma m√©trica invariante √† rota√ß√£o idealmente retornaria uma dist√¢ncia muito menor (ou at√© 0), indicando que os objetos s√£o essencialmente o mesmo. Este exemplo ilustra como a dist√¢ncia Euclidiana pode ser enganosa quando transforma√ß√µes est√£o presentes. Uma m√©trica invariante, como a dist√¢ncia tangente, seria projetada para lidar com esse problema, conforme explicado posteriormente.

**Corol√°rio 116:** O uso de m√©tricas invariantes √© essencial em problemas onde os dados apresentam transforma√ß√µes que n√£o devem influenciar a classifica√ß√£o ou reconhecimento de padr√µes.

> ‚ö†Ô∏è **Nota Importante**: M√©tricas invariantes s√£o projetadas para medir a similaridade entre objetos que s√£o transforma√ß√µes uns dos outros, removendo a influ√™ncia de transforma√ß√µes irrelevantes.

> ‚ùó **Ponto de Aten√ß√£o**:  A escolha de uma m√©trica invariante adequada depende das transforma√ß√µes que se espera encontrar nos dados e da necessidade de generalizar em rela√ß√£o a essas transforma√ß√µes.

### Dist√¢ncia Euclidiana vs. M√©tricas Invariantes: Um Exemplo com Rota√ß√£o de D√≠gitos Manuscritos

Para ilustrar a diferen√ßa entre a **dist√¢ncia Euclidiana** e as **m√©tricas invariantes**, podemos considerar o exemplo do reconhecimento de d√≠gitos manuscritos, onde as imagens dos d√≠gitos podem apresentar varia√ß√µes em sua orienta√ß√£o (rota√ß√£o) [^13.3.3].

```mermaid
graph LR
    subgraph "Distance Metrics Comparison"
        direction TB
        A["Handwritten Digit Image (Original)"]
        B["Rotated Handwritten Digit Image"]
        C["Euclidean Distance:\nSensitive to Rotation"]
        D["Invariant Metric:\nInsensitive to Rotation"]
        A & B --> C
        A & B --> D
    end
```

A dist√¢ncia Euclidiana entre duas imagens de d√≠gitos manuscritos √© calculada com base na diferen√ßa entre os valores de seus pixels correspondentes. No entanto, se uma imagem for rotacionada, os valores dos pixels mudar√£o significativamente, mesmo que o d√≠gito em si seja o mesmo. Isso significa que a dist√¢ncia Euclidiana ser√° grande entre uma imagem original e uma imagem rotacionada do mesmo d√≠gito, o que dificulta a classifica√ß√£o correta.

Uma m√©trica invariante √† rota√ß√£o, por outro lado, seria capaz de medir a similaridade entre as duas imagens, mesmo que uma delas esteja rotacionada. Essa m√©trica ignoraria a rota√ß√£o e focaria na forma essencial do d√≠gito, permitindo que o classificador identifique as duas imagens como pertencentes √† mesma classe. O conceito de dist√¢ncia tangente busca realizar essa compara√ß√£o entre objetos com pequenas transforma√ß√µes, atrav√©s da compara√ß√£o da proje√ß√£o desses objetos em um espa√ßo tangente no ponto de opera√ß√£o.

**Lemma 117:** A dist√¢ncia Euclidiana √© sens√≠vel a transforma√ß√µes geom√©tricas como a rota√ß√£o, o que limita sua capacidade de medir a similaridade entre objetos que apresentam essas transforma√ß√µes, enquanto m√©todos que utilizam o conceito de dist√¢ncia tangente podem obter resultados melhores.
*Prova*: A dist√¢ncia euclidiana mede apenas a dist√¢ncia entre dois pontos, mas n√£o considera que uma rota√ß√£o de um objeto pode n√£o alterar sua similaridade intr√≠nseca. $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Considere duas imagens de um d√≠gito '3', representadas como vetores de pixels. A imagem original, $I_1$, tem pixels com valores (ap√≥s normaliza√ß√£o) como:
>
> $I_1 = [0.1, 0.2, 0.7, 0.8, 0.3, 0.4, 0.9, 0.7, 0.2]$
>
> E a imagem rotacionada, $I_2$, tem pixels com valores:
>
> $I_2 = [0.2, 0.7, 0.8, 0.3, 0.4, 0.9, 0.7, 0.2, 0.1]$
>
> A dist√¢ncia Euclidiana entre $I_1$ e $I_2$ √©:
>
> $d(I_1, I_2) = \sqrt{(0.2-0.1)^2 + (0.7-0.2)^2 + (0.8-0.7)^2 + (0.3-0.8)^2 + (0.4-0.3)^2 + (0.9-0.4)^2 + (0.7-0.9)^2 + (0.2-0.7)^2 + (0.1-0.2)^2}$
> $d(I_1, I_2) = \sqrt{0.01 + 0.25 + 0.01 + 0.25 + 0.01 + 0.25 + 0.04 + 0.25 + 0.01} = \sqrt{1.08} \approx 1.04$
>
> Essa dist√¢ncia √© relativamente alta. Uma m√©trica invariante √† rota√ß√£o idealmente retornaria uma dist√¢ncia menor, pois ambas as imagens representam o mesmo d√≠gito, apenas com uma rota√ß√£o diferente. M√©tricas invariantes, como a dist√¢ncia tangente, tentam minimizar o efeito dessas transforma√ß√µes.

**Corol√°rio 117:** A m√©tricas invariantes, que consideram transforma√ß√µes nos dados, s√£o essenciais para que modelos de classifica√ß√£o e reconhecimento possam generalizar para novos dados com transforma√ß√µes.

> ‚ö†Ô∏è **Nota Importante**:  A dist√¢ncia Euclidiana √© sens√≠vel a transforma√ß√µes, como rota√ß√µes, o que pode levar a resultados enviesados.

> ‚ùó **Ponto de Aten√ß√£o**: M√©tricas invariantes s√£o necess√°rias para medir a similaridade entre objetos que podem apresentar transforma√ß√µes relevantes, o que melhora a capacidade de generaliza√ß√£o.

### Dist√¢ncia Tangente: Aproximando a Invari√¢ncia por Rota√ß√£o

A **dist√¢ncia tangente** √© uma abordagem para construir m√©tricas invariantes que aproximam a invari√¢ncia a transforma√ß√µes geom√©tricas por meio da considera√ß√£o das transforma√ß√µes de vizinhan√ßa [^13.3.3]. A ideia central da dist√¢ncia tangente √© representar a varia√ß√£o de uma imagem devido a pequenas transforma√ß√µes por um espa√ßo tangente, e calcular a dist√¢ncia entre os objetos com base na dist√¢ncia entre os espa√ßos tangentes.

```mermaid
graph LR
    subgraph "Tangent Distance Construction"
        direction TB
        A["Object"]
        B["Invariance Manifold:\nSet of Transformed Objects"]
        C["Tangent Space:\nLinear Approximation of Manifold"]
        D["Distance between Tangent Spaces:\nUsed as Invariant Distance"]
        A --> B
        B --> C
        C --> D
    end
```

O processo de constru√ß√£o da dist√¢ncia tangente pode ser descrito da seguinte forma:

1.  **Manifold de Invari√¢ncia:** Para cada objeto (por exemplo, uma imagem de um d√≠gito), √© constru√≠do um *manifold* (variedade) que representa as poss√≠veis transforma√ß√µes do objeto. No caso de rota√ß√£o, o *manifold* √© uma curva no espa√ßo de *features* que representa todas as imagens resultantes da rota√ß√£o da imagem original.
2.  **Espa√ßo Tangente:** Para cada objeto, √© constru√≠do um espa√ßo tangente, que aproxima o *manifold* de invari√¢ncia na vizinhan√ßa do objeto. O espa√ßo tangente √© representado por um subespa√ßo linear que captura as dire√ß√µes de varia√ß√£o das transforma√ß√µes.
3.  **Dist√¢ncia entre Espa√ßos Tangentes:** A dist√¢ncia entre dois objetos √© calculada com base na dist√¢ncia entre seus respectivos espa√ßos tangentes. Essa dist√¢ncia √© geralmente a dist√¢ncia Euclidiana entre os pontos de proje√ß√£o de cada objeto em seu espa√ßo tangente.

A dist√¢ncia tangente aproxima a invari√¢ncia em rela√ß√£o √†s transforma√ß√µes, pois mede a dist√¢ncia entre os espa√ßos tangentes, que representam as poss√≠veis varia√ß√µes que um objeto pode sofrer devido a essas transforma√ß√µes. A utiliza√ß√£o de espa√ßos tangentes para calcular a dist√¢ncia resulta em uma m√©trica que √© menos sens√≠vel a pequenas transforma√ß√µes, e mais adequada para cen√°rios onde os objetos podem variar devido a essas transforma√ß√µes.

**Lemma 118:** A dist√¢ncia tangente aproxima a invari√¢ncia a transforma√ß√µes por meio da modelagem das transforma√ß√µes atrav√©s de um espa√ßo tangente, que captura as varia√ß√µes do objeto devido a estas transforma√ß√µes.
*Prova*: O conceito da dist√¢ncia tangente surge da aproxima√ß√£o da variedade de transforma√ß√µes por um subespa√ßo linear, o espa√ßo tangente. $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Considere uma imagem de um d√≠gito '7' representado como um vetor $x$. Para construir o espa√ßo tangente para rota√ß√µes, podemos aplicar pequenas rota√ß√µes √† imagem $x$ e obter imagens ligeiramente rotacionadas, como $x + \delta_1$, $x + \delta_2$, etc., onde $\delta_i$ representa a mudan√ßa no vetor de pixels devido √† pequena rota√ß√£o.
>
> O espa√ßo tangente, $T_x$, √© ent√£o constru√≠do como o espa√ßo linear gerado pelos vetores de mudan√ßa $\delta_i$. Se considerarmos apenas uma rota√ß√£o em sentido hor√°rio e anti-hor√°rio, podemos ter dois vetores de base para o espa√ßo tangente, representando os gradientes da imagem em rela√ß√£o √† rota√ß√£o.
>
> Para calcular a dist√¢ncia tangente entre duas imagens $x_1$ e $x_2$, projetamos $x_1$ e $x_2$ em seus respectivos espa√ßos tangentes, $T_{x_1}$ e $T_{x_2}$. Sejam as proje√ß√µes $p_{x_1}$ e $p_{x_2}$. A dist√¢ncia tangente √© ent√£o calculada como a dist√¢ncia euclidiana entre $p_{x_1}$ e $p_{x_2}$. Esse processo aproxima a invari√¢ncia, pois considera as varia√ß√µes que a rota√ß√£o causa na imagem.

**Corol√°rio 118:** O uso de espa√ßos tangentes permite aproximar uma m√©trica invariante a rota√ß√µes, e outras transforma√ß√µes, e reduzir a necessidade de ter muitos exemplos de dados para cada classe.

> ‚ö†Ô∏è **Nota Importante**: A dist√¢ncia tangente √© uma abordagem para construir m√©tricas invariantes a transforma√ß√µes, utilizando espa√ßos tangentes para aproximar as varia√ß√µes devidas a transforma√ß√µes nos dados.

> ‚ùó **Ponto de Aten√ß√£o**:  A computa√ß√£o da dist√¢ncia tangente pode ser computacionalmente custosa, e seu uso pode ser mais apropriado para conjuntos de dados com transforma√ß√µes espec√≠ficas.

### A Aplica√ß√£o da Dist√¢ncia Tangente: Reconhecimento de D√≠gitos Manuscritos

A aplica√ß√£o da **dist√¢ncia tangente** em problemas de reconhecimento de d√≠gitos manuscritos tem demonstrado resultados not√°veis, especialmente na cria√ß√£o de modelos que sejam capazes de reconhecer d√≠gitos mesmo quando apresentam rota√ß√µes, e outras distor√ß√µes [^13.3.3].

```mermaid
graph LR
    subgraph "Tangent Distance in Digit Recognition"
        direction TB
        A["Handwritten Digit Image"]
        B["Compute Tangent Space"]
        C["Project Image onto Tangent Space"]
        D["Calculate Distance in Tangent Space"]
        A --> B
        B --> C
        C --> D
    end
```

Ao utilizar a dist√¢ncia tangente para calcular a proximidade entre as imagens de d√≠gitos, o modelo se torna menos sens√≠vel a pequenas rota√ß√µes, e outros tipos de transforma√ß√µes, o que melhora sua capacidade de generaliza√ß√£o. A dist√¢ncia tangente √© calculada com base na proje√ß√£o das imagens nos espa√ßos tangentes, que s√£o obtidos por meio de pequenas rota√ß√µes das imagens, ou por m√©todos mais sofisticados de suaviza√ß√£o.

> üí° **Exemplo Num√©rico:**
> Vamos considerar um cen√°rio simplificado com um d√≠gito '2'. Primeiro, criamos o espa√ßo tangente para uma imagem original do '2'. Isso envolve gerar pequenas varia√ß√µes da imagem, como rota√ß√µes em √¢ngulos de -5 e +5 graus. Os vetores que representam essas varia√ß√µes formam a base do espa√ßo tangente.
>
> Agora, temos duas imagens, $I_{2a}$ (original) e $I_{2b}$ (levemente rotacionada). Ao inv√©s de calcular a dist√¢ncia Euclidiana direta entre $I_{2a}$ e $I_{2b}$, projetamos ambas em seus respectivos espa√ßos tangentes. As proje√ß√µes s√£o $P_{2a}$ e $P_{2b}$. A dist√¢ncia tangente √© ent√£o a dist√¢ncia Euclidiana entre $P_{2a}$ e $P_{2b}$.
>
> Este processo garante que a dist√¢ncia entre as imagens seja menor, mesmo que uma delas esteja rotacionada, pois considera a estrutura invariante do d√≠gito.

A utiliza√ß√£o de k-NN com dist√¢ncia tangente no problema de reconhecimento de d√≠gitos manuscritos ilustra a import√¢ncia de m√©tricas invariantes em problemas onde os dados podem apresentar varia√ß√µes, e a capacidade de se adaptar a diferentes formas de representa√ß√£o dos dados. O uso de dados aumentados atrav√©s de transforma√ß√µes nos dados pode ser uma alternativa quando a computa√ß√£o da dist√¢ncia tangente se torna invi√°vel ou n√£o necess√°ria.

**Lemma 119:** A aplica√ß√£o da dist√¢ncia tangente no reconhecimento de d√≠gitos manuscritos permite que o modelo seja menos sens√≠vel a transforma√ß√µes como rota√ß√µes e generaliza melhor para dados n√£o vistos no treinamento.
*Prova*: O uso da dist√¢ncia tangente faz com que a decis√£o seja baseada na similaridade entre formas e n√£o na posi√ß√£o dos objetos no espa√ßo. $\blacksquare$

**Corol√°rio 119:** A m√©trica de dist√¢ncia tangente apresenta resultados superiores √† dist√¢ncia Euclidiana no reconhecimento de d√≠gitos manuscritos por ser invariante a pequenas varia√ß√µes nos dados de entrada.

> ‚ö†Ô∏è **Nota Importante**: A dist√¢ncia tangente √© uma m√©trica invariante que permite que o k-NN obtenha bom desempenho em problemas de reconhecimento de d√≠gitos manuscritos, onde as rota√ß√µes e varia√ß√µes nas formas dos d√≠gitos s√£o comuns.

> ‚ùó **Ponto de Aten√ß√£o**:  A computa√ß√£o da dist√¢ncia tangente pode ser computacionalmente custosa, e sua utiliza√ß√£o deve ser avaliada em rela√ß√£o ao ganho de desempenho e ao custo computacional.

### Conclus√£o

A incorpora√ß√£o da invari√¢ncia a transforma√ß√µes na medida de proximidade √© um conceito importante em problemas de aprendizado de m√°quina, onde os dados podem apresentar transforma√ß√µes que n√£o s√£o relevantes para a tarefa em quest√£o. M√©tricas invariantes, como a dist√¢ncia tangente, permitem que os modelos de classifica√ß√£o e reconhecimento de padr√µes generalizem melhor para dados que apresentam essas transforma√ß√µes, e que modelos como o k-NN possam apresentar desempenho superior em cen√°rios onde dados de treino e teste podem ser diferentes devido a rota√ß√£o, transla√ß√£o, ou outras transforma√ß√µes. A escolha de uma m√©trica adequada, que leve em considera√ß√£o as caracter√≠sticas do problema e as transforma√ß√µes que podem ocorrer, √© fundamental para o desenvolvimento de sistemas de aprendizado de m√°quina eficazes e robustos.

### Footnotes

[^13.3.3]: "In some problems, the training features are invariant under certain natural transformations. The nearest-neighbor classifier can exploit such invariances by incorporating them into the metric used to measure the distances between objects...The problem is handwritten digit recognition...Hence we want our nearest-neighbor classifier to consider these two '3's to be close together (similar)." *(Trecho de "13. Prototype Methods and Nearest-Neighbors")*
