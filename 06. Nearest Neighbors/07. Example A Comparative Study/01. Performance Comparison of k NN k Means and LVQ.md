## ComparaÃ§Ã£o de Desempenho: k-NN, K-Means e LVQ em Problemas Simulados de Duas Classes

```mermaid
graph LR
    subgraph "Comparative Analysis"
        direction TB
        A["Input Data: Simulated 2-Class Problems"]
        B["k-NN Algorithm"]
        C["K-Means Algorithm (Classification)"]
        D["LVQ Algorithm"]
        E["Performance Evaluation: Error Rate"]
        F["Parameter Tuning: k (k-NN), Prototypes (K-Means, LVQ)"]
        A --> B & C & D
        B --> E
        C --> E
        D --> E
        F --> B & C & D
        E --> G["Comparative Analysis Across Scenarios"]
    end
```

### IntroduÃ§Ã£o

Este capÃ­tulo apresenta uma **comparaÃ§Ã£o de desempenho** entre o mÃ©todo de **k-vizinhos mais prÃ³ximos (k-NN)**, o algoritmo **K-Means** (adaptado para classificaÃ§Ã£o) e o **Learning Vector Quantization (LVQ)**, utilizando problemas simulados de classificaÃ§Ã£o de duas classes [^13.3.1]. O objetivo Ã© analisar como esses mÃ©todos se comportam em diferentes cenÃ¡rios, incluindo problemas "fÃ¡ceis", onde as classes sÃ£o linearmente separÃ¡veis, e problemas "difÃ­ceis", onde as fronteiras de decisÃ£o sÃ£o mais complexas. Avaliaremos como a escolha dos parÃ¢metros de cada modelo (ex: o nÃºmero de vizinhos $k$ no k-NN e o nÃºmero de protÃ³tipos no K-Means e LVQ) influencia a taxa de erro, e como cada algoritmo lida com diferentes tipos de distribuiÃ§Ãµes de dados.

### Problemas Simulados: CenÃ¡rios "FÃ¡ceis" e "DifÃ­ceis"

Para avaliar o desempenho dos algoritmos, utilizaremos dois problemas simulados de classificaÃ§Ã£o de duas classes, descritos como "fÃ¡cil" e "difÃ­cil":

1.  **Problema "FÃ¡cil":** Nesse cenÃ¡rio, as duas classes sÃ£o separadas por um hiperplano linear. Os dados de cada classe sÃ£o distribuÃ­dos uniformemente, e as classes sÃ£o separadas por uma linha reta (um hiperplano de dimensÃ£o um em um espaÃ§o de duas dimensÃµes), ou seja, Ã© um problema linearmente separÃ¡vel.
2.  **Problema "DifÃ­cil":** Nesse cenÃ¡rio, as duas classes formam um padrÃ£o quadriculado no espaÃ§o de *features*. As classes nÃ£o sÃ£o separadas por nenhuma fronteira linear ou convexas, sendo necessÃ¡rio um classificador mais adaptÃ¡vel. Nesse caso, as classes se tornam nÃ£o linearmente separÃ¡veis, o que representa um desafio para modelos lineares.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Para o problema "fÃ¡cil", podemos gerar dados onde a classe 1 tem coordenadas x e y entre 0 e 1, e a classe 2 tem coordenadas x e y entre 2 e 3. Um exemplo de ponto da classe 1 seria (0.3, 0.7) e da classe 2 seria (2.5, 2.1). A fronteira de decisÃ£o linear poderia ser, por exemplo, a reta x = 1.5. JÃ¡ para o problema "difÃ­cil", podemos imaginar que a classe 1 consiste em pontos prÃ³ximos de (0,0) e (2,2), enquanto a classe 2 consiste em pontos prÃ³ximos de (0,2) e (2,0), formando um padrÃ£o quadriculado.

```mermaid
graph LR
    subgraph "Simulated Problems"
        direction LR
        A["Problem 'Easy': Linearly Separable"]
        B["Data: Uniform Distribution, Hyperplane Boundary"]
        C["Problem 'Difficult': Non-Linearly Separable"]
        D["Data: Grid Pattern, Complex Boundary"]
        A --> B
        C --> D
    end
```

Esses dois cenÃ¡rios permitem comparar a capacidade de diferentes mÃ©todos de classificaÃ§Ã£o de lidar com fronteiras de decisÃ£o lineares e nÃ£o lineares. Os dados de cada problema sÃ£o gerados de forma aleatÃ³ria para cada simulaÃ§Ã£o, e as simulaÃ§Ãµes sÃ£o repetidas vÃ¡rias vezes para calcular a mÃ©dia do erro.

**Lemma 99:** A comparaÃ§Ã£o de desempenho de algoritmos de classificaÃ§Ã£o em problemas simulados com classes linearmente separÃ¡veis ("fÃ¡cil") e nÃ£o linearmente separÃ¡veis ("difÃ­cil") permite avaliar a capacidade dos algoritmos de se adaptar a distribuiÃ§Ãµes de dados com diferentes complexidades.
*Prova*: Problemas simulados permitem o controle das propriedades dos dados, o que garante a anÃ¡lise dos algoritmos em diferentes cenÃ¡rios. $\blacksquare$

**CorolÃ¡rio 99:** A escolha de problemas com fronteiras de decisÃ£o diferentes (lineares e nÃ£o lineares) permite avaliar o desempenho dos algoritmos em diferentes condiÃ§Ãµes.

> âš ï¸ **Nota Importante**: Os problemas simulados "fÃ¡cil" e "difÃ­cil" servem como referÃªncia para avaliar o desempenho dos algoritmos em diferentes tipos de dados.

> â— **Ponto de AtenÃ§Ã£o**:  Em problemas reais, Ã© importante avaliar o desempenho dos algoritmos em uma variedade de cenÃ¡rios para entender suas limitaÃ§Ãµes e potencialidades.

### Metodologia da ComparaÃ§Ã£o: AvaliaÃ§Ã£o da Taxa de Erro

A metodologia utilizada para comparar o desempenho dos algoritmos consiste em:

1.  **GeraÃ§Ã£o dos Dados:** Gerar um conjunto de treinamento e um conjunto de teste para cada problema simulado (fÃ¡cil e difÃ­cil).
2.  **Ajuste dos Modelos:** Ajustar cada algoritmo (k-NN, K-Means e LVQ) aos dados de treinamento, utilizando diferentes valores para os parÃ¢metros de cada algoritmo (nÃºmero de vizinhos $k$ no k-NN, nÃºmero de protÃ³tipos por classe no K-Means e LVQ).
3.  **ClassificaÃ§Ã£o do Conjunto de Teste:** Classificar os dados do conjunto de teste utilizando os modelos ajustados no passo anterior.
4.  **CÃ¡lculo da Taxa de Erro:** Calcular a taxa de erro (proporÃ§Ã£o de classificaÃ§Ãµes incorretas) para cada modelo no conjunto de teste.
5.  **RepetiÃ§Ã£o das SimulaÃ§Ãµes:** Repetir os passos de 1 a 4 vÃ¡rias vezes (10 realizaÃ§Ãµes) e calcular a mÃ©dia e o desvio padrÃ£o da taxa de erro para cada modelo e para cada valor de parÃ¢metro, visando obter resultados com significÃ¢ncia estatÃ­stica.

```mermaid
graph LR
    subgraph "Methodology"
        direction TB
        A["Data Generation: Training and Test Sets"]
        B["Model Fitting: k-NN, K-Means, LVQ"]
        C["Classification: Test Set"]
        D["Error Rate Calculation"]
        E["Repeat Simulations (N=10)"]
         F["Calculate Mean and Std. Dev. of Error Rate"]
        A --> B
        B --> C
        C --> D
        D --> E
        E --> F
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Vamos supor que, apÃ³s gerar os dados de treinamento para o problema "fÃ¡cil", ajustamos um modelo k-NN com k=3. No conjunto de teste, temos 100 pontos. ApÃ³s classificar cada ponto, observamos que 5 pontos foram classificados incorretamente. A taxa de erro para essa execuÃ§Ã£o especÃ­fica seria 5/100 = 0.05 ou 5%. Repetimos esse processo 10 vezes, e obtemos as seguintes taxas de erro: 0.05, 0.06, 0.04, 0.07, 0.05, 0.05, 0.06, 0.04, 0.05, 0.06. A mÃ©dia da taxa de erro seria 0.053 e o desvio padrÃ£o seria aproximadamente 0.009. Isso nos dÃ¡ uma ideia da variabilidade do erro para k=3 no problema "fÃ¡cil".

A avaliaÃ§Ã£o do desempenho Ã© feita com base na taxa de erro mÃ©dia e no seu desvio padrÃ£o, o que permite analisar a estabilidade dos modelos e como eles se comportam em diferentes simulaÃ§Ãµes. A variaÃ§Ã£o dos parÃ¢metros de cada mÃ©todo permite avaliar a influÃªncia desses parÃ¢metros na taxa de erro.

**Lemma 100:** A utilizaÃ§Ã£o da mÃ©dia e do desvio padrÃ£o da taxa de erro em mÃºltiplas realizaÃ§Ãµes permite avaliar o desempenho mÃ©dio dos modelos e sua variabilidade, o que aumenta a robustez da comparaÃ§Ã£o entre os diferentes algoritmos.
*Prova*: O cÃ¡lculo da mÃ©dia e do desvio padrÃ£o em mÃºltiplas realizaÃ§Ãµes permitem avaliar a variabilidade dos resultados e estimar o erro padrÃ£o da mÃ©dia, o que permite avaliar a significÃ¢ncia estatÃ­stica das diferenÃ§as entre os modelos. $\blacksquare$

**CorolÃ¡rio 100:** O uso de um conjunto de teste separado do conjunto de treino permite avaliar a capacidade de generalizaÃ§Ã£o dos modelos para dados nÃ£o vistos.

> âš ï¸ **Nota Importante**:  A metodologia utilizada envolve a geraÃ§Ã£o de conjuntos de dados de treinamento e teste, o ajuste dos modelos e a avaliaÃ§Ã£o da taxa de erro para mÃºltiplos valores de hiperparÃ¢metros, e com mÃºltiplas simulaÃ§Ãµes.

> â— **Ponto de AtenÃ§Ã£o**:  A utilizaÃ§Ã£o de conjuntos de dados simulados permite um controle sobre a estrutura dos dados e avaliar o desempenho dos modelos em cenÃ¡rios conhecidos.

### Resultados da ComparaÃ§Ã£o: k-NN, K-Means e LVQ em CenÃ¡rios "FÃ¡cil" e "DifÃ­cil"

Os resultados da comparaÃ§Ã£o mostram como os diferentes algoritmos se comportam em cada cenÃ¡rio (fÃ¡cil e difÃ­cil) e como seus parÃ¢metros influenciam o desempenho [^13.3.1].

1.  **Problema "FÃ¡cil":** No problema "fÃ¡cil", em que as classes sÃ£o separadas por um hiperplano, o K-Means e o LVQ apresentaram resultados ligeiramente melhores do que o k-NN, para os melhores valores dos hiperparÃ¢metros. O K-Means e o LVQ conseguem capturar a estrutura linear dos dados usando poucos protÃ³tipos, enquanto o k-NN precisa de um grande nÃºmero de vizinhos para ter um desempenho competitivo.
2.  **Problema "DifÃ­cil":** No problema "difÃ­cil", onde as classes apresentam um padrÃ£o quadriculado, os mÃ©todos de protÃ³tipos (K-Means e LVQ) apresentam desempenho muito prÃ³ximo, e o k-NN apresenta um desempenho inferior para valores pequenos de k e desempenho superior para grandes valores de k. Nesse problema, o k-NN Ã© capaz de se ajustar Ã  complexidade da fronteira de decisÃ£o, desde que o nÃºmero de vizinhos seja bem ajustado.

```mermaid
graph LR
    subgraph "Comparative Results"
        direction TB
        A["Problem 'Easy': Linear Boundary"]
        B["K-Means & LVQ: Better Performance with fewer Prototypes"]
        C["k-NN: Competitive with large k"]
        D["Problem 'Difficult': Non-Linear Boundary"]
        E["K-Means & LVQ: Similar Performance"]
        F["k-NN: Poor with small k, better with large k"]
         A --> B & C
         D --> E & F
    end
```

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que, apÃ³s rodar as simulaÃ§Ãµes, obtivemos a seguinte tabela de taxas de erro mÃ©dias (em %) para o problema "fÃ¡cil" com diferentes parÃ¢metros:
>
> | MÃ©todo    | ParÃ¢metro | Taxa de Erro MÃ©dia (%) |
> |-----------|-----------|------------------------|
> | k-NN      | k=1       | 7.5                     |
> | k-NN      | k=5       | 5.2                     |
> | k-NN      | k=15      | 4.8                     |
> | K-Means   | Prot=2    | 4.5                     |
> | K-Means   | Prot=4    | 4.3                     |
> | LVQ       | Prot=2    | 4.6                     |
> | LVQ       | Prot=4    | 4.2                     |
>
> E para o problema "difÃ­cil":
>
> | MÃ©todo    | ParÃ¢metro | Taxa de Erro MÃ©dia (%) |
> |-----------|-----------|------------------------|
> | k-NN      | k=1       | 25.0                    |
> | k-NN      | k=5       | 15.0                    |
> | k-NN      | k=15      | 10.2                    |
> | K-Means   | Prot=2    | 10.1                    |
> | K-Means   | Prot=4    | 9.9                     |
> | LVQ       | Prot=2    | 10.5                    |
> | LVQ       | Prot=4    | 10.0                    |
>
> Observamos que, no problema "fÃ¡cil", K-Means e LVQ com poucos protÃ³tipos (Prot=2 ou 4) tÃªm um desempenho ligeiramente melhor que o k-NN. JÃ¡ no problema "difÃ­cil", o k-NN com k=15 consegue atingir um desempenho competitivo com os mÃ©todos de protÃ³tipos. Para k-NN, vemos que aumentar k diminui o erro no problema difÃ­cil, mas nÃ£o necessariamente no problema fÃ¡cil.

Em ambos os problemas, o K-Means e o LVQ apresentaram resultados semelhantes entre si, enquanto o desempenho do k-NN apresentou maior variabilidade, e maior sensibilidade ao valor de $k$. O melhor desempenho do k-NN no cenÃ¡rio difÃ­cil foi obtido com uma quantidade grande de vizinhos. Em problemas onde a escolha dos hiperparÃ¢metros nÃ£o pode ser feita de forma manual, o LVQ apresentou um bom desempenho de forma geral.

**Lemma 101:** O desempenho de diferentes algoritmos em diferentes cenÃ¡rios varia conforme a capacidade do modelo de se adaptar Ã s caracterÃ­sticas do problema, e a escolha ideal de algoritmo depende da estrutura dos dados e das caracterÃ­sticas da distribuiÃ§Ã£o das classes.
*Prova*: O problema "fÃ¡cil" favorece algoritmos que modelam fronteiras de decisÃ£o lineares, enquanto o problema "difÃ­cil" favorece algoritmos que podem capturar relaÃ§Ãµes nÃ£o lineares. $\blacksquare$

**CorolÃ¡rio 101:** A escolha dos hiperparÃ¢metros (k, nÃºmero de protÃ³tipos) Ã© essencial para o desempenho dos modelos, e deve ser feita com mÃ©todos de validaÃ§Ã£o e escolha de modelo.

> âš ï¸ **Nota Importante**: Em problemas lineares, K-Means e LVQ tendem a apresentar resultados comparÃ¡veis, e em problemas nÃ£o lineares, mÃ©todos mais flexÃ­veis como o k-NN com $k$ adaptado podem se destacar.

> â— **Ponto de AtenÃ§Ã£o**: Os resultados mostram como a escolha dos parÃ¢metros de cada algoritmo Ã© importante, e os resultados podem variar significativamente conforme a escolha do valor do parÃ¢metro.

### ConclusÃ£o

A comparaÃ§Ã£o de desempenho do k-NN, K-Means e LVQ em problemas simulados de duas classes mostra que cada mÃ©todo apresenta vantagens e limitaÃ§Ãµes em diferentes cenÃ¡rios. Em problemas lineares, modelos mais simples como K-Means podem ser adequados, enquanto em problemas nÃ£o lineares, modelos mais flexÃ­veis como o LVQ ou o k-NN (com $k$ ajustado) podem obter melhores resultados. A escolha do melhor modelo depende do problema especÃ­fico, e a avaliaÃ§Ã£o do desempenho deve ser feita por validaÃ§Ã£o cruzada, utilizando dados nÃ£o vistos para garantir a generalizaÃ§Ã£o do modelo. O resultado demonstra que mÃ©todos *model-free* oferecem flexibilidade em lidar com diferentes tipos de problemas de classificaÃ§Ã£o.

```mermaid
graph LR
    subgraph "Conclusion"
        direction TB
        A["k-NN, K-Means, and LVQ Performance Comparison"]
        B["Linear Problems: Simpler Models (K-Means) Adequate"]
        C["Non-Linear Problems: Flexible Models (LVQ, k-NN with optimized k) Perform Better"]
        D["Model Selection Requires Cross-Validation and Unseen Data"]
        E["Model-Free Methods Offer Flexibility"]
        A --> B
        A --> C
        B & C --> D
        D --> E
    end
```

### Footnotes

[^13.3.1]: "We tested the nearest-neighbors, K-means and LVQ classifiers on two simulated problems...Figure 13.5 shows the mean and standard error of the misclassification error for nearest-neighbors, K-means and LVQ over ten realizations, as the tuning parameters are varied. We see that K-means and LVQ give nearly identical results. For the best choices of their tuning parameters, K-means and LVQ outperform nearest-neighbors for the first problem, and they perform similarly for the second problem." *(Trecho de "13. Prototype Methods and Nearest-Neighbors")*
