## Atra√ß√£o e Repuls√£o de Prot√≥tipos: Ajuste Din√¢mico Guiado por R√≥tulos de Classe

```mermaid
graph LR
    subgraph "LVQ Prototype Adjustment"
        direction TB
        A["Training Data Point 'x·µ¢'"]
        B["Closest Prototype 'm‚±º'"]
        C{"Same Class? l(m‚±º) == l(x·µ¢)"}
        D["Attraction: 'm‚±º ‚Üê m‚±º + Œµ(x·µ¢ - m‚±º)'"]
        E["Repulsion: 'm‚±º ‚Üê m‚±º - Œµ(x·µ¢ - m‚±º)'"]
        A --> B
        B --> C
        C -- "Yes" --> D
        C -- "No" --> E
        D --> F["Updated Prototype 'm‚±º'"]
        E --> F
    end
```

### Introdu√ß√£o

Este cap√≠tulo explora o conceito de **atra√ß√£o e repuls√£o de prot√≥tipos**, um mecanismo fundamental no algoritmo **LVQ (Learning Vector Quantization)**, que permite ajustar dinamicamente o posicionamento dos prot√≥tipos com base nos r√≥tulos de classe dos dados de treinamento [^13.2.2]. A ideia central √© que, ao processar cada ponto de treinamento, os prot√≥tipos da mesma classe s√£o "atra√≠dos" pelo ponto, enquanto os prot√≥tipos de classes diferentes s√£o "repelidos". Esse processo de atra√ß√£o e repuls√£o leva a um posicionamento estrat√©gico dos prot√≥tipos nas regi√µes de decis√£o, resultando em modelos de classifica√ß√£o mais eficazes. Analisaremos como esse mecanismo opera, seu impacto no desempenho do modelo e como o LVQ se diferencia de outros m√©todos baseados em prot√≥tipos que n√£o utilizam esse mecanismo de ajuste.

### O Mecanismo de Atra√ß√£o e Repuls√£o: Ajuste Supervisionado de Prot√≥tipos

O mecanismo de **atra√ß√£o e repuls√£o de prot√≥tipos** √© uma caracter√≠stica fundamental do algoritmo **LVQ**, que o diferencia de outros m√©todos de prot√≥tipos como o K-Means [^13.2.2]. No LVQ, cada prot√≥tipo √© ajustado com base na compara√ß√£o entre seu r√≥tulo de classe e o r√≥tulo de classe do ponto de treinamento mais pr√≥ximo.

A ideia central √© que:

1.  **Atra√ß√£o:** Se o prot√≥tipo mais pr√≥ximo de um ponto de treinamento pertence √† mesma classe que o ponto, o prot√≥tipo √© movido em dire√ß√£o ao ponto. Isso faz com que o prot√≥tipo se torne mais representativo dessa classe.
2.  **Repuls√£o:** Se o prot√≥tipo mais pr√≥ximo de um ponto de treinamento pertence a uma classe diferente do ponto, o prot√≥tipo √© movido em dire√ß√£o oposta ao ponto. Isso faz com que o prot√≥tipo se afaste de regi√µes onde ele n√£o √© representativo, e aumenta a discrimina√ß√£o entre as classes.

Esse mecanismo de atra√ß√£o e repuls√£o √© guiado pelos r√≥tulos de classe dos dados de treinamento, o que torna o LVQ um algoritmo de aprendizado supervisionado. O tamanho do passo de movimenta√ß√£o dos prot√≥tipos √© controlado por um par√¢metro chamado taxa de aprendizagem (*learning rate*), que √© um hiperpar√¢metro do modelo. A taxa de aprendizado geralmente diminui com o tempo, o que garante que os prot√≥tipos converjam para uma solu√ß√£o est√°vel.

**Lemma 50:** O mecanismo de atra√ß√£o e repuls√£o do LVQ ajusta os prot√≥tipos de forma din√¢mica, posicionando-os em regi√µes estrat√©gicas do espa√ßo de *features* que melhor representam as fronteiras de decis√£o entre as classes.
*Prova*: Os prot√≥tipos s√£o movidos iterativamente com base no r√≥tulo das classes, aproximando prot√≥tipos da mesma classe e afastando prot√≥tipos de classes diferentes, criando regi√µes de decis√£o mais precisas. $\blacksquare$

**Corol√°rio 50:** A taxa de aprendizado controla o tamanho do passo da movimenta√ß√£o dos prot√≥tipos, e valores muito altos levam a oscila√ß√µes e dificuldade de converg√™ncia, enquanto valores muito baixos levam a um aprendizado lento e a modelos de desempenho inferior.

> üí° **Exemplo Num√©rico:**
>
> Imagine que temos um prot√≥tipo $m_1 = [1, 1]$ representando a classe A e um ponto de treinamento $x_1 = [2, 2]$ tamb√©m da classe A. Se a taxa de aprendizagem $\epsilon = 0.1$, a atualiza√ß√£o do prot√≥tipo ser√°:
>
> $m_1 \leftarrow m_1 + \epsilon (x_1 - m_1)$
> $m_1 \leftarrow [1, 1] + 0.1 ([2, 2] - [1, 1])$
> $m_1 \leftarrow [1, 1] + 0.1 [1, 1]$
> $m_1 \leftarrow [1.1, 1.1]$
>
> O prot√≥tipo $m_1$ se moveu em dire√ß√£o ao ponto $x_1$. Agora, se tivermos um prot√≥tipo $m_2 = [3, 3]$ representando a classe B e o mesmo ponto $x_1 = [2, 2]$ (da classe A), a atualiza√ß√£o (repuls√£o) ser√°:
>
> $m_2 \leftarrow m_2 - \epsilon (x_1 - m_2)$
> $m_2 \leftarrow [3, 3] - 0.1 ([2, 2] - [3, 3])$
> $m_2 \leftarrow [3, 3] - 0.1 [-1, -1]$
> $m_2 \leftarrow [3.1, 3.1]$
>
> O prot√≥tipo $m_2$ se moveu para longe do ponto $x_1$. Este exemplo ilustra como a atra√ß√£o e repuls√£o funcionam em termos num√©ricos.

> ‚ö†Ô∏è **Nota Importante**:  O mecanismo de atra√ß√£o e repuls√£o √© uma caracter√≠stica fundamental do LVQ, que permite que o algoritmo ajuste os prot√≥tipos com base nas informa√ß√µes sobre os r√≥tulos de classe.

> ‚ùó **Ponto de Aten√ß√£o**:  O mecanismo de atra√ß√£o e repuls√£o, juntamente com a taxa de aprendizagem, √© respons√°vel por posicionar os prot√≥tipos em regi√µes de alta densidade de cada classe e pr√≥ximo das fronteiras de decis√£o, o que leva a modelos discriminativos e com bom desempenho.

### Implementa√ß√£o do Mecanismo de Atra√ß√£o e Repuls√£o no LVQ

A implementa√ß√£o do mecanismo de atra√ß√£o e repuls√£o no LVQ √© relativamente simples [^13.2.2]. Seja $x_i$ um ponto de treinamento e seja $m_j$ o prot√≥tipo mais pr√≥ximo de $x_i$. O ajuste do prot√≥tipo $m_j$ √© dado pelas seguintes regras:

1.  **Atra√ß√£o (Prot√≥tipos da Mesma Classe):** Se o r√≥tulo de classe do prot√≥tipo $m_j$ for igual ao r√≥tulo de classe do ponto $x_i$ (ou seja, $l(m_j) = l(x_i)$), ent√£o o prot√≥tipo √© movido em dire√ß√£o ao ponto de treinamento:
    $$m_j \leftarrow m_j + \epsilon (x_i - m_j)$$
    onde $\epsilon$ √© a taxa de aprendizagem.
2.  **Repuls√£o (Prot√≥tipos de Classes Diferentes):** Se o r√≥tulo de classe do prot√≥tipo $m_j$ for diferente do r√≥tulo de classe do ponto $x_i$ (ou seja, $l(m_j) \neq l(x_i)$), ent√£o o prot√≥tipo √© movido em dire√ß√£o oposta ao ponto de treinamento:
    $$m_j \leftarrow m_j - \epsilon (x_i - m_j)$$

A taxa de aprendizado ($\epsilon$) geralmente diminui com o tempo, seguindo um esquema de decaimento pr√©-definido. A repeti√ß√£o dos passos de identifica√ß√£o do prot√≥tipo mais pr√≥ximo e atualiza√ß√£o do prot√≥tipo garante que os prot√≥tipos se posicionem estrategicamente no espa√ßo de *features*.

```mermaid
graph LR
    subgraph "LVQ Update Rule"
        direction TB
         A["Find Closest Prototype: 'm‚±º' to 'x·µ¢'"]
         B{"Check Class Labels: 'l(m‚±º)' == 'l(x·µ¢)'"}
         C["Attract: 'm‚±º ‚Üê m‚±º + Œµ(x·µ¢ - m‚±º)'"]
         D["Repel: 'm‚±º ‚Üê m‚±º - Œµ(x·µ¢ - m‚±º)'"]
         E["Repeat with Decay in 'Œµ'"]
         A --> B
         B -- "Yes" --> C
         B -- "No" --> D
         C --> E
         D --> E
    end
```

**Lemma 51:** A aplica√ß√£o da regra de atualiza√ß√£o do LVQ, com atra√ß√£o de prot√≥tipos da mesma classe e repuls√£o de prot√≥tipos de classes diferentes, faz com que os prot√≥tipos se posicionem perto das fronteiras de decis√£o entre as classes, o que melhora o desempenho do modelo de classifica√ß√£o.
*Prova*: A regra de atualiza√ß√£o garante a aproxima√ß√£o de prot√≥tipos da classe correta e o afastamento dos prot√≥tipos de outras classes, levando a uma melhor representa√ß√£o das fronteiras de decis√£o. $\blacksquare$

**Corol√°rio 51:** O decaimento gradual da taxa de aprendizado garante que os prot√≥tipos convirjam para uma solu√ß√£o est√°vel e evitam oscila√ß√µes durante o processo de aprendizado.

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar uma situa√ß√£o com dois prot√≥tipos e um ponto de treinamento. Suponha que temos dois prot√≥tipos, $m_1 = [0.5, 0.5]$ (classe A) e $m_2 = [1.5, 1.5]$ (classe B), e um ponto de treinamento $x_1 = [0.8, 0.7]$ (classe A). Inicialmente, $m_1$ √© o prot√≥tipo mais pr√≥ximo de $x_1$. Usando uma taxa de aprendizagem inicial de $\epsilon = 0.2$ e aplicando a regra de atra√ß√£o:
>
> $m_1 \leftarrow [0.5, 0.5] + 0.2 ([0.8, 0.7] - [0.5, 0.5])$
> $m_1 \leftarrow [0.5, 0.5] + 0.2 [0.3, 0.2]$
> $m_1 \leftarrow [0.56, 0.54]$
>
> Agora, suponha que processamos outro ponto $x_2 = [1.2, 1.3]$ (classe B). O prot√≥tipo mais pr√≥ximo √© $m_2$. Aplicando a regra de atra√ß√£o:
>
> $m_2 \leftarrow [1.5, 1.5] + 0.2 ([1.2, 1.3] - [1.5, 1.5])$
> $m_2 \leftarrow [1.5, 1.5] + 0.2 [-0.3, -0.2]$
> $m_2 \leftarrow [1.44, 1.46]$
>
> Se, em vez disso, $x_2$ fosse da classe A, ent√£o $m_2$ seria repelido:
>
> $m_2 \leftarrow [1.5, 1.5] - 0.2 ([1.2, 1.3] - [1.5, 1.5])$
> $m_2 \leftarrow [1.5, 1.5] - 0.2 [-0.3, -0.2]$
> $m_2 \leftarrow [1.56, 1.54]$
>
> Este exemplo mostra como os prot√≥tipos se movem de acordo com a classe dos pontos de treinamento.

> ‚ö†Ô∏è **Nota Importante**: A implementa√ß√£o do mecanismo de atra√ß√£o e repuls√£o no LVQ envolve a atualiza√ß√£o dos prot√≥tipos com base nas informa√ß√µes sobre os r√≥tulos de classe dos dados de treinamento.

> ‚ùó **Ponto de Aten√ß√£o**: O esquema de decaimento da taxa de aprendizagem e o valor inicial da taxa s√£o hiperpar√¢metros que afetam a converg√™ncia e o desempenho do algoritmo LVQ.

### Compara√ß√£o com o Posicionamento de Prot√≥tipos no K-Means

O posicionamento de prot√≥tipos no **K-Means** difere fundamentalmente do LVQ, pois o K-Means n√£o utiliza informa√ß√µes sobre os r√≥tulos de classe para ajustar os prot√≥tipos [^13.2.1]. No K-Means, os prot√≥tipos (centr√≥ides) s√£o posicionados nos centros dos *clusters* de dados, buscando minimizar a vari√¢ncia intra-cluster. O K-Means n√£o move os prot√≥tipos com o objetivo de discriminar as classes, como o LVQ, o que pode levar a prot√≥tipos que n√£o representam adequadamente as fronteiras de decis√£o.

```mermaid
graph LR
    subgraph "K-Means Prototype Positioning"
        direction TB
        A["Find cluster assignments"]
        B["Update centroids to mean of each cluster"]
        C["Repeat A and B until convergence"]
        A --> B
        B --> C
    end
```

A aus√™ncia de um mecanismo de atra√ß√£o e repuls√£o no K-Means limita sua capacidade de modelar fronteiras de decis√£o complexas, especialmente em cen√°rios onde as classes se sobrep√µem ou apresentam formas irregulares. O K-Means √© mais adequado para problemas onde as classes s√£o aproximadamente convexas e linearmente separ√°veis, enquanto o LVQ √© mais adequado para problemas com fronteiras de decis√£o n√£o lineares e mais desafiadoras.

**Lemma 52:** O K-Means busca representar as regi√µes de dados com centros de clusters, mas n√£o utiliza informa√ß√µes sobre r√≥tulos das classes, limitando sua capacidade de representar adequadamente as fronteiras de decis√£o.
*Prova*: A regra de atualiza√ß√£o do K-means move o centr√≥ide para a m√©dia dos pontos, e n√£o h√° nenhuma influ√™ncia do r√≥tulo da classe sobre o posicionamento. $\blacksquare$

**Corol√°rio 52:** A falta de um mecanismo de atra√ß√£o e repuls√£o no K-Means limita sua capacidade de posicionar estrategicamente os prot√≥tipos, o que pode levar a uma capacidade de generaliza√ß√£o inferior para problemas de classifica√ß√£o complexos.

> üí° **Exemplo Num√©rico:**
>
> Para ilustrar a diferen√ßa, imagine que temos duas classes, A e B, em um espa√ßo 2D. A classe A forma um c√≠rculo em torno do ponto [1,1] e a classe B forma um c√≠rculo em torno do ponto [3,3].
>
> **K-Means:** Se aplicarmos K-Means com dois prot√≥tipos para todo o conjunto de dados, sem levar em conta as classes, os centr√≥ides provavelmente se posicionar√£o no meio dos dois c√≠rculos, sem necessariamente representar a fronteira de decis√£o.
>
> **LVQ:** O LVQ, ao contr√°rio, usaria prot√≥tipos para cada classe e os moveria para as regi√µes de maior densidade de cada classe e para perto da fronteira, resultando em um modelo que discrimina melhor as classes.
>
> ```mermaid
> graph LR
>     A(Classe A) -->|K-Means Centroid| C
>     B(Classe B) -->|K-Means Centroid| C
>     A -->|LVQ Prot√≥tipo A| D
>     B -->|LVQ Prot√≥tipo B| E
>     style C fill:#f9f,stroke:#333,stroke-width:2px
>     style D fill:#ccf,stroke:#333,stroke-width:2px
>     style E fill:#ccf,stroke:#333,stroke-width:2px
> ```
>
> No diagrama acima, o centr√≥ide do K-Means (C) fica no meio, enquanto os prot√≥tipos do LVQ (D e E) se posicionam mais pr√≥ximos das fronteiras das classes.

> ‚ö†Ô∏è **Nota Importante**: O K-Means n√£o utiliza informa√ß√µes sobre os r√≥tulos de classe no posicionamento dos prot√≥tipos, ao contr√°rio do LVQ, que se baseia no mecanismo de atra√ß√£o e repuls√£o para ajustar os prot√≥tipos com base nos r√≥tulos de classe.

> ‚ùó **Ponto de Aten√ß√£o**:  A capacidade do LVQ de ajustar os prot√≥tipos com base nas informa√ß√µes sobre os r√≥tulos de classe permite que ele crie fronteiras de decis√£o mais precisas e eficazes em compara√ß√£o com o K-Means.

### Conclus√£o

O mecanismo de atra√ß√£o e repuls√£o de prot√≥tipos √© uma caracter√≠stica fundamental do LVQ, que permite que o algoritmo posicione estrategicamente os prot√≥tipos no espa√ßo de *features*, de forma a melhor representar a distribui√ß√£o das classes e suas fronteiras de decis√£o. O ajuste din√¢mico dos prot√≥tipos com base nos r√≥tulos de classe diferencia o LVQ do K-Means e o torna mais adequado para lidar com fronteiras de decis√£o complexas, resultando em modelos de classifica√ß√£o com melhor capacidade de generaliza√ß√£o e mais precisos. A compreens√£o desse mecanismo √© essencial para utilizar e adaptar o LVQ a uma variedade de problemas de classifica√ß√£o e reconhecimento de padr√µes.

### Footnotes

[^13.2.2]: "In this technique due to Kohonen (1989), prototypes are placed strategically with respect to the decision boundaries in an ad-hoc way. LVQ is an online algorithm-observations are processed one at a time. The idea is that the training points attract prototypes of the correct class, and repel other prototypes. When the iterations settle down, prototypes should be close to the training points in their class." *(Trecho de "13. Prototype Methods and Nearest-Neighbors")*

[^13.2.1]: "K-means clustering is a method for finding clusters and cluster centers in a set of unlabeled data... To use K-means clustering for classification of labeled data, the steps are: apply K-means clustering to the training data in each class separately, using R prototypes per class; assign a class label to each of the K √ó R prototypes; classify a new feature x to the class of the closest prototype." *(Trecho de "13. Prototype Methods and Nearest-Neighbors")*
