## Modelos de Verossimilhança Local

### Introdução
Este capítulo explora os métodos de *kernel smoothing* e modelos relacionados, com foco na flexibilidade na estimativa da função de regressão $f(X)$ [^1]. Em particular, esta seção se concentra nos modelos de verossimilhança local, que permitem que os parâmetros variem localmente com base nos dados observados. Como vimos anteriormente, modelos paramétricos podem ser feitos locais se o método de ajuste acomodar pesos de observação. Exploraremos como associar um parâmetro $\theta_i$ a cada observação $y_i$, linear nos covariáveis $x_i$, e basear a inferência para $\beta$ na log-verossimilhança local a $x_0$, permitindo uma modelagem mais flexível de $\theta(X)$ [^15].

### Conceitos Fundamentais

#### Verossimilhança Local
Em modelos de verossimilhança local, associamos um parâmetro $\theta_i$ a cada observação $y_i$, onde $\theta_i$ é linear nos covariáveis $x_i$, ou seja, $\theta_i = x_i^T \beta$ [^15]. A inferência para $\beta$ é baseada na log-verossimilhança local em torno de um ponto $x_0$, permitindo uma modelagem mais flexível de $\theta(X)$. A log-verossimilhança local é dada por:
$$\nl(\beta(x_0)) = \sum_{i=1}^N K_{\lambda}(x_0, x_i) l(y_i, x_i^T \beta(x_0))$$
onde $K_{\lambda}(x_0, x_i)$ é uma função kernel que pondera as observações com base na proximidade de $x_i$ a $x_0$ [^15].

#### Modelos Lineares Generalizados (GLM)
Muitos modelos de verossimilhança, particularmente a família de Modelos Lineares Generalizados (GLM), envolvem os covariáveis de forma linear [^15]. A verossimilhança local permite uma flexibilização de um modelo globalmente linear para um que seja linear localmente.

#### Variações e Extensões
Existem várias maneiras de estender o conceito de verossimilhança local:

1.  Variáveis diferentes podem ser associadas a $\theta$ daquelas usadas para definir a verossimilhança local [^16]:
    $$\nl(\theta(x_0)) = \sum_{i=1}^N K_{\lambda}(x_0, z_i) l(y_i, \eta(x_i, \theta(x_0)))$$
    onde $\eta(x, \theta)$ pode ser um modelo linear em $x$. Isso ajusta um modelo de coeficiente variável $\theta(z)$ maximizando a verossimilhança local.

2.  Modelos auto-regressivos de séries temporais de ordem $k$ podem ser ajustados usando verossimilhança local [^16]. Dado um conjunto de lags $z_t = (y_{t-1}, y_{t-2}, ..., y_{t-k})$, o modelo se torna $y_t = z_t^T \beta + \epsilon_t$. O ajuste por mínimos quadrados locais com um kernel $K(x_0, z_t)$ permite que o modelo varie de acordo com o histórico de curto prazo da série.

#### Exemplo: Regressão Logística Multiclasse Local
Considere a versão local do modelo de regressão logística linear multiclasse (Capítulo 4 [^16]). Os dados consistem em características $x_i$ e uma resposta categórica associada $g_i \in \\{1, 2, ..., J\\}$, e o modelo linear tem a forma:
$$Pr(G = j|X = x) = \frac{e^{\beta_{j0} + \beta_j^T x}}{1 + \sum_{l=1}^{J-1} e^{\beta_{l0} + \beta_l^T x}}$$
A log-verossimilhança local para este modelo J-classe pode ser escrita como:
$$\sum_{i=1}^N K_{\lambda}(x_0, x_i) \left[ \beta_{g_i 0}(x_0) + \beta_{g_i}(x_0)^T (x_i - x_0) - \log \left( 1 + \sum_{k=1}^{J-1} e^{\beta_{k0}(x_0) + \beta_k(x_0)^T (x_i - x_0)} \right) \right]$$

Notamos que:
*   Usamos $g_i$ como um subscrito na primeira linha para selecionar o numerador apropriado [^16].
*   $\beta_{J0} = 0$ e $\beta_J = 0$ pela definição do modelo [^16].
*   Centramos as regressões locais em $x_0$, de modo que as probabilidades posteriores ajustadas em $x_0$ são simplesmente [^16]:
    $$Pr(G = j|X = x_0) = \frac{e^{\beta_{j0}(x_0)}}{1 + \sum_{l=1}^{J-1} e^{\beta_{l0}(x_0)}}$$

### Conclusão
Os modelos de verossimilhança local oferecem uma abordagem flexível para modelar dados, permitindo que os parâmetros variem localmente com base nas características dos dados [^15]. Essa abordagem pode ser particularmente útil quando a relação entre as variáveis preditoras e a variável resposta não é constante em todo o espaço de características. Ao usar funções kernel para ponderar as observações locais, os modelos de verossimilhança local podem se adaptar a estruturas complexas nos dados. As técnicas de suavização kernel descritas anteriormente neste capítulo fornecem as ferramentas necessárias para implementar esses modelos de forma eficaz.

### Referências
[^1]: Page 191: "In this chapter we describe a class of regression techniques that achieve flexibility in estimating the regression function f(X) over the domain IR by fitting a different but simple model separately at each query point xo."
[^15]: Page 205: "Local likelihood models associate a parameter θi with each observation yi, linear in the covariate(s) xi, and base inference for β on the log-likelihood local to x0, allowing more flexible modeling of θ(X)."
[^16]: Page 206: "As above, except different variables are associated with θ from those used for defining the local likelihood..."
<!-- END -->