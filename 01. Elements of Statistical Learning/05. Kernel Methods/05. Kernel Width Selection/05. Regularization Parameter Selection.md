## Seleção do Parâmetro de Regularização

### Introdução
A seleção apropriada do parâmetro de regularização é crucial para o desempenho de métodos de *kernel smoothing* [^1]. Um parâmetro de regularização mal escolhido pode levar a *overfitting* (alta variância) ou *underfitting* (alto viés) dos dados [^3]. Este capítulo explora diferentes técnicas para selecionar o parâmetro de regularização, focando em validação cruzada e graus de liberdade efetivos.

### Conceitos Fundamentais

A escolha do parâmetro $\lambda$ que determina a largura do *kernel* é fundamental. Um $\lambda$ grande implica menor variância (médias sobre mais observações), mas maior *bias* (assume-se que a função verdadeira é constante dentro da janela). Métricas de largura de janela (constante $h_{\lambda}(x_0)$) tendem a manter o *bias* da estimativa constante, mas a variância é inversamente proporcional à densidade local. Larguras de janela do vizinho mais próximo exibem o comportamento oposto; a variância permanece constante e o *bias* absoluto varia inversamente com a densidade local [^3].

**Validação Cruzada**
A validação cruzada é uma técnica geral para estimar o desempenho de um modelo preditivo em dados não vistos. Ela envolve particionar os dados em subconjuntos, treinar o modelo em alguns subconjuntos e avaliar seu desempenho em subconjuntos restantes. Existem diferentes tipos de validação cruzada, incluindo:

*   **Validação Cruzada Leave-One-Out (LOOCV):** Nesta abordagem, cada observação é usada uma vez como um conjunto de validação, enquanto o restante das observações é usado como conjunto de treinamento. O erro de validação cruzada é então calculado como a média dos erros em todas as observações. A validação cruzada *leave-one-out* é particularmente simples para estimadores lineares [^9].

*   **Validação Cruzada Generalizada (Cp):** A estatística $C_p$ é uma estimativa do erro de predição, ajustada para o número de parâmetros no modelo. É definida como [^9, Ex. 6.10]:

    $$C_p = ASR(\lambda) + \frac{2\sigma^2}{N} trace(S_{\lambda})$$

    onde $ASR(\lambda)$ é o erro quadrático médio (Average Squared Residual) no conjunto de treinamento, $\sigma^2$ é uma estimativa da variância do erro, $N$ é o tamanho da amostra e $trace(S_{\lambda})$ são os graus de liberdade efetivos.

*   **Validação Cruzada K-Fold:** Nesta abordagem, os dados são particionados em $k$ subconjuntos de tamanhos aproximadamente iguais. Para cada subconjunto, o modelo é treinado nos subconjuntos restantes e avaliado no subconjunto atual. O erro de validação cruzada é então calculado como a média dos erros em todos os subconjuntos.

A validação cruzada $k$-fold também pode ser usada [^9].

**Graus de Liberdade Efetivos**
Os graus de liberdade efetivos são uma medida da complexidade de um modelo. Em *kernel smoothing*, os graus de liberdade efetivos são definidos como o traço da matriz *smoother* $S_x$, onde $\hat{f} = S_x y$ [^9]. A matriz *smoother* $S_x$ é construída a partir dos *kernels* equivalentes [^9]. O traço da matriz *smoother*, $trace(S_x)$, pode ser usado para calibrar a quantidade de *smoothing* [^9].

Para regressão linear local, a matriz *smoother* é construída a partir dos *kernels* equivalentes e tem a entrada *ij*-ésima dada por [^9]:

$${S_x}_{ij} = l_i(x_j)$$

onde $l_i(x_j)$ são os *kernels* equivalentes.

### Conclusão

A seleção do parâmetro de regularização é um passo crítico em *kernel smoothing*. Validação cruzada e graus de liberdade efetivos são ferramentas úteis para selecionar um valor apropriado para o parâmetro de regularização. A escolha da técnica específica dependerá das características do problema e dos recursos computacionais disponíveis.

### Referências
[^1]: Página 191
[^3]: Página 193
[^9]: Página 199
<!-- END -->