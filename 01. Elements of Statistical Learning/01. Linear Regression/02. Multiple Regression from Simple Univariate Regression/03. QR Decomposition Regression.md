## A Decomposição QR e a Regressão Múltipla

### Introdução
Este capítulo explora a **decomposição QR** no contexto da regressão múltipla, detalhando sua utilidade na obtenção de uma base ortogonal conveniente para o espaço das colunas da matriz de design e na simplificação da solução de mínimos quadrados [^55]. A regressão múltipla, como vimos anteriormente [^52], lida com a modelagem da relação entre uma variável resposta e múltiplos preditores, e a decomposição QR oferece uma abordagem computacionalmente eficiente para resolver o problema de mínimos quadrados.

### Conceitos Fundamentais

A **decomposição QR** de uma matriz $X$ expressa $X$ como o produto de uma matriz ortogonal $Q$ e uma matriz triangular superior $R$ [^55]:
$$X = QR$$
onde $Q^TQ = I$. Essa decomposição é fundamental para resolver problemas de mínimos quadrados de forma eficiente e numericamente estável.

**Base Ortogonal para o Espaço das Colunas de X:** A matriz $Q$ fornece uma base ortogonal para o espaço das colunas de $X$. Isso significa que as colunas de $Q$ são mutuamente ortogonais e cada coluna tem norma unitária. Essa base ortogonal simplifica muitos cálculos relacionados à regressão, incluindo a solução de mínimos quadrados e a projeção ortogonal de $y$ no espaço das colunas de $X$ [^55].

**Solução de Mínimos Quadrados:** A solução de mínimos quadrados para o vetor de coeficientes $\beta$ pode ser expressa em termos da decomposição QR como [^55]:
$$beta = R^{-1}Q^Ty$$
e a projeção de $y$ no espaço das colunas de $X$ (ou seja, os valores ajustados $\hat{y}$) é dada por [^55]:
$$hat{y} = QQ^Ty$$
A grande vantagem dessa formulação é que $R$ é uma matriz triangular superior, o que torna a solução de $\beta$ computacionalmente eficiente através de *back-substitution* [^55].

**Algoritmo de Gram-Schmidt:** O algoritmo de Gram-Schmidt é um procedimento para ortogonalizar um conjunto de vetores linearmente independentes. No contexto da regressão múltipla, o procedimento de Gram-Schmidt pode ser usado para calcular a decomposição QR da matriz de design $X$ [^55]. O algoritmo procede ortogonalizando sequencialmente as colunas de $X$, produzindo as colunas da matriz $Q$ e os elementos da matriz $R$.

**Algoritmo 3.1 (Regressão por Ortogonalização Sucessiva):** O Algoritmo 3.1 [^54], também conhecido como procedimento de Gram-Schmidt, detalha como ortogonalizar as colunas de $X$ sucessivamente.
1. Inicialize $z_0 = x_0 = 1$.
2. Para $j = 1, 2, ..., p$:
   - Regrida $x_j$ sobre $z_0, z_1, ..., z_{j-1}$ para produzir coeficientes $\gamma_{\ell j} = (z_\ell, x_j) / (z_\ell, z_\ell)$, $\ell = 0, ..., j-1$ e vetor residual $z_j = x_j - \sum_{\ell=0}^{j-1} \gamma_{\ell j}z_\ell$.
3. Regrida $y$ sobre o residual $z_p$ para obter a estimativa $\beta_p$.

Este algoritmo resulta em [^54]:
$$beta_p = \frac{(z_p, y)}{(z_p, z_p)}$$

**Decomposição QR em Forma Matricial:** O passo 2 do Algoritmo 3.1 pode ser representado em forma matricial como [^55]:
$$X = Z\Gamma$$
onde $Z$ tem como colunas os $z_j$ (em ordem) e $\Gamma$ é a matriz triangular superior com entradas $\gamma_{kj}$. Introduzindo a matriz diagonal $D$ com a j-ésima entrada diagonal $D_{jj} = ||z_j||$, obtemos [^55]:
$$X = ZD^{-1}DF = QR$$
onde $Q = ZD^{-1}$ é uma matriz ortogonal ($Q^TQ = I$) e $R$ é uma matriz triangular superior.

### Conclusão

A decomposição QR oferece uma ferramenta poderosa para a análise de regressão múltipla, fornecendo uma base ortogonal para o espaço das colunas da matriz de design. Essa base simplifica a solução de mínimos quadrados e oferece insights sobre a estrutura dos dados. O procedimento de Gram-Schmidt é um método prático para calcular a decomposição QR, e a compreensão desses conceitos é essencial para o desenvolvimento e a aplicação de modelos de regressão eficientes e precisos.

### Referências
[^55]: Linear Models and Least Squares, p. 55
[^52]: Multiple Regression from Simple Univariate Regression, p. 52
[^54]: Regression by Successive Orthogonalization, p. 54
<!-- END -->