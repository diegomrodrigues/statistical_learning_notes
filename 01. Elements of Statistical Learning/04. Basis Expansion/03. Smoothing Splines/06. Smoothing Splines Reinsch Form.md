## Decomposição Espectral e Shrinkage Diferencial em Smoothing Splines

### Introdução
Este capítulo aprofunda a análise de **smoothing splines**, explorando a representação de Reinsch e a decomposição espectral da **matriz smoother**. Como vimos anteriormente, smoothing splines são uma ferramenta poderosa para ajustar dados, equilibrando a fidelidade aos dados observados com a suavidade da função resultante. Este capítulo se concentrará em como a decomposição espectral revela o mecanismo subjacente de **shrinkage diferencial** aplicado aos componentes da função.

### Conceitos Fundamentais

A **forma de Reinsch** de um smoothing spline é dada por $S_{\lambda} = (I + \lambda K)^{-1}$ [^1]. Aqui, $S_{\lambda}$ representa a **matriz smoother**, $I$ é a **matriz identidade**, $K$ é a **matriz de penalidade**, e $\lambda$ é o **parâmetro de suavização**. A matriz de penalidade $K$ quantifica a rugosidade da função, e $\lambda$ controla o trade-off entre o ajuste aos dados e a suavidade.

A **decomposição espectral** de $S_{\lambda}$ oferece insights valiosos sobre como o smoothing spline opera. Especificamente, $S_{\lambda}$ pode ser expressa em termos de seus **autovetores** $u_k$ e **autovalores** $p_k(\lambda)$ [^1]. A ação do smoothing spline pode ser vista como uma decomposição de $y$ (o vetor de resposta) em relação a uma base completa $\{u_k\}$, seguida por um *encolhimento diferencial* das contribuições usando os fatores $p_k(\lambda)$ [^1].

Formalmente, a decomposição espectral de $S_{\lambda}$ é dada por:

$$ S_{\lambda} = \sum_{k=1}^{N} p_k(\lambda) u_k u_k^T $$

onde:
*   $N$ é o número de observações
*   $u_k$ são os autovetores ortonormais de $S_{\lambda}$ (e também de $K$)
*   $p_k(\lambda)$ são os autovalores correspondentes, que dependem de $\lambda$

A **saída do smoothing spline** pode então ser escrita como:

$$ \hat{f} = S_{\lambda} y = \sum_{k=1}^{N} p_k(\lambda) \langle u_k, y \rangle u_k $$

onde $\langle u_k, y \rangle$ representa o produto interno entre o autovetor $u_k$ e o vetor de resposta $y$.

É crucial notar que os **autovetores** $u_k$ *não são afetados* por mudanças em $\lambda$ [^1]. Isso significa que toda a família de smoothing splines indexada por $\lambda$ compartilha os mesmos autovetores. Apenas os **autovalores** $p_k(\lambda)$ variam com $\lambda$, determinando o grau de *shrinkage* aplicado a cada componente $u_k$.

A matriz de penalidade $K$ é conhecida como a **matriz de penalidade**, e de fato uma forma quadrática em $K$ tem uma representação em termos de uma soma ponderada de segundas diferenças ao quadrado (divididas) [^1].

A forma como os autovalores $p_k(\lambda)$ diminuem com o aumento de $k$ (associado a autovetores de maior frequência) determina o comportamento de suavização. Autovetores correspondentes a autovalores maiores de $K$ (e, portanto, menores $p_k(\lambda)$) são mais fortemente penalizados, resultando em maior suavização.

A relação entre os autovalores $p_k(\lambda)$ da matriz smoother e os autovalores $d_k$ da matriz de penalidade $K$ é dada por [^1]:

$$ p_k(\lambda) = \frac{1}{1 + \lambda d_k} $$

Esta equação demonstra que:

*   Para $\lambda = 0$, $p_k(\lambda) = 1$ para todo $k$, e não há penalidade, resultando em interpolação.
*   À medida que $\lambda \rightarrow \infty$, $p_k(\lambda) \rightarrow 0$ para todo $k$ (exceto possivelmente para os primeiros autovetores associados ao espaço nulo de $K$), resultando em uma linha de mínimos quadrados simples, já que nenhuma segunda derivada pode ser tolerada [^1].

Este resultado relaciona-se com a forma de Reinsch [^1]. A forma de Reinsch $S_{\lambda} = (I + \lambda K)^{-1}$ expressa a matriz smoother em termos da matriz de penalidade $K$.

### Conclusão

A decomposição espectral da matriz smoother $S_{\lambda}$ revela que o smoothing spline opera através da decomposição do vetor de resposta $y$ em uma base ortonormal de autovetores $\{u_k\}$ e, em seguida, aplicando um *shrinkage diferencial* às contribuições de cada autovetor usando os autovalores $p_k(\lambda)$ [^1]. Como os autovetores $u_k$ permanecem constantes para diferentes valores do parâmetro de suavização $\lambda$, a família de smoothing splines indexada por $\lambda$ compartilha a mesma base de autovetores, com apenas o grau de *shrinkage* variando. Este framework fornece uma compreensão profunda do mecanismo de suavização e permite uma análise mais precisa do compromisso entre o ajuste aos dados e a suavidade da função resultante.

### Referências
[^1]: Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning: Data Mining, Inference, and Prediction*. Springer Science & Business Media.

<!-- END -->