## Modelagem Probabilística e Estimação: Verossimilhança Condicional vs. Conjunta na Regressão Logística e LDA

### Introdução

Como explorado anteriormente neste capítulo sobre métodos lineares para classificação, tanto a **Linear Discriminant Analysis (LDA)** quanto a **Regressão Logística** são técnicas fundamentais que frequentemente resultam em fronteiras de decisão lineares. Uma análise inicial das suas formulações matemáticas pode sugerir uma grande semelhança, especialmente quando observamos a forma dos logaritmos das razões de chances (log-odds) posteriores. Para a LDA, sob a suposição de densidades Gaussianas com matriz de covariância comum $\Sigma$, o log-odds entre as classes $k$ e $K$ é linear em $x$ [^1]:

$$\
\log \frac{\Pr(G=k|X=x)}{\Pr(G=K|X=x)} = \log \frac{\pi_k}{\pi_K} - \frac{1}{2}(\mu_k + \mu_K)^T\Sigma^{-1}(\mu_k - \mu_K) + x^T\Sigma^{-1}(\mu_k - \mu_K) = \alpha_{k0} + \alpha_k^T x \quad (4.33)
$$

De forma análoga, o modelo de regressão logística é construído explicitamente para ter logits lineares [^2]:

$$\
\log \frac{\Pr(G=k|X=x)}{\Pr(G=K|X=x)} = \beta_{k0} + \beta_k^T x \quad (4.34)
$$

Apesar desta semelhança formal, existe uma diferença crucial na maneira como os coeficientes lineares ($\alpha$ e $\beta$) são estimados, que reflete abordagens fundamentalmente distintas para a modelagem probabilística subjacente. Este capítulo aprofunda essa distinção, focando em como a regressão logística modela diretamente a distribuição *condicional* $\Pr(G|X)$ através da maximização da verossimilhança condicional, deixando a distribuição *marginal* $\Pr(X)$ não especificada, em contraste com a LDA, que modela a distribuição *conjunta* $\Pr(X, G)$ via maximização da verossimilhança completa.

### Conceitos Fundamentais: Verossimilhança Condicional e a Densidade Marginal em Regressão Logística

A abordagem da **regressão logística** concentra-se exclusivamente na modelagem das probabilidades posteriores $\Pr(G=k|X=x)$. O modelo, como visto nas equações (4.17) e (4.18) [^3], especifica a forma funcional destas probabilidades diretamente em termos dos parâmetros $\beta_{k0}$ e $\beta_k$:

$$\
\Pr(G=k|X=x) = \frac{\exp(\beta_{k0} + \beta_k^T x)}{1 + \sum_{l=1}^{K-1} \exp(\beta_{l0} + \beta_l^T x)}, \quad k=1, \dots, K-1 \quad (4.36 \text{ adaptada})
$$
$$\
\Pr(G=K|X=x) = \frac{1}{1 + \sum_{l=1}^{K-1} \exp(\beta_{l0} + \beta_l^T x)} \quad (4.36 \text{ adaptada})
$$

A estimação dos parâmetros $\theta = \\{\beta_{10}, \beta_1, \dots, \beta_{(K-1)0}, \beta_{K-1}\\}$ é realizada através da maximização da **verossimilhança condicional** dos dados de treinamento $G$ dado $X$. Assumindo $N$ observações independentes $(x_i, g_i)$, a log-verossimilhança condicional é dada por [^4]:

$$\
l(\theta) = \sum_{i=1}^N \log \Pr(G=g_i | X=x_i; \theta) \quad (4.19 \text{ adaptada})
$$

> O ponto crucial desta abordagem é que *o modelo de regressão logística deixa a densidade marginal de X, $\Pr(X)$, como uma função de densidade arbitrária* [^5]. Os parâmetros de $\Pr(G|X)$ são ajustados maximizando a verossimilhança condicional (multinomial, dadas as probabilidades $\Pr(G=k|X)$) [^5].

Embora $\Pr(X)$ seja totalmente ignorada no processo de ajuste dos parâmetros $\beta$, pode-se considerar que essa densidade marginal está sendo estimada de forma totalmente não paramétrica e irrestrita, utilizando a função de distribuição empírica que atribui massa $1/N$ a cada observação $x_i$ [^5]. A estimação foca unicamente na relação entre os preditores $X$ e a variável resposta $G$.

### Conceitos Fundamentais: Verossimilhança Conjunta e a Densidade Marginal em LDA

Em contraste, a **LDA** baseia-se na modelagem da distribuição *conjunta* $\Pr(X, G=k)$. Como detalhado na Seção 4.3, a LDA assume que as **densidades condicionais de classe** $f_k(x) = \Pr(X=x|G=k)$ são Gaussianas multivariadas com um vetor de médias $\mu_k$ específico da classe e uma matriz de covariância $\Sigma$ comum a todas as classes [^6]:

$$\
f_k(x) = \frac{1}{(2\pi)^{p/2} |\Sigma|^{1/2}} \exp\left(-\frac{1}{2}(x-\mu_k)^T \Sigma^{-1} (x-\mu_k)\right) \quad (4.8)
$$

Utilizando o teorema de Bayes, as probabilidades posteriores $\Pr(G=k|X=x)$ são derivadas a partir destas densidades condicionais e das probabilidades a priori $\pi_k = \Pr(G=k)$ [^7]:

$$\
\Pr(G=k|X=x) = \frac{f_k(x) \pi_k}{\sum_{l=1}^K f_l(x) \pi_l} \quad (4.7)
$$

A estimação dos parâmetros na LDA ($\mu_k$, $\Sigma$, $\pi_k$) é realizada maximizando a **verossimilhança conjunta** (ou completa) baseada na densidade conjunta [^5]:

$$\
\Pr(X, G=k) = \Pr(X|G=k) \Pr(G=k) = f_k(x) \pi_k = \phi(X; \mu_k, \Sigma) \pi_k \quad (4.37)
$$

onde $\phi$ denota a função de densidade Gaussiana. Notavelmente, esta abordagem implica um modelo específico para a densidade marginal $\Pr(X)$. A densidade marginal $\Pr(X)$ é inerentemente modelada como uma mistura de distribuições Gaussianas [^8]:

$$\
\Pr(X) = \sum_{k=1}^K \Pr(X|G=k) \Pr(G=k) = \sum_{k=1}^K \pi_k \phi(X; \mu_k, \Sigma) \quad (4.38)
$$

Portanto, ao contrário da regressão logística, a estimação na LDA utiliza informações sobre a distribuição marginal dos preditores $X$, conforme ditado pela suposição Gaussiana.

### Implicações das Abordagens Distintas

A diferença fundamental entre maximizar a verossimilhança condicional (Regressão Logística) e a verossimilhança conjunta (LDA) tem implicações significativas:

1.  **Suposições do Modelo:** A regressão logística faz menos suposições, especificando apenas a forma funcional de $\Pr(G|X)$ (logits lineares) [^5]. A LDA, por outro lado, baseia-se na suposição mais forte de que as densidades condicionais de classe $f_k(x)$ são Gaussianas com covariância comum [^6, ^8].

2.  **Eficiência versus Robustez:** Ao confiar em suposições adicionais sobre o modelo (Gaussianidade), a LDA incorpora mais informações sobre os parâmetros (através da componente marginal $\Pr(X)$) e, consequentemente, pode estimá-los de forma mais eficiente (menor variância) *se as suposições do modelo forem verdadeiras* [^8]. Ignorar a parte marginal da verossimilhança, como faz a regressão logística, pode levar a uma perda de eficiência. Efron (1975) mostrou que, no pior caso (quando as suposições da LDA são verdadeiras), essa perda de eficiência assintótica na taxa de erro pode ser de cerca de 30% [^8]. No entanto, se as suposições da LDA (particularmente a Gaussianidade) não se verificarem, a regressão logística tende a ser mais **robusta**, pois suas estimativas não dependem da validade dessas suposições [^9]. Na prática, frequentemente as suposições da LDA não são corretas (por exemplo, presença de preditores qualitativos), tornando a regressão logística uma aposta mais segura [^9].

3.  **Sensibilidade a Outliers:** A LDA pode não ser robusta a outliers grosseiros. Observações longe da fronteira de decisão, que seriam sub-ponderadas pela regressão logística (como implícito no algoritmo IRLS, ver Seção 4.4.1), ainda desempenham um papel na estimação da matriz de covariância comum $\Sigma$ na LDA [^10]. Isso significa que pontos atípicos podem influenciar indevidamente a orientação das fronteiras de decisão estimadas pela LDA.

4.  **Casos de Separação Perfeita:** Quando os dados são perfeitamente separáveis por um hiperplano, as estimativas de máxima verossimilhança para os parâmetros da regressão logística podem tornar-se indefinidas (infinitas), pois a verossimilhança condicional pode ser levada arbitrariamente perto do seu valor máximo (ver Exercício 4.5 [^11] e Figura 4.16 [^12]). Os coeficientes da LDA para os mesmos dados permanecerão bem definidos [^10]. A verossimilhança marginal na LDA atua como um regularizador, exigindo que as densidades de classe sejam "visíveis" a partir da visão marginal, o que impede essas degenerações [^10].

5.  **Interpretação e Uso:** A regressão logística é frequentemente utilizada como uma ferramenta de análise de dados e inferência para entender o papel das variáveis de entrada na explicação do resultado [^13]. A LDA, embora também usada para classificação, deriva sua estrutura de um modelo generativo para os dados.

### Conclusão

Embora tanto a Regressão Logística quanto a LDA possam produzir classificadores com fronteiras de decisão lineares e partilhem uma forma funcional semelhante para os log-odds, elas derivam de princípios de modelagem e estimação distintos. A Regressão Logística adota uma abordagem *discriminativa*, modelando $\Pr(G|X)$ diretamente via maximização da **verossimilhança condicional** e deixando $\Pr(X)$ não especificada. A LDA adota uma abordagem *generativa*, modelando a **verossimilhança conjunta** $\Pr(X, G)$ sob suposições específicas (Gaussianidade das classes), o que implicitamente define um modelo para $\Pr(X)$. Esta diferença leva a um trade-off entre **eficiência** (potencialmente maior na LDA se as suposições forem válidas) e **robustez** (geralmente maior na Regressão Logística devido a menos suposições). A escolha entre os métodos na prática depende da validade das suposições da LDA para os dados em questão e dos objetivos da análise. A experiência sugere que os modelos frequentemente fornecem resultados semelhantes, mas a regressão logística é considerada uma opção mais segura e robusta em cenários onde as suposições da LDA são questionáveis [^9].

### Referências

[^1]: Page 127, Eq. 4.33 e texto circundante.
[^2]: Page 127, Eq. 4.34 e texto circundante.
[^3]: Page 119, Eq. 4.17, 4.18.
[^4]: Page 120, Eq. 4.19.
[^5]: Page 127, Bloco de texto após Eq. 4.36.
[^6]: Page 108, Eq. 4.8.
[^7]: Page 108, Eq. 4.7.
[^8]: Page 128, Primeiro parágrafo.
[^9]: Page 128, Último parágrafo.
[^10]: Page 128, Terceiro e quarto parágrafos.
[^11]: Page 136, Exercício 4.5.
[^12]: Page 134, Figura 4.16 e legenda.
[^13]: Page 121, Último parágrafo.

<!-- END -->